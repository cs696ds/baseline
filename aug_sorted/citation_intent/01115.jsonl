{"text": "I was also surprised at how much more accurate postag was compared to cpos .Thinking that postag was probably trained on the full treebank corpus , I did the same , and re - evaluated : .The result was 98.08 % accuracy .", "label": "", "metadata": {}, "score": "41.53864"}
{"text": "We therefore did not include FD modelling in the 1998 evaluation system .The soft - clustering technique developed at JHU [ 9 ] had shown worthwhile reductions in word error rate on the Switchboard corpus and we performed a preliminary evaluation on Broadcast News data .", "label": "", "metadata": {}, "score": "41.973465"}
{"text": "[52 ] used this corpus to develop an automated system for identifying negated text fragments .Their system achieved a precision of 96 % and a recall of 93 % .Vincze et al .[16 ] developed BioScope , an open access corpus of biomedical text containing token level annotations for negation cues and their respective scopes .", "label": "", "metadata": {}, "score": "42.855724"}
{"text": "The results were even worse than the three - way splitting model , and an overall ( micro - averaged ) performance loss of 5 % was observed .In order to test the concept further , we repeated the two - way splitting experiment with the GENIA Event corpus .", "label": "", "metadata": {}, "score": "44.53988"}
{"text": "She also provided a description for the scope of each cue based on its syntactic context .Sarafraz and Nenadic [ 33 ] used the previous studies on negation to derive a primary list of 14 negation cues .They further compiled a secondary list of 18 additional negation cues that were semi - automatically extracted from the BioNLP'09 ST corpus .", "label": "", "metadata": {}, "score": "44.69681"}
{"text": "This was improved to 6.5 % coverage error ( 3.3 % for in - domain ) .The structure of a semantic grammar is such that , once a concept hierarchy is created , addition to language variants is a simple process .", "label": "", "metadata": {}, "score": "45.63432"}
{"text": "Do you find any of them surprising ?Using the same training and test data , and the same feature extractor , build three classifiers for the task : a decision tree , a naive Bayes classifier , and a Maximum Entropy classifier .", "label": "", "metadata": {}, "score": "45.764595"}
{"text": "More recently , supervised machine learning ( ML ) technologies have received considerable attention and have shown promising results [ 16 - 18 ] .Bruce [ 19 ] applied a Bayesian algorithm and chose features based on their \" informative \" nature .", "label": "", "metadata": {}, "score": "46.220337"}
{"text": "We designed experiments to measure the impact of the choice of a negation cue list on the overall system performance .We found that a significant variation ( ranging between 5 % and 8 % , depending on the corpus ) in the system performance was caused by the cue list used .", "label": "", "metadata": {}, "score": "46.2795"}
{"text": "The best results ( 10-fold cross validation ) achieved on the BioNLP'09 ST corpus were 4 % less than the best results achieved on the GENIA Event corpus .The BioInfer corpus is the smallest in size ( almost 14 times smaller than GENIA Event ) and the most complex , with 60 different event types .", "label": "", "metadata": {}, "score": "46.639847"}
{"text": "A corpus of 21890 transcriptions ( from June 1998 through February 1999 ) was used for this purpose .This was reduced to 5162 sentences through preprocessing ( essentially replacement of tokens by class type ) then analyzed in order of frequency .", "label": "", "metadata": {}, "score": "46.699097"}
{"text": "The corpus has been annotated with various levels of linguistic and semantic information , such as sentence splitting , tokenization , part - of - speech tagging , chunking annotation , and term - event information .For chunker training , we selected a subset of 500 abstracts that constituted a previous version of the GENIA corpus [ 12 ] .", "label": "", "metadata": {}, "score": "47.199806"}
{"text": "Morante and Daelemans [ 43 ] presented a machine learning approach to detecting the scope of negation cues and tested their system on the BioScope corpus .Their system determined the full scope of negation cues with an accuracy of 66 % for abstracts , 41 % for papers and 71 % for clinical notes .", "label": "", "metadata": {}, "score": "47.332176"}
{"text": "However , Sarafraz and Nenadic [ 33 ] used command features to achieve better performance .The evaluation of the individual feature sets showed that dependency and lexical features achieved results more than twice as high as command features .Similarly , the combination of lexical and dependency features achieved significantly better results than the combination of the lexical and command features .", "label": "", "metadata": {}, "score": "47.388893"}
{"text": "To our knowledge , the only previous study on the classification of negated bio - events was reported by Sanchez - Graillet and Poesio [ 38 ] , who analysed negated PPIs in 50 biomedical articles .They identified seven classes of negation for PPIs , based on lexical and syntactic patterns .", "label": "", "metadata": {}, "score": "47.762894"}
{"text": "For example , in the BioNLP'09 ST corpus , 9 % of regulation events are negated , whereas only 5 % of binding events are negated .Based on this observation , we engineered two semantic features : one based on the event - type and the other on its complexity status ( i.e. , whether the event is simple or complex ) .", "label": "", "metadata": {}, "score": "48.228462"}
{"text": "Once we have a decision tree , it is straightforward to use it to assign labels to new input values .What 's less straightforward is how we can build a decision tree that models a given training set .But before we look at the learning algorithm for building decision trees , we 'll consider a simpler task : picking the best \" decision stump \" for a corpus .", "label": "", "metadata": {}, "score": "48.24121"}
{"text": "The key rule - based solutions include those presented by Chapman et al .[ 39 ] , Mutalik et al .[ 15 ] , Elkin et al .[ 41 ] , Huang and Lowe [ 37 ] and Boytcheva et al .", "label": "", "metadata": {}, "score": "48.491566"}
{"text": "In this study we investigate an alternative , automatic approach to create an annotated corpus .We have shown before that a system combining the outputs of various chunkers performs better than each of the individual chunkers .Here we postulate that the annotations of such a combined system on a given corpus can be taken as a reference standard , establishing a \" silver standard corpus \" ( SSC ) .", "label": "", "metadata": {}, "score": "48.563904"}
{"text": "One solution to this problem is to perform multiple evaluations on different test sets , then to combine the scores from those evaluations , a technique known as cross - validation .In particular , we subdivide the original corpus into N subsets called folds .", "label": "", "metadata": {}, "score": "48.763195"}
{"text": "These unambiguous cues accounted for 95 % of all instances of negations .Agarwal and Yu [ 44 ] developed a system for the automatic identification of negation cues using Conditional Random Fields ( CRF ) .Their system achieved an F - score of 98 % for clinical notes and 97 % for biomedical abstracts .", "label": "", "metadata": {}, "score": "48.8936"}
{"text": "The word error rate on BNeval97 of 14.3 % ( including FV and SAT ) represents a 13 % reduction relative to the same stage of the 1997 evaluation system [ 16 ] .We have recently experimented with discriminative training of large vocabulary systems and using the frame discrimination ( FD ) technique [ 13 ] .", "label": "", "metadata": {}, "score": "49.149277"}
{"text": "Several papers [ 29 , 30 ] realized this issue and reported results for the baseline .More specifically , they excluded samples with a majority sense larger than a threshold because they realized the contribution of the classifier would not be much for those cases .", "label": "", "metadata": {}, "score": "49.57401"}
{"text": "Some of these were included in 1998 HTK Hub4 evaluation system .Other experiments which did n't lead to overall word error rate reductions include discriminative training using the frame discrimination method and use of the soft - clustering technique .The paper is arranged as follows .", "label": "", "metadata": {}, "score": "49.624794"}
{"text": "However , if we instead evaluate the classifier on a more balanced corpus , where the most frequent word sense has a frequency of 40 % , then a 95 % accuracy score would be a much more positive result .( A similar issue arises when measuring inter - annotator agreement in 2 . ) 3.3 Precision and Recall .", "label": "", "metadata": {}, "score": "49.682247"}
{"text": "The choice of machine learning algorithm can significantly influence the performance of a classification task .This has been demonstrated for various natural language processing tasks including text categorisation [ 58 ] , word sense disambiguation [ 59 ] and the detection of negated terms [ 48 ] .", "label": "", "metadata": {}, "score": "49.703754"}
{"text": "In terms of automated approaches , Morante and Daelemans [ 43 ] proposed a machine learning system for the identification of negation cues .Their system achieved an F - score of over 99 % for both clinical notes and biomedical abstracts .", "label": "", "metadata": {}, "score": "49.730774"}
{"text": "Once an initial set of features has been chosen , a very productive method for refining the feature set is error analysis .First , we select a development set , containing the corpus data for creating the model .This development set is then subdivided into the training set and the dev - test set .", "label": "", "metadata": {}, "score": "49.927475"}
{"text": "View Article .Sang E , Buchholz S : Introduction to the CoNLL-2000 shared task : chunking .Proceedings of CoNLL-2000 and LLL-2000 ; Lisbon 2000 , 127 - 132 .Littlestone N , Warmuth MK : The weighted majority algorithm .", "label": "", "metadata": {}, "score": "49.946037"}
{"text": "The category - trigram used 1000 automatically derived word classes and was trained using LMtrain98 .Category bigrams and trigrams were added only if the leave - one training set likelihood improved and the final category model contained 0.85 million bigrams and 9.4 million trigrams .", "label": "", "metadata": {}, "score": "50.2302"}
{"text": "We note that the BioInfer corpus does not mark temporal or spatial attributes of bio - events .Instead , it incorporates specialized event - types for capturing this type of information .Finally , the comparisons and contrasts type accounts for 8 % of negated bio - events .", "label": "", "metadata": {}, "score": "50.247528"}
{"text": "Information on a word 's classification elsewhere in the same text has been successfully used in a number of NER systems ( cf .[14 ] and [ 15 ] ) .By incorporating all of these resources as features in a probabilistic system , we aimed to make use of their information while taking into account their reliability .", "label": "", "metadata": {}, "score": "50.29274"}
{"text": "45 ] .The key machine learning approaches include the systems presented by Averbuch et al .[46 ] , Goldin and Chapman [ 47 ] , Goryachev et al .[ 48 ] , Rokach et al .[49 ] and Councill et al .", "label": "", "metadata": {}, "score": "50.31501"}
{"text": "Our results are consistent with Caruana and Niculescu - Mizil [ 74 ] , who conducted a wide - ranging study , comparing the performance of ten supervised learning methods .They measured the performance of each method on 11 different binary classification problems , and found that Random Forest outperformed the other algorithms .", "label": "", "metadata": {}, "score": "50.434616"}
{"text": "This poorer performance was also reflected in the number of frames assigned to multiple speaker segments : 1.6 % for BNeval97 but 4.3 % for BNeval98 .This paper has described the development and performance of the 1998 HTK broadcast news transcription system .", "label": "", "metadata": {}, "score": "50.6379"}
{"text": "P1 to P3 use triphones and P4-P6 quinphones .The results ( over the complete 1998 evaluation set ) for each of these stages , together with additional contrasts , is shown in Table 6 .There is a 12 % reduction in error by using gender dependent models and VTLN ( P1 to P2 ) and a further 7 % from using MLLR .", "label": "", "metadata": {}, "score": "50.76778"}
{"text": "Our final system was trained on the combined training and development data of 10,000 sentences and 262,139 words and employed approximately 1.25 million features ; using quasi - Newton it trained in less than two hours .In a real - world application the time taken for training is largely irrelevant because it is a one - time cost .", "label": "", "metadata": {}, "score": "50.918365"}
{"text": "And if you are interested in a service that could apply these processes to your own data , please fill out this NLTK services survey .NLTK Training Sets .For the brown corpus , I trained on 2/3 of the reviews , lore , and romance categories , and tested against the remaining 1/3 .", "label": "", "metadata": {}, "score": "50.94954"}
{"text": "Although it can be possible to gain insight by studying them , it typically takes a lot more work .But all explicit models can make predictions about new \" unseen \" language data that was not included in the corpus used to build the model .", "label": "", "metadata": {}, "score": "51.06256"}
{"text": "These results provide strong evidence that both event and corpus characteristics , as well domain , can determine the most appropriate set of negation cues to use in a classifier .Thus , although some sets of domain specific cue lists ( e.g. , c40 and cCore ) can provide consistent performance across different corpora , explicit annotation of negation cues in different gold standard corpora will allow further sets of cue lists to be produced .", "label": "", "metadata": {}, "score": "51.07326"}
{"text": "Decision trees have been used extensively for various problems in bioinformatics [ 64 ] .They have also been used to detect negations in medical texts [ 47 ] .Our implementation of C4.5 used the following optimisation settings : ( 1 ) apply sub - tree replacement , ( 2 ) apply sub - tree raising , ( 3 ) require a minimum of 2 instances per leaf , ( 4 ) set a confidence threshold for pruning of 0.25 .", "label": "", "metadata": {}, "score": "51.267265"}
{"text": "This is particularly encouraging , as these corpora contain more complex and varied bio - events than the BioNLP'09 ST corpus .Selection of negation cues .Various lists of negation cues have previously been proposed for different negation detection tasks .", "label": "", "metadata": {}, "score": "51.392033"}
{"text": "We experimented with various algorithms and cue - lists , but we were not able to improve the performance for class-2 by more than 2 % .Two - Way Splitting : In this experiment , we split the bio - events according to their complexity status , i.e. , simple or complex .", "label": "", "metadata": {}, "score": "51.39676"}
{"text": "Most of the above papers reporting on the use of ML for WSD follow a similar pattern .A set of ambiguous words is selected , a corpus for each word is collected , and the different senses within the corpus are annotated ( automatically or manually ) .", "label": "", "metadata": {}, "score": "51.597015"}
{"text": "We were particularly interested in the comparison of the dependency and the constituency features , as both have previously been used for the task of identifying negated bio - events .Kilicoglu and Bergler [ 30 ] used a rule - based approach based on dependency relations between the negation cues and the event - triggers , whilst MacKinlay et al .", "label": "", "metadata": {}, "score": "51.821518"}
{"text": "These values have been calculated using a linear extrapolation function and the maximum ( 100 % ) recall value for event extraction .Sarafraz and Nenadic [ 33 ] proposed a machine learning approach for the identification of negated bio - events .", "label": "", "metadata": {}, "score": "51.87118"}
{"text": "Implementation .Our entry was a machine learning system using a discriminatively trained sequence tagger .We devoted most of our efforts to finding useful features .The final system makes exhaustive use of clues within the sentence , as well as using various external resources , and pre- and post - processing .", "label": "", "metadata": {}, "score": "52.392345"}
{"text": "Similarly , for the task of identifying negation scopes in biomedical research literature , Morante and Daelemans [ 43 ] obtained analogous results for Instance - Based learning and SVM .In contrast to these results , we found that Na\u00efve Bayes performs significantly worse than decision trees , and that Instance - Based learning outperforms SVM .", "label": "", "metadata": {}, "score": "52.54181"}
{"text": "Since the number of irrelevant documents far outweighs the number of relevant documents , the accuracy score for a model that labels every document as irrelevant would be very close to 100 % .It is therefore conventional to employ a different set of measures for search tasks , based on the number of items in each of the four categories shown in 3.1 : .", "label": "", "metadata": {}, "score": "52.57553"}
{"text": "At the very least , your training corpus and testing corpus should share the same set of part - of - speech tags , and in similar proportion .Otherwise , mistakes will be made , such as not recognizing common symbols , or finding -LRB- and -RRB- tags where they do not exist .", "label": "", "metadata": {}, "score": "52.58039"}
{"text": "This is in contrast to Sarafraz and Nenadic , who achieved an increase in both recall and precision .In terms of individual classes , Class-3 and Class-1 achieved results which were slightly higher and slightly lower than the single - class model , respectively .", "label": "", "metadata": {}, "score": "52.921165"}
{"text": "The main variations are usually in the selection of features and choice of machine - learning algorithms .Experiments are usually performed on a fixed amount of documents ( i.e. 1,000 abstracts ) per an ambiguous word , where the entire set consists of all the senses , and the sense distribution is generally uneven .", "label": "", "metadata": {}, "score": "52.957535"}
{"text": "This suggests that there is not necessarily a close correlation between the size of the corpus used for training and the overall performance of the system .We further tested this hypothesis by conducting an additional experiment on the GENIA Event corpus .", "label": "", "metadata": {}, "score": "53.11292"}
{"text": "They reported an F - measure of over 0.7 for genes with sufficient number of known document references .Liu [ 29 ] investigated the effect of window size and claimed that biomedical ambiguous words needed a larger window size than general English ambiguous words .", "label": "", "metadata": {}, "score": "53.189194"}
{"text": "View Article .Engelson SP , Dagan I : Minimizing manual annotation cost in supervised training from corpora .34th Annual Meeting of Association for Computational Linguistics 319 - 326 .Pustejovsky J , Castano J , Cochran B , Kotecki M , Morrell M : Automatic extraction of acronym - meaning pairs from MEDLINE databases .", "label": "", "metadata": {}, "score": "53.192574"}
{"text": "The above experiment was repeated 10 times , each time starting with a different randomly selected subset of 10 abstracts .The reported results are the averaged F - scores of the 10 experiments .Performance evaluation .The chunker and silver standard annotations were compared with the gold standard annotations by exact matching , similar to the procedure followed in CoNLL-2000 [ 15 ] .", "label": "", "metadata": {}, "score": "53.209335"}
{"text": "Testing showed that a GENIA - trained POS tagger performed much better than one trained on Wall Street Journal text , due to the specialized nature of biomedical text .The task essentially required only picking out whether words were genes or not , but to allow recognition of adjacent but different named entities , the data made a NEWGENE versus NEWGENE1 distinction ( in which the second of two adjacent but separate entities was labelled as NEWGENE1 ) .", "label": "", "metadata": {}, "score": "53.27281"}
{"text": "PubMed View Article .Banko M , Brill E : Mitigating the paucity - of - data problem : exploring the effect of training corpus size on classifier performance for natural language processing .Proceedings of the First International Conference on Human Language Technology Research ; San Diego 2001 , 1 - 5 .", "label": "", "metadata": {}, "score": "53.323444"}
{"text": "Based on the above analysis , we decided : ( 1 ) not to create separate lists for ambiguous and unambiguous cues , ( 2 ) to treat low manner indicators as negation cues .We then compiled four separate lists of negation cues for comparison .", "label": "", "metadata": {}, "score": "53.37065"}
{"text": "When training a supervised classifier , you should split your corpus into three datasets : a training set for building the classifier model ; a dev - test set for helping select and tune the model 's features ; and a test set for evaluating the final model 's performance .", "label": "", "metadata": {}, "score": "53.411884"}
{"text": "Considering only the problem of segmentation of NEs , Collins [ 21 ] applies reranking to candidate structures generated from a maximum - entropy tagger and achieves a 17.7 % relative reduction in error rate .Such features can not be encoded in a standard sequence tagger .", "label": "", "metadata": {}, "score": "53.444717"}
{"text": "The simple algorithm for selecting decision stumps described above must construct a candidate decision stump for every possible feature , and this process must be repeated for every node in the constructed decision tree .A number of algorithms have been developed to cut down on the training time by storing and reusing information about previously evaluated examples .", "label": "", "metadata": {}, "score": "53.453358"}
{"text": "Figure 2 shows corpus growth over time .In August the Communicator was publicized on the Web and made available for public use , increasing variability .All models are 5-state semi - continuous HMMs , though the number of states differs as noted below .", "label": "", "metadata": {}, "score": "53.47647"}
{"text": "Our experiments indicated that a GSC consisting of only 10 or 25 abstracts but expanded with an SSC yields similar performances as a GSC of 100 or 250 abstracts .Practically , these results suggest that the time and effort spent in creating a GSC of sufficient size may be much reduced .", "label": "", "metadata": {}, "score": "53.662354"}
{"text": "Borthwick A : A Maximum Entropy Approach to Named Entity Recognition .PhD thesis , New York University 1999 .McCallum A , Freitag D , Pereira F : Maximum Entropy Markov Models for Information Extraction and Segmentation .International Conference on Machine Learning 2000 , 591 - 598 .", "label": "", "metadata": {}, "score": "53.682247"}
{"text": "Clearly , the improvement is largest for small sizes of the GSC , leveling off with increasing size .The performance obtained with a small set of GSC abstracts combined with an SSC is comparable to a larger GSC set without SSC .", "label": "", "metadata": {}, "score": "53.687668"}
{"text": "This could involve parsing or less sophisticated treatment of coordinations .Our work in [ 16 ] shows that full parsing can give value to NER tasks .However , if one heads in this direction , one can no longer so easily think of NER as a lightweight initial processing step feeding into more complex analysis such as information extraction and full sentence understanding .", "label": "", "metadata": {}, "score": "53.716164"}
{"text": "If you also use the --metrics option , and the corpus reader provides a tagged_sents ( ) method , then you can get detailed performance metrics by comparing the tagger 's results against the actual tags .NLTK Default Tagger Performance on Treebank .", "label": "", "metadata": {}, "score": "53.74723"}
{"text": "Ginter [ 27 ] introduced a new family of classifiers , which were based on an ordering and weighing of the feature vectors obtained from word counts and word co - occurrence in the text .This method was used to determine whether a term was a gene versus a protein and achieved 86 % accuracy .", "label": "", "metadata": {}, "score": "53.794487"}
{"text": "We subsequently based our assessment of performance on error rates and associated standard errors .Our method also differs from related work because the sample size for each sense is always fixed , whereas in related work the sample size for the entire corpus is generally fixed but not the sample sizes of the senses .", "label": "", "metadata": {}, "score": "53.795826"}
{"text": "For example , training the chunkers on a GSC consisting of only 10 abstracts but supplemented with an SSC yielded similar performance as training them on a GSC of 100 - 250 abstracts .The combined system even performed better than any of the individual chunkers trained on a GSC of 500 abstracts .", "label": "", "metadata": {}, "score": "53.879593"}
{"text": "However , in the BioInfer corpus , it does not appear as a negation cue even once .Compilation of cue lists .Having identified negation cues as an important factor in the identification of negated bio - events , we conclude that it is important to : . determine the impact of the choice of cue lists on the overall task performance .", "label": "", "metadata": {}, "score": "53.917923"}
{"text": "In terms of individual classes , the complex class performed better than the simple class .We further experimented with various algorithms and cue - lists , but we were not able to improve the performance on the simple class by more than 1 % .", "label": "", "metadata": {}, "score": "53.969986"}
{"text": "Rather , the specific features of the annotated events appear to have more of an impact on the performance .In general , it seems that the level of detail of the information annotated for each event , in particular the text fragments associated with the event , is more important than the corpus size .", "label": "", "metadata": {}, "score": "54.091133"}
{"text": "Here , as others have done previously ( e.g. [ 15 ] ) , we experimented with building separate language models for each of the 3 data sources and then interpolating the language models .For efficiency and ease of use in decoding , a model merging process was employed using tools supplied by Entropic Ltd. , that gives a similar effect to explicit model interplotation but saves run - time computation and storage .", "label": "", "metadata": {}, "score": "54.3668"}
{"text": "The test set serves in our final evaluation of the system .For reasons discussed below , it is important that we employ a separate dev - test set for error analysis , rather than just using the test set .The division of the corpus data into different subsets is shown in 1.3 .", "label": "", "metadata": {}, "score": "54.495857"}
{"text": "We have also used a complexity feature , which indicates whether a bio - event is complex , i.e. , whether it has one or more participants which are bio - events themselves .Lexical Features : These include : whether there is a negation cue present in the sentence , the cue itself , whether a negation deactivator is present and its relative position with respect to the negation cue .", "label": "", "metadata": {}, "score": "54.62415"}
{"text": "Our results suggest that the time and effort spent in creating a GSC of sufficient size may be much reduced .Whether the approach is applicable to other systems in a natural - language processing pipeline has to be further investigated .", "label": "", "metadata": {}, "score": "54.742844"}
{"text": "These findings favour the wider argument that we made in Nawaz et al .[ 55 ] for the annotation of lexical cues indicating different aspects of the correct interpretation of an event .Feature engineering and selection .In comparison to previous work , our feature engineering approach has the following unique aspects : . use of a combination of syntactic , lexical , semantic , lexico - semantic and lexico - syntactic features . incorporation of all available textual fragments associated with the bio - event ( including the trigger , participants and attributes of the event ) . incorporation of event hierarchy information ( i.e. , complexity status ) . incorporation of negation deactivators . incorporation of constituency as well as dependency relations / scopes .", "label": "", "metadata": {}, "score": "54.87419"}
{"text": "X. Luo of JHU supplied code to help with the soft - clustering experiments .Fiscus , J.G. ( 1997 )A Post - Processing System to Yield Reduced Word Error Rates : Recogniser Output Voting Error Reduction ( ROVER ) .", "label": "", "metadata": {}, "score": "54.918243"}
{"text": "The notion that a combination of systems can be used to create a \" silver standard \" corpus has been explored in the CALBC ( Collaborative Annotation of a Large Biomedical Corpus ) project [ 5 ] .Through CALBC , the natural - language processing community has been invited to annotate a very large biomedical corpus with a variety of named - entity recognition systems .", "label": "", "metadata": {}, "score": "54.971905"}
{"text": "This agrees with work by Rifkin and Klatau [ 34 ] .A description of the different multi - class algorithms is provided in the Methods section .Table 5 .Results for BPD data set .Annotation of the table : Dist : Distribution of senses ; S. Size : sample size ; Err .", "label": "", "metadata": {}, "score": "55.121353"}
{"text": "We compiled two such lists ( c40 and cCore ) , both of which performed consistently in all experiments .We also discovered that , for the task of identifying negated bio - events , the Random Forest algorithm consistently outperforms five other learning algorithms .", "label": "", "metadata": {}, "score": "55.16344"}
{"text": "To begin with , they 're simple to understand , and easy to interpret .This is especially true near the top of the decision tree , where it is usually possible for the learning algorithm to find very useful features .", "label": "", "metadata": {}, "score": "55.192123"}
{"text": "This calculation is then overlaid with a Viterbi - style dynamic programming algorithm [ 3 ] to find the best sequence of classifications .Such models are commonly referred to as maximum entropy models in the NLP literature [ 4 , 5 ] and are also known as maximum entropy Markov models or MEMMs [ 6 ] .", "label": "", "metadata": {}, "score": "55.244946"}
{"text": "We also sought to incorporate the GENIA corpus of NE - annotated MEDLINE abstracts but found this difficult because it used an entirely different tag set to the BioCreative data and the mapping between them was unclear .The C&C tagger is another maximum entropy sequence tagger ; it was used here for pragmatic reasons related to memory use .", "label": "", "metadata": {}, "score": "55.32116"}
{"text": "Also surprising was that removing word shape features actually increased our f - score by 0.13 % .The \" zero - order \" and \" first - order \" experiments refer to how far back the classifier can see the NE tags assigned to previous words during sequence search .", "label": "", "metadata": {}, "score": "55.379333"}
{"text": "It has also been used to detect negations in medical texts [ 47 , 48 ] .Our implementation of Na\u00efve Bayes used a default precision of 0.1 for numeric attributes for cases of zero training instances .SVM : Support Vector Machines ( SVMs ) [ 69 ] perform classification by constructing an N -dimensional hyperplane that optimally separates the data into two categories .", "label": "", "metadata": {}, "score": "55.57727"}
{"text": "The key results are as follows : .The use of the c40 cue list resulted in high performance on all three datasets .This list resulted in better performance than other cue lists on GENIA Event and BioNLP'09 ST , achieving the highest precision and recall on both datasets .", "label": "", "metadata": {}, "score": "55.60849"}
{"text": "However , its precision was noticeably low ( ranging between 32 % and 42 % ) , which led to the lowest F - scores for all datasets .SVM scored fifth for all three datasets .Although it performed much better than Na\u00efve Bayes , it was significantly behind Random Forest and C4.5 .", "label": "", "metadata": {}, "score": "55.65986"}
{"text": "Therefore , this type of method may not be applicable and ML approaches may be useful .Recently , Humphrey [ 26 ] proposed another type of statistical - based method to resolve the ambiguity problem within the UMLS Metathesaurus .They used a Journal Descriptor Indexing ( JDI ) method , which is ultimately based on statistical associations between words in a training set of MEDLNE citations and a small set of journal descriptors assumed to be inherited by the citations .", "label": "", "metadata": {}, "score": "55.68736"}
{"text": "Thus , when using a more powerful model , we end up with less data that can be used to train each parameter 's value , making it harder to find the best parameter values .As a result , a generative model may not do as good a job at answering questions 1 and 2 as a conditional model , since the conditional model can focus its efforts on those two questions .", "label": "", "metadata": {}, "score": "55.964577"}
{"text": "Our analysis showed that the ability of a word / phrase to act as a negation cue depends not only on the context and domain of text , but also on the annotation / information perspective ( e.g. , linguistic vs. biological perspective ) .", "label": "", "metadata": {}, "score": "56.057137"}
{"text": "At that point , the best thing you can do is find / make good data , then use existing algos to learn from it .\\n .\\n .the original NLTK is very good , available for free online , but takes \" textbook \" approach .", "label": "", "metadata": {}, "score": "56.1018"}
{"text": "We observed that the triphone coverage of the corpus was rather sparse .For example , while there were 129516 possible triphones in the domain ( computed from the dictionary used for recognition ) , only 15783 were present in the training data .", "label": "", "metadata": {}, "score": "56.10953"}
{"text": "In summary , descriptive models provide information about correlations in the data , while explanatory models go further to postulate causal relationships .Most models that are automatically constructed from a corpus are descriptive models ; in other words , they can tell us what features are relevant to a given pattern or construction , but they ca n't necessarily tell us how those features and patterns relate to one another .", "label": "", "metadata": {}, "score": "56.117752"}
{"text": "We chose the following six algorithms , and used their WEKA [ 60 ] library implementations to carry out our experiments : .Decision Trees : Decision Tree algorithms learn rules that are expressed as \" conjunctions of constraints on the attribute values of instances .", "label": "", "metadata": {}, "score": "56.12697"}
{"text": "Tagging .Tagging used a Viterbi - style algorithm with a beam size of 30 .Tagging was quick ; the evaluation data of 5000 sentences was tagged in approximately one minute ( excluding web statistics , which were pre - computed ) .", "label": "", "metadata": {}, "score": "56.143337"}
{"text": "This suggests that more clarity in what should be annotated ( or perhaps just when a variety of answers of different extent should be counted as correct ) is needed .It also may suggest that performance of 83 % or improvement of just a few points is sufficient for the technology to be practically applicable .", "label": "", "metadata": {}, "score": "56.150696"}
{"text": "In that case , stick with a simpler tagger that 's nearly as accurate and orders of magnitude faster .ABSTRACT .This paper presents the development of the HTK broadcast news transcription system for the November 1998 Hub4 evaluation .Overall these changes to the system reduced the error rate by 13 % on the 1997 evaluation data and the final system had an overall word error rate of 13.8 % for the 1998 evaluation data sets .", "label": "", "metadata": {}, "score": "56.17764"}
{"text": "Despite being successfully used for various text mining and bioinformatics tasks [ 66 , 67 ] , the Random Forest algorithm has not been previously used for detecting negation scopes , negated concepts or negated events .Logistic Regression : Logistic Regression classifiers try to predict the class probability of an object by fitting the training data to a logistic function [ 61 ] .", "label": "", "metadata": {}, "score": "56.252502"}
{"text": "As future work , we plan to integrate our system with the EventMine system [ 75 ] .The resulting system will be able to extract bio - events of the specified polarity from plain text documents , and will serve as the foundation for a more elaborate system for detecting textual contradictions .", "label": "", "metadata": {}, "score": "56.29284"}
{"text": "View Article .Pedersen T , Bruce R : Distinguishing word senses in untagged text .Second Conference on Empirical Methods in Natural Language Processing .Hsu G , Lin C : A comparison of methods for multi - class support vector machines .", "label": "", "metadata": {}, "score": "56.49009"}
{"text": "These are : the compilation of a negation cue list , the design and selection of suitable features and the choice of machine learning algorithm .In order to analyse these aspects , we conducted a series of experiments on the three bio - event corpora .", "label": "", "metadata": {}, "score": "56.548866"}
{"text": "When trained on GENIA GSC and tested on PennBioIE GSC , the F - score of the combined system dropped to 82.1 % for noun phrases and 91.9 % for verb phrases .Since this performance is considerably lower than that of the combined system based on all chunkers , we did not further pursue the use of an SSC based on the three trainable chunkers only .", "label": "", "metadata": {}, "score": "56.58992"}
{"text": "On the other hand , if scores vary widely across the N training sets , then we should probably be skeptical about the accuracy of the evaluation score .4 Decision Trees .In the next three sections , we 'll take a closer look at three machine learning methods that can be used to automatically build classification models : decision trees , naive Bayes classifiers , and Maximum Entropy classifiers .", "label": "", "metadata": {}, "score": "56.60756"}
{"text": "In particular , for each consecutive word index i , a score is computed for each possible current and previous tag .This same basic approach is taken by two more advanced models , called Maximum Entropy Markov Models and Linear - Chain Conditional Random Field Models ; but different algorithms are used to find scores for tag sequences .", "label": "", "metadata": {}, "score": "56.673603"}
{"text": "We investigated the use of a silver standard corpus ( SSC ) that is automatically generated by combining the outputs of multiple chunking systems .We explored two use scenarios : one in which chunkers are trained on an SSC in a new domain for which a GSC is not available , and one in which chunkers are trained on an available , although small GSC but supplemented with an SSC .", "label": "", "metadata": {}, "score": "56.681347"}
{"text": "Many previous studies in negation detection have used SVMs [ 33 , 43 , 48 ] .Our implementation of SVM replaced all missing values , and converted the nominal attributes to binary attributes .It also normalised all attributes by default .", "label": "", "metadata": {}, "score": "56.732513"}
{"text": "The micro averages for precision , recall and F - score were used to measure the overall performance .In comparison to the results achieved without data splitting , the three - way splitting model showed a considerable ( 21 % ) improvement in precision .", "label": "", "metadata": {}, "score": "56.805904"}
{"text": "Van Landeghem et al .[ 32 ] achieved the second best results of 11 % recall , 45 % precision and 17 % F - score .They also used a customised rule - based system .MacKinlay et al .", "label": "", "metadata": {}, "score": "56.8308"}
{"text": "Benefits over traditional baselines are particularly pronounced in morphologically rich languages .Thus , any orthographically aware model must be able to capture non - compositional effects in addition to more regular effects due to , e.g. , morphological processes .To model the complex form - function relationship , we turn to long short - term memories ( LSTMs ) , which are designed to be able to capture complex non - linear and non - local dynamics in sequences .", "label": "", "metadata": {}, "score": "56.915497"}
{"text": "If each ambiguous gene symbol in an article were accompanied by its corresponding long form , the disambiguation task would be much easier .Schijvenaars [ 13 ] showed that 33 % of the human genes in their thesaurus were affected by homonymy .", "label": "", "metadata": {}, "score": "57.00541"}
{"text": "The extent to which explicit models can give us insights into linguistic patterns depends largely on what kind of model is used .Some models , such as decision trees , are relatively transparent , and give us direct information about which factors are important in making decisions and about which factors are related to one another .", "label": "", "metadata": {}, "score": "57.01055"}
{"text": "Various decision tree algorithms have been proposed over the years .However , we concentrated on C4.5 [ 62 ] , which is an enhanced version of ID3 [ 63 ] .The C4.5 algorithm constructs the decision tree by choosing the attribute with the highest value of normalised information gain at each node and creates new branches corresponding to the different values of this attribute .", "label": "", "metadata": {}, "score": "57.01829"}
{"text": "do contractions matter ? can you replace them with two words ?Demo shows the results from 4 different tokenizers\\n . loads a pos tagger trained on treebank - first call will take a few seconds to load the pickle file off disk , every subsequent call will use in - memory tagger .", "label": "", "metadata": {}, "score": "57.08858"}
{"text": "You can also get detailed metrics on Found vs Actual counts , as well as Precision and Recall for each tag by using the --metrics argument with a corpus that provides a tagged_sents method , like treebank : .These additional metrics can be quite useful for identifying which tags a tagger has trouble with .", "label": "", "metadata": {}, "score": "57.145317"}
{"text": "Because of its size ( on 26.02.2004 , Google estimated that it indexed over 4,285 M web pages ) , the web is the least vulnerable to incompleteness but is highly vulnerable to noise .Nevertheless , the web has been used to good effect in various NLP tasks ( see [ 11 ] for an overview ) from machine translation [ 12 ] to anaphora resolution [ 13 ] .", "label": "", "metadata": {}, "score": "57.184113"}
{"text": "It can be seen that the new training corpus reduces the WER by a 0.7 % absolute and a further 0.5 % absolute reduction was obtained by using a merged interpolated language model .The merged interpolated models gave most improvement on the spontaneous speech portions of the data .", "label": "", "metadata": {}, "score": "57.215733"}
{"text": "Furthermore the 1998 4-gram language model gave a constant 15 % improvement ( over all test sets ) in perplexity over the equivalent model used in the 1997 evaluation .The overall decoding process proceeds as for the 1997 system , but with a couple of additional stages .", "label": "", "metadata": {}, "score": "57.235695"}
{"text": "The event - triggers and/or participants of several events may fall under the scope of a negation cue .However , it is highly unlikely that all of these events will be negated .Vincze et al .[ 35 ] conducted an in - depth comparison of a linguistically annotated corpus of negation scopes ( BioScope ) and a biologically annotated corpus of negated bio - events ( GENIA Event ) .", "label": "", "metadata": {}, "score": "57.258213"}
{"text": "The process can then be repeated until all of the inputs have been labeled .This strategy is demonstrated in 1.7 .First , we must augment our feature extractor function to take a history argument , which provides a list of the tags that we 've predicted for the sentence so far .", "label": "", "metadata": {}, "score": "57.269226"}
{"text": "Similar results were also reported by Mutalik et al .[ 15 ] , who , despite identifying over 60 negation cues , found that only a small set of cues account for the majority of negation instances .In their corpus of 40 medical documents , only four negation cues accounted for almost 93 % of all negation instances .", "label": "", "metadata": {}, "score": "57.27384"}
{"text": "View Article .Kilicoglu H , Bergler S : Syntactic Dependency Based Heuristics for Biological Event Extraction .In BioNLP 2009 Shared Task .Stroudsburg , PA : Association for Computational Linguistics ( ACL ) ; 2009:119 - 127 .MacKinlay A , Martinez D , Baldwin T : Biomedical event annotation with CRFs and precision grammars .", "label": "", "metadata": {}, "score": "57.292435"}
{"text": "This in turn was used to design a set of 500 sentences densely sampling these triphones and recordings made , totaling 3141 utterances .The addition of such focused supplementary data resulted in a relative reduction in word error rates of less than 5 % on the above test sets .", "label": "", "metadata": {}, "score": "57.324516"}
{"text": "One way to capture this intuition that distribution ( i ) is more \" fair \" than the other two is to invoke the concept of entropy .In the discussion of decision trees , we described entropy as a measure of how \" disorganized \" a set of labels was .", "label": "", "metadata": {}, "score": "57.362892"}
{"text": "Sentence splitting , tokenization , and part - of - speech tagging were included in our chunking pipeline , either as integral part of the chunkers ( Yamcha , Lingpipe ) or as separate components ( OpenNLP ) .We used the gold - standard sentence , token , and part - of - speech annotations for training , but did not use this information in creating the SSC or evaluating the trained models : the input of the annotation pipeline consisted of plain abstracts , the output were chunking annotations .", "label": "", "metadata": {}, "score": "57.424118"}
{"text": "Curran JR , Clark S : Language Independent NER using a Maximum Entropy Tagger .Proceedings of the Seventh Conference on Natural Language Learning ( CoNLL-03 ) , Edmonton , Canada 2003 , 164 - 167 .Finkel J , Dingare S , Nguyen H , Nissim M , Manning C : Exploiting Context for Biomedical Entity Recognition : From Syntax to the Web .", "label": "", "metadata": {}, "score": "57.4301"}
{"text": "Unknown Words in Treebank .Suprisingly , the treebank corpus contains 6592 words tags with -NONE- .Share this : .If you liked the NLTK demos , then you 'll love the text processing APIs .They provide all the functionality of the demos , plus a little bit more , and return results in JSON .", "label": "", "metadata": {}, "score": "57.45777"}
{"text": "There are unfortunately two difficulties with this approach .Most of the early data captured for training will be from a relatively small pool of developers ; at the same time the rate of data acquisition will be slow .Figure 1 shows the distribution of data across speakers for the CMU Communicator ( through the Fall of 1999 ) .", "label": "", "metadata": {}, "score": "57.491943"}
{"text": "International Conference on Machine Learning 2001 , 282 - 289 .Kudo T , Matsumoto Y : Chunking with Support Vector Machines .Proceedings of the North American Chapter of the Association for Computational Linguistics 2001 .Collins M : Ranking Algorithms for Named Entity Extraction : Boosting and the Voted Perceptron .", "label": "", "metadata": {}, "score": "57.58381"}
{"text": "Combining the best solutions for each aspect of the problem , we propose a novel framework for the identification of negated bio - events .We have evaluated our system on each of the three open access corpora mentioned above .The performance of the system significantly surpasses the best results previously reported on the BioNLP'09 ST corpus , and achieves even better results on the GENIA Event and BioInfer corpora , both of which contain more varied and complex events .", "label": "", "metadata": {}, "score": "57.59819"}
{"text": "However there is still much interest in reducing the error rate of such systems further which will increase the potential for further applications as well as establishing techniques for the accurate transcription of general audio material .The HTK Broadcast News Transcription System used in the 1997 DARPA / NIST Hub4 evaluation had an overall word error rate of 15.8 % .", "label": "", "metadata": {}, "score": "57.60139"}
{"text": "This allows feature values to interact , but can be problematic when two or more features are highly correlated with one another .Maximum Entropy classifiers use a basic model that is similar to the model used by naive Bayes ; however , they employ iterative optimization to find the set of feature weights that maximizes the probability of the training set .", "label": "", "metadata": {}, "score": "57.60382"}
{"text": "In terms of volume , the GENIA Event corpus is the largest , with almost 37,000 events , while BioInfer is the smallest , with fewer than 2,700 bio - events .Regarding event - types , BioInfer is the richest , with 60 event - types , whilst BioNLP'09 ST is the simplest , with only 9 event - types .", "label": "", "metadata": {}, "score": "57.61055"}
{"text": "CoNLL 7 2003 , 180 - 183 .Manning CD , Sch\u00fctze H : Foundations of Statistical Natural Language Processing Boston , MA : MIT Press 1999 .Ratnaparkhi A : A Maximum Entropy Model for Part - Of - Speech Tagging .", "label": "", "metadata": {}, "score": "57.80668"}
{"text": "In contrast , the Maximum Entropy classifier model leaves it up to the user to decide what combinations of labels and features should receive their own parameters .In particular , it is possible to use a single parameter to associate a feature with more than one label ; or to associate more than one feature with a given label .", "label": "", "metadata": {}, "score": "57.8368"}
{"text": "Proc EMNLP 2002 , 41 - 48 .Mohammad S , Pedersen T : Combining lexical and syntactic features for supervised word sense disambiguation .Proc of the CoNLL .Wilks Y , Fass D , Guo C , MacDonald J , Plate T , Slator B : Providing Machine Tractable Dictionary Tools Cambridge , MA : MIT Press 1990 .", "label": "", "metadata": {}, "score": "57.84652"}
{"text": "We present a maximum - entropy based system incorporating a diverse set of features for identifying gene and protein names in biomedical abstracts .Results .This system was entered in the BioCreative comparative evaluation and achieved a precision of 0.83 and recall of 0.84 in the \" open \" evaluation and a precision of 0.78 and recall of 0.85 in the \" closed \" evaluation .", "label": "", "metadata": {}, "score": "57.85208"}
{"text": "Bioinformatics 2004 , 20 : 2597 - 2604 .View Article PubMed .Schijvenaars BJ , Mons B , Weeber M , Schuemie MJ , van Mulligen EM , Wain HM , et al .: Thesaurus - based disambiguation of gene symbols .", "label": "", "metadata": {}, "score": "57.874466"}
{"text": "Their system achieved the third best results with 5 % recall , 34 % precision and 9 % F - score .It is important to note that these systems did not operate on gold standard event annotations .Instead , they performed event extraction as a preliminary step to the identification of negated events .", "label": "", "metadata": {}, "score": "57.934383"}
{"text": "The significance of this observation is that it implies that the language for a domain can be incrementally extended without the concomitant need for restructuring the entire grammar as its complexity increases .It further raises the possibility that language components may be reused from application to application , provided that the sub - domains in question are substantially the same .", "label": "", "metadata": {}, "score": "57.955856"}
{"text": "The distributions of the various states of the triphones that were learnt in this manner were then used to build the final decision trees .Since this tends to merge the identity of triphones with similar transitions , the entropy of adjacent states was also considered during the decision tree building process to maintain triphone identities .", "label": "", "metadata": {}, "score": "57.95979"}
{"text": "This problem was somewhat ameliorated within the BioCreative evaluation by a facility for annotators to be able to specify alternate correct answers , which allowed as correct matches of several lengths in places where the annotators thought it appropriate .The CoNLL task also used a straight f - score metric , but note that the \" mid - nineties \" results commonly remembered from MUC NER competitions reflect an easier metric where partial credit was given for cases of incorrect boundary identification .", "label": "", "metadata": {}, "score": "57.99729"}
{"text": "We also found that we obtained different gene boundaries when we ran the classifier forwards versus backwards ( reversing the order of the words ) and obtained a significant improvement in recall at the expense of precision by simply combining the two sets of results .", "label": "", "metadata": {}, "score": "58.039886"}
{"text": "[ 41 ] created an ontology of terms that start negations ( e.g. , no , denies and ruled out ) and another set which stop the propagation of the assignment of negation ( e.g. , other than ) .Kilicoglu and Bergler [ 30 ] created a list of 9 negation cues from the BioNLP'09 ST corpus .", "label": "", "metadata": {}, "score": "58.044624"}
{"text": "Cue list comparison .In order to compare the performance of the four cue lists , we ran a series of experiments using each cue list ( in turn ) to engineer the features .In all cases , the Random Forest algorithm was used , as it had consistently produced the best results for all datasets .", "label": "", "metadata": {}, "score": "58.062546"}
{"text": "In addition , papers should also characterize the difficulty of the WSD task , the WSD situations addressed and not addressed , as well as the ML methods and features used .This should lead to an improved understanding of the generalizablility and the limitations of the methodology .", "label": "", "metadata": {}, "score": "58.171883"}
{"text": "In their study , rare senses ( senses appearing in less than 40 documents ) were excluded from the testing set .This makes the disambiguation task easier because it reduces the problem of sparse senses .In addition , the training set was created based on long - form and short - form pairs , where ambiguous words not having long - forms were not tested .", "label": "", "metadata": {}, "score": "58.416214"}
{"text": "However the observed decrease in error rate was more dramatic in the cases where the different senses were well separated .For example , in BSA , the error rate dropped to approximately 5 % when the sample size was 80 and the sense distributions were almost balanced , and it was approximately 8 % for other distributions with the same size .", "label": "", "metadata": {}, "score": "58.445057"}
{"text": "The classifier was then run again ; this time incorporating the web feature .Using web - querying only on likely candidates for genes as identified by an initial run of the tagger was more efficient than using it on all words .", "label": "", "metadata": {}, "score": "58.47068"}
{"text": "Does a \" universal \" list of negation cues exist ?Our analysis of negated bio - events confirmed that negation cues are ambiguous .Whether a word acts as a negation cue for a bio - event depends on the lexical as well as the contextual polarity of the word .", "label": "", "metadata": {}, "score": "58.4813"}
{"text": "The same study , which was also performaned for the Fly organism , showed similar results , but with slightly higher ambiguity rates .For a more complete description of this study and the results , please [ see additional file 1 ] .", "label": "", "metadata": {}, "score": "58.538223"}
{"text": "Kang N , van Mulligen EM , Kors JA : Comparing and combining chunkers of biomedical text .J Biomed Inform 2011 , 44 : 354 - 360 .PubMed View Article .Rebholz - Schuhmann D , Yepes AJ , van Mulligen EM , Kang N , Kors J , Milward D , Corbett P , Hahn U : The CALBC silver standard corpus - harmonizing multiple semantic annotations in a large biomedical corpus .", "label": "", "metadata": {}, "score": "58.591194"}
{"text": "Therefore , it is hard to compile a universal list of negation cues .However , the potential utility of domain specific lists has been reinforced by our experiments .The c40 and cCore cue lists showed consistently high performance across the three bio - event corpora .", "label": "", "metadata": {}, "score": "58.638615"}
{"text": "The basic adaptation approach in our system remains MLLR for both means and variances [ 2 ] .In addition , for the quinphone stage of iterative unsupervised adaptation , the effect of a single full variance ( FV ) transform [ 3 ] was investigated .", "label": "", "metadata": {}, "score": "58.72863"}
{"text": "Paris : European Language Resources Association ( ELRA ) ; 2010:2498 - 2507 .Miyao Y , Tsujii J : Feature Forest Models for Probabilistic HPSG Parsing .Comput Linguist 2008 , 34 ( 1 ) : 35 - 80 .View Article .", "label": "", "metadata": {}, "score": "58.76522"}
{"text": "Features : These include command and scope features .The concept of a command relation was first introduced by Langacker [ 57 ] as a means of identifying the nodes affected by a given element in the constituency parse tree of a sentence .", "label": "", "metadata": {}, "score": "58.801712"}
{"text": "Vincze et al .[16 ] report that around 13 % of sentences found in biomedical research articles contain some form of negation .Our analysis of three open access bio - event corpora showed that more than 6 % of bio - events are negated .", "label": "", "metadata": {}, "score": "58.826828"}
{"text": "This is the approach taken by Hidden Markov Models .Hidden Markov Models are similar to consecutive classifiers in that they look at both the inputs and the history of predicted tags .However , rather than simply finding the single best tag for a given word , they generate a probability distribution over tags .", "label": "", "metadata": {}, "score": "58.873653"}
{"text": "The information gain is then equal to the original entropy minus this new , reduced entropy .The higher the information gain , the better job the decision stump does of dividing the input values into coherent groups , so we can build decision trees by selecting the decision stumps with the highest information gain .", "label": "", "metadata": {}, "score": "58.952682"}
{"text": "The combined system performs better than any of the individual chunkers , including GATE and MetaMap which proved to have F - scores lower than each of the three trainable chunkers , in agreement with our previous findings [ 4 ] .", "label": "", "metadata": {}, "score": "59.03785"}
{"text": "With the same sample size change , the error rate for PCA dropped from 43.00 % to only 28.53 % .Results for BPD are shown in Table 5 , which contains the results from three different multi - class SVM algorithms .", "label": "", "metadata": {}, "score": "59.088875"}
{"text": "One solution to this problem is to stop dividing nodes once the amount of training data becomes too small .Another solution is to grow a full decision tree , but then to prune decision nodes that do not improve performance on a dev - test .", "label": "", "metadata": {}, "score": "59.14883"}
{"text": "Using all of the knowledge sources , the SVM method achieved the highest accuracy rate of 65.4 % .Another type of WSD approach uses established knowledge from curated terminology systems [ 23 , 24 ] .In the biomedical domain , Schijvenaars [ 13 ] developed a simple thesaurus - based algorithm to disambiguate human gene symbols using training data from PubMed abstracts and annotations from the Online Mendelian Inheritance in Man(OMIM )", "label": "", "metadata": {}, "score": "59.15174"}
{"text": "Since annotation diversity is generally considered a key factor for the improvement seen by ensemble systems ( 4 ) , it may be expected that the combined chunker system shows a smaller increase of performance when based on the SSC than on the GSCs .", "label": "", "metadata": {}, "score": "59.157284"}
{"text": "Abstract .Background .To train chunkers in recognizing noun phrases and verb phrases in biomedical text , an annotated corpus is required .The creation of gold standard corpora ( GSCs ) , however , is expensive and time - consuming .", "label": "", "metadata": {}, "score": "59.168713"}
{"text": "For example , decision trees can be very effective at capturing phylogeny trees .However , decision trees also have a few disadvantages .One problem is that , since each branch in the decision tree splits the training data , the amount of training data available to train nodes lower in the tree can become quite small .", "label": "", "metadata": {}, "score": "59.229572"}
{"text": "Remarkably , the performance difference between the combined systems based on GENIA GSC and PennBioIE SSC is only small ( 0.2 percentage point ) .To test the consistency of this result , we redid the experiment with interchanged corpora , i.e. , GENIA GSC was used for training the chunkers and generating the SSC , and PennBioIE GSC was used for testing .", "label": "", "metadata": {}, "score": "59.256306"}
{"text": "Thompson P , Iqbal S , McNaught J , Ananiadou S : Construction of an annotated corpus to support biomedical information extraction .BMC Bioinformatics 2009 , 10 : 349 .View Article PubMed .Buyko E , Beisswanger E , Hahn U : The GeneReg Corpus for Gene Expression Regulation Events - An Overview of the Corpus and its In - Domain and Out - of - Domain Interoperability .", "label": "", "metadata": {}, "score": "59.283943"}
{"text": "Liu H , Johnson SB , Friedman C : Automatic resolution of ambiguous terms based on machine learning and conceptual relations in the UMLS .J Am Med Inform Assoc 2002 , 9 : 621 - 636 .View Article PubMed .", "label": "", "metadata": {}, "score": "59.340393"}
{"text": "The baseline acoustic corpus available in 1997 used recorded audio from various US broadcast news shows ( television and radio ) .This amounted to a total of 72 hours of usable data ( BNtrain97 ) .This data was annotated to ensure that each segment was acoustically homogeneous ( same speaker , background noise condition and channel ) .", "label": "", "metadata": {}, "score": "59.342293"}
{"text": "Stroudsburg , PA : Association for Computational Linguistics ; 2010:46 - 49 .Sauri R , Pustejovsky J : FactBank : a corpus annotated with event factuality .Lang Resour Eval 2009 , 43 ( 3 ) : 227 - 268 .", "label": "", "metadata": {}, "score": "59.378277"}
{"text": "The results presented here agree with general results presented in the literature on the performance of classifiers [ 43 - 45 ] .Future work .To further analyze the effects of \" sample size \" , \" sense distribution \" and \" degree of difficulty \" on the error rate , an error decomposition model will be explored .", "label": "", "metadata": {}, "score": "59.451027"}
{"text": "For example , the Expected Likelihood Estimation for the probability of a feature given a label basically adds 0.5 to each count(f , label ) value , and the Heldout Estimation uses a heldout corpus to calculate the relationship between feature frequencies and feature probabilities .", "label": "", "metadata": {}, "score": "59.4517"}
{"text": "Our study is different because it quantified the effect of similarity of senses , and studied the relation between \" similarity of senses \" and other issues such as \" sample size \" and \" sense distribution \" .Podowski 's [ 28 ] work covered task types 2 and 3 , while Hatzivassiloglou 's [ 10 ] work addressed task type 4 .", "label": "", "metadata": {}, "score": "59.46773"}
{"text": "Once a model is deemed sufficiently accurate , it can then be used to automatically predict information about new language data .These predictive models can be combined into systems that perform many useful language processing tasks , such as document classification , automatic translation , and question answering .", "label": "", "metadata": {}, "score": "59.513245"}
{"text": "\\n .\\n .can train taggers , chunkers , and text classifiers , and is great for analyzing corpora and how a model performs against a labeled corpus .I use nltk - trainer to train all my models nowadays .", "label": "", "metadata": {}, "score": "59.549423"}
{"text": "Earlier studies have investigated a number of the issues discussed here in the context of constructing better classifiers .A discussion of some of the issues involved can be found in [ 43 ] .Here , we examined these issues in the context of word sense disambiguation .", "label": "", "metadata": {}, "score": "59.63247"}
{"text": "The intuition that motivates Maximum Entropy classification is that we should build a model that captures the frequencies of individual joint - features , without making any unwarranted assumptions .An example will help to illustrate this principle .Suppose we are assigned the task of picking the correct word sense for a given word , from a list of ten possible senses ( labeled A - J ) .", "label": "", "metadata": {}, "score": "59.65863"}
{"text": "Wilson T , Wiebe J , Hoffmann P : Recognizing contextual polarity : An exploration of features for phrase - level sentiment analysis .Computational linguistics 2009 , 35 ( 3 ) : 399 - 433 .View Article .Nawaz R , Thompson P , McNaught J , Ananiadou S : Meta - Knowledge Annotation of Bio - Events .", "label": "", "metadata": {}, "score": "59.73857"}
{"text": "Meanwhile , we also recorded the percentage of ambiguous words that were removed from the ambiguous word - list for different thresholds .We removed words with frequencies higher than 10 % , 1 % , 0.1 % and 0.05 % from the two lists of the mouse organism .", "label": "", "metadata": {}, "score": "59.775166"}
{"text": "Then we give implementation details of our training procedure , and finally we describe tagging and a postprocessing phase aimed at improving boundary detection .Model .The model used was a conditional Markov model sequence tagger , implemented in Java and based on the tagger used in [ 2 ] .", "label": "", "metadata": {}, "score": "59.81133"}
{"text": "A further study by Tolentino et al .[40 ] analysed negated biomedical concepts occurring in a corpus of 41 medical documents .They found that only 5 negation cues ( no , neither / nor , ruled out , denies and without ) accounted for 89 % of all negated concepts found in the corpus .", "label": "", "metadata": {}, "score": "59.822144"}
{"text": "Using a clustering procedure and a set of smoothing rules the final segments to be processed by the decoder are generated .For recognition , each frame of input speech is represented by a 39 dimensional feature vector that consists of 13 ( including ) MF - PLP cepstral parameters and their first and second differentials .", "label": "", "metadata": {}, "score": "59.885925"}
{"text": "This was similarly transcribed at the speaker turn level but did n't distinguish between background conditions which meant that marked training segments were no longer necessarily homogeneous .The combined set of 1997 and 1998 data is denoted BNtrain98 .System development mainly used the 1997 Hub4 evaluation data , BNeval97 .", "label": "", "metadata": {}, "score": "59.958473"}
{"text": "In other work [ 16 ] we have explored using the web with low - frequency words to improve both recall and precision .To give a bigger context , we automatically located the full Medline abstract from which each BioCreative sentence was taken by searching Medline for the sentence using cgi scripts .", "label": "", "metadata": {}, "score": "59.994637"}
{"text": "The system takes the 1997 system and includes the additional acoustic training data in BNtrain98 ; cluster - based normalisation and VTLN ; the revised language modelling data and build procedure and full variance adaptation with SAT training .The word N - grams were trained by interpolating ( and merging ) component LMs trained on the acoustic transcriptions , the broadcast news texts and the newspaper texts .", "label": "", "metadata": {}, "score": "60.0242"}
{"text": "It is often , in fact common , that selections for a single word come different instances of that word joined at appropriate parts of the speech .The common prompts are invariably rendered from the original full prompts , thus preserving the original quality exactly .", "label": "", "metadata": {}, "score": "60.041786"}
{"text": "Of course , this assumption is unrealistic ; features are often highly dependent on one another .We 'll return to some of the consequences of this assumption at the end of this section .This simplifying assumption , known as the naive Bayes assumption ( or independence assumption ) makes it much easier to combine the contributions of the different features , since we do n't need to worry about how they should interact with one another .", "label": "", "metadata": {}, "score": "60.055954"}
{"text": "One possibility would be to identify the comparison / contrast markers and patterns and engineer features based on them .Feature engineering is discussed in detail in the \" Feature Design \" section below .Analysis of negation cues .Although the context and syntactic structure of a sentence play important roles in determining the negation status of a bio - event contained within the sentence , the presence of a negation cue is the most important factor to be considered .", "label": "", "metadata": {}, "score": "60.07334"}
{"text": "For BPD , which has three different senses , three different multi - class SVM methods [ 47 ] : \" mc - svm \" , \" one - vs - rest \" , \" one - vs - one \" , were used . \" Mc - svm \" implements the algorithm with a decision function which considers all classes at once , while \" one - vs - rest \" and \" one - ve - one \" are constructed by combining several binary SVM classifiers .", "label": "", "metadata": {}, "score": "60.143578"}
{"text": "This is consistent with the previously reported comparisons between dependency and constituency features for the tasks of opinion mining [ 71 , 72 ] and PPI extraction [ 73 ] .However , it is important to emphasise that our conclusions are based on specific representations of constituency features that we have used in our experiments .", "label": "", "metadata": {}, "score": "60.15058"}
{"text": "While it works great if you know exactly what you 're looking for , I worry that new / interested users will have a harder time getting started .New Corpora .Since the 0.9.9 release , a number of new corpora and corpus readers have been added : .", "label": "", "metadata": {}, "score": "60.160557"}
{"text": "Stanford , CA : CSLI ; 2001 .Mutalik PG , Deshpande A , Nadkarni PM : Use of general - purpose negation detection to augment concept indexing of medical documents : a quantitative study using the UMLS .J Am Med Inform Assoc 2001 , 8 ( 6 ) : 598 - 609 .", "label": "", "metadata": {}, "score": "60.173004"}
{"text": "9 Further Reading .Many of the machine learning algorithms discussed in this chapter are numerically intensive , and as a result , they will run slowly when coded naively in Python .For information on increasing the efficiency of numerically intensive algorithms in Python , see ( Kiusalaas , 2005 ) .", "label": "", "metadata": {}, "score": "60.17366"}
{"text": "We developed a fast implementation technique to make FD training on large HMM sets practical and on the WSJ / NAB task FD gives similar reductions in word error rate ( about 5 % relative ) to lattice - based MMIE with a much smaller computational cost .", "label": "", "metadata": {}, "score": "60.24055"}
{"text": "But some reported that certain classification algorithms were better than others .It is still an unclear issue , probably due to the interaction of different combinations of issues .The comparison between different classifiers should be a carefully controlled experiment .", "label": "", "metadata": {}, "score": "60.25406"}
{"text": "The reduced bandwidth models are used for data classified as narrow band .The system uses the LIMSI 1993 WSJ pronunciation dictionary augmented by pronunciations from a TTS system and hand generated corrections for a 65k word vocabulary .The 1997 system used N - gram language models trained on 132 million words of broadcast news texts , the LDC - distributed 1995 newswire texts , and the transcriptions from BNtrain97 ( LMtrain97 ) .", "label": "", "metadata": {}, "score": "60.265106"}
{"text": "Several evaluations were performed , showing that stochastic generation produces output equivalent to , and in some cases judged better than , handcrafted templates .LIMITED - DOMAIN SYNTHESIS .The quality of speech output in a dialog system is important to a user 's perception of the system .", "label": "", "metadata": {}, "score": "60.308754"}
{"text": "View Article PubMed .Maglott D , Ostell J , Pruitt KD , Tatusova T : Entrez Gene : Gene - centered information at NCBI .Nucleic Acids Res 2005 , 3 : D54-D58 .Yngve VH : Syntax and the problem of multiple meaning .", "label": "", "metadata": {}, "score": "60.367195"}
{"text": "Negation cues can be ambiguous [ 42 , 53 ] , i.e. , in some contexts they may not trigger negations .Wilson et al .[54 ] pointed out the difference between the lexical and contextual polarities of a word .", "label": "", "metadata": {}, "score": "60.375336"}
{"text": "bag - of - words is the simplest model , but ignores frequency .good for small text , but frequency can be very important for larger documents .other algorithms , like SVM , create sparse arrays of 1 or 0 depending on word presence , but require knowning full vocabulary beforehand .", "label": "", "metadata": {}, "score": "60.386528"}
{"text": "Both of these words have a negative lexical polarity , as they convey the \" state of not having something \" .That is why they have been identified as negation cues in the BioScope corpus .Morante [ 42 ] also identified both of these words as unambiguous negation cues .", "label": "", "metadata": {}, "score": "60.394592"}
{"text": "We used a simple voting approach to create an SSC .More sophisticated voting methods exist , such as weighted voting [ 17 ] or Borda count [ 18 ] , but these methods require information about the confidence or rank of the chunks , information that is not available for the chunkers in this study .", "label": "", "metadata": {}, "score": "60.397854"}
{"text": "Mooney RJ : Comparative experiments on disambiguating word senses : An illustration of the role of bias in machine learning .Proc 1996 Conf on Empirical Methods in Natural Language Processing 82 - 91 .Ng HT , Lee HB : Integrating multiple knowledge sources to disambiguate word sense : An examplar - based approach .", "label": "", "metadata": {}, "score": "60.400887"}
{"text": "We begin by selecting the overall best decision stump for the classification task .We then check the accuracy of each of the leaves on the training set .Leaves that do not achieve sufficient accuracy are then replaced by new decision stumps , trained on the subset of the training corpus that is selected by the path to the leaf .", "label": "", "metadata": {}, "score": "60.42044"}
{"text": "The training data was observed to contain a large number of triphones with very poor representation .Since the data for these triphones was scarce , distributions learnt for these triphones , and decision trees built based on these distributions , were likely to be poorly estimated .", "label": "", "metadata": {}, "score": "60.42988"}
{"text": "To test the null hypothesis of no differences in the error rates among the different sample sizes ( and overall probability distribution ) for the BSA and PCA abbreviations , we used Friedman 's test .Then we performed sub - analysis using the sign - test ( see Methods section for details ) .", "label": "", "metadata": {}, "score": "60.493805"}
{"text": "Giving a prompt list of just over 600 utterances .These were then recorded in the style of a helpful agent .The recordings were autolabelled using a simple alignment technique between the naturally spoken utterances and synthesized equivalents .The utterances were then used to build a unit selection synthesizer using the algorithm first described in [ [ 5 ] ] .", "label": "", "metadata": {}, "score": "60.496284"}
{"text": "In those instances we kept only the shorter gene .We found that this postprocessing was quite valuable and added approximately 1 % to our f - score .It was used in both the open and closed sections .See [ 20 ] for a more general classifier combination approach that includes forwards and backwards component models .", "label": "", "metadata": {}, "score": "60.512028"}
{"text": "This variation in performance is mainly due to an uneven distribution of negated bio - events across these classes .Conclusion .We have conducted a detailed analysis of the problem of identifying negated bio - events , given gold standard event annotations .", "label": "", "metadata": {}, "score": "60.528477"}
{"text": "This leads us to the following conclusions : .Despite the apparent similarities , the task of identifying negated bio - events is inherently different from the other negation detection tasks like negated term detection and negation scope detection .Since the Random Forest algorithm clearly outperforms the other learning algorithms for the task of identifying negated bio - events , its feasibility for other negation detection tasks should be investigated .", "label": "", "metadata": {}, "score": "60.56622"}
{"text": "Table 1 shows the performance of the three trainable chunkers and the combined system on the PennBioIE GSC when trained on three different corpora : GENIA GSC , PennBioIE SSC , or PennBioIE GSC .GATE and MetaMap could not be trained and when tested on the PennBioIE GSC had F - scores of 78.2 % ( MetaMap ) and 72.8 % ( GATE ) for noun phrases , and 77.7 % ( MetaMap ) for verb phrases .", "label": "", "metadata": {}, "score": "60.58732"}
{"text": "Yarowsky D , Florian R : Evaluating sense disambiguation across diverse parameter spaces .Nat Lang Eng 2002 , 8 : 293 - 310 .View Article .Surdeanu M , Turmo J , Comelles E : Named entity recognition from spontaneous open - domain speech .", "label": "", "metadata": {}, "score": "60.590652"}
{"text": "In general , simple classifiers always treat each input as independent from all other inputs .In many contexts , this makes perfect sense .For example , decisions about whether names tend to be male or female can be made on a case - by - case basis .", "label": "", "metadata": {}, "score": "60.675392"}
{"text": "Transformational joint classifiers work by creating an initial assignment of labels for the inputs , and then iteratively refining that assignment in an attempt to repair inconsistencies between related inputs .The Brill tagger , described in ( 1 ) , is a good example of this strategy .", "label": "", "metadata": {}, "score": "60.698402"}
{"text": "50 ] .Wilbur et al .[51 ] created a corpus of 6,945 text fragments ( sentences and clauses ) in which each fragment is annotated along five dimensions , one of which is polarity .Their corpus contained 6,498 ( 94 % ) positive and 447 ( 6 % ) negative fragments .", "label": "", "metadata": {}, "score": "60.758472"}
{"text": "Analyze Tagger Coverage .You can analyze the coverage of a part - of - speech tagger against any corpus using analyze_tagger_coverage.py .Here 's the results for the treebank corpus using NLTK 's default part - of - speech tagger : .", "label": "", "metadata": {}, "score": "60.81468"}
{"text": "As previously stated , maximum entropy systems allow incorporation of large numbers of diverse features ; however , parameter estimation for large models can be time - consuming .We found that a particularly large number of features was necessary for high performance in the biomedical domain , and improved on our initial parameter estimation method ( conjugate gradient descent as in [ 2 ] ) by implementing a quasi - Newton optimization procedure .", "label": "", "metadata": {}, "score": "60.892452"}
{"text": "In this paper , we also demonstrated that ambiguity of biomedical entities is a significant problem , which has a substantial impact on text mining and retrieval tasks in the biomedical domain .ML methods are still needed for WSD , which is critical for increasing the accuracy of biomedical natural language , text mining , and information retrieval systems .", "label": "", "metadata": {}, "score": "60.897938"}
{"text": "The resulting novel framework for the identification of negated bio - events has been evaluated on each of the three open access corpora mentioned above , achieving significantly better results than the existing state - of - the - art systems .", "label": "", "metadata": {}, "score": "60.89855"}
{"text": "On the GENIA Event dataset , the best results were achieved by the Random Forest classifier using the c40 cue list .The classifier achieved 83 % precision and 67 % recall , which equates to an F - score of 74 % .", "label": "", "metadata": {}, "score": "60.904995"}
{"text": "For classification tasks that have a small number of well - balanced labels and a diverse test set , a meaningful evaluation can be performed with as few as 100 evaluation instances .But if a classification task has a large number of labels , or includes very infrequent labels , then the size of the test set should be chosen to ensure that the least frequent label occurs at least 50 times .", "label": "", "metadata": {}, "score": "60.93461"}
{"text": "54 ] have labelled them as negative polarity shifters .Similarly , indicators of low manner have been treated as negation cues in the field of biomedical text mining .Examples can be found in the three corpora of negated bio - events ( i.e. , GENIA Event , BioInfer and BioNLP'09 ST ) , as well as in the BioScope corpus .", "label": "", "metadata": {}, "score": "61.000706"}
{"text": "Journal of Biomedical Semantics 2011 , 2 ( Suppl 5 ) : S8 .View Article PubMed .Harabagiu S , Hickl A , Lacatusu F : Negation , Contrast and Contradiction in Text Processing .In Twenty - First National Conference on Artificial Intelligence ( AAAI-06 ) : 2006 .", "label": "", "metadata": {}, "score": "61.032936"}
{"text": "The June set contains predominantly ( though not exclusively ) developer speech , while the October test set contains a greater proportion of public speech , as well as more challenging data ( e.g. , from cell phones ) .Model 1 : For training this model , we used all transcribed data collected between April 1998 and January 2000 , excluding the data collected during June 1999 and October 1999 .", "label": "", "metadata": {}, "score": "61.046852"}
{"text": "When large amounts of annotated data are available , it is common to err on the side of safety by using 10 % of the overall data for evaluation .Another consideration when choosing the test set is the degree of similarity between instances in the test set and those in the development set .", "label": "", "metadata": {}, "score": "61.097168"}
{"text": "Therefore , a complex event is 2.5 times more likely to be negated than a simple event .These experiments show that there is some correlation between the event - type and polarity .However , designing individual classifiers for different types of events does not improve the overall system performance .", "label": "", "metadata": {}, "score": "61.103012"}
{"text": "Therefore it is important that we understand the different elements affecting their performance .Methods .After manually reviewing a set of WSD papers in the biomedical domain , different issues associated with performance were enumerated .For an initial study , we conducted experiments to evaluate the effect of three confounding issues : \" sample size \" , \" sense distribution \" and \" degree of difficulty \" , and we used an automatically generated data set .", "label": "", "metadata": {}, "score": "61.162544"}
{"text": "The basic assumption behind and motivation for using external resources is that there are instances in the data where contextual clues do not provide sufficient evidence for confident classification .All external resources are vulnerable to incompleteness , noise , and ambiguity .", "label": "", "metadata": {}, "score": "61.209568"}
{"text": "we built a regular expression tagger that chooses a part - of - speech tag for a word by looking at the internal make - up of the word .However , this regular expression tagger had to be hand - crafted .", "label": "", "metadata": {}, "score": "61.24299"}
{"text": "The corpus data is divided into two sets : the development set , and the test set .The development set is often further subdivided into a training set and a dev - test set .Having divided the corpus into appropriate datasets , we train a model using the training set , and then run it on the dev - test set .", "label": "", "metadata": {}, "score": "61.248524"}
{"text": "In these cases , use the function nltk.classify.apply_features , which returns an object that acts like a list but does not store all the feature sets in memory : . 1.2Choosing The Right Features .Selecting relevant features and deciding how to encode them for a learning method can have an enormous impact on the learning method 's ability to extract a good model .", "label": "", "metadata": {}, "score": "61.323814"}
{"text": "That is , we trained our Random Forest classifier on the Training subset of the BioNLP'09 ST data and tested it on the Development subset .In this setting , our system achieved an F - score of just under 70 % , which is significantly higher than the results of Sarafraz and Nenadic .", "label": "", "metadata": {}, "score": "61.3302"}
{"text": "Performance figures of the CALBC SSC against GSCs for named - entity recognition are not yet available , but we presume that they will be much lower .However , despite the differences between an SSC and GSC , chunking systems trained on these corpora showed remarkably similar performances .", "label": "", "metadata": {}, "score": "61.332504"}
{"text": "Because the parameters for Maximum Entropy classifiers are selected using iterative optimization techniques , they can take a long time to learn .This is especially true when the size of the training set , the number of features , and the number of labels are all large .", "label": "", "metadata": {}, "score": "61.367012"}
{"text": "In contrast to the above characteristics , the scopes of negation cues are continuous and relatively less ambiguous [ 16 ] .A few interesting consequences of this contrast are : .A sentence containing a negation cue may not contain any negated events at all .", "label": "", "metadata": {}, "score": "61.46629"}
{"text": "Conversely , 16 % of negated bio - events had event - triggers which were outside the scope of the negation cues present in the sentence containing the event .They concluded that negation scope detection is not sufficient for the identification of negated bio - events , as the latter is a more complex task , which requires a deeper and more complex analysis than other negation detection tasks , like negated term detection and negation scope detection .", "label": "", "metadata": {}, "score": "61.46692"}
{"text": "has sentence tokenizers for 16 languages .Smarter than just splitting on punctuation .\\n . loads a word tokenizer trained on treebank , then calls the tokenize ( ) method\\n . non - ascii characters are also a problem for word_tokenize ( ) .", "label": "", "metadata": {}, "score": "61.58591"}
{"text": "The system achieved an accuracy rate of 92.7 % on an automatically generated testing set .Schijvenaars 's study described an effective method for gene disambiguation , but the evaluation results were limited to certain conditions .The automatically generated testing set contained human genes symbols that appeared as long - form and short - form pairs ( e.g. prostate specific antigen ( PSA ) ) in articles , where at least 6 articles were determined to be associated with each gene sense .", "label": "", "metadata": {}, "score": "61.59592"}
{"text": "The stochastic language generation process described earlier is not a problem for this technique , reformulating similar sentence forms is dealt with adequately .Of course although we have coupled the synthesis closely to the generation it is still possible that some words are generated which do not appear in the recorded database .", "label": "", "metadata": {}, "score": "61.656494"}
{"text": "Although the work of Sanchez - Graillet and Poesio concerns bio - events , their classification is specific to PPIs and can not be trivially extended to all types of bio - events .Therefore , a more general framework is required , which can be applied to classify all types negated bio - events .", "label": "", "metadata": {}, "score": "61.684174"}
{"text": "We used all three open access corpora of negated bio - events in our experiments .Table 1 shows the statistics for these corpora .The GENIA Event corpus is the largest and contains bio - events of 36 different semantic types .", "label": "", "metadata": {}, "score": "61.7647"}
{"text": "This shows that chunkers may considerably differ with the gold standard with respect to the annotation of stopwords .Since the creation of an SSC is automatic , its size can be very large .For different text - processing applications , increasing amounts of data for training classifiers have been shown to improve classifier performance [ 21 - 23 ] .", "label": "", "metadata": {}, "score": "61.77466"}
{"text": "Other than the participants , an event may contain additional attributes including location , time and experimental context .BioInfer :The BioInfer corpus [ 25 ] contains 1,100 sentences in which 2,662 bio - events have been identified .Each event belongs to one of the 60 event classes defined in the BioInfer Relationship Ontology .", "label": "", "metadata": {}, "score": "61.81657"}
{"text": "In earlier versions of the CMU Communicator we used a general - purpose commercial speech synthesis system .More recently we have begun to experiment with synthesis tailored specifically to this domain .Unit selection synthesis , where appropriate sub - word units are selected from general speech databases , for example AT&T 's NextGen [ 3 ] , can produce very high quality synthesis .", "label": "", "metadata": {}, "score": "61.82329"}
{"text": "So what happens when we ignore the independence assumption , and use the naive Bayes classifier with features that are not independent ?One problem that arises is that the classifier can end up \" double - counting \" the effect of highly correlated features , pushing the classifier closer to a given label than is justified .", "label": "", "metadata": {}, "score": "61.89875"}
{"text": "Morante R , Schrauwen S , Daelemans W : Corpus - Based Approaches to Processing the Scope of Negation Cues : An Evaluation of the State of the Art .Ninth International Conference on Computational Semantics ( IWCS 2011 )2011 , 350 - 354 .", "label": "", "metadata": {}, "score": "61.90984"}
{"text": "Even though the individual folds might be too small to give accurate evaluation scores on their own , the combined evaluation score is based on a large amount of data , and is therefore quite reliable .A second , and equally important , advantage of using cross - validation is that it allows us to examine how widely the performance varies across different training sets .", "label": "", "metadata": {}, "score": "61.926758"}
{"text": "This could also be due to the existence of other confounding factors in the datasets that were used .In our study , we controlled for this factor by using \" bag - of - word \" features in all experiments , but it would be interesting to see if the performance improves when different feature vectors are used .", "label": "", "metadata": {}, "score": "62.004715"}
{"text": "\" Sample size ' , \" sense distribution \" and \" degree of difficulty \" were three of multiple confounding issues that affect the performance of a WSD classifier .Results from our experiments demonstrated that these three factors were intrinsically connected .", "label": "", "metadata": {}, "score": "62.006218"}
{"text": "Thus , the input will never be assigned this label , regardless of how well the other features fit the label .In particular , just because we have n't seen a feature / label combination occur in the training set , does n't mean it 's impossible for that combination to occur .", "label": "", "metadata": {}, "score": "62.03864"}
{"text": "this trains a very basic sentiment analysis classifier on the movie_reviews corpus , which has reviews categorized into pos or neg\\n .treebank is a very standard corpus for testing taggers and chunkers\\n .NLP is n't black magic , but you can treat it as a black box until the defaults are n't good enough .", "label": "", "metadata": {}, "score": "62.071316"}
{"text": "But note that history will only contain tags for words we 've already classified , that is , words to the left of the target word .Thus , while it is possible to look at some features of words to the right of the target word , it is not possible to look at the tags for those words ( since we have n't generated them yet ) .", "label": "", "metadata": {}, "score": "62.109245"}
{"text": "We evaluated our system on the three open access corpora of negated bio - events mentioned above .Our results on the BioNLP'09 ST corpus were significantly higher than the previously reported best results .We achieved even better results on the GENIA Event and BioInfer corpora , both of which contain more varied and complex events .", "label": "", "metadata": {}, "score": "62.188602"}
{"text": "The contribution from each feature is then combined with this prior probability , to arrive at a likelihood estimate for each label .The label whose likelihood estimate is the highest is then assigned to the input value .5.1 illustrates this process .", "label": "", "metadata": {}, "score": "62.195724"}
{"text": "The chunkers then annotated the PennBioIE corpus and the annotations of all chunkers were combined to yield the silver standard .Subsequently , Lingpipe , OpenNLP , and Yamcha were trained on the PennBioIE SSC and on the PennBioIE GSC , using 10-fold cross - validation .", "label": "", "metadata": {}, "score": "62.224346"}
{"text": "The use of the cCore cue list resulted in consistent performance , achieving the second best results ( F - score ) for all three datasets .The results were very close to the top performing cue list for GENIA Event and BioNLP'09 ST , with margins of 0.5 % and 1.8 % , respectively .", "label": "", "metadata": {}, "score": "62.24331"}
{"text": "If an event contains other events as its participants , then it is called a complex event .This kind of event representation allows the information contained within a piece of text to be represented as a collection of nested events .", "label": "", "metadata": {}, "score": "62.25247"}
{"text": "[ 3 ] combined eight systems for event extraction and showed that the performance of the combined system increased by 4 percentage points as compared to the best individual system .We previously combined six publicly available text chunkers using a simple voting approach [ 4 ] .", "label": "", "metadata": {}, "score": "62.3193"}
{"text": "This leaves us open to the criticism that much of the effort was not machine learning , and one might have been able to develop a system of hand - crafted rules in the same time .Use of automatic feature induction would partly address this criticism .", "label": "", "metadata": {}, "score": "62.34839"}
{"text": "Significance of detecting negated bio - events .Negation is considered a universal property of all human languages [ 12 ] .However , the concept and manifestation of negation in natural languages is far more subtle and complex in force and scope than it is in formal logic [ 13 - 15 ] .", "label": "", "metadata": {}, "score": "62.383575"}
{"text": "The best results on the BioInfer dataset were also achieved by a Random Forest classifier .However , the cBioInfer cue list was used to engineer the features .This classifier achieved 86 % precision , 85 % recall and 85 % F - score .", "label": "", "metadata": {}, "score": "62.40073"}
{"text": "I think NLTK 's ideal role is be a standard interface between corpora and NLP algorithms .There are many different corpus formats , and every algorithm has its own data structure requirements , so providing common abstract interfaces to connect these together is very powerful .", "label": "", "metadata": {}, "score": "62.43576"}
{"text": "Furthermore , while the general definition of bio - events in all corpora complies with the description above , the exact specification of a bio - event , the types of participants and the semantic roles ascribed to them vary from corpus to corpus .", "label": "", "metadata": {}, "score": "62.445557"}
{"text": "A possible explanation for this phenomenon is that the SSC incorporates results from the chunkers that are subsequently trained on it .As a consequence , the diversity of the chunkers trained on the SSC may be less than those trained on the GSCs .", "label": "", "metadata": {}, "score": "62.485363"}
{"text": "Preprocessing .During both training and testing we used the tokenization supplied by the task organizers .This tokenization was of quite poor quality .For instance , periods were always separated off as tokens , and so a text string like [ increased ] by 1.7-fold . was tokenized as .", "label": "", "metadata": {}, "score": "62.48638"}
{"text": "Algorithm selection .We designed a series of experiments to evaluate and compare the performance of six learning algorithms with respect to the task of identifying negated bio - events .All of these algorithms , with the exception of Random Forest , had previously been used for different negation detection tasks with varying degrees of success .", "label": "", "metadata": {}, "score": "62.540882"}
{"text": "Otherwise , your evaluation results may be unrealistically optimistic .Decision trees are automatically constructed tree - structured flowcharts that are used to assign labels to input values based on their features .Although they 're easy to interpret , they are not very good at handling cases where feature values interact in determining the proper label .", "label": "", "metadata": {}, "score": "62.58815"}
{"text": "The resulting systems will be able to extract bio - events with attached polarities from textual documents , which can serve as the foundation for more elaborate systems that are able to detect mutually contradicting bio - events .Background .Introduction .", "label": "", "metadata": {}, "score": "62.704964"}
{"text": "Stroudsburg , PA : Association for Computational Linguistics ( ACL ) ; 2009:77 - 85 .Van Landeghem S , Saeys Y , De Baets B , Van de Peer Y : Analyzing text in search of bio - molecular events : a high - precision machine learning framework .", "label": "", "metadata": {}, "score": "62.726494"}
{"text": "In this case , the classifier will make its decisions based only on information about which of the common suffixes ( if any ) a given word has .Now that we 've defined our feature extractor , we can use it to train a new \" decision tree \" classifier ( to be discussed in 4 ): .", "label": "", "metadata": {}, "score": "62.72832"}
{"text": "The training set and test set are taken from the same genre , and so we can not be confident that evaluation results would generalize to other genres .What 's worse , because of the call to random.shuffle ( ) , the test set contains sentences that are taken from the same documents that were used for training .", "label": "", "metadata": {}, "score": "62.75431"}
{"text": "New York , NY : Association for Computing Machinery ( ACM ) ; 1998:148 - 155 .Escudero G , Mhrquez L , Rigau G : A Comparison between Supervised Learning Algorithms for Word Sense Disambiguation .In 4th Conference on Computational Natural Language Learning , CoNLL'2000 .", "label": "", "metadata": {}, "score": "62.792343"}
{"text": "( b )During prediction , the same feature extractor is used to convert unseen inputs to feature sets .These feature sets are then fed into the model , which generates predicted labels .In the rest of this section , we will look at how classifiers can be employed to solve a wide variety of tasks .", "label": "", "metadata": {}, "score": "62.79381"}
{"text": "The difference between a generative model and a conditional model is analogous to the difference between a topographical map and a picture of a skyline .Although the topographical map can be used to answer a wider variety of questions , it is significantly more difficult to generate an accurate topographical map than it is to generate an accurate skyline .", "label": "", "metadata": {}, "score": "62.820976"}
{"text": "Elkin PL , Brown SH , Bauer BA , Husser CS , Carruth W , Bergstrom LR , Wahner - Roedler DL : A controlled trial of automated classification of negation from clinical notes .BMC Med Inform Decis Mak 2005 , 5 : 13 .", "label": "", "metadata": {}, "score": "62.84584"}
{"text": "Unfortunately , the number of possible tag sequences is quite large .Given a tag set with 30 tags , there are about 600 trillion ( 30 10 ) ways to label a 10-word sentence .In order to avoid considering all these possible sequences separately , Hidden Markov Models require that the feature extractor only look at the most recent tag ( or the most recent n tags , where n is fairly small ) .", "label": "", "metadata": {}, "score": "62.911774"}
{"text": "McGraw Hill ; 1997 .Quinlan JR : C4.5 : Programs for Machine Learning .San Mateo , CA : Morgan Kaufmann Publishers ; 1993 .Quinlan JR : Induction of decision trees .Mach Learn 1986 , 1 ( 1 ) : 81 - 106 .", "label": "", "metadata": {}, "score": "62.970524"}
{"text": "This voice was built in under a week .The stages involved in building such limited domain synthesizers are as follows .First we constructed a set of sentences for recording which adequately covered the desired domain .For Communicator we analyzed the utterances from logs of the most recent three months and sorted them by frequency .", "label": "", "metadata": {}, "score": "62.977314"}
{"text": "In Modern Studies in English .Edited by : Reibel D , Schane S. Englewood Cliffs , NJ : Prentice - Hall ; 1969:160 - 186 .Dumais S , Platt J , Heckerman D : Inductive Learning Algorithms and Representations for Text Categorization .", "label": "", "metadata": {}, "score": "63.01342"}
{"text": "The resulting likelihood score can be thought of as an estimate of the probability that a randomly selected value from the training set would have both the given label and the set of features , assuming that the feature probabilities are all independent .", "label": "", "metadata": {}, "score": "63.02326"}
{"text": "Event - based text mining .Event - based text mining approaches constitute a promising alternative to the traditional approaches , which are mainly based on the bag - of - words principle [ 7 - 9 ] .Textual events are template - like , structured representations of pieces of knowledge contained within documents .", "label": "", "metadata": {}, "score": "63.024193"}
{"text": "Corpus / domain idiosyncrasies .Certain cues which are unambiguous and/or frequent in one corpus can be ambiguous and/or scarce in another .For example , words like protected and abolish are treated as negation cues in BioInfer .However , they are mostly interpreted as indicators of negative_regulation , rather than negation , in the GENIA Event and BioNLP'09 ST corpora .", "label": "", "metadata": {}, "score": "63.046463"}
{"text": "Corpora .There are only a few publicly available corpora in the biomedical domain that incorporate chunk annotations .We used the GENIA Treebank corpus [ 12 ] and the PennBioIE corpus [ 13 ] .The GENIA corpus [ 12 ] has been developed at the University of Tokyo .", "label": "", "metadata": {}, "score": "63.060326"}
{"text": "Our results on the practical value of an SSC are different from those that were recently reported by Chowdhury and Lavelli [ 6 ] .They found a considerable drop in performance of a gene recognition system trained on the CALBC SSC as compared to the system trained on the BioCreative GSC , and also noticed that the system trained on a combination of SSC and GSC performed worse than on the GSC only .", "label": "", "metadata": {}, "score": "63.065834"}
{"text": "Stroudsburg , PA : Association for Computational Linguistics ( ACL ) ; 2009:128 - 136 .Sarafraz F , Nenadic G : Using SVMs with the Command Relation Features to Identify Negated Events in Biomedical Literature .In Workshop on Negation and Speculation in Natural Language Processing ( NeSp - NLP 2010 ) , ACL 2010 .", "label": "", "metadata": {}, "score": "63.127277"}
{"text": "This figure shows the plots of ' ' error rate ' ' versus ' ' sample size ' ' with different sense distributions of PCA data set ( case where the 2 ambiguous senses are very similar ) using 5-fold cross validation .", "label": "", "metadata": {}, "score": "63.15615"}
{"text": "To generate a labeled input , the model first chooses a label for the input , then it generates each of the input 's features based on that label .Every feature is assumed to be entirely independent of every other feature , given the label .", "label": "", "metadata": {}, "score": "63.169052"}
{"text": "The returned dictionary , known as a feature set , maps from feature names to their values .Feature names are case - sensitive strings that typically provide a short human - readable description of the feature , as in the example ' last_letter ' .", "label": "", "metadata": {}, "score": "63.176422"}
{"text": "However there is a concern that a very limited set of words may have accounted for the vast majority of ambiguity .Therefore , for each ambiguous word , we calculated its frequency , which is defined as the ratio between the number of abstracts containing the word and the total number of abstracts in the pool .", "label": "", "metadata": {}, "score": "63.201164"}
{"text": "[ 48 ] , who compared the performance of SVM and Na\u00efve Bayes for the task of detecting negations in medical texts .They found that SVM outperformed Na\u00efve Bayes by a significant margin ( 8 % ) .On the other hand , Goldin and Chapman [ 47 ] compared the performance of Naive Bayes and decision trees for the task of identifying negated terms in medical texts .", "label": "", "metadata": {}, "score": "63.20233"}
{"text": "If we want to generate a probability estimate for each label , rather than just choosing the most likely label , then the easiest way to compute P(features ) is to simply calculate the sum over labels of P(features , label ) : . 5.2 Zero Counts and Smoothing .", "label": "", "metadata": {}, "score": "63.21658"}
{"text": "We can compensate for lack of data and for overfitting by smoothing the state distributions of the models with uniform distributions .This produces a slight improvement in error rate for both test sets ( Model 1b ) .Model 2 : We investigated state tying using a rule - based tying procedure prior to building decision trees .", "label": "", "metadata": {}, "score": "63.227745"}
{"text": "A decision tree is a simple flowchart that selects labels for input values .This flowchart consists of decision nodes , which check feature values , and leaf nodes , which assign labels .To choose the label for an input value , we begin at the flowchart 's initial decision node , known as its root node .", "label": "", "metadata": {}, "score": "63.314453"}
{"text": "The original data set for PCA contained 6 different senses , but we only used the two that were very similar for our experiments .We used a simple \" full - form substitution \" method to automatically generate a data set for the experiments described in this paper , and this dataset was partitioned into training and testing sets .", "label": "", "metadata": {}, "score": "63.340683"}
{"text": "And for treebank , I again used a 2/3 vs 1/3 split .The ClassifierBasedPOSTagger is not necessarily more accurate than the bcraubt tagger from part 3 ( at least with the default feature detector ) .It also takes much longer to train and tag ( more details below ) and so may not be worth the tradeoff in efficiency .", "label": "", "metadata": {}, "score": "63.37855"}
{"text": "In the first scenario , a chunker has to be trained for a biomedical subdomain for which a GSC is not available .Rather than creating a new GSC , we generate an SSC for the new domain and train the chunker on the SSC .", "label": "", "metadata": {}, "score": "63.411293"}
{"text": "View Article .Chapman WW , Bridewell W , Hanbury P , Cooper GF , Buchanan BB : A simple algorithm for identifying negated findings and diseases in discharge summaries .J Biomed Inform 2001 , 34 ( 5 ) : 301 - 310 .", "label": "", "metadata": {}, "score": "63.42846"}
{"text": "Kim J - D , Ohta T , Tsujii J : Corpus annotation for mining biomedical events from literature .BMC Bioinformatics 2008 ., 9 ( 10 ) : .Nawaz R , Thompson P , Ananiadou S : Event Interpretation : A Step towards Event - Centred Text Mining .", "label": "", "metadata": {}, "score": "63.472828"}
{"text": "Central contributions are rich use of features derived from the training data at multiple levels of granularity , a focus on correctly identifying entity boundaries , and the innovative use of several external knowledge sources including full MEDLINE abstracts and web searches .", "label": "", "metadata": {}, "score": "63.474003"}
{"text": "View Article .Van Erp M , Schomaker L : Variants of the borda count method for combining ranked classifier hypotheses .Proceedings of the Seventh International Workshop on Frontiers in Handwriting Recognition ; Amsterdam 2000 , 443 - 452 .Seki K , Mostafa J : An application of text categorization methods to gene ontology annotation .", "label": "", "metadata": {}, "score": "63.483017"}
{"text": "Our analysis showed that a significant proportion ( 37 % ) of negated bio - events can not be detected by considering the event - trigger alone .It also revealed that identification of negated bio - events is a complex task that requires a deeper level of analysis than that required for tasks such as negated term detection and negation scope detection .", "label": "", "metadata": {}, "score": "63.601532"}
{"text": "For document topic identification , we can define a feature for each word , indicating whether the document contains that word .To limit the number of features that the classifier needs to process , we begin by constructing a list of the 2000 most frequent words in the overall corpus .", "label": "", "metadata": {}, "score": "63.60393"}
{"text": "Computational Linguistics 2003 , 29 ( 3 ) : 459 - 484 .View Article .Grefenstette G : The WWW as a Resource for Example - Based MT Tasks .Proceedings of ASLIB'99 Translating and the Computer 21 , London 1999 .", "label": "", "metadata": {}, "score": "63.65452"}
{"text": "[ Before ROVER combination an alignment pass was run to get exact word timings .Due to the effects of automatic segmentation this process reduces the WER by about 0.1 % absolute .] Table 6 : Word error rates for each stage of the 1998 HTK broadcast news evaluation system ( also P4 FV contrast ) .", "label": "", "metadata": {}, "score": "63.73045"}
{"text": "Multiple classifier systems have been applied in many domains , including biomedical text mining and information extraction .For instance , Smith et al .[ 2 ] combined the results of 19 systems for gene mention recognition , and found that the combined system outperformed the best individual system by 3.5 percentage points in terms of F - score .", "label": "", "metadata": {}, "score": "63.733337"}
{"text": "However it has been noted that unit selection synthesis is often better when the utterance to be synthesized is closer to the domain of the database .The result offers very high quality synthesis that sounds almost human .The techniques used for this are more fully described in [ 4 ] .", "label": "", "metadata": {}, "score": "63.755516"}
{"text": "It contains one leaf for each possible feature value , specifying the class label that should be assigned to inputs whose features have that value .In order to build a decision stump , we must first decide which feature should be used .", "label": "", "metadata": {}, "score": "63.786797"}
{"text": "The triphone HMMs were estimated using BNtrain97 and contained 6684 decision - tree clustered states [ 17 ] , each with 12 Gaussians per state while the quinphone models used 8180 states and 16 Gaussians per state .The HMMs were initially trained on all the wide - band analysed training data .", "label": "", "metadata": {}, "score": "63.797176"}
{"text": "Results .We have conducted a detailed analysis of three open access bio - event corpora containing negation information ( i.e. , GENIA Event , BioInfer and BioNLP'09 ST ) , and have identified the main types of negated bio - events .", "label": "", "metadata": {}, "score": "63.838905"}
{"text": "We also observed that the features based on the POS tags of negation cues , event - triggers , event - themes and event - causes did not improve the performance .Similarly , the features based on the semantic types of event - themes and event - causes did not influence the performance either .", "label": "", "metadata": {}, "score": "63.86857"}
{"text": "However , conditional models can not be used to answer the remaining questions 3 - 6 .However , this additional power comes at a price .Because the model is more powerful , it has more \" free parameters \" which need to be learned .", "label": "", "metadata": {}, "score": "63.878365"}
{"text": "This happens when words are given the wrong tag ( creating false positives and false negatives ) while the overall tag frequency remains about the same .The CC tag is a great example of this : the Found count is only 3 higher than the Actual count , yet Precision is 68.75 % and Recall is 73.33 % .", "label": "", "metadata": {}, "score": "63.910297"}
{"text": "A number of the features listed in Table 1 , as well as the features used to incorporate external resources , are relatively unintuitive conjunctions of other features that were chosen by lengthy trial and error processes .Feature induction might suggest useful feature conjunctions that we have overlooked and reduce the cost of incorporating additional resources .", "label": "", "metadata": {}, "score": "63.94733"}
{"text": "To reduce the effect of insignificant differences between chunks , words from the stopwords list in PubMed [ 16 ] and punctuation remarks were removed before matching if they appeared at the start or the end of a phrase .Results .", "label": "", "metadata": {}, "score": "63.95598"}
{"text": "The system then uses quinphone models ( VTLN / SAT trained ) and MLLR with an additional FV transform to process the data ( P4 ) .This stage is repeated twice more while increasing the number of MLLR transforms ( P5/P6 ) .", "label": "", "metadata": {}, "score": "63.96988"}
{"text": "Scaling Up to Large Datasets .Python provides an excellent environment for performing basic text processing and feature extraction .If you plan to train classifiers with large amounts of training data or a large number of features , we recommend that you explore NLTK 's facilities for interfacing with external machine learning packages .", "label": "", "metadata": {}, "score": "64.082214"}
{"text": "Historically , the main motivation for identifying negated events has been to ensure their exclusion from lists of extracted interactions .However , recently , there has been a growing interest in negative results , which has resulted in negation detection being identified as a key challenge in biomedical relation extraction .", "label": "", "metadata": {}, "score": "64.122025"}
{"text": "Sanchez - Graillet and Poesio [ 38 ] developed a set of heuristics for extracting negated PPIs from biomedical articles .They implemented their system using a Functional Dependency Grammar ( FDG ) parser .Their preliminary results ranged from 54 % to 63 % F - score , depending on the method of protein name recognition .", "label": "", "metadata": {}, "score": "64.12302"}
{"text": "This result contrasts with a 17.2 % error rate observed for models trained on the much larger Switchboard I corpus and adapted to the Communicator domain ( June 99 test set ) .MODELING LANGUAGE .The basis for the Communicator language is the ATIS language developed previously for a similar domain ( airline schedule information retrieval ) .", "label": "", "metadata": {}, "score": "64.130035"}
{"text": "Now that we 've defined a feature extractor , we need to prepare a list of examples and corresponding class labels .Next , we use the feature extractor to process the names data , and divide the resulting list of feature sets into a training set and a test set .", "label": "", "metadata": {}, "score": "64.1935"}
{"text": "We borrowed disjunctive word features from [ 10 ] , and introduced abbreviation and parentheses matching features to model key problems in this textual domain .The resulting feature set is summarized in Table 1 and comprises all of the features used in the closed section .", "label": "", "metadata": {}, "score": "64.20529"}
{"text": "Identification of negated bio - events : task description and analysis .Following previous work [ 29 - 33 ] , we treat the task of identifying negated bio - events as an independent task in itself .That is , we assume that event annotation has already been performed , and aim to create an automated means of classifying the identified events according to their polarity .", "label": "", "metadata": {}, "score": "64.22734"}
{"text": "System details can be found in [ 16 ] .The data segmentation [ 4 ] aims to generate acoustically homogeneous speech segments and discard non - speech portions such as pure music .It uses a set of Gaussian mixture models to classify the data as to type ( wideband speech , narrow - band speech , pure music , speech and music ) , and then any pure music is discarded .", "label": "", "metadata": {}, "score": "64.23241"}
{"text": "Paris : European Language Resources Association ( ELRA ) ; 2010 .Kim J - D , Ohta T , Pyysalo S , Kano Y , Tsujii J : Overview of BioNLP'09 Shared Task on Event Extraction .In ACL Workshop on BioNLP : Shared Task .", "label": "", "metadata": {}, "score": "64.25146"}
{"text": "return features . words ( ' pos / cv957_8737 .The reason that we compute the set of all words in a document in , rather than just checking if word in document , is that checking whether a word occurs in a set is much faster than checking whether it occurs in a list ( 4.7 ) .", "label": "", "metadata": {}, "score": "64.25781"}
{"text": "We could then use those interactions to adjust the contributions that individual features make .To make this more precise , we can rewrite the equation used to calculate the likelihood of a label , separating out the contribution made by each feature ( or label ) : .", "label": "", "metadata": {}, "score": "64.315346"}
{"text": "Human Language Technology conference / North American Chapter of the Association for Computational Linguistics Annual Meeting ; Boston 2004 , 61 - 68 .Ferrucci D , Lally A : UIMA : an architectural approach to unstructured information processing in the corporate research environment .", "label": "", "metadata": {}, "score": "64.33496"}
{"text": "This is what NLTK already does best , and I hope that becomes even more true in the future .Share this : .NLTK Trainer includes 2 scripts for analyzing both a tagged corpus and the coverage of a part - of - speech tagger .", "label": "", "metadata": {}, "score": "64.40621"}
{"text": "Instead of just passing in the word to be tagged , we will pass in a complete ( untagged ) sentence , along with the index of the target word .This approach is demonstrated in 1.6 , which employs a context - dependent feature extractor to define a part of speech tag classifier . def pos_features ( sentence , i ) : . return features .", "label": "", "metadata": {}, "score": "64.42817"}
{"text": "The 1998 evaluation data , BNeval98 , consisted of two 1.5 hour data sets : the first drawn from a similar epoch as the 1997 data and the second drawn from June 1998 .The evaluation results are presented for each of the NIST ' ' focus ' ' conditions which are shown in Table 1 .", "label": "", "metadata": {}, "score": "64.47767"}
{"text": "A somewhat better approach is to ensure that the training set and test set are taken from different documents : .If we want to perform a more stringent evaluation , we can draw the test set from documents that are less closely related to those in the training set : .", "label": "", "metadata": {}, "score": "64.525795"}
{"text": "Aronson AR : Effective mapping of biomedical text to the UMLS Metathesaurus : the MetaMap program .Proc AMIA Symp 2001 , 17 - 21 : 17 - 21 .Weeber M , Klein H , Aronson AR , Mork JG , de Jong - van den Berg LT , Vos R : Text - based discovery in biomedicine : the architecture of the DAD - system .", "label": "", "metadata": {}, "score": "64.551636"}
{"text": "Initially we used bandwidth independent , gender independent triphones to evaluate the technique and under these conditions it gave a 1 % absolute reduction in WER .However , when bandwidth dependent , gender dependent models with variance normalisation and MLLR adaptation were used , there was no WER advantage and hence soft clustering was not used in the 1998 evaluation system .", "label": "", "metadata": {}, "score": "64.55716"}
{"text": "While the system produces good results it is computationally expensive : a companion paper [ 12 ] discusses a version of the system that runs in less than ten times real - time on commodity hardware .This work is in part supported by an EPSRC grant on ' ' Multimedia Document Retrieval ' ' reference GR / L49611 and by a grant from DARPA .", "label": "", "metadata": {}, "score": "64.581924"}
{"text": "The Maximum Entropy classifier uses a model that is very similar to the model employed by the naive Bayes classifier .But rather than using probabilities to set the model 's parameters , it uses search techniques to find a set of parameters that will maximize the performance of the classifier .", "label": "", "metadata": {}, "score": "64.589905"}
{"text": "The subsequent sections give the details of a number of experiments that we performed in system development .This is followed by a description of , and the results from , the 1998 Hub4 evaluation system .The full recognition results from the various stages of operation are included .", "label": "", "metadata": {}, "score": "64.61136"}
{"text": "Buyko E , Wermter J , Poprat M , Hahn U : Automatically adapting an NLP core engine to the biology domain .Proceedings of the Joint BioLINK - Bio - Ontologies Meeting ; Fortaleza 2006 , 65 - 68 .Kudo T , Matsumoto Y : Chunking with support vector machines .", "label": "", "metadata": {}, "score": "64.70288"}
{"text": "Furthermore , the event representation of text allows a document to be viewed as a collection of nested textual events .We call this the event view of a document .When used in conjunction with event and term ontologies , the event view can facilitate the extraction of the implicit relations present in the text .", "label": "", "metadata": {}, "score": "64.706635"}
{"text": "In response to the importance of detecting negated bio - events , we have carried out an in - depth analysis of three open access bio - event corpora containing negation information , and propose a new classification of negated bio - events .", "label": "", "metadata": {}, "score": "64.76369"}
{"text": "Using the set of features designed for that task in CoNLL 2003 [ 24 ] , our system achieves an f - score of 0.76 on the BioCreative development data , a dramatic ten points lower than its f - score of 0.86 on the CoNLL newswire data .", "label": "", "metadata": {}, "score": "64.77709"}
{"text": "View Article .Boyack KW , Newman D , Duhon RJ , Klavans R , Patek M , Biberstine JR , Schijvenaars B , Skupin A , Ma N , B\u00f6rner K : Clustering more than two million biomedical publications : comparing the accuracies of nine text - based similarity approaches .", "label": "", "metadata": {}, "score": "64.81239"}
{"text": "Lingpipe , OpenNLP , and Yamcha were trained on the gold standard annotations of each subset and the total set , and tested on the 1,499 GENIA abstracts that were not used for training .The GSC and corresponding SSC ( together always totaling 500 abstracts ) were then used to train the chunkers .", "label": "", "metadata": {}, "score": "64.83865"}
{"text": "Dependency ( Lexico - Syntactic )Features : These features are constructed using the textual bio - event information and the dependency relations found in the sentence .They include : whether direct and/or indirect dependency relations exist between the negation cue and the event - trigger and/or event - location , the types of these dependency relations and the length of the dependency chains .", "label": "", "metadata": {}, "score": "64.92468"}
{"text": "Feature engineering and selection is a vital part of any machine learning system .Various types of features have previously been used for different negation detection tasks .However , most previous work has concentrated on event - triggers , whilst the other semantic aspects of the event ( like location and participants ) have been ignored .", "label": "", "metadata": {}, "score": "64.9971"}
{"text": "This involves the identification of the sequence of words within in a sentence that is affected by a particular negation cue .Despite the apparent similarities , identification of negated bio - events is essentially different from negation scope detection .While scope annotation focusses on linguistic properties of the text , the goal of bio - event annotation is to identify which kinds of biological information appear in which parts of text .", "label": "", "metadata": {}, "score": "65.03123"}
{"text": "In this case , we will have a harder time coming up with an appropriate distribution by hand ; however , we can verify that the following distribution looks appropriate : .Furthermore , the remaining probabilities appear to be \" evenly distributed .", "label": "", "metadata": {}, "score": "65.03291"}
{"text": "It often included left or right context as part of the entity which was not contained in the gold standard .In several instances , the classifier split a string into separate entities which in fact referred to a single entity , or tagged separate entities as a single one .", "label": "", "metadata": {}, "score": "65.163795"}
{"text": "An additional issue is that this study limited the disambiguation of gene symbols to gene senses and one other category called \" non - gene sense \" , but the actual sense in this category was not resolved .This could be critical for NLP systems accessing phenotypic or disease - related information .", "label": "", "metadata": {}, "score": "65.20525"}
{"text": "The framework used by supervised classification is shown in 1.1 .Figure 1.1 : Supervised Classification .( a )During training , a feature extractor is used to convert each input value to a feature set .These feature sets , which capture the basic information about each input that should be used to classify it , are discussed in the next section .", "label": "", "metadata": {}, "score": "65.321815"}
{"text": "Following the branch that describes our input value , we arrive at a new decision node , with a new condition on the input value 's features .We continue following the branch selected by each node 's condition , until we arrive at a leaf node which provides a label for the input value .", "label": "", "metadata": {}, "score": "65.36515"}
{"text": "As was mentioned before , there are several methods for identifying the most informative feature for a decision stump .One popular alternative , called information gain , measures how much more organized the input values become when we divide them up using a given feature .", "label": "", "metadata": {}, "score": "65.37277"}
{"text": "Note .Most classification methods require that features be encoded using simple value types , such as booleans , numbers , and strings .But note that just because a feature has a simple type , this does not necessarily mean that the feature 's value is simple to express or compute .", "label": "", "metadata": {}, "score": "65.45877"}
{"text": "Supervised ML methods have also been applied to WSD in the biomedical domain .Hatzivassiloglou [ 10 ] developed a disambiguation system to determine the class of a known biomedical named entity by choosing one of three pre - defined senses : gene , RNA , protein .", "label": "", "metadata": {}, "score": "65.51911"}
{"text": "Because of the potentially complex interactions between the effects of related features , there is no way to directly calculate the model parameters that maximize the likelihood of the training set .Therefore , Maximum Entropy classifiers choose the model parameters using iterative optimization techniques , which initialize the model 's parameters to random values , and then repeatedly refine those parameters to bring them closer to the optimal solution .", "label": "", "metadata": {}, "score": "65.5333"}
{"text": "Liu H , Teller V , Friedman C : A multi - aspect comparison study of supervised word sense disambiguation .J Am Med Inform Assoc 2004 , 11 : 320 - 331 .View Article PubMed .Leroy G , Rindflesch TC : Effects of information and machine learning algorithms on word sense disambiguation with small datasets .", "label": "", "metadata": {}, "score": "65.55294"}
{"text": "Creation of the silver standard .We used a simple voting scheme to generate silver standard annotations from the annotations produced by the different chunkers .For each phrase identified by a chunker , the number of chunkers that gave exactly matching annotations was counted .", "label": "", "metadata": {}, "score": "65.58326"}
{"text": "We conclude that an SSC can be a viable alternative for or a supplement to a GSC when training chunkers in a biomedical domain .A combined system only shows improvement if the SSC is used to supplement a GSC .Whether the approach is applicable to other systems in a natural - language processing pipeline has to be further investigated .", "label": "", "metadata": {}, "score": "65.58905"}
{"text": "LANGUAGE GENERATION .To date , most of the research in natural language generation ( NLG ) has focused on generating text using template - based or rule - based ( linguistic ) techniques .In order to overcome some of the difficulties in using the current NLG technologies for spoken dialogue systems , we investigated a corpus - based approach to NLG [ 7 ] .", "label": "", "metadata": {}, "score": "65.63278"}
{"text": "We used the Enju parser [ 56 ] for extracting the part of speech ( POS ) tags , phrase structure trees and the dependency relations .A brief explanation of each feature set is as follows : .Syntactic Features : These include the POS tags of the event - trigger , event - themes , event - causes and the negation cues found in the sentence .", "label": "", "metadata": {}, "score": "65.64484"}
{"text": "For each sense , we recorded all the retrieved PMIDs , randomly selected 250 , and then obtained the corresponding abstracts to form a data pool , from which all the experiments were drawn .Feature vector and machine - learning algorithm .", "label": "", "metadata": {}, "score": "65.69289"}
{"text": "One is that the SSC that we used for training the chunkers was evaluated against the GSC of the same subdomain , whereas in the other study the domains from which the CALBC SSC and the BioCreative GSC are taken , are more divergent .", "label": "", "metadata": {}, "score": "65.69353"}
{"text": "Finally , we decided to use a different ( though similarly sized ) portion of newspaper texts covering 1995 to February 1998 ( about 70MW in total ) .All these sources excluded data from the designated test epochs .This corpus was denoted LMtrain98 .", "label": "", "metadata": {}, "score": "65.70256"}
{"text": "1.6 Sequence Classification .In order to capture the dependencies between related classification tasks , we can use joint classifier models , which choose an appropriate labeling for a collection of related inputs .In the case of part - of - speech tagging , a variety of different sequence classifier models can be used to jointly choose part - of - speech tags for all the words in a given sentence .", "label": "", "metadata": {}, "score": "65.82103"}
{"text": "For example , in multi - class classification , each instance may be assigned multiple labels ; in open - class classification , the set of labels is not defined in advance ; and in sequence classification , a list of inputs are jointly classified .", "label": "", "metadata": {}, "score": "65.82379"}
{"text": "The Gene Ontology Consortium .Nat Genet 2000 , 25 ( 1 ) : 25 - 29 .View Article PubMed .Pyysalo S , Ginter F , Heimonen J , Bj\u00c2\u00a8orne J , Boberg J , J\u00c2\u00a8arvinen J , Salakoski T : BioInfer : A Corpus for Information Extraction in the Biomedical Domain .", "label": "", "metadata": {}, "score": "65.86202"}
{"text": "It appears that the optimal negation cue list varies , both according to the domain of the text and the exact context / task in which they are identified .Detection of negated terms , negated sentences and negation scopes .The bulk of work on negation detection in the biomedical domain has been focussed on the detection of negated terms in medical reports .", "label": "", "metadata": {}, "score": "65.93797"}
{"text": "For example , when the total sample size is 20 and 5-fold cross validation is used the size of the training set is 16 , while if the sample size is 80 the size of the training set is 64 .", "label": "", "metadata": {}, "score": "65.9386"}
{"text": "Conversely , if there is information found in the hypothesis that is absent from the text , then there will be no entailment .Not all words are equally important - Named Entity mentions such as the names of people , organizations and places are likely to be more significant , which motivates us to extract distinct information for word s and ne s ( Named Entities ) .", "label": "", "metadata": {}, "score": "65.990906"}
{"text": "So I can only conclude that a different feature detector is used .Hopefully the NLTK leaders will publish the training method so we can all know for sure .This was run with python 2.6.4 on an Athlon 64 Dual Core 4600 + with 3 G RAM , but the important thing is the relative times . braubt is over 246 times faster than cpos !", "label": "", "metadata": {}, "score": "65.99643"}
{"text": "The resulting parse is evaluated for coherence then passed to the Agenda dialog manager [ 9 ] .Coherence is evaluated using goodness of the parse ( features such as coverage and fragmentation ) as well as word - level decoder confidence ; inputs deemed incoherent .", "label": "", "metadata": {}, "score": "66.02817"}
{"text": "We note that the quality of data for BioCreative was overall quite good and the organizers ' innovation of providing alternate correct boundaries for a given named entity was instrumental in reducing spurious errors due to debatable boundaries .Conclusion .We have presented in detail a machine learning system for identifying genes and proteins in text and described its feature set comprising both contextual clues and external resources .", "label": "", "metadata": {}, "score": "66.055504"}
{"text": "We can treat RTE as a classification task , in which we try to predict the True / False label for each pair .Although it seems likely that successful approaches to this task will involve a combination of parsing , semantics and real world knowledge , many early attempts at RTE achieved reasonably good results with shallow analysis , based on similarity between the text and hypothesis at the word level .", "label": "", "metadata": {}, "score": "66.097336"}
{"text": "View Article PubMed .Pyysalo S , Ohta T , Kim J - D , Tsujii J : Static Relations : a Piece in the Biomedical Information Extraction Puzzle .In Workshop on Natural Language Processing in Biomedicine ( BioNLP ) - NAACL 2009 .", "label": "", "metadata": {}, "score": "66.13089"}
{"text": "Continuing on , the classifier checks if the word ends in \" s \" .1.5 Exploiting Context .By augmenting the feature extraction function , we could modify this part - of - speech tagger to leverage a variety of other word - internal features , such as the length of the word , the number of syllables it contains , or its prefix .", "label": "", "metadata": {}, "score": "66.13233"}
{"text": "You can get part - of - speech tag statistics on a tagged corpus using analyze_tagged_corpus.py .Here 's the tag counts for the treebank corpus : .By default , analyze_tagged_corpus.py sorts by tags , but you can sort by the highest count using --sort count --reverse .", "label": "", "metadata": {}, "score": "66.19559"}
{"text": "See the NLTK webpage for a list of recommended machine learning packages that are supported by NLTK .3 Evaluation .In order to decide whether a classification model is accurately capturing a pattern , we must evaluate that model .The result of this evaluation is important for deciding how trustworthy the model is , and for what purposes we can use it .", "label": "", "metadata": {}, "score": "66.19748"}
{"text": "The first step in creating a classifier is deciding what features of the input are relevant , and how to encode those features .For this example , we 'll start by just looking at the final letter of a given name .", "label": "", "metadata": {}, "score": "66.27531"}
{"text": "Kim et al .[ 9 ] define a bio - event as a dynamic bio - relation involving one or more participants .These participants can be bio - entities or ( other ) bio - events , and are usually each assigned a semantic role / slot like theme and cause , etc .", "label": "", "metadata": {}, "score": "66.300545"}
{"text": "Nevertheless , the lower results equally reflect that finding correct entity boundaries in the biomedical domain is an extremely hard task , whereas in many cases it is quite trivial for people or place names in English - capitalization giving sufficient clues .", "label": "", "metadata": {}, "score": "66.334785"}
{"text": "They trained their classifier on the BioNLP'09 training dataset and tested it on the BioNLP'09 development dataset .They achieved 38 % precision , 76 % recall and 51 % F - score .In a further experiment , they split the data into smaller sets containing different event - types , and trained and tested the classifier separately for each smaller dataset .", "label": "", "metadata": {}, "score": "66.42087"}
{"text": "\\n .pos tags might not be useful by themselves , but they are useful metadata for other NLP tasks like dictionary lookup , pos specific keyword analysis , and they are essential for chunking & NER\\n .every Tree has a draw ( ) method that uses TKinter\\n .", "label": "", "metadata": {}, "score": "66.43399"}
{"text": "To understand the effects of increased sample size on the error rate , we stratified by the sense distribution and then tested the null hypothesis of no difference between the error rates obtained under the different sample sizes using the sign test .", "label": "", "metadata": {}, "score": "66.44682"}
{"text": "Stroudsburg , PA : Association for Computational Linguistics ( ACL ) ; 2009:21 - 29 .View Article .Agarwal S , Yu H : Biomedical negation scope detection with conditional random fields .Journal of the American Medical Informatics Association ( JAMIA ) 2010 , 17 : 696 - 701 .", "label": "", "metadata": {}, "score": "66.490265"}
{"text": "Conclusion .Several different independent aspects affect performance when using ML techniques for WSD .We found that combining them into one single result obscures understanding of the underlying methods .Although we studied only four abbreviations , we utilized a well - established statistical method that guarantees the results are likely to be generalizable for abbreviations with similar characteristics .", "label": "", "metadata": {}, "score": "66.49677"}
{"text": "Table 7 : OOV rate and perplexities of the 1998 evaluation LMs .Perplexities shown for trigram ( tg ) , 4-gram ( fg ) and word 4-gram interpolated with category trigram ( fgintcat ) .The out - of - vocabulary ( OOV ) rate and perplexity of these language models on BNeval97 and the two halves of the BNeval98 set is shown in Table 7 .", "label": "", "metadata": {}, "score": "66.536736"}
{"text": "Markatou M , Tian H , Biswas S , Hripcsak G : Analysis of variance of cross - validation estimators of the generalization error .Journal of Machine Learning Research 2005 , 6 : 1127 - 1168 .Resnik P , Yarowsky D : Distinguishing systems and distinguishing senses : New evaluation tools for words sense disambiguation .", "label": "", "metadata": {}, "score": "66.57886"}
{"text": "Furthermore , in line with the triphone figures , the overall gain for 1998 trained MLLR adapted quinphone models was 0.4 % absolute due to VTLN .For the 1998 system , the additional transcriptions from the 1998 acoustic training were available .", "label": "", "metadata": {}, "score": "66.58849"}
{"text": "In all our experiments , we used a voting threshold of three out of five chunkers for noun phrases , and a threshold of two out of four for verb phrases ( GATE only generates noun phrases ) .These thresholds gave uniformly the best results in terms of F - score when the silver standard annotations of the training data were evaluated against the gold standard .", "label": "", "metadata": {}, "score": "66.694595"}
{"text": "For example , consider the part - of - speech tagging task .At one extreme , we could create the training set and test set by randomly assigning sentences from a data source that reflects a single genre ( news ) : .", "label": "", "metadata": {}, "score": "66.69748"}
{"text": "history.append(tag ) .history.append(tag ) .return zip(sentence , history ) .1.7 Other Methods for Sequence Classification .One shortcoming of this approach is that we commit to every decision that we make .For example , if we decide to label a word as a noun , but later find evidence that it should have been a verb , there 's no way to go back and fix our mistake .", "label": "", "metadata": {}, "score": "66.74577"}
{"text": "Previous work on the identification of negated events has primarily been focussed on negated trigger events , i.e. , the cases where a negation cue modifies the event - trigger .However , our analysis shows that a significant proportion ( 37 % ) of negated events belongs to the other types .", "label": "", "metadata": {}, "score": "66.766"}
{"text": "Deactivators of no : The word no is the second most frequent negation cue in the BioScope corpus and accounts for almost 30 % of the total negation instances in the corpus .However , in over 6 % of cases , it does not indicate a negation .", "label": "", "metadata": {}, "score": "66.80767"}
{"text": "One solution is to make use of a lexicon , which describes how different words relate to one another .Using WordNet lexicon , augment the movie review document classifier presented in this chapter to use features that generalize the words that appear in a document , making it more likely that they will match words found in the training data .", "label": "", "metadata": {}, "score": "66.853386"}
{"text": "Chowdhury MFM , Lavelli A : Assessing the practical usability of an automatically annotated corpus .Proceedings of the Fifth Linguistic Annotation Workshop ; Portland 2011 , 101 - 109 .Cunningham H : GATE , a general architecture for text engineering .", "label": "", "metadata": {}, "score": "66.86512"}
{"text": "BioInfer is the only corpus of bio - events containing annotation of negation cues .We compiled a list of negation cues identified in the corpus , and labelled it cBioInfer .The use of the cue list did not result in high performance when applied to the other two datasets ( i.e. , GENIA Event and BioNLP'09 ST ) .", "label": "", "metadata": {}, "score": "66.87381"}
{"text": "The Maximum Entropy classifier model is a generalization of the model used by the naive Bayes classifier .Like the naive Bayes model , the Maximum Entropy classifier calculates the likelihood of each label for a given input value by multiplying together the parameters that are applicable for the input value and label .", "label": "", "metadata": {}, "score": "66.90233"}
{"text": "The goal of our work is not to overcome existing benchmarks , but show that much of the feature engineering done in the benchmarks can be learnt automatically from the task specific data .More importantly , we wish to show large dimensionality word look tables can be compacted into a lookup table using characters and a compositional model allowing the model scale better with the size of the training data .", "label": "", "metadata": {}, "score": "66.90326"}
{"text": "Once we 've picked a feature , we can build the decision stump by assigning a label to each leaf based on the most frequent label for the selected examples in the training set ( i.e. , the examples where the selected feature has that value ) .", "label": "", "metadata": {}, "score": "66.90665"}
{"text": "We repeated this experiment ten times with randomly selected training and testing datasets , and the average F - score was only slightly ( 0.5 % ) less than the F - score achieved by the 10-fold cross validation .", "label": "", "metadata": {}, "score": "67.02564"}
{"text": "Tateisi Y , Yakushiji A , Ohta T , Tsujii J : Syntax Annotation for the GENIA corpus .Proceedings of the Second International Joint Conference on Natural Language Processing ; Jeju Island , South Korea 2005 , 222 - 227 .", "label": "", "metadata": {}, "score": "67.05124"}
{"text": "Some iterative optimization techniques are much faster than others .When training Maximum Entropy models , avoid the use of Generalized Iterative Scaling ( GIS ) or Improved Iterative Scaling ( IIS ) , which are both considerably slower than the Conjugate Gradient ( CG ) and the BFGS optimization methods .", "label": "", "metadata": {}, "score": "67.07173"}
{"text": "A brief description of each list is as follows : .c40 : We formulated a list of 40 cue words by combining the previously published lists and cues discovered during our own initial analysis of negated bio - events .cBioInfer : We extracted negation cues from the BioInfer corpus .", "label": "", "metadata": {}, "score": "67.087"}
{"text": "We discarded the cues which occurred only once in the corpus and labelled the remaining list as cBioInfer .cBioScope : This is the list of 28 negation cues , compiled by Morante [ 42 ] from the BioScope corpus .cCore : We analysed 1,000 randomly selected negated bio - events from the three corpora containing negated bio - events .", "label": "", "metadata": {}, "score": "67.10977"}
{"text": "It can be seen that there is a rather different distribution data type between the two sets : particularly for F0 , F2 , F4 and FX .The HTK Broadcast News system runs in a number of stages .This is followed by generating a lattice for each segment using the adapted triphone models with a bigram LM , expanding these lattices using a word 4-gram interpolated with a category trigram LM , and performing iterative lattice rescoring and MLLR adaptation with a set of quinphone HMMs .", "label": "", "metadata": {}, "score": "67.11144"}
{"text": "However , the addition of these features improved the overall performance by 0.5 % to 1 % , depending on the dataset .In order to further investigate the correlation between event - type and polarity , we designed two experiments : .", "label": "", "metadata": {}, "score": "67.17341"}
{"text": "The default tagger is 93.9 % accurate on the conll2000 corpus , which is to be expected since both treebank and conll2000 are based on the Wall Street Journal .You can see all the metrics shown below for yourself by running python analyze_tagger_coverage.py conll2000 --metrics .", "label": "", "metadata": {}, "score": "67.188354"}
{"text": "Hull D , Pettifer S , Kell D : Defrosting the digital library : bibliographic tools for the next generation web .PLoS Comput Biol 2008 , 4 ( 10 ) : e1000204 .View Article PubMed .Ananiadou S , McNaught J ( Eds ) : Text Mining for Biology and Biomedicine .", "label": "", "metadata": {}, "score": "67.19704"}
{"text": "Effects of \" sense distribution \" have been addressed in other papers [ 30 , 37 ] because it is believed that the performance of a WSD classifier may change if the distribution of the different senses is unbalanced .For example , when there is a majority sense for an ambiguous word , the improvement of a WSD classifier is believed to be very small .", "label": "", "metadata": {}, "score": "67.206024"}
{"text": "How do you think that your results might be different if you used a different feature extractor ?What features are relevant in this distinction ?Build a classifier that predicts when each word should be used .However , dialog acts are highly dependent on context , and some sequences of dialog act are much more likely than others .", "label": "", "metadata": {}, "score": "67.217125"}
{"text": "Merkel M , Andersson M : Combination of contextual features for word sense disambiguation .SENSEVAL-2 Workshop 123 - 127 .Bruce R , Wiebe J : Word sense disambiguation using decomposable models .Proceedings of the Thirty - second Annual Meeting of the Association of Computational Linguistics 139 - 146 .", "label": "", "metadata": {}, "score": "67.27387"}
{"text": "Here , we can see that the classifier begins by checking whether a word ends with a comma - if so , then it will receive the special tag \" , \" .Next , the classifier checks if the word ends in \" the \" , in which case it 's almost certainly a determiner .", "label": "", "metadata": {}, "score": "67.27393"}
{"text": "Event - based retrieval allows the user to specify one or more constraints on the events to be retrieved , without having to be concerned about the precise wording used in the text .These constraints could be in terms of the type of the event , and/or the type(s ) of its participants , and/or the precise format of participants playing particular roles in the event .", "label": "", "metadata": {}, "score": "67.320145"}
{"text": "Individual features make their contribution to the overall decision by \" voting against \" labels that do n't occur with that feature very often .In particular , the likelihood score for each label is reduced by multiplying it by the probability that an input value with that label would have the feature .", "label": "", "metadata": {}, "score": "67.32457"}
{"text": "Rate this definition : .Spoken Corpus Frequency .Rank popularity for the word ' Victory ' in Spoken Corpus Frequency : # 1804 .Written Corpus Frequency .Rank popularity for the word ' Victory ' in Written Corpus Frequency : # 4158 .", "label": "", "metadata": {}, "score": "67.33569"}
{"text": "Amongst the bio - event corpora introduced above , only three contain annotations relating to event polarity , i.e. , GENIA Event , BioInfer and BioNLP'09 ST .Negation cues ( i.e. , words and phrases that explicitly indicate a negation ) have been explicitly annotated only in BioInfer .", "label": "", "metadata": {}, "score": "67.343376"}
{"text": "The pattern indicates an occurrence of the word not immediately followed by one of its deactivators .We only considered the following five deactivators : clear , evident , known , necessarily and only .In our analysis of the GENIA Event corpus , we discovered a total of 261 events which belonged to the sentences containing the above pattern .", "label": "", "metadata": {}, "score": "67.382095"}
{"text": "In addition , we used an SVM classifier for all the experiments .Since the goals of our study did not include the comparison of different algorithms , we do not present related results here .Other studies showed that different ML algorithms had similar performance for WSD tasks [ 29 , 30 ] .", "label": "", "metadata": {}, "score": "67.39552"}
{"text": "System development involves a great deal of knowledge engineering , which is both time - consuming and requires a variety of experts to participate in the process .Therefore methods that seek to minimize this resource , for example through training based on domain - specific corpora are preferred .", "label": "", "metadata": {}, "score": "67.43422"}
{"text": "For example , \" Varicella - zoster \" would become Xx - xxx , \" mRNA \" would become xXXX , and \" CPA1 \" would become XXXd .Beyond standard word and POS tag features , character substring and word shape features were central players in the system of [ 2 ] .", "label": "", "metadata": {}, "score": "67.55002"}
{"text": "Most evaluation techniques calculate a score for a model by comparing the labels that it generates for the inputs in a test set ( or evaluation set ) with the correct labels for those inputs .This test set typically has the same format as the training set .", "label": "", "metadata": {}, "score": "67.557175"}
{"text": "Random Forest outperformed the other algorithms on GENIA Event and BioInfer , and scored second on the BioNLP'09 ST by a narrow margin of 0.8 % .Logistic Regression achieved the third best results on both GENIA Event and BioInfer .It scored fourth on BioNLP'09 ST . .", "label": "", "metadata": {}, "score": "67.57402"}
{"text": "Once again , there are many distributions that are consistent with this new piece of information , such as : .But again , we will likely choose the distribution that makes the fewest unwarranted assumptions - in this case , distribution ( v ) .", "label": "", "metadata": {}, "score": "67.63511"}
{"text": "Figure 12 shows the micro - averaged results for each algorithm .Discussion .Comparison with previous results .As mentioned earlier , the identification of negated bio - events is a new area of research and only a few results have been reported previously .", "label": "", "metadata": {}, "score": "67.74296"}
{"text": "The features used in our model are all binary indicator functions that pick out particular data contexts and pair them with each class .As is common for NLP models using many features , we employ equal - scale quadratic regularization of the parameter weights to prevent parameters rarely present in the data having high weights , which leads to model overfitting .", "label": "", "metadata": {}, "score": "67.76299"}
{"text": "The Negatome database [ 19 ] has been released , which provides information about non - interacting protein pairs .Efforts have been made to incorporate negation in the popular biomedical ontologies [ 20 ] .Furthermore , negation detection has been identified as the foremost challenge in biomedical relation extraction [ 21 ] .", "label": "", "metadata": {}, "score": "67.78046"}
{"text": "Recently , in the field of biomedical text mining , the development and enhancement of event - based systems has received significant interest .The ability to identify negated events is a key performance element for these systems .We have conducted the first detailed study on the analysis and identification of negated bio - events .", "label": "", "metadata": {}, "score": "67.79199"}
{"text": "This is exactly what the Maximum Entropy classifier does as well .In particular , for each joint - feature , the Maximum Entropy model calculates the \" empirical frequency \" of that feature - i.e. , the frequency with which it occurs in the training set .", "label": "", "metadata": {}, "score": "67.808624"}
{"text": "These observable patterns - word structure and word frequency - happen to correlate with particular aspects of meaning , such as tense and topic .But how did we know where to start looking , which aspects of form to associate with which aspects of meaning ?", "label": "", "metadata": {}, "score": "67.83507"}
{"text": "Over a period of three weeks the system synthesized 18,276 phrases , 459 of which ( 2.5 % ) contained out of vocabulary words ( 71 different words ) .These were all less frequent ( or forgotten ) places names .", "label": "", "metadata": {}, "score": "67.90748"}
{"text": "Many of our features were focused on increasing the correct identification of entity boundaries .This is partly an artifact of the scoring metric : using an f - score of exact match precision and recall means that one is penalized twice , both for a FP and a FN , in cases of an incorrect boundary identification .", "label": "", "metadata": {}, "score": "67.92761"}
{"text": "Coinciding with the github move , the documentation was updated to use Sphinx , the same documentation generator used by Python and many other projects .While I personally like Sphinx and restructured text ( which I used to write this post ) , I 'm not thrilled with the results .", "label": "", "metadata": {}, "score": "67.93889"}
{"text": "The default tagger is 99.57 % accurate on treebank , and below you can see exactly on which tags it fails .The Found column shows the number of occurrences of each tag produced by the default tagger , while the Actual column shows the actual number of occurrences in the treebank corpus .", "label": "", "metadata": {}, "score": "67.96524"}
{"text": "It was presented to show the degree of difficulty among different abbreviations .Results from 5-fold cross - validation showed no statistical difference with results from 10-fold cross - validation , which indicated 5-fold cross - validation might be used in evaluation in order to save computational power ( for a discussion of the relative merits of 5-fold cross - validation vs. 10-fold cross - validation , see [ 35 ] ) .", "label": "", "metadata": {}, "score": "67.994354"}
{"text": "Note that the polarity of E1 is positive .Based on our analysis of negated bio - events , we conclude that the ambiguity status of a negation cue is not universal .Rather , it is determined by the : . nature of text under consideration .", "label": "", "metadata": {}, "score": "68.047554"}
{"text": "Tables 2 , 3 , 4 show the performance of both the \" open \" and \" closed \" versions of the system on the development and evaluation data as well as lesion studies showing the individual contribution of feature classes to the overall performance .", "label": "", "metadata": {}, "score": "68.04816"}
{"text": "It applies these N(N-1)/2 SVM classifiers and the class assignment is determined by a voting strategy ( e.g. the class chose by the maximum number of SVM classifiers wins ) .The performance was measured using both a 5-fold and a 10-fold cross - validation method .", "label": "", "metadata": {}, "score": "68.05995"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of BPD data set ( where there are 3 ambiguous senses that are different ) using 5-fold cross validation and \" one - vs - rest \" algorithm .", "label": "", "metadata": {}, "score": "68.06234"}
{"text": "This section provides a brief overview of the previous work done on types of negation , negation cues , detection of negated terms and negation scopes , detection of negated protein - protein interactions ( PPIs ) and identification of negated bio - events .", "label": "", "metadata": {}, "score": "68.115364"}
{"text": "To be able to identify whether there are significant differences in the error rates due to different sample sizes and sense distributions while controlling for the abbreviation used , we used Friedman 's procedure .Notice that if we stratify by the abbreviation , the mean error rates form a two - way table where the columns correspond to different sample sizes and the rows correspond to different sense distributions .", "label": "", "metadata": {}, "score": "68.16088"}
{"text": "Other confounding issues of WSD .Other issues in addition to sample size , distribution of senses , and difficulty of the task also affect the performance and subsequent assessment of WSD classifiers , as noted below : .As often discussed in various papers , different features were evaluated to see their contribution to classifier performance [ 10 , 20 , 29 ] .", "label": "", "metadata": {}, "score": "68.17528"}
{"text": "Each time the error analysis procedure is repeated , we should select a different dev - test / training split , to ensure that the classifier does not start to reflect idiosyncrasies in the dev - test set .But once we 've used the dev - test set to help us develop the model , we can no longer trust that it will give us an accurate idea of how well the model would perform on new data .", "label": "", "metadata": {}, "score": "68.210464"}
{"text": "In the case of Communicator , destination names and the names of users registering for the service .The latter components can be easily modified to accommodate evolution and do not appear to impact the core language .This is accommodated in language modeling through the use of a class language model .", "label": "", "metadata": {}, "score": "68.21478"}
{"text": "We will learn more about the naive Bayes classifier later in the chapter .For now , let 's just test it out on some names that did not appear in its training data : .Observe that these character names from The Matrix are correctly classified .", "label": "", "metadata": {}, "score": "68.28158"}
{"text": "This FV transform was used with , for the wideband data , HMMs estimated with a single iteration of speaker adaptive training ( SAT ) [ 14 ] to update the mean parameters .The effect of these changes is shown in Table 5 .", "label": "", "metadata": {}, "score": "68.295944"}
{"text": "Vincze V , Szarvas G , Farkas R , Mora G , Csirik J : The BioScope corpus : biomedical texts annotated for uncertainty , negation and their scopes .BMC Bioinformatics 2008 , 9 ( 11 ) : S9 .View Article PubMed .", "label": "", "metadata": {}, "score": "68.29607"}
{"text": "But by the time the decision tree learner has descended far enough to use these features , there is not enough training data left to reliably determine what effect they should have .If we could instead look at the effect of these features across the entire training set , then we might be able to make some conclusions about how they should affect the choice of label .", "label": "", "metadata": {}, "score": "68.31105"}
{"text": "View Article PubMed .Wiegand M , Balahur A , Roth B , Klakow D , Montoyo A : A Survey on the Role of Negation in Sentiment Analysis .In Workshop on Negation and Speculation in Natural Language Processing ( NeSp - NLP 2010 ) , ACL 2010 .", "label": "", "metadata": {}, "score": "68.455536"}
{"text": "It is worth comparing these performance figures with levels of interannotator agreement in the biomedical domain .Interannotator agreement effectively provides a ceiling on the performance that can be expected from a system by measuring how well a human annotator performs on a task .", "label": "", "metadata": {}, "score": "68.46234"}
{"text": "We looked up all tokens in the gazetteer and in the English dictionary CELEX and calculated the frequency of each token in the corpus .We then identified abbreviations and long forms using the method of [ 7 ] .We tagged the data for part - of - speech ( POS ) using the TnT POS tagger [ 8 ] trained on the GENIA corpus [ 9 ] , which provides a gold standard for POS tags in biomedical text .", "label": "", "metadata": {}, "score": "68.49603"}
{"text": "It has been our experience that once the core of the language for a domain is identified , it remains stable as long as the definition of the domain is not significantly altered .This is due in part to the inherent stability of certain sub - languages such as that for dates and times as well as an apparent independence between sub - domains comprising the full domain .", "label": "", "metadata": {}, "score": "68.540276"}
{"text": "6.3 Generative vs Conditional Classifiers .An important difference between the naive Bayes classifier and the Maximum Entropy classifier concerns the type of questions they can be used to answer .The naive Bayes classifier is an example of a generative classifier , which builds a model that predicts P(input , label ) , the joint probability of a ( input , label ) pair .", "label": "", "metadata": {}, "score": "68.573715"}
{"text": "Sometimes , the text containing a bio - event also contains a word or phrase that provides an indication of the rate , level , strength or intensity of the interaction .In [ 55 ] , we refer to this indication as the manner of the event , and three types of manner are distinguished : high , neutral and low .", "label": "", "metadata": {}, "score": "68.59269"}
{"text": "Miyao Y , Sagae K , Saetre R , Matsuzaki T , Tsujii J : Evaluating contributions of natural language parsers to protein - protein interaction extraction .Bioinformatics 2009 , 25 ( 3 ) : 394 - 400 .View Article PubMed .", "label": "", "metadata": {}, "score": "68.68698"}
{"text": "By removing stopwords before matching we tried to remove \" uninformative \" words that should not play a role in determining whether phrases are the same , similar to other studies ( e.g. , [ 19 , 20 ] ) .Stopword removal can be seen as a relaxation of the strict matching requirement .", "label": "", "metadata": {}, "score": "68.68954"}
{"text": "We can then examine individual error cases where the model predicted the wrong label , and try to determine what additional pieces of information would allow it to make the right decision ( or which existing pieces of information are tricking it into making the wrong decision ) .", "label": "", "metadata": {}, "score": "68.732"}
{"text": "However , the BioInfer corpus is unique in the sense that it annotates even contrast and comparison markers as negation cues .Figure 7 shows an example of this type of negation .The event E1 is triggered by the word activate , and it expresses the positive_regulation of p38 MAPk by MKK3 in LPS - treated neutrophils .", "label": "", "metadata": {}, "score": "68.74136"}
{"text": "The confusion matrix indicates that common errors include a substitution of NN for JJ ( for 1.6 % of words ) , and of NN for NNS ( for 1.5 % of words ) .Note that periods ( . ) indicate cells whose value is 0 , and that the diagonal entries - which correspond to correct classifications - are marked with angle brackets .", "label": "", "metadata": {}, "score": "68.74183"}
{"text": "Rather than expanding the GSC , we supplement the GSC with an SSC from the same domain and train the chunker on the combined GSC and SSC to improve chunker performance .Related work .During the past decade , much research has been devoted to systems that combine different classifiers , also called multiple classifier systems or ensemble - based systems [ 1 ] .", "label": "", "metadata": {}, "score": "68.75694"}
{"text": "5.3 Non - Binary Features .We have assumed here that each feature is binary , i.e. that each input either has a feature or does not .Label - valued features ( e.g. , a color feature which could be red , green , blue , white , or orange ) can be converted to binary features by replacing them with binary features such as \" color - is - red \" .", "label": "", "metadata": {}, "score": "68.77311"}
{"text": "This section provides a brief overview of bio - events and describes the problem of identifying negated bio - events .Bio - events .In its most general form , a textual event is as an action , relation , process or state expressed in the text [ 23 ] .", "label": "", "metadata": {}, "score": "68.80366"}
{"text": "When performing classification tasks with three or more labels , it can be informative to subdivide the errors made by the model based on which types of mistake it made .A confusion matrix is a table where each cell [ i , j ] indicates how often label j was predicted when the correct label was i .", "label": "", "metadata": {}, "score": "68.82092"}
{"text": "Stroudsburg , PA : Association for Computational Linguistics ; 2006:1017 - 1024 .View Article .Ananiadou S , Thompson P , Nawaz R : Improving Search Through Event - based Biomedical Text Mining .In First International Workshop on Automated Motif Discovery in Cultural Heritage and Scientific Communication Texts ( AMICUS 2010 ) , CLARIN / DARIAH 2010 .", "label": "", "metadata": {}, "score": "68.824356"}
{"text": "3.5 Cross - Validation .In order to evaluate our models , we must reserve a portion of the annotated data for the test set .As we already mentioned , if the test set is too small , then our evaluation may not be accurate .", "label": "", "metadata": {}, "score": "68.87891"}
{"text": "How likely is a given input value with a given label ?What is the most likely label for an input that might have one of two values ( but we do n't know which ) ?The Maximum Entropy classifier , on the other hand , is an example of a conditional classifier .", "label": "", "metadata": {}, "score": "68.898315"}
{"text": "Error rates for each combination of sense distribution and sample size were averaged using 30 runs .Statistical methodology .To quantify the effects of sample size , sense distribution and difficulty of the task on the error rate , appropriate statistical methods were used .", "label": "", "metadata": {}, "score": "68.90565"}
{"text": "Removing second and third order features also improved our result marginally .Table 2 .Development set results System Results on Cross - Validated Training / Dev Data .Discussion .Sources of error .A number of false positives ( FPs ) occurred when the entity tagged by the classifier was a description of a gene rather than a gene name , as with \" homologue gene \" .", "label": "", "metadata": {}, "score": "68.97054"}
{"text": "We use a maximum likelihood technique to select the best data warp factor via a parabolic search .It is important when comparing the warped data likelihoods to properly take into account the effect of the transformation .We have done this implicitly by performing variance normalisation on the data .", "label": "", "metadata": {}, "score": "68.97975"}
{"text": "In our example , we chose distribution ( i ) because its label probabilities are evenly distributed - in other words , because its entropy is high .In general , the Maximum Entropy principle states that , among the distributions that are consistent with what we know , we should choose the distribution whose entropy is highest .", "label": "", "metadata": {}, "score": "69.038315"}
{"text": "Results .We ran a series of experiments to obtain the best results for each dataset and to systematically evaluate the impact of using different cue lists and learning algorithms .This section describes the results of our experiments .All results are based on 10-fold cross validation .", "label": "", "metadata": {}, "score": "69.05296"}
{"text": "Utterances were classified into 29 categories , corresponding to major speech acts ; within each utterance concepts were tagged as belonging to one of 24 classes .For each utterance category , a 5-gram language model was built then used for generation ( the NLG component was provided with a speech act and a set of concepts to transmit to the user ) .", "label": "", "metadata": {}, "score": "69.11064"}
{"text": "Tanabe L , Wilbur WJ : Tagging gene and protein names in biomedical text .Bioinformatics 2002 , 18 : 1124 - 1132 .View Article PubMed .Malouf R : A comparison of algorithms for maximum entropy parameter estimation .Proceedings of the Sixth Conference on Natural Language Learning ( CoNLL-2002 ) 2002 , 49 - 55 .", "label": "", "metadata": {}, "score": "69.1494"}
{"text": "And since the number of branches increases exponentially as we go down the tree , the amount of repetition can be very large .A related problem is that decision trees are not good at making use of features that are weak predictors of the correct label .", "label": "", "metadata": {}, "score": "69.23062"}
{"text": "On the other hand , if the input values have a wide variety of labels , then there are many labels with a \" medium \" frequency , where neither P(l ) nor log 2P(l ) is small , so the entropy is high .", "label": "", "metadata": {}, "score": "69.26639"}
{"text": "In this study , we used 4 abbreviations from Liu 's abbreviation list .However , we used a different method to collect the datasets because we wanted to control the sample sizes of the senses for our experiments .Leroy [ 30 ] tried to reduce the training sample size by supplying external knowledge from the UMLS for supervised machine learning algorithms , but the results were not promising .", "label": "", "metadata": {}, "score": "69.35898"}
{"text": "Correlation between event - type and polarity .Our analysis of negated bio - events revealed that certain words act as negation cues only in the context of specific types of events ( see section 5.1.4 ) .Apart from this , we did not find any evidence of \" linguistic correlation \" between the semantic type of an event and its polarity .", "label": "", "metadata": {}, "score": "69.37946"}
{"text": "The names classifier that we have built generates about 100 errors on the dev - test corpus : .Looking through this list of errors makes it clear that some suffixes that are more than one letter can be indicative of name genders .", "label": "", "metadata": {}, "score": "69.39596"}
{"text": "We therefore adjust our feature extractor to include features for two - letter suffixes : .Rebuilding the classifier with the new feature extractor , we see that the performance on the dev - test dataset improves by almost 2 percentage points ( from 76.5 % to 78.2 % ) : .", "label": "", "metadata": {}, "score": "69.39939"}
{"text": "In other words , f 2 is an exact copy of f 1 , and contains no new information .When the classifier is considering an input , it will include the contribution of both f 1 and f 2 when deciding which label to choose .", "label": "", "metadata": {}, "score": "69.40094"}
{"text": "As shown in Figure 5 , PCA , which has two very close senses , had much higher error rates than BSA , which has two unrelated senses .Therefore , when comparing the performance of different WSD systems , data sets with the same degree of difficulty should be used .", "label": "", "metadata": {}, "score": "69.464386"}
{"text": "Hence , a positive contextual polarity can be ascribed to these words in certain instances .Similarly , the words absent and absence may also be used to convey negative regulation rather than negation .Figure 8 shows a case of conflicting lexical and contextual polarities .", "label": "", "metadata": {}, "score": "69.47711"}
{"text": "We appreciated and benefited from the feedback and suggestions from the anonymous reviewers and participants at the BioCreative Workshop , and final comments from Lynette Hirschman .This work was performed as part of the SEER project , which is supported by a Scottish Enterprise Edinburgh - Stanford Link Grant ( R36759 ) .", "label": "", "metadata": {}, "score": "69.47824"}
{"text": "In a recent article on biologists ' perspective of negation , Krallinger [ 22 ] identified events with negated locations as of particular interest to biomedical practitioners .Comparison and contrast .This category corresponds to bio - events where the negation is signalled via contrast or comparison , normally with another bio - event .", "label": "", "metadata": {}, "score": "69.48128"}
{"text": "There are many probability distributions that we could choose for the ten senses , such as : .Although any of these distributions might be correct , we are likely to choose distribution ( i ) , because without any more information , there is no reason to believe that any word sense is more likely than any other .", "label": "", "metadata": {}, "score": "69.49385"}
{"text": "When comparing the performance of WSD classifiers , those metrics are critical because they indicate whether or not an improvement is statistically significant ; if there is a large deviation , there may not actually be an improvement even though one error rate is smaller than the other .", "label": "", "metadata": {}, "score": "69.50609"}
{"text": "More information on characteristics and performance of these chunkers can be found in our previous comparative study of chunkers [ 4 ] , which also included Genia Tagger .Since Genia Tagger comes with a fixed pre - trained model based on the corpora that we use in this study , it could bias the results of our experiments and was not included .", "label": "", "metadata": {}, "score": "69.64252"}
{"text": "Use the dev - test set to check your progress .Once you are satisfied with your classifier , check its final performance on the test set .How does the performance on the test set compare to the performance on the dev - test set ?", "label": "", "metadata": {}, "score": "69.67383"}
{"text": "The most direct method of facilitating the recognition of a particular negated event - type by the system is to engineer features corresponding to that type , e.g. , features based on constituency or dependency relations between the negation cue and the event constituents ( triggers , participants and attributes ) .", "label": "", "metadata": {}, "score": "69.68035"}
{"text": "[ 1 ] R. Singh , B. Raj , and R. M. Stern , Domain adduced state tying for cross domain acoustic modelling , Proc .Eurospeech , 1999 .", "label": "", "metadata": {}, "score": "69.701004"}
{"text": "The SklearnClassifier provides a general interface to text classification with scikit - learn .While scikit - learn is still pre-1.0 , it is rapidly becoming one of the most popular machine learning toolkits , and provides more advanced feature extraction methods for classification .", "label": "", "metadata": {}, "score": "69.72951"}
{"text": "It uses normalised Euclidean distance to find the training instance closest to a given test instance , and predicts the same class as this training instance .IB1 is similar to the nearest neighbour algorithm , except that it normalises its attributes ' ranges , processes instances incrementally , and has a simple policy for tolerating missing values .", "label": "", "metadata": {}, "score": "69.74617"}
{"text": "We found that while the ABGene tagger used alone achieved only a modest f - score of 0.62 on the BioCreative development data , use of ABGene NE output as a feature nevertheless slightly improved our recall and overall f - score .", "label": "", "metadata": {}, "score": "69.83486"}
{"text": "PubMed View Article .Kim J , Ohta T , Pyysalo S , Kano Y , Tsujii J : Overview of BioNLP'09 shared task on event extraction .Proceedings of the Workshop on BioNLP : Shared Task ; Boulder 2009 , 1 - 9 .", "label": "", "metadata": {}, "score": "69.84115"}
{"text": "The frequency of the negated participants type ranges between 10 % and 17 % , with a micro average of 11 % .This is the second most prevalent type in BioNLP'09 ST and BioInfer and the third most prevalent type in GENIA .", "label": "", "metadata": {}, "score": "69.87463"}
{"text": "In a very recent study , Chowdhury and Lavelli compared a gene recognition system trained on an initial version of the CALBC SSC against the system trained on the BioCreative GSC [ 6 ] .Methods .Chunking systems .To generate a silver standard , we used five well - known and publicly available chunkers : GATE chunker 5.0 [ 7 ] , Lingpipe 3.8 [ 8 ] , MetaMap 2008v2 [ 9 ] , OpenNLP 2.1 [ 10 ] , and Yamcha 0.33 [ 11 ] .", "label": "", "metadata": {}, "score": "70.01825"}
{"text": "SIGIR'04 Workshop on Search and Discovery in BioInformatics .Hatzivassiloglou V , Duboue PA , Rzhetsky A : Disambiguating proteins , genes , and RNA in text : a machine learning approach .Bioinformatics 2001 , 17 ( Suppl 1 ) : S97 - 106 .", "label": "", "metadata": {}, "score": "70.01893"}
{"text": "They used the Training subset of the BioNLP'09 ST dataset for training their system and the Development subset for testing .They achieved 38 % precision , 76 % recall and 51 % F - score .In comparison , our system achieved an F - score of above 70 % with 10-fold cross validation on the entire BioNLP'09 ST dataset .", "label": "", "metadata": {}, "score": "70.10991"}
{"text": "We incorporated additional information by tagging the abstract and then adding to words in the test sentence a feature that indicated whether the word was tagged as a gene in the abstract .We found that this feature was only helpful when combined with other information such as frequency and whether the word had appeared in the English dictionary CELEX .", "label": "", "metadata": {}, "score": "70.16803"}
{"text": "These constructions include : no sign of , no evidence of , no proof and no guarantee that .Our analysis of the GENIA Event corpus revealed that in some cases , these constructions do trigger negated events .For example , consider the sentence in Figure 10 , where the construction no evidence triggers the negation of event E2 .", "label": "", "metadata": {}, "score": "70.2035"}
{"text": "These papers are important in that they report on useful methods and provide insights and overall results .However , a deeper and more systematic analysis is needed in order to obtain a better understanding of the different factors affecting the performance of ML methods for WSD .", "label": "", "metadata": {}, "score": "70.31175"}
{"text": "Both E2 and E3 have been annotated as negated ; this is despite the fact that the sentence lacks an explicit negation cue .Bio - event example with comparison and contrast ( Source : GENIA Event Corpus ; PMID : 10079106 ) .", "label": "", "metadata": {}, "score": "70.32138"}
{"text": "We used several command features including the existence of S- , VP- and NP - command relations between the negation cue and the event - trigger and/or event - location .The scope features were engineered using the information pertaining to whether the event - trigger , event - participants or event - location fall under the syntactic scope of the negation cue .", "label": "", "metadata": {}, "score": "70.3573"}
{"text": "A sprint thru Python 's Natural Language ToolKit , presented at SFPython on 9/14/2011 .Covers tokenization , part of speech tagging , chunking & NER , text classification , and training text classifiers with nltk - trainer . text processing is very useful in a number of areas , and there 's tons of unstructured text flooding the internet nowadays , and NLP / ML is one of the best ways to deal with it\\n . this is what I 'll cover today , but there 's a lot more I wo n't be covering\\n .", "label": "", "metadata": {}, "score": "70.38887"}
{"text": "Kazama J , Makino T , Ohta Y , Tsujii J - I : Biomedical Name Recognition : Tuning support vector machines for biomedical named entity recognition .Proceedings of the ACL 2002 Workshop on Natural Language Processing in the Biomedical Domain 2002 , 1 - 8 .", "label": "", "metadata": {}, "score": "70.39003"}
{"text": "We have tested the two scenarios using three chunkers , Lingpipe , OpenNLP , and Yamcha , and two different corpora , GENIA and PennBioIE .When the outputs of the chunkers were combined , the combined system showed little improvement when using the SSC .", "label": "", "metadata": {}, "score": "70.47066"}
{"text": "The i th binary SVM classifier is trained by considering all instances associated with the i th class as positive examples and the others as negative instances .It applies the N classifiers and chooses the one with the highest confidence .", "label": "", "metadata": {}, "score": "70.514"}
{"text": "In example ( 1 ) below which appeared in the evaluation data , our system annotated \" nuclear factor Y \" as a gene while the gold standard annotated only \" nuclear factor \" ; we were penalized for both a FP and a FN .", "label": "", "metadata": {}, "score": "70.62679"}
{"text": "Aha DW , Kibler D , Albert MK : Instance - based learning algorithms .Mach Learn 1991 , 6 : 37 - 66 .Wilson T , Wiebe J , Hwa R : Just How Mad Are You ?Finding Strong and Weak Opinion Clauses .", "label": "", "metadata": {}, "score": "70.67007"}
{"text": "We call these values w[label ] and w[f , label ] the parameters or weights for the model .Using the naive Bayes algorithm , we set each of these parameters independently : .However , in the next section , we 'll look at a classifier that considers the possible interactions between these parameters when choosing their values .", "label": "", "metadata": {}, "score": "70.76222"}
{"text": "First , we construct a list of documents , labeled with the appropriate categories .For this example , we 've chosen the Movie Reviews Corpus , which categorizes each review as positive or negative .words(fileid ) ) , category ) ... for category in movie_reviews . categories ( ) ... for fileid in movie_reviews .", "label": "", "metadata": {}, "score": "70.76919"}
{"text": "Given a suitable architecture , the principal effort in development in taken up in the acquisition and processing of a domain knowledge base .This paper describes a variety of techniques we have applied to modeling in acoustic , language , task , generation and synthesis components of the system .", "label": "", "metadata": {}, "score": "70.81464"}
{"text": "Our analysis revealed that the instances of each of the five main types of negated bio - events are present in the three corpora with varying frequencies .Table 2 shows the distributions in the three different corpora and the macro and micro averages for each type .", "label": "", "metadata": {}, "score": "70.94321"}
{"text": "The 0.9 version of the corpus was released in 2004 and includes the CYP and Oncology corpora of the Linguistic Data Consortium .The CYP corpus consists of 324 Medline abstracts on the inhibition of cytochrome P450 enzymes .The Oncology corpus consists of 318 Medline abstracts on cancer and molecular genetics .", "label": "", "metadata": {}, "score": "70.98102"}
{"text": "Silver standard as alternative for gold standard .To test whether an SSC could serve as a substitute for a GSC , we compared the performance of chunkers trained on silver standard annotations of the abstracts in the PennBioIE corpus with the performance of the chunkers trained on the gold standard annotations of the same corpus .", "label": "", "metadata": {}, "score": "71.10189"}
{"text": "For each combination of error rates we have a sample of 30 observations .To exemplify , assume the pair consisted of the error rates obtained under sample size 20 and 40 .Then the set of observations was comprised of those error rates obtained from the 30 simulation runs .", "label": "", "metadata": {}, "score": "71.15051"}
{"text": "Acknowledgements .This study was supported by the European Commission FP7 Program ( FP7/2007 - 2013 ) under grant no .231727 ( the CALBC Project ) .Authors ' contributions .NK co - developed the methodology , built the software infrastructure , carried out the experiments , and drafted the manuscript .", "label": "", "metadata": {}, "score": "71.1759"}
{"text": "A number of different studies have identified negation cues that appear in medical and biomedical texts .Chapman et al .[ 39 ] compiled a comprehensive list of 272 negation cues specific to medical discharge summaries .They reported that two negation cues ( no and without ) accounted for a large proportion of negative statements .", "label": "", "metadata": {}, "score": "71.19467"}
{"text": "We can systematically evaluate the classifier on a much larger quantity of unseen data : .Finally , we can examine the classifier to determine which features it found most effective for distinguishing the names ' genders : .This listing shows that the names in the training set that end in \" a \" are female 33 times more often than they are male , but names that end in \" k \" are male 32 times more often than they are female .", "label": "", "metadata": {}, "score": "71.19505"}
{"text": "\" But greetings , questions , answers , assertions , and clarifications can all be thought of as types of speech - based actions .Recognizing the dialogue acts underlying the utterances in a dialogue can be an important first step in understanding the conversation .", "label": "", "metadata": {}, "score": "71.21224"}
{"text": "For each abbreviation , we measured error rates of the SVM classifier under different combinations of sample size , sense distribution , cross validation scheme ( 5-fold vs. 10-fold ) , and multi - class SVM algorithms ( for BPD only , which has 3 different senses ) .", "label": "", "metadata": {}, "score": "71.25813"}
{"text": "In 11th World Congress on Medical Informatics ( MEDINFO-2004 ) .IOS Press : Amsterdam ; 2004:1 - 8 .Goldin IM , Chapman WW : Learning to Detect Negation with ' Not ' in Medical Texts .In ACM - SIGIR 2003 .", "label": "", "metadata": {}, "score": "71.27202"}
{"text": "In 2000 , the UMLS Metathesaurus [ 6 ] , a comprehensive resource that specifies and categorizes biomedical concepts , contained 9,416 ambiguous terms , and in 2004 , the number increased to 21,295 , an increase of 126 % within 4 years [ 7 ] .", "label": "", "metadata": {}, "score": "71.276665"}
{"text": "Here , we focus only on the two most common negation cues i.e. , no and not .Deactivators of not : The word not is the most frequent negation cue in the BioScope corpus and accounts for over 41 % of the total negation instances in the corpus .", "label": "", "metadata": {}, "score": "71.31653"}
{"text": "Garten Y , Coulet A , Altman R : Recent progress in automatically extracting information from the pharmacogenomic literature .Pharmacogenomics 2010 , 11 ( 10 ) : 1467 - 1489 .View Article PubMed .Krallinger M : Importance of Negations and Experimental Qualifiers in Biomedical Literature .", "label": "", "metadata": {}, "score": "71.342575"}
{"text": "Acoustic models with 5000 tied states were trained using these trees , and the same data as used by Model 2 .This however did not appear to improve performance .Model 4 : We trained models 6000 state models in a standard fashion , using all Communicator data recorded through April 2000 .", "label": "", "metadata": {}, "score": "71.39483"}
{"text": "Typically , the joint - features that are used to construct Maximum Entropy models exactly mirror those that are used by the naive Bayes model .In particular , a joint - feature is defined for each label , corresponding to w [ label ] , and for each combination of ( simple ) feature and label , corresponding to w [ f , label ] .", "label": "", "metadata": {}, "score": "71.44258"}
{"text": "View Article .Weston J , Watkins C : Multiclass support vector machines .Proceedings of ESANN99 .Copyright .\u00a9 Xu et al .2006 .This article is published under license to BioMed Central Ltd. our model requires only a single vector per character type and a fixed set of parameters for the compositional model .", "label": "", "metadata": {}, "score": "71.47296"}
{"text": "Similarly , the bio - entities are normally also assigned types / classes from a chosen taxonomy / ontology , e.g. , the Gene Ontology [ 24 ] .The template of a bio - event can also contain additional slots , e.g. , to denote temporal and spatial attributes .", "label": "", "metadata": {}, "score": "71.48851"}
{"text": "The contextual polarity of a word is more dynamic , and depends on the context of the text fragment containing the word .The contextual polarity can be different from the lexical polarity , and this difference is the key source of ambiguity in determining whether a word or phrase constitutes a negation cue .", "label": "", "metadata": {}, "score": "71.53188"}
{"text": "There 's also a significant difference in the file size of the pickled taggers ( trained on treebank ) : .Fin .I think there 's a lot of room for experimentation with classifier based taggers and their feature detectors .", "label": "", "metadata": {}, "score": "71.5596"}
{"text": "Classification is the task of choosing the correct class label for a given input .In basic classification tasks , each input is considered in isolation from all other inputs , and the set of labels is defined in advance .Some examples of classification tasks are : .", "label": "", "metadata": {}, "score": "71.57527"}
{"text": "import math def entropy ( labels ) : .Once we have calculated the entropy of the original set of input values ' labels , we can determine how much more organized the labels become once we apply the decision stump .", "label": "", "metadata": {}, "score": "71.57843"}
{"text": "For PCA , the estimated distribution was ( 0.67 , 0.33 ) .Four different sample sizes were used ( 20 , 40 , 80 and 120 ) , and for each , a proportional sample for each sense was obtained based on the particular distribution .", "label": "", "metadata": {}, "score": "71.62601"}
{"text": "All the words in the title and abstract of the articles were used as features for machine learning and an SVM algorithm was used to generate a classifier .We used a package called \" Spider \" [ 46 ] to perform all the SVM training and testing .", "label": "", "metadata": {}, "score": "71.63689"}
{"text": "Performance ( F - score ) of chunkers and their combination trained on subsets of different size of the GENIA GSC and on the GSC subset supplemented with an SSC , for noun - phrase and verb - phrase recognition .Discussion .", "label": "", "metadata": {}, "score": "71.66806"}
{"text": "According to the GENIA Event annotation scheme , this sentence contains a single bio - event , anchored to the verb activates .Figure 1 shows the structured representation of this bio - event .Typical structured representation of the bio - event contained in the above sentence .", "label": "", "metadata": {}, "score": "71.79735"}
{"text": "MM and CF conceived of the study , and participated in its design and coordination and helped to draft the manuscript .MM also performed statistical analysis and interpreted the results .HL advised in the design of study .All authors read and approved the final manuscript .", "label": "", "metadata": {}, "score": "71.81183"}
{"text": "It 's important to understand what we can learn about language from an automatically constructed model .One important consideration when dealing with models of language is the distinction between descriptive models and explanatory models .Descriptive models capture patterns in the data but they do n't provide any information about why the data contains those patterns .", "label": "", "metadata": {}, "score": "71.827194"}
{"text": "The final hypothesis combination uses word - level confidence scores based on an N - best homogeneity measure .These are used with the NIST ROVER program [ 1 ] to produce the final output .We first compared the effect of using the additional training data in the BNtrain98 set .", "label": "", "metadata": {}, "score": "71.85178"}
{"text": "There is a 6 % gain from employing the category trigram and 4-gram over the trigram alone , and a 7 % gain moving from adapted triphones to adapted quinphones : most of which ( 5 % ) was due to the full variance adaptation .", "label": "", "metadata": {}, "score": "71.92473"}
{"text": "1471 - 2105 - 7 - 334-S1.doc Additional File 1 : Supplementary material for gene ambiguity for mining MEDLINE ( DOC 925 KB ) .Authors ' contributions .HX carried out data collection , programming , experiments using SVM and drafted the manuscript .", "label": "", "metadata": {}, "score": "71.93238"}
{"text": "Similarly , using quinphone models with MLLR a gain of 0.5 % in WER was achieved with increased training data .We also did some experiments that used automatic segmentation of the extended training data to try and ensure that the segments used in training were acoustically homogeneous but this provided no additional improvements .", "label": "", "metadata": {}, "score": "71.95824"}
{"text": "Select only the instances where inst.attachment is N : .Using this sub - corpus , build a classifier that attempts to predict which preposition is used to connect a given pair of nouns .For example , given the pair of nouns \" team \" and \" researchers , \" the classifier should predict the preposition \" of \" .", "label": "", "metadata": {}, "score": "71.97256"}
{"text": "View Article .Carpenter B : LingPipe for 99.99 % recall of gene mentions .Proceedings of the Second BioCreative Challenge Evaluation Workshop ; Valencia 2007 , 307 - 309 .Aronson AR : Effective mapping of biomedical text to the UMLS Metathesaurus : the MetaMap program .", "label": "", "metadata": {}, "score": "71.99329"}
{"text": "WRB .Unknown Words in CoNLL2000 .The conll2000 corpus has 0 words tagged with -NONE- , yet the default tagger is unable to identify 50 unique words .Here 's a sample : boiler - room , so - so , Coca - Cola , top-10 , AC&R , F-16 , I-880 , R2-D2 , mid-1992 .", "label": "", "metadata": {}, "score": "72.01883"}
{"text": "Proc of the 2003 Conference on Empirical Methods in Natural Language Processing ; Sapporo , Japan 2003 , 176 - 183 .6 - 7 July 2002 .Mikheev A , Moens M , Grover C : Named Entity Recognition Without Gazetteers .", "label": "", "metadata": {}, "score": "72.02409"}
{"text": "PyConWhat would you want to learn in 3 hours?What kinds of NLP problems do you face at work?What do you want to do with text ?Abstract .Background .Negation occurs frequently in scientific literature , especially in biomedical literature .", "label": "", "metadata": {}, "score": "72.0916"}
{"text": "Della Pietra S , Della Pietra V , Lafferty J : Inducing features of random fields .IEEE Transactions Pattern Analysis and Machine Intelligence 1997 , 19 : 380 - 393 .View Article .McCallum A : Efficiently Inducing Features of Conditional Random Fields .", "label": "", "metadata": {}, "score": "72.147484"}
{"text": "At that point , we can use the test set to evaluate how well our model will perform on new input values . 1.3 Document Classification .In 1 , we saw several examples of corpora where documents have been labeled with categories .", "label": "", "metadata": {}, "score": "72.166725"}
{"text": "The features were engineered from the cCore cue list .We chose the cCore cue list because it had performed consistently on all three datasets .Table 6 shows the results for each dataset .The key findings are as follows : . C4.5 performed consistently ( in terms of F - score ) on all three datasets .", "label": "", "metadata": {}, "score": "72.23711"}
{"text": "Multiple comparisons , adjusted for multiple testing , indicated that when the overall significance level is 0.1 , the sense distributions ( 0.5 , 0.5 ) and ( 0.6 , 0.4 ) impact the error rate .These results show that almost balanced sense distributions and rather large training sample sizes reduce the error rate to approximately half of our best guess , which is using the majority sense .", "label": "", "metadata": {}, "score": "72.30159"}
{"text": "Find a translation for the Victory definition in other languages : .Affiliated with .Affiliated with .Abstract .Background .Good automatic information extraction tools offer hope for automatic processing of the exploding biomedical literature , and successful named entity recognition is a key component for such tools .", "label": "", "metadata": {}, "score": "72.32645"}
{"text": "The listing in 2.1 shows how this can be done . def segment_sentences ( words ) : . sents.append(words[start:i+1 ] ) . sents.append(words[start : ] ) .return sents . 2.2 Identifying Dialogue Act Types .When processing dialogue , it can be useful to think of utterances as a type of action performed by the speaker .", "label": "", "metadata": {}, "score": "72.37125"}
{"text": "Bio - event annotation is information - centred and depends entirely on biologists ' conception of the relationship between an event , its participants and other events expressed in the text .The event - trigger and participants of an event are each mapped to a span of text .", "label": "", "metadata": {}, "score": "72.474625"}
{"text": "Results for BSA data set .Annotation of the table : Dist : Distribution of senses ; S. Size : sample size ; Err .Rate : Error Rate ; SE : Standard Error of error rates ; CV : cross - validation ; .", "label": "", "metadata": {}, "score": "72.54178"}
{"text": "These posts have all been labeled with one of 15 dialogue act types , such as \" Statement , \" \" Emotion , \" \" ynQuestion \" , and \" Continuer .\" We can therefore use this data to build a classifier that can identify the dialogue act types for new instant messaging posts .", "label": "", "metadata": {}, "score": "72.55325"}
{"text": "Hall M , Frank E , Holmes G , Pfahringer B , Reutemann P , Witten IH : The WEKA data mining software : an update .SIGKDD Explorations 2009 , 11 ( 1 ) : 10 - 18 .View Article .", "label": "", "metadata": {}, "score": "72.60664"}
{"text": "Nat Biotechnol 2008 , 26 ( 9 ) : 1011 - 1013 .View Article PubMed .Breiman L : Random forests .Mach Learn 2001 , 45 ( 1 ) : 5 - 32 .View Article .Chen X - W , Liu M : Prediction of protein - protein interactions using random decision forest framework .", "label": "", "metadata": {}, "score": "72.62781"}
{"text": "No assumptions are made about the original distribution ( e.g. normal vs. other ) of the documents .Analysis of variance models are versatile statistical tools for studying the relation between error rates and sense distribution , sample size , and degree of difficulty of a task .", "label": "", "metadata": {}, "score": "72.78896"}
{"text": "Experiments with no adaptation ( or cluster - based normalisation ) showed that the word error rate ( WER ) was reduced by up to 0.9 % absolute .However when MLLR adaptation and VTLN were applied ( see below ) the WER gain was reduced to 0.4 % absolute .", "label": "", "metadata": {}, "score": "72.808136"}
{"text": "FNs also occurred in some coordinated NPs where the modifier was attached to only one of the phrases but modified all of the coordinated members .Abbreviations , expansions , and names in parentheses were also frequent causes of FNs .The single largest source of error was mistaken boundaries ( 37 % of FP and 39 % of FN ) .", "label": "", "metadata": {}, "score": "72.814224"}
{"text": "Cohen KB , Hunter L , Troyanskaya O : Getting started in text mining .PLoS Comput Biol 2008 , 4 ( 1 ) : e20 .View Article PubMed .Zweigenbaum P , Demner - Fushman D , Yu H , Cohen KB : Frontiers of biomedical text mining : current progress .", "label": "", "metadata": {}, "score": "72.86913"}
{"text": "IEEE Workshop on Automatic Speech Recognition and Understanding , pp .347 - 354 , Santa Barbara .the defeat of an enemy in battle , or of an antagonist in any contest ; a gaining of the superiority in any struggle or competition ; conquest ; triumph ; -- the opposite of defeat .", "label": "", "metadata": {}, "score": "72.88283"}
{"text": "Pacific Symposium on Biocomputing , Kauai 2003 .Brants T : TnT - A Statistical Part - of - Speech Tagger .ANLP 6 2000 , 224 - 231 .Ohta T , Tateisi Y , Mima H , Tsujii J : GENIA Corpus : an Annotated Research Abstract Corpus in Molecular Biology Domain .", "label": "", "metadata": {}, "score": "73.036255"}
{"text": "View Article PubMed .Friedman M : The use of ranks to avoid the assumption of normality implicit in the analysis of variance .Journal of the American Statistical Association 1937 , 32 : 675 - 701 .View Article .Rifkin R , Klatau A : In defense of one - vs - all classification .", "label": "", "metadata": {}, "score": "73.07579"}
{"text": "This situation has naturally led to an interest in automated techniques for problems such as topic classification , word sense disambiguation , and tokenization in the biomedical domain ( cf .MEDLINE 's Indexing Initiative [ 1 ] ) .In this paper we focus on the particular problem of Named Entity Recognition ( NER ) which requires the identification of names corresponding to shallow semantic categories .", "label": "", "metadata": {}, "score": "73.09462"}
{"text": "The naive Bayes classification method , which we 'll discuss next , overcomes this limitation by allowing all features to act \" in parallel . \"5 Naive Bayes Classifiers .In naive Bayes classifiers , every feature gets a say in determining which label should be assigned to a given input value .", "label": "", "metadata": {}, "score": "73.11184"}
{"text": "Relationship between the negation cues and event - types .We investigated the relationship between negation cues and different types of bio - events .Our analysis revealed two classes of negation cues with respect to event - types .These are : .", "label": "", "metadata": {}, "score": "73.12719"}
{"text": "In particular , entropy is defined as the sum of the probability of each label times the log probability of that same label : .Figure 4.2 : The entropy of labels in the name gender prediction task , as a function of the percentage of names in a given set that are male .", "label": "", "metadata": {}, "score": "73.2787"}
{"text": "Indicators of low manner have historically been treated as negation cues .In the field of sentiment analysis , such indicators have been considered as a special class of negative polarity indicators .Wiegand et al .[53 ] refer to this class of cues as diminishers , while Wilson et al .", "label": "", "metadata": {}, "score": "73.286255"}
{"text": "Dietterich TG : Approximate statistical tests for comparing supervised classification learning algorithms .Neural Computation 1998 , 10 : 1895 - 1924 .View Article PubMed .Salzberg SL : On comparing classifiers : Pitfalls to avoid and a recommended approach .", "label": "", "metadata": {}, "score": "73.32721"}
{"text": "How can we identify particular features of language data that are salient for classifying it ?How can we construct models of language that can be used to perform language processing tasks automatically ?What can we learn about language from these models ?", "label": "", "metadata": {}, "score": "73.427284"}
{"text": "Named entity recognition is generally considered more difficult than chunking , having to deal with increased complexities in boundary recognition , disambiguation , and spelling variation of entities .Clearly , the better a silver standard will approach a gold standard for the domain of interest , the better the performance of systems trained on an SSC .", "label": "", "metadata": {}, "score": "73.55727"}
{"text": "This is the second most prevalent type in GENIA Event and the third most prevalent in BioInfer and BioNLP'09 ST .The frequency of negated trigger events ranges between 61 % and 67 % in the three corpora , with a micro average of 63 % .", "label": "", "metadata": {}, "score": "73.57422"}
{"text": "It is useful for testing whether one random variable in a pair tends to have larger ( smaller or simply different ) values than the other random variable in the pair .In our case , the random variables in the pair are the error rates obtained under the different sample sizes used .", "label": "", "metadata": {}, "score": "73.587875"}
{"text": "Note that if most input values have the same label ( e.g. , if P(male ) is near 0 or near 1 ) , then entropy is low .In particular , labels that have low frequency do not contribute much to the entropy ( since P(l ) is small ) , and labels with high frequency also do not contribute much to the entropy ( since log 2", "label": "", "metadata": {}, "score": "73.60081"}
{"text": "For example , a sample testing set with size 20 and sense distribution ( 0.5 , 0.5 ) means 10 samples in the set are with one sense and the other 10 samples are with the other sense .The estimated sense distribution is listed in the last column of Table 1 , which is calculated based on the number of retrieved articles for each sense and the number of retrieved articles for all the senses .", "label": "", "metadata": {}, "score": "73.62311"}
{"text": "This process is illustrated in 5.2 and 5.3 .Figure 5.2 : Calculating label likelihoods with naive Bayes .Naive Bayes begins by calculating the prior probability of each label , based on how frequently each label occurs in the training data .", "label": "", "metadata": {}, "score": "73.745544"}
{"text": "This was mainly because most biomedical research has been focussed around the publication and analysis of positive results [ 17 ] .However , over the past decade , there has been a growing interest in negative results , for example : .", "label": "", "metadata": {}, "score": "73.75334"}
{"text": "return features .Example 1.2 ( code_gender_features_overfitting .py ) : Figure 1.2 : A Feature Extractor that Overfits Gender Features .The feature sets returned by this feature extractor contain a large number of specific features , leading to overfitting for the relatively small Names Corpus .", "label": "", "metadata": {}, "score": "73.76656"}
{"text": "In the original algorithm unit types are simple phones , but in this limited domain synthesizer we constrain this further by defining types as phones plus the word that phone came from .This apparently severe constraint allows the system to produce near perfect synthesis as the phones it selects always come from an instance of the word that is to be synthesized .", "label": "", "metadata": {}, "score": "73.77693"}
{"text": "View Article .Councill IG , McDonald R , Velikovich L : What 's Great and What 's Not : Learning to Classify the Scope of Negation for Improved Sentiment Analysis .In Workshop on Negation and Speculation in Natural Language Processing ( NeSp - NLP 2010 ) , ACL 2010 .", "label": "", "metadata": {}, "score": "73.77984"}
{"text": "The full - form in the title or abstract of the article was then replaced with the ambiguous abbreviation , and the appropriate sense was noted separately .Table 1 shows the number of articles that were obtained for the different abbreviations and senses .", "label": "", "metadata": {}, "score": "73.784256"}
{"text": "Using the cBioInfer cue list caused a significant performance drop on GENIA Event and BioNLP'09 ST ( by almost 5 % and 8 % , respectively ) , compared to when c40 and cCore were used .However , as expected , it resulted in the best performance on BioInfer by a fair margin ( over 7 % ) .", "label": "", "metadata": {}, "score": "73.84538"}
{"text": "This transcription is used for both gender selection as well as VTLN warp selection for each segment cluster .Gender dependent VTLN models are then used ( P2 ) to provide a revised transcription which is used to estimate global mean and variance MLLR transforms for each cluster .", "label": "", "metadata": {}, "score": "73.88083"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" for BSA , RSV and PCA data sets with fixed distribution of \" ( 0.5 , 0.5 ) \" using 5-fold cross validation .Discussion .", "label": "", "metadata": {}, "score": "73.94939"}
{"text": "View Article PubMed .Rzhetsky A , Iossifov I , Koike T , Krauthammer M , Kra P , Morris M , Yu H , Dubou\u00e9 PA , Weng W , Wilbur WJ : GeneWays : a system for extracting , analyzing , visualizing , and integrating molecular pathway data .", "label": "", "metadata": {}, "score": "73.99704"}
{"text": "Cases of adjacent named entities are sufficiently rare that it is hard to do well on them ; we maximized performance by making the system unable to represent this situation .Features - closed section .The features described here were used in both the closed and open sections .", "label": "", "metadata": {}, "score": "74.01274"}
{"text": "Table 4 : % WER on BNeval97 for different trigram LMs with VTLN unadapted triphone HMMs with either pooled data or ( merged ) interpolated LMs .The effect of using three different LMs on BNeval97 with VTLN data and 1998 unadapted triphone HMMs is shown in Table 4 .", "label": "", "metadata": {}, "score": "74.016815"}
{"text": "But there 's a lot to be learned from taking a closer look at how these learning methods select models based on the data in a training set .An understanding of these methods can help guide our selection of appropriate features , and especially our decisions about how those features should be encoded .", "label": "", "metadata": {}, "score": "74.038864"}
{"text": "The same study , which was also performed for the Fly organism , showed similar results , but with slightly higher ambiguity rates .This study shows that the ambiguity among gene symbols , English words and other biomedical terms is extensive and the distribution of ambiguity is very sparse .", "label": "", "metadata": {}, "score": "74.165825"}
{"text": "You can rearrange ubt any way you want to change the order of the taggers ( though ubt is generally the most accurate order ) .Training Affix Taggers .The --sequential argument also recognizes the letter a , which will insert an AffixTagger into the backoff chain .", "label": "", "metadata": {}, "score": "74.2668"}
{"text": "We found that many of our errors stemmed from gene boundaries ( 37 % of false positives and 39 % of false negatives ) and addressed this issue in several ways .Boundary errors were often due to mismatched parentheses ; the parentheses - matching feature described above did not eliminate these errors due to ( generally erroneous ) instances in the training data which contained mismatched parentheses .", "label": "", "metadata": {}, "score": "74.28364"}
{"text": "Features Used Description of the Full Feature Set Used In the Closed Section Submission .A feature that signals when one parentheses in a pair has been assigned a different tag than the other in a window of 4 words .Features - open section .", "label": "", "metadata": {}, "score": "74.29712"}
{"text": "When the senses are well separated , any increase in the sample size results in a statistically significant decrease of the error rate .This holds for all sense distributions and it is in agreement with the finding that for BSA there was no significant effect of the sense distributions on the error rates for the different sample sizes used .", "label": "", "metadata": {}, "score": "74.38066"}
{"text": "Although it 's often possible to get decent performance by using a fairly simple and obvious set of features , there are usually significant gains to be had by using carefully constructed features based on a thorough understanding of the task at hand .", "label": "", "metadata": {}, "score": "74.39463"}
{"text": "The range of sample size per sense ranges from 10 - 40 , with increments of 10 per sense .Average error rates ( Err .Rate ) and average standard errors ( SE ) were reported for each combination of distribution and sample size ( see Methods section ) .", "label": "", "metadata": {}, "score": "74.40932"}
{"text": "Although we have focussed on the identification of negated bio - events , our approach can be modified straightforwardly for events in other textual domains .We also plan to explore this further .Declarations .Acknowledgements .The work described in this paper has been funded by the Biotechnology and Biological Sciences Research Council ( grant numbers BBS / B/13640 , BB / F006039/1 ( ONDEX ) ) through the MetaNet4U project ( ICT PSP Programme , Grant Agreement : No 270893 ) .", "label": "", "metadata": {}, "score": "74.44078"}
{"text": "All authors read and approved the manuscript .Authors ' Affiliations .Department of Medical Informatics , Erasmus University Medical Center .References .Polikar R : Ensemble based systems in decision making .IEEE Circuit Syst Mag 2006 , 6 : 21 - 45 .", "label": "", "metadata": {}, "score": "74.466324"}
{"text": "Train a Sentiment Classifier$ . pickle .Notable Included Corporamovie_reviews : pos & neg categorized IMDb reviewstreebank : tagged and parsed WSJ texttreebank_chunk : tagged and chunked WSJ textbrown : tagged & categorized english text60 other corpora in many languages .Other NLTK FeaturesclusteringmetricsparsingstemmingWordNet ... and a lot more .", "label": "", "metadata": {}, "score": "74.48059"}
{"text": "As the Friedman 's test indicated , the effect of the sense distribution on the error rate is significant .When the sense distribution is ( 0.5 , 0.5 ) there are statistically significant differences between the pairs of error rates produced under sample size ( 20 and 120 ) , the sample sizes ( 40 and 120 ) and the sample sizes ( 80 and 120 ) .", "label": "", "metadata": {}, "score": "74.49656"}
{"text": "We had expected more value from extra data sources , but it may well be that they are difficult to exploit effectively because of subtly different decisions about what does and does not count as a named entity to be tagged .", "label": "", "metadata": {}, "score": "74.524185"}
{"text": "10 Exercises .Find out what type and quantity of annotated data is required for developing such systems .Why do you think a large amount of data is required ?Begin by splitting the Names Corpus into three subsets : 500 words for the test set , 500 words for the dev - test set , and the remaining 6900 words for the training set .", "label": "", "metadata": {}, "score": "74.65242"}
{"text": "NER is an important component for more complex information extraction tasks such as automatic extraction of protein - protein interaction information .We present a system based on a maximum - entropy sequence tagger which achieved state - of - the - art performance in the BioCreative comparative evaluation .", "label": "", "metadata": {}, "score": "74.71176"}
{"text": "Tolentino H , Matters M , Walop W , Law B , Tong W , Liu F , Fontelo P , Kohl K , Payne D : Concept Negation in Free Text Components of Vaccine Safety Reports .In AMIA Annual Symposium .", "label": "", "metadata": {}, "score": "74.727394"}
{"text": "It 's common to start with a \" kitchen sink \" approach , including all the features that you can think of , and then checking to see which features actually are helpful .We take this approach for name gender features in 1.2 .", "label": "", "metadata": {}, "score": "74.8665"}
{"text": "Tables 2 , 3 and 4 display the results for BSA , PCA and RSV , each of which has two senses .The distribution shown with bold font in column 1 is the estimated distribution of the senses , which is calculated based on the number of retrieved articles for each sense and the number of retrieved articles for all the senses .", "label": "", "metadata": {}, "score": "74.87286"}
{"text": "The explicit negation cue not modifies the phrase in monocytic or epithelial cells .This phrase contains the location for E2 , E3 , E5 and E6 , making these events negated .Bio - event example with negated attribute ( Source : BioNLP ST Corpus ; PMID : 10022882 ) .", "label": "", "metadata": {}, "score": "74.91603"}
{"text": "For all other sense distributions , an increase in the sample size did not produce a significant reduction in the error rate - that is , there are no statistically significant differences between the error rates .We would like to stress here a limitation of the current study .", "label": "", "metadata": {}, "score": "75.08711"}
{"text": "Classifiers can help us to understand the linguistic patterns that occur in natural language , by allowing us to create explicit models that capture those patterns .Typically , these models are using supervised classification techniques , but it is also possible to build analytically motivated models .", "label": "", "metadata": {}, "score": "75.142105"}
{"text": "A phrase annotated by the gold standard was counted as false negative if the system did not render it exactly ; a phrase annotated by a system was counted as false positive if it did not exactly match the gold standard .", "label": "", "metadata": {}, "score": "75.21956"}
{"text": "In our study , we proposed a simple \" full - term substitution \" method , which is described in more detail in the Methods section , to automatically generate training data , but this is only applicable for abbreviations .In this study , we used a \" full - form substitution \" method to automatically generate the data set for the experiments , which is an artificial training set .", "label": "", "metadata": {}, "score": "75.25101"}
{"text": "The --double - metaphone algorithm comes from metaphone.py , while all the other phonetic algorithm have been copied from the advas project ( which appears to be abandoned ) .I created these options after discussions with Michael D Healy about Twitter Linguistics , in which he explained the prevalence of regional spelling variations .", "label": "", "metadata": {}, "score": "75.25542"}
{"text": "For some research I 'm doing with Michael D. Healy , I need to measure part - of - speech tagger coverage and performance .To that end , I 've added a new script to nltk - trainer : analyze_tagger_coverage.py .", "label": "", "metadata": {}, "score": "75.2668"}
{"text": "Figure 11 shows the micro - averaged results for each cue list .Algorithm comparison .In order to compare the performance of the chosen learning algorithms for the task of identifying negated bio - events , we ran a series of experiments on each dataset .", "label": "", "metadata": {}, "score": "75.34454"}
{"text": "Figures 1 , 2 and 3 show the error rate versus the sample size for each distribution of the BSA , PCA and RSV data sets with 5-fold cross - validation .As the figures indicate , the reduction of the error rate as a function of the sample size is more dramatic for BSA than for PCA .", "label": "", "metadata": {}, "score": "75.38778"}
{"text": "Huang Y , Lowe HJ : A novel hybrid approach to automated negation detection in clinical radiology reports .J Am Med Inform Assoc 2007 , 14 ( 3 ) : 304 - 311 .View Article PubMed .Sanchez - Graillet O , Poesio M : Negation of protein - protein interactions : analysis and extraction .", "label": "", "metadata": {}, "score": "75.394455"}
{"text": "Here , tokens is a merged list of tokens from the individual sentences , and boundaries is a set containing the indexes of all sentence - boundary tokens .Next , we need to specify the features of the data that will be used in order to decide whether punctuation indicates a sentence - boundary : . isupper ( ) , ... ' prev - word ' :", "label": "", "metadata": {}, "score": "75.44731"}
{"text": "If you do want to backoff to a sequential tagger , be sure to specify a cutoff probability , like so : . python train_tagger.py treebank --sequential ubt --classifier NaiveBayes --cutoff_prob 0.4 .Any of the NLTK classification algorithms can be used for the --classifier argument , such as Maxent or MEGAM , and every algorithm other than NaiveBayes has specific training options that can be customized .", "label": "", "metadata": {}, "score": "75.61409"}
{"text": "Ginter F , Boberg J , Salakoski T , Salakoski T : New Techniques for Disambiguation in Natural Language and Their Application to Biological Text .Journal of Machine Learning Research 2004 , 5 : 605 - 621 .Podowski RM , Cleary JG , Goncharoff NT , Amoutzias G , Hayes WS : AZuRE , a scalable system for automated term disambiguation of gene and protein names .", "label": "", "metadata": {}, "score": "75.783356"}
{"text": "We will call xml_posts ( ) to get a data structure representing the XML annotation for each post : .Next , we 'll define a simple feature extractor that checks what words the post contains : .Finally , we construct the training and testing data by applying the feature extractor to each post ( using post.get ( ' class ' ) to get a post 's dialogue act type ) , and create a new classifier : . 2.3 Recognizing Textual Entailment .", "label": "", "metadata": {}, "score": "75.7921"}
{"text": "To check how reliable the resulting classifier is , we compute its accuracy on the test set .And once again , we can use show_most_informative_features ( ) to find out which features the classifier found to be most informative . 1.4 Part - of - Speech Tagging .", "label": "", "metadata": {}, "score": "75.851746"}
{"text": "The transform result is either stored in a product structure ( for this domain , an itinerary ) or an immediate action taken ( for example , notifying the user of an error ) .ACOUSTIC MODELLING .It is our belief that optimal recognition performance can be obtained most readily using domain - specific data .", "label": "", "metadata": {}, "score": "75.88655"}
{"text": "Nucleic Acids Res 2010 , 38 : 540 - 544 .View Article .Ceusters W , Elkin P , Smith B : Negative findings in electronic health records and biomedical ontologies : a realist approach .Int J Med Inform 2007 , 76 ( 3 ) : 326 - 333 .", "label": "", "metadata": {}, "score": "75.9386"}
{"text": "Huang and Lowe [ 37 ] proposed a classification of negations found in medical reports .Their classification was based on the syntactic category of the negation signal and phrase patterns .They identified 4 syntactic categories of negation signals : adjective - like ( such as no , absent and without ) , adverb ( such as not ) , verb ( such as deny ) and noun ( such as absence ) .", "label": "", "metadata": {}, "score": "76.03136"}
{"text": "The parse result is treated as a set of concepts that individual handlers on the agenda consume .Once matched , the concepts are either used directly ( i.e. , to set a target value ) or are first transformed through a call to a domain agent .", "label": "", "metadata": {}, "score": "76.04103"}
{"text": "Performance ( F - score ) of chunkers and their combination when trained for noun - phrase and verb - phrase recognition on different training sets .Silver standard as supplement of gold standard .Table 2 shows the performances of chunkers and the combined system when trained on GSCs of varying sizes and on the GSCs supplemented with an SSC .", "label": "", "metadata": {}, "score": "76.06283"}
{"text": "Obviously , to create the SSC we need trained chunkers , and thus a GSC for their initially training .We explored the use of a GSC from another , but related , domain than the domain of interest .Alternatively , we supplemented a GSC with an SSC in the same domain of interest .", "label": "", "metadata": {}, "score": "76.1408"}
{"text": "Each event belongs to one of the 4 classes from the Gene Regulation Ontology .BioNLP'09 ST ( Shared Task ) : The BioNLP'09 ST Corpus [ 29 ] contains 950 MEDLINE abstracts .This corpus contains two subsets : the Development subset , comprising 150 abstracts and the Training subset , comprising 800 abstracts .", "label": "", "metadata": {}, "score": "76.24863"}
{"text": "One of the first attempts at classifying negation in natural language was made by Aristotle .In terms of more recent work , Tottie [ 13 ] presented a taxonomy of clausal negations in English .She identified 6 top - level categories of clausal negation : denials , rejections , imperatives , questions , supports and repetitions .", "label": "", "metadata": {}, "score": "76.38376"}
{"text": "Further investigations will have to reveal how the quality of an SSC affects classifier performance and whether the use of SSCs in other application areas is equally advantageous as their use in text chunking .Conclusions .We have shown that an automatically created SSC can be a viable alternative for or a supplement to a GSC when training chunkers in a biomedical domain .", "label": "", "metadata": {}, "score": "76.4212"}
{"text": "Chunking is a natural language processing technique that splits text into groups of words that constitute a grammatical unit , e.g. , a noun phrase or a verb phrase .It is an important processing step in systems that try to automatically extract information from text .", "label": "", "metadata": {}, "score": "76.472176"}
{"text": "In particular , we notice that when the sense distribution ( P1 , P2 ) was very unbalanced ( i.e. 0.9 , 0.1 ) , then the error rate was almost equal to the minority sense proportion .All these findings indicate that the effectiveness of an increase in the sample size is very dependent on the degree of difficulty .", "label": "", "metadata": {}, "score": "76.55252"}
{"text": "Inherently negative bio - event example ( Source : GENIA Event Corpus ; PMID : 9427533 ) .Negated event - trigger .In this category , an explicit negation cue modifies the event - trigger .For example , consider the sentence shown in Figure 4 .", "label": "", "metadata": {}, "score": "76.60042"}
{"text": "Instance - Based Algorithms : Instance - Based ( also known as Memory - Based ) learning algorithms do not derive generalisations or abstractions from the complete training data .Rather , they keep all training data in memory , and generate classification predictions using only the most similar training instances .", "label": "", "metadata": {}, "score": "76.80349"}
{"text": "The methodology is easy to apply , it provides a principled way of studying the effects of the different factors on the error rate , and since it is based on a strong theoretical foundation , it guarantees that the results to apply to all abbreviations with similar characteristics .", "label": "", "metadata": {}, "score": "76.85687"}
{"text": "Conclusion .In this paper , we aimed to further an understanding of the different factors affecting the performance of ML techniques for WSD by systematically simulating a variety of situations where different sample size , sense distribution , degree of difficulty , and cross validation methods were used .", "label": "", "metadata": {}, "score": "76.86946"}
{"text": "The system understands about 500 destinations worldwide , chosen on the basis of passenger statistics , with a concentration on North America .Figure 1 Percent of training corpus account for by individual talkers .The system uses the Sphinx II decoder in a real - time mode , with post - recognition barge - in ; state - specific language models are used to improve recognition [ 10 ] .", "label": "", "metadata": {}, "score": "76.893265"}
{"text": "2.1 Sentence Segmentation .Sentence segmentation can be viewed as a classification task for punctuation : whenever we encounter a symbol that could possibly end a sentence , such as a period or a question mark , we have to decide whether it terminates the preceding sentence .", "label": "", "metadata": {}, "score": "77.06583"}
{"text": "Let 's begin by finding out what the most common suffixes are : .Next , we 'll define a feature extractor function which checks a given word for these suffixes : . endswith(suffix ) ... return features .Feature extraction functions behave like tinted glasses , highlighting some of the properties ( colors ) in our data and making it impossible to see other properties .", "label": "", "metadata": {}, "score": "77.26398"}
{"text": "[ What , \" s \" , up , ? ][ What , \" \" , s , up , ? ] Why Part - of - Speech Tag?word definition lookup ( WordNet , WordNik)fine - grained text analyticspart - of - speech specific keyword analysischunking & named entity recognition ( NER ) .", "label": "", "metadata": {}, "score": "77.298874"}
{"text": "Detection of negated bio - events .Identification of negated bio - events was an optional sub - task in the BioNLP'09 Shared Task Challenge [ 29 ] .Six teams participated in this task and reported the first results on the identification of negated bio - events .", "label": "", "metadata": {}, "score": "77.32642"}
{"text": "Of course , we do n't usually build naive Bayes classifiers that contain two identical features .However , we do build classifiers that contain features which are dependent on one another .For example , the features ends - with(a ) and ends - with(vowel ) are dependent on one another , because if an input value has the first feature , then it must also have the second feature .", "label": "", "metadata": {}, "score": "77.33694"}
{"text": "In particular , the identity of the previous word is included as a feature .It is clear that exploiting contextual features improves the performance of our part - of - speech tagger .For example , the classifier learns that a word is likely to be a noun if it comes immediately after the word \" large \" or the word \" gubernatorial \" .", "label": "", "metadata": {}, "score": "77.440765"}
{"text": "The explicit negation cue not modifies the two causes of E2 , i.e. , IFN - alpha and IL-12 .Again , it is important to note that the scope of this cue ( not ) includes neither the trigger for event E2 nor any of its participants .", "label": "", "metadata": {}, "score": "77.51052"}
{"text": "Deactivators of negation cues .The ability of some words to act as negation cues is affected by the syntactic constructions in which they are used .This means that a word that normally acts as a negation cue can cease to act in that capacity if it is preceded and/or followed by certain other words .", "label": "", "metadata": {}, "score": "77.58528"}
{"text": "GREC :The Gene Regulation Event Corpus ( GREC ) [ 27 ] contains 240 MEDLINE abstracts in which 3,067 bio - events have been identified .Each event has a set of arguments , which can include both the event participants and attributes like time , location and manner , etc . .", "label": "", "metadata": {}, "score": "77.64464"}
{"text": "However , you can change this by specifying one or more --affix N options , where N should be a positive number for prefixes , and a negative number for suffixes .For example , to train an aubt tagger with 2 AffixTaggers , one that uses a 3 character suffix , and another that uses a 2 character prefix , specify the --affix argument twice : . python train_tagger.py treebank --sequential aubt --affix -3 --affix 2 .", "label": "", "metadata": {}, "score": "77.65835"}
{"text": "View Article PubMed .Humphrey SM , Rogers WJ , Kilicoglu H , Demner - Fushman D , Rindflesch TC : Word sense disambiguation by selecting the best semantic type based on Journal Descriptor Indexing : Preliminary experiment .Journal of the American Society for Information Science and Technology 2006 , 57 : 96 - 113 .", "label": "", "metadata": {}, "score": "77.66586"}
{"text": "Goryachev S , Sordo M , Zeng QT , Ngo L : Implementation and Evaluation of Four Different Methods of Negation Detection .Boston , MA : DSG ; 2006 .Rokach L , Romano R , Maimon O : Negation recognition in medical narrative reports .", "label": "", "metadata": {}, "score": "77.68629"}
{"text": "In 23rd International Conference on Machine Learning .Association for Computing Machinery ( ACM ) : New York , NY ; 2006:161 - 168 .Miwa M , Saetre R , Kim J - D , Tsujii J : Event extraction with complex event classification using rich features .", "label": "", "metadata": {}, "score": "77.72339"}
{"text": "These features indicate that all important words in the hypothesis are contained in the text , and thus there is some evidence for labeling this as True .The module nltk.classify.rte_classify reaches just over 58 % accuracy on the combined RTE test data using methods like these .", "label": "", "metadata": {}, "score": "77.75087"}
{"text": "def rte_features ( rtepair ) : . return features .Example 2.2 ( code_rte_features . py ) : Figure 2.2 : \" Recognizing Text Entailment \" Feature Extractor .The RTEFeatureExtractor class builds a bag of words for both the text and the hypothesis after throwing away some stopwords , then calculates overlap and difference .", "label": "", "metadata": {}, "score": "77.90138"}
{"text": "Even in cases where our error in the evaluation data was in fact an error , it could not infrequently be traced to a similar error in the training data .In example ( 5 ) we annotated \" human cyclin - dependent kinase \" and were penalized for a FP ; however , our annotation mirrors the pattern of ( 6 ) which appeared in the training data . ... both PC12 and C6 cell nuclear extracts were recruited by the CCAAT - box as a complex containing nuclear factor Y. .", "label": "", "metadata": {}, "score": "78.283134"}
{"text": "Statistical tests [ 39 , 40 ] can be used to compare different classifiers .It is very important that the baseline of a classification task is reported because it shows how much of an improvement there is using a classifier as compared to the baseline .", "label": "", "metadata": {}, "score": "78.30122"}
{"text": "Morante R : Descriptive Analysis of Negation Cues in Biomedical Texts .In Seventh International Language Resources and Evaluation ( LREC 2010 ) .American Medical Informatics Association ( AMIA ) ; 2010:1429 - 1436 .Morante R , Daelemans W : A Metalearning Approach to Processing the Scope of Negation .", "label": "", "metadata": {}, "score": "78.32302"}
{"text": "You might think this can solved with better tokenization , but for words like F-16 and I-880 , tokenizing on the \" - \" would be incorrect .Missing Symbols and Rare Tags .The default tagger apparently does not recognize parentheses or the SYM tag , and has trouble with many of the more rare tags , such as FW , LS , RBS , and UH .", "label": "", "metadata": {}, "score": "78.43996"}
{"text": "View Article PubMed .Miyao Y , Ohta T , Masuda K , Tsuruoka Y , Yoshida K , Ninomiya T , Tsujii J : Semantic Retrieval for the Accurate Identification of Relational Concepts in Massive Textbases .In ACL ' 06 : Proceedings of the 21st", "label": "", "metadata": {}, "score": "78.47215"}
{"text": "The authors declare that they have no competing interests .Authors ' contributions .All authors contributed to the production of the manuscript .RN conceived of and designed the experiments .PT helped with the production of manuscript , and SA supervised all steps of the work .", "label": "", "metadata": {}, "score": "78.486664"}
{"text": "In contrast , explanatory models attempt to capture properties and relationships that cause the linguistic patterns .For example , we might introduce the abstract concept of \" polar verb \" , as one that has an extreme meaning , and categorize some verb like adore and detest as polar .", "label": "", "metadata": {}, "score": "78.51562"}
{"text": "Two ambiguous gene symbol lists were formed as a result of the comparisons : a gene - English list ( containing gene symbols ambiguous with general English words ) and a gene - UMLS list ( containing gene symbols ambiguous with biomedical terms ) .", "label": "", "metadata": {}, "score": "78.62836"}
{"text": "Shatkay H , Feldman R : Mining the biomedical literature in the genomic era : an overview .J Comput Biol 2003 , 10 : 821 - 855 .View Article PubMed .Fukuda K , Tamura A , Tsunoda T , Takagi T : Toward information extraction : identifying protein names from biological papers .", "label": "", "metadata": {}, "score": "78.74303"}
{"text": "5.4 The Naivete of Independence .The reason that naive Bayes classifiers are called \" naive \" is that it 's unreasonable to assume that all features are independent of one another ( given the label ) .In particular , almost all real - world problems contain features with varying degrees of dependence on one another .", "label": "", "metadata": {}, "score": "78.82406"}
{"text": "Na\u00efve Bayes : Na\u00efve Bayes is one of the simplest probabilistic classification algorithms .It uses the Bayes probability model for predicting the class probabilities of inputs .The word na\u00efve indicates that the algorithm assumes class conditional independence , i.e. , it assumes that the effect of a variable value on a given class is independent of the values of other variables [ 61 ] .", "label": "", "metadata": {}, "score": "78.90082"}
{"text": "For the details of the ambiguity study , please refer to the sub - section \" Gene Ambiguity for mining MEDLINE \" in the Methods section .Research in automated WSD can be traced back to the 1950s [ 15 ] .", "label": "", "metadata": {}, "score": "78.93265"}
{"text": "Make use of this fact to build a consecutive classifier for labeling dialog acts .Be sure to consider what features might be useful .See the code for the consecutive classifier for part - of - speech tags in 1.7 to get some ideas .", "label": "", "metadata": {}, "score": "79.06441"}
{"text": "Chen L , Liu H , Friedman C : Gene name ambiguity of eukaryotic nomenclatures .Bioinformatics 2005 , 21 : 248 - 256 .View Article PubMed .Schuemie MJ , Weeber M , Schijvenaars BJA , van Mulligen EM , van der Eijk CC , Jelier R , et al .", "label": "", "metadata": {}, "score": "79.29198"}
{"text": "View Article PubMed .Qi Y , Klein - Seetharaman J , Bar - Joseph Z : Random Forest Similarity for Protein - Protein Interaction Prediction from Multiple Sources .In Pacific Symposium on Biocomputing .Stanford , CA : Stanford University ; 2005:531 - 542 .", "label": "", "metadata": {}, "score": "79.4006"}
{"text": "Data set for experiments .Four abbreviations were used in the experiments .Table 1 lists the detailed information about the abbreviations and their senses .These abbreviations were originally specified in the ABBR data set [ 8 ] .We chose them by considering the different levels of semantic similarity among their senses .", "label": "", "metadata": {}, "score": "79.57045"}
{"text": "We found an overall improvement in WER with cluster - based variance normalisation of 0.3 % absolute and a further 0.6 % absolute by applying VTLN in both training and testing without adaptation .However with mean and variance MLLR adaptation the separate beneficial effect of variance normalisation and VTLN is much reduced .", "label": "", "metadata": {}, "score": "79.58605"}
{"text": "Hand DJ : Construction and assessment of classification rules Chichester , England : John Wiley & Sons 1997 .Hand DJ : Assessing Classification Rules .Journal of Applied Statistics 1994 , 21 : 3 - 16 .View Article .Fukunaga K , Hayes RR : Effect of sample size in classifier design .", "label": "", "metadata": {}, "score": "79.67807"}
{"text": "Precision , which indicates how many of the items that we identified were relevant , is TP/(TP+FP ) .Recall , which indicates how many of the relevant items that we identified , is TP/(TP+FN ) .The F - Measure ( or F - Score ) , which combines the precision and recall to give a single score , is defined to be the harmonic mean of the precision and recall : ( 2 \u00d7 Precision \u00d7 Recall ) / ( Precision + Recall ) .", "label": "", "metadata": {}, "score": "79.92345"}
{"text": "We computed the standard deviation of the error rate as follows .Recall that for each abbreviation , each sense distribution and each sample size we run the experiment 30 times .The error rate was computed using both a 5-fold and a 10-fold cross - validation scheme .", "label": "", "metadata": {}, "score": "80.01207"}
{"text": "These event participants describe the different aspects of the event , e.g. , what causes the event , what is affected by it , where it took place , etc .Based on its function , each participant is usually assigned a role within the event .", "label": "", "metadata": {}, "score": "80.77552"}
{"text": "nltk - users mailing list is pretty active , and you can also try stackoverflow\\n .\\n .NLTK in 20 minutes .NLTK in 20 minutesA sprint thru Pythons Natural Language ToolKit .Why Text Processing?sentiment analysisspam filteringplagariasm detection / document similaritydocument categorization / topic detectionphrase extraction , summarizationsmarter searchsimple keyword frequency analysis .", "label": "", "metadata": {}, "score": "80.79678"}
{"text": "DISCUSSION .The Carnegie Mellon Communicator system has provided a framework for experimenting with domain - specific , corpus - driven knowledge base configuration at different levels of a spoken dialog system .ACKNOWLEDGEMENTS .We would like to thank Maxine Eskenazi and Karin Gregory for their work in managing corpus collection and transcription , as well as lexicon maintenance .", "label": "", "metadata": {}, "score": "80.94651"}
{"text": "The combination of systems always performed better than any of the individual systems , but performance increase of the combined system was larger when the individual systems were trained on GENIA or PennBioIE GSCs than when they were trained on the PennBioIE SSC ( cf .", "label": "", "metadata": {}, "score": "80.97592"}
{"text": "If the Precision is less than 1 , that means the tagger gave the tag to a word that it should n't have ( a false positive ) .If the Recall is less than 1 , it means the tagger did not give the tag to a word that it should have ( a false negative ) .", "label": "", "metadata": {}, "score": "81.06085"}
{"text": "But contextual features often provide powerful clues about the correct tag - for example , when tagging the word \" fly , \" knowing that the previous word is \" a \" will allow us to determine that it is functioning as a noun , not a verb .", "label": "", "metadata": {}, "score": "81.07726"}
{"text": "Gender Identification .In 4 we saw that male and female names have some distinctive characteristics .Names ending in a , e and i are likely to be female , while names ending in k , o , r , s and t are likely to be male .", "label": "", "metadata": {}, "score": "81.11369"}
{"text": "Based on this feature extractor , we can create a list of labeled featuresets by selecting all the punctuation tokens , and tagging whether they are boundary tokens or not : . ? ! ' ] Using these featuresets , we can train and evaluate a punctuation classifier : .", "label": "", "metadata": {}, "score": "81.18823"}
{"text": "So the lesson is : do not use a classifier based tagger if speed is an issue .Here 's the code for timing postag .You can do the same thing for any other pickled tagger by replacing nltk.tag ._ POS_TAGGER with a nltk.data accessible path with a . pickle suffix for the load method .", "label": "", "metadata": {}, "score": "81.24544"}
{"text": "Results .Support Vector Machine ( SVM ) classifiers were applied to an automatically generated data set containing four ambiguous biomedical abbreviations : BPD , BSA , PCA , and RSV , which were chosen because of varying degrees of differences in their respective senses .", "label": "", "metadata": {}, "score": "81.42055"}
{"text": "The SSC as a substitute for a GSC corresponds with a use scenario in which a chunker created for one subdomain has to be adapted to another , where a GSC for the new domain is not available .In the second use scenario , we supplemented a ( small ) GSC with an SSC for the same domain as the GSC .", "label": "", "metadata": {}, "score": "81.493095"}
{"text": "Modeling the linguistic data found in corpora can help us to understand linguistic patterns , and can be used to make predictions about new language data .Supervised classifiers use labeled training corpora to build models that predict the label of an input based on specific features of that input .", "label": "", "metadata": {}, "score": "81.56218"}
{"text": "We will gloss over the mathematical and statistical underpinnings of these techniques , focusing instead on how and when to use them ( see the Further Readings section for more technical background ) .Before looking at these methods , we first need to appreciate the broad scope of this topic .", "label": "", "metadata": {}, "score": "81.5756"}
{"text": "Authors ' Affiliations .National Centre for Text Mining , Manchester Interdisciplinary Biocentre , University of Manchester .References .Ananiadou S , Kell DB , Tsujii J : Text mining and its potential applications in systems biology .Trends Biotechnol 2006 , 24 ( 12 ) : 571 - 579 .", "label": "", "metadata": {}, "score": "81.59649"}
{"text": "The creation of a gold standard corpus ( GSC ) is tedious and expensive : annotation guidelines have to be established , domain experts must be trained , the annotation process is time - consuming , and annotation disagreements have to be resolved .", "label": "", "metadata": {}, "score": "81.71295"}
{"text": "AAAI Fall Symp 93 98 - 107 .Hamosh A , Scott AF , Amberger J , Bocchini C , Valle D , McKusick VA : Online Mendelian Inheritance in Man ( OMIM ) , a knowledgebase of human genes and genetic disorders .", "label": "", "metadata": {}, "score": "81.71936"}
{"text": "Finally , the effect of the automatic segmentation procedure on the BNeval98 set was investigated .On BNeval97 we had found that automatic segmentation had produced very similar overall accuracy to manually defined segments .However on BNeval98 the automatic segmenter faired more poorly .", "label": "", "metadata": {}, "score": "81.7411"}
{"text": "GENIA Event : The GENIA Event corpus [ 9 ] contains 1,000 MEDLINE abstracts in which 36,858 bio - events have been identified .Each event belongs to one of the 36 event classes defined in the GENIA Event Ontology .The event participants can be bio - entities or other bio - events .", "label": "", "metadata": {}, "score": "81.74455"}
{"text": "Wilbur WJ , Rzhetsky A , Shatkay H : New directions in biomedical text annotation : definitions , guidelines and corpus construction .BMC Bioinformatics 2006 , 7 ( 1 ) : 356 .View Article PubMed .Shatkay H , Pan F , Rzhetsky A , Wilbur WJ : Multi - dimensional classification of biomedical text : toward automated , practical provision of high - utility text to diverse users .", "label": "", "metadata": {}, "score": "81.81827"}
{"text": "Sang EFTK , De Meulder F : Introduction to the CoNLL-2003 Shared Task : Language - Independent Named Entity Recognition .Proceedings of CoNLL-2003 2003 , 142 - 147 .Hirschman L , Morgan A , Yeh A : Rutabaga by Any Other Name : Extracting Biological Names .", "label": "", "metadata": {}, "score": "81.938965"}
{"text": "As stated above , gazetteer lookup was performed for each token in the preprocessing stage .Lookup was case - insensitive but punctuation was required to match exactly .For multiple word entries in the gazetteer we required all words in the entry to match .", "label": "", "metadata": {}, "score": "82.02856"}
{"text": "Zhang H : The Optimality of Naive Bayes .In 17th International FLAIRS Conference .American Association for Artificial Intelligence ( AAAI ) : Palo Alto , CA ; 2004 .Cortes C , Vapnik V : Support - Vector Networks .", "label": "", "metadata": {}, "score": "82.0747"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of RSV data set ( case where the 2 ambiguous senses both refer to viruses but the viruses are different types of viruses ) using 5-fold cross validation .", "label": "", "metadata": {}, "score": "82.083786"}
{"text": "Authors ' Affiliations .Department of Computer Science , Stanford University .Institute for Communicating and Collaborative Systems , University of Edinburgh .References .Aronson AR , Bodenreider O , Chang HF , Humphrey SM , Mork JG , Nelson SJ , Rindflesch TC , Wilbur WJ : The NLM Indexing Initiative . 2000 AMIA Annual Fall Symposium 2000 , 17 - 21 .", "label": "", "metadata": {}, "score": "82.14815"}
{"text": "The estimate of the standard error was then obtained by averaging the above values over the 30 runs .Gene ambiguity for mining MEDLINE .To determine the extent of the gene ambiguity problem in MEDLINE , we searched MEDLINE abstracts to determine how many abstracts contained gene symbols that were ambiguous with general English words or biomedical terms .", "label": "", "metadata": {}, "score": "82.26119"}
{"text": "The online version of this article ( doi : 10 .1186/\u200b1471 - 2105 - 7 - 334 ) contains supplementary material , which is available to authorized users .Background .During the last few years , there has been a surge of interest in information extraction and text mining of the biomedical literature [ 1 , 2 ] .", "label": "", "metadata": {}, "score": "82.33747"}
{"text": "NLTK has moved development and hosting to github , replacing google code and SVN .The primary motivation is to make new development easier , and already a Python 3 branch is under active development .I think this is great , since github makes forking & pull requests quite easy , and it 's become the de - facto \" social coding \" site .", "label": "", "metadata": {}, "score": "82.344635"}
{"text": "Figure 4 shows plots of the error rate versus sample size for each distribution of the BPD data set based on the 5-fold cross validation using the \" one - vs - rest \" algorithm .The plots for the four different sense distributions are very similar and actually agree with results obtained indicating that the effect of the different distributions on the error rate is insignificant .", "label": "", "metadata": {}, "score": "82.40233"}
{"text": "To demonstrate the extent of the ambiguity problem in MEDLINE we searched MEDLINE abstracts to determine how many abstracts contained gene symbols that were ambiguous with general English words or biomedical terms .We repeated the same procedure for the fly and yeast organisms as well .", "label": "", "metadata": {}, "score": "82.523705"}
{"text": "Conference of the American Association for Artificial Intelligence ( AAAI-2004 ) .Palo Alto , CA : American Association for Artificial Intelligence ( AAAI ) ; 2004:761 - 769 .Joshi M , Penstein - Rose C : Generalizing Dependency Features for Opinion Mining .", "label": "", "metadata": {}, "score": "82.59686"}
{"text": "3.2 Accuracy .The simplest metric that can be used to evaluate a classifier , accuracy , measures the percentage of inputs in the test set that the classifier correctly labeled .The function nltk.classify.accuracy ( ) will calculate the accuracy of a classifier model on a given test set : . format(nltk.classify.accuracy(classifier , test_set ) ) ) 0.75 .", "label": "", "metadata": {}, "score": "82.71575"}
{"text": "To date , there have been four RTE Challenges , where shared development and test data is made available to competing teams .Here are a couple of examples of text / hypothesis pairs from the Challenge 3 development dataset .The label True indicates that the entailment holds , and False , that it fails to hold .", "label": "", "metadata": {}, "score": "82.8616"}
{"text": "Lastly , a parentheses - matching feature that signalled when one parenthesis was classified differently from its pair was added in an effort to eliminate errors where the tagger classified matching parentheses differently .All of these basic feature types were then used singly or combined in various ways to create new features .", "label": "", "metadata": {}, "score": "82.86667"}
{"text": "cBioScope .cBioInfer . cCore .absence , fail , inability , independent , independently , insensitive , insufficient , lack ( noun ) , lack ( verb ) , little , neither , no , nor , not , resistant , unable , unaffected , unchanged , without .", "label": "", "metadata": {}, "score": "82.909805"}
{"text": "It contains data for four words : hard , interest , line , and serve .Choose one of these four words , and load the corresponding data : .Using this dataset , build a classifier that predicts the correct sense tag for a given instance .", "label": "", "metadata": {}, "score": "82.966064"}
{"text": "Character substrings refer to all substrings of the current word , up to a length of 6 characters .Thus the word \" bio \" would have features _ b , _ bi , _ bio , _ bio _ , bio _ , io _ , o _ , bio , bi , io , b , i , o .", "label": "", "metadata": {}, "score": "83.00865"}
{"text": "During training , we use the annotated tags to provide the appropriate history to the feature extractor , but when tagging new sentences , we generate the history list based on the output of the tagger itself . def pos_features ( sentence , i , history ) : . return features class ConsecutivePosTagger ( nltk .", "label": "", "metadata": {}, "score": "83.02088"}
{"text": "The textual bio - event information includes the text fragment indicating the occurrence of the bio - event ( i.e. , the event - trigger ) , the text fragments identifying the event participants and the text fragments indicating any event attributes , like location , etc .", "label": "", "metadata": {}, "score": "83.0647"}
{"text": "Smith L , Tanabe LK , Ando RJ , Kuo CJ , Chung IF , Hsu CN , Lin YS , Klinger R , Friedrich CM , Ganchev K , et al .: Overview of BioCreative II gene mention recognition .", "label": "", "metadata": {}, "score": "83.081894"}
{"text": "Model 2 represents a significant improvement in accuracy .Table 1 .WER obtained using different acoustic models .Model 3 : It was observed that the performance of Model 1 on tracking test sets had steadily deteriorated in the Fall of 1999 , due in part to a noisier signal .", "label": "", "metadata": {}, "score": "83.24706"}
{"text": "The explosion of information in the biomedical domain and particularly in genetics has highlighted the need for automated text information extraction techniques .MEDLINE , the primary research database serving the biomedical community , currently contains over 14 million abstracts , with 60,000 new abstracts appearing each month .", "label": "", "metadata": {}, "score": "83.632454"}
{"text": "Greenberg JH ( Ed ) : Universals of Human Language .Stanford , California : Stanford University Press ; 1978 .Tottie G : Negation in English Speech and Writing : A Study in Variation .New York : Academic ; 1991 .", "label": "", "metadata": {}, "score": "83.63421"}
{"text": "5.5 The Cause of Double - Counting .The reason for the double - counting problem is that during training , feature contributions are computed separately ; but when using the classifier to choose labels for new inputs , those feature contributions are combined .", "label": "", "metadata": {}, "score": "83.63429"}
{"text": "It has two participants : the arbitrary protein Y and the event E1 , which act as the cause and the theme of the event , respectively .Bio - event corpora for training and evaluation .Recently , significant effort has been put into the creation of various bio - event corpora .", "label": "", "metadata": {}, "score": "83.64365"}
{"text": "Note .Your Turn : Modify the gender_features ( ) function to provide the classifier with features encoding the length of the name , its first letter , and any other features that seem like they might be informative .Retrain the classifier with these new features , and test its accuracy .", "label": "", "metadata": {}, "score": "83.696594"}
{"text": "For using the web we built several contexts indicative of gene entities including \" X gene \" , \" X mutation \" or \" X antagonist \" .For each entity X identified as a gene by an initial run of the tagger , we submitted the instantiation of each pattern to the Web using the Google API and obtained the number of hits .", "label": "", "metadata": {}, "score": "83.96775"}
{"text": "Of the latter three are deemed closed with respect to the domain ( e.g. , holidays , ordinal numbers ) .There is a total of 1573 words in the class component of the language model .A key issue in managing the knowledge base as a whole is coordinating modifications that impact different components of the base .", "label": "", "metadata": {}, "score": "84.03663"}
{"text": "The increase in F - scores varies between 1.7 and 3.1 percentage points for noun phrases and between 1.0 and 3.3 percentage points for verb phrases .Although performance further increases when training on PennBioIE GSC instead of PennBioIE SSC , differences are not large : 0.2 to 0.8 percentage point for noun phrases , 0.3 to 1.7 percentage point for verb phrases .", "label": "", "metadata": {}, "score": "84.15048"}
{"text": "Precision is the number of true positives divided by the sum of true positives and false positives ; recall is the number of true positives divided by the sum of true positives and false negatives ; and F - score is the first harmonic mean of precision and recall .", "label": "", "metadata": {}, "score": "84.2319"}
{"text": "Examples of Errors Examples of FPs , FNs and boundary errors .In some of the examples square brackets are used to indicate the differences between the classifier 's output and the annotation in the gold standard .Declarations .Acknowledgements .", "label": "", "metadata": {}, "score": "84.28343"}
{"text": "There are different types of WSD and some are more difficult than others .For example , if two senses are syntactically different , a reliable part of speech tagging method could be effective in resolving the ambiguity .For senses that correspond to the same syntactic category , the similarity of their semantic categories will affect the difficulty of the task ( i.e. the bovine serum albumin sense of BSA is substantially different from the body surface area sense ) .", "label": "", "metadata": {}, "score": "84.485916"}
{"text": "Error Rate versus Sample Size with different sense distributions of BSA data set .This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of BSA data set ( case where the 2 ambiguous senses are very different ) using 5-fold cross - validation .", "label": "", "metadata": {}, "score": "84.592575"}
{"text": "Copyright .\u00a9 Kang et al ; licensee BioMed Central Ltd. 2012 .Learning to Classify Text .Detecting patterns is a central part of Natural Language Processing .Words ending in -ed tend to be past tense verbs ( 5 . )", "label": "", "metadata": {}, "score": "84.59547"}
{"text": "View Article PubMed .Gaudan S , Krisch H , Rebholz - Schuhmann D : Resolving abbreviations to their senses in Medline .Bioinformatics 2005 , 21 : 3658 - 3664 .View Article PubMed .Schuemie MJ , Kors JA , Mons B : Word sense disambiguation in the biomedical domain : an overview .", "label": "", "metadata": {}, "score": "84.71507"}
{"text": "Both E2 and E3 are negated , as they are both triggered by the word required , which is being modified by the explicit negation cue not .Interestingly , the scope of the negation cue ( not ) , according to the BioScope annotation guidelines , also includes the trigger for event E1 ( which is not negated ) .", "label": "", "metadata": {}, "score": "85.03163"}
{"text": "Department of Biomedical Informatics , Columbia University .Department of Biostatistics , Bioinformatics and Biomathematics , Georgetown University Medical Center .References .Krallinger M , Valencia A : Text - mining and information - retrieval services for molecular biology .Genome Biol 2005 , 6 : 224 .", "label": "", "metadata": {}, "score": "85.25459"}
{"text": "Methods .Types of negated bio - events .We conducted an in - depth analysis of the types of negation observed in the three open access bio - event corpora containing negation annotation .Our analysis revealed five main types of negated bio - events : .", "label": "", "metadata": {}, "score": "85.37183"}
{"text": "These are bio - events in which the event - trigger is itself a negation cue , like independent , immobilization , unaffected , dysregulation , etc .As an example , consider the sentence shown in Figure 3 .The event E1 is triggered by the word infection and represents the initiation of viral infection of HIV-1 .", "label": "", "metadata": {}, "score": "85.39838"}
{"text": "Thus , the performance of chunkers trained on either SSC or GSC was always tested on the GSC .Silver standard as supplement of gold standard .To test whether an SSC would have additional value as a supplement for a given GSC , we compared the performance of chunkers trained on a subset of the GENIA GSC with the performance of the chunkers trained on the same subset supplemented with an SSC .", "label": "", "metadata": {}, "score": "85.56303"}
{"text": "For example , the size of PubMed is increasing at the rate of approximately two papers per minute [ 2 ] .As a result , it is becoming increasingly difficult for biologists to keep abreast of developments within biomedicine , and automated means are required to satisfy their information needs .", "label": "", "metadata": {}, "score": "85.71097"}
{"text": "The default training options are a maximum of 200 rules with a minimum score of 2 , but you can change that with the --max_rules and --min_score arguments .You can also change the rule template bounds , which defaults to 1 , using the --template_bounds argument .", "label": "", "metadata": {}, "score": "85.82185"}
{"text": "For example , consider a classifier that determines the correct word sense for each occurrence of the word bank .If we evaluate this classifier on financial newswire text , then we may find that the financial - institution sense appears 19 times out of 20 .", "label": "", "metadata": {}, "score": "86.079834"}
{"text": "The bio - events in the BioNLP'09 ST dataset were split into three classes .The localization , transcription , protein_catabolism , gene_expression and phosphorylation events were grouped together as Class-1 .The binding events were grouped as Class-2 , and the regulation events ( regulation , positive_regulation and negative_regulation ) were grouped together as Class-3 .", "label": "", "metadata": {}, "score": "86.16587"}
{"text": "THE CMU COMMUNICATOR .The Carnegie Mellon Communicator [ 8 ] is a telephone - based dialog system that supports planning in a travel domain .Currently the task is captured in an approximately 2700-word language based on corpora derived from human - human , wizard of oz and human - computer interaction .", "label": "", "metadata": {}, "score": "86.64289"}
{"text": "Boytcheva S , Strupchanska A , Paskaleva E , Tcharaktchiev D , Str DG : Some Aspects of Negation Processing in Electronic Health Records .In International Workshop Language and Speech Infrastructure for Information Access in the Balkan Countries .Bulgaria : Bulgarian Academy of Sciences ; 2005:1 - 8 .", "label": "", "metadata": {}, "score": "86.687874"}
{"text": "The event E1 is anchored to the word expression and has been assigned the event - type of gene_expression .It has a single participant , the arbitrary gene X , which acts as the theme of the event .E1 also has a location attribute , which has the arbitrary value of Z .", "label": "", "metadata": {}, "score": "87.20633"}
{"text": "Four ambiguous abbreviations : BPD , BSA , PCA , and RSV , were used in this study .They were chosen because they were associated with varying degrees of differences between their respective senses .For example , two of the senses of PCA studied are very similar whereas two senses of BSA are very different .", "label": "", "metadata": {}, "score": "87.23538"}
{"text": "Negated attribute .There are bio - events in which an explicit negation cue modifies an event attribute , such as location .An example of this type of negation is shown in Figure 6 .The events E1 , E2 , E3 , E4 , E5 and E6 are all triggered by the word coexpressed .", "label": "", "metadata": {}, "score": "87.48201"}
{"text": "A tagger trained with any of these phonetic features will be an instance of nltk_trainer . tagging.taggers.PhoneticClassifierBasedPOSTagger , which means nltk_trainer must be included in your PYTHONPATH in order to load & use the tagger .The simplest way to do this is to install nltk - trainer using python setup.py install .", "label": "", "metadata": {}, "score": "87.80203"}
{"text": "Directions for improvement .The learning curve in Figure 1 suggests that we can expect only very limited improvement from the availability of additional training data , given the current task and feature set .Rather we must explore other avenues , including better exploitation of existing features and resources , development of additional features , incorporation of additional external resources , or experimentation with other algorithms and strategies for approaching the task .", "label": "", "metadata": {}, "score": "88.258965"}
{"text": "Deciding what the topic of a news article is , from a fixed list of topic areas such as \" sports , \" \" technology , \" and \" politics . \"Deciding whether a given occurrence of the word bank is used to refer to a river bank , a financial institution , the act of tilting to the side , or the act of depositing something in a financial institution .", "label": "", "metadata": {}, "score": "89.00638"}
{"text": "Each combination of labels and features that receives its own parameter is called a joint - feature .Note that joint - features are properties of labeled values , whereas ( simple ) features are properties of unlabeled values .Note .", "label": "", "metadata": {}, "score": "89.18182"}
{"text": "Textual events are usually anchored to particular text fragments that are central to the description of the event .The most important of these text fragments is the event - trigger , which is usually a verb or a noun that indicates the occurrence of the event .", "label": "", "metadata": {}, "score": "89.97438"}
{"text": "Acknowledgements .This work was supported by part by Grants R01 LM7659 , R01 LM8635 from the National Library of Medicine , and Grants NSF - DMS-0504957 , NSF- IIS-0430743 from the National Science Foundation .We would like to thank Lyudmila Shagina for providing technical support .", "label": "", "metadata": {}, "score": "90.2466"}
{"text": "[36 ] identified two main classes of negation : directly licensed negations and indirectly licensed negations .The directly licensed negations include : overt negative markers ( such as not ) , negative quantifiers ( like no ) and strongly negative adverbs ( like never ) .", "label": "", "metadata": {}, "score": "90.57347"}
{"text": "Negated participant .This category corresponds to bio - events in which at least one participant ( theme or cause ) is modified by an explicit negation cue .As an example , consider the sentence shown in Figure 5 .Both events , E1 and E2 , are triggered by the phrase synergistically induced ; however , they have opposite polarities .", "label": "", "metadata": {}, "score": "90.75572"}
{"text": "CAT reporter gene \" where the classifier only recognized \" CAT reporter \" as a gene .Because many abbreviations were not genes and because the precision and recall of the gazetteer were fairly low , we believe that both abbreviation and gazetteer features helped more in identifying gene boundaries than in identifying genes .", "label": "", "metadata": {}, "score": "91.11869"}
{"text": "Negated bio - events .Vincze et al .[ 16 ] define negation in the context of biomedical literature as ' the implication of the non - existence of something ' .Negation at the bio - event level is non - existence of an event , i.e. , a negated bio - event indicates the non - existence of that event .", "label": "", "metadata": {}, "score": "91.40106"}
{"text": "In the training corpus , most documents are automotive , so the classifier starts out at a point closer to the \" automotive \" label .But it then considers the effect of each feature .In this example , the input document contains the word \" dark , \" which is a weak indicator for murder mysteries , but it also contains the word \" football , \" which is a strong indicator for sports documents .", "label": "", "metadata": {}, "score": "92.2641"}
{"text": "Nevertheless human intervention is required at two points : the identification of alternative renderings of a particular identifier ( e.g. , JFK as well as KENNEDY for an airport name ) and the choice of a pronunciation .While it is possible to automatically generate pronunciations as well as variants , human review is always necessary to ensure accuracy .", "label": "", "metadata": {}, "score": "92.6927"}
{"text": "A number of natural language processing systems in the biomedical domain reported decreased precision due to the ambiguity problem [ 3 , 4 ] .Weeber [ 5 ] found that in order to replicate Swanson 's literature - based discovery of the involvement of magnesium deficiency in migraine , it was important to resolve the ambiguity of an abbreviation mg , which can denote either magnesium or milligram .", "label": "", "metadata": {}, "score": "93.737305"}
{"text": "This research was sponsored by the Space and Naval Warfare Systems Center , San Diego , under Grant No . N66001 - 99 - 1 - 8905 .The content of the information in this publication does not necessarily reflect the position or the policy of the US Government , and no official endorsement should be inferred .", "label": "", "metadata": {}, "score": "93.83581"}
{"text": "In [ 55 ] , we proposed an alternative approach to event interpretation .We argued that polarity and manner should be treated as orthogonal dimensions of event interpretation , i.e. , the value of manner should not influence the value of polarity and vice - versa .", "label": "", "metadata": {}, "score": "93.94803"}
{"text": "Smaller increases in the sample size had an insignificant effect .We performed further sub - analysis using non - parametric multiple comparisons to identify the pairs of sample sizes that differ when the abbreviations BSA and RSV were analyzed .This analysis revealed that in the case of BSA the improvements in terms of error rate were statistically significant across distributions as the sample size increased from 20 to 40 .", "label": "", "metadata": {}, "score": "94.050934"}
{"text": "For BSA , RSV and BPD , we found that the effect of the sense distribution on the error rate was insignificant .For PCA this effect was significant .The effect of different sample sizes on the error rate was significant for BSA , RSV , and BPD .", "label": "", "metadata": {}, "score": "94.31198"}
{"text": "True negatives are irrelevant items that we correctly identified as irrelevant .False positives ( or Type I errors ) are irrelevant items that we incorrectly identified as relevant .False negatives ( or Type II errors ) are relevant items that we incorrectly identified as irrelevant .", "label": "", "metadata": {}, "score": "94.363144"}
{"text": "These limits may change in the future depending on usage & demand .If you 'd like to do more , please fill out this survey to let me know what your needs are .If you like it , please share it .", "label": "", "metadata": {}, "score": "95.73731"}
{"text": "This occurred frequently with measures , such as \" kat / L \" ( katal per litre ) and acronyms for non - gene entities .Acronym ambiguity was a related source of error .The abbreviation \" HAT \" , for instance , could stand for the gene name \" histone acetyltransferase \" but actually referred to \" hepatic artery thrombosis \" in one specific context .", "label": "", "metadata": {}, "score": "96.14224"}
{"text": "Nitrogen balance was compared , and metabolic complications were monitored by evaluating BUN , serum creatinine , creatinine clearance , serum CO2 , SGOT , SGPT , serum LDH , and serum alkaline phosphatase .Envelope - function matching conditions for GaAs/(Al , Ga)As heterojunctions .", "label": "", "metadata": {}, "score": "97.98712"}
{"text": "View Article PubMed .Copyright .\u00a9 Finkel et al 2005 .This article is published under license to BioMed Central Ltd. ABSTRACT .The Carnegie Mellon Communicator is a telephone - based dialog system that supports planning in a travel domain .", "label": "", "metadata": {}, "score": "98.94266"}
{"text": "For example , when classifying documents into topics ( such as sports , automotive , or murder mystery ) , features such as hasword(football ) are highly indicative of a specific label , regardless of what other the feature values are .", "label": "", "metadata": {}, "score": "100.398895"}
{"text": "Learning curve for the performance of the \" open \" NER system on development data .One obvious improvement of our current system would be the incorporation of protein names into our gazetteer .Due to ambiguity in the guidelines we were unaware that protein names were to be recognized and incorporated only gene names into our gazetteer .", "label": "", "metadata": {}, "score": "100.565674"}
{"text": "View Article PubMed .Copyright .\u00a9 Nawaz et al . ; licensee BioMed Central Ltd. 2013 .This article is published under license to BioMed Central Ltd.Affiliated with .Abstract .Background .Automated techniques have been developed that address the WSD problem for a number of text processing situations , but the problem is still a challenging one .", "label": "", "metadata": {}, "score": "102.07796"}
{"text": "This is NLTK . \") [ Hello SF Python . , This is NLTK .] We missed you ! \" ) [ Hello , Mr. Anderson . , We missed you ! ][ This , is , NLTK , . ]", "label": "", "metadata": {}, "score": "102.71114"}
{"text": "The event has two slots , i.e. , theme and cause , whose labels help to characterise the contribution that the slot filler makes towards the meaning of the event .In this case , the slots are filled by the subject and object of the verb activate , both of which correspond to different types of bio - entities ( i.e. , operon and protein ) .", "label": "", "metadata": {}, "score": "102.993065"}
{"text": "Shortly after the tour ended , Michael and Marlon Jackson quit the group .Jermaine , Tito , Randy and Jackie Jackson continued on as the Jacksons , and releasing one more album , 1989 's 2300 Jackson Street before splitting up .", "label": "", "metadata": {}, "score": "103.90082"}
{"text": "Some inherently negative event - triggers which can be applied to various types of events are also included in this category .For example , event - triggers like unaffected and independent can be used for various types of events including positive_regulation , negative_regulation and correlation events .", "label": "", "metadata": {}, "score": "104.10921"}
{"text": "Challenge 3 , Pair 81 ( False ) .T :According to NC Articles of Organization , the members of LLC company are H. Nelson Beavers , III , H. Chester Beavers and Jennie Beavers Stewart .H : Jennie Beavers Stewart is a share - holder of Carolina Analytical Laboratory .", "label": "", "metadata": {}, "score": "107.690544"}
{"text": "T : Parviz Davudi was representing Iran at a meeting of the Shanghai Co - operation Organisation ( SCO ) , the fledgling association that binds Russia , China and four former Soviet republics of central Asia together to fight terrorism .", "label": "", "metadata": {}, "score": "112.48467"}
{"text": "The album sold over seven million copies worldwide , opening at number four on the US Billboard 200 , selling 185,000 copies in first week sales .On October 30 , 1984 , the album was certified 2\u00d7 Platinum by RIAA for the sales of over 2 million copies in the United States .", "label": "", "metadata": {}, "score": "119.96849"}
{"text": "victorie , OF .victorie , victoire , F. victoire , L. victoria .See Victor . ]Freebase ( 0.00 / 0 votes )Rate this definition : .Victory is the fourteenth album by The Jacksons , released on July 2 , 1984 on Epic Records .", "label": "", "metadata": {}, "score": "123.96387"}
