{"text": "Our generative self - trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without self - training .Additionally , we show that multiple self - trained grammars can be combined in a product model to achieve even higher accuracy .", "label": "", "metadata": {}, "score": "25.64701"}
{"text": "Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .On the other hand , our grammars are much more compact and substantially more accurate than previous work on automatic annotation .Despite its simplicity , our best grammar achieves an F1 of 89.9 % on the Penn Treebank , higher than most fully lexicalized systems .", "label": "", "metadata": {}, "score": "33.199574"}
{"text": "Combining multiple grammars that were self - trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5\\% on the WSJ test set and 89.6\\% on our Broadcast News test set .This work shows how to improve state - of - the - art monolingual natural language processing models using unannotated bilingual text .", "label": "", "metadata": {}, "score": "40.35792"}
{"text": "In addition , our discriminative approach integrally admits features beyond local tree configurations .We present a multi - scale training method along with an efficient CKY - style dynamic program .On a variety of domains and languages , this method produces the best published parsing accuracies with the smallest reported grammars .", "label": "", "metadata": {}, "score": "42.595882"}
{"text": "We show that the automatically induced latent variable grammars of Petrov et al .2006 vary widely in their underlying representations , depending on their EM initialization point .We use this to our advantage , combining multiple automatically learned grammars into an unweighted product model , which gives significantly improved performance over state - of - the - art individual grammars .", "label": "", "metadata": {}, "score": "43.225918"}
{"text": "We have designed a Lexical - Functional Grammar ( LFG ) ( Kaplan and Bresnan , 1982 ) f - structure annotation algorithm to automatically annotate this treebank with f - structure information approximating to basic predicate - argument or dependency structures ( Cahill et al . , 2002c , 2004a ) .", "label": "", "metadata": {}, "score": "43.301517"}
{"text": "To date , the best result achieved by our own Penn - II induced grammars is a dependency f - score of 80.33 % against the PARC 700 , an improvement of 0.73 % over the best handcrafted grammar of ( Kaplan et al .", "label": "", "metadata": {}, "score": "44.78066"}
{"text": "Across eight languages , the multilingual approach gives error reductions over the standard monolingual DMV averaging 21.1 % and reaching as high as 39 % . ... inally given as simple multinomial distributions with one parameter per outcome . \" ...We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available , using annotated data from a set of one or more helper languages .", "label": "", "metadata": {}, "score": "45.27089"}
{"text": "Despite its simplicity , a product of eight automatically learned grammars improves parsing accuracy from 90.2 % to 91.8 % on English , and from 80.3 % to 84.5 % on German .Pruning can massively accelerate the computation of feature expectations in large models .", "label": "", "metadata": {}, "score": "46.53794"}
{"text": "The best accuracies were in the 80 - 84\\% range for F1 and LAS ; even part - of - speech accuracies were just above 90\\% .Coarse - to - fine inference has been shown to be a robust approximate method for improving the efficiency of structured prediction models while preserving their accuracy .", "label": "", "metadata": {}, "score": "46.583138"}
{"text": "We believe that our approach successfully addresses the knowledge - acquisition bottleneck ( familiar from rule - based approaches to Al and NLP ) in wide - coverage , constraint - based grammar development .Our approach can provide an attractive , wide - coverage , multilingual , deep , constraint - based grammar acquisition paradigm .", "label": "", "metadata": {}, "score": "47.321083"}
{"text": "Unlike previous work , our final model does not require any additional resources at run - time .Compared to a state - of - the - art approach , we achieve more than 20 % relative error reduction .Additionally , we annotate a corpus of search queries with part - of - speech tags , providing a resource for future work on syntactic query analysis .", "label": "", "metadata": {}, "score": "48.12828"}
{"text": "The model is formally a latent variable CRF grammar over trees , learned by iteratively splitting grammar productions ( not categories ) .Different regions of the grammar are refined to different degrees , yielding grammars which are three orders of magnitude smaller than the single - scale baseline and 20 times smaller than the split - and - merge grammars of Petrov et al .", "label": "", "metadata": {}, "score": "48.600174"}
{"text": "Our grammar inducer is trained on the Wall Street Journal ( WSJ ) and achieves 59.5 % accuracy out - of - domain ( Brown sentences with 100 or fewer words ) , more than 6 % higher than the previous best results .", "label": "", "metadata": {}, "score": "48.625603"}
{"text": "Unlike previous work on projecting syntactic resources , we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers .The projected parsers from our system result in state - of - the - art performance when compared to previously studied unsupervised and projected parsing systems across eight different languages .", "label": "", "metadata": {}, "score": "49.61877"}
{"text": "Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations .Finally , we show that hybridizing these two approaches results in still more accurate generation systems .Automatic and human evaluation of generated sentences are presented across two domains and four languages .", "label": "", "metadata": {}, "score": "49.742687"}
{"text": "Our best model produces the lowest alignment error rate yet reported on Canadian Hansards bilingual data . ...e probabalistic models developed at IBM by Brown et al .( 1993 ) , sometimes augmented by an HMMbased model or Och and Ney 's \" Model 6 \" ( Och and Ney , 2003 ) . \" ...", "label": "", "metadata": {}, "score": "50.28041"}
{"text": "Nonetheless , the resulting grammars encode many linguistically interpretable patterns and give the best published parsing accuracies on three German treebanks .We demonstrate that log - linear grammars with latent variables can be practically trained using discriminative methods .Central to efficient discriminative training is a hierarchical pruning procedure which allows feature expectations to be efficiently approximated in a gradient - based procedure .", "label": "", "metadata": {}, "score": "50.512024"}
{"text": "Our method does not assume any knowledge about the target language ( in particular no tagging dictionary is assumed ) , making it applicable to a wide array of resource - poor languages .We use graph - based label propagation for cross - lingual knowledge transfer and use the projected labels as features in an unsupervised model ( Berg - Kirkpatrick et al . , 2010 ) .", "label": "", "metadata": {}, "score": "50.81858"}
{"text": "In an empirical evaluation we show that our model consistently out - performs the current state - of - the - art across 10 languages . ...MM ) and also with the character LM ( 1HMM - LM ) .Starred entries denote results reported in CGS10 .", "label": "", "metadata": {}, "score": "50.85304"}
{"text": "We show that addressing this task directly , using probabilistic finite - state methods , produces better results than relying on the local predictions of a current best unsupervised parser , Seginer 's ( 2007 ) CCL .These finite - state models are combined in a cascade to produce more general ( full - sentence ) constituent structures ; doing so outperforms CCL by a wide margin in unlabeled PARSEVAL scores for English , German and Chinese .", "label": "", "metadata": {}, "score": "50.895153"}
{"text": "Across eight European languages , our approach results in an average absolute improvement of 10.4 % over a state - of - the - art baseline , and 16.7 % over vanilla hidden Markov models induced with the Expectation Maximization algorithm .", "label": "", "metadata": {}, "score": "50.93118"}
{"text": "Given this fixed network representation , we learn a final layer using the structured perceptron with beam - search decoding .On the Penn Treebank , our parser reaches 94.26 % unlabeled and 92.41 % labeled attachment accuracy , which to our knowledge is the best accuracy on Stanford Dependencies to date .", "label": "", "metadata": {}, "score": "51.2616"}
{"text": "Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning .This work describes systems for detecting semantic categories present in news video .", "label": "", "metadata": {}, "score": "51.439304"}
{"text": "In [ 15 ] , Quattoni et al .evaluated a range of different neighborhood structure and come to the conclusion that the minimum spanning tree ( MST ) shows better performances than many other complex connected graph structures .Following this , we adopt MST as the basic structure and extend it to a novel weighted neighborhood structure ( WNS ) .", "label": "", "metadata": {}, "score": "51.459217"}
{"text": "Charniak E , Johnson M : Coarse - to - Fine n - Best Parsing and MaxEnt Discriminative Reranking .43rdAnnual Meeting of the Association for Computational Linguistics Association for Computational Linguistics 2005 .Ortmanns S , Ney H , Aubert X : Word graph algorithm for large vocabulary continuous speech recognition .", "label": "", "metadata": {}, "score": "51.541904"}
{"text": "We use a publicly available structured output SVM to create a max - margin syntactic aligner with a soft cohesion constraint .The resulting aligner is the first , to our knowledge , to use a discriminative learning method to train an ITG bitext parser . ... rence for links to appear near one another ( Vogel et al .", "label": "", "metadata": {}, "score": "51.84481"}
{"text": "In this thesis , we focus on the task of semantic parsing , which maps a natural language sentence into a complete , formal meaning representation in a meaning representation language .We present two novel state - of - the - art learned syntax - based semantic parsers using statistical syntactic parsing techniques , motivated by the following two reasons .", "label": "", "metadata": {}, "score": "52.287613"}
{"text": "Initial experiments show that this approach is able to construct accurate parsers which generalize well to novel sentences and significantly outperform previous approaches to learning case - role mapping based on connectionist techniques .Planned extensions of the general framework and the specific applications as well as plans for further evaluation are also discussed .", "label": "", "metadata": {}, "score": "52.40746"}
{"text": "In addi ... . \" ...Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "52.562454"}
{"text": "Our method does not assume any knowledge about the target language ( in particular no tagging dictionary is assumed ) , making it applicable to a wide array of resource - poor languages .We use graph - based label propagation for cross - lingual knowledge transfer and use the projected labels as features in an unsupervised model ( Berg - Kirkpatrick et al .", "label": "", "metadata": {}, "score": "53.08761"}
{"text": "However , there are cases in which ... . by Shay B. Cohen , Noah A. Smith , Alex Clark , Dorota Glowacka , Colin De La Higuera , Mark Johnson , John Shawe - taylor . \" ...Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .", "label": "", "metadata": {}, "score": "53.123543"}
{"text": "In this paper we present a novel approach for inducing word alignments from sentence aligned data .We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for t ... \" .", "label": "", "metadata": {}, "score": "53.167904"}
{"text": "Empirical results show that the learned parsers generalize well to novel sentences and out - perform previous approaches based on connectionist techniques .ML ID : 25 .Learning Search - Control Heuristics for Logic Programs : Applications to Speedup Learning and Language Acquisition [ Details ] [ PDF ] John M. Zelle March 1993 .", "label": "", "metadata": {}, "score": "53.508354"}
{"text": "For future work , I propose to extend our PCFG induction model in several ways : improving the lexicon learning algorithm , discriminative re - ranking of top - k parses , and integrating the meaning representation language ( MRL ) grammar for extra structural information .", "label": "", "metadata": {}, "score": "53.524544"}
{"text": "2012 , Article ID 868413 , 3 pages , 2012 .View at Publisher \u00b7 View at Google Scholar .S. Gu , Y. Zheng , and C. Tomasi , \" Critical nets and beta - stable features for image matching , \" in Proceedings of the 11th European Conference on Computer Vision ( ECCV ' 10 ) , vol .", "label": "", "metadata": {}, "score": "53.553017"}
{"text": "Generative part - based models [ 5 - 9 ] have shown high flexibility because of their advantage of handling missing data ( i.e. , the correspondence between local features and parts ) in a principled manner .So , each part can be interpreted in a semantically meaningful way .", "label": "", "metadata": {}, "score": "53.736427"}
{"text": "Participants were to build a single parsing system that is robust to domain changes and can handle noisy text that is commonly encountered on the web .There was a constituency and a dependency parsing track and 11 sites submitted a total of 20 systems .", "label": "", "metadata": {}, "score": "53.828148"}
{"text": "To achieve these results we need to mitigate the lack of domain knowledge in the model by providing it with a large amount of automatically parsed data .We extend and improve upon recent work in structured training for neural network transition - based dependency parsing .", "label": "", "metadata": {}, "score": "53.828255"}
{"text": "The main novelty of our approaches lies in the use of a latent two - layer hierarchical formulation of labels and a weighted minimum spanning tree neighborhood structure .The model can effectively encode latent label - level context , as well as observation - level context .", "label": "", "metadata": {}, "score": "53.930542"}
{"text": "Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "53.935345"}
{"text": "We have demonstrated that ReRanker leads to improvement in prediction accuracy through a simple strategy of incorporating additional evidence .There are many directions along which the work can be extended or improved .The first step of the reranking strategy is to identify single - gene loci on a target species .", "label": "", "metadata": {}, "score": "54.27086"}
{"text": "Reranking the K best hypotheses has been an effective technique in natural language processing systems [ 27 - 29 ] .For example , in speech recognition , it is a widely adopted practice to generate the K best recognition hypotheses with a fast one - pass recognizer , and then rerank them based on probabilities given by a more powerful language model [ 30 ] .", "label": "", "metadata": {}, "score": "54.36516"}
{"text": "Because we do not have gold - standard references for training a secondary conditional reranker , we incorporate weak supervision of evaluations against the perceptual world during the process of improving model performance .All these approaches are evaluated on the two publicly available domains that have been actively used in many other grounded language learning studies .", "label": "", "metadata": {}, "score": "54.641975"}
{"text": "In particular , we introduce set - valued features to encode the predicted morphological properties and part - of - speech confusion sets of the words being parsed .We also investigate the use of joint parsing and part - of - speech tagging in the neural paradigm .", "label": "", "metadata": {}, "score": "54.7778"}
{"text": "( 1993 ) .In our model , arbitrary , nonindependent features may be freely incorporated , thereby overcoming the inherent limitation of generative models , which requ ... \" .We introduce a discriminatively trained , globally normalized , log - linear variant of the lexical translation models proposed by Brown et al .", "label": "", "metadata": {}, "score": "54.83382"}
{"text": "We highlight the use of this resource via two experiments , including one that reports competitive accuracies for unsupervised grammar induction without gold standard part - of - speech tags .We present an online learning algorithm for training structured prediction models with extrinsic loss functions .", "label": "", "metadata": {}, "score": "54.871666"}
{"text": "We present several models to this end ; in particular a partially observed conditional random field model , where coupled token and type constraints provide a partial signal for training .Averaged across eight previously studied Indo - European languages , our model achieves a 25 % relative error reduction over the prior state of the art .", "label": "", "metadata": {}, "score": "55.078392"}
{"text": "However , it does not scale to problems with a large set of potential meanings for each sentence , such as the navigation instruction following task studied by Chen and Mooney ( 2011 ) .This paper presents an enhancement of the PCFG approach that scales to such problems with highly - ambiguous supervision .", "label": "", "metadata": {}, "score": "55.26088"}
{"text": "Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with lambda - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain .", "label": "", "metadata": {}, "score": "55.44326"}
{"text": "We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality . ... evious work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word - alignment as a supervised task .", "label": "", "metadata": {}, "score": "55.486683"}
{"text": "We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches .Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic - based approach .", "label": "", "metadata": {}, "score": "55.56423"}
{"text": "For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .", "label": "", "metadata": {}, "score": "55.64067"}
{"text": "Our methods result in state - of - the - art performance on the task of executing sequences of natural language instructions , achieving up to 25 % error reduction , with lexicons that are up to 70 % smaller and are qualitatively less noisy .", "label": "", "metadata": {}, "score": "55.6661"}
{"text": "In this proposal , we present a new approach to semantic parsing based on string - kernel - based classification .Our system takes natural language sentences paired with their formal meaning representations as training data .For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .", "label": "", "metadata": {}, "score": "55.70456"}
{"text": "Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .", "label": "", "metadata": {}, "score": "55.771446"}
{"text": "Building on this work , we demonstrate substan ... \" .For many years , statistical machine translation relied on generative models to provide bilingual word alignments .In 2005 , several independent efforts showed that discriminative models could be used to enhance or replace the standard generative approach .", "label": "", "metadata": {}, "score": "55.776855"}
{"text": "These classifiers are further refined using EM - type iterations based on their performance on the training data .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .Our experiments on two real - world data sets that have deep meaning representations show that this approach compares favorably to other existing systems in terms of accuracy and coverage .", "label": "", "metadata": {}, "score": "55.863335"}
{"text": "The main innovation of the algorithm is its use of state - of - the - art statistical machine translation techniques .A statistical word alignment model is used for lexical acquisition , and the parsing model itself can be seen as an instance of a syntax - based translation model .", "label": "", "metadata": {}, "score": "56.060703"}
{"text": "First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .", "label": "", "metadata": {}, "score": "56.12876"}
{"text": "For example , there are 6031 loci where ReRanker selects the most probable candidate models as defined by Evigan ; there are 820 loci where ReRanker-5 g selects the second to the fifth most probable candidate models as defined by Evigan , and so on .", "label": "", "metadata": {}, "score": "56.284626"}
{"text": "Finally , we introduce the idea of evaluating systems based on their ability to produce cluster prototypes that are useful as input to a prototype - driven learner .In most cases , the prototype - driven learner outperforms the unsupervised system used to initialize it , yielding state - of - the - art results on WSJ and improvements on non - English corpora .", "label": "", "metadata": {}, "score": "56.34099"}
{"text": "Despite the much simplified training process , our acoustic model achieves state - of - the - art results on phone classification ( where it outperforms almost all other methods ) and competitive performance on phone recognition ( where it outperforms standard CD triphone / subphone / GMM approaches ) .", "label": "", "metadata": {}, "score": "56.43942"}
{"text": "Around 2009 , we parsed large volumes of text at a rate of about 1,000,000 sentences a day by distributing the work over 6 dual core / dual processor machines .Sure ! !These instructions concentrate on parsing from the command line , since you need to use that to be able to set most options .", "label": "", "metadata": {}, "score": "56.46653"}
{"text": "In future work , we intend to pursue several directions in developing accurate semantic parsers for a variety of application domains .This will involve exploiting prior knowledge about the natural - language syntax and the application domain .We also plan to construct a syntax - aware word - based alignment model for lexical acquisition .", "label": "", "metadata": {}, "score": "56.515984"}
{"text": "Broadly speaking , all of these gene finders employ the strategy of adding comparative side - information to an existing ab initio model ; genome annotation pipelines such as EnsEMBL [ 23 ] and UCSC Known Genes [ 24 ] add comparative components to ab initio models and expressed - sequence data sources .", "label": "", "metadata": {}, "score": "56.529762"}
{"text": "Across various hierarchical encoding schemes and for multiple language pairs , we show speed - ups of up to 50 times over single - pass decoding while improving BLEU score .Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram - to - trigram decoder .", "label": "", "metadata": {}, "score": "56.572662"}
{"text": "We focus on two important sub - tasks , semantic parsing and tactical generation .The key idea is that both tasks can be treated as the translation between natural languages and formal meaning representation languages , and therefore , can be performed using state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}, "score": "56.75297"}
{"text": "In our experiments , we use the beta - stable feature extracting method [ 20 ] to locate local features and SIFT descriptor [ 21 ] to construct feature vectors .Rather than selecting features that persist over a wide interval of scales , beta - stable features are chosen at a scale so that the number of convex and concave regions of the image brightness function remains constant within a scale interval of length beta .", "label": "", "metadata": {}, "score": "56.847878"}
{"text": "Our first- , second- , and third - order models achieve accuracies comparable to those of their unpruned counterparts , while exploring only a fraction of the search space .We observe speed - ups of up to two orders of magnitude compared to exhaustive search .", "label": "", "metadata": {}, "score": "56.91378"}
{"text": "This can be integrated with ModelFetcher ( if the model is already installed , download_and_install_model is a no - op ) : .You can also load parser and reranker models manually : .Parsing a single sentence and reading information about the top parse with parse ( ) .", "label": "", "metadata": {}, "score": "56.93798"}
{"text": "Our work is also the first attempt to use the same automatically - learned grammar for both parsing and generation .Unlike previous systems that require manually - constructed grammars and lexicons , our systems require much less knowledge engineering and can be easily ported to other languages and domains .", "label": "", "metadata": {}, "score": "57.0133"}
{"text": "This may be caused by overfitting since our model has to use more parameters to encode more contextual dependencies .From the results in the last row of Table 1 , we can see that incorporating the weights of neighborhood structures is important since the performance of such a model dropped .", "label": "", "metadata": {}, "score": "57.06809"}
{"text": "A mixture grammar fit with the EM algorithm shows improvement over a single PCFG , both in parsing accuracy and in test data likelihood .We argue that this improvement comes from the learning of specialized grammars that capture non - local correlations .", "label": "", "metadata": {}, "score": "57.28997"}
{"text": "We have designed and implemented two PCFG - based probabilistic parsing architectures for parsing unseen text into f - structures : the pipeline and the integrated model .Both architectures parse raw text into basic , but possibly incomplete , predicate - argument structures ( \" proto f - structures \" ) with long distance dependencies ( LDDs ) unresolved ( Cahill et al . , 2002c ) .", "label": "", "metadata": {}, "score": "57.354576"}
{"text": "Experimental results show that the number of examples needed to reach a given level of performance can be significantly reduced with this method .ML ID : 90 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixth Workshop on Very Large Corpora , Montreal , Quebec , Canada , August 1998 .", "label": "", "metadata": {}, "score": "57.40408"}
{"text": "Specifically , an ini- tial hypothesis lattice is constrcuted using local features .Candidate sentences are then assigned syntactic language model scores .These global syntactic scores are combined with local low - level scores in a log - linear model .", "label": "", "metadata": {}, "score": "57.458923"}
{"text": "We have also ported our grammar induction methodology to German and the TIGER treebank resource ( Cahill et al . , 2003a ) .We have developed a method for treebank - based , wide - coverage , deep , constraintbased grammar acquisition .", "label": "", "metadata": {}, "score": "57.517975"}
{"text": "The goals of the optimization problem are two - fold : keep the new weight vector as close to the current weight vector as possible ; and score the true best candidate higher than the predicted candidate by their quality difference .", "label": "", "metadata": {}, "score": "57.59326"}
{"text": ".. a top - scoring MT system in the Chinese newswire track of the 2008 NIST evaluation .However , except for ( Fraser and Marcu , 2007b ) , none of these advances in alignment quality has improv ... . \" ...", "label": "", "metadata": {}, "score": "57.864098"}
{"text": "Unlike existing preordering models , we train feature - rich discriminative classifiers that directly predict the target - side word order .Our approach combines the strengths of lexical reordering and syntactic preordering models by performing long - distance reorderings using the structure of the parse tree , while utilizing a discriminative model with a rich set of features , including lexical features .", "label": "", "metadata": {}, "score": "57.888016"}
{"text": "We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process ( HDP ) .Our HDP - PCFG model allows the complexity of the grammar to grow as more training data is available .In addition to presenting a fully Bayesian model for the PCFG , we also develop an efficient variational inference procedure .", "label": "", "metadata": {}, "score": "57.918755"}
{"text": "If the aggregated evidence at this locus supports less than K candidate gene models , all possible models will be generated .In the original Viterbi decoding implementation of Evigan , an optimal path may contain multiple genes , whereas in the implementation of the K -best decoder only single - gene paths are returned .", "label": "", "metadata": {}, "score": "58.064705"}
{"text": "All images are resized to . used in the weighted neighborhood structure is set to 0.7 to encourage the use of shape information .Due to space constraints , we provide a few examples of the detection results ( as shown in Figure 5 ) .", "label": "", "metadata": {}, "score": "58.239014"}
{"text": "With 100 K unlabeled and 2 K labeled questions , uptraining is able to improve parsing accuracy to 84 % , closing the gap between in - domain and out - of - domain performance .We study self - training with products of latent variable grammars in this paper .", "label": "", "metadata": {}, "score": "58.41539"}
{"text": "We show that our method performs overall better and faster than previous approaches in both domains .ML ID : 160 .Learning Transformation Rules for Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate , Yuk Wah Wong , Ruifang Ge , and Raymond J. Mooney April 2004 .", "label": "", "metadata": {}, "score": "58.420673"}
{"text": "We also discuss the more general , and computationally more difficult , problem of finding good parsing strategies for non - binarizable rules , and present an approximate polynomial - time algorithm for this problem . \" ...For many years , statistical machine translation relied on generative models to provide bilingual word alignments .", "label": "", "metadata": {}, "score": "58.422894"}
{"text": "International Conference on Machine Learning ( ICML ' 01 ) , pp .282 - 289 , 2001 .S. Kumar and M. Hebert , \" Discriminative fields for modeling spatial dependencies in natural images , \" Advances in Neural Information Processing Systems , pp .", "label": "", "metadata": {}, "score": "58.43584"}
{"text": "It first runs a ( simpler ) PCFG parser and then an untyped dependency parser , and then runs a third parser which finds the parse with the best joint score across the two other parsers via a product model .This is described in the NIPS Fast Exact Inference paper .", "label": "", "metadata": {}, "score": "58.491295"}
{"text": "The resulting grammars are extremely compact com- pared to other high - performance parsers , yet the parser gives the best published accuracies on several languages , as well as the best generative parsing numbers in English .In addi- tion , we give an associated coarse - to - fine inference scheme which vastly improves inference time with no loss in test set accuracy .", "label": "", "metadata": {}, "score": "58.67669"}
{"text": "We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system .We use a corpus of weakly - labeled reference reorderings to guide parser training .Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress .", "label": "", "metadata": {}, "score": "58.74125"}
{"text": "Our best results show a 26-fold speedup compared to a sequential C implementation .We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data .We first demonstrate that delexicalized parsers can be directly transferred between languages , producing significantly higher accuracies than unsupervised parsers .", "label": "", "metadata": {}, "score": "58.901257"}
{"text": "The two models we present overcome such limitations by employing a learned semantic lexicon as a basic correspondence unit between NL and MR for PCFG rule generation .Finally , we present a method of adapting discriminative reranking to grounded language learning in order to improve the performance of our proposed generative models .", "label": "", "metadata": {}, "score": "59.025066"}
{"text": "Proceedings of the Human Language Technology Conference of the NAACL , Companion Volume : Short Papers Not Logged In . bllipparser 2014.02.09 .The BLLIP parser ( also known as the Charniak - Johnson parser or Brown Reranking Parser ) is described in the paper Charniak and Johnson ( Association of Computational Linguistics , 2005 ) .", "label": "", "metadata": {}, "score": "59.062256"}
{"text": "We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser .Existing methods incrementally expand the lexicon by greedily adding entries , considering a single training datapoint at a time .We propose using corpus - level statistics for lexicon learning decisions .", "label": "", "metadata": {}, "score": "59.07029"}
{"text": "We present a new approach to learning a semantic parser ( a system that maps natural language sentences into logical form ) .Unlike previous methods , it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .", "label": "", "metadata": {}, "score": "59.124672"}
{"text": "When the model is finished training , or when you want to test one of the intermediate models , you can run it using the standard LexicalizedParser commands .In our experiments , we found that simpler PCFG models actually make better underlying PCFG models .", "label": "", "metadata": {}, "score": "59.16452"}
{"text": "Latent variable grammars take an observed ( coarse ) treebank and induce more fine - grained grammar categories , that are better suited for modeling the syntax of natural languages .Estimation can be done in a generative or a discriminative framework , and results in the best published parsing accuracies over a wide range of syntactically divergent languages and domains .", "label": "", "metadata": {}, "score": "59.18795"}
{"text": "View at Google Scholar .S. Kumar and M. Hebert , \" Discriminative random fields : A discriminative framework for contextual interaction in classification , \" in Proceedings of the International Conference on Computer Vision ( ICCV ' 03 ) , vol .", "label": "", "metadata": {}, "score": "59.217484"}
{"text": "In addition to producing gapless local alignments , DiAlign also provides for each segment an alignment score , which is basically the negative logarithm of the probability that two random sequences can be aligned as well as these two sequences .The sequence similarity feature f 4 ( t ) is given by normalizing the alignment score by the length of r , or .", "label": "", "metadata": {}, "score": "59.265053"}
{"text": "They also permit the use of well - understood , generalpurpose learn ... \" .Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .Their symbolic component is amenable to inspection by humans , while their probabilistic component helps resolve ambiguity .", "label": "", "metadata": {}, "score": "59.36308"}
{"text": "However , it is not always possible to restrict the set of possible alignments to such limited numbers .Thus , we present another system that allows each sentence to be aligned to one of exponentially many connected subgraphs without explicitly enumerating them .", "label": "", "metadata": {}, "score": "59.37127"}
{"text": "We also show that our techniques can be applied to full - scale parsing applications by demonstrating its effectiveness in learning state - split grammars .Treebank parsing can be seen as the search for an optimally refined grammar consistent with a coarse training treebank .", "label": "", "metadata": {}, "score": "59.41868"}
{"text": "Most recent work on semantic analysis of natural language has focused on ' ' shallow ' ' semantics such as word - sense disambiguation and semantic role labeling .Our work addresses a more ambitious task we call semantic parsing where natural language sentences are mapped to complete formal meaning representations .", "label": "", "metadata": {}, "score": "59.482765"}
{"text": "In the future , we intend to pursue several directions in developing more accurate semantic parsing algorithms and automating the annotation process .This work will involve exploring alternative tree representations for better generalization in parsing .We also plan to apply discriminative reranking methods to semantic parsing , which allows exploring arbitrary , potentially correlated features not usable by the baseline learner .", "label": "", "metadata": {}, "score": "59.560127"}
{"text": "We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .", "label": "", "metadata": {}, "score": "59.624344"}
{"text": "This paper presents a general framework , learning search - control heuristics for logic programs , which can be used to improve both the efficiency and accuracy of knowledge - based systems expressed as definite - clause logic programs .The approach combines techniques of explanation - based learning and recent advances in inductive logic programming to learn clause - selection heuristics that guide program execution .", "label": "", "metadata": {}, "score": "59.647194"}
{"text": "ML ID : 273 . \"Grounded \" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts .Borschinger et al .( 2011 ) introduced an approach to grounded language learning based on unsupervised PCFG induction .", "label": "", "metadata": {}, "score": "59.64801"}
{"text": "Second , how can we efficiently infer optimal structures within them ?Hierarchical coarse - to - fine methods address both questions .Coarse - to - fine approaches exploit a sequence of models which introduce complexity gradually .At the top of the sequence is a trivial model in which learning and inference are both cheap .", "label": "", "metadata": {}, "score": "60.098022"}
{"text": "For example , noun phrases might be split into subcategories for subjects and objects , singular and plural , and so on .This splitting process admits an efficient incremental inference scheme which reduces parsing times by orders of magnitude .Furthermore , it produces the best parsing accuracies across an array of languages , in a fully language - general fashion .", "label": "", "metadata": {}, "score": "60.158077"}
{"text": "We present an approach to multilingual grammar induction that exploits a phylogeny - structured model of parameter drift .Our method does not require any translated texts or token - level alignments .Instead , the phylogenetic prior couples languages at a parameter level .", "label": "", "metadata": {}, "score": "60.214363"}
{"text": "We present an approach to multilingual grammar induction that exploits a phylogeny - structured model of parameter drift .Our method does not require any translated texts or token - level alignments .Instead , the phylogenetic prior couples languages at a parameter level .", "label": "", "metadata": {}, "score": "60.214363"}
{"text": "In such models , each part is generally represented by small templates or local image feature information , and the whole object is modeled as a collection of parts with or without geometric and cooccurrence constraints .The final discriminate of object is achieved by solving the probability density function or using a Hough vote mechanism .", "label": "", "metadata": {}, "score": "60.29379"}
{"text": "The same conceptual strategy could readily be applied to candidate gene models produced by other annotation pipelines as well as accommodate diverse sources of evidence in place of or in addition to comparative genomics data .For example , one can easily envision further improving gene models selection by reranking based on protein sequence motifs or signals , transcript or protein expression data , etc .", "label": "", "metadata": {}, "score": "60.315575"}
{"text": "Because each refinement introduces only limited complexity , both learning and inference can be done in an incremental fashion .In this dissertation , we describe several coarse - to - fine systems .In the domain of syntactic parsing , complexity is in the grammar .", "label": "", "metadata": {}, "score": "60.330906"}
{"text": "Next , I present a PCFG induction model for grounded language learning that extends the model of Borschinger , Jones , and Johnson ( 2011 ) by utilizing a semantic lexicon .Our model overcomes such limitations by employing a semantic lexicon as the basic building block for PCFG rule generation .", "label": "", "metadata": {}, "score": "60.375908"}
{"text": "We obtain gains in ... \" .Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .We present an algorithm for identifying and deleting incorrect word alignment links , using features of the extracted rules .", "label": "", "metadata": {}, "score": "60.487495"}
{"text": "View Article PubMed .Gross S , Do C , Batzoglou S : CONTRAST : de novo gene prediction using a semi - Markov conditional random field .BCATS 2005 Symposium Proceedings 2005 , 82 .Huang X : Fast comparison of a DNA sequence with a protein sequence database .", "label": "", "metadata": {}, "score": "60.54606"}
{"text": "This is a rather simplified approach for identifying orthologs but in practice it produces reasonably good results .More comprehensive approaches would be searching all candidate models of a gene against the reference proteins or examining multiple species and phylogentic relationships between the species [ 36 , 43 ] .", "label": "", "metadata": {}, "score": "60.54737"}
{"text": "Finally , we test the system on an alternate sentence representation , and on a set of large , artificial corpora with varying levels of ambiguity and synonymy .One difficulty in using machine learning methods for building natural language interfaces is building the required annotated corpus .", "label": "", "metadata": {}, "score": "60.58451"}
{"text": "International Conference on Computational Linguistics ( COLING 2010 ) , 543 - -551 , Beijing , China , August 2010 .We present a probabilistic generative model for learning semantic parsers from ambiguous supervision .Our approach learns from natural language sentences paired with world states consisting of multiple potential logical meaning representations .", "label": "", "metadata": {}, "score": "60.737186"}
{"text": "Yes , you can .However , for good results , you should make sure that you provide correctly tokenized input and use exactly the correct tag names .( That is , the input must be tokenized and normalized exactly as the material in the treebank underlying the grammar is . )", "label": "", "metadata": {}, "score": "60.78271"}
{"text": "The paper gives a very efficient algorithm to compute it .This kernel is also an improvement over the word subsequence kernel because it only counts linguistically meaningful word subsequences which are based on word dependencies .It overcomes some of the difficulties encountered by syntactic tree kernels as well .", "label": "", "metadata": {}, "score": "60.805336"}
{"text": "Starting from a mono - phone model , we learn increasingly refined models that capture phone internal structures , as well as context - dependent variations in an automatic way .Our approaches reduces error rates compared to other baseline approaches , while streamlining the learning procedure .", "label": "", "metadata": {}, "score": "60.8494"}
{"text": "An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job - search queries .ML ID : 75 .An Inductive Logic Programming Method for Corpus - based Parser Construction [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney January 1997 .", "label": "", "metadata": {}, "score": "60.950302"}
{"text": "Moreover , learning the class density models may become even harder when the training data is limited [ 10 ] .In this paper , we focus on the discriminative random field model , called conditional random field ( CRF ) , which is originally proposed by Lafferty et al .", "label": "", "metadata": {}, "score": "60.9609"}
{"text": "Memory usage expands roughly with the square of the sentence length .You may wish to set a -maxLength and to skip long sentences .The factored parser requires several times as much memory as just running the PCFG parser , since it runs 3 parsers .", "label": "", "metadata": {}, "score": "61.021217"}
{"text": "Experimental results are presented demonstrating WOLFIE 's ability to learn useful lexicons for a database interface in four different natural languages .The lexicons learned by WOLFIE are compared to those acquired by a competing system developed by Siskind ( 1996 ) .", "label": "", "metadata": {}, "score": "61.028584"}
{"text": "Syntactic parsing is a fundamental problem in computational linguistics and natural language processing .Traditional approaches to parsing are highly complex and problem specific .Recently , Sutskever et al .( 2014 ) presented a task - agnostic method for learning to map input sequences to output sequences that achieved strong results on a large scale machine translation problem .", "label": "", "metadata": {}, "score": "61.133095"}
{"text": "Here we evaluate seven different POS induction systems spanning nearly 20 years of work , using a variety of measures .We show that some of the oldest ( and simplest ) systems stand up surprisingly well against more recent approaches .", "label": "", "metadata": {}, "score": "61.472347"}
{"text": "ML ID : 45 .Learning Semantic Grammars With Constructive Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In Proceedings of the 11th National Conference on Artificial Intelligence , 817 - 822 , 1993 .", "label": "", "metadata": {}, "score": "61.507557"}
{"text": "We introduce a semi - supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word - alignment quality on a small , manually word - aligned sub ... \" .", "label": "", "metadata": {}, "score": "61.524582"}
{"text": "S. Y. Chen , H. Tong , and C. Cattani , \" Markov models for image labeling , \" Mathematical Problems in Engineering , vol .2012 , Article ID 814356 , 18 pages , 2012 .View at Publisher \u00b7 View at Google Scholar .", "label": "", "metadata": {}, "score": "61.55004"}
{"text": "Standard inference can be used at test time .Our approach is able to scale to very large problems and yields significantly improved target domain accuracy .It is well known that parsing accuracies drop significantly on out - of - domain data .", "label": "", "metadata": {}, "score": "61.5881"}
{"text": "Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output , but are often very computationally intensive .The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two langu ... \" .", "label": "", "metadata": {}, "score": "61.607964"}
{"text": "Previous sentence segmentation systems have typically been very local , using low - level prosodic and lexical features to independently decide whether or not to segment at each word boundary position .In this work , we leverage global syntactic information from a syn- tactic parser , which is better able to capture long distance depen- dencies .", "label": "", "metadata": {}, "score": "61.665424"}
{"text": "663 - 676 , 2010 .View at Publisher \u00b7 View at Google Scholar . D. G. Lowe , \" Object recognition from local scale - invariant features , \" in Proceedings of the 7th IEEE International Conference on Computer Vision ( ICCV'99 ) , pp .", "label": "", "metadata": {}, "score": "61.71599"}
{"text": "All of these gene finders effectively incorporate cross - species information , achieving improvement in prediction accuracy over single - species gene finders , although doing so often requires significant effort in model and algorithm design and implementation to cast comparative information into a form compatible with the existing gene models .", "label": "", "metadata": {}, "score": "61.798237"}
{"text": "ML ID : 314 .Semantic Parsing using Distributional Semantics and Probabilistic Logic [ Details ] [ PDF ][Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .", "label": "", "metadata": {}, "score": "61.911423"}
{"text": "In general , though , you should not use this part of the feature and simply use \" .Yes , for the PCFG parser ( only ) .With a PCFG parser , you can give the option -printPCFGkBest n and it will print the n highest - scoring parses for a sentence .", "label": "", "metadata": {}, "score": "61.91629"}
{"text": "Preliminary experimental results show that this system can learn correct and useful mappings .The correctness is evaluated by comparing a known lexicon to one learned from the training input .The usefulness is evaluated by examining the effect of using the lexicon learned by WOLFIE to assist a parser acquisition system , where previously this lexicon had to be hand - built .", "label": "", "metadata": {}, "score": "62.042793"}
{"text": "In a complete database - query application , parsers learned by CHILL outperform an existing hand - crafted system , demonstrating the promise of empricial techniques for automating the construction certain NLP systems .ML ID : 71 .Semantic Lexicon Acquisition for Learning Parsers [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney 1997 .", "label": "", "metadata": {}, "score": "62.11068"}
{"text": "The k best parses are extracted efficiently using the algorithm of Huang and Chiang ( 2005 ) .This may be because the parser chose an incorrect structure for your sentence , or because the phrase structure annotation conventions used for training the parser do n't match your expectations .", "label": "", "metadata": {}, "score": "62.114025"}
{"text": "We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .The main innovation of WASP is its use of state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}, "score": "62.141663"}
{"text": "We describe experiments on learning latent variable grammars for various German treebanks , using a language - agnostic statistical approach .In our method , a minimal initial grammar is hierarchically refined using an adaptive split - and - merge EM procedure , giving compact , accurate grammars .", "label": "", "metadata": {}, "score": "62.25532"}
{"text": "[ 9 ] developed a hierarchical probabilistic model to capture the complex structure in multiple object scenes .However , generative approaches often can not compete with discriminative manner in the field of object category detection .The generative framework has natural drawback that it has to assume the independence of the observed data to make the model computationally .", "label": "", "metadata": {}, "score": "62.34686"}
{"text": "On full - scale treebank parsing experiments , the discriminative latent models outperform both the comparable generative latent models as well as the discriminative non - latent baselines .We present a maximally streamlined approach to learning HMM - based acoustic models for automatic speech recognition .", "label": "", "metadata": {}, "score": "62.352413"}
{"text": "We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for the use of arbitrary and overlapping features over these data .", "label": "", "metadata": {}, "score": "62.447487"}
{"text": "Uncontrolled Keywords : .Lexical - Functional Grammar ; LFG ; Treebank Tool Suite ; TTS ; constraint - based grammatical resources Affiliated with .Abstract .Background .Most gene finders score candidate gene models with state - based methods , typically HMMs , by combining local properties ( coding potential , splice donor and acceptor patterns , etc ) .", "label": "", "metadata": {}, "score": "62.45318"}
{"text": "A variety of features were extracted from candidate gene models , including the posterier probabilities defined by Evigan and various similarity features determined by comparison with orthologous proteins / gene models .Note that these features could readily be expanded to include additional informative similarity features .", "label": "", "metadata": {}, "score": "62.460793"}
{"text": "It does not attempt to determine grammaticality , though it will normally prefer a \" grammatical \" parse for a sentence if one exists .This is appropriate in many circumstances , such as when wanting to interpret user input , or dealing with conversational speech , web pages , non - native speakers , etc . .", "label": "", "metadata": {}, "score": "62.593452"}
{"text": "We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task .For languages from different families the improvements often exceed 2 BLEU .Many of these gains are also significant in human evaluations .We present a new collection of treebanks with homogeneous syntactic dependency annotation for six languages : German , English , Swedish , Spanish , French and Korean .", "label": "", "metadata": {}, "score": "62.66051"}
{"text": "This paper presents an approach for inducing transformation rules that map natural - language sentences into a formal semantic representation language .The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .", "label": "", "metadata": {}, "score": "62.72113"}
{"text": "Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .In this paper , we demonstrate a discriminative approach to training simple word alignment models that are comparable in accuracy to the more complex generative models normally used .", "label": "", "metadata": {}, "score": "62.734097"}
{"text": "Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .", "label": "", "metadata": {}, "score": "62.747665"}
{"text": "By contrast , Quattoni et al . presented an expansion graph structure of CRF framework [ 15 ] that uses hidden variables , which are not observed during training , to represent the assignment of parts .Moreover , located CRF model [ 16 ] , proposed by Kapoor and Winn , introduces global positions to the hidden variables and can model the long - range spatial configuration and local interactions simultaneously .", "label": "", "metadata": {}, "score": "62.77487"}
{"text": "As output Evigan provides a list of the K gene models with the highest probabilities according to its evidence integration network .The CONTRAST [ 10 ] gene finder predicts D. melanogaster genes based on conservation with a reference species genome , motivated by the assumption that coding sequence is more likely to be conserved than non - coding sequence .", "label": "", "metadata": {}, "score": "62.7848"}
{"text": "Experiments show the potential of the approach .ML ID : 301 .Grounded Language Learning Models for Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joo Hyun Kim PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2013 .", "label": "", "metadata": {}, "score": "62.78917"}
{"text": "Unlike conventional reranking used in syntactic and semantic parsing , gold - standard reference trees are not naturally available in a grounded setting .Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .", "label": "", "metadata": {}, "score": "62.89645"}
{"text": "Experimental results are presented that demonstrate WOLFIE 's ability to learn useful lexicons for a realistic domain .The lexicons learned by WOLFIE are also compared to those learned by another lexical acquisition system , that of Siskind ( 1996 ) .", "label": "", "metadata": {}, "score": "62.929005"}
{"text": "Invited paper .Semantic parsing is the task of mapping a natural language sentence into a complete , formal meaning representation .Over the past decade , we have developed a number of machine learning methods for inducing semantic parsers by training on a corpus of sentences paired with their meaning representations in a specified formal language .", "label": "", "metadata": {}, "score": "63.06535"}
{"text": "ReRanker selected the second to the fifth most probable Evigan model in 820 genes , the sixth to the tenth most probable model in 228 genes ; and even lower probability models for 698 genes .Performance by rank on Drosophila melanogaster .", "label": "", "metadata": {}, "score": "63.08304"}
{"text": "The hierarchical graphical structure of our contextual hierarchical part - driven CRF model is shown as Figure 1 . can be modeled as CRFs .Thus , the whole model can be seen as the combination of two single - layer CRFs .", "label": "", "metadata": {}, "score": "63.093548"}
{"text": "Below are some statistics for 32-bit operation with the supplied englishPCFG and englishFactoredGrammars .We have parsed sentences as long as 234 words , but you need lots of RAM and patience .You can use the -outputFormat wordsAndTags option .", "label": "", "metadata": {}, "score": "63.131554"}
{"text": "We present a new generative alignment model which avoids these structural limitations , and show that it is effective when trained using both unsupervised and semi - supervised training methods . ... lar to work using discriminative log - linear models for alignment , which is similar to discriminative log - linear models used for the SMT decoding ( translation ) problem ( Och and Ney , 2002 ; Och , 2003 ) .", "label": "", "metadata": {}, "score": "63.16426"}
{"text": "Besides being robust , this approach is also flexible and able to learn under a wide range of supervision , from extra to weaker forms of supervision .It can easily utilize extra supervision given in the form of syntactic parse trees for natural language sentences by using a syntactic tree kernel instead of a string kernel .", "label": "", "metadata": {}, "score": "63.25483"}
{"text": "Meanwhile , beta - stable local features are introduced as observed data to ensure the discriminative and robustness of part description .The object category detection problem can be solved in a probabilistic framework using a supervised learning method based on maximum a posteriori ( MAP ) estimation .", "label": "", "metadata": {}, "score": "63.426003"}
{"text": "Empirical methods for building natural language systems has become an important area of research in recent years .Most current approaches are based on propositional learning algorithms and have been applied to the problem of acquiring broad - coverage parsers for relatively shallow ( syntactic ) representations .", "label": "", "metadata": {}, "score": "63.441406"}
{"text": "By using a top - down approach to heuristically guide the construction of generalizations of a bottom clause , Beth combines the strength of both approaches .Learning patterns for detecting potential terrorist activity is a current challenge problem for relational data mining .", "label": "", "metadata": {}, "score": "63.441635"}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .", "label": "", "metadata": {}, "score": "63.495514"}
{"text": "We have investigated the utility of a simple post - processing step for selecting among a set of alternative gene models , using global scoring rules to rerank competing models for more accurate prediction .For each gene locus , we first generate the K best candidate gene models using the gene finder Evigan , and then rerank these models using comparisons with putative orthologous genes from closely - related species .", "label": "", "metadata": {}, "score": "63.561226"}
{"text": "The parsing and generation algorithms learn all of their linguistic knowledge from annotated corpora , and can handle natural - language sentences that are conceptually complex .A nice feature of our algorithms is that the semantic parsers and tactical generators share the same learned synchronous grammars .", "label": "", "metadata": {}, "score": "63.73012"}
{"text": "In this paper , we suggest an alternative to the Dirichlet prior , a family of logistic normal distributions .We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction , demonstrating performance improvements with our priors on a set of six treebanks in different natural languages .", "label": "", "metadata": {}, "score": "63.80394"}
{"text": "Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers .ML ID : 200 .Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus [ Details ] [ PDF ] Yuk Wah Wong and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL-2007 ) , Prague , Czech Republic , June 2007 .", "label": "", "metadata": {}, "score": "63.83985"}
{"text": "We present experiments with sequence models on part - of - speech tagging and named entity recognition tasks , and with syntactic parsers on dependency parsing and machine translation reordering tasks .Low - latency solutions for syntactic parsing are needed if parsing is to become an integral part of user - facing natural language applications .", "label": "", "metadata": {}, "score": "63.86608"}
{"text": "ML ID : 99 .Learning for Semantic Interpretation : Scaling Up Without Dumbing Down [ Details ] [ PDF ] Raymond J. Mooney In Workshop Notes for the Workshop on Learning Language in Logic , 7 - 15 , Bled , Slovenia , 2000 .", "label": "", "metadata": {}, "score": "63.94105"}
{"text": "However , I believe that logical approaches may have the most relevance and impact at the level of semantic interpretation , where a logical representation of sentence meaning is important and useful .We have explored the use of inductive logic programming for learning parsers that map natural - language database queries into executable logical form .", "label": "", "metadata": {}, "score": "63.96766"}
{"text": "Programmatically , you can do the same things by creating a TokenizerFactory with the appropriate options , such as : .getWordsFromString(str ) ) ; .There is nevertheless a potential cost of making tokenization changes .This normalization was added in the first place because the parser is trained on American English , normalized according to Penn Treebank conventions .", "label": "", "metadata": {}, "score": "64.035164"}
{"text": "Or it may be because the parser made a mistake .While our goal is to improve the parser when we can , we ca n't fix individual examples .The parser is just choosing the highest probability analysis according to its grammar .", "label": "", "metadata": {}, "score": "64.03565"}
{"text": "Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing computing systems that understand natural language input .This thesis presents a new machine learning approach for semantic parsing based on string - kernel - based classification .", "label": "", "metadata": {}, "score": "64.07856"}
{"text": "Experimental results with a complete database - query application for U.S. geography show that CHILL is able to learn parsers that outperform a pre - existing , hand - crafted counterpart .These results demonstrate the ability of a corpus - based system to produce more than purely syntactic representations .", "label": "", "metadata": {}, "score": "64.13548"}
{"text": "This means that the final object label only relies on the latent middle - level labels rather than on the original observations .The hypothesis makes sense because it is theoretically possible that we estimate the object or background occurrence by the spatial distribution of meaningful object parts in real world .", "label": "", "metadata": {}, "score": "64.18845"}
{"text": "They can also provide insight into important issues in human language acquisition .However , within AI , computational linguistics , and machine learning , there has been relatively little research on developing systems that learn such semantic parsers .This paper briefly reviews our own work in this area and presents semantic - parser acquistion as an important challenge problem for AI .", "label": "", "metadata": {}, "score": "64.20736"}
{"text": "Future work includes extending the algorithm and performing tests on a more realistic corpus .ML ID : 56 .Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers [ Details ] [ PDF ] John M. Zelle PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , 1995 .", "label": "", "metadata": {}, "score": "64.218124"}
{"text": "Weight estimation .The parameter weight vector w in the scoring function is estimated from a training set D to optimize reranking accuracy using the MIRA online large - margin learning algorithm [ 46 ] .In our experiments , q k is the exon - level F - score ( harmonic mean of sensitivity and specificity ) for t k relative to the reference annotation genes at t k 's locus .", "label": "", "metadata": {}, "score": "64.23546"}
{"text": "People are often confused about how to get from that example to parsing paragraphs of text .You need to split the text into sentences first and then to pass each sentence to the parser .To do that , we use the included class DocumentPreprocessor .", "label": "", "metadata": {}, "score": "64.37465"}
{"text": "However , this hard constraint can also rule out correct alignments , and its utility decreases as alignment models become more ... \" .Word alignment methods can gain valuable guidance by ensuring that their alignments maintain cohesion with respect to the phrases specified by a monolingual dependency tree .", "label": "", "metadata": {}, "score": "64.44833"}
{"text": "Such features provide a sparse and repeatable manner to express object parts and actually reduce the computation complexity of the model .The remainder of this paper is organized as follows .Section 2 gives detailed introduction on the proposed contextual hierarchical part - driven CRF Model .", "label": "", "metadata": {}, "score": "64.45104"}
{"text": "N06 - 1054 [ bib ] : Roy Tromble ; Jason Eisner A fast finite - state relaxation method for enforcing global constraints on sequence decoding .N06 - 1055 [ bib ] : Nianwen Xue Semantic role labeling of nominalized predicates in Chinese .", "label": "", "metadata": {}, "score": "64.54377"}
{"text": "If you want to obtain the same results , you can either POS - tag your corpus before tagging it ( see # 12 ) or you can disable the POS tagger in CoreNLP by updating the list of annotators : .", "label": "", "metadata": {}, "score": "64.55344"}
{"text": "We present a system that learns to transform natural - language navigation instructions into executable formal plans .Given no prior linguistic knowledge , the system learns by simply observing how humans follow navigation instructions .The system is evaluated in three complex virtual indoor environments with numerous objects and landmarks .", "label": "", "metadata": {}, "score": "64.615875"}
{"text": "In the recent literature the alignment task has frequently been decoupled from the translation task , and assumptions have been made about measuring alignment quality for machine translation which , it turns out , are not justified .In particular , none of the tens of papers published over the last five years has shown that significant decreases in Alignment Error Rate , AER ( Och and Ney , 2003 ) , result in significant increases in translation quality .", "label": "", "metadata": {}, "score": "64.6185"}
{"text": "Conclusion .In this paper we presented a contextual hierarchical part - driven CRF model for object category detection .By incorporating two single - level models , the proposed model can effectively represent latent label - level context and observation - level context simultaneously .", "label": "", "metadata": {}, "score": "64.642426"}
{"text": "ML ID : 229 .A Dependency - based Word Subsequence Kernel [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the conference on Empirical Methods in Natural Language Processing ( EMNLP-2008 ) , 400 - -409 , Waikiki , Honolulu , Hawaii , October 2008 .", "label": "", "metadata": {}, "score": "64.67351"}
{"text": "Soong F , Huang E : A tree - trellis based fast search for finding the N - best sentence hypotheses in continuous speech recognition .Proceedings of ICASSP-91 IEEE Computer Society 1991 , 705 - 708 .Altschul SF , Gish W , Miller W , Myers EW , Lipman DJ : Basic local alignment search tool .", "label": "", "metadata": {}, "score": "64.722916"}
{"text": "In recent years there has been considerable interest in corpus - based methods for constructing natural language parsers .These empirical approaches replace hand - crafted grammars with linguistic models acquired through automated training over language corpora .A common thread among such methods to date is the use of propositional or probablistic representations for the learned knowledge .", "label": "", "metadata": {}, "score": "64.76852"}
{"text": "In this case , it would download WSJ and install it to /tmp / models / WSJ .Note that it returns the path to the downloaded model .Basic usage .The easiest way to construct a parser is with the from_unified_model_dir class method .", "label": "", "metadata": {}, "score": "64.87875"}
{"text": "To manage this complexity , we translate into target language clusterings of increasing vocabulary size .This approach gives dramatic speed - ups while additionally increasing final translation quality .The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .", "label": "", "metadata": {}, "score": "64.91937"}
{"text": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .", "label": "", "metadata": {}, "score": "64.98924"}
{"text": "Specifically , I will present two probabilistic generative models for learning such correspondences .The models are applied to two publicly available datasets in two different domains , sportscasting and navigation , and compared with previous work on the same data .", "label": "", "metadata": {}, "score": "65.12067"}
{"text": "State - of - the - art natural language processing models are anything but compact .Syntactic parsers have huge grammars , machine translation systems have huge transfer tables , and so on across a range of tasks .With such complexity come two challenges .", "label": "", "metadata": {}, "score": "65.2497"}
{"text": "This paper presents approaches for automatically transforming a meaning representation grammar ( MRG ) to conform it better with the natural language semantics .It introduces grammar transformation operators and meaning representation macros which are applied in an error - driven manner to transform an MRG while training a semantic parser learning system .", "label": "", "metadata": {}, "score": "65.28089"}
{"text": "In particular , functional and comparative genomics datasets may help to select among competing models of comparable probability by exploiting features likely to be associated with the correct gene models , such as conserved exon / intron structure or protein sequence features .", "label": "", "metadata": {}, "score": "65.312836"}
{"text": "Toward this goal , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .", "label": "", "metadata": {}, "score": "65.35402"}
{"text": "Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing user - friendly natural language interfaces to computing systems .Most of the research in natural language understanding , however , has mainly focused on shallow semantic analysis like case - role analysis or word sense disambiguation .", "label": "", "metadata": {}, "score": "65.41163"}
{"text": "Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries .ML ID : 219 .Learning for Semantic Parsing with Kernels under Various Forms of Supervision [ Details ] [ PDF ] [ Slides ] Rohit J. Kate PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}, "score": "65.41745"}
{"text": "Here are example commands for parsing two of the test files , one in UTF-8 and one in GB18030 .The ( Linux ) computer that this is being run on is set up to work with UTF-8 ( and this webpage is also in UTF-8 ) , so for the case of GB18030 , the output is piped through the Unix iconv utility for display .", "label": "", "metadata": {}, "score": "65.56369"}
{"text": "[ 7 ] in 2003 , in which objects are modeled as flexible constellations of parts and the appearance , spatial relations , and cooccurrence of local parts are learned in an unsupervised manner .Felzenszwalb and Huttenlocher [ 8 ] proposed a pictorial structure model , in which deformable configuration is represented by spring - like connections between pairs of parts .", "label": "", "metadata": {}, "score": "65.604706"}
{"text": "The relatively poor performance of ReRanker-5 g would then follow from a relative lack of candidates in the source evidence : ReRanker-5 g is constrained to select from among the potential models suggested by Evigan-5 g , which performs relatively poorly on this subset .", "label": "", "metadata": {}, "score": "65.61199"}
{"text": "In general , with appropriate grammars loaded , you can parse with and ask for output of the PCFG , ( untyped ) dependency , or factored parsers .For English , although the grammars and parsing methods differ , the average quality of englishPCFG.ser.gz and englishFactored.ser.gz is similar , and so many people opt for the faster englishPCFG.ser.gz , though englishFactored.ser.gz sometimes does better because it does include lexicalization .", "label": "", "metadata": {}, "score": "65.734985"}
{"text": "N06 - 1021 [ bib ] : Simon Corston - Oliver ; Anthony Aue ; Kevin Duh ; Eric Ringger Multilingual Dependency Parsing using Bayes Point Machines .N06 - 1022 [ bib ] : Eugene Charniak ; Mark Johnson ; Micha Elsner ; Joseph Austerweil ; David Ellis ; Isaac Haxton ; Catherine Hill ; R. Shrivaths ; Jeremy Moore ; Michael Pozar ; Theresa Vu Multilevel Coarse - to - Fine PCFG Parsing .", "label": "", "metadata": {}, "score": "65.74453"}
{"text": "Motivated by these demands , we propose a novel contextual hierarchical part - driven conditional random field ( CRF ) model , which is based on not only individual object part appearance but also model contextual interactions of the parts simultaneously .", "label": "", "metadata": {}, "score": "65.804"}
{"text": "View Article PubMed .Collins M : Discriminative Reranking for Natural Language Parsing .Proc 17th International Conf on Machine Learning Morgan Kaufmann , San Francisco , CA 2000 , 175 - 182 .Shen L , Sarkar A , Och FJ : Discriminative Reranking for Machine Translation .", "label": "", "metadata": {}, "score": "65.93646"}
{"text": "ML ID : 68 .Learning to Parse Database Queries using Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In AAAI / IAAI , 1050 - 1055 , Portland , OR , August 1996 .", "label": "", "metadata": {}, "score": "65.95622"}
{"text": "We randomly split the images into two equal separate subsets for training and testing .Figure 4 shows the examples of the assignment of parts to local features for two object categories .It is apparent that the proposed model can effectively associate the mass of scattered and unordered observations with their corresponding object parts .", "label": "", "metadata": {}, "score": "65.96719"}
{"text": "Previous generative word alignment models have made structural assumptions such as the 1-to-1 , 1-to - N , or phrase - based consecutive word assumptions , while previous discriminative models have either made such ... \" .Word alignment is the problem of annotating parallel text with translational correspondence .", "label": "", "metadata": {}, "score": "65.98944"}
{"text": "I first present a historical view of the shifting emphasis of research on various tasks in natural language processing and then briefly review our own work on learning for semantic interpretation .I will then attempt to encourage others to study such problems and explain why I believe logical approaches have the most to offer at the level of producing semantic interpretations of complete sentences .", "label": "", "metadata": {}, "score": "66.08176"}
{"text": "The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two languages .We develop a theory of binarization for synchronous context - free grammars and present a linear - time algorithm for binarizing synchronous rules when possible .", "label": "", "metadata": {}, "score": "66.08292"}
{"text": "This HeadFinder will give consistent left - branching binarization .If you would like to also get out the true probabilities that a vanilla PCFG parser would produce , there are a couple more options that you need to set : . -smoothTagsThresh", "label": "", "metadata": {}, "score": "66.118065"}
{"text": "In the ortholog identification step , most of those wrong loci will be removed because they tend to not be associated with orthologs from a reference species .But it would be very useful to devise an additional step before reranking , to identify problematic loci and even recover correct locus information .", "label": "", "metadata": {}, "score": "66.140076"}
{"text": "In this thesis , we focus on devising effective models for simultaneously disambiguating such supervision and learning the underlying semantics of language to map NL sentences into proper logical MRs .We present probabilistic generative models for learning such correspondences along with a reranking model to improve the performance further .", "label": "", "metadata": {}, "score": "66.4883"}
{"text": "You can use it as follows : .There are several options , including one for batch - processing lots of files ; see the Javadoc documentation of the main method of PTBTokenizer .Parsing speed depends strongly on the distribution of sentence lengths - and on your machine , etc .", "label": "", "metadata": {}, "score": "66.49105"}
{"text": "In this paper , we explored a learning approach which combines different learning methods in inductive logic programming ( ILP ) to allow a learner to produce more expressive hypothese than that of each individual learner .Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method .", "label": "", "metadata": {}, "score": "66.49367"}
{"text": "In our method the first , monolingual view consists of supervised predictors learned separately for each language .The second , bilingual view consists of log - linear predictors learned over both languages on bilingual text .Our training procedure estimates the parameters of the bilingual model using the output of the monolingual model , and we show how to combine the two models to account for dependence between views .", "label": "", "metadata": {}, "score": "66.51512"}
{"text": "We have developed methods for automatically learning semantic parsers from annotated corpora using inductive logic programming and other learning methods .We have explored learning semantic parsers for mapping natural - language sentences to case - role analyses , formal database queries , and formal command languages ( i.e. the Robocup coaching language for use in advice - taking learners ) .", "label": "", "metadata": {}, "score": "66.52414"}
{"text": "Image Features .For the object category detection task , the robustness and distinctiveness are basic requirements for local features in order to provide powerful expression ability for objects .On the other hand , the quantity of features corresponds to the quantity of observations and has an enormous influence on computational complexity .", "label": "", "metadata": {}, "score": "66.600006"}
{"text": "The algorithm uses a similarity graph to encourage similar n - grams to have similar POS tags .We demonstrate the efficacy of our approach on a domain adaptation task , where we assume that we have access to large amounts of unlabeled data from the target domain , but no additional labeled data .", "label": "", "metadata": {}, "score": "66.618484"}
{"text": "Kumar and Herbert [ 12 , 13 ] first introduced the extension of 1D CRFs to 2D graphs over image and applied it to object detection .By treating object detection problem as a labeling problem , CRF model can not only flexibly utilize various heuristic image features , but also get the contextual interactions among image parts through its classic graphical structure .", "label": "", "metadata": {}, "score": "66.62583"}
{"text": "This strategy tends to identify relatively more target genes and thus enjoy higher sensitivity .For ReRanker , where putative ortholog detection is needed , if ortholog detection for a gene fails , ReRanker misses the opportunity to locate the gene and will thus show lower sensitivity .", "label": "", "metadata": {}, "score": "66.65497"}
{"text": "The option -smoothTagsThresh 0 stops any probability mass being reserved for unknown words .Naturally , such a parser will be unable to parse any sentence with unknown words in it .The 2003 unlexicalized parsing paper lists several modifications that gradually improve the performance of the Stanford parser for English .", "label": "", "metadata": {}, "score": "66.82981"}
{"text": "I will first present a system we completed that can describe events in RoboCup 2D simulation games by learning only from sample language commentaries paired with traces of simulated activities without any language - specific prior knowledge .By applying an EM - like algorithm , the system was able to simultaneously learn a grounded language model as well as align the ambiguous training data .", "label": "", "metadata": {}, "score": "66.84123"}
{"text": "Our research further demonstrates the breadth of the applicability of neural network methods to dependency parsing , as well as the ease with which new features can be added to neural parsing models .We present structured perceptron training for neural network transition - based dependency parsing .", "label": "", "metadata": {}, "score": "66.88682"}
{"text": "SYNSEM also significantly improves results with limited training data , and is shown to be robust to syntactic errors .ML ID : 246 .Training a Multilingual Sportscaster : Using Perceptual Context to Learn Language [ Details ] [ PDF ] David L. Chen , Joohyun Kim , Raymond J. Mooney Journal of Artificial Intelligence Research , 37:397 - -435 , 2010 .", "label": "", "metadata": {}, "score": "66.89095"}
{"text": "Tree least general generalizations ( TLGGs ) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences .The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears .", "label": "", "metadata": {}, "score": "67.01112"}
{"text": "Further possible applications of the presented approaches include summarized machine translation tasks and learning from real perception data assisted by computer vision and robotics .ML ID : 291 .Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .", "label": "", "metadata": {}, "score": "67.06036"}
{"text": "Blue bars provide a histogram showing the number of candidate gene models per locus , as identified by Evigan-5 g .The red scatter plot shows the number of candidate gene models per locus versus the number of exons per gene ( average number of exons per candidate where multiple candiates are predicted ) .", "label": "", "metadata": {}, "score": "67.12074"}
{"text": "Over 38,000 EST sequences for D. pseudoobscura were obtained from dbEST [ 38 ] and aligned to D. pseudoobscura annotated transcripts that were identified as the putative orthologs of the entire test set ( 7777 transcripts ) , using BLAST ( E - value cutoff of 1e-5 ) .", "label": "", "metadata": {}, "score": "67.12696"}
{"text": "View Article PubMed .Siepel A , Haussler D : Computational identification of evolutionarily conserved exons .Proceedings of the Eighth Annual International Conference on Computational Molecular Biology 2004 , 8 : 177 - 186 .McAuliffe J , Pachter L , Jordan M : Multiple - sequence functional annotation and the generalized hidden Markov phylogeny .", "label": "", "metadata": {}, "score": "67.14598"}
{"text": "Existing hand - crafted systems can provide in - depth analysis of domain sub - languages , but are often notoriously fragile and costly to build .Existing machine - learned systems are considerably more robust , but are limited to relatively shallow NLP tasks .", "label": "", "metadata": {}, "score": "67.15765"}
{"text": "In our model , arbitrary , nonindependent features may be freely incorporated , thereby overcoming the inherent limitation of generative models , which require that features be sensitive to the conditional independencies of the generative process .However , unlike previous work on discriminative modeling of word alignment ( which also permits the use of arbitrary features ) , the parameters in our models are learned from unannotated parallel sentences , rather than from supervised word alignments .", "label": "", "metadata": {}, "score": "67.159706"}
{"text": "ML ID : 272 .Learning Language from Ambiguous Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .Building a computer system that can understand human languages has been one of the long - standing goals of artificial intelligence .", "label": "", "metadata": {}, "score": "67.185455"}
{"text": "In this proposal , we present a novel statistical approach to semantic parsing , WASP , which can handle meaning representations with a nested structure .The WASP algorithm learns a semantic parser given a set of sentences annotated with their correct meaning representations .", "label": "", "metadata": {}, "score": "67.20902"}
{"text": "Using the source gene finders ' prediction sets , Evigan identified 13,669 gene loci in the D. melanogaster genome ( see Methods ) .Figure 1 shows the number of candidate models identified per locus , and the number of exons per gene .", "label": "", "metadata": {}, "score": "67.253586"}
{"text": "View Article .Liu Q , Mackey A , Roos D , Pereira F : Evigan : a hidden variable model for integrating gene evidence for eukaryotic gene prediction .Bioinformatics 2008 , 24 ( 5 ) : 597 - 605 .", "label": "", "metadata": {}, "score": "67.32448"}
{"text": "For most natural language processing tasks , a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well - formed strings .This paper reviews our work on using inductive logic programming methods to learn deterministic shift - reduce parsers that translate natural language into a semantic representation .", "label": "", "metadata": {}, "score": "67.353935"}
{"text": "Next , we describe two PCFG induction models for grounded language learning that extend the previous grounded language learning model of Borschinger , Jones , and Johnson ( 2011 ) .Borschinger et al .'s approach works well in situations of limited ambiguity , such as in the sportscasting task .", "label": "", "metadata": {}, "score": "67.393295"}
{"text": "We also intend to broaden the scope of application domains , for example , domains where the sentences are noisy as typical in speech , or domains where corpora available for training do not have natural language sentences aligned with their unique meaning representations .", "label": "", "metadata": {}, "score": "67.56839"}
{"text": "N06 - 1045 [ bib ] : Jonathan May ; Kevin Knight A Better N - Best List : Practical Determinization of Weighted Finite Tree Automata .N06 - 1046 [ bib ] : Regina Barzilay ; Mirella Lapata Aggregation via Set Partitioning for Natural Language Generation .", "label": "", "metadata": {}, "score": "67.77997"}
{"text": "1150 - 1157 , Nice , France , October 2003 .View at Scopus .S. Kumar and M. Hebert , \" Multiclass discriminative fields for parts - based object detection , \" in Snowbird Learning Workshop , March 2004 . A. Kapoor and J. Winn , \" Located hidden random fields : Learning discriminative parts for object detection , \" in Proceedings of the European Conference on Computer Vision ( ECCV ' 06 ) , pp .", "label": "", "metadata": {}, "score": "67.83612"}
{"text": "In practice , however , discrepancy is rarely observed .Ortholog identification .Ortholog pairs between the target species and a reference species are identified by BLASTP [ 42 ] reciprocal best hits between the best candidate models ( translated into protein products ) on the target species and the proteins on the reference species .", "label": "", "metadata": {}, "score": "67.852455"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Scopus .R. Fergus , P. Perona , and A. Zisserman , \" Object class recognition by unsupervised scale - invariant learning , \" in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition ( CVPR ' 03 ) , pp .", "label": "", "metadata": {}, "score": "67.908905"}
{"text": "ML ID : 269 .Learning to Interpret Natural Language Navigation Instructions from Observations [ Details ] [ PDF ] [ Slides ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th AAAI Conference on Artificial Intelligence ( AAAI-2011 ) , 859 - 865 , August 2011 .", "label": "", "metadata": {}, "score": "67.934875"}
{"text": "N06 - 1015 [ bib ] : Simon Lacoste - Julien ; Ben Taskar ; Dan Klein ; Michael I. Jordan Word Alignment via Quadratic Assignment .N06 - 1016 [ bib ] : Jinying Chen ; Andrew Schein ; Lyle Ungar ; Martha Palmer An Empirical Study of the Behavior of Active Learning for Word Sense Disambiguation .", "label": "", "metadata": {}, "score": "67.938416"}
{"text": "N06 - 1051 [ bib ] : Huyen - Trang Vu ; Patrick Gallinari A Machine Learning based Approach to Evaluating Retrieval Systems .N06 - 1052 [ bib ] : Tao Tao ; Xuanhui Wang ; Qiaozhu Mei ; ChengXiang Zhai Language Model Information Retrieval with Document Expansion .", "label": "", "metadata": {}, "score": "67.95907"}
{"text": "Semantic parsing is the process of mapping a natural - language sentence into a formal representation of its meaning .A shallow form of semantic representation is a case - role analysis ( a.k.a . a semantic role labeling ) , which identifies roles such as agent , patient , source , and destination .", "label": "", "metadata": {}, "score": "67.99703"}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .Training the system requires sentences annotated with augmented parse trees .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .", "label": "", "metadata": {}, "score": "68.01778"}
{"text": "The conversion code generally expects Penn Treebank style trees which have been stripped of functional tags and empty elements .This generally corresponds to the output of the Stanford , Charniak or Collins / Bikel parsers .The exception is that it gets value from the -TMP annotation on bare temporal NPs in order to recognize them as having temporal function ( tmod ) .", "label": "", "metadata": {}, "score": "68.072235"}
{"text": "The parser is supplied with 5 Chinese grammars ( and , with access to suitable training data , you could train other versions ) .You can find them inside the supplied stanford - parser- YYYY - MM - DD -models.jar file ( in the GUI , select this file and then navigate inside it ; at the command line , use jar -tf to see its contents ) .", "label": "", "metadata": {}, "score": "68.13185"}
{"text": "The number of candidate models per locus identified by Evigan is based on the agreement among available evidence sources ( gene finders ) .Disagreements about exon call multiply out for multi - exon genes , explaining the abundance of candidate models for those genes .", "label": "", "metadata": {}, "score": "68.147316"}
{"text": "Schwartz R , Chow Y : The n - best algorithm : an efficient and exact procedure for finding the n most likely sentence hypotheses .Proceedings of International Conference on Acoustics , Speech and Signal Processing 1990 , 81 - 84 .", "label": "", "metadata": {}, "score": "68.15046"}
{"text": "We compare a number of semantic parsing approaches on the highly noisy training data collected from ordinary users , and find that loosely synchronous systems perform best .ML ID : 317 .Intelligent robots frequently need to understand requests from naive users through natural language .", "label": "", "metadata": {}, "score": "68.19319"}
{"text": "We present a new edition of the Google Books Ngram Corpus , which describes how often words and phrases were used over a period of five centuries , in eight languages ; it reflects 6 % of all books ever published .", "label": "", "metadata": {}, "score": "68.2392"}
{"text": "Learning for Semantic Parsing Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] [ Slides ] Ruifang Ge PhD Thesis , Department of Computer Science , University of Texas at Austin , Austin , TX , May 2010 .165 pages .", "label": "", "metadata": {}, "score": "68.247955"}
{"text": "7sISI - University of Southern California ISI - TR-616 Acknowledgments This work was supporte ... . \" ...Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .", "label": "", "metadata": {}, "score": "68.30435"}
{"text": "Methods .This section details how ReRanker prioritizes candidate gene models on a target species by comparison with orthologs from a reference species .Subsections address the generation of candidate gene models , ortholog identification between the two species , the construction of similarity features between gene models , the format of scoring function of candidate gene models and learning of the reranker 's scoring parameters .", "label": "", "metadata": {}, "score": "68.31011"}
{"text": "If POS - tagging sentences prior to parsing is an option , that speeds things up ( less possibilities to search ) .The main tool remaining is to run multiple parsers at once in parallel .If you have a machine with enough memory and multiple cores , you can very usefully run several parsing threads at once .", "label": "", "metadata": {}, "score": "68.323395"}
{"text": "ReRanker is successful at improving the identification of correct gene models even when selected candidates are far from the top of the list provided by Evigan .Incorporating Genie 's prediction into ReRanker-5 g ( through Evigan-5 g ) could have introduced a circularity , because ReRanker 's performance was evaluated on D. melanogaster annotations , which were developed with the help of Genie .", "label": "", "metadata": {}, "score": "68.513306"}
{"text": "Learning Language Semantics from Ambiguous Supervision [ Details ] [ PDF ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the 22nd Conference on Artificial Intelligence ( AAAI-07 ) , 895 - 900 , Vancouver , Canada , July 2007 .", "label": "", "metadata": {}, "score": "68.526405"}
{"text": "Demos of learned natural - language database interfaces : .Tutorial on semantic parsing presented at ACL 2010 : .Using natural language to write programs is a touchstone problem for computational linguistics .We present an approach that learns to map natural - language descriptions of simple \" if - then \" rules to executable code .", "label": "", "metadata": {}, "score": "68.55203"}
{"text": "If you call the parser programmatically and then convert the parse tree to a list of grammatical relations , you have to call setGenerateOriginalDependencies(true ) on your instance of TreebankLanguagePack as shown in the following snippet : .Alternatively , if you use SemanticGraphFactory.makeFromTree ( ) to build a SemanticGraph from a constitueny tree , then use the following method with originalDependencies set to true .", "label": "", "metadata": {}, "score": "68.58977"}
{"text": "However , constructing such corpora can be expensive and time - consuming due to the expertise it requires to annotate such data .In this thesis , we explore alternative ways of learning which do not rely on direct human supervision .", "label": "", "metadata": {}, "score": "68.64693"}
{"text": "ML ID : 66 .Corpus - Based Lexical Acquisition For Semantic Parsing [ Details ] [ PDF ] Cynthia Thompson February 1996 .Ph.D. proposal .Building accurate and efficient natural language processing ( NLP ) systems is an important and difficult problem .", "label": "", "metadata": {}, "score": "68.659515"}
{"text": "References . S. Y. Chen , J. H. Zhang , Y. F. Li , and J. W. Zhang , \" A hierarchical model incorporating segmented regions and pixel descriptors for video background subtraction , \" IEEE Transactions on Industrial Informatics , vol . 8 , no . 1 , pp .", "label": "", "metadata": {}, "score": "68.74425"}
{"text": "We show that dependency parsers have more difficulty parsing questions than constituency parsers .In particular , deterministic shift - reduce dependency parsers , which are of highest interest for practical applications because of their linear running time , drop to 60 % labeled accuracy on a question test set .", "label": "", "metadata": {}, "score": "68.805115"}
{"text": "Some of this improvement is from training , but more than half is from parsing with induced constraints , in inference .Punctuation - aware decoding works with existing ( even already - trained ) parsing models and always increased accuracy in our experiments . ... mplementation , extension , understanding and debugging . \" ...", "label": "", "metadata": {}, "score": "68.816826"}
{"text": "Considering only unary and pairwise potentials , the posterior distribution .Figure 2 : ( a ) Part evidence from single observation , ( b ) cooccurrence of connected parts , ( c ) compatibility between image label and single part label , and ( d ) compatibility between image label and connected part labels .", "label": "", "metadata": {}, "score": "69.03688"}
{"text": "In this work we address the problem of unsupervised part - of - speech induction by bringing together several strands of research into a single model .We develop a novel hidden Markov model incorporating sophisticated smoothing using a hierarchical Pitman - Yor processes prior , providing an elegant and principled means of incorporating lexical characteristics .", "label": "", "metadata": {}, "score": "69.11564"}
{"text": "Often , that works out okay , but , overall , results wo n't be quite as good .The default character encoding depends on the language that you are parsing .It is defined in the appropriate TreebankLanguagePack class .That is , it will never default to your platform default character encoding .", "label": "", "metadata": {}, "score": "69.11787"}
{"text": "Semantic parsing is the construction of a complete , formal , symbolic meaning representation of a sentence .While it is crucial to natural language understanding , the problem of semantic parsing has received relatively little attention from the machine learning community .", "label": "", "metadata": {}, "score": "69.149185"}
{"text": "ML ID : 171 .Learning to Transform Natural to Formal Languages [ Details ] [ PDF ] [ Slides ] Rohit J. Kate , Yuk Wah Wong and Raymond J. Mooney In Proceedings of the Twentieth National Conference on Artificial Intelligence ( AAAI-05 ) , 1062 - 1068 , Pittsburgh , PA , July 2005 .", "label": "", "metadata": {}, "score": "69.15297"}
{"text": "A simple extension using transductive SVMs enables the system to do semi - supervised learning and improve its performance utilizing unannotated sentences which are usually easily available .Another extension involving EM - like retraining makes the system capable of learning under ambiguous supervision in which the correct meaning representation for each sentence is not explicitly given , but instead a set of possible meaning representations is given .", "label": "", "metadata": {}, "score": "69.184326"}
{"text": "Unfortunately the relationship between alignment quality and statistical machine translation performance has not been well understood .In the recent literature the alignment task has frequently been decoupled from the ... \" .Automatic word alignment plays a critical role in statistical machine translation .", "label": "", "metadata": {}, "score": "69.19576"}
{"text": "N06 - 1004 [ bib ] : Roland Kuhn ; Denis Yuen ; Michel Simard ; Patrick Paul ; George Foster ; Eric Joanis ; Howard Johnson Segment Choice Models : Feature - Rich Models for Global Distortion in Statistical Machine Translation .", "label": "", "metadata": {}, "score": "69.25627"}
{"text": "Experimental results on challenging datasets with high intraclass variability have demonstrated that the proposed model can effectively represent multiple context information and give competitive detection performance .Our future researches will focus on the following directions : introducing more sparse and robust local features to reduce the computational complexity and utilizing high - order clique potentials to investigate more contextual dependencies in images .", "label": "", "metadata": {}, "score": "69.43097"}
{"text": "Figure 5 : Examples of successful detections on satellite images and synthetic images .Note that simulation airplane models in the last two synthetic images are also correctly detected .Performance Comparison .We compare the detection performance of our model with those of three existing models : hidden CRF [ 15 ] model , located HRF [ 16 ] model , and multiclass CRF [ 14 ] model .", "label": "", "metadata": {}, "score": "69.56491"}
{"text": "Each such extended region is a gene locus .This procedure often produces thousands or tens of thousands of gene loci on the target species , depending on the size of the genome and the Evigan initial prediction set .For each proposed gene locus , Evigan was used to generate the K best candidate gene models for the gene with the posterior probability for each , by integrating the evidence overlapping with the region .", "label": "", "metadata": {}, "score": "69.58308"}
{"text": "Extras includeExtras , boolean threadSafe , Predicate . filter , . boolean originalDependencies )Tools . by Yang Liu , Qun Liu , Shouxun Lin - in Proceedings of COLING - ACL , 2006 . \" ...We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .", "label": "", "metadata": {}, "score": "69.5911"}
{"text": "N06 - 1030 [ bib ] : John Kominek ; Alan W Black Learning Pronunciation Dictionaries : Language Complexity and Word Selection Strategies .N06 - 1031 [ bib ] : Bryant Huang ; Kevin Knight Relabeling Syntax Trees to Improve Syntax - Based Machine Translation Quality .", "label": "", "metadata": {}, "score": "69.66423"}
{"text": "If your file is extremely large , splitting it into multiple files and parsing them sequentially will reduce memory usage .A 64-bit application requires more memory than a 32-bit application ( Java uses lots of pointers ) .", "label": "", "metadata": {}, "score": "69.7486"}
{"text": "Meanwhile , Graphics Processor Units ( GPUs ) have become widely available , offering the opportunity to alleviate this bottleneck by exploiting the fine - grained data parallelism found in the CKY algorithm .In this paper , we explore the design space of parallelizing the dynamic programming computations carried out by the CKY algorithm .", "label": "", "metadata": {}, "score": "69.76418"}
{"text": "S. Lazebnik , C. Schmid , and J. Ponce , \" A maximum entropy framework for part - based texture and object recognition , \" in Proceedings of the 10th IEEE International Conference on Computer Vision ( ICCV ' 05 ) , pp .", "label": "", "metadata": {}, "score": "69.826584"}
{"text": "Abstract .Traditionally , rich , constraint - based grammatical resources have been hand - coded .Scaling such resources beyond toy fragments to unrestricted , real text is knowledge - intensive , timeconsuming and expensive .The work reported in this thesis is part of a larger project to automate as much as possible the construction of wide - coverage , deep , constraint - based grammatical resources from treebanks .", "label": "", "metadata": {}, "score": "69.95186"}
{"text": "An exon is considered correct if its boundaries and reading frame are both correct .A gene is counted correct if all of its exons are precisely predicted .For genes with multiple transcripts , sensitivity and specificity were determined at the exon , transcript and gene levels .", "label": "", "metadata": {}, "score": "69.99059"}
{"text": "ML ID : 47 .Acquisition of a Lexicon from Semantic Representations of Sentences [ Details ] [ PDF ] Cynthia A. Thompson In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL-95 ) , 335 - 337 , Cambridge , MA , 1995 .", "label": "", "metadata": {}, "score": "70.20026"}
{"text": "We present a novel approach which employs a randomized sequence of pruning masks .Formally , we apply auxiliary variable MCMC sampling to generate this sequence of masks , thereby gaining theoretical guarantees about convergence .Because each mask is generally able to skip large portions of an underlying dynamic program , our approach is particularly compelling for high - degree algorithms .", "label": "", "metadata": {}, "score": "70.2618"}
{"text": "Compared to a previous generative model for semantic alignment , it also supports full semantic parsing .Experimental results on the Robocup sportscasting corpora in both English and Korean indicate that our approach produces more accurate semantic alignments than existing methods and also produces competitive semantic parsers and improved language generators .", "label": "", "metadata": {}, "score": "70.306755"}
{"text": "Let S ( t ) and S ( r ) denote the presence or absence of signal peptides on t and r .Then the feature f 6 ( t ) is given by .If the reference gene contains a signal peptide , target candidate gene models with signal peptides are preferred ; If the reference gene does not contain signal peptide , no preference is imposed on target candidate gene models .", "label": "", "metadata": {}, "score": "70.30704"}
{"text": "Most of the other parsing and generation algorithms presented in this thesis are extensions of WASP or its inverse .We demonstrate the effectiveness of our parsing and generation algorithms by performing experiments in two real - world , restricted domains .", "label": "", "metadata": {}, "score": "70.30827"}
{"text": "ML ID : 223 .Transforming Meaning Representation Grammars to Improve Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the Twelfth Conference on Computational Natural Language Learning ( CoNLL-2008 ) , 33 - -40 , Manchester , UK , August 2008 .", "label": "", "metadata": {}, "score": "70.3099"}
{"text": "Parsing file : chinese-onesent-unseg.txt with 1 sentences .Parsing [ sent .1 len .falling back to PCFG parse .Parsed 5 words in 1 sentences ( 6.08 wds / sec ; 1.22 sents / sec ) .1 sentences were parsed by fallback to PCFG .", "label": "", "metadata": {}, "score": "70.31865"}
{"text": "We apply this alignment model to both French - English and Romanian - English language pairs .An exception is Taskar et al .( 2005 ) who presented a word matching model for discriminative alignment which they they were able to solve optimally .", "label": "", "metadata": {}, "score": "70.33135"}
{"text": "Sensitivity is defined as the fraction of annotated exons ( or genes ) predicted correctly .Specificity is the fraction of the predicted exons ( or genes ) that correspond precisely to any exon ( or gene ) in the curated annotation set .", "label": "", "metadata": {}, "score": "70.46576"}
{"text": "Experimental results are presented in Section 4 .Finally , in Section 5 we draw the conclusions .Contextual Hierarchical Part - Driven CRF Model .The conditional random field is simply a Markov random field ( MRF ) [17 ] globally conditioned on the observation .", "label": "", "metadata": {}, "score": "70.46669"}
{"text": "N06 - 1027 [ bib ] : Donghui Feng ; Erin Shaw ; Jihie Kim ; Eduard Hovy Learning to Detect Conversation Focus of Threaded Discussions .N06 - 1028 [ bib ] : Klaus Zechner ; Isaac Bejar Towards Automatic Scoring of Non - Native Spontaneous Speech .", "label": "", "metadata": {}, "score": "70.49447"}
{"text": "Semantic parsing , on the other hand , involves deep semantic analysis in which word senses , semantic roles and other components are combined to produce useful meaning representations for a particular application domain ( e.g. database query ) .Prior research in machine learning for semantic parsing is mainly based on inductive logic programming or deterministic parsing , which lack some of the robustness that characterizes statistical learning .", "label": "", "metadata": {}, "score": "70.50534"}
{"text": "Building natural language parsing systems by hand is a tedious , error - prone undertaking .We build on previous research in automating the construction of such systems using machine learning techniques .The result is a combined system that learns semantic lexicons and semantic parsers from one common set of training examples .", "label": "", "metadata": {}, "score": "70.61569"}
{"text": "The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .The learned transformation rules incrementally map a natural - language sentence or its syntactic parse tree into a parse - tree for the target formal language .", "label": "", "metadata": {}, "score": "70.65321"}
{"text": "LexicalizedParser -encoding utf-8 /u / nlp / data / lexparser / chineseFactored .ser.gz chinese-onesent-utf8.txt Loading parser from serialized file /u / nlp / data / lexparser / chineseFactored . ser.gz ... done [ 20.7 sec].Parsing file : chinese-onesent-utf8.txt with 2 sentences .", "label": "", "metadata": {}, "score": "70.66748"}
{"text": "If the reference gene does not have a signal peptide while a target candidate model does , the candidate will not be penalized .Scoring function .The features just described are used to compute a score S ( t ) for each candidate gene model t .", "label": "", "metadata": {}, "score": "70.668564"}
{"text": "Our linguistic analysis confirms the strong connection between English punctuation and phrase boundaries in the Penn Treebank .However , approaches that naively include punctuation marks in the grammar ( as if they were words ) do not perform well with Klein and Manning 's Dependency Model with Valence ( DMV ) .", "label": "", "metadata": {}, "score": "70.6931"}
{"text": "Table 4 .Gene - finding performance for D. melanogaster genes with D. pseudoobscura EST evidence .Performance on the 1191 D. melanogaster loci whose putative orthologs on D. pseudoobscura are supported by EST sequences ( see text for details ) .", "label": "", "metadata": {}, "score": "70.69794"}
{"text": "Automatic Construction of Semantic Lexicons for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixteenth National Conference on Artificial Intelligence ( AAAI-99 ) , 487 - 493 , Orlando , FL , July 1999 .", "label": "", "metadata": {}, "score": "70.724304"}
{"text": "ML ID : 95 .Active Learning for Natural Language Parsing and Information Extraction [ Details ] [ PDF ] Cynthia A. Thompson , Mary Elaine Califf and Raymond J. Mooney In Proceedings of the Sixteenth International Conference on Machine Learning ( ICML-99 ) , 406 - 414 , Bled , Slovenia , June 1999 .", "label": "", "metadata": {}, "score": "70.75183"}
{"text": "N06 - 1036 [ bib ] : Gang Ji ; Jeff Bilmes Backoff Model Training using Partially Observed Data : Application to Dialog Act Tagging .N06 - 1037 [ bib ] : Min Zhang ; Jie Zhang ; Jian Su Exploring Syntactic Features for Relation Extraction using a Convolution Tree Kernel .", "label": "", "metadata": {}, "score": "70.80815"}
{"text": "We first present a system that learned to sportscast for RoboCup simulation games by observing how humans commentate a game .Using the simple assumption that people generally talk about events that have just occurred , we pair each textual comment with a set of events that it could be referring to .", "label": "", "metadata": {}, "score": "70.872665"}
{"text": "This will change the size of the n - best list and pick the defaults for all other options .It returns a dictionary of the current options : .Use this if all you want is a tokenizer : . [ ' Tokenize ' , ' this ' , ' sentence ' , ' , ' , ' please ' , ' . ' ] Parsing shell .", "label": "", "metadata": {}, "score": "70.87735"}
{"text": "Finally , we also plan to investigate ways to combine our semantic parser with some recently developed semantic parsers to form committees in order to get the best overall performance .ML ID : 181 .Learning for Semantic Parsing Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong 2005 .", "label": "", "metadata": {}, "score": "70.90926"}
{"text": "The annotations are produced automatically with statistical models that are specifically adapted to historical text .The corpus will facilitate the study of linguistic trends , especially those related to the evolution of syntax .Syntactic analysis of search queries is important for a variety of information- retrieval tasks ; however , the lack of annotated data makes training query analysis models difficult .", "label": "", "metadata": {}, "score": "70.912415"}
{"text": "For a semantic parser to work well , conformity between natural language and meaning representation grammar is necessary .However meaning representation grammars are typically designed to best suit the application which will use the meaning representations with little consideration for how well they correspond to natural language semantics .", "label": "", "metadata": {}, "score": "70.933365"}
{"text": "Four of the parsers assume input that has already been word segmented , while the fifth does word segmentation internal to the parser .This is discussed further below .The parser also comes with 3 Chinese example sentences , in files whose names all begin with chinese .", "label": "", "metadata": {}, "score": "70.966034"}
{"text": "Generative Models of Grounded Language Learning with Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joohyun Kim Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , June 2012 . \"", "label": "", "metadata": {}, "score": "71.05682"}
{"text": "When Brown et al .( 1993 ) wan ... . \" ...We consider a new subproblem of unsupervised parsing from raw text , unsupervised partial parsing - the unsupervised version of text chunking .We show that addressing this task directly , using probabilistic finite - state methods , produces better results than relying on the local predictions of a current ... \" .", "label": "", "metadata": {}, "score": "71.065216"}
{"text": "N06 - 1001 [ bib ] : Wei Wang ; Kevin Knight ; Daniel Marcu Capitalizing Machine Translation .N06 - 1002 [ bib ] : Chris Quirk ; Arul Menezes Do we need phrases ?Challenging the conventional wisdom in Statistical Machine Translation .", "label": "", "metadata": {}, "score": "71.07165"}
{"text": "For best results , we recommend that you first segment input text with a high quality word segmentation system which provides word segmentation according to Penn Chinese Treebank conventions ( note that there are many different conventions for Chinese word segmentation ... ) .", "label": "", "metadata": {}, "score": "71.13455"}
{"text": "While multiple LexicalizedparserQuery threads share the same grammar ( LexicalizedParser ) , the memory space savings are n't huge , as most of the memory goes to the transient data structures used in chart parsing .So , if you are running lots of parsing threads concurrently , you will need to give a lot of memory to the JVM .", "label": "", "metadata": {}, "score": "71.21091"}
{"text": "These results support the claim that ILP techniques as implemented in CHILL represent a viable alternative with significant potential advantages over neural - network , propositional , and probablistic approaches to empirical parser construction .ML ID : 48 .This paper presents results from recent experiments with CHILL , a corpus - based parser acquisition system .", "label": "", "metadata": {}, "score": "71.21832"}
{"text": "Starting with version 1.6.2 of the parser , there is a fairly flexible scheme for options in tokenization style .You can give options such as this one to turn off Americanization of spelling : .Or this one to change several options : .", "label": "", "metadata": {}, "score": "71.262924"}
{"text": "Discriminative learning allows easy incorporation of any feature one might have access to during the alignment search .Because the features are handled so easily , ... . \" ...Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .", "label": "", "metadata": {}, "score": "71.29169"}
{"text": "When offered a selection of alternative gene models , cross - species comparison frequently allows ReRanker to select the correct models .Performance on the entire D. melanogaster test set of 7777 loci ( see Table 1 ) .Augustus , CONTRAST , Geneid , Genie and Genscan are ab initio predictors used as evidence sources for Evigan-5 g .", "label": "", "metadata": {}, "score": "71.40492"}
{"text": "Let l ( t ) and l ( r ) denote the coding sequence length of t and r .The length similarity feature f 2 ( t ) is given by .( Normalizing by the coding length of the target gene model is not a good idea , because it may bias towards target candidate gene models that are very long or short . )", "label": "", "metadata": {}, "score": "71.52116"}
{"text": "Note that ReRanker-5 g improves on Evigan-5 g acrosss the board ; italics indicates where other comparative approaches outperform ReRanker-5 g ( see text ) .When ReRanker selects an alternative model , does it always choose the next most probable candidate from the list of possibilities defined by Evigan ?", "label": "", "metadata": {}, "score": "71.56763"}
{"text": "There has been an increased interest in using probabilistic grammars in the Bayesian setting .To date , most of the literature has focused on using a Dirichlet prior .The Dirichlet prior has several limitations , including that it can not directly model covariance between the probabilistic grammar 's parameters .", "label": "", "metadata": {}, "score": "71.57175"}
{"text": "ML ID : 57 .Lexical Acquisition : A Novel Machine Learning Problem [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Technical Report , Artificial Intelligence Lab , University of Texas at Austin , January 1996 .", "label": "", "metadata": {}, "score": "71.59401"}
{"text": "PubMed .Batzoglou S , Pachter L , Mesirovi J , Berger B , Lander E : Human and mouse gene structure : comparative analysis and application to exon prediction .Genome Res 2000 , 10 ( 7 ) : 950 - 958 .", "label": "", "metadata": {}, "score": "71.67894"}
{"text": "Again , the +1 term in the numerator and denominator smoothes the counts , and also prevents division by zero .Sequence similarity .The sequence similarity feature between t and r is computed from the alignment score given by DiAlign [ 44 ] , a multiple sequence alignment program .", "label": "", "metadata": {}, "score": "71.68714"}
{"text": "We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .", "label": "", "metadata": {}, "score": "71.702034"}
{"text": "The weight vector w is initially the zero vector .The pseudocode \" Outline of MIRA update \" shows a single cycle of updating the weight vector .The true best candidate is denote by , given by the maximum quality assessment .", "label": "", "metadata": {}, "score": "71.78981"}
{"text": "Let t and r denote a candidate gene model ( or its translated protein ) on the target species and a protein / gene on the reference species , respectively .Posterior probability .Let p ( t ) denote t 's Evigan posterior probability given the evidence .", "label": "", "metadata": {}, "score": "71.809845"}
{"text": "Google , Inc. .Department of Biology , University of Pennsylvania .References .Parra G , Agarwal P , Abril J , Wiehe T , Fickett J , Guigo R : Comparative gene prediction in human and mouse .Genome Res 2003 , 13 : 108 - 117 .", "label": "", "metadata": {}, "score": "71.85938"}
{"text": "The new Viewer adds three features for more powerful search : wildcards , morphological inflections , and capitalization .These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text .", "label": "", "metadata": {}, "score": "71.89963"}
{"text": "This paper reviews our prior work on this topic and discusses directions for future research .ML ID : 196 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .", "label": "", "metadata": {}, "score": "71.9917"}
{"text": "Gelfand M , Mironov A , Pevzner P : Gene recognition via spliced sequence alignment .Proc Natl Acad Sci USA 1996 , 93 : 9061 - 9066 .View Article PubMed .Yeh R , Lim L , Burge C : Computational inference of homologous gene structures in the human genome .", "label": "", "metadata": {}, "score": "72.06357"}
{"text": "Primary acoustic , speech , and vision systems were trained to discriminate instances of the categories .Higher - level systems exploited correlations among the categories , incorporated sequential context , and combined the joint evidence from the three information sources .", "label": "", "metadata": {}, "score": "72.16724"}
{"text": "Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .A long - standing goal for the field of artificial intelligence is to enable computer understanding of human languages .A core requirement in reaching this goal is the ability to transform individual sentences into a form better suited for computer manipulation .", "label": "", "metadata": {}, "score": "72.28752"}
{"text": "Note that , since the local features are extracted automatically during training and testing , the quantity and structure ( constructed by MST ) of observations should be unpredictable .As a result , the computing time of our model is influenced by the object complexity and image quality .", "label": "", "metadata": {}, "score": "72.31326"}
{"text": "All of these tasks are accomplished within the same framework , using a single , general learning method that can acquire new syntactic and semantic categories for resolving ambiguities .Experimental evidence from both aritificial and real - world corpora demonstrate that CHILL learns parsers as well or better than previous artificial neural network or probablistic approaches on comparable tasks .", "label": "", "metadata": {}, "score": "72.35457"}
{"text": "This ' universal ' treebank is made freely available in order to facilitate research on multilingual dependency parsing .We consider the construction of part - of - speech taggers for resource - poor languages .Recently , manually constructed tag dictionaries from Wiktionary and dictionaries projected via bitext have been used as type constraints to overcome the scarcity of annotated data in this setting .", "label": "", "metadata": {}, "score": "72.4164"}
{"text": "To facilitate future research in unsupervised induction of syntactic structure and to standardize best - practices , we propose a tagset that consists of twelve universal part - of - speech categories .In addition to the tagset , we develop a mapping from 25 different treebank tagsets to this universal set .", "label": "", "metadata": {}, "score": "72.52074"}
{"text": "For English , the parser by default now produces Universal Dependencies , which are extensively documented on that page .You can also have it produce the prior Stanford Dependencies representation .For this , and for the Chinese dependencies , you can find links to documentation on the Stanford Dependencies page .", "label": "", "metadata": {}, "score": "72.65933"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .S. Kumar , Models for learning spatial interactions in natural images for context - based classification [ Ph.D. thesis ] , The Robotics Institute , Carnegie Mellon University , 2005 .", "label": "", "metadata": {}, "score": "72.74168"}
{"text": "Introduction .Object category detection is one of the most important problems in computer vision and is still full of challenges because of various factors such as object deformation , occlusion , and viewpoint change .To address these challenges , successful object detection methods need to strike the balance between being flexible enough to model intraclass variability and being discriminative enough to find objects with ambiguity appearance in complicate scenes [ 1 - 3 ] .", "label": "", "metadata": {}, "score": "72.788506"}
{"text": "The need for NLIs has become more pronounced given the widespread access to complex databases now available through the Internet .However , such systems are difficult to build and must be tailored to each application .A current research topic involves using machine learning methods to automate the development of NLI 's .", "label": "", "metadata": {}, "score": "72.794205"}
{"text": "PubMed .Morgenstern B : DIALIGN 2 : improvement of the segment - to - segment approach to multiple sequence alignment .Bioinformatics 1999 , 15 : 211 - 218 .View Article PubMed .Bendtsen J , Nielsen H , Heijne G , Brunak S : Improved prediction of signal peptides : SignalP 3.0 .", "label": "", "metadata": {}, "score": "72.826645"}
{"text": "Finally , we also show that ensembles of different semantic parser learning systems can obtain the best overall performance .ML ID : 215 .Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}, "score": "72.88839"}
{"text": "Korf I , Flicek P , Duan D , Brent M : Integrating genomic homology into gene structure prediction .Bioinformatics 2001 , 17 ( Suppl 1 ) : S140 - 148 .PubMed .Flicek P , Keibler E , Hu P , Korf I , Brent MR : Leveraging the mouse genome for gene prediction in human : From whole - genome shotgun reads to a global synteny map .", "label": "", "metadata": {}, "score": "72.94129"}
{"text": "In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .Active learning methods ( Cohn , Atlas , & Ladner , 1994 ) attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .", "label": "", "metadata": {}, "score": "72.94937"}
{"text": "By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser , the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus .ML ID : 264 .", "label": "", "metadata": {}, "score": "72.9661"}
{"text": "MIRA algorithm wrapper .Perform the following N times : .Get an example e from the training set D .Output the average weight vector .Evaluation .For each locus on the target species , Evigan 's prediction is always the top gene model from the original candidate list generated by Evigan ; ReRanker 's prediction is the candidate model with the highest reranking score as described above .", "label": "", "metadata": {}, "score": "73.01823"}
{"text": "In other words , different edges should have different weights during calculating pairwise potentials .We denote the edge cost between node .Note that , all the terms in the derivatives can be calculated using Belief Propagation ( BP ) algorithm [ 17 ] , provided the graphical structure does not contain cycles .", "label": "", "metadata": {}, "score": "73.15129"}
{"text": "Experimental results are presented on learning to map English coaching instructions for Robocup soccer into an existing formal language for coaching simulated robotic agents .ML ID : 140 .Learning Semantic Parsers : An Important But Under - Studied Problem [ Details ] [ PDF ] Raymond J. Mooney In Papers from the AAAI 2004 Spring Symposium on Language Learning : An Interdisciplinary Perspective , 39 - -44 , Stanford , CA , March 2004 .", "label": "", "metadata": {}, "score": "73.16008"}
{"text": "Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind ( 1996 ) , with results favorable to Wolfie .", "label": "", "metadata": {}, "score": "73.16734"}
{"text": "Bioinformatics 2005 , 21 ( 18 ) : 3596 - 3603 .View Article PubMed .Allen JE , Pertea M , Salzberg SL : JIGSAW , GeneZilla and GlimmerHMM : puzzling out the feature of human genes in the ENCODE regions .", "label": "", "metadata": {}, "score": "73.17137"}
{"text": "Genia ( biomedical English ) .Originally we used the treebank beta version reformatted by Andrew Clegg , his training split , but more recently ( 1.6.5 + ? ) we 've used the official Treebank , and David McClosky 's splits .", "label": "", "metadata": {}, "score": "73.25853"}
{"text": "Therefore , the generators are said to be the inverse of the parsers , an elegant property that has been widely advocated .Furthermore , we show that our parsers and generators can handle formal meaning representation languages containing logical variables , including predicate logic .", "label": "", "metadata": {}, "score": "73.28952"}
{"text": "Integrating Top - down and Bottom - up Approaches in Inductive Logic Programming : Applications in Natural Language Processing and Relational Data Mining [ Details ] [ PDF ] Lappoon R. Tang PhD Thesis , Department of Computer Sciences , University of Texas , Austin , TX , August 2003 .", "label": "", "metadata": {}, "score": "73.34801"}
{"text": "There is a call , setConstraints , which you can make before using the LexicalizedParserQuery to run the parser .If you add a ParserConstraint object spanning a set of words , the parser will only produce parse trees which include that span of words as a constituent .", "label": "", "metadata": {}, "score": "73.382675"}
{"text": "View at Google Scholar .M. Fischler and R. A. Elschlager , \" The representation and matching of pictorial structures , \" IEEE Transactions on Computers , vol .22 , no . 1 , pp .67 - 92 , 1973 .", "label": "", "metadata": {}, "score": "73.45419"}
{"text": "N06 - 1060 [ bib ] : Andrew Freeman ; Sherri Condon ; Christopher Ackerman Cross Linguistic Name Matching in English and Arabic .N06 - 1061 [ bib ] : Gunes Erkan Language Model - Based Document Clustering Using Random Walks .", "label": "", "metadata": {}, "score": "73.8537"}
{"text": "DVParser with no flags .The memory requirements of the parser is not actually that high , but the more threads added with -trainingThreads , the more memory will be required to train .As the parser is training , it will output intermediate models every 20 minutes ( by default ) .", "label": "", "metadata": {}, "score": "73.88196"}
{"text": "View at Scopus . E. B. Sudderth , A. Torralba , W. T. Freeman , and A. S. Willsky , \" Describing visual scenes using transformed objects and parts , \" International Journal of Computer Vision , vol .77 , no . 1 - 3 , pp .", "label": "", "metadata": {}, "score": "73.88414"}
{"text": "Integrating Statistical and Relational Learning for Semantic Parsing : Applications to Learning Natural Language Interfaces for Databases [ Details ] [ PDF ] Lappoon R. Tang May 2000 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .", "label": "", "metadata": {}, "score": "73.9337"}
{"text": "This process is described in the several papers on the topic by Marie - Catherine de Marneffe .Confusingly , the current code to generate Stanford Dependencies requires a phrase structure ( CFG ) parse .It does n't require or use a dependency parse .", "label": "", "metadata": {}, "score": "74.01703"}
{"text": "Learning Language from Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen December 2009 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .Most current natural language processing ( NLP ) systems are built using statistical learning algorithms trained on large annotated corpora which can be expensive and time - consuming to collect .", "label": "", "metadata": {}, "score": "74.14189"}
{"text": "An example of this command line is java -mx12 g edu.stanford.nlp.parser.dvparser.DVParser -cachedTrees /path / to / cached .wsj.ser.gz -train -testTreebank /path / to / wsj 2200 - 2219 -debugOutputFrequency 500 -trainingThreads 8 -parser /path / to / pcfg / pcfg.ser.gz -dvIterations 40 -dvBatchSize 25 -wordVectorFile /path / to / embedding -model /scr / nlp / data / dvparser / wsj / train / averaged / averaged . ser.gz .", "label": "", "metadata": {}, "score": "74.1673"}
{"text": "The ATIS corpus of airline information queries was used to test the acquisition of syntactic parsers , and CHILL performed competitively with recent statistical methods .English queries to a small database on U.S. geography were used to test the acquisition of a complete natural language interface , and the parser that CHILL acquired was more accurate than an existing hand - coded system .", "label": "", "metadata": {}, "score": "74.17288"}
{"text": "We introduce a dialog agent for mobile robots that understands human instructions through semantic parsing , actively resolves ambiguities using a dialog manager , and incrementally learns from human - robot conversations by inducing training data from user paraphrases .Our dialog agent is implemented and tested both on a web interface with hundreds of users via Mechanical Turk and on a mobile robot over several days , tasked with understanding navigation and delivery requests through natural language in an office environment .", "label": "", "metadata": {}, "score": "74.17418"}
{"text": "For future work , I am proposing to solve the more complex task of learning how to give and receive navigation instructions in a virtual environment .In this setting , each instruction corresponds to a navigation plan that is not directly observable .", "label": "", "metadata": {}, "score": "74.26794"}
{"text": "It is such an ambitious task that it sometimes is referred to as an AI - complete problem , implying that its difficulty is equivalent to solving the central artificial intelligence problem -- making computers as intelligent as people .Despite its complexity , natural language understanding continues to be a fundamental problem in natural language processing in terms of its theoretical and empirical importance .", "label": "", "metadata": {}, "score": "74.295334"}
{"text": "You will need a collection of syntactically annotated data such as the Penn Treebank to train the parser .If they are not in the same format as currently supported Treebanks , you may need to write classes to read in the trees , etc .", "label": "", "metadata": {}, "score": "74.42"}
{"text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural - language interface for database queries .CHILL treats parser acquisition as the learning of search - control rules within a logic program representing a shift - reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge .", "label": "", "metadata": {}, "score": "74.428345"}
{"text": "Note that it does not come with any parsing models but includes a downloader .The primary maintenance for the parser takes place at GitHub .Fetching parsing models .Before you can parse , you 'll need some parsing models .", "label": "", "metadata": {}, "score": "74.44114"}
{"text": "View Article PubMed .Chatterji S , Pachter L : Reference based annotation with GeneMapper .Genome Biology 2006 ., 7 ( 4 ) : .Brejova B , Brown DG , Li M , Vinar T : ExonHunter : a comprehensive approach to gene finding .", "label": "", "metadata": {}, "score": "74.449234"}
{"text": "Acknowledgement This work is supported by National High Technology Research and Development Program contract \" Generally Technical Research and Basic Database Establishment of Chinese Platform\"(Subj ... . by Er Fraser Daniel Marcu - In Technical Report ISI - TR-616 . html , ISI / University of Southern California , 2006 . \" ...", "label": "", "metadata": {}, "score": "74.49735"}
{"text": "N06 - 1039 [ bib ] : Yusuke Shinyama ; Satoshi Sekine Preemptive Information Extraction using Unrestricted Relation Discovery .N06 - 1040 [ bib ] : Mehryar Mohri ; Brian Roark Probabilistic Context - Free Grammar Induction Based on Structural Zeros .", "label": "", "metadata": {}, "score": "74.67512"}
{"text": "The lexicon , or the mapping from words to meanings , is one component that is typically difficult to update and that changes from one domain to the next .Therefore , automating the acquisition of the lexicon is an important task in automating the acquisition of NLP systems .", "label": "", "metadata": {}, "score": "74.755905"}
{"text": "Training the RNN parser is a two step process .First , because the RNN parser uses the parsings of a simpler PCFG parser to train , it is useful to precache the results of that parser before training the RNN parser .", "label": "", "metadata": {}, "score": "74.801216"}
{"text": "Multiple candidate models were identified for 11,701 genes ( 86 % ) , and 9125 genes ( 67 % ) were paired with D. pseudoobscura genes as putative orthologs based on reciprocal best BLAST hits [ 36 ] ; 7975 loci exhibited both multiple candidate models and putative orthologs .", "label": "", "metadata": {}, "score": "74.816444"}
{"text": "Annotated gene models of D. melanogaster , used as training set for estimating reranker parameters , and also as a standard for evaluating prediction accuracy .Evigan is a recently developed gene finder that integrates diverse sources of evidence , including predictions from multiple other gene finders .", "label": "", "metadata": {}, "score": "75.01616"}
{"text": "A widely used alternative approach for using cross - species information in gene prediction involves aligning reference gene models ( or proteins ) to the target genome , and using these alignments to either build new gene finders , or modify existing ab initio ones by explicitly modeling alignments . GeneWise", "label": "", "metadata": {}, "score": "75.034164"}
{"text": "N06 - 1006 [ bib ] : Bill MacCartney ; Trond Grenager ; Marie - Catherine de Marneffe ; Daniel Cer ; Christopher D. Manning Learning to recognize features of valid textual entailments .N06 - 1007 [ bib ] : Viktor Pekar Acquisition of Verb Entailment from Text .", "label": "", "metadata": {}, "score": "75.0611"}
{"text": "This answer is specific to English .It mostly applies to other languages although some components are missing in some languages .The file englishPCFG.ser.gz comprises just an unlexicalized PCFG grammar .It is basically the parser described in the ACL 2003 Accurate Unlexicalized Parsing paper .", "label": "", "metadata": {}, "score": "75.06345"}
{"text": "The penalty for a recognition failure is often small : if two con- figurations are confused , they are often similar to each other , and the illusion works well enough , for instance , to drive a graphics animation of the moving hand .", "label": "", "metadata": {}, "score": "75.06787"}
{"text": "The model is l ... \" .We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .A TAT is capable of generating both terminals and non - terminals and per - forming reordering at both low and high levels .", "label": "", "metadata": {}, "score": "75.07923"}
{"text": "A gene is counted correct if one of its transcripts is predicted correctly .Declarations .Acknowledgements .This work was funded in part by NSF ITR awards EIA 0205456 and IIS 0428193 , which we greatly appreciate .We also thank reviewers and editors for very helpful suggestions to make the paper better .", "label": "", "metadata": {}, "score": "75.09918"}
{"text": "1 len .2 len .Parsed 14 words in 2 sentences ( 6.55 wds / sec ; 0.94 sents / sec ) .Parsing file : chinese - onesent with 1 sentences .Parsing [ sent .1 len .Parsed 10 words in 1 sentences ( 10.78 wds / sec ; 1.08 sents / sec ) .", "label": "", "metadata": {}, "score": "75.25619"}
{"text": "N06 - 1033 [ bib ] : Hao Zhang ; Liang Huang ; Daniel Gildea ; Kevin Knight Synchronous Binarization for Machine Translation .N06 - 1034 [ bib ] : Kate Forbes - Riley ; Diane Litman Modelling User Satisfaction and Student Learning in a Spoken Dialogue Tutoring System with Generic , Tutoring , and User Affect Parameters .", "label": "", "metadata": {}, "score": "75.34002"}
{"text": "ML ID : 222 .Learning to Sportscast : A Test of Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] [ Video ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .", "label": "", "metadata": {}, "score": "75.37755"}
{"text": "We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language ( NL ) sentences into their formal meaning representations ( MRs ) .Given NL sentences annotated with their MRs , the initial supervised semantic parser learns the mapping by training Support Vector Machine ( SVM ) classifiers for every production in the MR grammar .", "label": "", "metadata": {}, "score": "75.48323"}
{"text": "See especially the sample invocation in the parser.lexparser package documentation .The included file makeSerialized.csh effectively documents how the included grammars were made .The included file ParserDemo.java gives a good first example of how to call the parser programmatically , including getting Tree and typedDependencies output .", "label": "", "metadata": {}, "score": "75.501495"}
{"text": "The supplied file makeSerialized.csh shows exactly what options we used to train the parsers that are included in the distribution .If you want to train the parser on a new language and/or treebank format , you can ( and people have done so ) , but you need to spend a while learning about the code , especially if you wish to develop language - specific features .", "label": "", "metadata": {}, "score": "75.53972"}
{"text": "ML ID : 92 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia Ann Thompson PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , December 1998 .", "label": "", "metadata": {}, "score": "75.55064"}
{"text": "See the parser.lexparser package documentation , the LexicalizedParser.main method documentation , the TreePrint class , and the documentation of variables in the Train , Test , and Options classes , and appropriate language - particular TreebankLangParserParams .For the rest , you need to look at the source code .", "label": "", "metadata": {}, "score": "75.559074"}
{"text": "We describe a novel approach for inducing unsupervised part - of - speech taggers for languages that have no labeled training data , but have translated text in a resource - rich language .Our method does not assume any knowledge about the target language ( in particular no tagging dictionary is assumed ) , m ... \" .", "label": "", "metadata": {}, "score": "75.71031"}
{"text": "The Inverse Entailment approach to ILP , implemented in the Progol and Aleph systems , starts with the construction of a bottom clause , the most specific hypothesis covering a seed example .When mining relational data with a large number of background facts , the bottom clause becomes intractably large , making learning very inefficient .", "label": "", "metadata": {}, "score": "75.763275"}
{"text": "Hebrew : UTF-8 .However , the parser is able to parse text in any encoding , providing you pass the correct encoding option on the command line , for example : .-encoding ISO_8859 - 15 .( Or , when used within a program , it is your job to open files with the right kind of Reader / Writer . ) caseless.ser.gz - Loading parser from serialized file edu / stanford / nlp / models / lexparser / englishPCFG .", "label": "", "metadata": {}, "score": "75.77846"}
{"text": "N06 - 1057 [ bib ] : Liang Zhou ; Chin - Yew Lin ; Dragos Stefan Munteanu ; Eduard Hovy ParaEval : Using Paraphrases to Evaluate Summaries Automatically .N06 - 1058 [ bib ] : David Kauchak ; Regina Barzilay Paraphrasing for Automatic Evaluation .", "label": "", "metadata": {}, "score": "75.821"}
{"text": "The segments produced by DiAlign can be used to extract another useful similarity feature : shared splice sites .Figure 3 shows the alignment betweeen the coding sequences of t and r output by DiAlign , where blue boxes represent gapless local alignments and wavy lines represent unaligned regions .", "label": "", "metadata": {}, "score": "75.82313"}
{"text": "You pass to the parse method a List .If the items in this list implement HasTag , such as being of type TaggedWord or CoreLabel , and the tag value is not null , then the parser will use the tags that you provide .", "label": "", "metadata": {}, "score": "75.94939"}
{"text": "One core issue toward this goal is \" grounded \" language learning , a process of learning the semantics of natural language with respect to relevant perceptual inputs .In order to ground the meanings of language in a real world situation , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .", "label": "", "metadata": {}, "score": "75.98996"}
{"text": "There is n't a separate included tagger ; the parser does POS tagging as part of parsing .Yes , you can .You can use the main method of EnglishGrammaticalStructure ( for English , or the corresponding class for Chinese ) .", "label": "", "metadata": {}, "score": "76.019485"}
{"text": "The performance of SCISSOR is further improved by using discriminative reranking for incorporating non - local features .The second semantic parser , SYNSEM , exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .", "label": "", "metadata": {}, "score": "76.07847"}
{"text": "Training data consists of natural language sentences annotated with multiple potential meaning representations , only one of which is correct .Such ambiguous supervision models the type of supervision that can be more naturally available to language - learning systems .Given such weak supervision , our approach produces a semantic parser that maps sentences into meaning representations .", "label": "", "metadata": {}, "score": "76.08699"}
{"text": "ML ID : 130 .Acquiring Word - Meaning Mappings for Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Journal of Artificial Intelligence Research , 18:1 - 44 , 2003 .This paper focuses on a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .", "label": "", "metadata": {}, "score": "76.0981"}
{"text": "A new system , Wolfie , learns semantic lexicons to be used as background knowledge by a previously developed parser acquisition system , Chill .The combined system is tested on a real world domain of answering database queries .We also compare this combination to a combination of Chill with a previously developed lexicon learner , demonstrating superior performance with our system .", "label": "", "metadata": {}, "score": "76.14425"}
{"text": "We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .ML ID : 187 .", "label": "", "metadata": {}, "score": "76.21979"}
{"text": "To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance .ML ID : 121 .", "label": "", "metadata": {}, "score": "76.24739"}
{"text": "View Article PubMed .Chatterji S , Pachter L : Large multiple organism gene finding by collapsed Gibbs sampling .J Comput Biol 2005 , 12 ( 6 ) : 599 - 608 .View Article PubMed .Carter D , Durbin R : Vertebrate gene finding from multiple - species alignments using a two - level strategy .", "label": "", "metadata": {}, "score": "76.42272"}
{"text": "Automating the construction of semantic grammars is a difficult and interesting problem for machine learning .This paper shows how the semantic - grammar acquisition problem can be viewed as the learning of search - control heuristics in a logic program .", "label": "", "metadata": {}, "score": "76.52287"}
{"text": "View Article PubMed .Hsu F , Kent W , Clawson H , Kuhn R , Diekhans M , Haussler D : The UCSC Known Genes .Bioinformatics 2006 , 22 ( 9 ) : 1036 - 1046 .View Article PubMed .", "label": "", "metadata": {}, "score": "76.57941"}
{"text": "A brief demo program included with the download will demonstrate how to load the tool and start processing text .When using this demo program , be sure to include all of the appropriate jar files in the classpath .For part - of - speech tags and phrasal categories , this depends on the language and treebank on which the parser was trained ( and was decided by the treebank producers not us ) .", "label": "", "metadata": {}, "score": "76.62056"}
{"text": "This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with representations of their meaning , and allows for both synonymy and polysemy .", "label": "", "metadata": {}, "score": "76.79808"}
{"text": "View Article PubMed .Gross S , Brent M : Using multiple alignments to improve gene prediction .J Comput Biol 2006 , 13 ( 2 ) : 379 - 93 .View Article PubMed .Alexandersson M , Cawley S , Pachter L : SLAM : Cross - Species Gene Finding and Alignment with a Generalized Pair Hidden Markov Model .", "label": "", "metadata": {}, "score": "76.84603"}
{"text": "Note that the latent label . may be arbitrary and disorganized due to the uncertainty of local feature extraction .Meanwhile , different observations may be associated with the same part label , which corresponded to the meaningful object component .Due to the fact that adjacent or relevant observations are more likely to have the same label , we should consider label - level context in our model in addition to observation - level context .", "label": "", "metadata": {}, "score": "76.9753"}
{"text": "They are : .PCFG .Factored .Factored , segmenting .Xinhua ( mainland , newswire ) .xinhuaPCFG.ser.gz . xinhuaFactored.ser.gz .xinhuaFactoredSegmenting.ser.gz .Mixed Chinese .chinesePCFG.ser.gz . chineseFactored.ser.gz .The PCFG parsers are smaller and faster .But the Factored parser is significantly better for Chinese , and we would generally recommend its use .", "label": "", "metadata": {}, "score": "77.00328"}
{"text": "At the API level , with the factored parser , if you ask for getBestDependencyParse ( ) , then you will get the best untyped dependency parse .If you call that method with englishPCFG.ser.gz , it will return null , as there is no dependency parse .", "label": "", "metadata": {}, "score": "77.01407"}
{"text": "Yes , you can .Various tokenizers are included .The one used for English is called PTBTokenizer .It is a hand - written rule - based ( FSM ) tokenizer , but is quite accurate over newswire - style text .", "label": "", "metadata": {}, "score": "77.163155"}
{"text": "This gives a reasonable , but not excellent , Chinese word segmentation system .( It 's performance is n't as good as the Stanford CRF word segmenter mentioned above . )To use it , you use the -segmentMarkov option or a grammar trained with this option .", "label": "", "metadata": {}, "score": "77.16574"}
{"text": "Stanke M , Schoffmann O , Morgenstern B , Waack S : Gene prediction in eukaryotes with a generalized hidden Markov model that uses hints from external sources .BMC Bioinformatics 2006 , 7 : 62 .View Article PubMed .Stanke M , Waack S : Gene prediction with a hidden Markov model and a new intron submodel .", "label": "", "metadata": {}, "score": "77.25537"}
{"text": "If you want to display the output in a command window , you separately also need to work out what character set your computer supports for display .If that is different to the encoding of the file , you will need to convert the encoding for display .", "label": "", "metadata": {}, "score": "77.34609"}
{"text": "N06 - 1012 [ bib ] : Charles Sutton ; Michael Sindelar ; Andrew McCallum Reducing Weight Undertraining in Structured Discriminative Learning .N06 - 1013 [ bib ] : Necip Fazil Ayan ; Bonnie J. Dorr A Maximum Entropy Approach to Combining Word Alignments .", "label": "", "metadata": {}, "score": "77.353355"}
{"text": "We obtain state - of - theart performance for two tasks of structure prediction : unsupervised part - of - speech tagging and unsupervised dependency parsing . ... parsing .In its purest form , such research has improved our understanding of unsupervised learning practically and formally , and has led to a wide range of new algorithmic ... . \" ...", "label": "", "metadata": {}, "score": "77.382965"}
{"text": "The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .", "label": "", "metadata": {}, "score": "77.387955"}
{"text": "Finally , we will investigate the impact of different statistical syntactic parsers on semantic parsing using the automated SAPT - generation process .ML ID : 184 .A Kernel - based Approach to Learning Semantic Parsers [ Details ] [ PDF ] [ Slides ] Rohit J. Kate 2005 .", "label": "", "metadata": {}, "score": "77.39693"}
{"text": "For instance : .Parsing file : chinese - onesent with 1 sentences .Parsing [ sent .1 len .Parsed 10 words in 1 sentences ( 7.10 wds / sec ; 0.71 sents / sec ) .There are many kinds of ' vanilla ' , but , providing your treebank is in Penn Treebank format , then , yes , this is easy to do .", "label": "", "metadata": {}, "score": "77.56737"}
{"text": "The lexicon learned consists of words paired with meaning representations .Wolfie is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .", "label": "", "metadata": {}, "score": "77.66555"}
{"text": "Two new integrated ILP systems for these tasks that overcome limitations of existing methods will be presented .Cocktail is a new ILP algorithm for inducing semantic parsers .For this task , two features of a parse state , functional structure and context , provide important information for disambiguation .", "label": "", "metadata": {}, "score": "77.723656"}
{"text": "There are two major ILP approaches : top - down and bottom - up .The former searches the hypothesis space from general to specific while the latter the other way round .Integrating both approaches has been demonstrated to be more effective .", "label": "", "metadata": {}, "score": "77.74205"}
{"text": "It can be invoked from the command line .For example , this will download and install the standard WSJ model : . shell% python -m bllipparser .ModelFetcher -i WSJ .Run python -mbllipparser .ModelFetcher with no arguments for a full listing of options and available parsing models .", "label": "", "metadata": {}, "score": "77.80482"}
{"text": "ML ID : 180 .A Statistical Semantic Parser that Integrates Syntax and Semantics [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of CoNLL-2005 , Ann Arbor , Michigan , June 2005 .We introduce a learning semantic parser , Scissor , that maps natural - language sentences to a detailed , formal , meaning - representation language .", "label": "", "metadata": {}, "score": "77.90821"}
{"text": "In particular , you can now download a version of our CRF - based word segmenter ( similar to the system we used in the Second Sighan Bakeoff ) from our software page .However , for convenience , we also provide an ability for the parser to do word segmentation .", "label": "", "metadata": {}, "score": "77.97824"}
{"text": "Yes .The parser treats a filename as - as meaning to read from stdin and by default writes to stdout ( this can be changed with the -writeOutputFiles option ) .Note : the tokenizer uses lookahead , so you will either need to close the input to get the last sentence parsed , or use another option like -sentences newline .", "label": "", "metadata": {}, "score": "78.071915"}
{"text": "ILP algorithms , which learn relational ( first - order ) rules , are used in a parser acquisition system called CHILL that learns rules to control the behavior of a traditional shift - reduce parser .Using this approach , CHILL is able to learn parsers for a variety of different types of analyses , from traditional syntax trees to more meaning - oriented case - role and database query forms .", "label": "", "metadata": {}, "score": "78.120285"}
{"text": "Control rules are induced using a novel ILP algorithm which handles difficult issues arising in the induction of search - control heuristics .Both the control - rule framework and the induction algorithm are crucial to CHILL 's success .The main advantage of CHILL over propositional counterparts is its flexibility in handling varied representations .", "label": "", "metadata": {}, "score": "78.332504"}
{"text": "This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with meaning representations .", "label": "", "metadata": {}, "score": "78.35411"}
{"text": "Questions with answers .In recent distributions , the models are included in a jar file inside the parser distribution .For example , in the 2012 - 11 - 12 distribution , the models are included in stanford - parser-2.0.4-models.jarThe easiest way to access these models is to include this file in your classpath .", "label": "", "metadata": {}, "score": "78.35466"}
{"text": "Without the temporal annotation , some simple temporals like today will still be recognized , but a bare temporal like last week in I left last week will be tagged as an object ( dobj ) .With the Stanford parser , you can get marking of temporal NPs in the tree output by giving the option -retainTmpSubcategories , either on the command line or by passing it to the setOptionFlags(String [ ] ) method of the parser .", "label": "", "metadata": {}, "score": "78.54845"}
{"text": "Either form of list will pass the tags to the parser .Or you can do this with code that you write .Here 's an example that very manually makes the List in question : . ; List .There are other constraints which can be added , but they have to be added programmatically .", "label": "", "metadata": {}, "score": "78.59122"}
{"text": "The relevant options are -sentences ( see above ) , -tokenized , -tokenizerFactory , -tokenizerMethod , and -tagSeparator .If , for example , you want to denote a POS tag by appending /POS on a word , you would include the options -tokenized -tagSeparator / -tokenizerFactory edu.stanford.nlp.process.WhitespaceTokenizer -tokenizerMethod newCoreLabelTokenizerFactory in your invocation of LexicalizedParser .", "label": "", "metadata": {}, "score": "78.63639"}
{"text": "Gene loci on the target species were first defined and candidate gene models for each locus are generated by Evigan .The term gene locus refers to a genomic region containing only a single gene .Gene loci on the target species were first identified by an initial prediction gene set produced by Evigan integrating multiple lines of evidence ( Augustus , Genscan , Genie , Geneid , CONTRAST were used in the experiment ) .", "label": "", "metadata": {}, "score": "78.636604"}
{"text": "N06 - 1042 [ bib ] : Deniz Yuret ; Ferhan Ture Learning Morphological Disambiguation Rules for Turkish .N06 - 1043 [ bib ] : Anna Corazza ; Giorgio Satta Cross - Entropy and Estimation of Probabilistic Context - Free Grammars .", "label": "", "metadata": {}, "score": "78.75934"}
{"text": "On the D. melanogaster loci which are these transcripts ' putative orthologs , performance of ReRanker-5 g and Evigan-5 g were evaluated and presented in Table 4 .ReRanker-5 g outperforms Evigan-5 g for sensitivity and specificity at the gene , transcript and exon level .", "label": "", "metadata": {}, "score": "78.79506"}
{"text": "Active learning methods attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .However , existing results for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to two non - classification tasks in natural language processing : semantic parsing and information extraction .", "label": "", "metadata": {}, "score": "78.806564"}
{"text": "Parallel dat ... \" .We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available , using annotated data from a set of one or more helper languages .Our approach is based on a model that locally mixes between supervised models from the helper languages .", "label": "", "metadata": {}, "score": "78.82855"}
{"text": "The parser uses considerable amounts of memory .If you see a java.lang.OutOfMemoryError , you either need to give the parser more memory or to take steps to reduce the memory needed .( You give java more memory at the command line by using the -mx flag , for example -mx500 m . )", "label": "", "metadata": {}, "score": "79.00017"}
{"text": "More precisely , an inductive logic programming ( ILP ) method , TABULATE , is developed for learning multiple models that are integrated via linear weighted combination to produce probabilistic models for statistical semantic parsing .Initial experimental results from three different domains suggest that an integration of statistical and logical approaches to semantic parsing can outperform a purely logical approach .", "label": "", "metadata": {}, "score": "79.00844"}
{"text": ".. \" ...We show how punctuation can be used to improve unsupervised dependency parsing .Our linguistic analysis confirms the strong connection between English punctuation and phrase boundaries in the Penn Treebank .However , approaches that naively include punctuation marks in the grammar ( as if they were wo ... \" .", "label": "", "metadata": {}, "score": "79.12155"}
{"text": "You can give the options -outputFormat typedDependencies or -outputFormat typedDependenciesCollapsed to get typed dependencies ( or grammatical relations ) output ( for English and Chinese only , currently ) .You can print out lexicalized trees ( head words and tags at each phrasal node with the -outputFormatOptions lexicalize option .", "label": "", "metadata": {}, "score": "79.293655"}
{"text": "Getting information about the top parse : .ptb_parse ( S1 ( S ( NP ( DT This ) ) ( VP ( VBZ is ) ( NP ( DT a ) ( NN sentence ) ) ) ( .If you have an existing tokenizer , tokenization can also be specified by passing a list of strings : .", "label": "", "metadata": {}, "score": "79.40524"}
{"text": "Airplane Detection in Satellite Images .In this section , we verify our model by 170 airplane ( top view ) satellite images taken from Google Earth .To gather a sufficiently large learning dataset , we acquire images from different heights and different directions .", "label": "", "metadata": {}, "score": "79.83983"}
{"text": "Unlike many current corpus - based approaches that use propositional or probabilistic learning algorithms , CHILL uses techniques from inductive logic programming ( ILP ) to learn relational representations .The reported experiments compare CHILL 's performance to that of a more naive application of ILP to parser acquisition .", "label": "", "metadata": {}, "score": "79.85109"}
{"text": "In fact , ReRanker-5 g and Evigan-5 g significantly outperform all of the five ab initio predictors used as evidence sources for Evigan-5 g ( Table 2 ) .Another factor that migh raise concerns of circularity in our evaluations is ReRanker 's use of D. pseudoobscura as a reference for gene prediction on D. melanogaster , since the former was annotated based on the latter .", "label": "", "metadata": {}, "score": "79.89838"}
{"text": "Background .Cross - species comparisons have been shown to be effective in locating genes and predicting gene structures .Augustus+ [ 19 , 20 ] extends Augustus [ 21 ] by incorporating alignments with genes and proteins of reference species into its ab initio gene model .", "label": "", "metadata": {}, "score": "79.90387"}
{"text": "PubMed .Solovyev V , Kosarev P , Seledsov I , Vorobyev D : Automatic annotation of eukaryotic genes , pseudogenes and promoters .Genome Biology 2006 , 7 ( Suppl 1 ) : S10 .View Article PubMed .Curwen V , Eyras E , Andrews T , Clarke L , Mongin E , Searle SM , Clamp M : The Ensembl Automatic Gene Annotation System .", "label": "", "metadata": {}, "score": "79.95888"}
{"text": "There is considerable Javadoc documentation included in the javadoc/ directory of the distribution .You should start by looking at the javadoc for the parser.lexparser package and the LexicalizedParser class .( The documentation appearing on the nlp.stanford.edu website refers to code under development and is not necessarily consistent with the released version of the parser . )", "label": "", "metadata": {}, "score": "80.05777"}
{"text": "N06 - 1024 [ bib ] : Ryan Gabbard ; Seth Kulick ; Mitchell Marcus Fully Parsing the Penn Treebank .N06 - 1025 [ bib ] : Simone Paolo Ponzetto ; Michael Strube Exploiting Semantic Role Labeling , WordNet and Wikipedia for Coreference Resolution .", "label": "", "metadata": {}, "score": "80.113266"}
{"text": "[ graphical display of the parse appears ] Contextual Hierarchical Part - Driven Conditional Random Field Model for Object Category Detection .College of Mechatronics Engineering and Automation , National University of Defense Technology , Changsha 410073 , China .Received 25 October 2012 ; Accepted 11 November 2012 .", "label": "", "metadata": {}, "score": "80.13173"}
{"text": "( Since these parsers were written , direct typed dependency parsers have been increasingly explored .Both us and others have now built parsers that directly parse to Stanford Dependencies .See the Stanford Dependencies page for more information . )For Chinese ( and Arabic , German , and \" WSJ \" ) , you can look at the included file makeSerialized.csh , and easily see exactly what files the models are trained on , in terms of LDC or Negra file numbers .", "label": "", "metadata": {}, "score": "80.14923"}
{"text": "By default , our Chinese parser uses GB18030 ( the native character encoding of the Penn Chinese Treebank and the national encoding of China ) for input and output .However , it is very easy to parse text in another character encoding : you simply give the flag -encoding encoding to the parser , where encoding is a character set encoding name recognized within Java , such as : UTF-8 , Big5-HKSCS , or GB18030 .", "label": "", "metadata": {}, "score": "80.21978"}
{"text": "This paper reviews our recent work on applying inductive logic programming to the construction of natural language processing systems .We have developed a system , CHILL , that learns a parser from a training corpus of parsed sentences by inducing heuristics that control an initial overly - general shift - reduce parser .", "label": "", "metadata": {}, "score": "80.3004"}
{"text": "N06 - 1009 [ bib ] : Tawanda Sibanda ; Ozlem Uzuner ; Ozlem Uzuner Role of Local Context in Automatic Deidentification of Ungrammatical , Fragmented Text .N06 - 1010 [ bib ] : Jing Jiang ; ChengXiang Zhai Exploiting Domain Structure for Named Entity Recognition .", "label": "", "metadata": {}, "score": "80.44182"}
{"text": "By default , DocumentPreprocessor uses PTBTokenizer for tokenization .If you need to change that , either because you have a better Tokenizer for your domain or because you have already tokenized your text , you can do that by passing in a TokenizerFactory such as a WhitespaceTokenizerFactory for no tokenization beyond splitting on whitespace .", "label": "", "metadata": {}, "score": "80.61772"}
{"text": "ParsingShell /path / to / model .Once in the shell , type a sentence to have the parser parse it : .Tokens : I saw the astronomer with the telescope .If you have nltk installed , you can use its tree visualization to see the output : .", "label": "", "metadata": {}, "score": "80.812485"}
{"text": "An example command line for this process , with some of the most useful flags , is java -mx4 g edu.stanford.nlp.parser.dvparser.CacheParseHypotheses -model /path / to / pcfg / pcfg.ser.gz -treebank /path / to / wsj 200 - 2199 -output cached.wsj.ser.gz -numThreads 6 .", "label": "", "metadata": {}, "score": "81.08299"}
{"text": "Results on these 1746 loci are shown in Table 3 .The performance of Evigan-5 g is relatively poor on these loci where genes contain relatively more exons ( 6.6 exons per gene on average for Table 3 versus 4.6 exons per gene for Table 2 ) reflecting the difficulties that genes of more exons pose to ab initio gene finders .", "label": "", "metadata": {}, "score": "81.10068"}
{"text": "The algorithm will loop over the examples in the training set until the weight vector does not change significantly .Outline of MIRA update .It is common practice to consider the average of the updated weight vector at each round as the final output weight vector , because the average weight vector often gives better performance than individual weight vectors [ 46 ] .", "label": "", "metadata": {}, "score": "81.12988"}
{"text": "Here , BP is suitable for our case due to the tree - like neighborhood structure .Experiments .In this section , we demonstrate the capability of the proposed model on two different datasets : Caltech-4 standard dataset and airplane images collected from Google Earth .", "label": "", "metadata": {}, "score": "81.15871"}
{"text": "Instead , we use distributional semantics to generate only the relevant part of an on - the - fly ontology .Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .", "label": "", "metadata": {}, "score": "81.25734"}
{"text": "In the area of program optimization , a prototype system , DOLPHIN , is able to transform some intractable specifications into polynomial - time algorithms , and outperforms competing approaches in several benchmark speedup domains .A prototype language acquisition system , CHILL , is also described .", "label": "", "metadata": {}, "score": "81.46838"}
{"text": "The comparative feature - points detecting results are shown in Figures 3(a ) and 3(b ) .Object Detection on Standard Database .The first dataset that we used to test our model is a subset of the Caltech-4 standard dataset , which contains images for two object categories , car ( rear view ) and airplane ( side view ) , and one background category .", "label": "", "metadata": {}, "score": "81.4999"}
{"text": "Behavior Control : Finally we show how all these elements can be incorporated into a goal keeping robot .We develop simple behaviors that can be used in a layered architecture and enable the robot to block most balls that are being shot at the goal .", "label": "", "metadata": {}, "score": "81.610176"}
{"text": "To turn these off , you can use the following options : .At present , we do n't have any documentation beyond what you get in the download and what 's on this page .If you would like to help by producing better documentation , feel free to write to parser-support@lists.stanford.edu .", "label": "", "metadata": {}, "score": "81.734085"}
{"text": "These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .", "label": "", "metadata": {}, "score": "81.88037"}
{"text": "N06 - 1048 [ bib ] : Gregory Marton ; Alexey Radul Nuggeteer : Automatic Nugget - Based Evaluation using Descriptions and Judgements .N06 - 1049 [ bib ] : Jimmy Lin ; Dina Demner - Fushman Will Pyramids Built of Nuggets Topple Over ?", "label": "", "metadata": {}, "score": "81.923645"}
{"text": "The problem occurs in the domain of lexical acquisition .The ambiguous and synonymous nature of words causes the difficulty of using standard induction techniques to learn a lexicon .Additionally , negative examples are typically unavailable or difficult to construct in this domain .", "label": "", "metadata": {}, "score": "81.96867"}
{"text": "View Article PubMed .Crammer K , Dekel O , Keshet J , Shalev - Shwartz S , Singer Y : Online Passive - Aggressive Algorithms .Journal of Machine Learning Research 2006 .Copyright .\u00a9 Liu et al .2008 .", "label": "", "metadata": {}, "score": "82.00942"}
{"text": "N06 - 1018 [ bib ] : Benjamin Han ; Donna Gates ; Lori Levin Understanding Temporal Expressions in Emails .N06 - 1019 [ bib ] : Stephen Clark ; James Curran Partial Training for a Lexicalized - Grammar Parser .", "label": "", "metadata": {}, "score": "82.27289"}
{"text": "The comparative results are summarized in Table 1 .As can be seen , our model consistently gives the best results for these three object categories for the car rear dataset and airplane side dataset .Note that the airplanes ( side ) are easier to be discriminated than cars due to their distinct shape structure .", "label": "", "metadata": {}, "score": "82.3074"}
{"text": "This frequently seems to confuse people , because the main predicate of the clause is now not a verb .But we believe that this is the best thing to do for several reasons : .Consistency of treatment of auxiliary / copula between English periphrastic verb forms and adjectival / nominal predications .", "label": "", "metadata": {}, "score": "82.57059"}
{"text": "QL , FP and DR designed the experiments .QL performed the experiments and analyzed the results .QL , KC and FP contributed ideas to the algorithms .QL , FP and DR wrote the paper .Authors ' Affiliations .", "label": "", "metadata": {}, "score": "82.62836"}
{"text": "The first and third pairs of overlapping splice sites are identified as shared splice sites .Signal peptides .A signal peptide feature , f 6 ( t ) , represents the co - occurence of predicted signal peptide on t and r .", "label": "", "metadata": {}, "score": "82.731636"}
{"text": "View Article PubMed .Stanke M , Tzvetkova A , Morgenstern B : AUGUSTUS at EGASP : using EST , protein and genomic alignments for improved gene prediction in the human genome .Genome Biology 2006 , 7 ( Suppl 1 ) : S11 .", "label": "", "metadata": {}, "score": "82.81661"}
{"text": "Second , adopting a syntax - based approach allows us to directly leverage the enormous progress made in statistical syntactic parsing .The first semantic parser , SCISSOR , adopts an integrated syntactic - semantic parsing approach , in which a statistical syntactic parser is augmented with semantic parameters to produce a semantically - augmented parse tree ( SAPT ) .", "label": "", "metadata": {}, "score": "83.2115"}
{"text": "The default HeadFinder is written specifically for the PTB .If you train a parser on trees that use a different set of productions , the default HeadFinder will not know how to handle this and will throw this exception .The easiest way to get around this problem is to use LeftHeadFinder instead .", "label": "", "metadata": {}, "score": "83.56915"}
{"text": "Again using January 2014 version 3.3.1 as an example , you would not make your classpath -cp stanford - parser-3.3.1.jar Instead , you would make it Windows : -cp stanford - parser-3.3.1 . jar : stanford - parser-3.3.1-models.jar .In order to see exactly which models are available , you can use jar tvf stanford - parser-3.3.1-models.jar This will show you that to access the Arabic Factored model , for example , you would use the path edu / stanford / nlp / models / lexparser / arabicFactored . ser.gz .", "label": "", "metadata": {}, "score": "83.62752"}
{"text": "We would recommend their use for parsing material from mainland China .The chinese grammars also include some training material from Hong Kong SAR and Taiwan .We 'd recommend their use if parsing material from these areas or a mixture of text types .", "label": "", "metadata": {}, "score": "83.6938"}
{"text": "UPPARSE , the software used for the experiments in this paper , is available under an open - sourc ... . \" ...In this work we address the problem of unsupervised part - of - speech induction by bringing together several strands of research into a single model .", "label": "", "metadata": {}, "score": "83.696075"}
{"text": "By only observing how humans follow navigation instructions , the system was able to infer the corresponding hidden navigation plans and parse previously unseen instructions in new environments for both English and Chinese data .With the rise in popularity of crowdsourcing , we also present results on collecting additional training data using Amazon 's Mechanical Turk .", "label": "", "metadata": {}, "score": "83.697525"}
{"text": "For example , this command ( with appropriate paths ) will convert a Penn Treebank file to uncollapsed typed dependencies : . java -cp stanford-parser.jar edu.stanford.nlp.trees.EnglishGrammaticalStructure -treeFile wsj/02/wsj_0201 .mrg -basic .Also , here is a sample Java class that you can download that converts from an input file of trees to typed dependencies .", "label": "", "metadata": {}, "score": "84.21954"}
{"text": "Semantic lexicons can also be learned from semantically annotated sentences and are an important source of knowledge for semantic parsing .Learning for semantic parsing is part of our research on natural language learning .\" The fish trap exists because of the fish .", "label": "", "metadata": {}, "score": "84.27078"}
{"text": "Gene models with good ( but not necessarily best ) probabilities defined by Evigan that also exhibit strong similarity to reference genes may thus be selected as most likely .Results and discussion .To assess the feasibility and accuracy of reranking candidate gene models based on cross - species comparison , we conducted an experiment seeking to identify gene models in the genome of Drosophila melanogaster ( stripped of all annotation ) , using D. pseudoobscura as reference species .", "label": "", "metadata": {}, "score": "84.28366"}
{"text": "Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .One of the main goals of natural language processing ( NLP ) is to build automated systems that can understand and generate human languages .", "label": "", "metadata": {}, "score": "84.945045"}
{"text": "When you do this , the tags for a token will be used in decreasing priority .token 0 ( ' Time ' ) should have tag VB , JJ , or NN and token 1 ( ' flies ' ) is unconstrained : .", "label": "", "metadata": {}, "score": "85.199005"}
{"text": "We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior knowledge .Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .", "label": "", "metadata": {}, "score": "85.23964"}
{"text": "With this code , you should be able to parse the sentence in a file with a command like this ( details depending on your shell , OS , etc . ) : . java -mx200 m -cp \" stanford - parser .", "label": "", "metadata": {}, "score": "85.24725"}
{"text": "The number of parts can be empirically set according to the complexity of objects .Figure 4 : Examples of the assignment of parts to local features for car object category ( a ) and airplane object category ( b ) , which are labeled by different number and colors .", "label": "", "metadata": {}, "score": "85.314354"}
{"text": "View Article PubMed .Meyer I , Durbin R : Gene structure conservation aids similarity based gene prediction .Nucleic Acids Res 2004 , 32 : 776 - 783 .View Article PubMed .Birney E , Clamp M , Durbin R : GeneWise and Genomewise .", "label": "", "metadata": {}, "score": "85.372925"}
{"text": "By default , the tokenizer used by the English parser ( PTBTokenizer ) performs various normalizations so as to make the input closer to the normalized form of English found in the Penn Treebank .One of these normalizations is the Americanization of spelling variants ( such as changing colour to color ) .", "label": "", "metadata": {}, "score": "85.739944"}
{"text": "By allowing both approaches to induce program clauses and choosing the best combination of their results , Cocktail learns more effective parsers .Experimental results on learning natural - language interfaces for two databases demonstrate that it learns more accurate parsers than Chillin , the previous best method for this task .", "label": "", "metadata": {}, "score": "85.801956"}
{"text": "The system learns to parse and generate commentaries without any engineered knowledge about the English language .Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games .The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model .", "label": "", "metadata": {}, "score": "85.974144"}
{"text": "Obviously , since the part appearance only reflects local image characteristics , these models can not get enough spatial information support .The neglected contextual interactions that are used to capture geometric relationships between parts of an object should play a more crucial role in the part - based model to enhance the representational power of model .", "label": "", "metadata": {}, "score": "86.65625"}
{"text": "Initially , the system will passively observe a human giving instruction to another human , and try to learn the correspondences between the instructions and the intended plan .After the system has a decent understanding of the language , it can then participate in the interactions to learn more directly by playing either the role of the instructor or the follower .", "label": "", "metadata": {}, "score": "86.910034"}
{"text": "This is an element of the dependency analysis we adopted .It 's not uncontroversial , and it could have been done differently , but we 'll try to explain briefly why we did things the way we did .The general philosophy of the grammatical relations design is that main predicates should be heads and auxiliaries should not .", "label": "", "metadata": {}, "score": "86.948975"}
{"text": "Experimental results show the improvements obtained over the purely supervised parser , particularly when the annotated training set is small .ML ID : 198 .This paper explores the use of statistical machine translation ( SMT ) methods for tactical natural language generation .", "label": "", "metadata": {}, "score": "86.977715"}
{"text": "For some sentences the parse tree output by the standalone parser and the tree output by the CoreNLP pipeline can be different .The reason for this is that if you run the CoreNLP pipeline with the default annotators , it will run a part - of - speech ( POS ) tagger before running the parser .", "label": "", "metadata": {}, "score": "87.097336"}
{"text": "Ball Tracking :The reliable tracking of the ball is vital in robot soccer .Therefore a Kalman - filter based system for estimating the ball position and velocity in the presence of occlusions is developped . -Sensor Fusion : The robot perceives its environment through several independent sensors ( camera , odometer , etc . ) , which have different delays .", "label": "", "metadata": {}, "score": "87.17206"}
{"text": "Learning for Semantic Parsing [ Details ] [ PDF ] Raymond J. Mooney In A. Gelbukh , editors , Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , 311 - -324 , Mexico City , Mexico , February 2007 .", "label": "", "metadata": {}, "score": "87.39078"}
{"text": "All data used in this experiment were downloaded from FlyBase [ 32 ] , including : .Whole genome sequence for D. melanogaster ( Release 5.1 ) , used as the target genome for gene model predictions .Ab initio gene model predictions from five gene finders ( Augustus [ 21 ] , Genscan [ 33 ] , Genie [ 34 ] , GeneID [ 35 ] and CONTRAST [ 10 ] ) , used as the input data for Evigan gene model predictions [ 31 ] .", "label": "", "metadata": {}, "score": "87.42705"}
{"text": "Genes where ReRanker-5 g selected the highest probability Evigan-5 g model .Genes where ReRanker-5 g selected a lower probability Evigan-5 g model ( used for Table 3 ) .Performance metrics include sensitivity and specificity on the gene , transcript and exon level ( see \" Methods \" for details ) , and the evaluation software Eval [ 37 ] was used .", "label": "", "metadata": {}, "score": "87.45647"}
{"text": "Of course , parsing will suffer unless your tokenization accurately matches the tokenization of the underlying treebank , for instance Penn Treebank tokenization .A common occurrence is that your text is already correctly tokenized but does not escape characters the way the Penn Treebank does ( turning parentheses into -LRB- and -RRB- , and putting a backslash in front of forward slashes and asterisks - presumably a holdover from Lisp ) .", "label": "", "metadata": {}, "score": "87.69412"}
{"text": "ML ID : 107 .The development of natural language interfaces ( NLI 's ) for databases has been a challenging problem in natural language processing ( NLP ) since the 1970 's .The need for NLI 's has become more pronounced due to the widespread access to complex databases now available through the Internet .", "label": "", "metadata": {}, "score": "87.7932"}
{"text": "You can invoke it with the -escaper flag , by using a command like the following ( which also shows output being sent to a file ) : . stp .Word segmentation : Chinese is not normally written with spaces between words .", "label": "", "metadata": {}, "score": "87.96851"}
{"text": "Experiments on Drosophila melanogaster demonstrate that reranking based on cross - species comparison outperforms the best gene models identified by Evigan alone , and also outperforms the comparative gene finders GeneWise and Augustus+ .Conclusion .Reranking gene models with cross - species comparison improves gene prediction accuracy .", "label": "", "metadata": {}, "score": "88.055695"}
{"text": "This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .Abstract .Even though several promising approaches have been proposed in the literature , generic category - level object detection is still challenging due to high intraclass variability and ambiguity in the appearance among different object instances .", "label": "", "metadata": {}, "score": "88.27394"}
{"text": "You may use the parse method that takes a String argument to have this done for you or you may be able to use of classes in the process package , such as DocumentPreprocessor and PTBTokenizer for tokenization , much as the main method of the parser does .", "label": "", "metadata": {}, "score": "88.295586"}
{"text": "Inductive Logic Programming for Natural Language Processing [ Details ] [ PDF ] Raymond J. Mooney In Stephen Muggleton , editors , Inductive Logic Programming : Selected papers from the 6th International Workshop , 3 - 22 , Berlin , 1996 .", "label": "", "metadata": {}, "score": "89.012955"}
{"text": "Computers fail to track these in fast video , but sleight of hand fools humans as well : what happens too quickly we just can not see .We show a 3D tracker for these types of motions that relies on the recognition of familiar configurations in 2D images ( classification ) , and fills the gaps in - between ( interpolation ) .", "label": "", "metadata": {}, "score": "89.22434"}
{"text": "The system does not use any prior language knowledge and was able to learn to sportscast in both English and Korean .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans .", "label": "", "metadata": {}, "score": "89.81818"}
{"text": "For part of speech and phrasal categories , here are relevant links : .Please read the documentation for each of these corpora to learn about their tagsets and phrasal categories .You can often also find additional documentation resources by doing web searches .", "label": "", "metadata": {}, "score": "89.90184"}
{"text": "Augustus+ [ 20 ] extends the ab initio gene finder Augustus [ 21 ] by considering transcript or protein alignments as extrinsic hints , up- or down - weighting ab initio gene parses based on consistency with the alignments .The bottom half of Tables 2 and Table 3 compares the performance of ReRanker-5 g with GeneWise and Augustus+ on the complete D. melanogaster test set , and the subset of genes where Evigan-5 g and ReRanker-5 g chose different models . GeneWise", "label": "", "metadata": {}, "score": "90.42932"}
{"text": "We feel that this is more useful for most semantic interpretation applications , because it directly connects the main predicate with its arguments , while the auxiliary is rendered as modifying the verb ( aux(singing , is ) ) .Most people seem to agree .", "label": "", "metadata": {}, "score": "90.8512"}
{"text": "predictions of CDS , donor , acceptor , start and stop information were then provided as extrinsic hints for Augustus+ ( using ab initio parameters trained for Drosophila melanogaster and default parameters for extrinsic protein hints ) .Evigan was also run to integrate GeneWise models with the five ab initio source gene finders described above , yielding Evigan-6 g .", "label": "", "metadata": {}, "score": "90.96857"}
{"text": "The shared splice feature f 5 ( t ) is given by .Infering shared splice sites from alignement .Blue boxes represent segments ( local alignments ) produced by DiAlign [ 44 ] between coding sequences of two gene models and the wavy lines represent unaligned regions .", "label": "", "metadata": {}, "score": "91.53375"}
{"text": "Parsing file : - i ca n't believe @mistamau does n't know who channing tatum is ... # loser Parsing [ sent .1 len .Parsed 14 words in 1 sentences ( 4.29 wds / sec ; 0.31 sents / sec ) .", "label": "", "metadata": {}, "score": "91.950806"}
{"text": "To translate a source sentence , we first employ a parser to pro - duce a source parse tree and then ap - ply TATs to transform the tree into a tar - get string .Our experiments show that the TAT - based model significantly outper - forms Pharaoh , a state - of - the - art decoder for phrase - based models . .", "label": "", "metadata": {}, "score": "92.69197"}
{"text": "There 's not much in the way of secret sauce to speed that up ( partly by the design of the parsers as guaranteed to find model optimal solutions ) .If you 're not using englishPCFG.ser.gz for English , then you should be - it 's much faster than the Factored parser .", "label": "", "metadata": {}, "score": "94.458405"}
{"text": "In order to measure the influence of neighborhood structures , we also investigate the performance of an equivalent model without weighted neighborhood structure .The object categories are car ( rear ) , airplane ( side ) , and airplane ( top ) , which have been mentioned in previous sections .", "label": "", "metadata": {}, "score": "95.69705"}
{"text": "ReRanker-5 g also outperformed Evigan-6 g as assessed by all criteria except for overall and internal exon sensitivity .In cases where ReRanker-5 g and Evigan-5 g make different choices ( Table 3 ) , ReRanker-5 g outperforms GeneWise and Evigan-6 g , but performs worse than Augustus+ in most categories .", "label": "", "metadata": {}, "score": "96.50432"}
{"text": ", Augustus+ and Evigan-6 g are other comparative gene predictors or approaches .Bold indicates where ReRanker-5 g outperforms Evigan-5 g ; italics indicates where other comparative approaches outperform ReRanker-5 g ( see text ) .Table 3 .Gene - finding performance for genes where ReRanker-5 g differs from Evigan-5 g .", "label": "", "metadata": {}, "score": "96.57178"}
{"text": "This work is supported by a special financial grant from the China Postdoctoral Science Foundation ( Grant no .20100481512 , 201104765 ) .The authors would like to thank Kevin Murphy for publishing CRF2D toolbox , which is very helpful for this work .", "label": "", "metadata": {}, "score": "97.25321"}
{"text": "ILP , which investigates the learning of relational ( first - order ) rules , provides an empirical method for acquiring knowledge within traditional , symbolic parsing frameworks .This dissertation details the architecture , implementation and evaluation of CHILL a computer system for acquiring natural language parsers by training over corpora of parsed text .", "label": "", "metadata": {}, "score": "97.35573"}
{"text": "Many different methods have been proposed , yet comparisons are difficult to make since there is little consensus on evaluation framework , and many papers evaluate against only one or two competitor syste ... \" .Part - of - speech ( POS ) induction is one of the most popular tasks in research on unsupervised NLP .", "label": "", "metadata": {}, "score": "97.46587"}
{"text": "That is , sentences like Jill is busy or Jill is a teacher .We continue to regard the adjective or noun as the predicate of which the subject is the argument , rather than changing and now regarding the copular verb is as the head and busy / teacher as a complement .", "label": "", "metadata": {}, "score": "97.596"}
{"text": "In this example , token 0 ( ' Time ' ) should have tag VB and token 1 ( ' flies ' ) should have tag NNS : .You do n't need to specify a tag for all words : Here , token 0 ( ' Time ' ) should have tag VB and token 1 ( ' flies ' ) is unconstrained : .", "label": "", "metadata": {}, "score": "98.1426"}
{"text": "The / DT quick / JJ brown / JJ fox / NN jumped / VBD over / IN the / DT lazy / JJ dog / NN .with the command : . ser.gz fox.txt .Partially - tagged input ( only indicating the POS of some words ) is also OK .", "label": "", "metadata": {}, "score": "98.40473"}
{"text": "This Master 's thesis describes parts of the control software used by the soccer robots of the Free University of Berlin , the so called FU - Fighters .The FU - Fighters compete in the Middle Sized League of RoboCup and reached the semi - finals during the 2004 RoboCup World Cup in Lisbon , Portugal .", "label": "", "metadata": {}, "score": "98.61566"}
{"text": "That is , they will just say Jill busy .Connection to logical representations : If you were to translate these sentences into a simple predicate logic form , you would presumably use busy(jill ) and teacher(jill ) .The treatment of the adjective or noun as the predicate in a predicate logic form parallels what we do in our grammatical relations representation .", "label": "", "metadata": {}, "score": "98.89106"}
{"text": "PTBEscapingProcessor .If calling the parser within your own program , the main parse methods take a List of words which should already be correctly tokenized and escaped before calling the parser .You do n't need to and can not give the -tokenized option .", "label": "", "metadata": {}, "score": "102.53883"}
{"text": "The rabbit snare exists because of the rabbit .Once you 've gotten the rabbit , you can forget the snare .Words exist because of meaning .Once you 've gotten the meaning , you can forget the words .", "label": "", "metadata": {}, "score": "111.25737"}
{"text": "Splice count similarity .As with coding length , we also compare the number of splice sites in source and target .Let s ( t ) and s ( t ) denote the number of splice sites of t and r .", "label": "", "metadata": {}, "score": "111.972946"}
{"text": "If a splice site of t and a splice site of r are mapped to the same relative position within a segment , as exemplified by the first and third pairs of splice sites in the figure , they are identified as a shared splice site .", "label": "", "metadata": {}, "score": "121.18831"}
{"text": "View at Scopus", "label": "", "metadata": {}, "score": "148.67963"}
