{"text": "We then exploit syntactic features , topic span features , and semantic features to disambiguate nouns and verbs in the context of ambiguous word .Finally , we conduct experiments on the standard data set SemCor to evaluate the performance of the proposed method , and the results indicate that our approach achieves relatively better performance than existing approaches .", "label": "", "metadata": {}, "score": "32.085754"}
{"text": "These features include syntactic features , semantic features , and topical features .The syntactic features are based on the preprocessing steps of the input text , such as tokenization , part - of - speech tagging , chunking , and parsing .", "label": "", "metadata": {}, "score": "32.567345"}
{"text": "Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet Agirre , E. and Rigau , G. ( 1996 ) .", "label": "", "metadata": {}, "score": "32.84958"}
{"text": "decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .This experiment involved the following steps : . # deriving a lexicon from the WordNet data files which contains all possible semantic tags for each noun , adjective , adverb and verb .", "label": "", "metadata": {}, "score": "34.37916"}
{"text": "We obtain a large improvement when adopting the WSD algorithm based on topical - semantic association graph .Acknowledgments .References .Z.-Y. Niu , D.-H. Ji , and C. L. Tan , \" Learning model order from labeled and unlabeled data for partially supervised classification , with application to word sense disambiguation , \" Computer Speech and Language , vol .", "label": "", "metadata": {}, "score": "34.774887"}
{"text": "In [ 1 ] , Stevenson et al .use supervised learners with linguistic features extracted from the context of the word in combination with MeSH terms for disambiguation .The UMLS has been used , by Humphrey et al . , as a knowledge source for assigning the correct sense for a given word [ 13 ] .", "label": "", "metadata": {}, "score": "34.970295"}
{"text": "What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 10 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .", "label": "", "metadata": {}, "score": "35.9089"}
{"text": "What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 10 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .", "label": "", "metadata": {}, "score": "35.9089"}
{"text": "View at Scopus .T. Pedersen and R. Bruce , \" Distinguishing word senses in untagged text , \" in Proceedings of the 2nd Conference on Empirical Methods in Natural Language Processing , 1997 .G. Sidorov and A. Gelbukh , \" Word sense disambiguation in a spanish explanatory dictionary , \" in Proceedings of the Tratamiento Autom\u00e1tico de Lengauje Natural ( TALN'01 ) , pp .", "label": "", "metadata": {}, "score": "35.930626"}
{"text": "The main classes of approaches of word sense disambiguation include supervised methods and unsupervised methods .The supervised methods rely on training and learning phases that require a dataset or corpus containing manually disambiguated instances to be used to train the system [ 5 , 6 ] .", "label": "", "metadata": {}, "score": "36.942024"}
{"text": "Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 5 ] and LDOCE [ 6 ] .", "label": "", "metadata": {}, "score": "36.982716"}
{"text": "Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 5 ] and LDOCE [ 6 ] .", "label": "", "metadata": {}, "score": "36.982716"}
{"text": "In this paper , we propose a novel approach to word sense disambiguation based on topical and semantic association .For a given document , supposing that its topic category is accurately discriminated , the correct sense of the ambiguous term is identified through the corresponding topic and semantic contexts .", "label": "", "metadata": {}, "score": "37.00209"}
{"text": "Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .", "label": "", "metadata": {}, "score": "37.08254"}
{"text": "Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .", "label": "", "metadata": {}, "score": "37.08254"}
{"text": "Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .", "label": "", "metadata": {}, "score": "37.08254"}
{"text": "M. Weeber , J. Mork , and A. Aronson , \" Developing a test collection for biomedical word sense disambiguation , \" in Proceedings of the Symposium American Medical Informatics Association ( AMIA ' 01 ) , 2001 .M. F. Porter , \" An algorithm for suffix stripping , \" Program , vol .", "label": "", "metadata": {}, "score": "37.173203"}
{"text": "This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .", "label": "", "metadata": {}, "score": "37.576134"}
{"text": "This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .", "label": "", "metadata": {}, "score": "37.576134"}
{"text": "It should be noted that unsupervised disambiguation can not actually label specific terms as a referring to a specific concept : that would require more information than is available .What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .", "label": "", "metadata": {}, "score": "37.873703"}
{"text": "More generally , the Semantic Web requires automatic annotation of documents according to a reference ontology .WSD is only beginning to be applied in these areas .Methods .There are four conventional approaches to WSD : . Dictionary-and knowledge - based methods : These rely primarily on dictionaries , thesauri , and lexical knowledge bases , without using any corpus evidence .", "label": "", "metadata": {}, "score": "38.087692"}
{"text": "391 - 407 , 1990 .View at Google Scholar .T. Pedersen and R. Bruce , \" Distinguishing word senses in untagged text , \" in Proceedings of the 2nd Conference on Empirical Methods in Natural Language Processing , 1997 . E. Agirre and P. Edmond , Word Sense Disambiguation : Algorithms and Applications , Springer , New York , NY , USA , 2006 .", "label": "", "metadata": {}, "score": "38.109062"}
{"text": "Related Work .Word sense disambiguation is the ability to identify the words ' sense in a computational manner [ 1 ] .We can broadly overview two main approaches to WSD , namely , machine learning and external knowledge sources .", "label": "", "metadata": {}, "score": "38.16046"}
{"text": "To reduce the effect of insignificant differences between chunks , words from the stopwords list in PubMed [ 16 ] and punctuation remarks were removed before matching if they appeared at the start or the end of a phrase .Results .", "label": "", "metadata": {}, "score": "38.95868"}
{"text": "[Links ] .[Links ] .Resnik , P. Selectional preference and sense disambiguation , ACL SIGLEX Workshop on Tagging Text with Lexical Semantics : Why , What , and How ?[Links ] .Ph.D. Thesis , University of Pennsylvania , December , 1993 .", "label": "", "metadata": {}, "score": "38.96762"}
{"text": "These contexts are generated using the words that define the senses of the ambiguous words , the exact string - matching algorithm , and the corpus .We use the measures employed in the domain of information retrieval , Harman , Croft , and Okapi combined to the Lesk algorithm , to assign the correct sense of those proposed .", "label": "", "metadata": {}, "score": "39.306866"}
{"text": "Sentence splitting , tokenization , and part - of - speech tagging were included in our chunking pipeline , either as integral part of the chunkers ( Yamcha , Lingpipe ) or as separate components ( OpenNLP ) .We used the gold - standard sentence , token , and part - of - speech annotations for training , but did not use this information in creating the SSC or evaluating the trained models : the input of the annotation pipeline consisted of plain abstracts , the output were chunking annotations .", "label": "", "metadata": {}, "score": "39.43981"}
{"text": "The sentences containing these occurrences with the ambiguous word represent the contexts of use .The second step of the proposed method is to measure the similarity between the different contexts of use generated from the glosses and the current context .", "label": "", "metadata": {}, "score": "40.205936"}
{"text": "These techniques have the potential to help in the adaptation of supervised models to different domains .Also , an ambiguous word in one language is often translated into different words in a second language depending on the sense of the word .", "label": "", "metadata": {}, "score": "40.272263"}
{"text": "Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .", "label": "", "metadata": {}, "score": "40.559578"}
{"text": "Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .", "label": "", "metadata": {}, "score": "40.559578"}
{"text": "Abend et al .[16 ] introduce a novel supervised learning model for mapping verb instances to VN classes , using rich syntactic features and class membership constraints .The above two methods are based on supervised learning methods with rich features based on part - of - speech tags , word stems , surrounding and cooccurring words , and dependency relationships .", "label": "", "metadata": {}, "score": "40.742153"}
{"text": "and knowledge - based methods .The Lesk method ( Lesk 1986 ) is the seminal dictionary - based method .It is based on the hypothesis that words used together in text are related to each other and that the relation can be observed in the definitions of the words and their senses .", "label": "", "metadata": {}, "score": "40.87053"}
{"text": "Table 2 indicates that the result of TSA with WordNet+ODP achieves the best performance to disambiguate words .The performances obtained for nouns are sensibly higher than the one obtained for verbs , confirming the claim that topical describing information is crucial to determine the unique sense of ambiguous term .", "label": "", "metadata": {}, "score": "40.878403"}
{"text": "View at Publisher \u00b7 View at Google Scholar .S. Banerjee and T. Pedersen , Adapting the lesk algorithm for word sense disambiguation to WordNet [ M.S. thesis ] , Partial Fulfillment of the Requirements , 2002 .S. Derwester , S. T. Dumais , G. W. Furnas , T. K. Landauer , and R. Harshmann , \" Indexing by latent semantic analysis , \" Journal of the American Society for Informartion Science , vol .", "label": "", "metadata": {}, "score": "40.96072"}
{"text": "The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .To appear in Journal of Natural Language Engineering , 4(3 ) .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .", "label": "", "metadata": {}, "score": "40.986313"}
{"text": "The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .To appear in Journal of Natural Language Engineering , 4(3 ) .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .", "label": "", "metadata": {}, "score": "40.986313"}
{"text": "( 1996 ) which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .A similarity matrix is thus formed which is subject to cluster analysis to determine groups of semantically related instances of terms .", "label": "", "metadata": {}, "score": "41.47856"}
{"text": "The sentence frames state that different senses of verbs may occur with an infinitive , with a transitive , and with an intransitive syntactic frame .The syntactic structure information provided by WordNet is rather scarce and not enough to implement the task of verb disambiguation .", "label": "", "metadata": {}, "score": "41.48912"}
{"text": "The corpus has been annotated with various levels of linguistic and semantic information , such as sentence splitting , tokenization , part - of - speech tagging , chunking annotation , and term - event information .For chunker training , we selected a subset of 500 abstracts that constituted a previous version of the GENIA corpus [ 12 ] .", "label": "", "metadata": {}, "score": "41.50314"}
{"text": "This evaluation measures a 58 % precision , using the simplified Lesk algorithm [ 24 ] , and only a 42 % under the original algorithm .The algorithm of Lesk is used to find the gloss that matches more with the candidate glosses of the words contained in the same sentence including the word to be disambiguated .", "label": "", "metadata": {}, "score": "41.67015"}
{"text": "Unsupervised word sense disambiguation rivaling supervised methods .Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics , 189 - 196 .Yarowsky , David .Word sense disambiguation .Handbook of Natural Language Processing , ed . by Dale et al .", "label": "", "metadata": {}, "score": "41.86573"}
{"text": "The main limitation with supervised methods is the need for a corpus of manually disambiguated instances of the ambiguous words .However , the advances in automatic text annotation and tagging techniques with the help of the plethora of knowledge sources like ontologies and text literature in the biomedical domain will help lessen this limitation .", "label": "", "metadata": {}, "score": "42.019054"}
{"text": "Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 9 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .", "label": "", "metadata": {}, "score": "42.19281"}
{"text": "Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 9 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .", "label": "", "metadata": {}, "score": "42.19281"}
{"text": "Table 1 : The performance of the topic identification based on extracting topic discriminative terms .The Performance of Word Sense Disambiguation .We compare our WSD approach based on topical and semantic association ( TSA ) using WordNet + ODP with other state - of - the - art WSD approaches , namely , the ExtLesk algorithm and the SSI algorithm .", "label": "", "metadata": {}, "score": "42.212605"}
{"text": "In addition , the approach of domain - oriented disambiguation [ 12 ] is similar to our idea .The hypothesis of this approach is that the knowledge of a topic or domain can help disambiguate words in a particular domain text [ 1 ] .", "label": "", "metadata": {}, "score": "42.497337"}
{"text": "Up to present , diverse WSD methods have been proposed .These methods are overviewed as machine learning ( includes supervised and unsupervised ) and external knowledge sources .Generally speaking , these methods have the potential bottleneck and limitation .However , almost all the methods , without exception , depend on the context in which the ambiguous word occurs .", "label": "", "metadata": {}, "score": "42.565395"}
{"text": "In order to evaluate our system , we developed a Method for Converting a Gold Standard from a constituent format to a dependency format .Additionally , each one of the modules of the system ( Selectional Preferences Acquisition and Prepositional Phrase Attachment Disambiguation ) , is evaluated in a separate and independent way to verify that they work properly .", "label": "", "metadata": {}, "score": "42.685528"}
{"text": "Lexical sample : the occurrences of a small sample of target words need to be disambiguated , and .All - words : all the words in a piece of running text need to be disambiguated .In order to define common evaluation datasets and procedures , public evaluation campaigns have been organized .", "label": "", "metadata": {}, "score": "43.043453"}
{"text": "Revision as of 04:20 , 25 June 2012 .Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .", "label": "", "metadata": {}, "score": "43.102383"}
{"text": "Links ] .Carreras , Xavier , Isaac Chao , Lluis Padr\u00f3 , Muntsa Padr\u00f3 .Proc .4 th Intern .Conf .[Links ] .Carroll , J. , D. McCarthy .Word sense disambiguation using automatically acquired verbal preferences .", "label": "", "metadata": {}, "score": "43.102856"}
{"text": "W. Croft , \" Experiments with representation in a document retrieval system , \" Research and Develpment , vol .2 , no . 1 , pp . 1 - 21 , 1983 .View at Google Scholar .S. Robertson , M. Walker , and M. Gatford , Okapi at TREC-3 , TREC-3 , NIST Special Publication , 1994 . A. Zouaghi , L. Merhbene , and M. Zrigui , \" Combination of information retrievalmethods with LESK algorithm for arabic word sense disambiguation , \" Artificial Intelligence Review , vol .", "label": "", "metadata": {}, "score": "43.11366"}
{"text": "Yarowsky reports that the system correctly classifies senses 96 % of the time .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .", "label": "", "metadata": {}, "score": "43.359222"}
{"text": "We present a method for recognizing semantic roles for Spanish sentences .If a complete parse can not be produced , a partial structure is built with some ( if not all ) dependency relations identified .Evaluation shows that in spite of its simplicity , the parser 's accuracy is superior to the available existing parsers for Spanish .", "label": "", "metadata": {}, "score": "43.443985"}
{"text": "These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 12 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .", "label": "", "metadata": {}, "score": "43.89144"}
{"text": "These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 12 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .", "label": "", "metadata": {}, "score": "43.89144"}
{"text": "After that , we apply the \u200e routing [ 4 ] for the words contained in the glosses of the ambiguous word .Then we use the exact string - matching algorithm [ 5 ] to be able to extract the contexts of uses from the corpus used .", "label": "", "metadata": {}, "score": "43.91861"}
{"text": "In Proceedings of COLING'96 and LDOCE J. Guthrie , L. Guthrie , Y. Wilks and H. Aidinejad , Subject - Dependent Co - Occurrence and Word Sense Disambiguation , ACL-91 , pp .146 - 152 .The information in these resources has been used in several ways , for example Wilks and Stevenson Y. Wilks and M. Stevenson .", "label": "", "metadata": {}, "score": "43.91951"}
{"text": "67 - 86 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . K. Tsutsumida , J. Okamoto , S. Ishizaki , M. Nakatsuji , A. Tanaka , and T. Uchiyama , Study of Word Sense Disambiguation System That Uses Contextual Features Approach of Combining Associative Concept Dictionary and Corpus[C ] , LREC , 2010 . A. Montoyo , M. Palomar , G. Rigau , and A. Suarez , \" Combining Knowledge- and Corpus - based Word - Sense - Disambiguation Methods[C ] , \" CoRR abs/1109 .", "label": "", "metadata": {}, "score": "43.992252"}
{"text": "View at Scopus In natural language processing , word sense disambiguation ( WSD ) is the problem of determining which \" sense \" ( meaning ) of a word is activated by the use of the word in a particular context , a process which appears to be largely unconscious in people .", "label": "", "metadata": {}, "score": "44.046825"}
{"text": "[Links ] .Sowa , John F. 1984 .Conceptual Structures : Information Processing in Mind and Machine .[Links ] .Steele , James ( ed . )Linguistics , Lexicography , and Implications .Ottawa : Univ . of Ottawa Press , 1990 .", "label": "", "metadata": {}, "score": "44.076206"}
{"text": "This figure shows that the Lesk algorithm ameliorates the rate of disambiguation .Conclusion .This paper has presented an unsupervised method to perform word sense disambiguation in Arabic .This algorithm is based on segmentation elimination of stop words , stemming and applying the approximate string matching algorithm for the words of the glosses .", "label": "", "metadata": {}, "score": "44.118164"}
{"text": "Given all that , the major difference between our disambiguation strategy and these existing approaches is that we focus on term - concept association and concept - topic association , moreover , in the way of determining the appropriate size of disambiguation context .", "label": "", "metadata": {}, "score": "44.219074"}
{"text": "References .M. Stevenson , Y. Guo , R. Gaizauskas , and D. Martinez , \" Knowledge sources for word sense disambiguation of biomedical text , \" in Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing ( BioNLP ' 08 ) , pp .", "label": "", "metadata": {}, "score": "44.7846"}
{"text": "View at Scopus .O. Abend , R. Reichart , and A. Rappoport , \" A supervised algorithm for verb disambiguation into VerbNet classes , \" in Proceedings of the 22nd International Conference on Computational Linguistics ( Coling ' 08 ) , pp .", "label": "", "metadata": {}, "score": "44.8988"}
{"text": "LRA extends the VSM approach in three ways : ( 1 ) patterns are derived automatically from the corpus , ( 2 ) Singular Value Decomposition is used to smooth the frequency data , and ( 3 ) synonyms are used to reformulate word pairs .", "label": "", "metadata": {}, "score": "44.93516"}
{"text": "Links ] .Weinreich , Uriel .Explorations in Semantic Theory , Mouton , The Hague , 1972 .[Links ] .Yarowsky , D. , Hierarchical decision lists for word sense disambiguation .[Links ] .Yarowsky , D. , S. Cucerzan , R. Florian , C. Schafer , R. Wicentowski .", "label": "", "metadata": {}, "score": "45.032352"}
{"text": "( i )The important number of glosses given by a dictionary for the ambiguous word .( ii )The problem of the sentence segmentation due to the ambiguity of the Arabic language [ 1 ] .( iii ) Finding the samples for the tests that can be judged as well as not so different for the process of disambiguation .", "label": "", "metadata": {}, "score": "45.138474"}
{"text": "Named entity recognition is generally considered more difficult than chunking , having to deal with increased complexities in boundary recognition , disambiguation , and spelling variation of entities .Clearly , the better a silver standard will approach a gold standard for the domain of interest , the better the performance of systems trained on an SSC .", "label": "", "metadata": {}, "score": "45.217453"}
{"text": "A Method for WSD .A word sense disambiguation method is an algorithm that assigns the most accurate sense to a given word in a given context .Our method is a supervised method requiring a training corpus that contains manually disambiguated instances of the ambiguous words .", "label": "", "metadata": {}, "score": "45.494488"}
{"text": "More contexts which may not be necessarily helpful , on the contrary , will increase computational complexity .Consequently , in order to achieve disambiguation task , there are several challenges , as follows : . combining topic chain and disambiguation context into topic semantic profile for identifying topic discriminative term and constructing topical graph based on the topic span intervals of topic discriminative term to implement the document 's topic identification , . determining the unique sense of ambiguous term using topical - semantic association graph , paying more attention to exploiting syntactic features , semantic features , and topical features to implement verb and noun disambiguation .", "label": "", "metadata": {}, "score": "45.549744"}
{"text": "To appear in Journal of Natural Language Engineering , 4(3 ) .use large lexicons ( generally machine readable dictionaries ) and the information associated with the senses ( such as part - of - speech tags , topical guides and selectional preferences ) to indicate the correct sense .", "label": "", "metadata": {}, "score": "45.705032"}
{"text": "Due to a variety of senses or the vague sense for a given term , the determination of its topic category label is the most difficult problem .Restricting semantic disambiguation context is a standard technique to mitigate the problem of term 's cross topic .", "label": "", "metadata": {}, "score": "45.71405"}
{"text": "Semi - supervised or minimally - supervised methods : These make use of a secondary source of knowledge such as a small annotated corpus as seed data in a bootstrapping process , or a word - aligned bilingual corpus .Unsupervised methods : These eschew ( almost ) completely external information and work directly from raw unannotated corpora .", "label": "", "metadata": {}, "score": "45.729786"}
{"text": "Finally , in Section 4 , we present \u200e the obtained results .Main Used Approaches .Most of the works related to the word sense disambiguation were applied to the English .They achieve a disambiguation rate of around 90 % .", "label": "", "metadata": {}, "score": "45.75354"}
{"text": "Table 2 : The performance of disambiguating through TSA versus other state - of - the art algorithms .Conclusions .In this paper , we propose a novel approach for word sense disambiguation based on topical and semantic association .Our experiments show that the topic categories of Open Directory Project merged into WordNet are of high quality and , more importantly , it enables external knowledge - based WSD applications to perform better than the existing methods of only using WordNet .", "label": "", "metadata": {}, "score": "45.79282"}
{"text": "Links ] .Sag , Ivan , Tom Wasow , and Emily M. Bender .Syntactic Theory .A Formal Introduction ( 2nd Edition ) .CSLI Publications , Stanford , CA , 2003 [ Links ] .Sebasti\u00e1n , N. , M. A. Mart\u00ed , M. F. Carreiras , and F. Cuestos .", "label": "", "metadata": {}, "score": "45.939274"}
{"text": "When trained on GENIA GSC and tested on PennBioIE GSC , the F - score of the combined system dropped to 82.1 % for noun phrases and 91.9 % for verb phrases .Since this performance is considerably lower than that of the combined system based on all chunkers , we did not further pursue the use of an SSC based on the three trainable chunkers only .", "label": "", "metadata": {}, "score": "45.976036"}
{"text": "Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , Segond , F. , Schiller , A. , Grefenstette , G. , and Chanod , J. ( 1997 ) .An experiment in semantic tagging using hidden markov model tagging .", "label": "", "metadata": {}, "score": "45.99872"}
{"text": "Yarowsky D , Florian R : Evaluating sense disambiguation across diverse parameter spaces .Nat Lang Eng 2002 , 8 : 293 - 310 .View Article .Surdeanu M , Turmo J , Comelles E : Named entity recognition from spontaneous open - domain speech .", "label": "", "metadata": {}, "score": "46.08752"}
{"text": "275 - 298 , Springer , 2006 .View at Google Scholar .G. K. Savova , A. R. Coden , I. L. Sominsky et al . , \" Word sense disambiguation across two domains : biomedical literature and clinical notes , \" Journal of Biomedical Informatics , vol .", "label": "", "metadata": {}, "score": "46.161713"}
{"text": "It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .", "label": "", "metadata": {}, "score": "46.310318"}
{"text": "It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .", "label": "", "metadata": {}, "score": "46.310318"}
{"text": "Also words with parentheses or square brackets are not ignored and part of speech is not used .After the text preprocessing is completed , for each word we convert the instances into numeric feature vectors .Then , we use SVM for training and testing with 5-fold cross validation 5FCV such that 80 % of the instances are used for training and the remaining 20 % are used for testing , and this is repeated five times by changing the training - testing portions of the data .", "label": "", "metadata": {}, "score": "46.35135"}
{"text": "Keywords : dependency parsing , pp attachment disambiguation , constituent to dependency conversion , heuristic rules , hybrid parser , selectional preferences .Resumen .Se presenta un m\u00e9todo para reconocer los roles sem\u00e1nticos de las oraciones en espa\u00f1ol , es decir , identificar el papel que tiene cada uno de los elementos de la oraci\u00f3n .", "label": "", "metadata": {}, "score": "46.459435"}
{"text": "( or mostly in . , then the MI indicates this as shown in ( 2 ) .Thus , MI can be used as a means to estimate the amount of information interaction between a context work and a class label .", "label": "", "metadata": {}, "score": "46.484386"}
{"text": "By removing stopwords before matching we tried to remove \" uninformative \" words that should not play a role in determining whether phrases are the same , similar to other studies ( e.g. , [ 19 , 20 ] ) .Stopword removal can be seen as a relaxation of the strict matching requirement .", "label": "", "metadata": {}, "score": "46.6294"}
{"text": "Our approach in this paper is a supervised approach .In this paper , we present and evaluate a supervised method for biomedical word sense disambiguation .The method is based on machine learning and uses some feature selection techniques in constructing feature vectors for the words to be disambiguated .", "label": "", "metadata": {}, "score": "47.142326"}
{"text": "Human language is ambiguous ; many words can have more than one sense : this sense is dependent on the context of use .The word sense disambiguation ( WSD ) allows us to find the most appropriate sense of an ambiguous word .", "label": "", "metadata": {}, "score": "47.242523"}
{"text": "This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 13 ] .", "label": "", "metadata": {}, "score": "47.26927"}
{"text": "This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 13 ] .", "label": "", "metadata": {}, "score": "47.26927"}
{"text": "[ 1 ] The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .", "label": "", "metadata": {}, "score": "47.41318"}
{"text": "[ 1 ] The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .", "label": "", "metadata": {}, "score": "47.41318"}
{"text": "In press . Y. Miyao , K. Sagae , R. S\u00e6tre , T. Matsuzaki , and J. Tsujii , \" Evaluating contributions of natural language parsers to protein - protein interaction extraction , \" Bioinformatics , vol .25 , no . 3 , pp .", "label": "", "metadata": {}, "score": "47.484"}
{"text": "( extended and modified version of this paper is available as technical report FI MU ) .Z\u00e1ckov\u00e1 E. , Popel\u00ednsk\u00fd L. , Nepil M. : Automatic Tagging of Compound Verb Groups in Czech Corpora .In Proceedings of TSD 2000 , LNAI 1902 , Springer Verlag 2000 , pp .", "label": "", "metadata": {}, "score": "47.509975"}
{"text": "The contexts are represented by high - dimensional spaces defined by word co - occurrences .The second one clusters the contexts that contain a specified target word such that the resulting clusters will be made up of contexts that use the target word in the same sense .", "label": "", "metadata": {}, "score": "47.882694"}
{"text": "An experiment in semantic tagging using hidden markov model tagging .In Vossen , P. , Adriaens , G. , Calzolari , N. , Sanfilippo , A. , and Wilks , Y. , editors , Proceedings of the ACL / EACL'97 Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources .", "label": "", "metadata": {}, "score": "47.92942"}
{"text": "An experiment in semantic tagging using hidden markov model tagging .In Vossen , P. , Adriaens , G. , Calzolari , N. , Sanfilippo , A. , and Wilks , Y. , editors , Proceedings of the ACL / EACL'97 Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources .", "label": "", "metadata": {}, "score": "47.92942"}
{"text": "Chunking is a natural language processing technique that splits text into groups of words that constitute a grammatical unit , e.g. , a noun phrase or a verb phrase .It is an important processing step in systems that try to automatically extract information from text .", "label": "", "metadata": {}, "score": "47.95011"}
{"text": "561 - 567 , 2011 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Merhbene , A. Zouaghi , and M. Zrigui , \" Arabic word sense disambiguation , \" in Proceedings of the 2nd International Conference on Agents and Artificial Intelligence ( ICAART'10 ) , pp .", "label": "", "metadata": {}, "score": "47.96673"}
{"text": "The ratio of the unambiguous word forms increased from 50.6 % to 58.5 % after processing by DIS .The number of tags per ambiguous token has decreased from 3.3 % to 2.7 % .In [ 17 ] a method for automatic finding of compound verb groups in a Czech sentence is introduced .", "label": "", "metadata": {}, "score": "48.0362"}
{"text": "However , it is not at all clear if these same meaning distinctions are applicable in computational applications , as the decisions of lexicographers are usually driven by other considerations .References .Suggested reading .Agirre , Eneko & Philip Edmonds ( eds . )", "label": "", "metadata": {}, "score": "48.111008"}
{"text": "The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .", "label": "", "metadata": {}, "score": "48.45847"}
{"text": "The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .", "label": "", "metadata": {}, "score": "48.45847"}
{"text": "This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .", "label": "", "metadata": {}, "score": "48.462036"}
{"text": "Performance has been lower than other methods , above , but comparisons are difficult since senses induced must be mapped to a known dictionary of word senses .Alternatively , if a mapping to a set of dictionary senses is not desired , cluster - based evaluations ( including measures of entropy and purity ) can be performed .", "label": "", "metadata": {}, "score": "48.53938"}
{"text": "Figure 1 below describes the principle of this method .We use the dictionary of \" Al - Mu'jam Al - Wasit \" to construct a database that contains the words and there definitions ( an electronic version of this dictionary ) .", "label": "", "metadata": {}, "score": "48.548714"}
{"text": "However , most translation systems do not use a separate WSD module .The lexicon is often pre - disambiguated for a given domain , or hand - crafted rules are devised , or WSD is folded into a statistical translation model , where words are translated within phrases which thereby provide context .", "label": "", "metadata": {}, "score": "48.65162"}
{"text": "These documents have the advantage of possessing an explicit structure that facilitates their presentation and their exploitation in different contexts to find relevant words more efficiently .Stopwords .We have compiled a list of stop words which have no influence on the meaning of the sentence .", "label": "", "metadata": {}, "score": "48.659462"}
{"text": "This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .", "label": "", "metadata": {}, "score": "48.67923"}
{"text": "These days WordNet is the usual dictionary in question .WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .", "label": "", "metadata": {}, "score": "48.765312"}
{"text": "The hierarchical structure is the common characteristics in knowledge representation , such as the hypernym / hyponym relations in WordNet or the topic coverage in ODP .We utilize the hierarchical structure features for measuring the semantic similarity , that is , node depth and node distance .", "label": "", "metadata": {}, "score": "48.776676"}
{"text": "When the words are monosemous , semantic feature is the best results ( 91.0 % ) ; in contrast , positional + statistical feature and topic span distribution feature are better than semantic feature ( 80.8 % and 83.1 % ) .", "label": "", "metadata": {}, "score": "48.865673"}
{"text": "[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .", "label": "", "metadata": {}, "score": "48.898506"}
{"text": "[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .", "label": "", "metadata": {}, "score": "48.898506"}
{"text": "The node pair with the shorter distance between has the greater similarity than that of the pair with the longer distance between them .Assume .The Topic Identification Algorithm .A topic similarity set of topic discriminative terms which occur in the text fragment will share the identical topic and similar semantic context .", "label": "", "metadata": {}, "score": "48.938164"}
{"text": "Third , treating WSD as a separate component or module may be misguided , as it might have to be more tightly integrated as an implicit process ( i.e. , as mutual disambiguation , below ) .Machine translation .WSD is required for lexical choice in MT for words that have different translations for different senses .", "label": "", "metadata": {}, "score": "49.084534"}
{"text": "Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .", "label": "", "metadata": {}, "score": "49.23197"}
{"text": "Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .", "label": "", "metadata": {}, "score": "49.23197"}
{"text": "4 , pp .609 - 619 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . A.-C. Le , A. Shimazu , V.-N. Huynh , and L.-M. Nguyen , \" Semi - supervised learning integrated with classifier combination for word sense disambiguation , \" Computer Speech and Language , vol .", "label": "", "metadata": {}, "score": "49.330692"}
{"text": "L. Al - Sulaiti and E. Atwell , \" The design of a corpus of contemporary arabic , \" International Journal of Corpus Linguistics , vol .11 , no . 2 , pp .135 - 171 , 2006 .View at Google Scholar \u00b7 View at Scopus . D. Yarowsky , \" One sense per collocation , \" in Proceedings of the ARPA Workshop on Human Language Technology , pp .", "label": "", "metadata": {}, "score": "49.35748"}
{"text": "6 , pp .1088 - 1100 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. Chen and H. Al - Mubaid , \" Context - based term disambiguation in biomedical literature , \" in Proceedings of the 19th International Florida Artificial Intelligence Research Society Conference ( FLAIRS ' 06 ) , pp .", "label": "", "metadata": {}, "score": "49.4069"}
{"text": "In Proceedings of the 14th International Conference on Computational Linguistics ( COLING-92 ) , pages 454 - 460 , Nantes , France , 1992 .This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .", "label": "", "metadata": {}, "score": "49.459965"}
{"text": "The system uses an ordered set of simple heuristic rules for determining iteratively the relationships between words to which a governor has not been yet assigned .For resolving certain cases of ambiguity we use cooccurrence statistics of words collected previously in an unsupervised manner , whether it be from big corpora , or from the Web ( through a search engine such as Google ) .", "label": "", "metadata": {}, "score": "49.48728"}
{"text": "Word meaning does not divide up into discrete senses .Finally , the very notion of \" word sense \" is slippery and controversial .Most people can agree in distinctions at the coarse - grained homograph level ( e.g. , pen as writing instrument or enclosure ) , but go down one level to fine - grained polysemy , and disagreements arise .", "label": "", "metadata": {}, "score": "49.59238"}
{"text": "[Links ] .Gladki , A. V. Syntax Structures of Natural Language in Automated Dialogue Systems ( in Russian ) .Moscow , Nauka , 1985 .[Links ] .Kudo , T. , Y. Matsumoto .Use of Support Vector Learning for Chunk Identification .", "label": "", "metadata": {}, "score": "49.651142"}
{"text": "Manning , Christopher D. & Hinrich Sch\u00fctze .Foundations of Statistical Natural Language Processing .Cambridge , MA : MIT Press .Mihalcea , Rada .Word sense disambiguation .Encyclopedia of Machine Learning .Springer - Verlag .Resnik , Philip and David Yarowsky .", "label": "", "metadata": {}, "score": "49.68632"}
{"text": "n .c .e . s . . .( .We also use the baseline method which is the most frequent sense ( mfs ) for each word .This lead , to a total of 31 words tested in this evaluation , and 18 words were dropped because they do not have at least two instances annotated for each one of two senses .", "label": "", "metadata": {}, "score": "49.709007"}
{"text": "Corpus - Based Methods .Since the evolution of the statistic methods based on large text corpus , two principal orientations appear .( i ) Unsupervised methods : these methods are based on training sets and use a non - annotated corpus .", "label": "", "metadata": {}, "score": "49.74163"}
{"text": "In : Alexander Gelbukh ( ed . )[ Links ] .Dik , Simon C. , The Theory of Functional Grammar .Part I : The structure of the clause .Dordrecht , Foris , 1989 .[Links ] .", "label": "", "metadata": {}, "score": "49.77118"}
{"text": "In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .", "label": "", "metadata": {}, "score": "49.90485"}
{"text": "In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .", "label": "", "metadata": {}, "score": "49.90485"}
{"text": "4 , pp .678 - 692 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. Navigli and P. Velardi , \" Structural semantic interconnections : a knowledge - based approach to word sense disambiguation , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}, "score": "49.92626"}
{"text": "Table 1 shows the performance of the three trainable chunkers and the combined system on the PennBioIE GSC when trained on three different corpora : GENIA GSC , PennBioIE SSC , or PennBioIE GSC .GATE and MetaMap could not be trained and when tested on the PennBioIE GSC had F - scores of 78.2 % ( MetaMap ) and 72.8 % ( GATE ) for noun phrases , and 77.7 % ( MetaMap ) for verb phrases .", "label": "", "metadata": {}, "score": "49.931747"}
{"text": "View Article .Sang E , Buchholz S : Introduction to the CoNLL-2000 shared task : chunking .Proceedings of CoNLL-2000 and LLL-2000 ; Lisbon 2000 , 127 - 132 .Littlestone N , Warmuth MK : The weighted majority algorithm .", "label": "", "metadata": {}, "score": "49.957165"}
{"text": "These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .", "label": "", "metadata": {}, "score": "49.97982"}
{"text": "These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .", "label": "", "metadata": {}, "score": "49.97982"}
{"text": "These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .", "label": "", "metadata": {}, "score": "49.97982"}
{"text": "S. Elmougy , H. Taher , and H. Noaman , \" Na\u00efve bayes classifier for arabic word sense disambiguation , \" in Proceedings of the Neuro - Linguistic Programming ( NLP ) , 2008 . A. Zouaghi , L. Merhbene , and M. Zrigui , \" Word sense disambiguation for arabic language using the variants of the lesk algorithm , \" in Proceedings of the International Conference on Artificial Intelligence ( ICAI'11 ) , vol .", "label": "", "metadata": {}, "score": "50.3153"}
{"text": "Using those rules we are able to recognise compound verb groups in unannotated Czech texts with the accuracy 93 % .Part - of - Speech Tagging by Means of Shallow Parsing , ILP and Active Learning [ 19 ] .Part - of - speech tagger for Czech is described that employs DIS shallow parser for Czech , manually - coded rules and inductive logic programming .", "label": "", "metadata": {}, "score": "50.321632"}
{"text": "Performance ( F - score ) of chunkers and their combination trained on subsets of different size of the GENIA GSC and on the GSC subset supplemented with an SSC , for noun - phrase and verb - phrase recognition .Discussion .", "label": "", "metadata": {}, "score": "50.39955"}
{"text": "Word sense disambiguation is the task of determining the correct sense of a given word in a given context .In the general language domain , and within natural language processing ( NLP ) , the word sense disambiguation ( WSD ) problem has been studied and investigated extensively over the past few decades [ 1 , 2 ] .", "label": "", "metadata": {}, "score": "50.503845"}
{"text": "There are several possible reasons for this .First , the domain of an application often constrains the number of senses a word can have ( e.g. , one would not expect to see the ' river side ' sense of bank in a financial application ) , and so lexicons can and have been constructed accordingly .", "label": "", "metadata": {}, "score": "50.5281"}
{"text": "Unsupervised methods .Unsupervised learning is the greatest challenge for WSD researchers .The underlying assumption is that similar senses occur in similar contexts , and thus senses can be induced from text by clustering word occurrences using some measure of similarity of context .", "label": "", "metadata": {}, "score": "50.544235"}
{"text": "Supervised methods are based on the assumption that the context can provide enough evidence on its own to disambiguate words ( hence , world knowledge and reasoning are deemed unnecessary ) .Probably every machine learning algorithm going has been applied to WSD , including associated techniques such as feature selection , parameter optimization , and ensemble learning .", "label": "", "metadata": {}, "score": "50.616005"}
{"text": "6 , pp .1088 - 1100 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. Stevenson , E. Agirre , and A. Soroa , \" Exploiting domain information for word sense disambiguation of medical documents , \" Journal of the American Medical Informatics Association , vol .", "label": "", "metadata": {}, "score": "50.71708"}
{"text": "In all our experiments , we used a voting threshold of three out of five chunkers for noun phrases , and a threshold of two out of four for verb phrases ( GATE only generates noun phrases ) .These thresholds gave uniformly the best results in terms of F - score when the silver standard annotations of the training data were evaluated against the gold standard .", "label": "", "metadata": {}, "score": "50.73805"}
{"text": "Since that , we test a modified version of the Lesk algorithm using five measures of similarities .These measures will be applied to find the similarity between each sense of the ambiguous word proposed in AWN and the senses of the other words contained in the same sentence .", "label": "", "metadata": {}, "score": "50.739693"}
{"text": "In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 A Learning - Based Approach for Biomedical Word Sense Disambiguation .", "label": "", "metadata": {}, "score": "50.901695"}
{"text": "Information extraction and knowledge acquisition .In information extraction and text mining , WSD is required for the accurate analysis of text in many applications .For instance , an intelligence gathering system might need to flag up references to , say , illegal drugs , rather than medical drugs .", "label": "", "metadata": {}, "score": "50.973236"}
{"text": "In the 1990s , the statistical revolution swept through computational linguistics , and WSD became a paradigm problem on which to apply supervised machine learning techniques .The 2000s saw supervised techniques reach a plateau in accuracy , and so attention has shifted to coarser - grained senses , domain adaptation , semi - supervised and unsupervised corpus - based systems , combinations of different methods , and the return of knowledge - based systems via graph - based methods .", "label": "", "metadata": {}, "score": "50.987976"}
{"text": "Sch\u00fctze , Hinrich .Automatic word sense discrimination .Computational Linguistics , 24(1):97 - 123 .Weaver , Warren .Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .", "label": "", "metadata": {}, "score": "51.065506"}
{"text": "A good example of this is Luk 's system A. Luk .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .", "label": "", "metadata": {}, "score": "51.210808"}
{"text": "Abstract .Background .To train chunkers in recognizing noun phrases and verb phrases in biomedical text , an annotated corpus is required .The creation of gold standard corpora ( GSCs ) , however , is expensive and time - consuming .", "label": "", "metadata": {}, "score": "51.235245"}
{"text": "[Links ] .Copestake , Ann , Dan Flickinger , Ivan A. Sag .Minimal Recursion Semantics .An introduction .CSLI , Stanford University , 1997 .[Links ] .In : Recent Advances in Dependency Grammar .Proc .", "label": "", "metadata": {}, "score": "51.26516"}
{"text": "The topical features are based on the topical describing information from the above - mentioned preprocessing steps of topic identification .The representation of context problem can be formally stated as follows .( i ) .For the syntactic feature , each sentence is analyzed for the parse tree .", "label": "", "metadata": {}, "score": "51.27705"}
{"text": "[Links ] .Mel'cuk , Igor A. Lexical Functions : A Tool for the Description of Lexical Relations in the Lexicon .In : L. Wanner ( ed . )[ Links ] .[Links ] .Monedero , J. , Gonz\u00e1lez , J. Go\u00f1i , C. Iglesias , A. Nieto .", "label": "", "metadata": {}, "score": "51.438377"}
{"text": "PubMed View Article .Banko M , Brill E : Mitigating the paucity - of - data problem : exploring the effect of training corpus size on classifier performance for natural language processing .Proceedings of the First International Conference on Human Language Technology Research ; San Diego 2001 , 1 - 5 .", "label": "", "metadata": {}, "score": "51.610584"}
{"text": "The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning . of a .word in a particular usage can only be determined by examining its context . . .", "label": "", "metadata": {}, "score": "51.949924"}
{"text": "Three kinds of inductive queries were implemented .Two of them , that ask for characteristic and discriminate rules , are adaptation of GeoMiner( Han et al . , SIGMOD'97 ) rules .The dependency rules add a new quality to the inductive query language .", "label": "", "metadata": {}, "score": "52.03686"}
{"text": "Rather than expanding the GSC , we supplement the GSC with an SSC from the same domain and train the chunker on the combined GSC and SSC to improve chunker performance .Related work .During the past decade , much research has been devoted to systems that combine different classifiers , also called multiple classifier systems or ensemble - based systems [ 1 ] .", "label": "", "metadata": {}, "score": "52.177673"}
{"text": "The methods based on rule combine heterogeneous learning modules .Proposed Method .As we have mentioned before , the majority of the works related to the WSD were applied to the English .However , there are some works applied to Arabic .", "label": "", "metadata": {}, "score": "52.209106"}
{"text": "language processing by part - of - speech taggers which predict .the . syntactic category of words . in text .with high levels of accuracy . E. Brill .Transformation - based error - driven learning . and .natural language processing : A case study in part of speech tagging .", "label": "", "metadata": {}, "score": "52.22522"}
{"text": "View Article .Van Erp M , Schomaker L : Variants of the borda count method for combining ranked classifier hypotheses .Proceedings of the Seventh International Workshop on Frontiers in Handwriting Recognition ; Amsterdam 2000 , 443 - 452 .Seki K , Mostafa J : An application of text categorization methods to gene ontology annotation .", "label": "", "metadata": {}, "score": "52.26818"}
{"text": "[Links ] .Agirre , E. , D. Martinez .Integrating selectional preferences in WordNet .[Links ] .Apresyan , Yuri D. , Igor Boguslavski , Leonid Iomdin , Alexandr Lazurski , Nikolaj Pertsov , Vladimir Sannikov , Leonid Tsinman .", "label": "", "metadata": {}, "score": "52.3183"}
{"text": "This paper introduces Latent Relational Analysis ( LRA ) , a method for measuring semantic similarity .LRA measures similarity in the semantic relations between two pairs of words .When two pairs have a high degree of relational similarity , they are analogous .", "label": "", "metadata": {}, "score": "52.36367"}
{"text": "Evaluating text categorization .In Proceedings of the Speech and Natural Language Workshop , Asilomar , pages 312 - 318 , 1991 .[Lin , 1998 ] D. Lin .Automatic retrieval and clustering of similar words .In Proceedings of the 36th Annual Meet - ing of the Association for Computational Linguistics and the 17th International Conference on Computational Lin - guistics ( COLING - ACL ' 98 ) , pages 768 - 774 , Montreal , Canada , 1998 .", "label": "", "metadata": {}, "score": "52.423996"}
{"text": "Knowledge - Based Methods .They were introduced in 1970 , based on the dictionary , thesaurus , and lexicon .Using these resources they extract the information necessary to disambiguate words .Some of them [ 10 ] tested the adequate definitions given by the electronic dictionary Collins English Dictionary ( CED ) and the Dictionary of Contemporary English ( LDOCE ) for the automatic treatment of the disambiguation .", "label": "", "metadata": {}, "score": "52.53135"}
{"text": "word . sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .first introduced by Warren Weaver in 1949 W. Weaver .In Machine Translation . of .", "label": "", "metadata": {}, "score": "52.63002"}
{"text": "We evaluate our topical identification algorithm using the precision ( the number of correct documents over the number of all documents ) on SemCor .Table 1 summarizes the performance of extracting the topic discriminative terms based on the selection of different features .", "label": "", "metadata": {}, "score": "52.64189"}
{"text": "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence ( IJCAI-03 ) , pages 805 - 810 , Acapulco , Mexico , 2003 .[ Barzilay and McKeown , 2001 ] R. Barzilay and K. McKe - own .Extracting paraphrases from a parallel corpus .", "label": "", "metadata": {}, "score": "52.662506"}
{"text": "Since annotation diversity is generally considered a key factor for the improvement seen by ensemble systems ( 4 ) , it may be expected that the combined chunker system shows a smaller increase of performance when based on the SSC than on the GSCs .", "label": "", "metadata": {}, "score": "52.714745"}
{"text": "WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .", "label": "", "metadata": {}, "score": "52.72317"}
{"text": "( i )Converting all words to lowercase .( ii ) Removing stopwords : removing all common function words like \" is \" \" the \" \" in \" , ... and so forth .( iii )Performing word stemming using Porter stemming algorithm [ 25 ] .", "label": "", "metadata": {}, "score": "52.774166"}
{"text": "Research has progressed steadily to the point where WSD systems achieve consistent levels of accuracy on a variety of word types and ambiguities .Among these , supervised learning approaches have been the most successful algorithms to date .Current accuracy is difficult to state without a host of caveats .", "label": "", "metadata": {}, "score": "52.78951"}
{"text": "Computer Recognition of English Word Senses , Amsterdam : North - Holland . published a book explicitly listing their rules for disambiguation of word senses .Revision as of 11:55 , 4 January 2011 .Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .", "label": "", "metadata": {}, "score": "52.822502"}
{"text": "In the previous work , [ 17 ] , we introduced a method for term disambiguation and evaluated it with biomedical terms to disambiguate gene and protein names in medical texts .The method relies on representing the instances of the word to be disambiguated , . , as a feature vector , and the components of this vector are neighborhood context words in the training instances .", "label": "", "metadata": {}, "score": "52.917088"}
{"text": "235 - 240 , 2012 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . D. Dligach and M. Palmer , \" Novel semantic features for verb sense disambiguation , \" in Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies , ACL-08 : HLT , pp .", "label": "", "metadata": {}, "score": "53.08333"}
{"text": "Word meaning is in principle infinitely variable and context sensitive .It does not divide up easily into distinct or discrete sub - meanings .Lexicographers frequently discover in corpora loose and overlapping word meanings , and standard or conventional meanings extended , modulated , and exploited in a bewildering variety of ways .", "label": "", "metadata": {}, "score": "53.08355"}
{"text": "Z. Zheng and R. Srihari , \" Optimally combining positive and negative feature for text categorization , \" in Proceedings of the Workshop on Learning from Imbalanced Data Sets II ( ICML ' 03 ) , 2003 .C. D. Manning and H. Schutze , Foundations of Statistical Natural Language Processing , The MIT Press , 1999 .", "label": "", "metadata": {}, "score": "53.121925"}
{"text": "To build this list , we collected from the net pronouns , noun , names , letters , noun - verb , and some words considered insignificant by humans .Experimental Data .Fifty words have been chosen .For each one of these ambiguous words , we evaluate 20 examples per sense .", "label": "", "metadata": {}, "score": "53.177223"}
{"text": "The method has been evaluated with the benchmark dataset NLM - WSD with various settings and in biomedical entity species disambiguation .The evaluation results showed that the approach is very competitive and outperforms recently reported results of other published techniques .", "label": "", "metadata": {}, "score": "53.1893"}
{"text": "The classifier will be then used to disambiguate unseen and unlabeled examples in the application phase .One of the main strength of this method is that the features are selected for learning and classification .Feature Selection The features selected from the training examples have great impact on the effectiveness of the machine learning technique .", "label": "", "metadata": {}, "score": "53.209385"}
{"text": "[ Salton and McGill , 1983 ] G. Salton and M.J. McGill .In - troduction to Modern Information Retrieval .McGraw - Hill , New York , 1983 .[ Turney et al . , 2003 ] P.D. Turney , M.L. Littman , J. Bigham , and V. Shnayder .", "label": "", "metadata": {}, "score": "53.343506"}
{"text": "1075 - 1086 , 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. Mihalcea , \" Knowledge - based methods for WSD[C ] , \" in Word Sense Disambiguation Algorithms and Applications , pp .", "label": "", "metadata": {}, "score": "53.444122"}
{"text": "4 , pp .330 - 345 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. Navigli and M. Lapata , \" An experimental study of graph connectivity for unsupervised word sense disambiguation , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}, "score": "53.451267"}
{"text": "This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .", "label": "", "metadata": {}, "score": "53.46232"}
{"text": "This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .", "label": "", "metadata": {}, "score": "53.46232"}
{"text": "This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .", "label": "", "metadata": {}, "score": "53.46232"}
{"text": "This classifier is then used on the untagged portion of the corpus to extract a larger training set , in which only the most confident classifications are included .The process repeats , each new classifier being trained on a successively larger training corpus , until the whole corpus is consumed , or until a given maximum number of iterations is reached .", "label": "", "metadata": {}, "score": "53.741028"}
{"text": "Discussion and Conclusion .The main weakness of the supervised and machine - learning - based methods for WSD is their dependency on the annotated training text which includes manually disambiguated instances of the ambiguous word [ 2 , 17 ] .", "label": "", "metadata": {}, "score": "53.946198"}
{"text": "[ 1 ] .The results of the three methods ( single , subset , full ) in Table 6 are taken directly from Agirre et al .[ 2 ] .In another work , Jimeno - Yepes and Aronson evaluate four unsupervised methods on the whole NLM - WSD set [ 4 ] as well as NB and combination of the four methods .", "label": "", "metadata": {}, "score": "54.010956"}
{"text": "Secondly , the other vertices are iteratively integrated into the different topical clusters according to the adjacency relationship and the previous calculation result of similarity for topic chains .The isolated individuals and too small topical clusters will be ignored .Finally , owing to the fact that the conventional document tends to contain a relatively small number of topics , we focus on those higher density components and choose top - level cooccurrence topic concepts as document 's topic category describing information .", "label": "", "metadata": {}, "score": "54.01899"}
{"text": "In earlier systems the senses were more typically generic senses selected by the originators of the system .These days [ [ WordNet ] ] is the usual dictionary in question .WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .", "label": "", "metadata": {}, "score": "54.019127"}
{"text": "Ambiguity has to be resolved in some queries .For instance , given the query \" depression \" should the system return documents about illness , weather systems , or economics ?Current IR systems ( such as Web search engines ) , like MT , do not use a WSD module ; they rely on the user typing enough context in the query to only retrieve documents relevant to the intended sense ( e.g. , \" tropical depression \" ) .", "label": "", "metadata": {}, "score": "54.061966"}
{"text": "Links ] .Lara , Luis Fernando .Diccionario del espa\u00f1ol usual en M\u00e9xico .Digital edition .Colegio de M\u00e9xico , Center of Linguistic and Literary Studies , 1996 .[Links ] .[Links ] .Mel'cuk , Igor A. Dependency Syntax : Theory and Practice .", "label": "", "metadata": {}, "score": "54.11328"}
{"text": "Abstract .We propose a new approach for determining the adequate sense of Arabic words .For that , we propose an algorithm based on information retrieval measures to identify the context of use that is the closest to the sentence containing the word to be disambiguated .", "label": "", "metadata": {}, "score": "54.12247"}
{"text": "Multiple classifier systems have been applied in many domains , including biomedical text mining and information extraction .For instance , Smith et al .[ 2 ] combined the results of 19 systems for gene mention recognition , and found that the combined system outperformed the best individual system by 3.5 percentage points in terms of F - score .", "label": "", "metadata": {}, "score": "54.13916"}
{"text": "During the process of our algorithm , we aim to determinate the mapping between WordNet and ODP .Formally , given the sense of a term in WordNet , we acquire a mapping to an ODP 's topic chain as follows : .", "label": "", "metadata": {}, "score": "54.17328"}
{"text": "In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .This takes a small number of seed definitions of the senses of some word ( the seeds could be WordNet synsets or definitions from some lexicon ) and uses these to classify the \" obvious \" cases in a corpus .", "label": "", "metadata": {}, "score": "54.29246"}
{"text": "View at Google Scholar .View at Google Scholar .F. Hristea , M. Popescu , and M. Dumitrescu , \" Performing word sense disambiguation at the border between unsupervised and knowledge - based techniques , \" Artificial Intelligence Review , vol .", "label": "", "metadata": {}, "score": "54.424137"}
{"text": "[Links ] .Text Mining at Detail Level Using Conceptual Graphs .In : Uta Priss et al .( Eds . ) : Conceptual Structures : Integration and Interfaces , 10 th Intern .Conf .[Links ] .", "label": "", "metadata": {}, "score": "54.455685"}
{"text": "Using the glosses of the word to be disambiguated , we generate the contexts of use for each sense from the corpus .The idea consists of combining the algorithm of stemming ( see Section 3.1.1 ) [ 4 ] to extract the roots and the algorithm of approximate string matching ( see Section 3.1.2 ) to find occurrences of the stems .", "label": "", "metadata": {}, "score": "54.546135"}
{"text": "Our method also outperforms all 10 other methods in 12 out of 31 words followed by NB which outperforms the rest in 7 words .Stevenson et al . in their paper [ 1 ] report extensive accuracy results of their method ( we call it Stevenson-2008 ) along with four other methods including Joshi-2005 and McInnes-2007 , with various combinations of words from NLM - WSD corpus used for testing .", "label": "", "metadata": {}, "score": "55.06826"}
{"text": "Compared with the previous work , both recall and accuracy increased and the number of training examples to label decreased .The method was tested on ambiguities that are frequent in Czech .The accuracy reached was higher than 96 % with recall higher than 95 % .", "label": "", "metadata": {}, "score": "55.12356"}
{"text": "Lemma disambiguator for Czech . was developed [ 12 , 13 ] employing Progol .A method for disambiguation were introduced that combines ILP and instance - based learning .The algorithm reached accuracy greater than 90 % , leaving less than 15 % of words ambiguous .", "label": "", "metadata": {}, "score": "55.138515"}
{"text": "Mapping a WordNet Sense to an ODP 's Category Label .We aim to construct a mapping relation from a WordNet sense to an ODP 's category label .Our proposed approach effectively fuses the semantic knowledge with hierarchical topic category to generate topic semantic knowledge profile for expediently handling a series of research hot issues , such as information extraction , topic identification , and word sense disambiguation .", "label": "", "metadata": {}, "score": "55.171055"}
{"text": "Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .", "label": "", "metadata": {}, "score": "55.192535"}
{"text": "Our system requires that each term should have instances in two or more species with at least 3 occurrences in each species .The results of Wang et al . are shown in Table 7 , whereas the results of our proposed system are shown in Table 8 in terms of precision , recall , and F1 .", "label": "", "metadata": {}, "score": "55.24785"}
{"text": "Identifying Topic Discriminative Term .Definition 4 ( topic discriminative term ) .Topic discriminative term ( TDT ) can be applied to characterize and highlight a term or phrase 's related subject matters in the document .The term or phrase of high discriminative should be strongly associated with the semantic context , owns the number of sense as little as possible , and explicitly specifies the topical category .", "label": "", "metadata": {}, "score": "55.248947"}
{"text": "Performance ( F - score ) of chunkers and their combination when trained for noun - phrase and verb - phrase recognition on different training sets .Silver standard as supplement of gold standard .Table 2 shows the performances of chunkers and the combined system when trained on GSCs of varying sizes and on the GSCs supplemented with an SSC .", "label": "", "metadata": {}, "score": "55.48504"}
{"text": "When the annotators did not assign any sense for an instance , then that instance is tagged with \" none \" .Only one term \" association \" with all of its 100 instances were annotated none and so dropped from the testing .", "label": "", "metadata": {}, "score": "55.50003"}
{"text": "The following ( 1 ) describes the method used to calculate the \u200e score of similarity between two contexts : .Okapi Measure . is the average of \u200e the collected use contexts lengths .This will enable us to increase the probability of finding the nearest context to the original sentence containing the ambiguous word .", "label": "", "metadata": {}, "score": "55.556747"}
{"text": "If a system makes an assignment for every word , then precision and recall are the same , and can be called accuracy .This model has been extended to take into account systems that return a set of senses with weights for each occurrence .", "label": "", "metadata": {}, "score": "55.60723"}
{"text": "LRA achieves state - of - the - art results , reaching human - level performance on the analogy questions and significantly exceeding VSM performance on both tasks .Keywords : . analogies , semantic relations , vector space model , noun - modifier expressions , latent relational analysis .", "label": "", "metadata": {}, "score": "55.612247"}
{"text": "Another example is the work of Pedersen [ 11 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .", "label": "", "metadata": {}, "score": "55.639214"}
{"text": "Another example is the work of Pedersen [ 11 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .", "label": "", "metadata": {}, "score": "55.639214"}
{"text": "In 1975 .Kelly and Stone .Computer Recognition of English Word Senses , Amsterdam : North - Holland . published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .", "label": "", "metadata": {}, "score": "55.667946"}
{"text": "and the class label based on the values . through . as defined above .We utilized the training corpus of the labeled instances of the word to be disambiguated to compile the list of all context words ( . as explained above ; all instances of one sense are under one class label .", "label": "", "metadata": {}, "score": "55.66834"}
{"text": "42 - 59 , Alexandria , Egypt , 2003 .T. H. Cormen , C. E. Leiserson , and R. L. Rivest , Introduction to Algorithms , chapter 34 , MIT Press , Cambridge , Mass , USA , 1990 .D. Harman , \" An experimental study of factors important in document ranking , \" in Proceedings of the 9th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , pp .", "label": "", "metadata": {}, "score": "55.685204"}
{"text": "B. L. Humphreys , D. A. B. Lindberg , H. M. Schoolman , and G. O. Barnett , \" The unified medical language system : an informatics research collaboration , \" Journal of the American Medical Informatics Association , vol .5 , no . 1 , pp . 1 - 11 , 1998 .", "label": "", "metadata": {}, "score": "55.708878"}
{"text": "[ 3 ] combined eight systems for event extraction and showed that the performance of the combined system increased by 4 percentage points as compared to the best individual system .We previously combined six publicly available text chunkers using a simple voting approach [ 4 ] .", "label": "", "metadata": {}, "score": "55.839554"}
{"text": "Lexical disambiguation .The Elsevier Encyclopedia of Language and Linguistics , 2nd Ed . , ed . by Keith Brown , 607 - 23 .Oxford : Elsevier .Ide , Nancy & Jean V\u00e9ronis .Word sense disambiguation : The state of the art .", "label": "", "metadata": {}, "score": "55.969337"}
{"text": "This algorithm will affiliate a score for the most relevant sense of the ambiguous word .For a sample of fifty ambiguous Arabic words that are chosen by their number of senses out of context ( the most ambiguous words ) , the proposed algorithm achieved a precision of 78 % and recall of 65 % .", "label": "", "metadata": {}, "score": "55.990578"}
{"text": "For the target verb , we firstly distinguish a sentence which is the sentence frame and identify corresponding object and subject , respectively .For the target noun , we focus on the modifier structure , the parallel structure , and subordinate clause for subject or object .", "label": "", "metadata": {}, "score": "56.018803"}
{"text": "This shows that chunkers may considerably differ with the gold standard with respect to the annotation of stopwords .Since the creation of an SSC is automatic , its size can be very large .For different text - processing applications , increasing amounts of data for training classifiers have been shown to improve classifier performance [ 21 - 23 ] .", "label": "", "metadata": {}, "score": "56.02449"}
{"text": "Meanwhile , a certain sense of the ambiguous target is associated with a particular topic , so that multiple senses can be distinguished through topical information .Consequently , we propose a topical - semantic association model that exploits the local feature and global feature in the context of ambiguous term to determine its unique sense .", "label": "", "metadata": {}, "score": "56.042458"}
{"text": "Influence of the Stemming and String - Matching .We measure the performance of our system using the metrics presented above , with and without the respective use of the stemming algorithm and the string - matching algorithm ( see Table 4 ) .", "label": "", "metadata": {}, "score": "56.112747"}
{"text": "As can be seen , all measures of comprehensive features perform better than the each feature .Especially , topic span distribution feature ( 86.2 % ) plays a more important role for improving the accuracy rate of documents ' topic identification .", "label": "", "metadata": {}, "score": "56.172523"}
{"text": "We conclude that the lowest rate of \u200e disambiguation is mainly due to the insufficient number \u200e of contexts of use , which results in the failure to meet all \u200e possible events .For that we try to collect as many texts as we can , to extend the size of the knowledge database .", "label": "", "metadata": {}, "score": "56.17637"}
{"text": "Our results suggest that the time and effort spent in creating a GSC of sufficient size may be much reduced .Whether the approach is applicable to other systems in a natural - language processing pipeline has to be further investigated .", "label": "", "metadata": {}, "score": "56.271675"}
{"text": "A phrase annotated by the gold standard was counted as false negative if the system did not render it exactly ; a phrase annotated by a system was counted as false positive if it did not exactly match the gold standard .", "label": "", "metadata": {}, "score": "56.27209"}
{"text": "The applications of SVM are abound ; in particular , in NLP domain like text categorization , relation extraction , named entity recognition , SVM proved to be the best performer .The Disambiguation Step In the testing step , we want to disambiguate an instance .", "label": "", "metadata": {}, "score": "56.299976"}
{"text": "It is due to the fact that there are not higher degree centrality vertices in topic graph .This often degrades performance , as too many low - degree centrality vertices may lead to more difficulty in identify the document 's topic .", "label": "", "metadata": {}, "score": "56.4393"}
{"text": "Dordrecht : Springer .Bar - Hillel , Yehoshua .Language and Information .New York : Addison - Wesley .Edmonds , Philip & Adam Kilgarriff .Introduction to the special issue on evaluating word sense disambiguation systems .Journal of Natural Language Engineering , 8(4):279 - 291 .", "label": "", "metadata": {}, "score": "56.54107"}
{"text": "Jurafsky , Daniel & James H. Martin .Speech and Language Processing .New Jersey , USA : Prentice Hall .Lesk , Michael .Automatic sense disambiguation using machine readable dictionaries : How to tell a pine cone from an ice cream cone .", "label": "", "metadata": {}, "score": "56.58455"}
{"text": "Thus , if this term blood pressure is found in a medical text , the reader has to manually judge and determines which one of these three senses is intended in that text .Word sense disambiguation contributes in many important applications including the text mining , information extraction , and information retrieval systems [ 1 , 2 , 4 ] .", "label": "", "metadata": {}, "score": "56.636253"}
{"text": "View Article .Boyack KW , Newman D , Duhon RJ , Klavans R , Patek M , Biberstine JR , Schijvenaars B , Skupin A , Ma N , B\u00f6rner K : Clustering more than two million biomedical publications : comparing the accuracies of nine text - based similarity approaches .", "label": "", "metadata": {}, "score": "56.665123"}
{"text": "Evaluation .The evaluation of WSD systems requires a test corpus hand - annotated with the target or correct senses , and assumes that such a corpus can be constructed .Two main performance measures are used : .Precision : the fraction of system assignments made that are correct .", "label": "", "metadata": {}, "score": "56.714962"}
{"text": "The evaluation results proved the competitiveness of the proposed approach as it outperforms some recently published techniques including supervised techniques .Related Work .In the biomedical domain , the applications of text mining and machine learning techniques were quite successful and encouraging [ 6 ] .", "label": "", "metadata": {}, "score": "56.734352"}
{"text": "In Fifth International Workshop on Computational Seman - tics ( IWCS-5 ) , Tilburg , The Netherlands , pages 285 - 301 , 2003 .[ Rosario and Hearst , 2001 ] B. Rosario and M. Hearst .Clas - sifying the semantic relations in noun - compounds via a domain - specific lexical hierarchy .", "label": "", "metadata": {}, "score": "56.906494"}
{"text": "The problem of WSD was first introduced by Warren Weaver in 1949 [ 3 ] .In 1975 Kelly and Stone [ 4 ] published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .", "label": "", "metadata": {}, "score": "56.935184"}
{"text": "The problem of WSD was first introduced by Warren Weaver in 1949 [ 3 ] .In 1975 Kelly and Stone [ 4 ] published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .", "label": "", "metadata": {}, "score": "56.935184"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. Chen and H. Al - Mubaid , \" Context - based term disambiguation in biomedical literature , \" in Proceedings of the 19th International Florida Artificial Intelligence Research Society Conference ( FLAIRS ' 06 ) , pp .", "label": "", "metadata": {}, "score": "56.964188"}
{"text": "Clearly , the improvement is largest for small sizes of the GSC , leveling off with increasing size .The performance obtained with a small set of GSC abstracts combined with an SSC is comparable to a larger GSC set without SSC .", "label": "", "metadata": {}, "score": "57.077255"}
{"text": "Firstly , compared with the syntactic structure of the target verb , the partial of senses may be filtered through sentence frames .Secondly , we calculate the similarity between the domain terms in the form of .and topic chains of the noun 's object to choose the verb sense of maximum similarity .", "label": "", "metadata": {}, "score": "57.22421"}
{"text": "This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .Abstract .In the biomedical domain , word sense ambiguity is a widely spread problem with bioinformatics research effort devoted to it being not commensurate and allowing for more development .", "label": "", "metadata": {}, "score": "57.24961"}
{"text": "Given that the Arabic word has flexional morphology , we used an algorithm to extract the word roots and then an algorithm for matching words to find occurrences of this root .Obtaining instances of a root consists of adding a suffix to the beginning of a word or a prefix in the end .", "label": "", "metadata": {}, "score": "57.313675"}
{"text": "[Links ] .Calvo , Hiram , Alexander Gelbukh .Acquiring Selectional Preferences from Untagged Text for Prepositional Phrase Attachment Disambiguation .In : Proc .[Links ] .Calvo , Hiram .Alexander Gelbukh , Adam Kilgarriff .Distributional Thesaurus versus WordNet : A Comparison of Backoff Techniques for Unsupervised PP Attachment .", "label": "", "metadata": {}, "score": "57.32132"}
{"text": "The above experiment was repeated 10 times , each time starting with a different randomly selected subset of 10 abstracts .The reported results are the averaged F - scores of the 10 experiments .Performance evaluation .The chunker and silver standard annotations were compared with the gold standard annotations by exact matching , similar to the procedure followed in CoNLL-2000 [ 15 ] .", "label": "", "metadata": {}, "score": "57.327816"}
{"text": "We used a simple voting approach to create an SSC .More sophisticated voting methods exist , such as weighted voting [ 17 ] or Borda count [ 18 ] , but these methods require information about the confidence or rank of the chunks , information that is not available for the chunkers in this study .", "label": "", "metadata": {}, "score": "57.38843"}
{"text": "Buyko E , Wermter J , Poprat M , Hahn U : Automatically adapting an NLP core engine to the biology domain .Proceedings of the Joint BioLINK - Bio - Ontologies Meeting ; Fortaleza 2006 , 65 - 68 .Kudo T , Matsumoto Y : Chunking with support vector machines .", "label": "", "metadata": {}, "score": "57.45533"}
{"text": "Kang N , van Mulligen EM , Kors JA : Comparing and combining chunkers of biomedical text .J Biomed Inform 2011 , 44 : 354 - 360 .PubMed View Article .Rebholz - Schuhmann D , Yepes AJ , van Mulligen EM , Kang N , Kors J , Milward D , Corbett P , Hahn U : The CALBC silver standard corpus - harmonizing multiple semantic annotations in a large biomedical corpus .", "label": "", "metadata": {}, "score": "57.608555"}
{"text": "In this section , we exploit the SemCor corpus to evaluate our approach .The SemCor corpus was the largest freely available textual corpus of semantically annotated words and has been extensively used in evaluating WSD systems .Topic Identification Based on Extracting TDT .", "label": "", "metadata": {}, "score": "57.708214"}
{"text": "In the work of Yarowsky [ 26 ] , a study of the influence of the window size on WSD shows that the most useful keywords for the WSD are included in a micro - context from six to eight words .", "label": "", "metadata": {}, "score": "57.850735"}
{"text": "The Algorithm 1 below describes the proposed algorithm of Arabic WSD and the score measure .In what follows we describe with more details each step cited above .Construction of the Context of Use : Motivation and Implementation .To maximize the probability of finding the context for each gloss , we proposed as a solution to generate the occurrences of the most significant words .", "label": "", "metadata": {}, "score": "57.99627"}
{"text": "These days [ [ WordNet ] ] is the usual dictionary in question .WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .", "label": "", "metadata": {}, "score": "58.070625"}
{"text": "For that , we use feature selection techniques such as mutual information ( MI ) [ 19 , 20 ] as follows .For each context word .that do not contain .that do not contain .Therefore , the mutual information ( MI ) can be defined as .", "label": "", "metadata": {}, "score": "58.076164"}
{"text": "However , these supervised methods are subject to a new knowledge acquisition bottleneck since they rely on substantial amounts of manually sense - tagged corpora for training , which are laborious and expensive to create .Semi - supervised methods .The bootstrapping approach starts from a small amount of seed data for each word : either manually - tagged training examples or a small number of surefire decision rules ( e.g. , play in the context of bass almost always indicates the musical instrument ) .", "label": "", "metadata": {}, "score": "58.222683"}
{"text": "Each context word .or with .or combination and in any distribution .We want to determine that , if we see a context word . suggests that this example belongs to .or to .Thus , we use as features those context words .", "label": "", "metadata": {}, "score": "58.225304"}
{"text": "These topic span intervals will be used to determine the appropriate size of context for the ambiguous term .To achieve the whole process of leveraging topic discriminative term for topic identification , we will design the Algorithm 1 .Determining the Unique Sense of Ambiguous Term Using Topical - Semantic Association Graph .", "label": "", "metadata": {}, "score": "58.28659"}
{"text": "Links ] .Calvo , Hiram , Alexander Gelbukh .Improving Prepositional Phrase Attachment Disambiguation Using the Web as Corpus , In A. Sanfeliu and J. Shulcloper ( Eds . )Calvo , Hiram , Alexander Gelbukh .Natural Language Interface Framework for Spatial Object Composition Systems .", "label": "", "metadata": {}, "score": "58.287193"}
{"text": "In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 Measuring Semantic Similarity by Latent Relational Analysis .", "label": "", "metadata": {}, "score": "58.355396"}
{"text": "More information on characteristics and performance of these chunkers can be found in our previous comparative study of chunkers [ 4 ] , which also included Genia Tagger .Since Genia Tagger comes with a fixed pre - trained model based on the corpora that we use in this study , it could bias the results of our experiments and was not included .", "label": "", "metadata": {}, "score": "58.362747"}
{"text": "The best similarity measure is obtained using a window size of three words .The Croft measure was the best one between those proposed .Comparison of the Similarity Measures .Figure 4 presents a comparison between the results given by the Lesk algorithm and those given by the Croft , Harman , and Okapi measures .", "label": "", "metadata": {}, "score": "58.60526"}
{"text": "For the supervised systems we can cite : the probabilistic methods ; the majority of them use the na\u00efve bayes algorithm and the maximum entropy approach .Methods are based on the similarity of the examples that use a similarity metric to compare the set of learned vector prototypes ( for each word sense ) .", "label": "", "metadata": {}, "score": "58.65127"}
{"text": "The average accuracy results of NB and two combinations ( NB , CombSW , and CombV ) on our 31 word - subset are 86 % , 73.1 % , and 72.1 % respectively which are lower than our results , see Table 6 .", "label": "", "metadata": {}, "score": "58.671925"}
{"text": "We conclude that an SSC can be a viable alternative for or a supplement to a GSC when training chunkers in a biomedical domain .A combined system only shows improvement if the SSC is used to supplement a GSC .Whether the approach is applicable to other systems in a natural - language processing pipeline has to be further investigated .", "label": "", "metadata": {}, "score": "58.719883"}
{"text": "Creation of the silver standard .We used a simple voting scheme to generate silver standard annotations from the annotations produced by the different chunkers .For each phrase identified by a chunker , the number of chunkers that gave exactly matching annotations was counted .", "label": "", "metadata": {}, "score": "58.793316"}
{"text": "[Links ] .Bolshakov , Igor A. [ Links ] .Bolshakov , Igor A. , Alexander Gelbukh .A Very Large Database of Collocations and Semantic Links .Proc .Conf .[Links ] .Bolshakov , Igor A. , Alexander Gelbukh .", "label": "", "metadata": {}, "score": "58.994385"}
{"text": "In the following example , assume that the target word .has 10 instances already labeled with one of two senses as shown in Table 1 .Class . are the instances of .with the first sense , while .are the instances of . instances in the second sense .", "label": "", "metadata": {}, "score": "59.114586"}
{"text": "Computer Recognition of English Word Senses , Amsterdam : North - Holland . published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .", "label": "", "metadata": {}, "score": "59.11883"}
{"text": "Agirre et al .proposed a graph - based WSD technique which is considered unsupervised but relies on UMLS [ 2 ] .The concepts of UMLS are represented as a graph , and WSD is done using personalized page rank algorithm [ 2 ] .", "label": "", "metadata": {}, "score": "59.13848"}
{"text": "El\u00e9ments de syntaxe structurale .Paris : Librairie Klincksieck , 1959 .[Links ] .Volk , Martin .Exploiting the WWW as a corpus to resolve PP attachment ambiguities .In Proceeding of Corpus Linguistics 2001 .Lancaster , 2001 .", "label": "", "metadata": {}, "score": "59.16215"}
{"text": "In fact , Bar - Hillel ( 1960 ) used the above example to argue that WSD could not be solved by \" electronic computer \" because of the need in general to model all world knowledge .In the 1970s , WSD was a subtask of semantic interpretation systems developed within the field of artificial intelligence , but since WSD systems were largely rule - based and hand - coded they were prone to a knowledge acquisition bottleneck .", "label": "", "metadata": {}, "score": "59.179363"}
{"text": "We use the metric of the precision .After that , as an upper bound , we use the context of use that corresponds to the most frequent sense ( MFS ) .Used Tools and Experimental Data .Dictionary .We use the dictionary of \" Al - Mu'jam Al - Wasit \" that contains the Arabic lexicography .", "label": "", "metadata": {}, "score": "59.286545"}
{"text": "As a supervised technique , this method consists of two stages learning ( or training ) stage and a testing ( or application ) stage .The trained models ( classifiers ) produced from the learning phase will then be used to disambiguate unseen and unlabeled examples in the testing phase .", "label": "", "metadata": {}, "score": "59.32647"}
{"text": "Consider .In addition , if there do not exist other TDTs in the conflict interval , the split intervals have a bias for the greater weight of TDT .On the basis of pruned topical graph , the document 's topical describing information is formed through detecting the high - density components and choosing top - level cooccurrence topic concepts of topic chains .", "label": "", "metadata": {}, "score": "59.388527"}
{"text": "Agirre E. , D. Mart\u00ednez .Unsupervised WSD based on automatically retrieved examples : The importance of bias .In Proceedings of the Conference on Empirical Methods in Natural Language Processing , EMNLP , Barcelona , Spain , 2004 .[Links ] .", "label": "", "metadata": {}, "score": "59.393436"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .G. K. Savova , A. R. Coden , I. L. Sominsky et al . , \" Word sense disambiguation across two domains : biomedical literature and clinical notes , \" Journal of Biomedical Informatics , vol .", "label": "", "metadata": {}, "score": "59.505035"}
{"text": "In bioinformatics and computational biology , there are quite a few tasks similar to WSD like biomedical term disambiguation , gene protein name disambiguation , and disambiguating species for biomedical named entities [ 9 - 11 ] .The task of biomedical named entity disambiguation or classification is an augmentation of the well - known task of biomedical named entity recognition ( NER ) .", "label": "", "metadata": {}, "score": "59.54234"}
{"text": "It is based on two steps [ 20 ] .The first step ( see Algorithm 2 ) consists of filling the matrix of the two words to be compared to .We use the corpus described in the experimental results , to extract the sentences containing the words of the glosses and their occurrences .", "label": "", "metadata": {}, "score": "59.59777"}
{"text": "In Proceedings of the International Conference on Re - cent Advances in Natural Language Processing ( RANLP-03 ) , Borovets , Bulgaria , pages 482 - 489 , 2003 .[ Turney and Littman , 2005 ] P.D. Turney and M.L. Littman .", "label": "", "metadata": {}, "score": "59.659496"}
{"text": "A possible explanation for this phenomenon is that the SSC incorporates results from the chunkers that are subsequently trained on it .As a consequence , the diversity of the chunkers trained on the SSC may be less than those trained on the GSCs .", "label": "", "metadata": {}, "score": "59.6649"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . H. Xu , M. Markatou , R. Dimova , H. Liu , and C. Friedman , \" Machine learning and word sense disambiguation in the biomedical domain : design and evaluation issues , \" BMC Bioinformatics , vol .", "label": "", "metadata": {}, "score": "59.66817"}
{"text": "Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Computer Recognition of English Word Senses , Amsterdam : North - Holland .Word sense disambiguation using conceptual density .", "label": "", "metadata": {}, "score": "59.67309"}
{"text": "Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Computer Recognition of English Word Senses , Amsterdam : North - Holland .Word sense disambiguation using conceptual density .", "label": "", "metadata": {}, "score": "59.67309"}
{"text": "These approaches based on the external resource usually have lower performance than the machine learning ways , but they have the advantage of a higher precision rate and a wider coverage .These approaches are overly dependent on the knowledge completeness and richness .", "label": "", "metadata": {}, "score": "59.74967"}
{"text": "Then , in the second learning phase , a specification of constraints on application of these operators is induced by means of ILP - so called ' forbidding predicates ' are learned .Automatic tagging of compound verb groups .Finding all parts of a compound verb group in a Czech sentence and tagging the group as a whole is an inevitable groundwork for any subsequent ( semantic ) analysis .", "label": "", "metadata": {}, "score": "59.88784"}
{"text": "devised a rule based system to disambiguate biomedical entity names , like gene products , based on species .In that approach [ 9 ] , some parsing techniques are used and syntactic parse tree with paths between words to determine if there exists a path between species word and the entity name .", "label": "", "metadata": {}, "score": "60.11069"}
{"text": "The target word . is shown in bold face .In this example , . is the total number of training examples .The values of a , b , c , d for .is more highly related with the class . than . , and so it has more discriminating power than . , and this is quantified by their MI values .", "label": "", "metadata": {}, "score": "60.17726"}
{"text": "If the topic concept occurs , then the branch of the corresponding topic chain is determined for the unique sense .Otherwise , the sense is fixed through choosing the semantic branch of the maximum similarity .The formula ( 7 ) can be defined as follows : . , respectively , denote the topic chain and disambiguation context similarity .", "label": "", "metadata": {}, "score": "60.462833"}
{"text": "F. Vasilescu , P. Langlais , and J. Lapalme , \" Evaluating variants of the lesk approach for disambiguating words , \" in Proceedings of the Language Resources and Evaluation , pp .633 - 636 , Lisbon , Portugal , 2004 .", "label": "", "metadata": {}, "score": "60.76068"}
{"text": "For simplicity , and without loss of generality , we assume that we have two senses ( two class labels ) .Moreover , following the same intuitive reasoning of mutual information , MI , we define another method , M2 , for selecting the words as features to be included in the feature vectors as follows : .", "label": "", "metadata": {}, "score": "60.786957"}
{"text": "In the biomedical named entity disambiguation , the extracted entity names ( e.g. , gene product names ) will be applied onto a process such that each occurrence should be disambiguated as either gene name or protein name as the same name can refer to a gene or protein .", "label": "", "metadata": {}, "score": "60.79294"}
{"text": "Moreover , the advances in ontology development and integration in the biomedical domain will facilitate even more the process of automatic text annotation .In this paper , we reported a machine learning approach for biomedical WSD .The approach was evaluated with a benchmark dataset , NLM - WSD , to facilitate the comparison with the results of previous work .", "label": "", "metadata": {}, "score": "60.945496"}
{"text": "Determining the Unique Sense through Choosing the Maximal Similarity .The reason for this is that the task of disambiguating the nouns and noun phrases form are easy to implement through calculating the similarity of topic and semantic ; nevertheless , the verb form is not suitable for directly calculating similarity . is mainly a process of topic and semantic context comparison between a target term and other adjoining ones .", "label": "", "metadata": {}, "score": "61.21495"}
{"text": "References . A. Zouaghi , M. Zrigui , and G. Antoniadis , \" Automatic understanding of Spontaneous arabic speech - a numerical model , \" TAL , vol .49 , no . 1 , pp .141 - 166 , 2008 .", "label": "", "metadata": {}, "score": "61.619164"}
{"text": "Select the SEEK icon to attempt to find the referenced article .If it does not appear to be in cogprints you will be forwarded to the paracite service .Poorly formated references will probably not work .[ Banerjee and Pedersen , 2003 ] S. Banerjee and T. Pedersen .", "label": "", "metadata": {}, "score": "61.71562"}
{"text": "This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .Abstract .Word sense disambiguation ( WSD ) is a fundamental problem in nature language processing , the objective of which is to identify the most proper sense for an ambiguous word in a given context .", "label": "", "metadata": {}, "score": "61.928802"}
{"text": "In this study we investigate an alternative , automatic approach to create an annotated corpus .We have shown before that a system combining the outputs of various chunkers performs better than each of the individual chunkers .Here we postulate that the annotations of such a combined system on a given corpus can be taken as a reference standard , establishing a \" silver standard corpus \" ( SSC ) .", "label": "", "metadata": {}, "score": "61.929222"}
{"text": "The more senses of term or phrase denote the weaker capacity of topic discrimination .The greater topic span distribution denotes the stronger topic representation .Consequently , we define the formula ( 1 ) for calculating the weight of TDT as follows : . are user - specified , the values of which are dynamically adjusted according to experimental effect .", "label": "", "metadata": {}, "score": "61.93541"}
{"text": "Hence , the formulation of reoccurrence topic span interval ( TSI ) for a certain TDT is defined as .Then , we exploit position feature , statistical feature , semantic feature , and topic span distribution feature to identify and extract topic discriminative term .", "label": "", "metadata": {}, "score": "62.09323"}
{"text": "WSD is hard for many reasons , three of which are discussed here .A sense inventory can not be task - independent .A task - independent sense inventory is not a coherent concept : each task requires its own division of word meaning into senses relevant to the task .", "label": "", "metadata": {}, "score": "62.60202"}
{"text": "Chowdhury MFM , Lavelli A : Assessing the practical usability of an automatically annotated corpus .Proceedings of the Fifth Linguistic Annotation Workshop ; Portland 2011 , 101 - 109 .Cunningham H : GATE , a general architecture for text engineering .", "label": "", "metadata": {}, "score": "62.640358"}
{"text": "Extension of GWiM has been developed [ 1 ] .Neighbourhood graphs [ 11 ] are used for description of spatial relations .The inductive query language is fully integrated with PostgreSQL database system .C4.5 , RT4 and Progol are used for computation of inductive queries .", "label": "", "metadata": {}, "score": "62.970947"}
{"text": "In biomedical text , named entities , like gene name , are used the same way irrespective of the species of the entity .As a result , it will be difficult to extract relevant medical information automatically from texts using information extraction system .", "label": "", "metadata": {}, "score": "62.976257"}
{"text": "Constructing Topical - Semantic Association Graph .We fully exploit the interrelationships between topical graph and context space to construct topical - semantic association graph .Figure 1 shows the example of the topical - semantic association graph .We take the proximal terms in the syntactic structure as adjoining feature , disambiguation context as semantic feature , and the topic chain of proximal terms and TDTs in topic span interval as topic feature .", "label": "", "metadata": {}, "score": "63.07048"}
{"text": "4 , pp .257 - 269 , 2012 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. Lesk , \" Automatic sense disambiguation using machine readable dictionaries : how to tell a pine cone from an ice cream cone , \" in Proceedings of the 5th Annual International Conference on Systems Documentation ( SIGDOC'86 ) , pp .", "label": "", "metadata": {}, "score": "63.11708"}
{"text": "[Links ] .Gelbukh , A. , G. Sidorov , L. Chanona .Corpus virtual , virtual : Un diccionario grande de contextos de palabras espa\u00f1olas compilado a trav\u00e9s de Internet .In : Julio Gonzalo , Anselmo Pe\u00f1as , Antonio Ferr\u00e1ndez , eds .", "label": "", "metadata": {}, "score": "63.297615"}
{"text": "The Learning Phase From the labeled training examples of the word , we build the feature vectors using the top context words selected by MI or M2 as features .After that , we use the support vector machine ( SVM ) [ 23 ] as the learner to train the classifier using the training vectors .", "label": "", "metadata": {}, "score": "63.437515"}
{"text": "Human Language Technology conference / North American Chapter of the Association for Computational Linguistics Annual Meeting ; Boston 2004 , 61 - 68 .Ferrucci D , Lally A : UIMA : an architectural approach to unstructured information processing in the corporate research environment .", "label": "", "metadata": {}, "score": "63.488575"}
{"text": "Similarity involving attributes and relations : Judgments of similarity and difference are not inverses .Psychological Science , 1(1 ) : 64 - 69 , 1990 .[Nastase and Szpakowicz , 2003 ] V. Nastase and S. Szpako - wicz .", "label": "", "metadata": {}, "score": "63.694626"}
{"text": "We construct a feature vector .for the instance .the same way as in the learning step .The induced learning model ( classifier ) from the learning step will be employed to classify it ( assign .to one of the two senses .", "label": "", "metadata": {}, "score": "63.889366"}
{"text": "[Links ] .Brill , Eric , Philip Resnik .[Links ] .Briscoe , Ted .John Carroll , Jonathan Graham and Ann Copestake .Relational evaluation schemes .In : Procs .[Links ] .Calvo , Hiram , Alexander Gelbukh .", "label": "", "metadata": {}, "score": "63.949997"}
{"text": "In the first scenario , a chunker has to be trained for a biomedical subdomain for which a GSC is not available .Rather than creating a new GSC , we generate an SSC for the new domain and train the chunker on the SSC .", "label": "", "metadata": {}, "score": "63.996254"}
{"text": "We investigated the use of a silver standard corpus ( SSC ) that is automatically generated by combining the outputs of multiple chunking systems .We explored two use scenarios : one in which chunkers are trained on an SSC in a new domain for which a GSC is not available , and one in which chunkers are trained on an available , although small GSC but supplemented with an SSC .", "label": "", "metadata": {}, "score": "64.05514"}
{"text": "Performance figures of the CALBC SSC against GSCs for named - entity recognition are not yet available , but we presume that they will be much lower .However , despite the differences between an SSC and GSC , chunking systems trained on these corpora showed remarkably similar performances .", "label": "", "metadata": {}, "score": "64.107445"}
{"text": "Further investigations will have to reveal how the quality of an SSC affects classifier performance and whether the use of SSCs in other application areas is equally advantageous as their use in text chunking .Conclusions .We have shown that an automatically created SSC can be a viable alternative for or a supplement to a GSC when training chunkers in a biomedical domain .", "label": "", "metadata": {}, "score": "64.15359"}
{"text": "One is that the SSC that we used for training the chunkers was evaluated against the GSC of the same subdomain , whereas in the other study the domains from which the CALBC SSC and the BioCreative GSC are taken , are more divergent .", "label": "", "metadata": {}, "score": "64.19722"}
{"text": "For example , training the chunkers on a GSC consisting of only 10 abstracts but supplemented with an SSC yielded similar performance as training them on a GSC of 100 - 250 abstracts .The combined system even performed better than any of the individual chunkers trained on a GSC of 500 abstracts .", "label": "", "metadata": {}, "score": "64.20903"}
{"text": "There is evidence from cognitive science that relational similarity is fundamental to many cognitive and linguistic tasks ( e.g. , analogical reasoning ) .In the Vector Space Model ( VSM ) approach to measuring relational similarity , the similarity between two pairs is calculated by the cosine of the angle between the vectors that represent the two pairs .", "label": "", "metadata": {}, "score": "64.23195"}
{"text": "Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .", "label": "", "metadata": {}, "score": "64.28241"}
{"text": "Finally , given a noun object , we can attain other synonyms verbs and retrieve the list of objects .If the result exists in the match content with object , then we choose the sense for the target verb .Experimental Result .", "label": "", "metadata": {}, "score": "64.302315"}
{"text": "Lingpipe , OpenNLP , and Yamcha were trained on the gold standard annotations of each subset and the total set , and tested on the 1,499 GENIA abstracts that were not used for training .The GSC and corresponding SSC ( together always totaling 500 abstracts ) were then used to train the chunkers .", "label": "", "metadata": {}, "score": "64.31664"}
{"text": "Our evaluation is done on 31 words ( as explained in Section 3 ) .We obtained the results of the other methods on these 31 words from the references shown in Table 6 to allow for direct comparison .The best result reported in their paper is 87.8 % using all words with VSM model and for McInnes 85.3 % also with the whole set [ 1 ] .", "label": "", "metadata": {}, "score": "64.36044"}
{"text": "However , we can see that our method 's performance is reasonably well standing in terms of precision , recall , and F1 .The main strength of this method is in using MI values as weights encoded in the feature vectors .", "label": "", "metadata": {}, "score": "64.58925"}
{"text": "The Lesk algorithm [ 10 ] will be used to choose the exact sense from the \u200e different senses \u200e given by these measures .This paper is structured as follows .We describe in \u200e \u200e Section 2 the main used approaches for WSD .", "label": "", "metadata": {}, "score": "64.64457"}
{"text": "The combined system performs better than any of the individual chunkers , including GATE and MetaMap which proved to have F - scores lower than each of the three trainable chunkers , in agreement with our previous findings [ 4 ] .", "label": "", "metadata": {}, "score": "64.68362"}
{"text": "Links ] .Chomsky , Noam .Syntactic Structures .The Hague : Mouton & Co , 1957 .[Links ] .Civit , Montserrat , and Maria Ant\u00f2nia Mart\u00ed .Est\u00e1ndares de anotaci\u00f3n morfosint\u00e1ctica para el espa\u00f1ol .Workshop of tools and resources for Spanish and Portuguese .", "label": "", "metadata": {}, "score": "64.70845"}
{"text": "Proceedings of the 1stWorkshop on Text , Speech , Dialogue - TSD'98 , Brno , Czech Republic , Sept. 1998 .Z\u00e1ckov\u00e1 E. , Pala K. : Corpus - Based Rules for Czech Verb Discontinuous Constituents .Proceedings of TSD'99 , Springer Verlag 1999 , LNAI 1692 , pp .", "label": "", "metadata": {}, "score": "64.890495"}
{"text": "[Links ] .Gelbukh , A. , S. Torres , H. Calvo .Transforming a Constituency Treebank into a Dependency Treebank .Submitted to Procesamiento del Lenguaje Natural No .34 , Spain , 2005 .[Links ] .Gelbukh , Alexander , Grigori Sidorov , Francisco Vel\u00e1squez .", "label": "", "metadata": {}, "score": "65.02617"}
{"text": "They employed three learners VSM ( vector space model ) , Na\u00efve Bayes ( NB ) , and SVM .The results included in Table 6 are their best results with VSM and ( linguistic + MeSH ) features [ 1 ] .", "label": "", "metadata": {}, "score": "65.17102"}
{"text": "The Lesk algorithm , introduced in 1986 , was derived and used in several studies of Pedersen and Bruce [ 21 ] and Sidorov and Gelbukh [ 22 ] , and so forth .We can also cite the work of Vasilescu et al .", "label": "", "metadata": {}, "score": "65.214615"}
{"text": "Proc .Conf .[Links ] .Evaluation of TnT Tagger for Spanish .In Proc .[Links ] .Pollard , Carl , and Ivan Sag .University of Chicago Press , Chicago , IL and London , UK , 1994 .", "label": "", "metadata": {}, "score": "65.44465"}
{"text": "DC represents the horizontal synonyms relation and the vertical hypernyms relation from lower - level concept to upper - level concept .Simultaneously , the glosses can also be available to calculate the semantic similarity .Definition 3 ( topic semantic profile ) .", "label": "", "metadata": {}, "score": "65.485794"}
{"text": "M. Belgacem , A. Zouaghi , M. Zrigui , and G. Antoniadis , Amelioration of the Performance of a Semantic Analyzer for the Comprehension of the Spontaneous Arabic Speech , Applied Imagery Pattern Recognition , Washington , DC , USA , 2009 . A. Zouaghi , L. Merhbene , and M. Zrigui , \" A hybrid approach for arabic word sense disambiguation , \" IJCPOL .", "label": "", "metadata": {}, "score": "65.53628"}
{"text": "Links ] .Yuret , Deniz .Discovery of Linguistic Relations Using Lexical Attraction , PhD thesis , MIT , 1998 .[Links ] is being used in a textual context .A more technical discussion of WSD follows below .", "label": "", "metadata": {}, "score": "65.653015"}
{"text": "All the results showed that the technique is fairly successful and effective in the disambiguation task .Thus , more research work should be exerted to carry out further improvements on the performance of this technique .In future work of this research , we plan to investigate the possibility of disambiguating entity names when all instances of that entity are occurring in one species .", "label": "", "metadata": {}, "score": "65.88106"}
{"text": "Remarkably , the performance difference between the combined systems based on GENIA GSC and PennBioIE SSC is only small ( 0.2 percentage point ) .To test the consistency of this result , we redid the experiment with interchanged corpora , i.e. , GENIA GSC was used for training the chunkers and generating the SSC , and PennBioIE GSC was used for testing .", "label": "", "metadata": {}, "score": "65.90779"}
{"text": "LNCS 1338 , Springer - Verlag 1997 .( modified version of this paper is available as technical report FI MU ) .Pavelek T. , Popel\u00ednsk\u00fd L. : Towards lemma disambiguation : Similarity classes .In Proc . of Summer School on Information Systems , Ruprechtov 1999 ( in Czech ) .", "label": "", "metadata": {}, "score": "65.917595"}
{"text": "Table 2 below describes the characteristics of the dictionary .We give in what follows a sample of glosses for the word \" \u0639\u064a\u0646 \" \" ayn \" given by the dictionary Al - Wasit .First gloss .In this work we choose to work on fine - grained senses .", "label": "", "metadata": {}, "score": "65.94253"}
{"text": "We propose some measure that determines the degree of similarity between a sentence ( containing an ambiguous word ) and a document ( that represents the contexts of use for a given sense of the ambiguous word ) .Let .The results of each comparison are a score indicating the \u200e degree of semantic similarity between \u200e the CC and given CU .", "label": "", "metadata": {}, "score": "66.09343"}
{"text": "An early sceptic was Bar - Hillel who famously proclaimed that \" sense ambiguity could not be resolved . by .electronic computer either current or imaginable \" .Y. Bar - Hillel .Language and Information .Addison - Wesley , 1964 .", "label": "", "metadata": {}, "score": "66.106384"}
{"text": "Decision lists [ 14 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .", "label": "", "metadata": {}, "score": "66.149185"}
{"text": "Decision lists [ 14 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .", "label": "", "metadata": {}, "score": "66.149185"}
{"text": "The evaluation results of our method compare very well with those reported in [ 9 ] as shown in Table 7 .From their results ( Table 7 ) , we notice that the best overall performance was obtained with the ML method ( machine learning ) with precision , recall , and F1 values being equal at 82.69 .", "label": "", "metadata": {}, "score": "66.177475"}
{"text": "Applications .The utility of WSD .There is no doubt that the above applications require and use word sense disambiguation in one form or another .However , WSD as a separate module has not yet been shown to make a decisive difference in any application .", "label": "", "metadata": {}, "score": "66.21888"}
{"text": "It seems obvious that a fixed size of the context window is not adapted for all the words .In order to solve this problem , we suggest determining the optimal size of the appropriate context for each test .We use a window size of 3 words ( three words on the left and three words on the right of the ambiguous word ) , 2 words and one word .", "label": "", "metadata": {}, "score": "66.29988"}
{"text": "Out of the 100 instances of depression , 85 instances are tagged with the first sense , and remaining 15 instances are tagged with \" None \" ( i.e. , no instances tagged with a second sense ) , and so it was excluded in this evaluation .", "label": "", "metadata": {}, "score": "66.359"}
{"text": "Matrix Computations .Third edition .Johns Hop - kins University Press , Baltimore , MD , 1996 .[ Landauer and Dumais , 1997 ] T.K. Landauer and S.T. Du - mais .A solution to Plato 's problem : The latent semantic analysis theory of the acquisition , induction , and repre - sentation of knowledge .", "label": "", "metadata": {}, "score": "66.477554"}
{"text": "The chunkers then annotated the PennBioIE corpus and the annotations of all chunkers were combined to yield the silver standard .Subsequently , Lingpipe , OpenNLP , and Yamcha were trained on the PennBioIE SSC and on the PennBioIE GSC , using 10-fold cross - validation .", "label": "", "metadata": {}, "score": "66.488106"}
{"text": "The labeled training instances will be used to extract the word features for the feature vectors .Suppose the word .labeled with sense . or .( i.e. , in the set .or in the set . can be viewed as . and .", "label": "", "metadata": {}, "score": "66.54021"}
{"text": "The more the TDTs in the certain text fragment are , the more chance there is that they are related to a similar topic content . topical subgraphs .The vertices are represented for corresponding topic span intervals ( TSI ) of TDT ; meanwhile , these TDTs associate with the corresponding topic semantic profiles which include disambiguation contexts and topic chains .", "label": "", "metadata": {}, "score": "66.580284"}
{"text": "In the process of generating topical graph , the subgraph is firstly constructed through immediate overlap of topic span intervals .Then , the multiple subgraphs are connected to the whole topical graph through the immediate adjoining relationship of topic span intervals of TDT , and these intervals are not overlapped .", "label": "", "metadata": {}, "score": "66.74538"}
{"text": "In Table 6 , the results of the three methods ( Joshi-2005 , McInnes-2007 , and Stevenson-2008 ) are taken from Stevenson et al .[ 1 ] .These three methods are supervised methods and used various machine learning algorithm and wide sets of features .", "label": "", "metadata": {}, "score": "66.7837"}
{"text": "Why is WSD hard ?This article discusses the common and traditional characterization of WSD as an explicit and separate process of disambiguation with respect to a fixed inventory of word senses .Words are typically assumed to have a finite and discrete set of senses , a gross simplification of the complexity of word meaning , as studied in lexical semantics .", "label": "", "metadata": {}, "score": "66.86275"}
{"text": "In one instance , c - myc might refer to a human gene , while in another instance it refers to a mouse gene .For example , in Table 3 , the biomedical entity name BCL-2 ( a protein name ) in the first text ( no . 1 ) is human while in the second one is a mouse protein .", "label": "", "metadata": {}, "score": "66.88269"}
{"text": "Progol was also tested in tag disambiguation of Czech nouns [ 12 ] .The first results for tag disambiguation reach average accuracy 91.5 % . was implemented which is capable to learn a sequence of context - dependent parse actions from a set of syntactically annotated sentences .", "label": "", "metadata": {}, "score": "66.89064"}
{"text": "I . and . is the total number of training examples .MI is a well - known concept in information theory and statistical learning .MI is a measure of interaction and common information between two variables [ 22 ] .", "label": "", "metadata": {}, "score": "67.02121"}
{"text": "ACM SIGIR Forum , 32(2 ) : 14 - 15 , 1998 .[Dagan and Glickman , 2004 ] I. Dagan and O. Glickman , Probabilistic textual entailment : Generic applied model - ing of language variability .In Learning Methods for Text Understanding and Mining , Grenoble , France , 2004 .", "label": "", "metadata": {}, "score": "67.16016"}
{"text": "These 10 words will be used to compose the feature vectors for training or testing examples of the terms to be disambiguated .For example , a simple feature vector of size 5 can be as follows : .This feature vector represents an instance that has the first , third , and fourth context words available in its context , and 1.23 is the MI value of the context word with the highest MI .", "label": "", "metadata": {}, "score": "67.212105"}
{"text": "Machine Learning , in press , 2005 .Groundwork .DESAM [5 ] , a corpus of Czech newspaper texts was built at Natural Language Processing Laboratory , Faculty of Informatics , Masaryk University .It contains more than 1 000 000 word positions , about 130 000 different word forms , about 65 000 of them occuring more then once , and 1665 different tags .", "label": "", "metadata": {}, "score": "67.3222"}
{"text": "Tateisi Y , Yakushiji A , Ohta T , Tsujii J : Syntax Annotation for the GENIA corpus .Proceedings of the Second International Joint Conference on Natural Language Processing ; Jeju Island , South Korea 2005 , 222 - 227 .", "label": "", "metadata": {}, "score": "67.46798"}
{"text": "The increase in F - scores varies between 1.7 and 3.1 percentage points for noun phrases and between 1.0 and 3.3 percentage points for verb phrases .Although performance further increases when training on PennBioIE GSC instead of PennBioIE SSC , differences are not large : 0.2 to 0.8 percentage point for noun phrases , 0.3 to 1.7 percentage point for verb phrases .", "label": "", "metadata": {}, "score": "67.47354"}
{"text": "The notion that a combination of systems can be used to create a \" silver standard \" corpus has been explored in the CALBC ( Collaborative Annotation of a Large Biomedical Corpus ) project [ 5 ] .Through CALBC , the natural - language processing community has been invited to annotate a very large biomedical corpus with a variety of named - entity recognition systems .", "label": "", "metadata": {}, "score": "67.47653"}
{"text": "For that reason we use this algorithm which returns only three consonants .The rank of letters in a word depends on the length of the word , and if the word contains an even or odd number of letters .The three letters with the lowest weights are selected .", "label": "", "metadata": {}, "score": "67.69148"}
{"text": "PubMed View Article .Kim J , Ohta T , Pyysalo S , Kano Y , Tsujii J : Overview of BioNLP'09 shared task on event extraction .Proceedings of the Workshop on BioNLP : Shared Task ; Boulder 2009 , 1 - 9 .", "label": "", "metadata": {}, "score": "68.06763"}
{"text": "The global feature perspective is characterized by topical association knowledge , namely , the topical describing information .The Representation of Context for the Ambiguous Term .The representation of ambiguous term in the context space is an important decisive factor for choosing the appropriate sense .", "label": "", "metadata": {}, "score": "68.18999"}
{"text": "View at Scopus . H. Al - Mubaid , \" Context - based technique for biomedical term classification , \" in Proceedings of the IEEE Congress on Evolutionary Computation ( CEC ' 06 ) , pp .5726 - 5733 , Vancouver , Canada , July 2006 .", "label": "", "metadata": {}, "score": "68.217186"}
{"text": "In a very recent study , Chowdhury and Lavelli compared a gene recognition system trained on an initial version of the CALBC SSC against the system trained on the BioCreative GSC [ 6 ] .Methods .Chunking systems .To generate a silver standard , we used five well - known and publicly available chunkers : GATE chunker 5.0 [ 7 ] , Lingpipe 3.8 [ 8 ] , MetaMap 2008v2 [ 9 ] , OpenNLP 2.1 [ 10 ] , and Yamcha 0.33 [ 11 ] .", "label": "", "metadata": {}, "score": "68.28104"}
{"text": "Approximate String Matching .Unlike English , Arabic has a rich derivational system and it is one of the characteristics that makes it ambiguous .The Arabic words are based on roots , generally trilateral .We use the algorithm of approximate string matching [ 5 ] to find the possible occurrences of a stem obtained using the last step .", "label": "", "metadata": {}, "score": "68.75744"}
{"text": "WiM extends Markus by shifting bias , generating negative examples and employing oracles .Important feature of WiM is its ability to learn a logic program from a small set of examples .If necessary it poses a query to the user .", "label": "", "metadata": {}, "score": "68.86035"}
{"text": "View Article .Carpenter B : LingPipe for 99.99 % recall of gene mentions .Proceedings of the Second BioCreative Challenge Evaluation Workshop ; Valencia 2007 , 307 - 309 .Aronson AR : Effective mapping of biomedical text to the UMLS Metathesaurus : the MetaMap program .", "label": "", "metadata": {}, "score": "68.8979"}
{"text": "Links ] .Prescher , Detlef , Stefan Riezler , and Mats Rooth .In Proceedings of the 18thInternational Conference on Computational Linguistics , Saarland University , Saarbr\u00fccken , Germany , 2000 .[Links ] .Ratnaparkhi , Adwait , Jeff Reynar , and Salim Roukos .", "label": "", "metadata": {}, "score": "68.95444"}
{"text": "In this paper , \u200e we are \u200e interested in determining the \u200e meaning of \u200e Arabic \u200e ambiguous words which we can meet in \u200e the messages \u200e transcribed by the module of speech \u200e \u200e recognition .We propose some steps [ 3 ] to build a system for Arabic word sense disambiguation .", "label": "", "metadata": {}, "score": "69.12923"}
{"text": "[ Lesk , 1986 ] M.E. Lesk .Automatic sense disambiguation using machine readable dictionaries : How to tell a pine cone from a ice cream cone .In Proceedings of ACM SIGDOC ' 86 , pages 24 - 26 , 1986 .", "label": "", "metadata": {}, "score": "69.27356"}
{"text": "Our experiments indicated that a GSC consisting of only 10 or 25 abstracts but expanded with an SSC yields similar performances as a GSC of 100 or 250 abstracts .Practically , these results suggest that the time and effort spent in creating a GSC of sufficient size may be much reduced .", "label": "", "metadata": {}, "score": "69.39384"}
{"text": "Acknowledgements .This study was supported by the European Commission FP7 Program ( FP7/2007 - 2013 ) under grant no .231727 ( the CALBC Project ) .Authors ' contributions .NK co - developed the methodology , built the software infrastructure , carried out the experiments , and drafted the manuscript .", "label": "", "metadata": {}, "score": "69.52794"}
{"text": "Silver standard as alternative for gold standard .To test whether an SSC could serve as a substitute for a GSC , we compared the performance of chunkers trained on silver standard annotations of the abstracts in the PennBioIE corpus with the performance of the chunkers trained on the gold standard annotations of the same corpus .", "label": "", "metadata": {}, "score": "69.679596"}
{"text": "The NLM - WSD corpus contains 50 ambiguous terms with 100 instances for each term for a total of 5000 examples .Each example is basically a Medline abstract containing one or more occurrences of the ambiguous word .The instances of these ambiguous terms were disambiguated by 11 annotators who assigned a sense for each instance [ 24 ] .", "label": "", "metadata": {}, "score": "69.770874"}
{"text": "Corpora .There are only a few publicly available corpora in the biomedical domain that incorporate chunk annotations .We used the GENIA Treebank corpus [ 12 ] and the PennBioIE corpus [ 13 ] .The GENIA corpus [ 12 ] has been developed at the University of Tokyo .", "label": "", "metadata": {}, "score": "69.77317"}
{"text": "For example , when disambiguating the words in pine cone , the definitions of the appropriate senses both include the words evergreen and tree ( at least in one dictionary ) .An alternative to the use of the definitions is to consider general word - sense relatedness and to compute the semantic similarity of each pair of word senses based on a given lexical knowledge - base such as WordNet .", "label": "", "metadata": {}, "score": "69.860405"}
{"text": "Links ] .Su\u00e1rez , A. , M. Palomar .[Links ] .Tapanainen , Pasi .Academic Dissertation .University of Helsinki , Language Technology , Department of General Linguistics , Faculty of Arts , 1999 .[Links ] .", "label": "", "metadata": {}, "score": "70.03109"}
{"text": "Conf . on Application of Natural Language to Information Systems .[Links ] .In Proceedings of the 6 th Applied Natural Language Processing Conference , Seattle , Washington , USA , 2000 .[Links ] .Brants , Thorsten .", "label": "", "metadata": {}, "score": "70.12841"}
{"text": "Definition 5 ( the reoccurrence topic span of TDT ) .When a sentence is a basic processing unit , the reoccurrence topic span ( TS ) of TDT is defined as text spans for expressing the particular topical meaning , which starts form the first occurrence of TDT and ends to the last occurrence TDT .", "label": "", "metadata": {}, "score": "70.2377"}
{"text": "Corpus .We chose to work on texts dealing with multiple domains ( sport , politics , religion , science , etc . ) .These texts are extracted from newspaper articles , which were recorded in the corpus of Al - Sulaiti and Atwell [ 25 ] .", "label": "", "metadata": {}, "score": "70.24814"}
{"text": "In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press . . . .In 1975 Kelly and Stone E.F. Kelly and P.J. Stone . . .", "label": "", "metadata": {}, "score": "70.372604"}
{"text": "In Proceedings of GIS ...Ostrava'99 Conference , ISSN 1211 - 4855 , 1999 .Popel\u00ednsk\u00fd L. , Pavelek T. , Pt\u00e1cn\u00edk T. : Towards disambiguation in Czech corpora .In Proc . of LLL Workshop Bled , 1999 .Popel\u00ednsk\u00fd L. , Pavelek T. : Mining lemma disambiguation rules from Czech corpora .", "label": "", "metadata": {}, "score": "70.43072"}
{"text": "LNCS 1510 , Springer - Verlag 1998 .Popel\u00ednsk\u00fd L. : Inductive inference to support object - oriented analysis and design .In : Proc . of 3rd Conf on Knowledge - Based Software Engineering , Smolenice 1998 , IOS Press .", "label": "", "metadata": {}, "score": "70.69803"}
{"text": "Table 4 shows that the combination of the stemming algorithm with the string - matching algorithm gives the best results .Influence of the Size of the Use Contexts .To determine the size of the collected context of use for each sense , we evaluate the results given by our system varying the size of that context of use ( 50 words , 100 words , and 150 words ) .", "label": "", "metadata": {}, "score": "70.760345"}
{"text": "To check the validity of the algorithm presented in the previous section , tests were conducted using some free tools .The English works were evaluated using Senseval-1 or Senseval-2 .However in our work we have to make our experimental data using a totally different set of resources .", "label": "", "metadata": {}, "score": "70.918274"}
{"text": "To extract the stems of the Arabic words we use the Al - Shalabi - Kanaan \u200e algorithm [ 4 ] .Its advantage is \u200e that it does not use any resources .This algorithm extracts word roots by assigning \u200e weights to word 's letters ( the weights are real \u200e numbers predefined between 0 and 5 ) multiplied by the rank \u200e which depends on the letter 's position .", "label": "", "metadata": {}, "score": "71.32358"}
{"text": "We obtained the data from the project of Wang et al .[ 9 ] .From their data , we tested the biomedical entity names that occur in at least two species with at least 3 occurrences in each species .", "label": "", "metadata": {}, "score": "71.452034"}
{"text": "Then , MI ( or M2 ) value is computed for all context words .Then , the context words . are ordered based on their MI values , and the top .words .with highest MI values are selected as features .", "label": "", "metadata": {}, "score": "71.77457"}
{"text": "Here the \" senses \" are words in the target language , which often correspond to significant meaning distinctions in the source language ( bank could translate to French banque ' financial bank ' or rive ' edge of river ' ) .", "label": "", "metadata": {}, "score": "72.2766"}
{"text": "Definition 1 ( topic chain ) .A topic chain ( TC ) is a branch of topic hierarchy and represents a sequence of ordered topic category label terms in ODP .It represents a notation of .Definition 2 ( disambiguation context ) .", "label": "", "metadata": {}, "score": "72.59996"}
{"text": "The SSC as a substitute for a GSC corresponds with a use scenario in which a chunker created for one subdomain has to be adapted to another , where a GSC for the new domain is not available .In the second use scenario , we supplemented a ( small ) GSC with an SSC for the same domain as the GSC .", "label": "", "metadata": {}, "score": "72.92555"}
{"text": "Obviously , to create the SSC we need trained chunkers , and thus a GSC for their initially training .We explored the use of a GSC from another , but related , domain than the domain of interest .Alternatively , we supplemented a GSC with an SSC in the same domain of interest .", "label": "", "metadata": {}, "score": "73.245834"}
{"text": "Biomedical WSD ( NLM - WSD ) .Dataset We used the benchmark dataset NLM - WSD for biomedical word sense disambiguation [ 24 ] .This dataset was created as a unified and benchmark set of ambiguous medical terms that have been reviewed and disambiguated by reviewers from the field .", "label": "", "metadata": {}, "score": "73.40304"}
{"text": "The function description ( si ) finds all the candidate senses obtained by the information retrieval methods .The function score returns the index of the candidate sense : score .The application of this algorithm allowed us to obtain a rate of disambiguation up to 76 % .", "label": "", "metadata": {}, "score": "73.67258"}
{"text": "We have tested the two scenarios using three chunkers , Lingpipe , OpenNLP , and Yamcha , and two different corpora , GENIA and PennBioIE .When the outputs of the chunkers were combined , the combined system showed little improvement when using the SSC .", "label": "", "metadata": {}, "score": "73.93431"}
{"text": "If the entity has 5 or more occurrences in one species , we repeat five times using 5FCV as in Section 4.1 .We extracted and tested our system on a total 465 instances of entity names with an average of 8 instances per species for each entity name .", "label": "", "metadata": {}, "score": "74.133644"}
{"text": "Brno 1993 .( See also Proceedings of 10th WLP'94 , Zuerich 1994 , Switzerland . )Popel\u00ednsk\u00fd L. : Knowledge Discovery in Spatial Data by Means of ILP .In : Zytkow J.M. , Quafafou M.(Eds . ) : Principles of Data Mining and Knowledge Discovery .", "label": "", "metadata": {}, "score": "74.40968"}
{"text": "Copyright .\u00a9 Kang et al ; licensee BioMed Central Ltd. 2012 .The problem of WSD was first introduced by Warren Weaver in 1949 W. Weaver .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .", "label": "", "metadata": {}, "score": "75.10774"}
{"text": "Proc . of 4th Workshop on Inductive Logic Programming ( ILP'94 ) , Bad Honeff , Germany , 1994 .Popel\u00ednsk\u00fd L. : Towards Program Synthesis From A Small Example Set .Proceedings of 21stCzech - Slovak conference on Computer Science SOFSEM'94 , pp.91 - 96 Czech Society for Comp .", "label": "", "metadata": {}, "score": "75.12523"}
{"text": "Our results on the practical value of an SSC are different from those that were recently reported by Chowdhury and Lavelli [ 6 ] .They found a considerable drop in performance of a gene recognition system trained on the CALBC SSC as compared to the system trained on the BioCreative GSC , and also noticed that the system trained on a combination of SSC and GSC performed worse than on the GSC only .", "label": "", "metadata": {}, "score": "75.57012"}
{"text": "WSD was first formulated as a distinct computational task during the early days of machine translation in the 1940s , making it one of the oldest problems in computational linguistics .Warren Weaver , in his famous 1949 memorandum on translation , first introduced the problem in a computational context .", "label": "", "metadata": {}, "score": "75.6548"}
{"text": "values of 100 , 200 , and 300 .With . , for example , each training example will be represented by a vector of 100 entries such that the first entry represent the context word .with the highest MI value , and the second entry represents the context word with the second highest MI value and so on .", "label": "", "metadata": {}, "score": "75.94862"}
{"text": "Table 6 contains the results for 11 methods : baseline method ( mfs ) , our method ( last column ) , and 9 other methods from recent work published in 2008 to 2010 ( from [ 1 , 2 , 4 ] ) .", "label": "", "metadata": {}, "score": "76.503174"}
{"text": "130 - 137 , 1980 .View at Google Scholar A Novel Approach to Word Sense Disambiguation Based on Topical and Semantic Association .Received 22 August 2013 ; Accepted 11 September 2013 .Academic Editors : C.-C. Chang and F. Yu .", "label": "", "metadata": {}, "score": "76.55512"}
{"text": "View at Scopus .G. Forman , \" An Extensive Empirical study of feature selection metrics for text classification , \" Journal of Machine Learning Research , vol .3 , pp .1289 - 1305 , 2003 .View at Google Scholar .", "label": "", "metadata": {}, "score": "76.85277"}
{"text": "La evaluaci\u00f3n muestra que a pesar de su simplicidad , la precisi\u00f3n del analizador es superior a aquella de los analizadores existentes actuales para el espa\u00f1ol .A pesar de que ciertas reglas gramaticales y los recursos l\u00e9xicos usados son espec\u00edficos para el espa\u00f1ol , el enfoque sugerido es independiente del lenguaje .", "label": "", "metadata": {}, "score": "77.16728"}
{"text": "All authors read and approved the manuscript .Authors ' Affiliations .Department of Medical Informatics , Erasmus University Medical Center .References .Polikar R : Ensemble based systems in decision making .IEEE Circuit Syst Mag 2006 , 6 : 21 - 45 .", "label": "", "metadata": {}, "score": "77.2499"}
{"text": "The amount of WSD research in the biomedical domain is not proportional to the extent of the problem .As an example , in the biomedical texts , the term \" blood pressure \" has three possible senses according to the Unified Medical Language System ( UMLS )", "label": "", "metadata": {}, "score": "77.259575"}
{"text": "Expressivity of ophthalmology diseases in descendent populations of a rural region ( IGA MZ CR 4377 - 3 Ministry of Health , CZ ) - collaboration with Health of Child Research Institute in Brno . K. Pala , P. Rychl\u00fd and P. Smrz : DESAM - annotated corpus for Czech .", "label": "", "metadata": {}, "score": "77.95126"}
{"text": "Smith L , Tanabe LK , Ando RJ , Kuo CJ , Chung IF , Hsu CN , Lin YS , Klinger R , Friedrich CM , Ganchev K , et al .: Overview of BioCreative II gene mention recognition .", "label": "", "metadata": {}, "score": "78.412704"}
{"text": "This algorithm takes so much time during its execution ; to facilitate that , we generated a table in our knowledge base in which are recorded occurrences of each root are recorded .Until now this table has a list of 7,349 roots with an average of seven occurrences for each root .", "label": "", "metadata": {}, "score": "78.93054"}
{"text": "The 0.9 version of the corpus was released in 2004 and includes the CYP and Oncology corpora of the Linguistic Data Consortium .The CYP corpus consists of 324 Medline abstracts on the inhibition of cytochrome P450 enzymes .The Oncology corpus consists of 318 Medline abstracts on cancer and molecular genetics .", "label": "", "metadata": {}, "score": "78.988495"}
{"text": "# constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .# computing a HMM model based on the training corpus , runnig the tagger on the test corpus and comparing the results with the original tags in the test corpus .", "label": "", "metadata": {}, "score": "79.01454"}
{"text": "The combination of systems always performed better than any of the individual systems , but performance increase of the combined system was larger when the individual systems were trained on GENIA or PennBioIE GSCs than when they were trained on the PennBioIE SSC ( cf .", "label": "", "metadata": {}, "score": "79.09332"}
{"text": "[ Berry , 1992 ] M.W. Berry .Large scale singular value com - putations .International Journal of Supercomputer Ap - plications , 6(1 ) : 13 - 49 , 1992 .[ Clarke et al . , 1998 ] C.L.A. Clarke , G.V. Cormack , and C.R. Palmer .", "label": "", "metadata": {}, "score": "79.70366"}
{"text": "We used . , and the window size is 5 .The accuracy results of this first evaluation ( EV1 ) are shown in Table 4 .The detailed results of this evaluation are included in Table 5 .In the second evaluation ( EV2 ) and third evaluation ( EV3 ) , we changed the parameter and the word / features selection formula .", "label": "", "metadata": {}, "score": "80.61354"}
{"text": "Thus , the performance of chunkers trained on either SSC or GSC was always tested on the GSC .Silver standard as supplement of gold standard .To test whether an SSC would have additional value as a supplement for a given GSC , we compared the performance of chunkers trained on a subset of the GENIA GSC with the performance of the chunkers trained on the same subset supplemented with an SSC .", "label": "", "metadata": {}, "score": "82.22111"}
{"text": "Adicionalmente , cada uno de los m\u00f3dulos del sistema ( Adquisici\u00f3n de Preferencias de Selecci\u00f3n , Desambiguaci\u00f3n de Sintagma Preposicional ) se eval\u00faa de una forma separada e independiente para verificar su correcto funcionamiento .Finalmente , presentamos algunas aplicaciones de nuestro sistema : Desambiguaci\u00f3n de sentidos de palabras y Estaganograf\u00eda ling\u00fc\u00edstica .", "label": "", "metadata": {}, "score": "82.52515"}
{"text": "Proc . of 3rdEuropean Conference PKDD'99 , Prague Czech Republic 1999 .LNCS 1704 , Springer - Verlag 1999 .Popel\u00ednsk\u00fd L. : Towards practical inductive logic programming .PhD thesis FEL CTU Prague 2000 .Smrz P. , Z\u00e1ckov\u00e1 E. : New Tools for Disambiguation of Czech Texts .", "label": "", "metadata": {}, "score": "83.2994"}
{"text": "The creation of a gold standard corpus ( GSC ) is tedious and expensive : annotation guidelines have to be established , domain experts must be trained , the annotation process is time - consuming , and annotation disagreements have to be resolved .", "label": "", "metadata": {}, "score": "84.2207"}
{"text": "The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .", "label": "", "metadata": {}, "score": "84.350815"}
{"text": "The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .", "label": "", "metadata": {}, "score": "84.350815"}
{"text": "El sistema usa un conjunto ordenado de reglas heur\u00edsticas simples para determinar iterativamente las relaciones entre palabras para las cuales no se les ha asignado a\u00fan un gobernante .Estas estad\u00edsticas han sido obtenidas previamente de una manera no supervisada , ya sea a partir de grandes corpus de texto , o a trav\u00e9s de Internet ( a trav\u00e9s de un motor de b\u00fasqueda como Google ) .", "label": "", "metadata": {}, "score": "85.37547"}
{"text": "9 , supplement 11 , article S7 , 2008 .View at Google Scholar .57 , no . 1 , pp .96 - 113 , 2006 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .", "label": "", "metadata": {}, "score": "86.12288"}
{"text": "New York : Marcel Dekker .Contribution to Semantic Analysis of Arabic Language .Received 11 June 2012 ; Revised 8 August 2012 ; Accepted 28 August 2012 .Academic Editor : Srinivas Bangalore .Copyright \u00a9 2012 Anis Zouaghi et al .", "label": "", "metadata": {}, "score": "88.2728"}
{"text": "Furthermore , in species disambiguation , the term c - myc is a gene , but it can be either in a human gene ( homo sapiens ) or mouse gene ( mus musculus ) depending on the context [ 9 - 11 , 14 - 16 ] .", "label": "", "metadata": {}, "score": "88.77539"}
{"text": "# The boy leapt from the bank into the cold water .# The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers . to .the edge . of a . river and in the second to a building .", "label": "", "metadata": {}, "score": "91.00689"}
{"text": "The opposite is true of river , which requires a choice in French ( fleuve ' flows into the sea ' , or rivi\u00e8re ' flows into a river ' ) .Different algorithms for different applications .Completely different algorithms might be required by different applications .", "label": "", "metadata": {}, "score": "95.705986"}
{"text": "In EV3 , we kept .Table 5 contains the results of EV2 and EV3 .To judge on performance of our method and compare our results with similar techniques , we included several reported results from three recent publications from 2008 to 2010 [ 1 , 2 , 4 ] with our results in Table 6 under the same experimental settings .", "label": "", "metadata": {}, "score": "96.95276"}
{"text": "Under this project there were developed some versions of WiM dedicated to specialised applications , e.g. object - oriented analysis and design [ 10 ] and knowledge discovery in geographic data [ 9 ] .ESPRIT METAL - combination of statistical methods with machine learning , multistrategy learning .", "label": "", "metadata": {}, "score": "99.27161"}
{"text": "The box was in the pen .John was very happy .playpen , pen - a portable enclosure in which babies may be left to play .penitentiary , pen - a correctional institution for those convicted of major crimes .", "label": "", "metadata": {}, "score": "104.55701"}
{"text": "The use of selectional preferences ( or selectional restrictions ) are also useful .For example , knowing that one typically cooks food , one can disambiguate the word bass in I am cooking bass ( i.e. , it 's not a musical instrument ) .", "label": "", "metadata": {}, "score": "104.81915"}
{"text": "A .c .c . u .r . a .c .y .n .o . . .o .f .i .n .s .t . a .n .c .e . s .", "label": "", "metadata": {}, "score": "105.19072"}
{"text": "i .t .h .c .o .r .r .e . c . t . a .s .s .i . g .n .e . d .s .e . n .", "label": "", "metadata": {}, "score": "105.64567"}
{"text": "e . s .t .o .t . a .l .n .o . . .o .f .t .e . s .t .e . d .i .n .s .", "label": "", "metadata": {}, "score": "105.913345"}
{"text": "The features of the context ( such as neighboring words ) provide the evidence for classification .A famous example is to determine the sense of pen in the following passage ( Bar - Hillel 1960 ) : .Little John was looking for his toy box .", "label": "", "metadata": {}, "score": "108.729904"}
