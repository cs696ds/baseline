{"text": "The learning rates of the FLVQ and SCS algorithms have opposite tendencies ( Bezdek & Pal , 1995 ) .The SCS has difficulty in selecting good parameters ( Bezdek & Pal , 1995 ) .The supervised fuzzy min - max classification network ( Simpson , 1992 ) as well as the unsupervised fuzzy min - max clustering net- work ( Simpson , 1993 ) is a kind of combination of fuzzy logic and the ART 1 ( Carpenter & Grossberg , 1987a ) .", "label": "", "metadata": {}, "score": "29.987537"}
{"text": "This process is repeated until the remaining potential values of all the grids fall below a threshold .However , the grid structure causes the complexity to grow exponentially with the dimension of the problem .The subtractive clustering ( Chiu , 1994a ) , as a modified moun- tain clustering , uses all the data points to replace all the grid points as potential cluster centers .", "label": "", "metadata": {}, "score": "31.311"}
{"text": "To accelerate the sequential NG , a truncated exponential func- tion is used as the neighborhood function and the neighborhood ranking is implemented without evaluating and sorting all the dis- tances ( Choy & Siu , 1998b ) .In Rovetta and Zunino ( 1999 ) , an im- proved NG and its analog VLSI subcircuitry have been developed basedonpartialsorting .", "label": "", "metadata": {}, "score": "31.511662"}
{"text": "The dynamic cell structures ( DCS ) model ( Bruske & Sommer , 1995 ) uses a modified Kohonen learning rule to adjust the prototypes and the competitive Heb- bian rule so as to establish a dynamic lateral connection structure .Applying the DCS to the GCS yields the DCS - GCS algorithm , which hasabehaviorsimilartothatoftheGNG.Thelife - longlearningcell .", "label": "", "metadata": {}, "score": "31.886848"}
{"text": "The popular frequency sensitive competitive learning ( FSCL ) ( Ahalt , Krishnamurty , Chen , & Melton , 1990 ) reduces the under- utilization problem by introducing a distortion measure that ensuresallcodewordsinthecodebooktobeupdatedwithasimilar probability .The codebooks obtained by the FSCL algorithm have sufficient entropy so that Huffman coding of the VQ indices would not provide significant additional compression .", "label": "", "metadata": {}, "score": "32.128212"}
{"text": "On the other hand , the purpose of modular systems is to break down a complex problem into several subproblems so that each learning algorithm either solves a different task or trained by different training set .The taxonomy proposed by Sharkey [ 63 ] was further extended by Rokach [ 64 ] .", "label": "", "metadata": {}, "score": "32.867493"}
{"text": "Robust clustering Outliers in a data set affects the result of clustering .The in- fluence of outliers can be eliminated by using the robust statistics approach ( Huber , 1981 ) .This idea has also been incorporated into many robust clustering methods ( Bradley , Mangasarian , & Steet , 1996 ; Dave & Krishnapuram , 1997 ; Frigui & Krishnapuram , 1999 ; Hathaway & Bezdek , 2000 ; Kersten , 1999 ; Leski , 2003a ) .", "label": "", "metadata": {}, "score": "33.209534"}
{"text": "This results in a reduced computational complexity for classification problems by splitting the problem into a series of condition - driven clustering problems .A family of generalized weighted conditional FCM algorithms are derived in Leski ( 2003b ) .Other fuzzy clustering algorithms Many other clustering algorithms are based on the concept of fuzzy membership .", "label": "", "metadata": {}, "score": "33.946003"}
{"text": "Besides the algorithm(s ) to use , the way how data are utilized in modeling is another critical factor for the success of data - driven methods in modeling a problem .For example , when a multi - class real - world problem is modeled with a binary class classification algorithm , as in SVM , different class binarization strategies can be used .", "label": "", "metadata": {}, "score": "34.010292"}
{"text": "An incremental network for on - line unsupervised classification and topology learning .Neural Netw ( in print ) .Gao , K. , Ahmad , M.O. , & Swamy , M.N.S. ( 1991 ) .Nonlinear signal processing with self - organizing neural networks .", "label": "", "metadata": {}, "score": "34.407593"}
{"text": "Dietterich and Bakiri introduced ECOC to be used within the ensemble setting ( Dietterich 1995 ) .The idea is to use a different class encoding for each member of the ensemble .The encodings constitute a binary C by T code matrix , where C and T are the number of classes and ensemble size , respectively , combined by the minimum Hamming distance rule .", "label": "", "metadata": {}, "score": "34.71483"}
{"text": "Section 2 is a brief summary on the background of techniques used in this paper , namely support vector machine ( SVM ) ; C4.5 decision tree ; and class binarization .Section 3 introduces the hypothesis and logic behind the problem formulation used in modeling .", "label": "", "metadata": {}, "score": "34.734505"}
{"text": "Finally , they assumed that the training set is without attacks , by filtering it with a signature - based IDS , in order to throw out at least known attacks .Similar approach was also proposed by Corona et al .", "label": "", "metadata": {}, "score": "35.21257"}
{"text": "In this case , the classifier combination involves merging the individual ( usually weaker and/or diverse ) classifiers to obtain a single ( stronger ) expert of superior performance .Examples of this approach include bagging predictors ( Breiman 1996 ) , boosting ( Schapire 1990 ) , AdaBoost ( Freund 2001 ) and their many variations .", "label": "", "metadata": {}, "score": "35.44199"}
{"text": "The subtractive clustering can be improved by performing a search over \u03b1 and \u03b2 , which makes it essentially equivalent to the least - biased fuzzy clustering algorithm ( Beni & Liu , 1994 ) .The least - biased fuzzy clustering , based on the deterministic anneal- ing approach ( Rose , 1998 ; Rose , Gurewitz , & Fox , 1990 ) , tries to minimize the clustering entropy of each cluster under the assump- tion of unbiased centroids .", "label": "", "metadata": {}, "score": "35.54486"}
{"text": "Buhmann , J. , & Kuhnel , H. ( 1993 ) .Vector quantization with complexity costs .IEEE Transactions on Information Theory , 39(4 ) , 1133 - 1145 .Burke , L. I. ( 1991 ) .Clustering characterization of adaptive resonance .", "label": "", "metadata": {}, "score": "35.690403"}
{"text": "\u00b5ji N ? mxi ? m ?TheFCMhasalso been extended for clustering other data types , such as symbolic data ( El - Sonbaty & Ismail , 1998 ) .For a blend of unlabeled and labeled patterns , the FCM with partial supervision ( Pedrycz & Waletzky , 1997 ) can be applied and the method is derived following the same procedure as that of the FCM .", "label": "", "metadata": {}, "score": "35.706516"}
{"text": "Other topics such as global search based clustering are also reviewed in Xu and Wunsch II ( 2005 ) .Clustering has become an important tool for data mining , also known as knowledge discovery in databases ( KDD ) ( Jain et al . , 1999 ) , which emerges as a rapidly growing area .", "label": "", "metadata": {}, "score": "35.749947"}
{"text": "For example , a series of multilayer perceptron ( MLP ) neural networks can be trained by using different weight initializations , number of layers / nodes , error goals , etc .Adjusting such parameters allows one to control the instability of the individual classifiers , and hence contribute to their diversity .", "label": "", "metadata": {}, "score": "35.755272"}
{"text": "The fuzzy FSCL ( FFSCL ) ( Chung & Lee , 1994 ) combines the frequency sensitivity with fuzzy competitive learning .Since both the FSCL and the FFSCL use a non-Euclideandistancetodeterminethewinner , theproblemofshared clusters may occur : a number of prototypes move into the same cluster as learning proceeds . can be generalized as F(uj ) ? ?", "label": "", "metadata": {}, "score": "35.852036"}
{"text": "In Xie and Beni ( 1991 ) , the ratio of compactness and separation is used as a cluster validity criterion for fuzzy clustering .Entropy cluster validity measures based on class conformity are given in Boley ( 1998 ) ; He et al .", "label": "", "metadata": {}, "score": "35.91134"}
{"text": "They reported that the proposed method provides significant improvement of prediction accuracy in ID .Muda et al .[120 ] proposed a combined approach of clustering and classification .The clustering is performed by using K - means algorithm to form groups of similar data in earlier stage .", "label": "", "metadata": {}, "score": "35.91962"}
{"text": "Neural Networks , 4 , 759 - 771 .Carpenter , G. , Grossberg , S. , & Rosen , D.B. ( 1991b ) .ART 2-A : An adaptive resonance algorithm for rapid category learning and recognition , Proc int joint conf neural netw , vol .", "label": "", "metadata": {}, "score": "35.985428"}
{"text": "Implementations using analog or optical hardware are more .Page 7 .K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 95 desirable .A modified ART 1 in the fast learning mode has been de- rived for easy hardware implementation in Serrano - Gotarredona and Linares - Barranco ( 1996 ) , and the method has also been ex- tended for the full mode and the STM steady - state mode .", "label": "", "metadata": {}, "score": "36.21502"}
{"text": "An introduction to computing with neural nets .IEEE ASSP Magazine , 4(2 ) , 4 - 22 .Liu , Z. Q. , Glickman , M. , & Zhang , Y. J. ( 2000 ) .Soft - competitive learning paradigms .", "label": "", "metadata": {}, "score": "36.29689"}
{"text": "The basic principle is to evaluate several individual pattern classifiers , and integrate them in order to reach a classification that is better than the one obtained by each of them separately .Our overview focused on supervised AI - based ensemble for intrusion detection proposed in last decade , since historically these were the first to be studied and applied to several application domains .", "label": "", "metadata": {}, "score": "36.313232"}
{"text": "Hammer , B. , Micheli , A. , Sperduti , A. , & Strickert , M. ( 2004 ) .Recursive self- organizing network models .Neural Networks , 17 , 1061 - 1085 .Hathaway , R. J. , & Bezdek , J. C. ( 1994 ) .", "label": "", "metadata": {}, "score": "36.31422"}
{"text": "The method is more effective than the CURE in discovering clusters of arbitrary shapes and varying densities ( Karypis et al . , 1999 ) .The VQ - clustering and VQ - agglomeration methods ( Wang & Rau , 2001 ) involve a VQ process followed , respectively , by clustering and agglomerative clustering that treat the codewords as initial prototypes .", "label": "", "metadata": {}, "score": "36.40139"}
{"text": "It is useful for VQ , clustering , feature extraction , and data visualization .The Kohonen learning rule is a major development of competitive learning .The SOM is related to adaptive C - means , but performs a topological feature map which is more complex than just cluster analysis .", "label": "", "metadata": {}, "score": "36.48191"}
{"text": "Similar approach of multiclassifier systems is also advocated by Sabhnani and Serpen [ 23 ] by combining three different machine learning techniques , namely , an ANN , k - means clustering , and a Gaussian classifier .However , they do not provide further implementation details about training the classifiers , nor about determining output of the ensemble .", "label": "", "metadata": {}, "score": "36.57542"}
{"text": "Zainal et al .[35 ] proposed heterogeneous ensemble of linear genetic programming ( LGP ) , adaptive neural fuzzy inference system ( ANFIS ) , and random forest ( RF ) for ID .Base classifiers are generated by using class - specific features of KDD cup 99 dataset .", "label": "", "metadata": {}, "score": "36.672894"}
{"text": "Clustering methods can be based on statistical model identification ( McLachlan & Basford , 1988 ) or competitive learning .In this paper , we give a comprehensive overview of competitive learning based clustering methods .Associated topics such as the under - utilization problem , fuzzy clustering , robust clustering , clustering based on non - Euclidean distance measures , supervised clustering , hierarchical clustering as well as cluster validity are also described .", "label": "", "metadata": {}, "score": "36.712837"}
{"text": "Clustering methods can be based on statistical model identification ( McLachlan & Basford , 1988 ) or competitive learning .In this paper , we give a comprehensive overview of competitive learning based clustering methods .Associated topics such as the under - utilization problem , fuzzy clustering , robust clustering , clustering based on non - Euclidean distance measures , supervised clustering , hierarchical clustering as well as cluster validity are also described .", "label": "", "metadata": {}, "score": "36.712837"}
{"text": "In his 2000 review article , Dietterich lists three primary reasons for using an ensemble based system : i ) statistical ; ii ) computational ; and iii ) representational ( Dietterich 2000 ) .Note that these reasons are similar to those listed above .", "label": "", "metadata": {}, "score": "36.936035"}
{"text": "In the hierarchical architecture , individual classifiers are combined into a structure , which is similar to that of a decision tree classifier .The tree nodes , however , may now be associated with complex classifiers demanding a large number of features .", "label": "", "metadata": {}, "score": "37.153168"}
{"text": "nealing .The SCS ( Yair et al . , 1992 ) employs a similar soft competitive strategy , but \u03b2 is fixed as unity .The winner - take - most criterion , however , detracts some pro- totypes from their corresponding clusters , and consequently be- comes biased toward the global mean of the clusters , since all the prototypes are attracted to each input pattern ( Liu , Glickman , & Zhang , 2000 ) .", "label": "", "metadata": {}, "score": "37.198936"}
{"text": "IEEE Transactions on Fuzzy Systems , 7(4 ) , 377 - 393 .Sato , A. , & Yamada , K. ( 1995 ) .Generalized learning vector quantization .In G. Tesauro , D. Touretzky , & T. Leen ( Eds . ) , Advances in neural information processing systems : vol . 7 ( pp .", "label": "", "metadata": {}, "score": "37.20321"}
{"text": "M. Pazzani , C. Merz , P. M. K. Ali , T. Hume , and C. Brunk , \" Reducing misclassification costs , \" in Proceedings of the 11th International Conference of Machine Learning ( ICML ' 94 ) , Morgan Kaufmann , 1994 .", "label": "", "metadata": {}, "score": "37.309288"}
{"text": "The outputs of these classifiers on their pseudo - training blocks , along with the actual correct labels for those blocks constitute the training dataset for the Tier 2 classifier ( see Figure 7 ) .Jordan and Jacobs ' mixture of experts ( Jacobs 1991 ) generates several experts ( classifiers ) whose outputs are combined through a ( generalized ) linear rule .", "label": "", "metadata": {}, "score": "37.38034"}
{"text": "Volume prototypes extend the cluster prototypes from points to regions in the clusteringspace(Kaymak&Setnes,2002 ) .Aclusterrepresentedby a volume prototype implies that all data points close to a cluster center belong fully to that cluster .In Kaymak and Setnes ( 2002 ) , the Gustafson - Kessel algorithm and the FCM have been extended by using the volume prototypes and similarity - driven merging of clusters .", "label": "", "metadata": {}, "score": "37.480064"}
{"text": "A fully analog integrated circuit of the SOM has been designed in Mann and Gilbert ( 1989 ) .A comprehensive survey of SOM applications is given in Kohonen ( 1996 ) .However , the SOM is not a good choice in terms of clustering performance compared to other popular clustering algorithms suchastheC - means , theneuralgas , andtheART2A(He , Tan,&Tan , 2004 ; Martinetz , Berkovich , & Schulten , 1993 ) .", "label": "", "metadata": {}, "score": "37.572388"}
{"text": "Shih , F. Y. , Moh , J. , & Chang , F. C. ( 1992 ) .A new ART - based neural architecture for patternclassificationandimageenhancementwithoutpriorknowledge .Pattern Recognition , 25(5 ) , 533 - 542 .Simpson , P. K. ( 1992 ) .", "label": "", "metadata": {}, "score": "37.636127"}
{"text": "Carpenter , G. A. , Grossberg , S. , Markuzon , N. , Reynolds , J. H. , & Rosen , D. B. ( 1992 ) .Fuzzy ARTMAP : A neural network architecture for incremental supervised learning of analog multidimensional maps .", "label": "", "metadata": {}, "score": "37.737915"}
{"text": "108 - 117 , 2002 .M. S. Kamel and N. M. Wanas , \" Data dependence in combining classifiers , \" in Proceedings of 4th International Workshop on Multiple Classifier Systems ( MCS ' 03 ) , T. Windeattand and F. Roli , Eds . , vol .", "label": "", "metadata": {}, "score": "37.93979"}
{"text": "108 - 117 , 2002 .M. S. Kamel and N. M. Wanas , \" Data dependence in combining classifiers , \" in Proceedings of 4th International Workshop on Multiple Classifier Systems ( MCS ' 03 ) , T. Windeattand and F. Roli , Eds . , vol .", "label": "", "metadata": {}, "score": "37.93979"}
{"text": "This article focuses on classification related applications of ensemble learning , however , all principle ideas described below can be easily generalized to function approximation or prediction type problems as well .An ensemble - based system is obtained by combining diverse models ( henceforth classifiers ) .", "label": "", "metadata": {}, "score": "38.137688"}
{"text": "Most of popular ensemble methods proposed and implemented in the literature utilize data level .These methods are used to generate different training sets and a learning algorithm , which can be applied to the obtained subsets of data in order to produce multiple hypotheses .", "label": "", "metadata": {}, "score": "38.21895"}
{"text": "Page 13 .K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 101 The conventional minimum spanning tree ( MST ) algorithm ( Zahn , 1971 ) is a graph - theoretical technique ( Swamy & Thulasir- aman , 1981 ; Thulasiraman & Swamy , 1992 ) .", "label": "", "metadata": {}, "score": "38.2334"}
{"text": "These are achieved by using an internal controller that jointly maximizes predictive generalization and minimizes predictive error by link- ing predictive success to category size on a trial - by - trial basis , us- ing only local operations .However , the ARTMAP is very sensitive to the order of the training patterns compared to learning by the radial basis function network ( RBFN ) ( Broomhead & Lowe , 1988 ) .", "label": "", "metadata": {}, "score": "38.365257"}
{"text": "This in turn means that the new dataset can be seen as being sampled from the cost - transformed probabilities .described in the introduction of this paper .This resampling method allows the application of any cost - in - sensitive learning method to the derived dataset , while still achieving cost - minimization with respect to the original dataset .", "label": "", "metadata": {}, "score": "38.373615"}
{"text": "Some IDSs have been developed based on single - classification technique while other IDSs ( called hybrid / ensemble IDS ) implement more - than - one - classfication technique .Ensemble - based IDSs have many advantages over the IDS implementing single technique ( refer to Section 2 ) .", "label": "", "metadata": {}, "score": "38.39549"}
{"text": "The performance of the PCM , however , relies heavily on initialization of cluster prototypes and estimation of\u03b2j , and the PCM tends to converge to coincidental clusters ( Dave & Krishnapuram , 1997 ) .Other robust clustering problems A family of robust clustering algorithms have been obtained by treating outliers as the fuzzy complement ( Yang & Wang , 2004 ) .", "label": "", "metadata": {}, "score": "38.41092"}
{"text": "Experiments with two artificial datasets and one application example show that this approach is more accurate than a method which uses class dependent costs given by experts a priori .Introduction .The inductive construction of classifiers from training sets is one of the most common research areas in machine learning ( ML ) and therefore in human - computer interaction .", "label": "", "metadata": {}, "score": "38.43434"}
{"text": "The methods are in general characterized by a two step approach : first , at learning of the classes as a set of independent classification problems ; second , at combination of the predictions by exploiting the associations between classes that describe the hierarchy .", "label": "", "metadata": {}, "score": "38.45975"}
{"text": "For a detailed overview of these and other combination rules , see ( Kuncheva 2005 ) .Other applications of ensemble systems .Ensemble based systems can be used in problem domains other than improving the generalization performance of a classifier .", "label": "", "metadata": {}, "score": "38.479027"}
{"text": "The enhanced - LBG algorithm .Neural Networks , 14 , 1219 - 1237 .Pedrycz , W. , & Waletzky , J. ( 1997 ) .Fuzzy clustering with partial supervision .IEEE Transacions on Systems Man and Cynernetics - B , 27(5 ) , 787 - 795 .", "label": "", "metadata": {}, "score": "38.54496"}
{"text": "As opposed to the GCS , the growing grid has a strictly rectangular topology .By inserting complete rows or columns of units , the grid may adapt its height / width ratio to the given pattern distribution .The GNG model ( Fritzke , 1995a , 1997a ) is based on the GCS ( Fritzke , 1994a ) and the NG ( Martinetz et al . , 1993 ) .", "label": "", "metadata": {}, "score": "38.635838"}
{"text": "The following notations will be used in both Sections 2.1 and 2.2 .The rest of this section is a brief overview of the SVM algorithm ; the C4.5 decision tree and the class binarization strategy to be used in the proposed method .", "label": "", "metadata": {}, "score": "38.6473"}
{"text": "Some researchers proposed to use a distributed environment in which each node is assigned a part of dataset .An ensemble method was used to fuse or select predictions .Thirdly , an important feature of IDS is the capability to adapt to dynamic behavior of intrusive and normal traffic .", "label": "", "metadata": {}, "score": "38.697296"}
{"text": ", 1996 ) is derived by solving a bilinear programming problem that utilizes the L1-norm distance .The fuzzy C - median ( Kersten , 1999 ) is a robust FCM method that uses the L1-norm with the exemplar estimation based on the fuzzy median .", "label": "", "metadata": {}, "score": "38.711246"}
{"text": "The algorithm takes typically five times as long as the FCM to com- plete cluster formation ( Karayiannis & Randolph - Gips , 2003 ) .The adaptive fuzzy clustering ( AFC ) ( Anderson , Bezdek , & Dave , 1982 ) also employs the Mahalanobis distance , and is suitable for ellipsoidal or linear clusters .", "label": "", "metadata": {}, "score": "38.75853"}
{"text": "In Proc int joint conf neural netw , vol .3 ( pp .1987 - 1992 ) .Vesanto , J. , & Alhoniemi , E. ( 2000 ) .Clustering of the self - organizing map .IEEE Transactions on Neural Networks , 11(3 ) , 586 - 600 .", "label": "", "metadata": {}, "score": "38.789505"}
{"text": "The self- creating and organizing neural network ( SCONN ) ( Choi & Park , 1994 ) employs adaptively modified node thresholds to control its self - growth .For a new input , the winning node is updated if it is active ; otherwise a new node is created from the winning node .", "label": "", "metadata": {}, "score": "38.798897"}
{"text": "An integrated approach to fuzzy learning vector quantization and fuzzy c - means clustering .IEEE Transactions on Fuzzy Systems , 5(4 ) , 622 - 628 .Karayiannis , N. B. , Bezdek , J. C. , Pal , N. R. , Hathaway , R. J. , & Pai , P. I. ( 1996 ) .", "label": "", "metadata": {}, "score": "39.047462"}
{"text": "The former approach involves the use of different classifiers to take a unique decision about the data pattern typically related to a single network packet whereas the later approach is mainly aimed at providing a high - level description of the detected pattern / attack by using the outputs of different classifiers / IDS .", "label": "", "metadata": {}, "score": "39.127518"}
{"text": "945 - 954 , 1995 .K. Woods , W. P. J. Kegelmeyer , and K. Bowyer , \" Combination of multiple classifiers using local accuracy estimates , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .19 , no .", "label": "", "metadata": {}, "score": "39.13339"}
{"text": "Clusteringofavectorialdatasetwithmissingentriesbelongsto robust clustering .In Hathaway and Bezdek ( 2001 ) , four strategies , namely the whole data , partial distance , optimal completion and nearest prototype strategies , are discussed for implementing the FCM for incomplete data .The introduction of the concept of noise clustering into relational clustering techniques leads to their robust versions ( Dave & Sen , 2002 ) .", "label": "", "metadata": {}, "score": "39.159153"}
{"text": "However , the C - means algorithm using the Mahalanobis distance tends to produce unusually large or unusually small clusters ( Mao & Jain , 1996 ) .The hyperellipsoidal clustering ( HEC ) network ( Mao & Jain , 1996 ) integrates PCA and clustering into one network , and can adaptively estimate the hyperellipsoidal shape of each cluster .", "label": "", "metadata": {}, "score": "39.170708"}
{"text": "A clustering technique for summarizing multivariate data .Behavioural Science , 12 , 153 - 155 .Bandyopadhyay , S. , Maulik , U. , & Pakhira , M. K. ( 2001 ) .Clustering using simulated annealing with probabilistic redistribution .", "label": "", "metadata": {}, "score": "39.196445"}
{"text": "An extensive study in [ 68 ] has shown that the two binarization strategies with an appropriate combination strategy are simple and useful ensemble methods to improve classifier performances , even when the classification algorithm itself can handle multiple classes .C4.5 decision tree used in this paper is an example of classification algorithms that can handle multiple classes .", "label": "", "metadata": {}, "score": "39.32061"}
{"text": "They discussed in detail some data mining methods such as ANN , fuzzy sets and fuzzy logic , statistical learning theory and kernel methods such as SVM and relevance vector machine ( RVM ) , simulated annealing , GA , Gaussian process , graphical methods and deep belief networks .", "label": "", "metadata": {}, "score": "39.322052"}
{"text": "In this paper , we propose a novel strategy to accomplish this by OVA class binarization .The SVM used in this paper is built using sequential minimal optimization ( SMO ) [ 52 ] .Although a SVM model depends on only a subset of the training data , it is well - known for its excellent performance in generalization and the classification of high - dimensional data [ 46 ] .", "label": "", "metadata": {}, "score": "39.32597"}
{"text": "An optimum number of clusters is determined via a process of competitive agglomeration , while the knowledge of the global shape of the clusters is incorporated via the use of prototypes .Robust statistics like the M - estimator ( Huber , 1981 ) is incorporated to combat the outliers .", "label": "", "metadata": {}, "score": "39.332424"}
{"text": "T. Y. Lin , \" Granular computing - structures , representations , and applications , \" in Lecture Notes in Artificial Intelligence , vol .View at Google Scholar .Z. Zhou and X. Liu , \" Training cost - sensitive neural networks with methods addressing the class imbalance problem , \" IEEE Transactions on Knowledge and Data Engineering , vol .", "label": "", "metadata": {}, "score": "39.4365"}
{"text": "Web mining is more difficult since the WWW is a less structured database ( Etzioni , 1996 ) .The topology - preserving property for the SOM makes it particularly suitable for web in- formation processing .References Ahalt , S.C.,Krishnamurty , A.K.,Chen , P.,&Melton , D.E.(1990 ) .", "label": "", "metadata": {}, "score": "39.45618"}
{"text": "Besides , the number of clusters does not need to be prespecified .The subtractive clustering is a deterministic method : For the same neural network structure , the same network parameters are always obtained .Both the C - means and the FCM require O(KNT ) computations , where T is the total number of epochs and each computation requires the calculation of the distance and the memberships .", "label": "", "metadata": {}, "score": "39.63814"}
{"text": "In contrast , the multi - disciplinary research field of data mining focuses on the non - trivial extraction of implicit , previously unknown , potentially useful knowledge about data [ 19 , 20 ] .Their advantages over signal processing methods include better adaptation to complex systems ; better accommodation to uncertainty ; and the fact they do not require calculation of characteristic defect frequencies from the physics of the components .", "label": "", "metadata": {}, "score": "39.647774"}
{"text": "A partitioning that results in both dense and loose clusters may lead to a large average fuzzy density .For shell clustering , the hypervolume and average density mea- sures are still applicable .However , the distance vector between a pattern and a prototype needs to be redefined .", "label": "", "metadata": {}, "score": "39.685555"}
{"text": "Configuring RBF neural networks .Electronics Letters , 34(7 ) , 684 - 685 .Staiano , A. , Tagliaferri , R. , & Pedrycz , W. ( 2006 ) .Improving RBF networks performance in regression tasks by means of a supervised fuzzy clustering .", "label": "", "metadata": {}, "score": "39.73284"}
{"text": "The algorithms described above have their built in combination rules , such as simple majority voting for bagging , weighted majority voting for AdaBoost , a separate classifier for stacking , etc .However , an ensemble of classifiers can be trained simply on different subsets of the training data , different parameters of the classifiers , or even with different subsets of features as in random subspace models .", "label": "", "metadata": {}, "score": "39.787903"}
{"text": "When an initial prototype is in a region with few training patterns , this results in a large cluster .This disadvantage can be remedied by a modified C - means ( Wilpon & Rabiner , 1985 ) .The clustering starts from one cluster .", "label": "", "metadata": {}, "score": "39.8302"}
{"text": "In this paper , we will consider the case of classification learning through the construction of decision trees , which minimize the mean cost of false classifications ( with error minimization as a special case ) .Ling et al .[", "label": "", "metadata": {}, "score": "39.85623"}
{"text": "Page 17 .K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 105 Celeux , G.,&Govaert , G.(1992 ) .AclassificationEMalgorithmforclusteringandtwo stochastic versions .Computational Statistics and Data Analysis , 14 , 315 - 332 .Chen , C.L.,Chen , W.C.,&Chang , F.Y.(1993 ) .", "label": "", "metadata": {}, "score": "39.86235"}
{"text": "Wolpert , D.H. , \" Combining Generalizers Using Partitions of the Learning Set \" , in 1992 Lectures in Complex Systems , Ed .L. Nadel et al . , Addison - Wesley , 1994 .PDF or Postscript .Wolpert , D.H. , \" On the Use of Evidence in Neural Networks \" , in Advances in Neural Information Processing Systems V , Ed . S. Hanson et al . , Morgan Kauffman , 1993 .", "label": "", "metadata": {}, "score": "39.87401"}
{"text": "SVM is a kernel method first introduced in [ 43 ] , which builds a model by constructing a hyperplane that best separates two classes .A detail review of the algorithms , including the SVM for classification and the support vector regression ( SVR ) for regression can be found in [ 44 ] .", "label": "", "metadata": {}, "score": "39.896675"}
{"text": "If this set of classifiers is fixed , the problem focuses on the ensemble integration phase .It is also possible to use a fixed combiner and optimize the set of input classifiers ; the problem focuses on the generation and selection phases .", "label": "", "metadata": {}, "score": "39.907875"}
{"text": "Some popular techniques in the signal processing approach for bearing fault diagnostics include fast Fourier transform ( FFT ) , wavelet methods , spectral kurtosis ( SK ) , amplitude demodulation by envelope analysis or Hilbert transform , described in papers such as [ 12 - 14 ] .", "label": "", "metadata": {}, "score": "39.956566"}
{"text": "Learning vector quantization The k - nearest - neighbor ( k - NN ) algorithm ( Duda & Hart , 1973 ) is a conventional classification technique .It is also used for outlier detection .Itgeneralizeswellforlargetrainingsets , andthetraining set can be extended at any time .", "label": "", "metadata": {}, "score": "39.972427"}
{"text": "The agglomeration algorithm requires that each codeword be moved directly to the centroid of its neighboring codewords .A similar two - stage clustering procedure that uses the SOM for VQ and an agglomerative clustering or the C - means for further clustering is given in Vesanto and Alhoniemi ( 2000 ) .", "label": "", "metadata": {}, "score": "39.984158"}
{"text": "Various clus- teringtechniquesbasedoncompetitivelearningaredescribed .The paper is organized as follows .In Section 2 , we give an introduction to competitive learning .In Section 3 , the Kohonen network and the self - organizing map ( SOM ) are treated .", "label": "", "metadata": {}, "score": "40.01411"}
{"text": "In the gated parallel variant , the outputs of individual classifiers are selected or weighted by a gating device before they are combined .In the cascading architecture , individual classifiers are invoked in a linear sequence .The number of possible classes for a given pattern is gradually reduced as more classifiers in the sequence have been invoked .", "label": "", "metadata": {}, "score": "40.033752"}
{"text": "Differing provisions from the publisher 's actual policy or licence agreement may be applicable . \"In clustering methods , data samples are unlabeled , and the challenge is how to categorize them into meaningful clusters .Being a fundamental data analysis method , clustering is commonly used in many applications , which include pattern recognition , image segmentation , and function approximation [ 4].", "label": "", "metadata": {}, "score": "40.06102"}
{"text": "Yet another application is the modeling of cognitive and general behavioral processes where , for example , emotional evaluation plays a major role .In this paper it is applied to the decision tree learning ( see also [ 18 , 19 ] ) .", "label": "", "metadata": {}, "score": "40.082573"}
{"text": "Miscellaneous clustering methods There are also numerous density based and graph theory based clustering algorithms .Here , we mention some algorithms associated with competitive learning and neural networks .The LBG has been implemented by storing the data points via a k- d tree , achieving typically an order of magnitude faster than the LBG ( Kanungo et al . , 2002 ) .", "label": "", "metadata": {}, "score": "40.114273"}
{"text": "4 , pp .497 - 508 , 2001 .R. Polikar , \" Bootstrap inspired techniques in computational intelligence : ensemble of classifiers , incremental learning , data fusion and missing features , IEEE Signal Processing Magazine , v. 24 , no .", "label": "", "metadata": {}, "score": "40.157192"}
{"text": "[ 22 ] .Sabhnani and Serpen [ 23 ] proposed a multi - classifier approach to detect intrusions .They utilized different classifiers , namely , an ANN , k - means clustering , and a Gaussian classifier to classify different classes of intrusions by using KDD 1999 dataset .", "label": "", "metadata": {}, "score": "40.22739"}
{"text": "AI - based techniques and their ensembles are presently attracting considerable attention from the research community for intrusion detection .Their features , such as flexibility , adaptability , new pattern recognition , fault tolerance , learning capabilities , high computational speed , and error resilience for noisy data , fit the prerequisite of building effective IDS .", "label": "", "metadata": {}, "score": "40.244366"}
{"text": "The OPTOC enables each prototype to situate at the centroid of one natural cluster when the number of clusters is greater than that of the prototypes .The SSCL starts with a single prototype and splits adaptively until all the clusters are found .", "label": "", "metadata": {}, "score": "40.27723"}
{"text": "Finally , diversity can also be achieved by using different features , or different subsets of existing features .In fact , generating different classifiers using random feature subsets is known as the random subspace method ( Ho 1998 ) , as described later in this article .", "label": "", "metadata": {}, "score": "40.29869"}
{"text": "However , just like any methods , SVM methods may not be the most accurate algorithm for all situations .In particular , it does not naturally handle multiple classes or generate proper probability estimates .In the formal statistical sense , the SVM do not belong to techniques of the ' Bayesian ' approach .", "label": "", "metadata": {}, "score": "40.30919"}
{"text": "The clustering results using the SOM as an intermediate step are comparable to that of direct clus- tering of the data , but with a significantly reduced computation time .Mountain and subtractive clusterings The mountain clustering ( Yager & Filev , 1994a , 1994b ) is a simple and effective method for estimating the number of clusters and the initial locations of the cluster centers .", "label": "", "metadata": {}, "score": "40.33439"}
{"text": "AI - based techniques and their ensembles can help to address this important issue , but still only a small number of researchers have focused it so far .Most of the methods discussed in this paper have their roots in the ensemble learning process .", "label": "", "metadata": {}, "score": "40.42627"}
{"text": "Novel neural network model combining radial basisfunction , competitiveHebbianlearningrule , andfuzzysimplifiedadaptive resonance theory .In Proc SPIE , vol .3165 , ( pp .98 - 112 ) .Ben - Hur , A.,Horn , D.,Siegelmann , H.,&Vapnik , V.(2001 ) .", "label": "", "metadata": {}, "score": "40.445908"}
{"text": "In Pal and Chakraborty ( 2000 ) , the mountain and subtractive clustering methods are improved by tuningtheprototypesobtainedusingthegradient - descentmethod to maximize the potential function .By modifying the potential function , the mountain method can also be used to detect other types of clusters like circular shells ( Pal & Chakraborty , 2000 ) .", "label": "", "metadata": {}, "score": "40.474148"}
{"text": "P. Lanzi , \" Fast feature selection with genetic algorithms : a filter approach , \" in Proceedings of the IEEE International Conference on Evolutionary Computation , 1997 .T. L. B. Tseng and C. C Huang , \" Rough set - based approach to feature selection in customer relationship management , \" Omega , vol .", "label": "", "metadata": {}, "score": "40.482555"}
{"text": "21 , no . 1 , pp .45 - 56 , 2004 .View at Publisher \u00b7 View at Google Scholar .P. Geibel , U. Brefeld , and F. Wysotzki , \" Perceptron and SVM learning with generalized cost models , \" Intelligent Data Analysis , vol . 8 , no .", "label": "", "metadata": {}, "score": "40.550545"}
{"text": "Williamson , J. ( 1996 ) .Gaussian ARTMAP : A neural network for fast incremental learning of noisy multidimensional maps .Neural Networks , 9(5 ) , 881 - 897 .Wilpon , J. G. , & Rabiner , L. R. ( 1985 ) .", "label": "", "metadata": {}, "score": "40.56105"}
{"text": "As an example of application , we describe its use in the construction of decision trees as classifiers from training sets consisting of objects / situations , each of which is described by a feature vector , its class , and observed or measured cost for misclassification .", "label": "", "metadata": {}, "score": "40.57107"}
{"text": "405 - 410 , 1997 .S. B. Cho and J. H. Kim , \" Combining multiple neural networks by fuzzy integral for robust classification , \" IEEE Transactions on Systems , Man and Cybernetics , vol .25 , no . 2 , pp .", "label": "", "metadata": {}, "score": "40.60211"}
{"text": "IEEE Transactions on Neural Networks , 5(4 ) , 561 - 575 .Choy , C. S. T. , & Siu , W. C. ( 1998a ) .A class of competitive learning models which avoids neuron underutilization problem .IEEE Transactions on Neural Networks , 9(6 ) , 1258 - 1269 .", "label": "", "metadata": {}, "score": "40.611275"}
{"text": "Many researchers proposed use of population - based approaches to generate diverse set of classifiers .Although some promising results have been achieved by current AI - based ensembles to IDSs , there are still challenges that lie ahead for researchers in this area .", "label": "", "metadata": {}, "score": "40.620102"}
{"text": "T.K. Ho , \" Complexity of classification problems and comparative advantages of combined classifiers , \" Int .Workshop on Multiple Classifier Systems , lecture Notes on Computer Science , Vol .1857 , pp .97 - 106 , 2000 , Springer- Verlag . F. Roli , G. Giacinto , \" Design of Multiple Classifier Systems , \" in H. Bunke and A. Kandel ( Eds . )", "label": "", "metadata": {}, "score": "40.625694"}
{"text": "The optimal number of substructures in the data set can be effectively estimated by using some validity criteria such as spherical shell thickness ( Krishnapuram et al . , 1992 ) , fuzzy hypervolume and fuzzy density ( Gath & Geva , 1989 ; Man & Gath , 1994 ) .", "label": "", "metadata": {}, "score": "40.635834"}
{"text": "Here , each member is trained by different dataset .Ensemble output is determined by one classifier .In nutshell , fusion based combination methods combine all the outputs of the base classifiers , whereas selection based combination methods try to choose the best classifiers among the set of the available base classifiers .", "label": "", "metadata": {}, "score": "40.662163"}
{"text": "This may improve the numerical accuracy ( Kohonen , 1990 ) .The SOM ( Kohonen , 1989 ) is a clustering network with a set of heuristic procedures : it is not based on the minimization of any known objective function .", "label": "", "metadata": {}, "score": "40.67065"}
{"text": "725 - 730 ) .Kohonen , T. , Oja , E. , Simula , O. , Visa , A. , & Kangas , J. ( 1996 ) .Engineering applications of the self - organizing map .Proceedings of IEEE , 84(10 ) , 1358 - 1384 .", "label": "", "metadata": {}, "score": "40.74089"}
{"text": "Competitive learning and soft competition for vector quantizer design .IEEE Transactions on Signal Processing , 40(2 ) , 294 - 309 .Yang , M. S. ( 1993 ) .On a class of fuzzy classification maximum likelihood procedures .Fuzzy Sets and Systems , 57 , 365 - 375 .", "label": "", "metadata": {}, "score": "40.770943"}
{"text": "[ 27 ] studied the SVM , ANNs ( artificial neural networks ) , LGPs ( linear genetic programs ) , and MARSs ( Multivariate Adaptive Regression Splines ) for classification of KDD dataset into five classes .As these classifiers obtained better performance over the others to detect different classes of intrusion in terms of detection accuracy , attack severity , training & testing time ( scalability ) .", "label": "", "metadata": {}, "score": "40.7735"}
{"text": "A new clustering technique for function approximation .IEEE Transactions on Neural Networks , 13(1 ) , 132 - 142 .Grossberg , S. ( 1976 ) .Adaptive pattern classification and universal recording : I. Parallel development and coding of neural feature detectors ; II .", "label": "", "metadata": {}, "score": "40.786346"}
{"text": "Neural Networks , 9(7 ) , 1185 - 1197 .Frigui , H. , & Krishnapuram , R. ( 1999 ) .A robust competitive clustering algorithm with applications in computer vision .IEEE Transactions on Pattern Analysis and Machine Intelligence , 21(5 ) , 450 - 465 .", "label": "", "metadata": {}, "score": "40.786743"}
{"text": "A kernel - based subtractive clustering method .Pattern Recognition Letters , 26 , 879 - 891 .Kohonen , T. ( 1982 ) .Self - organized formation of topologically correct feature maps .Biological Cybernetics , 43 , 59 - 69 .", "label": "", "metadata": {}, "score": "40.845325"}
{"text": "10 , pp .993 - 1001 , 1990 .R. E. Schapire , \" The Strength of Weak Learnability , \" Machine Learning , vol .5 , no . 2 , pp .197 - 227 , 1990 .R. A. Jacobs , M. I. Jordan , S. J. Nowlan , and G. E. Hinton , \" Adaptive mixtures of local ex - perts , \" Neural Computation , vol .", "label": "", "metadata": {}, "score": "40.9713"}
{"text": "However , the practice of AI - based classifiers reveals that each of them has advantages and disadvantages for intrusion detection .Ensemble has the power to combine the strengths of these classifiers in such a way that their disadvantages will be compensated , thus offering better solutions .", "label": "", "metadata": {}, "score": "40.97514"}
{"text": "The growing cell structures ( GCS ) network ( Fritzke , 1994a ) can be viewed as a modification of the SOM by integrating node recruiting / pruning functions .It assigns each nodes with a local accumulated statistical variable called signal counter ui .", "label": "", "metadata": {}, "score": "41.00309"}
{"text": "They proposed different concepts to describe the improved performance , reduced generalization error , and successful applications of ensembles to different fields over individual classifier .For example , Allwein et al .[59 ] interpreted the improved performance in the framework of large margin classifiers , Kleinberg in the reference of Stochastic Discrimination theory [ 60 ] , and Breiman in the terms of the bias variance analysis [ 61 ] .", "label": "", "metadata": {}, "score": "41.041214"}
{"text": "Proceedings of IEE - D , 140(6 ) , 442 - 448 .Cheng , T. W. , Goldgof , D. B. , & Hall , L. O. ( 1998 ) .Fast fuzzy clustering .Fuzzy Sets and Systems , 93 , 49 - 56 .", "label": "", "metadata": {}, "score": "41.07731"}
{"text": "Strauss , C.E. , Wolpert , D.H. , Wolf , D.R. , \" Alpha , Evidence , and the Entropic Prior \" , in Maximum Entropy and Bayesian Methods 1992 , Ed . A. Mohammed - Djafari , Kluwer , 1994 .", "label": "", "metadata": {}, "score": "41.095654"}
{"text": "A literature review on various clustering techniques is first presented .To evaluate the proposed MFMM model , a performance comparison study using benchmark data sets pertaining to clustering problems is conducted .The results obtained are comparable with those reported in the literature .", "label": "", "metadata": {}, "score": "41.10533"}
{"text": "79 - 87 , 1991 .M. J. Jordan and R. A. Jacobs , \" Hierarchical mixtures of experts and the EM algorithm , \" Neural Computation , vol .6 , no . 2 , pp .181 - 214 , 1994 . D. H. Wolpert , \" Stacked generalization , \" Neural Networks , vol .", "label": "", "metadata": {}, "score": "41.10727"}
{"text": "The popular C4.5 decision tree is an example of statistical and data mining methods that do not normally use with binarization , yet produces high diagnostics accuracies with our proposed OVA diagnostic approach .The Data Set .The data set used in this empirical analysis was collected from a machine fault simulator ( MFS ) as shown in Figure 7 .", "label": "", "metadata": {}, "score": "41.12946"}
{"text": "34 , no .4 , pp .369 - 374 , 1998 .View at Google Scholar .G. Giacinto and F. Roli , \" Dynamic classifier fusion , \" in Proceedings of the Multiple Classifier Systems .First International Workshop ( MCS ' 00 ) , J. Kittler and F. Roli , Eds . , vol .", "label": "", "metadata": {}, "score": "41.146515"}
{"text": "34 , no .4 , pp .369 - 374 , 1998 .View at Google Scholar .G. Giacinto and F. Roli , \" Dynamic classifier fusion , \" in Proceedings of the Multiple Classifier Systems .First International Workshop ( MCS ' 00 ) , J. Kittler and F. Roli , Eds . , vol .", "label": "", "metadata": {}, "score": "41.146515"}
{"text": "We feel that it might be of general importance for information theory .On the other hand , decision trees have the advantage of being able to be broken up into a set of rules which can be interpreted in a human - like fashion .", "label": "", "metadata": {}, "score": "41.187218"}
{"text": "Luk , A. , & Lien , S. ( 1999 ) .Lotto - type competitive learning and its stability .In : Proc int joint conf neural netw , vol . 2 ( pp .1425 - 1428 ) .MacQueen , J.B. ( 1967 ) .", "label": "", "metadata": {}, "score": "41.191483"}
{"text": "418 - 435 , 1992 . E. Allwein , R. E. Schapire , and Y. Singer , \" Reducing Multiclass to Binary : A Unifying Approach for Margin Classifiers , \" Journal of Machine Learning Research , vol .1 , pp .", "label": "", "metadata": {}, "score": "41.19612"}
{"text": "The is the soft competitive learning .The FCL algorithms ( Chung & Lee , 1994 ) are a class of sequential algorithms obtained by fuzzifying competitive learning algorithms , such as the SCL and the FSCL .The enhanced sequential fuzzy clustering ( ESFC ) ( Zheng & Billings , 1999 ) is a modification to the FCL to better overcome the under - utilization problem .", "label": "", "metadata": {}, "score": "41.256264"}
{"text": "This paper is a study to propose ways of reducing the number of scenarios for data collection , on different combination of defect types , while maintaining or even improving the diagnostic performances .Two popular statistical and data mining methods , namely SVM and C4.5 , are used in this study .", "label": "", "metadata": {}, "score": "41.259403"}
{"text": "Neural Networks , 8(4 ) , 605 - 618 .Huntsberger , T. L. , & Ajjimarangsee , P. ( 1990 ) .Parallel self - organizing feature maps for unsupervised pattern recognition .International Journal of General Systems , 16 , 357 - 372 .", "label": "", "metadata": {}, "score": "41.309822"}
{"text": "For the experiments , an RBF kernel was utilized and we performed an extensive parameter optimization .We also took a cost - proportional resampling method into consideration , as described in [ 13 , 14 ] .The resampling method we developed consists of building a new , cost - free dataset based on the original dataset with costs ( see also [ 33 , 34 ] ) .", "label": "", "metadata": {}, "score": "41.46178"}
{"text": "These heterogeneous features can not be used all together to train a single classifier ( and even if they could - by converting all features into a vector of scalar values - such a training is unlikely to be successful ) .", "label": "", "metadata": {}, "score": "41.493973"}
{"text": "Strickert , M. , & Hammer , B. ( 2005 ) .Merge SOM for temporal data .Neurocomputa- tion , 64 , 39 - 71 .Su , M. C. , & Chou , C. H. ( 2001 ) .A modified version of the K - means algorithm with a distance based on cluster symmetry .", "label": "", "metadata": {}, "score": "41.507706"}
{"text": "IEEE Transactions on Neural Networks , 6 , 776 - 778 .Uykan , Z. , Guzelis , C. , Celebi , M. E. , & Koivo , H. N. ( 2000 ) .Analysis of input - output clustering for determining centers of RBFN .", "label": "", "metadata": {}, "score": "41.51799"}
{"text": "Such a set of classifiers is said to be diverse .Classifier diversity can be achieved in several ways .Preferably , the classifier outputs should be class - conditionally independent , or better yet negatively correlated .The most popular method is to use different training datasets to train individual classifiers .", "label": "", "metadata": {}, "score": "41.528225"}
{"text": "368 - 374 ) .Cambridge ( MA ) : MIT Press .Broomhead , D. S. , & Lowe , D. ( 1988 ) .Multivariable functional interpolation and adaptive networks .Complex Systems , 2 , 321 - 355 .", "label": "", "metadata": {}, "score": "41.554634"}
{"text": "Neural Networks , 3(3 ) , 277 - 290 .Al - Harbi , S. H. , & Rayward - Smith , V. J. ( 2006 ) .Adapting k - means for supervised clustering .Applied Intelligence , 24 , 219 - 226 .", "label": "", "metadata": {}, "score": "41.610798"}
{"text": "The algorithm processes a set of N2numerical relationships between the N data points , and agglomerates according to their similarity or distance .Agglomerative clustering is based on a local connectivity criterion .TheruntimeisO ?canbebasedonthecentroid(Zhang , Ramakrishnan,&Livny,1996 ) , all - points ( Zahn , 1971 ) , or scatter - points ( Guha et al . , 2001 ) rep- resentation .", "label": "", "metadata": {}, "score": "41.637154"}
{"text": "M. Kukar and I. Kononenko , \" Cost - sensitive learning with neural networks , \" in Proceedings of the 13th European Conference on Artificial Intelligence ( ECAI ' 98 ) , H. Prade , Ed . , pp .445 - 449 , John Wiley & Sons , Chichester , UK , 1998 .", "label": "", "metadata": {}, "score": "41.642746"}
{"text": "For each input x , its two closest prototypes are connected by an edge .An edge aging scheme is used to remove obsolete edges .Competitive Hebbian learning avoids the topological defects observed for the SOM .ART networks Adaptive resonance theory ( ART ) ( Grossberg , 1976 ) is biologi- cally motivated and is a major advance in the competitive learning paradigm .", "label": "", "metadata": {}, "score": "41.67195"}
{"text": "This article describes how the costs of misclassification given with the individual training objects for classification learning can be used in the construction of decision trees for minimal cost instead of minimal error class decisions .This is demonstrated by defining modified , cost - dependent probabilities , a new , cost - dependent information measure , and using a cost - sensitive extension of the CAL5 algorithm for learning decision trees .", "label": "", "metadata": {}, "score": "41.675438"}
{"text": "In this construction ( learning ) of decision trees , which can be viewed as sequential decoders of class symbols coded by feature vectors , the next attribute for branching has to be selected if no unique class decision is possible yet .", "label": "", "metadata": {}, "score": "41.72137"}
{"text": "However , all three approaches locally move the borders towards the classes that contain the examples that are less expensive to be misclassified .Conclusions .In this article we introduced a new , cost - dependent information measure and described how object - dependent costs can be used to learn decision trees ( decoders ) for cost optimal decisions instead of error minimal decisions .", "label": "", "metadata": {}, "score": "41.748653"}
{"text": "A popular cluster validity measure is defined as ( Davies & Bouldin , 1979 ; Du & Swamy , 2006 ) ?The best clustering minimizes EWBR .This index indicates good clustering results for sphericalclusters(Vesanto&Alhoniemi,2000 ) .Alternativecriteria for the cluster compactness , cluster separation , and overall cluster quality measures are given in He et al .", "label": "", "metadata": {}, "score": "41.77478"}
{"text": "IEEE Transactions on Pattern Analysis and Machine Intelligence , 16(8 ) , 855 - 861 .Mann , J. R. , & Gilbert , S. ( 1989 ) .An analog self - organizing neural network chip .In D. S. Touretzky ( Ed . ) , Advances in neural information processing systems : vol . 1 ( pp .", "label": "", "metadata": {}, "score": "41.77854"}
{"text": "The smaller subset of classifiers may be selected according to clustering [ 91 ] or by selecting the classifiers whose performance exceeds specific threshold values .However , in the general literature on classifier combination , it is observed that there is no evidence supporting the use of base classifiers of the same type or different types [ 33 , 46 ] .", "label": "", "metadata": {}, "score": "41.84248"}
{"text": "R. Anand , K. Mehrotra , C. K. Mohan , and S. Ranka , \" Efficient classification for multiclass problems using modular neural networks , \" IEEE Transactions on Neural Networks , vol .6 , no . 1 , pp .", "label": "", "metadata": {}, "score": "41.89853"}
{"text": "R. Anand , K. Mehrotra , C. K. Mohan , and S. Ranka , \" Efficient classification for multiclass problems using modular neural networks , \" IEEE Transactions on Neural Networks , vol .6 , no . 1 , pp .", "label": "", "metadata": {}, "score": "41.89853"}
{"text": "119 - 139 , 1997 .J. Kittler , M. Hatef , R. P. W. Duin , and J. Mates , \" On combining classifiers , \" IEEE Trans . on Pattern Analysis and Machine Intelligence , vol .20 , no . 3 , pp .", "label": "", "metadata": {}, "score": "41.939903"}
{"text": "Lateral connections are generated by the competitive Hebbian learning rule .The GNG achieves robustness against noise and performs perfect topology - preserving mapping .The GNG with utility criterion ( GNG - U ) ( Fritzke , 1997a ) integrates an on - line cri- terion to identify and delete useless neurons , and can thus track nonstationary data input .", "label": "", "metadata": {}, "score": "41.94181"}
{"text": "In Staiano , Tagliaferri , and Pedrycz ( 2006 ) , a prototype regression function is built as a linear combi- nation of local linear regression models , one for each cluster , and is then inserted into the FCM .Thus , the prototypes are adjusted ac- cording to both the input distribution and the regression function in the output space . xT", "label": "", "metadata": {}, "score": "42.00647"}
{"text": "Carpenter , G. A. , & Grossberg , S. ( 1987a ) .A massively parallel architecture for a self - organizing neural pattern recognition machine .Computer Vision , Graphics , Image Processing , 37 , 54 - 115 .Carpenter , G. A. , & Grossberg , S. ( 1987b ) .", "label": "", "metadata": {}, "score": "42.01041"}
{"text": "They found that these multistrategy techniques , particularly the belief function , performed better than all three neural nets individually .The overall performance was also comparable to or better than a single neural net trained on the entire feature set ; however , the single neural net did a better job identifying previously unseen attacks .", "label": "", "metadata": {}, "score": "42.02278"}
{"text": "In Proc int conf artif neural netw ( ICANN ) ( pp .427 - 434 ) .Martinetz , T. M. , Berkovich , S. G. , & Schulten , K. J. ( 1993 ) .Neural - gas network for vector quantization and its application to time - series predictions .", "label": "", "metadata": {}, "score": "42.02762"}
{"text": "The fuzzy inference module implements nonlinear mappings from the outputs of the neurofuzzy classifiers of the pervious layer to the final output space which specifies if the input data are normal or intrusive .The genetic algorithm is used to optimize the structure of neurofuzzy engine .", "label": "", "metadata": {}, "score": "42.03547"}
{"text": "When a new input pattern x is presented to the map , the map gives the corresponding output c based on the nearest- neighborhood rule .Clustering is a fundamental data analysis method , and is widely used for pattern recognition , feature extrac- tion , VQ , image segmentation , and data mining .", "label": "", "metadata": {}, "score": "42.03855"}
{"text": "This can be done by using ( 1 ) different initialization parameters of base classifiers ; or ( 2 ) different subsets of feature space ( feature level ) ; or ( 3 ) different data subsets ( data level ) to train the base classifiers .", "label": "", "metadata": {}, "score": "42.044006"}
{"text": "J. R. Quinlan , C4.5 : Programs for Machine Learning , Morgan Kaufmann , San Mateo , Calif , USA , 1993 .L. Breiman , J. H. Friedman , R. A. Olshen , and C. J. Stone , Classification and Regression Trees , Wadsworth and Brooks , Monterey , Calif , USA , 1984 .", "label": "", "metadata": {}, "score": "42.046688"}
{"text": "The prespecified standard grid topology may not be able to match the structure of the distribution , leading to poor topological mappings .\u03b7k(t ) 1 + hwk\u03b7k(t ) .Extensions of the self - organizing Map Adaptive subspace SOM ( ASSOM ) ( Kohonen , 1996 , 1997 ; Koho- nen , Oja , Simula , Visa , & Kangas , 1996 ) is a modular neural net- work model comprising an array of topologically ordered SOM submodels .", "label": "", "metadata": {}, "score": "42.05563"}
{"text": "349 - 358 , Cambridge , UK , 2001 .M. Sewell , \" Ensemble Learning , \" Research Note RN/11/02 , UCL department of computer science , 2011 . E. Mayoraz and M. Moreira , \" On the decomposition of polychotomies into dichotomies , \" in Proceedings of the XIV International Conference on Machine Learning , pp .", "label": "", "metadata": {}, "score": "42.059196"}
{"text": "349 - 358 , Cambridge , UK , 2001 .M. Sewell , \" Ensemble Learning , \" Research Note RN/11/02 , UCL department of computer science , 2011 . E. Mayoraz and M. Moreira , \" On the decomposition of polychotomies into dichotomies , \" in Proceedings of the XIV International Conference on Machine Learning , pp .", "label": "", "metadata": {}, "score": "42.059196"}
{"text": "3 ( pp .1404 - 1407 ) .Gath , I. , & Geva , A. B. ( 1989 ) .Unsupervised optimal fuzzy clustering .IEEE Transactions on Pattern Analysis and Machine Intelligence , 11(7 ) , 773 - 781 .", "label": "", "metadata": {}, "score": "42.074287"}
{"text": "IEEE Transactions on Neural Networks , 8(3 ) , 505 - 518 .Karayiannis , N. B. ( 1999 ) .An axiomatic approach to soft learning vector quantization and clustering .IEEE Transactions on Neural Networks , 10(5 ) , 1153 - 1165 .", "label": "", "metadata": {}, "score": "42.092583"}
{"text": "In other words , a total of 18 features from the vibration data are used .Three classification algorithms , namely SVM , C4.5 and naive Bayes are applied with the proposed procedure and the results of the best performing method is reported below .", "label": "", "metadata": {}, "score": "42.154293"}
{"text": "The method al- ways converges to an optimal or near - optimum configuration .The enhanced LBG ( Patane & Russo , 2001 ) avoids bad local minima by incorporationoftheconceptofutilityofacodeword .Theenhanced LBGoutperformstheLBGwithutility(LBG - U)(Fritzke,1997b)both in terms of accuracy and the number of required iterations .", "label": "", "metadata": {}, "score": "42.158546"}
{"text": "Supervised clustering can be implemented by augmenting the input pattern with its output pattern , ?Bezdek , 1999 ; Uykan , Guzelis , Celebi , & Koivo , 2000 ) .A scaling factor \u03b2 is introduced to balance between the similarities in the input and output spaces ?", "label": "", "metadata": {}, "score": "42.16889"}
{"text": "McLachlan , G. , & Basford , K. ( 1988 ) .Mixture models : Inference and application to clustering .New York : Marcel Dekker .Moody , J. , & Darken , C. J. ( 1989 ) .Fast learning in networks of locally - tuned processing units .", "label": "", "metadata": {}, "score": "42.170525"}
{"text": "They used fuzzy clustering technique to generate different homogeneous training subsets from heterogeneous training set , which are further used to ANN models as base models .Finally , a metalearner , fuzzy aggregation module , was employed to aggregate these results .", "label": "", "metadata": {}, "score": "42.17486"}
{"text": "The Kohonen network is closely related to the C- means clustering ( Lippman , 1987 ) .There are some proofs for the convergence of the one - dimensional SOM based on the Markov chain analysis ( Flanagan , 1996 ) , but no general proof of conver- gence for multi - dimensional SOM is available ( Flanagan , 1996 ; Ko- honen , 1997 ) .", "label": "", "metadata": {}, "score": "42.192467"}
{"text": "For qualitative variables , the SOM has been generalized for multiple correspondence analy- sis ( Cottrell , Ibbou , & Letremy , 2004 ) .The SOM is designed for real - valued vectorial data analysis , and it is not suitable for non - vectorial data analysis such as the structured data analysis .", "label": "", "metadata": {}, "score": "42.200855"}
{"text": "Su , M.C.,&Liu , Y.C.(2005 ) .Anewapproachtoclusteringdatawitharbitraryshapes .Pattern Recognition , 38 , 1887 - 1901 .Sum , J. P. F. , Leung , C. S. , Tam , P. K. S. , Young , G. H. , Kan , W. K. , & Chan , L. W. ( 1999 ) .", "label": "", "metadata": {}, "score": "42.289314"}
{"text": "Fast sequential implementation of neural - gas network for vector quantization .IEEE Transactions on Communications , 46(3 ) , 301 - 304 .Chua , L. O. , & Yang , L. ( 1988 ) .Cellular neural network - Part I : Theory ; Part II : Applications .", "label": "", "metadata": {}, "score": "42.40274"}
{"text": "In contrast to the experiments with an extended Matlab implementation of the 2-norm SVM described in [ 14 ] , we used the SVMLight [ 32 ] here .This particular implementation of a 1-norm SVM allows the use of individual costs as example weights given as real values .", "label": "", "metadata": {}, "score": "42.412586"}
{"text": "L. I. Kuncheva , J. C. Bezdek , and R. Duin , \" Decision templates for multiple classifier fu - sion : an experimental comparison , \" Pattern Recognition , vol .34 , no . 2 , pp .299 - 314 , 2001 .", "label": "", "metadata": {}, "score": "42.428658"}
{"text": "Kruegel et al .[109 ] proposed a multimodel approach that uses a number of different anomaly detection techniques ( Bayesian technique ) to detect attacks against web servers and web - based applications .The multimodels help to reduce the vulnerability of the detection process with respect to mimicry attacks .", "label": "", "metadata": {}, "score": "42.452095"}
{"text": "113 - 141 , 2001 .View at Google Scholar \u00b7 View at Scopus . A. Sharkey , \" Types of multi - ney systems , \" in Multiple Classifier Systems , Third International Workshop ( MCS ' 02 ) , F. Roli and J. Kittler , Eds . , vol .", "label": "", "metadata": {}, "score": "42.467983"}
{"text": "113 - 141 , 2001 .View at Google Scholar \u00b7 View at Scopus . A. Sharkey , \" Types of multi - ney systems , \" in Multiple Classifier Systems , Third International Workshop ( MCS ' 02 ) , F. Roli and J. Kittler , Eds . , vol .", "label": "", "metadata": {}, "score": "42.467983"}
{"text": "They reported the better performance of proposed hybrid approach over single Na\u00efve Bayes classifier over KDD 1999 dataset .But the proposed method suffers from limitation that it is unable to detect similar attacks like U2R and R2L. Here , architecture of system can be parallel , cascading , or hierarchical [ 35 ] , the classifiers can be combined by ensemble- or hybrid - combining approach .", "label": "", "metadata": {}, "score": "42.469032"}
{"text": "L. I. Kuncheva , \" A theoretical study on six classifier fusion strategies , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .24 , no . 2 , pp .281 - 286 , 2002 .S. B. Cho and J. H. Kim , \" Multiple network fusion using fuzzy logic , \" IEEE Transactions on Neural Networks , vol .", "label": "", "metadata": {}, "score": "42.47753"}
{"text": "A cluster estimation method with extension to fuzzy model identification .In Proc IEEE int conf fuzzy syst , vol .2 , ( pp .1240 - 1245 ) .Choi , D. I. , & Park , S. H. ( 1994 ) .", "label": "", "metadata": {}, "score": "42.488228"}
{"text": "This advantage comes at the price of a higher computational effort .In serial implementation , the complexity for the NG is O(KlogK ) while the other three methods all have a complexity of O(K ) .Nevertheless , in parallel implementation all the four algorithms have a complexity of O(logK ) ( Martinetz et al . , 1993 ) .", "label": "", "metadata": {}, "score": "42.572838"}
{"text": "Chung , F. L. , & Lee , T. ( 1994 ) .Fuzzy competitive learning .Neural Networks , 7(3 ) , 539 - 551 .Corchado , J.,&Fyfe , C.(2000 ) .Acomparisonofkernelmethodsforinstantiatingcase based reasoning systems .Computing and Information Systems , 7 , 29 - 42 .", "label": "", "metadata": {}, "score": "42.62139"}
{"text": "IEEE Transactions on Pattern Analysis and Machine Intelligence , 24(7 ) , 881 - 892 .Kasuba , T. ( 1993 ) .Simplified fuzzy ARTMAP .AI Expert , 8(11 ) , 18 - 25 .Karayiannis , N. B. ( 1997 ) .", "label": "", "metadata": {}, "score": "42.660507"}
{"text": "Processing of high - dimensional data for ID is highly computationally expensive .This cause may lose real - time capability of IDS .The computation overhead may be reduced by applying feature reduction techniques , which can be further explored in [ 15 , 16 ] .", "label": "", "metadata": {}, "score": "42.668373"}
{"text": "Some strategies can be applied to combat this prob- lem ( Guha et al . , 2001 ; Vesanto & Alhoniemi , 2000 ; Wang & Rau , 2001 ; Zhang et al ., 1996 ) .N2 ?Dendrogramisusedtoillustratetheclusters produced by agglomerative clustering .", "label": "", "metadata": {}, "score": "42.673763"}
{"text": "P. Turney , \" Cost - sensitive classification : empirical evaluation of a hybrid genetic decision tree induction algorithm , \" Journal of Artificial Intelligence Research , vol .2 , no . 1 , pp .369 - 409 , 1994 .", "label": "", "metadata": {}, "score": "42.729836"}
{"text": "Statistical features are extracted from the time domain and the frequency domain .Prediction performance of the proposed strategy is compared with that of a simple multi - class classification , as well as that of random guess and worst - case classification .", "label": "", "metadata": {}, "score": "42.7414"}
{"text": "Experiments with two artificial datasets and one example of application show the feasibility of our approach and that it is more adequate than a method that uses cost matrices given by experts if cost - dependent training objects are available .Since decision trees constructed with CAL5_OC also separate the classes in the feature space by axis - parallel hyperplanes , it can be used to attain symbolic representations of classes and rules depending on and ordered by their importance .", "label": "", "metadata": {}, "score": "42.767185"}
{"text": "J. Friedman and P. Hall , \" On bagging and nonlinear estimation , \" Tech .Rep. , Statistics Department , University of Stanford , Palo Alto , Calif , USA , 2000 .View at Google Scholar .L. I. Kuncheva , F. Roli , G. L. Marcialis , and C. A. Shipp , \" Complexity of data subsets generated by the random subspace method : an experimental investigation , \" in Multiple Classi_er Systems .", "label": "", "metadata": {}, "score": "42.777073"}
{"text": "J. Friedman and P. Hall , \" On bagging and nonlinear estimation , \" Tech .Rep. , Statistics Department , University of Stanford , Palo Alto , Calif , USA , 2000 .View at Google Scholar .L. I. Kuncheva , F. Roli , G. L. Marcialis , and C. A. Shipp , \" Complexity of data subsets generated by the random subspace method : an experimental investigation , \" in Multiple Classi_er Systems .", "label": "", "metadata": {}, "score": "42.777073"}
{"text": "This is shown to be a cost - dependent generalization of the classical information measure introduced by Shannon , which only depends on classical probabilities .It is therefore of general importance and extends classic information theory , knowledge processing , and cognitive science , since subjective evaluations of decision alternatives can be included in entropy and the transferred information .", "label": "", "metadata": {}, "score": "42.804337"}
{"text": "C. X. Ling , Q. Yang , J. N. Wang , and S. C. Zhang , \" Decision trees with minimal costs , \" in Proceedings of the 21stInternational Conference on Machine learning , 2004 .N. Lavrac , D. Gamberger , and P. Turney , \" Cost - sensitive feature reduction applied to a hybrid genetic algorithm , \" in Proceedings of the 7th International Workshop on Algorithmic Learning Theory ( ALT ' 96 ) , 1996 .", "label": "", "metadata": {}, "score": "42.824226"}
{"text": "C5.0 is another enhancement of C4.5 with additional effectiveness , efficiencies and supports boosting .However , the C4.5 and C5.0 decision tree algorithms produce models with similar predictive accuracies [ 57 ] .While C4.5 decision trees naturally handle multiple classes , they can only examine a single feature at a time and do not perform well when the features are highly interdependent .", "label": "", "metadata": {}, "score": "42.84536"}
{"text": "24 , no . 2 , pp .123 - 140 , 1996 .Y. Freund and R. E. Schapire , \" Decision - theoretic generalization of on - line learning and an application to boosting , \" Journal of Computer and System Sciences , vol .", "label": "", "metadata": {}, "score": "42.852066"}
{"text": "Neural networks and physical systems with emergent collectivecomputationalabilities .ProceedingsoftheNationalAcademyofScience , 79 , 2554 - 2558 .Huber , P. J. ( 1981 ) .Robust statistics .New York : Wiley .Hung , C. , & Lin , S. ( 1995 ) .", "label": "", "metadata": {}, "score": "42.878662"}
{"text": "Classification , the most familiar and most popular data mining task , is a mapping from the database to the set of predefined , non - overlapping classes that partition the entire database .SVM is a kernel method which builds a model by constructing a hyperplane that best separates two classes .", "label": "", "metadata": {}, "score": "42.892265"}
{"text": "Page 11 .K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 99 12.1 .Noise clustering In the noise clustering approach ( Dave , 1991 ) , all outliers are collected into a separate , amorphous noise cluster , whose prototype has the same distance \u03b4 from all the data points , while all the other points are collected into K clusters .", "label": "", "metadata": {}, "score": "42.929306"}
{"text": "Neuro - fuzzy systems and rough sets are ideal tools for knowledge representation .Data mining needs first to discover the structural features in a database , and exploratory techniques through self - organization such as clustering are particularly promising .Some of the data mining approaches that use clustering are database segmentation , predictive modeling , and visualization of large databases ( Jain et al . , 1999 ) .", "label": "", "metadata": {}, "score": "42.9545"}
{"text": "The DBSCAN ( Ester , Kriegel , Sander , & Xu , 1996 ) is a widely known density based clustering algorithm .In the DBSCAN , a re- gion is defined as the set of points that lie in the ?", "label": "", "metadata": {}, "score": "42.985916"}
{"text": "Nor an improvement on the ensemble 's average performance can be guaranteed except for certain special cases ( Fumera 2005 ) .Hence combining classifiers may not necessarily beat the performance of the best classifier in the ensemble , but it certainly reduces the overall risk of making a particularly poor selection .", "label": "", "metadata": {}, "score": "43.06611"}
{"text": "Other reasons for combining different classifiers include [ 26 ] the following .( 1 ) a designer may have access to a number of different classifiers , each developed in a different context and for an entirely different representation / description of the same problem .", "label": "", "metadata": {}, "score": "43.102623"}
{"text": "Fuzzy Sets and Systems , 150(2 ) , 245 - 266 .Tsypkin , Y. Z. ( 1973 ) .Foundations of the theory of learning .New York : Academic .Urahama , K. , & Nagao , T. ( 1995 ) .", "label": "", "metadata": {}, "score": "43.15452"}
{"text": "[40 ] suggested a hybrid of SVM and clustering to cut down the training time .A hierarchical clustering algorithm is engaged to establish boundary points in the data that best separate the two classes .These boundary points are used to train the SVM .", "label": "", "metadata": {}, "score": "43.172245"}
{"text": "Thus , for small- or In Kim , Lee , Lee , and Lee ( 2005 ) , a kernel - induced distance is used to replace the Euclidean distance in the potential function .This enables to cluster the data that is linearly inseparable in the orig- inal space into homogeneous groups in the transformed high- dimensional space , where the data separability is increased .", "label": "", "metadata": {}, "score": "43.2196"}
{"text": "In supervised learning - based classification , ensembles have been successfully employed to different application domains .In the literature , many researchers have proposed different ensembles by considering different combination methods , training datasets , base classifiers , and many other factors .", "label": "", "metadata": {}, "score": "43.225513"}
{"text": "Moreover , hierarchical clustering is static , and points committed to a given cluster can not move to a different cluster .Hierarchical clustering has a typical complexity of O ? procedure , but is computationally more expensive ( Xu & Wunsch II , 2005 ) .", "label": "", "metadata": {}, "score": "43.251976"}
{"text": "Learn + + primarily for incremental learning problems that do not introduce new classes ( Polikar2001 ) , and Learn + + .NC for those that introduce new classes with additional datasets ( Muhlbaier 2008 ) are two examples of ensemble based incremental learning algorithms .", "label": "", "metadata": {}, "score": "43.266624"}
{"text": "However , it uses a large storage space , and has a computational complexity of O ? as the competitive learning network .The unsupervised LVQ is essentially the SCL based VQ .There are two families of the LVQ- stylemodels , supervisedmodelssuchastheLVQ1,thLVQ2,andthe LVQ3 ( Kohonen , 1989 ) as well as unsupervised models such as the LVQ ( Kohonen , 1989 ) and the incremental C - means ( MacQueen , 1967 ) .", "label": "", "metadata": {}, "score": "43.317978"}
{"text": "Syst .Signal Process .[ Google Scholar ] .F\u00fcrnkranz , J. Round robin classification .J. Mach .Learn .Res .[ Google Scholar ] .Lorena , A.C. ; de Carvalho , A.C. ; Gama , J.M. A review on the combination of binary classifiers in multiclass problems .", "label": "", "metadata": {}, "score": "43.365463"}
{"text": "Various classification techniques ( classifiers ) from different disciplines have been applied to detect the intrusions efficiently .Examples of these techniques include statistical techniques , artificial - intelligence- ( AI- ) based techniques , and its subfield techniques [ 5 , 19 , 20 ] .", "label": "", "metadata": {}, "score": "43.368515"}
{"text": "Kohonen network and learning vector quantization based fuzzy clustering The fuzzy SOM ( Huntsberger & Ajjimarangsee , 1990 ) modifies the SOM by replacing the learning rate with fuzzy membership .Page 9 .K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 97 of the nodes in each class .", "label": "", "metadata": {}, "score": "43.40693"}
{"text": "Neural Networks , 8(5 ) , 729 - 743 .Bezdek , J. C. , & Pal , N. R. ( 1998 ) .Some new indexes or cluster validity .IEEE Transactions on Systems Man and Cybernetics , 28(3 ) , 301 - 303 .", "label": "", "metadata": {}, "score": "43.44874"}
{"text": "46 , no . 1 - 3 , pp .191 - 202 , 2002 .View at Google Scholar . A. Lenarcik and Z. Piasta , \" Rough classifiers sensitive to costs varying from object to object , \" in Proceedings of the 1st", "label": "", "metadata": {}, "score": "43.458904"}
{"text": "Biological Cybernetics , 23 , 121 - 134 .Grossberg , S. ( 1987 ) .Competitive learning : From iterative activation to adaptive resonance .Cognitive Science , 11 , 23 - 63 .Guha , S. , Rastogi , R. , & Shim , K. ( 2001 ) .", "label": "", "metadata": {}, "score": "43.479218"}
{"text": "If there was a conflict then the decision given by the classifier with the highest weight is taken into account .They showed that the performance of the proposed method is superior to that of single usage of base classification methods .", "label": "", "metadata": {}, "score": "43.487133"}
{"text": "Stacked Generalization .In Wolpert 's stacked generalization ( or stacking ) , an ensemble of classifiers is first trained using bootstrapped samples of the training data , creating Tier 1 classifiers , whose outputs are then used to train a Tier 2 classifier ( meta - classifier ) ( Wolpert 1992 ) .", "label": "", "metadata": {}, "score": "43.61624"}
{"text": "Further details can be studied in [ 4 , 5 ] .Since the first introduction , IDSs have been evaluated using a number of different ways based upon evaluation datasets [ 6 ] .Various features of IDS can be evaluated , which may range from performance and correctness to usability .", "label": "", "metadata": {}, "score": "43.63928"}
{"text": "However , the order of the training patterns may influ- ence the final prototypes and clusters .Unlike the SOM ( Kohonen , 1982 ) , the Hopfield network ( Hopfield , 1982 ) , and the neocogni- tron ( Fukushima , 1980 ) , the ART 1 can deal with arbitrary com- binations of binary input patterns .", "label": "", "metadata": {}, "score": "43.64957"}
{"text": "IEEE Transactions on Neural Networks , 4(2 ) , 549 - 557 .Pal , N. R. , & Chakraborty , D. ( 2000 ) .Mountain and subtractive clustering method : Improvements and generalizations .International Journal of Intelligent Systems , 15 , 329 - 341 .", "label": "", "metadata": {}, "score": "43.655712"}
{"text": "The decisions made by each classifier can then be combined by any of the combination rules described below .Confidence Estimation .The very structure of an ensemble based system naturally allows assigning a confidence to the decision made by such a system .", "label": "", "metadata": {}, "score": "43.670746"}
{"text": "Learning internal representations by error propagation .In D. E. Rumelhart , & J. L. McClelland ( Eds . ) , Parallel distributed processing : Explorations in the microstructure of cognition , 1 : Foundation ( pp .318 - 362 ) .", "label": "", "metadata": {}, "score": "43.673832"}
{"text": "The approach is based on the motivation that human experts use different feature sets to detect different kinds of attacks .They generated different neural network - based classifiers by training them using different feature subsets of KDD cup 99 dataset , namely , intrinsic , content , and traffic features .", "label": "", "metadata": {}, "score": "43.691784"}
{"text": "The influence of measurement noise , the network models adopted , and the data preprocessing methods on damage identification is also discussed in the paper .The results show that the proposed model not only has good damage detection capability and noise tolerance , but also significantly reduces the data storage requirement and saves computing time .", "label": "", "metadata": {}, "score": "43.694427"}
{"text": "4 , pp .231 - 247 , 1994 .View at Publisher \u00b7 View at Google Scholar .View at Google Scholar .C. E. Shannon and W. Weaver , The Mathematical Theory of Communication , University of Illinois Press , Urbana , Ill , USA , 1949 . F. Wysotzki , W. M\u00fcller , and B. Schulmeister , \" Automatic construction of decision trees and neural nets for classification using statistical considerations , \" in Learning , Networks and Statistics , G. Della Riccia , H.-J. Lenz , and R. Kruse , Eds . , CISM Courses and Lectures no .", "label": "", "metadata": {}, "score": "43.718643"}
{"text": "But , computations of multiple predictions in ensembles increase computational overhead .Many researchers and practitioners advocate ensemble classifiers by keeping following points in mind .( 1 )The availability of enormous computational power ( to cope up computational overhead of ensemble classifiers ) ; ( 2 ) lack of quality training data for realistic evaluation ; ( 3 ) improved performance ( over single classifier ) of ensembles .", "label": "", "metadata": {}, "score": "43.726105"}
{"text": "Krishnapuram , R. , & Keller , J. M. ( 1993 ) .A possibilistic approach to clustering .IEEE Transactions on Fuzzy Systems , 1(2 ) , 98 - 110 .Krishnapuram , R. , & Kim , J. ( 2000 ) .", "label": "", "metadata": {}, "score": "43.745426"}
{"text": "Supervised training technique for radial basis function neural networks .Electronics Letters , 34(11 ) , 1115 - 1116 .Buckley , J. J. , & Eslami , E. ( 2002 ) .An introduction to fuzzy logic and fuzzy sets .", "label": "", "metadata": {}, "score": "43.772064"}
{"text": "The complexity of the CURE is not worse than that of centroid based hierarchical algorithms .The CURE provides a better performance with less execution time compared to the BIRCH ( Guha et al . , 2001 ) .It can discover clusters withinterestingshapesandislesssensitivetotheoutliersthanthe MST .", "label": "", "metadata": {}, "score": "43.778557"}
{"text": "The lotto type competitive learning ( LTCL ) ( Luk & Lien , 1998 ) can be treated as a generalization of the RPCL , where instead of just penalizing the nearest rival , all the losers are penalized equally .The generalized LTCL ( Luk & Lien , 1999 ) modifies the LTCL by allowing more than one winner , which are divided into tiers , with each tier being rewarded differently .", "label": "", "metadata": {}, "score": "43.785744"}
{"text": "\" It has better convergence properties as compare to k - means algorithm .The FCM needs to store U and all ci 's and the alternating estimation of U and ci 's causes a computational and storage burden for largescale data sets [ 23].", "label": "", "metadata": {}, "score": "43.795795"}
{"text": "Boosting was the predecessor of the AdaBoost family of algorithms - which arguably became one of the most popular machine learning algorithms in recent times .Since these seminal works , research in ensemble systems have expanded rapidly , appearing often in the literature under many creative names and ideas .", "label": "", "metadata": {}, "score": "43.85405"}
{"text": "M. Y. Su , K. C. Chang , H. F. Wei , and C. Y. Lin , \" Feature weighting and selection for a real - time network intrusion detection system based on GA with KNN , \" Intelligence and Security Informatics , vol .", "label": "", "metadata": {}, "score": "43.861042"}
{"text": "M. Y. Su , K. C. Chang , H. F. Wei , and C. Y. Lin , \" Feature weighting and selection for a real - time network intrusion detection system based on GA with KNN , \" Intelligence and Security Informatics , vol .", "label": "", "metadata": {}, "score": "43.861042"}
{"text": "They utilized multiple classifiers and tried to exploit their strengths .They used C4.5 decision tree [ 114 ] , Na\u00efve Bayes [ 115 ] , k - NN clustering [ 116 ] , VFI - voting feature intervals [ 34 ] , and OneR [ 117 ] classifiers as base classifiers over five malware datasets .", "label": "", "metadata": {}, "score": "43.86228"}
{"text": "Bandyopadhyay , S. , & Maulik , U. ( 2002 ) .An evolutionary technique based on k- means algorithm for optimal clustering .Information Sciences , 146 , 221 - 237 .Baraldi , A. , & Blonda , P. ( 1999 ) .", "label": "", "metadata": {}, "score": "43.872864"}
{"text": "Some of these combination rules operate on class labels only , whereas others need continuous outputs that can be interpreted as support given by the classifier to each of the classes .Xu et al ( Xu 1992 ) .defines three types of base model outputs to be used for classifier combination .", "label": "", "metadata": {}, "score": "43.925095"}
{"text": "N. C. Oza and K. Tumer , \" Input Decimation Ensembles : Decorrelation through Dimensio - nality Reduction , \" 2nd Int .Workshop on Multiple Classifier Systems , in Lecture Notes in Computer Science , J. Kittler and F. Roli , Eds . , vol .", "label": "", "metadata": {}, "score": "43.94471"}
{"text": "160 - 171 , Berlin , Germany , 1998 .T. G. Dietterich and G. Bakiri , \" Error - correcting output codes : a general method for improving multiclass inductive learning programs , \" in Proceedings of the 9th AAAI National Conference on Artificial Intelligence , pp .", "label": "", "metadata": {}, "score": "44.022507"}
{"text": "160 - 171 , Berlin , Germany , 1998 .T. G. Dietterich and G. Bakiri , \" Error - correcting output codes : a general method for improving multiclass inductive learning programs , \" in Proceedings of the 9th AAAI National Conference on Artificial Intelligence , pp .", "label": "", "metadata": {}, "score": "44.022507"}
{"text": "151 - 156 )Also : Neural Netw 4 : 493 - 504 .Carpenter , G. A. , Grossberg , S. , & Reynolds , J. H. ( 1991 ) .ARTMAP : Supervised real- time learning and classification of nonstationary data by a self - organizing neural network .", "label": "", "metadata": {}, "score": "44.026184"}
{"text": "Preliminaries of fuzzy sets and logic are given in Buckley and Eslami ( 2002 ) and Du and Swamy ( 2006 ) .Fuzzy C - means clustering ThediscretenessofeachclustermakestheC - meansanalytically and algorithmically intractable .Partitioning the dataset in a fuzzy manner avoids this problem .", "label": "", "metadata": {}, "score": "44.04997"}
{"text": "Khreich et al .[ 2 ] proposed an iterative Boolean combination ( IBC ) technique for efficient fusion of the responses from any crisp or soft detector trained on fixed - size datasets in the ROC space .The proposed technique applies all Boolean functions to combine the ROC curves corresponding to multiple classifiers .", "label": "", "metadata": {}, "score": "44.118656"}
{"text": "653 - 662 , 1987 .View at Google Scholar \u00b7 View at MathSciNet .Z. Pawlak , Rough Sets : Theoretical Aspects of Reasoning about Data , Kluwer Academic , Boston , Mass , USA , 1991 .M. Dash and H. Liu , \" Feature selection for classification , \" Intelligent Data Analysis , vol .", "label": "", "metadata": {}, "score": "44.148483"}
{"text": "A data point surrounded by many neighboring 4 r2 a , rabeing a normalized radius defining .Page 5 .K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 93 data points has a high potential value .Thus , the mountain and subtractive clustering techniques are less sensitive to noise than other clustering algorithms , such as the C - means and the fuzzy C- means ( FCM ) ( Bezdek , 1981 ) .", "label": "", "metadata": {}, "score": "44.234932"}
{"text": "By taking the best immediate , or local , solution in finding an answer , the algorithm selects an attribute to split on at any given node with any given data set , decides whether to stop branching and what branches to form .", "label": "", "metadata": {}, "score": "44.256428"}
{"text": "Feature selection .As mentioned earlier in this article , one way to improve diversity in the ensemble is to train individual classifiers different subsets of the available features .Selecting the feature subsets at random is known as the random subspace method , a term coined by ( Ho 1998 ) , who used it on constructing decision tree ensembles .", "label": "", "metadata": {}, "score": "44.289642"}
{"text": "P. Geibel , Risk - Sensitive Approaches for Reinforcement Learning , Shaker , 2006 .L. Li , V. Bulitko , and R. Greiner , \" Batch reinforcement learning with state importance , \" in Proceedings of the European Conference on Machine Learning ( ECML ' 04 ) , pp .", "label": "", "metadata": {}, "score": "44.29033"}
{"text": "Data mining , first appeared as knowledge discovery in databases [ 15 ] , and emerged from a diverse background of databases , statistics and machine learning [ 16 , 17 ] .Another related research field is pattern recognition , emerged from engineering disciplines , which can be viewed as another facet of the same field as machine learning , emerged from computer science [ 18 ] .", "label": "", "metadata": {}, "score": "44.3145"}
{"text": "181 , pp .4928 - 4942 , 2011 .View at Google Scholar .R. Susmaga , \" Computation of minimal cost reducts , \" in Foundations of Intelligent Systems , Z. Ras and A. Skowron , Eds . , vol .", "label": "", "metadata": {}, "score": "44.37645"}
{"text": "They claimed 94.71 % detection accuracy with 3.8 % of false alarm rate of old as well as new attacks .Chen et al .[ 41 ] suggested a hybrid flexible neural - tree - based IDS based on flexible neural tree , evolutionary algorithm , and particle swarm optimization ( PSO ) .", "label": "", "metadata": {}, "score": "44.45062"}
{"text": "The FCM has been generalized by introducing the generalized Boltzmann distributiontoescapelocalminima(Richardt , Karl,&Muller,1998 ) .Existing global optimization techniques can be incorporated into the FCM to provide globally optimum solutions .The \u03b5 - insensitive FCM ( \u03b5FCM ) is an extension to the FCM by introducing the robust statistics using Vapnik 's \u03b5 - insensitive estimator to reduce the effect of outliers ( Leski , 2003a ) .", "label": "", "metadata": {}, "score": "44.488823"}
{"text": "4 , pp .365 - 383 , 2007 .View at Google Scholar .N. Zhong , J. Z. Dong , and S. Ohsuga , \" Using rough sets with heuristics to feature selection , \" Journal of Intelligent Information Systems , vol .", "label": "", "metadata": {}, "score": "44.521183"}
{"text": "Wolpert , D.H. , \" The Existence of A Priori Distinctions between Learning Algorithms \" , Neural Computation , 8 , 1996 .PDF or Postscript .Wolpert , D.H. , \" Determining Whether Two Data Sets are from the Same Distribution \" , in Maximum Entropy and Bayesian Methods 1995 , Ed . K. Hanson and R. Silver , Kluwer Academic press , 1996 .", "label": "", "metadata": {}, "score": "44.556587"}
{"text": "36 , no . 1 , pp .105 - 139 , 1999 .View at Google Scholar \u00b7 View at Scopus .R. E. Banfield , L. O. Hall , K. W. Bowyer , and W. P. Kegelmeyer , \" A comparison of decision tree ensemble creation techniques , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}, "score": "44.582684"}
{"text": "36 , no . 1 , pp .105 - 139 , 1999 .View at Google Scholar \u00b7 View at Scopus .R. E. Banfield , L. O. Hall , K. W. Bowyer , and W. P. Kegelmeyer , \" A comparison of decision tree ensemble creation techniques , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}, "score": "44.582684"}
{"text": "This ( also called stacked generalization ) is a way of combining multiple classifiers using the concept of a metalearner [ 79 ] .Unlike bagging and boosting , stacking may be utilized to combine classifiers of different types .Note that steps ( 1 ) to ( 3 ) are the same as cross - validation , but instead of using a winner - takes - all approach , the base learners are combined , possibly non linearly .", "label": "", "metadata": {}, "score": "44.59393"}
{"text": "In the Voronoi tessellation , when the prototype of each Voronoi region is connected to all the prototypes of its bordering Voronoi regions , aDelaunaytriangulationisobtained .CompetitiveHebbian learning(Martinetz,1993;Martinetz&Schulten,1994)isamethod that generates a subgraph of the Delaunay triangulation , called ? \u03b7f \u03b70 ? \u03c1f \u03c10 ? t Tf , .", "label": "", "metadata": {}, "score": "44.6159"}
{"text": ", 1996 ) first performs an incremen- tal and approximate preclustering phase in which dense regions of points are represented by compact summaries , and a centroid based hierarchical algorithm is then used to cluster the set of sum- maries .The outliers are eliminated from the summaries via the identification of the sparsely distributed data points in the feature space .", "label": "", "metadata": {}, "score": "44.616722"}
{"text": "Martinetz , T. M. , & Schulten , K. J. ( 1994 ) .Topology representing networks .Neural Networks , 7 , 507 - 522 .Massey , L. ( 2003 ) .On the quality of ART1 text clustering .", "label": "", "metadata": {}, "score": "44.61836"}
{"text": "( ii )Cascading Classifiers Method .In this method , different base classifiers are employed sequentially to unclassified instance and confidence level of first classifier is recorded .If its level is high enough then its prediction is the ensemble final prediction .", "label": "", "metadata": {}, "score": "44.692516"}
{"text": "View at Google Scholar .S. Unger and F. Wysotzki , Lernf\u00e4hige Klassifizierungssysteme ( Classifier Systems Which Are Able to Learn ) , Akademie - Verlag , Berlin , Germany , 1981 .W. M\u00fcller and F. Wysotzki , \" Automatic construction of decision trees for classification , \" Annals of Operations Research , vol .", "label": "", "metadata": {}, "score": "44.71141"}
{"text": "But , availability of irrelevant and redundant feature affects detection performance of classifiers .Homogeneous ensembles focus on different features of training dataset and/or different training subsets and/or other ways to generate diverse base classifiers .Applications of the AI - based ensembles revealed that they have pros and cons .", "label": "", "metadata": {}, "score": "44.718895"}
{"text": "The method first finds an MST for the input data .The MST algorithm is good at clustering arbitrary shapes .The method , however , is very sensitive to the outliers , and it may merge two clusters due to a chain of outliers between them .", "label": "", "metadata": {}, "score": "44.722557"}
{"text": "Many researchers proposed fuzzy set theory to combine base classifiers using fuzzy aggregation connectives to determine ensemble prediction [ 76 , 77 ] .Fuzzy combination methods are effective as they measure the strength of every subset of classifiers .Thus to determine the class of any unclassified instance is the decision of ensemble which is based upon competence of every subset of based classifiers [ 50 ] .", "label": "", "metadata": {}, "score": "44.72302"}
{"text": "A total of 72 features of the vibration data from the two ( horizontal and vertical ) sensors are fed into C4.5 decision tree together for training and testing .Three classification algorithms , namely SVM , C4.5 and naive Bayes are applied with the proposed procedure and the results of the best performing method is reported below .", "label": "", "metadata": {}, "score": "44.726288"}
{"text": "Self - organization and associative memory .Berlin : Springer .Kohonen , T. ( 1990 ) .The self - organizing map .Proceedings of IEEE , 78 , 1464 - 1480 .Kohonen , T. ( 1996 ) .Emergence of invariant - feature detectors in the adaptive- subspace self - organizing map .", "label": "", "metadata": {}, "score": "44.73286"}
{"text": "401 - 407 , 2001 .L. I. Kuncheva , \" Switching between selection and fusion in combining classifiers : An ex - periment , \" IEEE Transactions on Systems , Man , and Cybernetics , Part B : Cybernetics , vol .", "label": "", "metadata": {}, "score": "44.751194"}
{"text": "IEEE Transactions on Fuzzy Systems , 6(2 ) , 195 - 204 .Ester , M. , Kriegel , H.P. , Sander , J. , & Xu , X. ( 1996 ) .A density - based algorithm for discovering clusters in large spatial databases with noise .", "label": "", "metadata": {}, "score": "44.77468"}
{"text": "( 4 ) Some unstable classifiers like neural networks show different results with different initializations due to the randomness inherent in the training procedure .Instead of selecting the best network and discarding the others , one can combine various networks .", "label": "", "metadata": {}, "score": "44.776978"}
{"text": "The graph is recur- sively partitioned into many small unconnected subgraphs , each partitioningyieldingtwosubgraphsofroughlyequalsize . Agglom- erative clustering is applied to the subclusters .Two subclusters are merged only when the interconnectivity as well as the closeness of the individual clusters is very similar .", "label": "", "metadata": {}, "score": "44.86179"}
{"text": "Wolpert , D.H. , \" How to Deal with Multiple Possible Generalizers \" , in Fast Learning and Invariant Object Recognition , Ed .B. Soucek , Wiley and Sons , 1992 .PDF or Postscript .Wolpert , D.H. , \" Stacked Generalization \" , Neural Networks , 5 , 241 - 259 , 1992 .", "label": "", "metadata": {}, "score": "44.907665"}
{"text": "A simple strategy for determining K is to perform clustering for a range of K , and select the value of K that minimizes a cluster validity measure .This procedure is computationally intensive when the actual number of clusters is large .", "label": "", "metadata": {}, "score": "44.91997"}
{"text": "The LVQ is used for VQ and classification , as well as for fine tuning the SOM ( Kohonen , 1989 , 1990 ) .LVQ algorithms define near - optimal decision borders between classes , even in the sense of classical Bayesian decision theory .", "label": "", "metadata": {}, "score": "44.970818"}
{"text": "An example of a ' Bayesian ' technique is the relevance vector machine ( RVM ) [ 53 ] . C4.5 Decision Tree .C4.5 decision tree is the most popular method in the ID3 decision tree family .The ID3 decision tree [ 54 ] family chooses attributes on the basis of information gain ( reduction in entropy ) .", "label": "", "metadata": {}, "score": "44.99624"}
{"text": "Diversity among the base classifiers can be measured by implicit or explicit methods [ 47 , 49 ] .In order to evaluate the performance , different performance metrics can be computed based upon benchmarked datasets .Discussion .Over the past decade , ID based upon ensemble approaches has been a widely studied topic , being able to satisfy the growing demand of reliable and intelligent IDS .", "label": "", "metadata": {}, "score": "45.007042"}
{"text": "Neural networks for vector quantization of speech and images .IEEE Journal on Selected Areas in Communications , 8(8 ) , 1449 - 1457 .Krishnapuram , R. , Nasraoui , O. , & Frigui , H. ( 1992 ) .The fuzzy c spherical shells algorithm : A new approach .", "label": "", "metadata": {}, "score": "45.020042"}
{"text": "The regularized distance achieves a trade - off between the hyperspherical and hyperellipsoidal cluster shapes to prevent the HEC network from producing unusually large or unusually small clusters .The Mahalanobis distance is used in the Gustafson - Kessel algorithm ( Gustafson & Kessel , 1979 ) and the AFC ( Anderson et al . , 1982 ) .", "label": "", "metadata": {}, "score": "45.086082"}
{"text": "The underlying complex decision boundary can then be approximated by an appropriate combination of different classifiers .In many applications that call for automated decision making , it is not unusual to receive data obtained from different sources that may provide complementary information .", "label": "", "metadata": {}, "score": "45.09325"}
{"text": "The SOM is popular for VQ , clustering analysis , feature extraction , and data visualization .The Kohonen network has the same structure as the competi- tivelearningnetwork .TheoutputlayeriscalledtheKohonenlayer .Input patterns are presented sequentially through the input layer , withoutspecifyingthedesiredoutput .", "label": "", "metadata": {}, "score": "45.097546"}
{"text": "583 - 590 , Morgan Kaufmann , San Francisco , Calif , USA , 2000 .C. Elkan , \" The foundations of cost - sensitive learning , \" in Proceedings of the 17th International Conference on Artificial Intelligence ( IJCAI ' 01 ) , B. Nebel , Ed . , pp .", "label": "", "metadata": {}, "score": "45.113426"}
{"text": "The alternating cluster estimation method ( Runkler & Bezdek , 1999 ) is a simple extension of the generalmethod(Dave&Krishnapuram,1997;Yang&Wang,2004 ) .The fuzzy robust C - spherical shells algorithm ( Yang & Wang , 2004 ) searches the clusters that belongs to the spherical shells by combining the concept of the fuzzy complement and the fuzzy C - spherical shells algorithm ( Krishnapuram , Nasraoui , & Frigui , 1992 ) .", "label": "", "metadata": {}, "score": "45.13719"}
{"text": "Many techniques generate a pool of homogeneous base classifiers , for examples , genetic algorithms .Although in ensembles , the combined knowledge is important , it is very computationally expensive to combine a large number of classifiers from the whole population [ 33 ] .", "label": "", "metadata": {}, "score": "45.16635"}
{"text": "The objective of this method is to offer an alternative classification when base classifiers disagree ( arbiter tree ) or to combine the predictions of base classifiers by learning their relationships with the correct class labels ( combiner trees ) [ 80 , 81 ] .", "label": "", "metadata": {}, "score": "45.185844"}
{"text": "[28 ] proposed a hybrid approach to detect intrusions .They utilized Bayesian networks ( BNs ) and classification and regression trees ( CARTs ) and their ensemble to generate hybrid system .They empirically proved that CART performed best for Normal , Probe , and U2R and the ensemble approach worked best for R2L and DoS. The heterogeneous ensemble was generated by training the individual classifiers from reduced KDD cup 99 dataset .", "label": "", "metadata": {}, "score": "45.217175"}
{"text": "IEEE Transactions on Neural Networks , 7(5 ) , 1062 - 1071 .Karayiannis , N. B. , & Pai , P. I. ( 1996 ) .Fuzzy algorithms for learning vector quantization .IEEE Transactions on Neural Networks , 7 , 1196 - 1211 .", "label": "", "metadata": {}, "score": "45.240967"}
{"text": "Cambridge , MA : MIT Press .Scholkopf , B. , Smola , A. , & Muller , K. R. ( 1998 ) .Nonlinear component analysis as a kernel eigenvalue problem .Neural Computation , 10 , 1299 - 1319 .", "label": "", "metadata": {}, "score": "45.247337"}
{"text": "Section 3 lists the reasons and benefits for combining multiple base classifiers .Various taxonomies proposed in the literature are presented in Section 4 .The section also describes various methods used at different levels to generate ensembles .Section 5 highlights various AI - based ensembles proposed for ID during the last decade .", "label": "", "metadata": {}, "score": "45.30279"}
{"text": "Fuzzy clustering for rela- tional data is reviewed in Dave and Sen ( 2002 ) .xj , ? \u03bbi ?Hierarchical clustering Existing clustering algorithms are broadly classified into partitional , hierarchical , and density based clustering .Clustering methods discussed thus far belong to partitional clustering .", "label": "", "metadata": {}, "score": "45.31933"}
{"text": "Kuncheva [ 46 ] proposed a basic taxonomy for generating a diverse pool of classifiers .She proposed that diverse classifiers can be generated by using various methods at four different levels , namely , ( 1 ) combination level ; ( 2 ) classifier level ; ( 3 ) feature level ; ( 4 ) data level .", "label": "", "metadata": {}, "score": "45.32682"}
{"text": "The costs defining the ( local ) decision thresholds are \" learned \" from the individual costs specified by the training objects .Note also that the area in the middle of Figure 1 , in which no class decision is possible due to the overlapping of both classes with equal probabilities , is reduced in size in Figure 4 .", "label": "", "metadata": {}, "score": "45.355568"}
{"text": "The results are compared with those from the fuzzy c - means and k - means clustering methods .The experimental outcome positively indicates the potential of MFMM in undertaking data clustering tasks and its applicability to the power systems domain .", "label": "", "metadata": {}, "score": "45.380318"}
{"text": "A scalable distributed syntactic , semantic and lexical language model M. Tan , W. Zhou , L. Zheng and S. Wang Computational Linguistics , Vol .38 , No . 3 , pp .631 - 671 , 2012 , [ pdf ] .", "label": "", "metadata": {}, "score": "45.411182"}
{"text": "In order for this process to be effective , the individual experts must exhibit some level of diversity among themselves , as described later in this article in more detail .Within the classification context , then , the diversity in the classifiers - typically achieved by using different training parameters for each classifier - allows individual classifiers to generate different decision boundaries .", "label": "", "metadata": {}, "score": "45.417213"}
{"text": "S. Norton , \" Generating better decision trees , \" in Proceedings of the 11th International Joint Conference on Artificial Intelligence , 1989 .M. N\u00fa\u00f1ez , \" The use of background knowledge in decision tree induction , \" Machine Learning , vol .", "label": "", "metadata": {}, "score": "45.44433"}
{"text": "The distributed ART ( dART ) ( Carpenter , 1997 ) combines the stable fast learning capability of ART systems with the noise tolerance and code compression capabilities of the multilayer perceptron ( MLP ) .With a WTA code , the unsupervised dART model reduces to the fuzzy ART ( Carpenter et al . , 1991a ) .", "label": "", "metadata": {}, "score": "45.468227"}
{"text": "The Kohonen learning rule provides a codebook in which the distortion effects are automatically taken into account .The SOM is especially powerful for the visualization of high - dimensional data .It converts complex , nonlinear statistical relations between high - dimensional data into simple geometric relations at a low - dimensional display .", "label": "", "metadata": {}, "score": "45.483093"}
{"text": "Clustering is the process of organizing objects into groups whose members are similar in some way .A variety of algorithms have recently emerged that meet these requirements and were successfully applied to real life data mining problem .Fuzzy c - means ( FCM ) and k - means are commonly used partitional algorithm based on unsupervised learning methods .", "label": "", "metadata": {}, "score": "45.505608"}
{"text": "Finally , the representational reason is to address to cases when the chosen model can not properly represent the sought decision boundary , which is discussed under divide and conquer section above .Perhaps one of the earliest work on ensemble systems is Dasarathy and Sheela 's 1979 paper ( Dasarathy 1979 ) , which first proposed using an ensemble system in a divide - and - conquer fashion , partitioning the feature space using two or more classifiers .", "label": "", "metadata": {}, "score": "45.509987"}
{"text": "On the rate of convergence in topology preserving neural networks .Biological Cybernetics , 65 , 55 - 63 .Luk , A. , & Lien , S. ( 1998 ) .Learning with lotto - type competition .In Proc int joint conf neural netw , vol . 2 ( pp .", "label": "", "metadata": {}, "score": "45.54506"}
{"text": "M. Kukar and I. Kononenko , \" Cost - sensitive learning with neural networks , \" in Proceedings of the 13th European Conference on Artificial Intelligence ( ECAI ' 98 ) , John Wiley & Sons , Chichester , UK , 1998 .", "label": "", "metadata": {}, "score": "45.547943"}
{"text": "448 - 456 , Springer , Berlin , Germany , 1999 .View at Google Scholar .F. Min and W. Zhu , \" Minimal cost attribute reduction through backtracking , \" in Proceedings of the International Conference on Database Theory and Application , vol .", "label": "", "metadata": {}, "score": "45.58014"}
{"text": "IEEE Transactions on Neural Networks , 3 , 776 - 786 .Simpson , P. K. ( 1993 ) .Fuzzy min - max neural networks - Part II : Clustering .IEEE Transactions on Fuzzy Systems , 1(1 ) , 32 - 45 .", "label": "", "metadata": {}, "score": "45.58766"}
{"text": "Applied Optics , 26 , 4919 - 4930 .Carpenter , G. A. , & Grossberg , S. ( 1988 ) .The ART of adaptive pattern recognition by a self - organizing neural network .Computer , 21 , 77 - 88 .", "label": "", "metadata": {}, "score": "45.601353"}
{"text": "Inthehierarchicalunsupervisedfuzzyclustering ( HUFC ) ( Geva , 1999 ) , PCA is applied to each cluster for optimal fea- ture extraction .This method is effective for data sets with a wide dynamic variation in both the covariance matrix and the number of members in each class .", "label": "", "metadata": {}, "score": "45.608612"}
{"text": "Journal of Intelligent Fuzzy Systems , 2(3 ) , 209 - 219 .Yager , R. R. , & Filev , D. ( 1994b ) .Approximate clustering via the mountain method .IEEE Transactions on Systems Man and Cybernetics , 24(8 ) , 1279 - 1284 .", "label": "", "metadata": {}, "score": "45.73757"}
{"text": "Research , vol .2 , pp .263 - 286 , 1995 .T. K. Ho , \" Random subspace method for constructing decision forests , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .20 , no . 8 , pp .", "label": "", "metadata": {}, "score": "45.790237"}
{"text": "Abbasion et al .[47 ] discussed multi - fault diagnosis of normal and three fault types in two different bearings at different locations of a system .Sugumaran et al .[ 48 ] discussed the use of a multi - class SVM built from one - class SVMs to reduce the computational efforts required by the traditional binary SVM .", "label": "", "metadata": {}, "score": "45.800808"}
{"text": "( 1 ) Ensemble comprise of multiple weak classifiers instead of single classifier .The multiple classifiers complement weaknesses of each other and hence improve the performance .( 2 ) Ensembles use the combined knowledge to model the hypothesis of the problem upon different subset of dataset or feature subspace .", "label": "", "metadata": {}, "score": "45.812355"}
{"text": "131 - 156 , 1997 .View at Google Scholar .X. Wang , J. Yang , X. Teng , W. Xia , and R. Jensen , \" Feature selection based on rough sets and particle swarm optimization , \" Pattern Recognition Letters , vol .", "label": "", "metadata": {}, "score": "45.814724"}
{"text": "IEEE Transactions on Circuits and Systems - II , 43(4 ) , 329 - 334 .Angelov , P. P. , & Filev , D. P. ( 2004 ) .An approach to online identification of Takagi- Sugeno fuzzy models .IEEE Transactions on Systems , Man and Cybernetics - B , 34(1 ) , 484 - 498 .", "label": "", "metadata": {}, "score": "45.844643"}
{"text": "199 - 214 , 2001 .View at Google Scholar . H. Liu and H. Motoda , Feature Selection for Knowledge Discovery and Data Mining , vol .454 , Springer , 1998 .Y. Weiss , Y. Elovici , and L. Rokach , \" The CASH algorithm - cost - sensitive attribute selection using histograms , \" Information Sciences , vol .", "label": "", "metadata": {}, "score": "45.854576"}
{"text": "Wolpert , D.H. , \" Filter Likelihoods and Exhaustive Learning \" , in Computational Learning Theory and Natural Learning Systems II , Ed . S. Hanson et al . , MIT Press,1994 .PDF or Postscript .Wolpert , D.H. , \" Bayesian back - propagation over I - O functions rather than weights \" , in Advances in Neural Information Processing Systems VI , Ed . S. Hanson et al . , Morgan Kauffman , 1994 .", "label": "", "metadata": {}, "score": "45.92148"}
{"text": "Information Systems , 26(1 ) , 35 - 58 .Gustafson , D.E.,&Kessel , W.(1979 ) .Fuzzyclusteringwithafuzzycovariancematrix .In Proc IEEE conf decision contr ( pp .761 - 766 ) .Hamker , F. H. ( 2001 ) .Life - long learning cell structures - Continuously learning without catastrophic interference .", "label": "", "metadata": {}, "score": "45.923985"}
{"text": "In order to validate the evaluation results of IDS on a simulated dataset , one has to develop a methodology to quantify the similarity of simulated and real network traces .KDD cup 1999 dataset and its original form possess some special features , such as huge volume , high dimension , and highly skewed data distribution .", "label": "", "metadata": {}, "score": "45.93144"}
{"text": "Dunn , J. C. ( 1974 ) .Some recent investigations of a new fuzzy partitioning algorithm and its applicatiopn to pattern classification problems .Journla of Cybernetics , 4 , 1 - 15 .El - Sonbaty , Y. , & Ismail , M. ( 1998 ) .", "label": "", "metadata": {}, "score": "45.932343"}
{"text": "We leave this to future work .References . D. Michie , D. H. Spiegelhalter , and C. C. Taylor , Machine Learning , Neural and Statistical Classification , Series in Artificial Intelligence , Ellis Horwood , 1994 .L. Saitta , Ed . , Machine Learning - A Technological Roadmap , University of Amsterdam , Amsterdam , The Netherlands , 2000 .", "label": "", "metadata": {}, "score": "45.93654"}
{"text": "Another benefit of bagging methods is that they are parallel in nature in both the training and classification phases , whereas the boosting method is sequential in nature [ 33 ] .AI Based Ensembles for ID .Many researchers employed AI - based ensembles and hybrid approaches to improve performance of IDS .", "label": "", "metadata": {}, "score": "45.954475"}
{"text": "Yu , J. , & Yang , M. S. ( 2005 ) .Optimality test for generalized FCM and its application to parameter selection .IEEE Transactions on Fuzzy Systems , 13(1 ) , 164 - 176 .Zahn , C. T. ( 1971 ) .", "label": "", "metadata": {}, "score": "45.958447"}
{"text": "Workshop on Multiple Classifier Systems , Lecture Notes in Computer Science , F. Roli , J. Kittler , and T. Windeatt , Eds . , vol .3077 , pp . 1 - 15 , 2004 .L. I. Kuncheva , Combining Pattern Classifiers , Methods and Algorithms .", "label": "", "metadata": {}, "score": "45.981735"}
{"text": "In the fast learning mode , both the STM and the LTM are implemented by their steady - state nonlinear algebraic equations , andthuspropersequencingofSTMandLTMeventsisrequired .The fast learning mode is inexpensive and is most popular .LiketheincrementalC - means , theARTmodelfamilyissensitive to the order of presentation of the input patterns .", "label": "", "metadata": {}, "score": "45.983448"}
{"text": "335 - 347 , 1989 .View at Google Scholar .Q. H. Liu , F. Li , F. Min , M. Ye , and G. W. Yang , \" An efficient reduction algorithm based on new conditional information entropy , \" Control and Decision , vol .", "label": "", "metadata": {}, "score": "46.02053"}
{"text": "131 - 161 ) .New York : Springer - Verlag .Liu , S. H. , & Lin , J. S. ( 2000 ) .A compensated fuzzy Hopfield neural network for codebook design in vector quantization .International Journal of Pattern Recognition and Artifical Intelligence , 14(8 ) , 1067 - 1079 .", "label": "", "metadata": {}, "score": "46.062973"}
{"text": "However , it has been shown that a properly trained ensemble decision is usually correct if its confidence is high , and usually incorrect if its confidence is low .Using such an approach then , the ensemble decisions can be used to estimate the posterior probabilities of the classification decisions ( Muhlbaier 2005 ) .", "label": "", "metadata": {}, "score": "46.07978"}
{"text": "Partitional clustering has a typical complexity of O(N ) .Hierarchical clustering consists of a sequence of partitions in a hierarchical structure , which can be represented as a clustering treecalleddendrogram .Hierarchicalclusteringtakestheformofei- ther agglomerative or divisive technique .New clusters are formed by reallocating the membership degree of one point at a time , basedonacertainmeasureofsimilarityordistance .", "label": "", "metadata": {}, "score": "46.120842"}
{"text": "The C - means clustering is closely related to the SCL , and is a special case of the SOM .The batch C - means ( Linde et al ., 1980 ) , also called the Linde - Buzo - Gray , LBG or generalized Lloyd algorithm , is applied when the whole training set is available .", "label": "", "metadata": {}, "score": "46.24817"}
{"text": "Classification and regression are the most common data mining formulations , where the classes ( categorical in classification and continuous in regression ) are utilized in the modeling ( supervised learning ) .Five of the ten popular algorithms are designed for classification and regression .", "label": "", "metadata": {}, "score": "46.260506"}
{"text": "Development and spatial structure of cortical feature maps : A model study .In R. P. Lippmann , J. E. Moody , & D. S. Touretzky ( Eds . ) , Advances in neural information processing systems : vol .3 ( pp .", "label": "", "metadata": {}, "score": "46.297997"}
{"text": "T. ( 33 )The average fuzzy density criterion ( Gath & Geva , 1989 ) is defined as the average of the fuzzy density in each cluster , Sisums the membership degrees of only those members within a hyperellipsoid defined by Fi .", "label": "", "metadata": {}, "score": "46.344315"}
{"text": "Many researchers suggested the use of feature selection / reduction techniques [ 16 , 122 ] .These techniques help remove irrelevant and redundant features and identify appropriate features for intrusion detection .The reduction in features reduces the amount of audit data for effective IDS .", "label": "", "metadata": {}, "score": "46.35423"}
{"text": "Thus , the derived degree of membership does not decrease as the number of clusters increases .Without this constraint , the modified objective function is decomposed into many individual objective functions , one for each cluster , which can be optimized separately .", "label": "", "metadata": {}, "score": "46.356697"}
{"text": "The RPCL automaticallyallocatesanappropriatenumberofprototypesforan input data set , and all the extra candidate prototypes will finally be pushed to infinity .It provides a better performance than the FSCL .The RPCL can be regarded as an unsupervised extension of the supervised LVQ2 ( Kohonen , 1990 ) .", "label": "", "metadata": {}, "score": "46.44743"}
{"text": "I. H. Witten and E. Frank , Data Mining : Practical Machine Learning Tools and Techniques , The Morgan Kaufmann Series in Data Management Systems , Morgan Kaufmann , San Francisco , Calif , USA , 2nd edition , 2005 .C. M. Bishop , Pattern Recognition and Machine Learning , Information Science and Statistics , Springer , New York , NY , USA , 2006 .", "label": "", "metadata": {}, "score": "46.519142"}
{"text": "I. H. Witten and E. Frank , Data Mining : Practical Machine Learning Tools and Techniques , The Morgan Kaufmann Series in Data Management Systems , Morgan Kaufmann , San Francisco , Calif , USA , 2nd edition , 2005 .C. M. Bishop , Pattern Recognition and Machine Learning , Information Science and Statistics , Springer , New York , NY , USA , 2006 .", "label": "", "metadata": {}, "score": "46.519142"}
{"text": "Drummond and Holte [ 6 ] investigate the cost - sensitivity of four commonly used attribute selection criteria in tree learning .One way to incorporate costs in classification learning is to use a cost function that specifies the mean misclassification costs in a class - dependent manner a priori [ 1 , 7 - 10 ] .", "label": "", "metadata": {}, "score": "46.55458"}
{"text": "Xiang et al .[36 ] proposed a hierarchical hybrid system involving multiple - level hybrid classifier , which combines the supervised decision tree classifiers and unsupervised Bayesian clustering to detect intrusions .It was able to achieve a higher true positive rate than previously reported in the literature on the original training and test sets of the KDD Cup 99 dataset .", "label": "", "metadata": {}, "score": "46.587517"}
{"text": "878 - 882 , 2005 ( Chinese ) .View at Google Scholar . A. Skowron and C. Rauszer , \" The discernibility matrices and functions in information systems , \" in Intelligent Decision Support , 1992 .View at Google Scholar .", "label": "", "metadata": {}, "score": "46.694107"}
{"text": "Pattern Recognition Letters , 11(9 ) , 589 - 594 .Rovetta , S. , & Zunino , R. ( 1999 ) .Efficient training of neural gas vector quantizers withanalogcircuitimplementation .IEEETransactionsonCircuitsandSystems - II , 46(6 ) , 688 - 698 .", "label": "", "metadata": {}, "score": "46.728355"}
{"text": "SOM - based algorithms for qualitative variables .Neural Networks , 17 , 1149 - 1167 .Dave , R. N. ( 1990 ) .Fuzzy - shell clustering and applications to circle detection in digital images .International Journal of General Systems , 16 , 343 - 355 .", "label": "", "metadata": {}, "score": "46.797436"}
{"text": "Combination of classifiers involves development of ensemble at generation and selection phases of learning , whereas ensemble integration phase involve combination of different predictions of multiple classifiers .In the following paragraphs , we presented important AI - based ensembles studies proposed in the last decade and compared them by various evaluation metrics .", "label": "", "metadata": {}, "score": "46.79883"}
{"text": "G. Rogova , \" Combining the results of several neural network classifiers , \" Neural Networks , vol .7 , no .5 , pp .777 - 781 , 1994 .L. Lam and C. Y. Suen , \" Optimal combinations of pattern classifiers , \" Pattern Recognition Letters , vol .", "label": "", "metadata": {}, "score": "46.807266"}
{"text": "Characterization and detection of noise in clustering .Pattern Recognition Letters , 12 , 657 - 664 .Dave , R. N. , & Krishnapuram , R. ( 1997 ) .Robust clustering methods : A unified view .IEEE Transactions on Fuzzy Systems , 5(2 ) , 270 - 293 .", "label": "", "metadata": {}, "score": "46.809364"}
{"text": "It is capable of handling different measurement scales as well as both continuous and categorical variables .Advantages of C4.5 include easy to implement , no underlying assumptions and ability to generate non - parametric and non - linear models , and ability to reduce the dimensionality of input feature space in a way interpretable to the analysts .", "label": "", "metadata": {}, "score": "46.819366"}
{"text": "Optimal adaptive k - means algorithm with dynamicadjustmentoflearningrate . IEEETransactionsonNeuralNetworks,6(1 ) , 157 - 169 .Chiu , S. ( 1994a ) .Fuzzy model identification based on cluster estimation .Journal Intelligent and Fuzzy Systems , 2(3 ) , 267 - 278 .", "label": "", "metadata": {}, "score": "46.83571"}
{"text": "Zhang , Y. J. , & Liu , Z. Q. ( 2002 ) .Self - splitting competitive learning : A new on - line clustering paradigm .IEEE Transactions on Neural Networks , 13(2 ) , 369 - 380 .Zheng , G. L. , & Billings , S. A. ( 1999 ) .", "label": "", "metadata": {}, "score": "46.83647"}
{"text": "IntheFHN(Lin et al ., 1996 ) , an FCM strategy is imposed for updating the neuron states .TheCFHNhasbeenusedforVQinimagecompression(Liu & Lin,2000),sothattheparallelimplementationforcodebookdesign is feasible .Supervised clustering When output patterns are used in clustering , this leads to supervised clustering .The locations of the cluster centers are determined by both the input pattern spread and the output pattern deviations .", "label": "", "metadata": {}, "score": "46.837585"}
{"text": "R. Polikar , \" Bootstrap inspired techniques in computational intelligence : ensemble of classifiers , incremental learning , data fusion and missing features , IEEE Signal Processing Magazine , v. 24 , no .4 , pp .59 - 72 , 2007 .", "label": "", "metadata": {}, "score": "46.85253"}
{"text": "Xue , H. ; Yang , Q. ; Chen , S. SVM : Support Vector Machines .In The Top Ten Algorithms in Data Mining ; Wu , X. , Kumar , V. , Eds . ; Chapman & Hall / CRC : London , UK , 2009 ; pp .", "label": "", "metadata": {}, "score": "46.86473"}
{"text": "102 K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 structures(LLCS)algorithm(Hamker,2001)isanon - lineclustering and topology representation method .It employs a strategy similar to that of the ART , and incorporates similarity based unit pruning and aging based edge pruning procedures .", "label": "", "metadata": {}, "score": "46.886173"}
{"text": "Nonuniform VQ is realized by decreasing the activation levels of the active nodes and increasing those of the other nodes to estimate the asymptotic point density automatically .The SCONN avoids the under - utilization problem , and has VQ accuracy and speed advantage over the SOM and the batch C - means ( Linde et al .", "label": "", "metadata": {}, "score": "46.903984"}
{"text": "A fuzzy clustering strategy is included in the Hopfield net- work to eliminate the need for finding the weighting factors in the energy function .This energy function is called the scatter energy function , and is formulated based on the within - class scatter ma- trix .", "label": "", "metadata": {}, "score": "46.931866"}
{"text": "Expert Syst .Appl .[ Google Scholar ] .Galar , M. ; Fern\u00e1ndez , A. ; Barrenechea , E. ; Bustince , H. ; Herrera , F. An overview of ensemble methods for binary classifiers in multi - class problems : Experimental study on one - vs - one and one - vs - all schemes .", "label": "", "metadata": {}, "score": "46.943787"}
{"text": "Competitive learning with conscience In the leaky learning strategy ( Grossberg , 1987 ; Rumelhart & Zipser , 1985 ) , all the prototypes are updated .The conscience strategy realizes a similar idea by reducing the winning rate of the frequent winners ( Desieno , 1988 ) .", "label": "", "metadata": {}, "score": "46.98994"}
{"text": "Exploiting syntactic , semantic and lexical regularities in language modeling via directed Markov random fields S. Wang , S. Wang , R. Greiner , D. Schuurmans and L. Cheng The 22th International Conference on Machine Learning , ICML-2005 .[ pdf ] .", "label": "", "metadata": {}, "score": "47.009567"}
{"text": "Fuzzy clustering of elliptic ring - shaped clusters .Pattern Recognition Letters , 16 , 727 - 741 .Gersho , A. ( 1979 ) .Asymptotically optimal block quantization .IEEE Transactions on Information Theory , 25(4 ) , 373 - 380 .", "label": "", "metadata": {}, "score": "47.010532"}
{"text": "However , an examination of the generated model shows that only two of the four types are modeled in the decision tree , probably because the training size is too small .Performance Evaluation - Machine Fault Simulator ( MFS ) .", "label": "", "metadata": {}, "score": "47.041016"}
{"text": "The training data subset for the second classifier \\(C_2\\ ) is chosen as the most informative subset , given \\(C_1\\ .\\ ) Specifically , \\(C_2\\ ) is trained on a training data only half of which is correctly classified by \\(C_1\\ , \\ ) and the other half is misclassified .", "label": "", "metadata": {}, "score": "47.048923"}
{"text": "241 - 259 , 1992 .T. K. Ho , J. J. Hull , and S. N. Srihari , \" Decision combination in multiple classifier systems , \" IEEE Trans . on Pattern Analy .Machine Intel . , vol .16 , no . 1 , pp .", "label": "", "metadata": {}, "score": "47.068123"}
{"text": "IEEE Transactions on Nuclear Sciences , 43(4 ) , 2389 - 2398 .Linde , Y. , Buzo , A. , & Gray , R. M. ( 1980 ) .An algorithm for vector quantizer design .IEEE Transactions on Communications , 28 , 84 - 95 .", "label": "", "metadata": {}, "score": "47.08257"}
{"text": "439 - 455 , 2004 .View at Google Scholar .R. Klinkenberg and S. R\u00fcping , \" Concept drift and the importance of examples , \" in Text Mining - Theoretical Aspects and Applications , J. Franke , G. Nakhaeizadeh , and I. Renz , Eds . , Springer , 2003 .", "label": "", "metadata": {}, "score": "47.146687"}
{"text": "IEEE Transactions on Systems Man and Cybernetics - B , 29(6 ) , 786 - 801 .Baraldi , A. , & Alpaydin , E. ( 2002 ) .Constructive feedforward ART clustering networks - Part I ; Part II .IEEE Transactions on Neural Networks , 13(3 ) , 645 - 677 .", "label": "", "metadata": {}, "score": "47.17118"}
{"text": "G. Fumera and F. Roli , \" A Theoretical and Experimental Analysis of Linear Combiners for Multiple Classifier Systems , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , Vol .27 , no .6 pp .942 - 956 , 2005 .", "label": "", "metadata": {}, "score": "47.2181"}
{"text": "Kuncheva and Whitaker [ 50 ] proposed different metrics to measure diversity .The diversity in ensembles can be obtained by using different ( 1 ) starting point in hypothesis space ; ( 2 ) set of accessible hypotheses ; ( 3 ) traversal of hypothesis space [ 47 ] .", "label": "", "metadata": {}, "score": "47.311554"}
{"text": "Therefore , individual classifiers in an ensemble system need to make different errors on different instances .The intuition , then , is that if each classifier makes different errors , then a strategic combination of these classifiers can reduce the total error , a concept not too dissimilar to low pass filtering of the noise .", "label": "", "metadata": {}, "score": "47.323586"}
{"text": "Moore , B. ( 1988 ) .ART and pattern clustering .In D. Touretzky , G. Hinton , & T. Sejnowski ( Eds . ) , Proc 1988 connectionist model summer school ( pp .174 - 183 ) .San Mateo , CA : Morgan Kaufmann .", "label": "", "metadata": {}, "score": "47.33236"}
{"text": "The proposed system suffers from limitation of incremental learning .It requires continuous retraining for changing environment .Cretu et al .[113 ] proposed a micromodel - based ensemble of anomaly sensors to sanitize the training data .Here , different models are generated to produce provisional labels for each training input , and models are combined in a voting scheme to determine which parts of the training data may represent attacks .", "label": "", "metadata": {}, "score": "47.344116"}
{"text": "This is perhaps the primary reason why ensemble based systems are used in practice : what is the most appropriate classifier for a given classification problem ?The most commonly used procedure - choosing the classifiers with the smallest error on training data - is unfortunately a flawed one .", "label": "", "metadata": {}, "score": "47.345562"}
{"text": "To define a cost - dependent transinformation measure as a generalization of the Shannon information , we introduce the cost - dependent probabilities .are probabilities which do indeed satisfy the axioms and rules that hold for classical probabilities .The well - known Bayes decision rule decides for the class , which has the highest probability in the cost - free case [ 24 ] .", "label": "", "metadata": {}, "score": "47.38169"}
{"text": "Workshop on Multiple Classifier Systems , Lecture Notes in Computer Science , Vol .1857 , pp . 1 - 15 , 2000 , Springer - Verlag .L. K. Hansen and P. Salamon , \" Neural network ensembles , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}, "score": "47.406975"}
{"text": "In D. S. Touretzky ( Ed . ) , Advances in neural information processing systems : vol . 1 ( pp .634 - 642 ) .San Mateo , CA : Morgan Kaufmann .Man , Y. , & Gath , I. ( 1994 ) .", "label": "", "metadata": {}, "score": "47.410408"}
{"text": "( 20 ) corresponds to a soft- max rule and ( 21 ) is similar to the mean of the data points in a cluster .Both equations are dependent on each other .The iterative alternating optimization procedure terminates when the change in the prototypes is sufficiently small ( Bezdek , 1981 ; Karayiannis & Mi , 1997 ) .", "label": "", "metadata": {}, "score": "47.495476"}
{"text": "A typical value for m is 1.5 or 2.0 .The FCM needs to store U and all ci 's , and the alternating estimationofUandci'scausesacomputationalandstorageburden for large - scale data sets .The computation can be accelerated by combining their updates ( Kolen & Hutcheson , 2002 ) , and consequently the storage of U is avoided .", "label": "", "metadata": {}, "score": "47.55221"}
{"text": "Journal of Machine Learning Research , 2 , 125 - 137 .Beni , G. , & Liu , X. ( 1994 ) .A least biased fuzzy clustering method .IEEE Transactions on Pattern Analysis and Machine Intelligence , 16(9 ) , 954 - 960 .", "label": "", "metadata": {}, "score": "47.568893"}
{"text": "The cost - dependent information measure was used for the selection of the ( locally ) best next attribute for tree building .It can be used in other algorithms for decision tree learning , but it is of general importance for information theory , modeling in cognitive science and human - computer interaction because the control of behavior by error is replaced by control through costs for false decisions .", "label": "", "metadata": {}, "score": "47.570694"}
{"text": "Circuit implementation of a peak detector neural network .IEEE Transactions on Circuits and Systems - II , 40 , 585 - 591 .Dempster , A. P. , Laird , N. M. , & Rubin , D. B. ( 1977 ) .", "label": "", "metadata": {}, "score": "47.610107"}
{"text": "121 - 134 , Springer , New York , NY , USA , 1997 .View at Google Scholar .N. T\u00f3th and B. Pataki , \" On classification confidence and ranking using decision trees , \" in Proceedings of the 11th International Conference on Intelligent Engineering Systems ( INES ' 07 ) , pp .", "label": "", "metadata": {}, "score": "47.680775"}
{"text": "However , IBC does not allow to efficiently adapt a fusion function over time when new data becomes available , since it requires a fixed number of classifiers .The IBC technique was further improved as incremental Boolean combination ( incrBC ) by the authors [ 119 ] .", "label": "", "metadata": {}, "score": "47.69655"}
{"text": "Fuzzy Kohonen clustering networks .In Proc 1stIEEE int conf fuzzy syst , ( pp .1035 - 1043 ) .Boley , D. ( 1998 ) .Principal direction divisive partitioning .Data Mining and Knowledge Discovery , 2(4 ) , 325 - 344 .", "label": "", "metadata": {}, "score": "47.71582"}
{"text": "We start with the introduction of cost - dependent probabilities and a cost - dependent information measure as a generalization of the information measure introduced by Shannon , which only depends on classical probabilities [ 23 ] .The term \" information measure \" refers to the quantity of information produced by a source , which is coded and then transferred through a ( generally noisy ) channel to a receiver where it is decoded .", "label": "", "metadata": {}, "score": "47.763466"}
{"text": "The proposed OVA approach helps speed up this process by eliminating the need of data collection of all different types of concurrent faults of a component / structure .Technique Overview .Algorithms in data mining are often grouped by the type of model generated or the most usual way of formulating a problem .", "label": "", "metadata": {}, "score": "47.77923"}
{"text": "B. V. Dasarathy and B. V. Sheela ( 1979 ) , \" Composite classifier system design : concepts and me - thodology , \" Proceedings of the IEEE , vol .67 , no .5 , pp .708 - 713 .", "label": "", "metadata": {}, "score": "47.77928"}
{"text": "The induced Delaunay triangulation is optimally topology- preserving in a general sense ( Martinetz , 1993 ) .Given a number of prototypes in RJ , competitive Hebbian learning successively adds connections among them by evaluating input data drawn from P(x ) .", "label": "", "metadata": {}, "score": "47.793987"}
{"text": "The classification accuracies of both methods are higher than the accuracy of random guess among four single - defect classes ( 25 % ) .Next we compare the performance for concurrent defects , using the COMB data .When a multi - class classification is used , there is no way for the classifier to give the correct classification because this class does not exist in the training data and hence the classifier model .", "label": "", "metadata": {}, "score": "47.803978"}
{"text": "The system was tested on data gathered at Google , Inc. and two universities in USA and Europe , showing promising results .However , they used anomaly detection technique ( Bayesian technique ) to model attribute inputs without taking into account typical semantic differences between classes of characters ( alphabetic , numeric , and non - alphanumeric ) , which usually determine their meaning .", "label": "", "metadata": {}, "score": "47.82012"}
{"text": "The authors reported 84.1 % , 99.5 % , 14.1 % , and 31.5 % detection of Probe , DoS , U2R , and R2L attack classes .Yan and Hao [ 111 ] presented ensemble of neural network for ID based upon improved MOGA ( improvement of NSGA - II ) .", "label": "", "metadata": {}, "score": "47.824272"}
{"text": "( iv )Clustering - Based Selection Method .This method employs clustering technique to search subset of base classifiers which perform similar predictions about the unclassified instance .Then the method selects a model from each cluster to select subset of available base classifiers .", "label": "", "metadata": {}, "score": "47.839844"}
{"text": "The dataset comes with class - dependent costs estimated by experts , that is , a cost - matrix .The original version of CAL5 had already achieved good results for this dataset in the past and learned decision trees with an average of two nodes ( [ 1 , page 154 ] ) .", "label": "", "metadata": {}, "score": "47.847076"}
{"text": "Sotiris , V. ; Tse , P. ; Pecht , M. Anomaly detection through a bayesian support vector machine .IEEE Trans .Reliab .[ Google Scholar ] .Samanta , B. ; Al - Balushi , K. ; Al - Araimi , S. Artificial neural networks and support vector machines with genetic algorithm for bearing fault detection .", "label": "", "metadata": {}, "score": "47.86045"}
{"text": "ART 3 : Hierarchical search using chemical transmitters in self - organizing pattern recognition architectures .Neural Networks , 3 , 129 - 152 .Carpenter , G. , Grossberg , S. , & Rosen , D. B. ( 1991a ) .", "label": "", "metadata": {}, "score": "47.91198"}
{"text": "Ch . X. Ling and V. S. Sheng , \" Cost - sensitive learning and the class imbalance problem , \" in Encyclopedia of Machine Learning , C. Sammut , Ed . , Springer , 2008 .View at Google Scholar .", "label": "", "metadata": {}, "score": "47.948143"}
{"text": "Data clustering : A review .ACM Computing Surveys , 31(3 ) , 264 - 323 .Kanungo , T. , Mount , D. M. , Netanyahu , N. S. , Piatko , C. D. , Silverman , R. , & Wu , A. Y. ( 2002 ) .", "label": "", "metadata": {}, "score": "47.963596"}
{"text": "Competitive learning Competitive learning can be implemented using a two - layer ( J - K ) neural network , as shown in Fig . 1 .The input and output lay- ers are fully connected .The output layer is called the competition layer , wherein lateral connections are used to perform lateral inhi- bition . 2 ( 4 ) where N is the size of the pattern set , and \u00b5kpis the connection weight assigned to prototype ckwith respect to xp , denoting the membership of pattern p into cluster k. The SCL is derived by minimizing ( 3 ) under the assumptionthattheweightsareobtainedbythenearestprototype condition .", "label": "", "metadata": {}, "score": "47.966316"}
{"text": "48 , no .4 , pp .582 - 591 , 2010 .View at Google Scholar .P. Turney , \" Types of cost in inductive concept learning , \" in Proceedings of the ICML-2000 Workshop on Cost - Sensitive Learning , 2000 .", "label": "", "metadata": {}, "score": "47.98753"}
{"text": "Hierarchical unsupervised fuzzy clustering .IEEE Transactions on Fuzzy Systems , 7(6 ) , 723 - 733 .Girolami , M. ( 2002 ) .Mercer kernel based clustering in feature space .IEEE Transactions on Neural Networks , 13(3 ) , 780 - 784 .", "label": "", "metadata": {}, "score": "48.02897"}
{"text": "Kohonen , T. ( 1997 ) .Self - organizing maps .Berlin : Springer .Kohonen , T. , Kangas , J. , Laaksonen , J. , & Torkkola , K. ( 1992 ) .LVQPAK :A program package for the correct application of learning vector quantization algorithms .", "label": "", "metadata": {}, "score": "48.037697"}
{"text": "In Progress in neural information processing : Proc int conf neural info processing , vol . 1 ( pp .492 - 495 ) .Thulasiraman , K. , & Swamy , M. N. S. ( 1992 ) .Graphs : Theory and algorithms .", "label": "", "metadata": {}, "score": "48.0477"}
{"text": "Rumelhart , D. E. , & Zipser , D. ( 1985 ) .Feature discovery by competititve learning .Cognitive Science , 9 , 75 - 112 .Runkler , T. A. , & Bezdek , J. C. ( 1999 ) .", "label": "", "metadata": {}, "score": "48.077896"}
{"text": "The SVC can effectively deal with the outliers .Cluster validity An optimal number of clusters or a good clustering algorithm is onlyinthesenseofacertainclustervaliditycriterion .Manycluster validity measures are defined for this purpose .Measures based on maximal compactness and maximal separa- tion of clusters Agoodclusteringalgorithmshouldgenerateclusterswithsmall intracluster deviations and large inter - cluster separations .", "label": "", "metadata": {}, "score": "48.125977"}
{"text": "Second challenge to tackle in AI - based ensembles is the enormous amount of audit data that make it difficult to build effective IDS .The processing of enormous amount of data increases computational overhead and causes delay in detection of intrusions .", "label": "", "metadata": {}, "score": "48.134514"}
{"text": "[ pdf ] .Learning mixture models with the regularized latent maximum entropy principle S. Wang , D. Schuurmans , F. Peng and Y. Zhao IEEE Trans . on Neural Networks : Special Issue on Information Theoretic Learning , Vol .15 , No . 4 , pp .", "label": "", "metadata": {}, "score": "48.13803"}
{"text": "To ensure that individual boundaries are adequately different , despite using substantially similar training data , weaker or more unstable classifiers are used as base models , since they can generate suffi - ciently different decision boundaries even for small perturbations in their training parameters .", "label": "", "metadata": {}, "score": "48.14446"}
{"text": "When the amount of training data is too large to make a single classifier training difficult , the data can be strategically partitioned into smaller subsets .Each partition can then be used to train a separate classifier which can then be combined using an appropriate combination rule ( see below for different combination rules ) .", "label": "", "metadata": {}, "score": "48.15286"}
{"text": "A strategy based on one- versus -all ( OVA ) class binarization is proposed to improve fault diagnostics accuracy while reducing the number of scenarios for data collection , by predicting concurrent defects from training data of normal and single defects .", "label": "", "metadata": {}, "score": "48.162987"}
{"text": "2 + \u03b2j N ? 2 \u03b2j ?( 29 )For outliers , \u00b5jiis small .Some heuristics for selecting \u03b2jare given in Krishnapuram and Keller ( 1993 ) .Given a number of clusters K , the FCM will arbitrarily split or merge real clusters in the data set to produce exactly the specified number of clusters , while the PCM can find those natural clusters in the data set .", "label": "", "metadata": {}, "score": "48.166855"}
{"text": "The second phase of the process , which concerns the regular production use of the process , involves the fault detection ; isolation ; diagnosis ; prognosis and remaining useful life prediction ; and maintenance decisions .During the transition period before samples of all fault types are collected , the fault detection and isolation can still be performed .", "label": "", "metadata": {}, "score": "48.196564"}
{"text": "The MBCL avoids neuron under- utilization with probability one , as time goes to infinity .The FSCL ( Ahalt et al . , 1990 ; Krishnamurthy , Ahalt , Melton , & Chen , 1990 ) is a member of the MBCL family .", "label": "", "metadata": {}, "score": "48.21532"}
{"text": "The conditional FCM ( Pedrycz , 1998 ) develops clusters preserving homogeneity of the clustered patterns with regard to their similarity in the input space , as well as their respective values assumed in the output space .It is a supervised clustering .", "label": "", "metadata": {}, "score": "48.23911"}
{"text": "ACM Transactions on Knowledge Discovery from Data ( TKDD ) , Vol .6 , No . 2 , 8:1 - 42 , 2012 , [ pdf ] .Exploiting syntactic , semantic and lexical regularities in language modeling via directed Markov random fields S. Wang , S. Wang , L. Cheng , R. Greiner and D. Schuurmans Computational Intelligence , 2012 .", "label": "", "metadata": {}, "score": "48.27381"}
{"text": "Journal of the Royal Statistical Society B , 39(1 ) , 1 - 38 .Delport , V. ( 1996 ) .Codebook design in vector quantisation using a hybrid system of parallel simulated annealing and evolutionary selection .Electronics Letters , 32(13 ) , 1158 - 1160 .", "label": "", "metadata": {}, "score": "48.284492"}
{"text": "However , as already stated in the technological roadmap of the MLnetII project ( Network of Excellence in Machine Learning [ 2 ] ) , the consideration of costs in learning and classification is one of the most relevant fields in machine learning research and many applications .", "label": "", "metadata": {}, "score": "48.32157"}
{"text": "These approaches combine complementary multiple classifiers .They use combined knowledge to meet the challenges of ID - like high false alarm rate , low detection accuracy , and better performance in lack of sufficient amount of quality training dataset .The results of ensemble approach are proved to be improved than single best classifier .", "label": "", "metadata": {}, "score": "48.330322"}
{"text": "However , this purpose of dataset is also under criticism [ 121 ] .Therefore , using these datasets only is not sufficient to reveal the efficiency of a learning algorithm .So , new and good quality benchmark datasets need to be developed for realistic evaluation of IDS .", "label": "", "metadata": {}, "score": "48.333164"}
{"text": "Using these three basic architectures , we can build even more complicated classifier combination systems .He listed eighteen different methods for classifier combination and divided them into different categories according to their trainability , adaptivity , and requirement on the output of individual classifiers .", "label": "", "metadata": {}, "score": "48.346443"}
{"text": ",1993)isaVQmodelwhich minimizes a known cost function and converges to the C - means quantization error via a soft - to - hard competitive model transition .The soft - to - hard annealing process helps the algorithm escape from local minima .", "label": "", "metadata": {}, "score": "48.36228"}
{"text": "[ pdf ] .A rate distortion approach for semi - supervised conditional random fields Y. Wang , G. Haffari , S. Wang and G. Mori Advances in Neural Information Processing Systems , NIPS-2009 .[ pdf ] .Monetizing user activity on social networks - challenges and experiences M. Nagarajan , K. Baid , A. P. Sheth , and S. Wang The IEEE / WIC / ACM International Conference on Web Intelligence , WI-2009 .", "label": "", "metadata": {}, "score": "48.412918"}
{"text": "Khreich et al .[ 2 ] proposed an iterative Boolean combination ( IBC ) method to efficiently fuse the predictions from multiple classifiers .The IBC efficiently exploits all Boolean functions applied to the ROC curves and requires no prior assumptions about conditional independence of classifiers or convexity of ROC curves .", "label": "", "metadata": {}, "score": "48.414597"}
{"text": "Here , the authors addressed the problem related to the presence of noise ( i.e. , attacks ) in the training set .The proposed model composed of a set of ( independent ) application - specific modules .Each module , composed by multiple HMM ensembles , is trained using queries on a specific web application and , during the operational phase , outputs a probability value for each query on this web application .", "label": "", "metadata": {}, "score": "48.470413"}
{"text": "The ARTMAP , also called predictive ART , autonomously learns to classify arbitrarily many , arbitrarily ordered vectors into recognition categories based on predictive success ( Carpen- ter et al . , 1991 ) .Compared to the backpropagation ( BP ) learn- ing ( Rumelhart , Hinton , & Williams , 1986 ) , the ARTMAP has a number of advantages such as being self - organizing , self - stabili- zing , match learning , and real time .", "label": "", "metadata": {}, "score": "48.4745"}
{"text": "They proposed to partition the original dataset into two subsets .The first subset is reserved to form the metadataset and the second subset is used to build the base - level classifiers .This classifier ( Metaclassifier ) combines the different predictions into a final one .", "label": "", "metadata": {}, "score": "48.47643"}
{"text": "The resulting synergy has been shown to be an effective way for building IDSs with improved performance in terms of detection accuracy and false - positive rate .It may be concluded that by considering appropriate base classifiers , training sample size & combination method , the performance of hybrid classifier / ensemble can be improved .", "label": "", "metadata": {}, "score": "48.493362"}
{"text": "A two - stage procedure given in Su and Liu ( 2005 ) can cluster data with arbi- trary shapes , where an ART - like algorithm partitions data into a set of small multi - dimensional hyperellipsoids and an agglomera- tive algorithm sequentially merges those hyperellipsoids . Dendro-", "label": "", "metadata": {}, "score": "48.52739"}
{"text": "238 - 247 , 2001 .G. Brown , J. Wyatt , R. Harris , X. Yao , \" Diversity Creation Methods : A Survey and Categorisation , \" Journal of Information Fusion ( Special issue on Diversity in Multiple Classifier Systems ) .", "label": "", "metadata": {}, "score": "48.537075"}
{"text": "A more natural approach is to let the cost depend on the individual training example for which it is objectively measured or determined , and not just on its class .The mean cost for a class or subclass can then be computed ( \" learned \" ) on an objective basis .", "label": "", "metadata": {}, "score": "48.547356"}
{"text": "Du , K. L. , & Swamy , M. N. S. ( 2006 ) .Neural networks in a softcomputing framework .London : Springer .Duda , R. O. , & Hart , P. E. ( 1973 ) .Pattern classification and scene analysis .", "label": "", "metadata": {}, "score": "48.581024"}
{"text": "All four clusters are derived from Gaussian distributions .CAL5 constructs two piecewise linear functions which discriminate between the classes .Subdivisions within the same class built by CAL5 are omitted here .from the object - dependent costs given in the NSEP_OC training set as described in Section 4 .", "label": "", "metadata": {}, "score": "48.583755"}
{"text": "Berlin : Springer .Rose , K. ( 1998 ) .Deterministic annealing for clustering , compression , classification , regression , and related optimization problems .Proceedings of IEEE , 86(11 ) , 2210 - 2239 .Rose , K. , Gurewitz , E. , & Fox , G. C. ( 1990 ) .", "label": "", "metadata": {}, "score": "48.602905"}
{"text": "Wolpert , D.H. , \" Using a Mathematical Theory of Generalization to Construct a Generalizer Superior to NETtalk \" , Neural Networks , 3 , 445 - 452 , 1990 .PDF or Postscript .Wolpert , D.H. , \" A mathematical Theory of Generalization : part I , part II \" , Complex Systems , 4 , 151 - 200 , 201 - 249 , 1990 .", "label": "", "metadata": {}, "score": "48.644722"}
{"text": "Future work includes data collection and further analysis of the proposed approach with other combined defects such as BPFI BSF combined ; BPFO BSF combined ; and all three types combined .Acknowledgments .This research was supported in part by the Centre for Systems Informatics Engineering ( CSIE ) ( CityU # 9360144 ) ; HK RGC CRF ( # 8730029 ) ; HK RGC GRFs ( # 9041682 and # 9041578 ) ; and CityU grant SRG - Fd ( # CityU122613 ) .", "label": "", "metadata": {}, "score": "48.65957"}
{"text": "The following proposition states two important properties of the cost - sensitive transinformation and relates it to its classical , cost - independent counterpart .for those two classes , then there will be a larger mean difference of the cost - dependent probabilities compared to the classical probabilities , and the entropy will thus become smaller ; that is , it holds that . exceeds some threshold .", "label": "", "metadata": {}, "score": "48.69399"}
{"text": "Now , assume that each classifier has a probability p of making a correct decision .Weighted majority voting .Other combination rules .There are several other combination rules , which are arguably more sophisticated than the ones listed above .", "label": "", "metadata": {}, "score": "48.70432"}
{"text": "X. Ling , Q. Yang , J. Wang , and S. Zhang , \" Decision trees with minimal costs , \" in Proceedings of International Conference on Machine Learning ( ICML ' 04 ) , 2004 .C. Drummond and R. Holte , \" Exploiting the cost ( in)sensitivity of decision tree splitting criteria , \" in Proceedings of the 17th International Conference on Machine Learning ( ICML ' 00 ) , pp .", "label": "", "metadata": {}, "score": "48.708714"}
{"text": "Certain problems are just too difficult for a given classifier to solve .In fact , the decision boundary that separates data from different classes may be too complex , or lie outside the space of functions that can be implemented by the chosen classifier model .", "label": "", "metadata": {}, "score": "48.711693"}
{"text": "When novelty is detected , the ART adaptively and autonomouslycreatesanewcategorywiththeinputpatternasthe prototype .A large \u03c1 leads to many finely divided categories , while a smaller \u03c1 gives fewer categories .The stability and plastic- ity properties as well as the ability to efficiently process dynamic data make the ART attractive for clustering large , rapidly cha- nging sequences of input patterns , such as in the case of data mining ( Massey , 2003 ) .", "label": "", "metadata": {}, "score": "48.780785"}
{"text": "But , still some research issues exist .The major issues include diversity among the base classifiers , ensemble size , computational overhead , input feature space , and combining strategy .Ensemble Classifiers .The ensembles involve the employment of multiple base classifiers and combine their predictions to obtain reliable and more accurate predictions .", "label": "", "metadata": {}, "score": "48.81779"}
{"text": "231 - 250 , 1991 .View at Google Scholar .M. Tan , \" Cost - sensitive learning of classification knowledge and its applications in robotics , \" Machine Learning , vol .13 , no . 1 , pp .", "label": "", "metadata": {}, "score": "48.834713"}
{"text": "M. Sabhnani and G. Serpen , \" Application of machine learning algorithms to KDD intrusion detection dataset within misuse detection context , \" in Proceedings of the International Conference on Machine Learning ; Models , Technologies and Applications ( MLMTA ' 03 ) , pp .", "label": "", "metadata": {}, "score": "48.8506"}
{"text": "M. Sabhnani and G. Serpen , \" Application of machine learning algorithms to KDD intrusion detection dataset within misuse detection context , \" in Proceedings of the International Conference on Machine Learning ; Models , Technologies and Applications ( MLMTA ' 03 ) , pp .", "label": "", "metadata": {}, "score": "48.8506"}
{"text": "Self - organizing of orientation sensitive cells in the striata cortex .Kybernetik , 14 , 85 - 100 .Wang , J. H. , & Rau , J. D. ( 2001 ) .VQ - agglomeration : A novel approach to clustering .", "label": "", "metadata": {}, "score": "48.863052"}
{"text": "However , the method fails to identify clusters with non - spherical shapes or a wide variation in size by splitting larger clusters and merging smaller clusters .The CURE method ( Guha et al . , 2001 ) is a robust clustering algorithm based on the scatter - points represen- tation .", "label": "", "metadata": {}, "score": "48.87892"}
{"text": "IEEE Transactions on Fuzzy Systems , 8(2 ) , 228 - 236 .Lazzaro , J. , Lyckebusch , S. , Mahowald , M. A. , & Mead , C. A. ( 1989 ) .Winner - take- all networks of O(n ) complexity .", "label": "", "metadata": {}, "score": "48.884464"}
{"text": "Cambridge , MA : MIT Press .Fritzke , B. ( 1995b ) .Growing grid - A self - organizing network with constant neighborhood range and adaptation strength .Neural Processing Letters , 2(5 ) , 9 - 13 .Fritzke , B. ( 1997a ) .", "label": "", "metadata": {}, "score": "48.895935"}
{"text": "This process is recursively repeated [ 85 ] .( iii ) Dynamic Classifier Selection Method .This method measure the competence of each base classifier to determine the prediction of ensemble classifier .The competence of base classifier can be determined dynamically either by using prior information about base classifiers or by posterior information produced by them in terms of their predictions [ 86 , 87 ] .", "label": "", "metadata": {}, "score": "48.90206"}
{"text": "Sensors 2013 , 13 , 12663 - 12686 .[ Google Scholar ] .Quinlan , J. Induction of decision trees .Mach .Learn .[ Google Scholar ] .Shannon , C.E. A mathematical theory of communication .Bell Syst .", "label": "", "metadata": {}, "score": "48.933365"}
{"text": "Similar to bagging , boosting also creates an ensemble of classifiers by resampling the data , which are then combined by majority voting .However , in boosting , resampling is strategically geared to provide the most informative training data for each consecutive classifier .", "label": "", "metadata": {}, "score": "48.939194"}
{"text": "The findings of research work in each study are systematically summarized and compared , which allows us to clearly identify existing research challenges for intrusion detection and underline research directions .It is expected that this paper can serve as a practical channel through the maze of the literature .", "label": "", "metadata": {}, "score": "48.96979"}
{"text": "The STepwise Automatic Rival - penalized ( STAR ) C - means ( Cheung , 2003 ) is a generalizationoftheC -meansbasedontheFSCL(Ahaltetal.,1990 ) and a Kullback - Leibler divergence based criterion .The STAR C- means has a mechanism similar to the RPCL , but penalizes the rivals in an implicit way , whereby avoiding the problem of the RPCL .", "label": "", "metadata": {}, "score": "48.972374"}
{"text": "The incremental C - means gives the new prototype as ? where w is the index of the winning neuron , \u03b7(t ) is defined as in earlier formulations .The general procedure for the C - means clustering is to repeat the redistribution of patterns among the clusters using criterion ( 12 ) until there is no further change in the prototypes of the clusters .", "label": "", "metadata": {}, "score": "49.015327"}
{"text": "Full - text .It is widely used for pattern recognition , feature extraction , vector quantization ( VQ ) , image segmentation , function approximation , and data mining .As an unsupervised classification technique , clustering identifies some inherent structures present in a set of objects based on a similarity measure .", "label": "", "metadata": {}, "score": "49.068718"}
{"text": "Troika combines base classifiers in three stages : specialists level , metaclassifiers , and super classifier .In order to conclude which ensemble performs best over multiple datasets , they followed the procedure proposed in [ 118 ] .Wang et al .", "label": "", "metadata": {}, "score": "49.08641"}
{"text": "4 , pp .459 - 471 , 2007 .View at Google Scholar .W. Siedlecki and J. Sklansky , \" A note on genetic algorithms for large - scale feature selection , \" Pattern Recognition Letters , vol .10 , no .", "label": "", "metadata": {}, "score": "49.099945"}
{"text": "( 2 ) Some times more than a single training set is available , each collected at a different time or in a different environment .These training sets may even use different features .( 3 ) Different classifiers trained on the same data may not only differ in their global performances , but they also may show strong local differences .", "label": "", "metadata": {}, "score": "49.162117"}
{"text": "The related studies of AI - based ensembles are compared by set of evaluation metrics driven from ( 1 ) architecture & approach followed ; ( 2 ) different methods utilized in different phases of ensemble learning ; ( 3 ) other measures used to evaluate classification performance of the ensembles .", "label": "", "metadata": {}, "score": "49.169174"}
{"text": "Both the experts themselves and the gating network requires the input instances for training .Several mixture - of - experts models can also be further combined to obtain a hierarchical mixture of experts ( Jordan 1994 ) .Mixture of experts are particularly useful when different experts are trained on different parts of the feature space , or when heterogeneous sets of features are available to be used for a data fusion problem .", "label": "", "metadata": {}, "score": "49.247974"}
{"text": "Vakil - Baghmisheh , M. T. , & Pavesic , N. ( 2003 ) .A fast simplified fuzzy ARTMAP network .Neural Processing Letters , 17 , 273 - 316 .Verzi , S.J. , Heileman , G.L. , Georgiopoulos , M. , & Anagnostopoulos , G.C. ( 2003 ) .", "label": "", "metadata": {}, "score": "49.30858"}
{"text": "San Mateo , CA : Morgan Kaufmann .Mao , J.,&Jain , A.K.(1996 ) .Aself - organizingnetworkforhyperellipsoidalclustering ( HEC ) .IEEE Transactions on Neural Networks , 7(1 ) , 16 - 29 .Martinetz , T.M. ( 1993 ) .", "label": "", "metadata": {}, "score": "49.35511"}
{"text": "S. Peddabachigari , A. Abraham , C. Grosan , and J. Thomas , \" Modeling intrusion detection system using hybrid intelligent systems , \" Journal of Network and Computer Applications , vol .30 , no . 1 , pp .114 - 132 , 2007 .", "label": "", "metadata": {}, "score": "49.380157"}
{"text": "S. Peddabachigari , A. Abraham , C. Grosan , and J. Thomas , \" Modeling intrusion detection system using hybrid intelligent systems , \" Journal of Network and Computer Applications , vol .30 , no . 1 , pp .114 - 132 , 2007 .", "label": "", "metadata": {}, "score": "49.380157"}
{"text": "247 - 268 , 2013 .View at Publisher \u00b7 View at Google Scholar .C. Elkan , \" The foundations of cost - sensitive learning , \" in Proceedings of the 7th International Joint Conference on Artificial Intelligence , 2001 .", "label": "", "metadata": {}, "score": "49.400078"}
{"text": "IEEE Transactions on Fuzzy Systems , 11(6 ) , 709 - 715 .Lin , J. S. ( 1999 ) .Fuzzy clustering using a compensated fuzzy Hopfield network .Neural Processing Letters , 10 , 35 - 48 .Lin , J. S. , Cheng , K. S. , & Mao , C. W. ( 1996 ) .", "label": "", "metadata": {}, "score": "49.417095"}
{"text": "In order to solve these problems , many researchers utilized AI - based ensembles for ID successfully .They proved that AI - based ensembles can improve detection performance over a single technique / classifier [ 27 - 29 ] .The concept of ensemble is to employ multiple base classifiers and their individual predictions are combined in some way to obtain reliable and more accurate predictions [ 17 , 25 ] .", "label": "", "metadata": {}, "score": "49.440147"}
{"text": "262 - 294 , 2000 .View at Google Scholar .G. Kumar , K. Kumar , and M. Sachdeva , \" An empirical comparative analysis of feature reduction methods for intrusion detection , \" International Journal of Information and Telecommunication , vol .", "label": "", "metadata": {}, "score": "49.455795"}
{"text": "262 - 294 , 2000 .View at Google Scholar .G. Kumar , K. Kumar , and M. Sachdeva , \" An empirical comparative analysis of feature reduction methods for intrusion detection , \" International Journal of Information and Telecommunication , vol .", "label": "", "metadata": {}, "score": "49.455795"}
{"text": "As a result , we arrived at a mean cost of 3.34 in the first case and 2.97 in the second .This means that the mean cost declined by about 11 % for the object - dependent , that is , optimized case .", "label": "", "metadata": {}, "score": "49.4708"}
{"text": "IEEETransactionsonNeuralNetworks,15(3 ) , 728 - 737 .Hoeppner , F. ( 1997 ) .Fuzzy shell clustering algorithms in image processing : Fuzzy C - rectangular and 2-rectangular shells .IEEE Transactions on Fuzzy Systems , 5(4 ) , 599 - 613 .", "label": "", "metadata": {}, "score": "49.471542"}
{"text": "[ pdf ] .Implicit online learning with kernels L. Cheng , S. Vishwanathan , D. Schuurmans , S. Wang and T. Caelli Advances in Neural Information Processing Systems , NIPS-2007 .[ pdf ] .Almost sure convergence of Titterington 's recursive estimator for finite mixture S. Wang and Y. Zhao Statistics & Probability Letters , Vol .", "label": "", "metadata": {}, "score": "49.4971"}
{"text": "To justify why certain hypotheses are proposed and why certain others are not , thus help the operator evaluate and act upon his / her experience .The focus of this paper lies in the multiple fault identification ability with statistical and data mining techniques .", "label": "", "metadata": {}, "score": "49.518284"}
{"text": "Hopfield network based fuzzy clustering The clustering problem can be cast as a problem of minimiza- tion of the MSE between the training patterns and the cluster cen- ters .This optimization problem can be solved using the Hopfield network ( Lin , 1999 ; Lin , Cheng , & Mao , 1996 ) .", "label": "", "metadata": {}, "score": "49.518967"}
{"text": "J. McCumber , \" Information system security : a comprehensive model , \" in Proceedings of the 14th National Computer Security Conference , Baltimore , Md , USA , 1991 .W. Khreich , E. Granger , A. Miri , and R. Sabourin , \" Iterative Boolean combination of classifiers in the ROC space : an application to anomaly detection with HMMs , \" Pattern Recognition , vol .", "label": "", "metadata": {}, "score": "49.52574"}
{"text": "J. McCumber , \" Information system security : a comprehensive model , \" in Proceedings of the 14th National Computer Security Conference , Baltimore , Md , USA , 1991 .W. Khreich , E. Granger , A. Miri , and R. Sabourin , \" Iterative Boolean combination of classifiers in the ROC space : an application to anomaly detection with HMMs , \" Pattern Recognition , vol .", "label": "", "metadata": {}, "score": "49.52574"}
{"text": "Many researchers applied and evaluated AI - based techniques using different evaluation datasets for ID .They reported many challenges related to AI - based techniques and dataset for ID .Each technique may have its own region in the feature space where it performs the best [ 26 ] .", "label": "", "metadata": {}, "score": "49.57347"}
{"text": "Each submodel is responsible for describing a specific region of the input space by its local principal subspace , and represents a manifold such as a linear subspace with a small dimensionality , whose basis vec- tors are determined adaptively .ASSOM not only inherits the topo- logical representation property of the SOM , but provides learning results which reasonably describe the kernels of various transfor- mation groups like the PCA .", "label": "", "metadata": {}, "score": "49.589268"}
{"text": "Thisall - pointsrepresentationcanclusterarbitraryshapes .The scatter - points representation achieves robustness to outliers , and identifies clusters that have non - spherical shape and wide variations in size .Agglomerative clustering Agglomerative clustering starts from N clusters , each contain- ing one data point .", "label": "", "metadata": {}, "score": "49.604706"}
{"text": "In the first group of simulations , the output cells are arranged in a 10\u00d7 10 grid , and the hexagonal neighborhood topology is used .The training result for 1000 epochs is shown in Fig .3a .When the 100 output cells are arranged in one dimension , the training result for 1000 epochs is showninFig.3b .", "label": "", "metadata": {}, "score": "49.61577"}
{"text": "Ensemble integration involves the combination of predictions of set of base classifiers selected in ensemble selection phase .It can use two different methods : ( 1 ) combination ( also called fusion ) ; or ( 2 ) selection [ 46 ] .", "label": "", "metadata": {}, "score": "49.617706"}
{"text": "IEEE Transactions on Acoustics , Speech and Signal Processing , 33(3 ) , 587 - 594 .Xie , X. L. , & Beni , G. ( 1991 ) .A validity measure for fuzzy clustering .IEEE Transactions on Pattern Analysis and Machine Intelligence , 13(8 ) , 841 - 847 .", "label": "", "metadata": {}, "score": "49.696365"}
{"text": "Semi - supervised conditional random fields for improved sequence segmentation and labeling F. Jiao , S. Wang , C. Lee , R. Greiner and D. Schuurmans The Joint 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics , COLING / ACL-2006 .", "label": "", "metadata": {}, "score": "49.710453"}
{"text": "The selection approach , specially its dynamic form , selects one ( or more ) classifier from the ensemble according to the prediction performance of these classifiers on similar data from the validation set .The ensemble integration phase involves many strategies to combine multiple predictions because these strategies have performance variability when tackling different problems .", "label": "", "metadata": {}, "score": "49.71094"}
{"text": "4 , pp .217 - 225 , 2009 .View at Google Scholar .C. Xiang , P. C. Yong , and L. S. Meng , \" Design of multiple - level hybrid classifier for intrusion detection system using Bayesian clustering and decision trees , \" Pattern Recognition Letters , vol .", "label": "", "metadata": {}, "score": "49.721836"}
{"text": "4 , pp .217 - 225 , 2009 .View at Google Scholar .C. Xiang , P. C. Yong , and L. S. Meng , \" Design of multiple - level hybrid classifier for intrusion detection system using Bayesian clustering and decision trees , \" Pattern Recognition Letters , vol .", "label": "", "metadata": {}, "score": "49.721836"}
{"text": "Many feature selection techniques for ensemble classifiers are proposed in the literature which can be further investigated in [ 15 , 16 , 103 ] .Data Level .This level focuses on ensemble generation phase of ensemble learning process .Here , different data subsets are used to train the pool of base classifiers .", "label": "", "metadata": {}, "score": "49.765663"}
{"text": "When all the K clusters have a similar size , the noise clustering is very effective .However , asinglethresholdistoorestrictiveifthecluster size varies widely in the data set .\u00b5ji ? m .Possibilistic C - means Unlike fuzzy clustering , the possibilistic C - means ( PCM ) ( Kr- ishnapuram & Keller , 1993 ) does not require the sum of the memberships of a data point across the clusters to be unity .", "label": "", "metadata": {}, "score": "49.78714"}
{"text": "Wu , X. ; Kumar , V. The Top Ten Algorithms in Data Mining ; Chapman & Hall / CRC : London , UK , 2009 ; Volume 9 .[ Google Scholar ] .Wang , G. ; Liu , C. ; Cui , Y. Clustering diagnosis of rolling element bearing fault based on integrated Autoregressive / Autoregressive Conditional Heteroscedasticity model .", "label": "", "metadata": {}, "score": "49.796173"}
{"text": "Rival - penalized competitive learning The problem of shared clusters is considered in the rival- penalized competitive learning ( RPCL ) algorithm ( Xu , Krzyzak , & Oja,1993 ) .TheRPCLaddsanewmechanismtotheFSCLbycreating arivalpenalizingforce .Foreachinput , thewinningunitismodified to adapt to the input , the second - place winner called the rival is also updated by a smaller learning rate along the opposite direction , and all the other prototypes remain unchanged ? \u03b7r .", "label": "", "metadata": {}, "score": "49.84522"}
{"text": "Smyth , P. and Wolpert , D. H. , \" Stacked Density Estimation \" , Neural Information Processing Systems 10 , MIT Press , 1998 .PDF or Postscript .Wolpert , D.H. , Knill , E. , and Grossman , T. , \" Some results concerning off - training - set and IID error for the Gibbs and Bayes optimal generalizers \" , Statistics and Computing , 8 ( 1 ) , March 1998 , pp .", "label": "", "metadata": {}, "score": "49.84796"}
{"text": "59 - 72 , 2007 .R. Polikar , \" Ensemble based systems in decision making , \" IEEE Circuits and Systems Magazine , vol .6 , no.3 , pp .21 - 45 , 2006 .Muhlbaier M. , Topalis A. , Polikar R. , \" Ensemble confidence estimates posterior probability , \" 6th Int .", "label": "", "metadata": {}, "score": "49.95172"}
{"text": "On convergence of maximum likelihood estimation of binary HMMs by EM algorithm M. Li , S. Wang and Y. Zhao The 32rd Annual Conference on Information Sciences and Systems , CISS-1998 , pp .1018 - 1024 .Short - term generation scheduling with transmission and environmental constraints using an augmented Lagrangian relaxation S. Wang , S. Shahidehpour , D. Kirschen , S. Mokhtari and G. Irisarri IEEE Trans . on Power Systems , Vol . 10 , No . 3 , pp .", "label": "", "metadata": {}, "score": "49.95689"}
{"text": "Hu et al .[112 ] suggested an AdaBoost algorithm - based ensemble which in turn uses decision stump as base classifiers .They utilized continuous and categorical features separately without any forced conversion .The proposed system was evaluated using KDD cup 99 dataset .", "label": "", "metadata": {}, "score": "49.96405"}
{"text": "Bishop [ 67 ] proposed five methods for combining the individual classifiers .The methods are Bayesian model averaging , committees , boosting , tree - based models , and conditional mixture models .Boosting is further divided into two types : ( 1 ) minimizing exponential error ; ( 2 ) error functions for boosting .", "label": "", "metadata": {}, "score": "50.003788"}
{"text": "Note that the transinformation computed for each attribute occurring in the feature vector ( apart from the one immediately preceding on the path in the tree ) for finding the optimal attribute for the new branch is now cost - dependent , since the intervals I and the thresholds .", "label": "", "metadata": {}, "score": "50.113953"}
{"text": "Page 19 .K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 107 Tou , J. T. , & Gonzalez , R. C. ( 1976 ) .Pattern recognition principles .Reading , MA : Addison Wesley .Tsekouras , G. , Sarimveis , H. , Kavakli , E. , & Bafas , G. ( 2004 ) .", "label": "", "metadata": {}, "score": "50.121117"}
{"text": "After each splitting , the C- means is applied until the existing clusters are convergent .This procedure is continued until K clusters are obtained .The relation between the PCA and the C - means has been es- tablished in Ding and He ( 2004 ) .", "label": "", "metadata": {}, "score": "50.13216"}
{"text": "497 - 501 , 1995 .L. I. Kuncheva , \" Using measures of similarity and inclusion for multiple classifier fusion by decision templates , \" Fuzzy Sets and Systems , L. I. Kuncheva , \" Using measures of similarity and inclusion for multiple classifier fusion by decision templates , \" vol .", "label": "", "metadata": {}, "score": "50.169647"}
{"text": "In the OVO or OAO strategy , classifiers are trained to discriminate between two of the k possible classes .One classifier is trained with a data subset of each possible pair of classes , then the output of the ( . k . classifiers are combined for prediction .", "label": "", "metadata": {}, "score": "50.180218"}
{"text": "Other more complicated methods are group - average - linkage , median- linkage , and centroid - linkage techniques .A cluster is conventionally represented by its centroid or pro- totype .This is desirable only for spherically shaped clusters , but causes cluster splitting for a large or arbitrarily shaped cluster , since the centroids of its subclusters can be far apart .", "label": "", "metadata": {}, "score": "50.187798"}
{"text": "Fuzzy Sets and Systems , 96 , 307 - 334 .Ritter , H. ( 1999 ) .Self - organizing maps in non - Euclidean spaces .In E. Oja , & S. Kaski ( Eds . ) , Kohonen maps ( pp .", "label": "", "metadata": {}, "score": "50.230057"}
{"text": "Widodo , A. ; Yang , B.S. Support vector machine in machine condition monitoring and fault diagnosis .Mech .Syst .Signal Process .[ Google Scholar ] .Abbasion , S. ; Rafsanjani , A. ; Farshidianfar , A. ; Irani , N. Rolling element bearings multi - fault classification based on the wavelet de - noising and support vector machine .", "label": "", "metadata": {}, "score": "50.30076"}
{"text": "KT ( Dave & Krishnapuram , 1997 ) .The subtractive clustering provides only rough estimates of the cluster centers , since the cluster centers obtained are situated at some data points .Moreover , since \u03b1 and \u03b2 are not determined from the data set and no cluster validity is used , the clusters produced may not appropriately represent the clusters .", "label": "", "metadata": {}, "score": "50.31163"}
{"text": "Wolpert , D.H. , \" A benchmark for how well neural nets generalize \" , Biological Cybernetics , 61 303 - 313 , 1989 .PDF or Postscript .The Use of Artificial - Intelligence - Based Ensembles for Intrusion Detection : A Review . 1 Department of Computer Application , Shaheed Bhagat Singh State Technical Campus , Ferozepur , Punjab 152004 , India 2 Department of Computer Science & Engineering , Punjab Institute of Technology , Kapurthala , Punjab 144601 , India .", "label": "", "metadata": {}, "score": "50.319096"}
{"text": "[ pdf ] .Augmenting naive Bayes text classifier using statistical n - gram language modeling F. Peng , D. Schuurmans and S. Wang Information Retrieval , Vol . 7 , No . 3 - 4 , pp .317 - 345 , 2004 .", "label": "", "metadata": {}, "score": "50.377235"}
{"text": "G. Wang , H. Jinxing , M. Jian , and H. Lihua , \" A new approach to intrusion detection using Artificial Neural Networks and fuzzy clustering , \" Expert Systems with Applications , vol .37 , no . 9 , pp .", "label": "", "metadata": {}, "score": "50.41527"}
{"text": "G. Wang , H. Jinxing , M. Jian , and H. Lihua , \" A new approach to intrusion detection using Artificial Neural Networks and fuzzy clustering , \" Expert Systems with Applications , vol .37 , no . 9 , pp .", "label": "", "metadata": {}, "score": "50.41527"}
{"text": "Selected subsets of feature are used to train accurate and diverse base classifiers .Final ensemble is constructed by using ensemble selection method .They reported improvement of ID in terms of detection rate and false - positive rate over other related approaches .", "label": "", "metadata": {}, "score": "50.419064"}
{"text": "Branching competitive learning network : A novel self - creating model .IEEE Transactions on Neural Networks , 15(2 ) , 417 - 429 .Xu , L. , Krzyzak , A. , & Oja , E. ( 1993 ) .Rival penalized competitive learning for clustering analysis , RBF net , and curve detection .", "label": "", "metadata": {}, "score": "50.419365"}
{"text": "Competitive algorithms for the clustering of noisy data .Fuzzy Sets and Systems , 141 , 281 - 299 .Yen , J. C. , Guo , J. I. , & Chen , H. C. ( 1998 ) .A new k - winners - take - all neural network and its array architecture .", "label": "", "metadata": {}, "score": "50.461445"}
{"text": "[ pdf ] .Combining statistical language models via the latent maximum entropy principle S. Wang , D. Schuurmans , F. Peng and Y. Zhao Machine Learning Journal : Special Issue on Learning in Speech and Language Technologies , Vol .60 , pp .", "label": "", "metadata": {}, "score": "50.59328"}
{"text": "Cluster validity with fuzzy sets .Journla of Cybernetics , 3(3 ) , 58 - 71 .Bezdek , J. ( 1981 ) .Pattern recognition with fuzzy objective function algorithms .New York : Plenum Press .Bezdek , J. C. , & Pal , N. R. ( 1995 ) .", "label": "", "metadata": {}, "score": "50.59524"}
{"text": "( 2004 ) .The ART 2A with an intermediate learning rate \u03b7 copes better with noisyinputsthanitdoeswithafastlearningrate , andtheemergent category structure is less dependent on the input presentation order ( Carpenter et al . , 1991b ) .The ART - C 2A ( He et al .", "label": "", "metadata": {}, "score": "50.603176"}
{"text": "This proves that there is neither a perfect combination strategy , nor one generally outperforming each other .This statement can be used as theoretical guideline for a malicious user to disrupt or evade the system , once combination strategy implemented is known to them .", "label": "", "metadata": {}, "score": "50.62071"}
{"text": "Pattern Recognition , 27 , 429 - 437 .Hathaway , R. J. , & Bezdek , J. C. ( 2000 ) .Generalized fuzzy c - means clustering strategies using Lpnorm distances .IEEE Transactions on Fuzzy Systems , 8(5 ) , 576 - 582 .", "label": "", "metadata": {}, "score": "50.62149"}
{"text": "10 , pp .2201 - 2212 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Khan , M. Awad , and B. Thuraisingham , \" A new intrusion detection system using support vector machines and hierarchical clustering , \" The International Journal on Very Large Data Bases , vol .", "label": "", "metadata": {}, "score": "50.653244"}
{"text": "10 , pp .2201 - 2212 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Khan , M. Awad , and B. Thuraisingham , \" A new intrusion detection system using support vector machines and hierarchical clustering , \" The International Journal on Very Large Data Bases , vol .", "label": "", "metadata": {}, "score": "50.653244"}
{"text": "Such a classifier can not learn the boundary shown in Figure 2 .Now consider a collection of circular decision boundaries generated by an ensemble of such classifiers as shown in Figure 3 , where each classifier labels the data as class O or class X , based on whether the instances fall within or outside of its boundary .", "label": "", "metadata": {}, "score": "50.664932"}
{"text": "Final ensemble prediction is the weighted voting of base classifiers .They empirically proved that by assigning proper weights to classifiers in ensemble approach improves the detection accuracy of all classes of network traffic than individual classifier .Menahem et al .", "label": "", "metadata": {}, "score": "50.670876"}
{"text": "Prominentunsupervisedself - organizingmethodsfornon - vectorial data are the temporal Kohonen map ( TKM ) , the recurrent SOM ( RSOM ) , the recursive SOM ( RecSOM ) , the SOM for structured data ( SOMSD ) , and the merge SOM ( MSOM ) .", "label": "", "metadata": {}, "score": "50.80505"}
{"text": "C. Kruegel , F. Valeur , and G. Vigna , Intrusion Detection and Correlation , Challenges and Solution , Advances in Information Security , Springer , 2005 .View at Scopus .View at Publisher \u00b7 View at Google Scholar .J. W. Haines , R. P. Lippmann , D. J. Fried , E. Tran , S. Boswell , and M. A. Zissman , \" DARPA intrusion detection system evaluation : design and procedures , \" Tech .", "label": "", "metadata": {}, "score": "50.93899"}
{"text": "C. Kruegel , F. Valeur , and G. Vigna , Intrusion Detection and Correlation , Challenges and Solution , Advances in Information Security , Springer , 2005 .View at Scopus .View at Publisher \u00b7 View at Google Scholar .J. W. Haines , R. P. Lippmann , D. J. Fried , E. Tran , S. Boswell , and M. A. Zissman , \" DARPA intrusion detection system evaluation : design and procedures , \" Tech .", "label": "", "metadata": {}, "score": "50.93899"}
{"text": "The combination of the classifiers is then based on the given instance : the classifier trained with data closest to the vicinity of the instance , according to some distance metric , is given the highest credit .One or more local experts can be nominated to make the decision ( Jacobs 1991 , Woods 1997 , Alpaydin 1996 , Giacinto 2001 ) .", "label": "", "metadata": {}, "score": "50.99437"}
{"text": "Comparison with Other Algorithms of Classification Learning .We compared the modified decision tree algorithm CAL5_OC with an extended perceptron algorithm ( DIPOL , a piecewise linear classifier [ 1 , 26 , 31 ] ) modified to include object - dependent costs .", "label": "", "metadata": {}, "score": "50.998028"}
{"text": "In the OVA or OAA strategy , classifiers are trained to determine whether an instance belongs to one of the k classes or not .Only k classifiers are needed in this strategy , but the training set for each classifier is much larger and the number of instances for the negative class can be much larger than the positive class .", "label": "", "metadata": {}, "score": "51.029633"}
{"text": "663 - 677 , September 2001 .[ pdf ] .Latent maximum entropy principle for statistical language modeling S. Wang , R. Rosenfeld and Y. Zhao IEEE Workshop on Automatic Speech Recognition and Understanding , ASRU-2001 .Recursive estimation of time - varying environments for robust speech recognition Y. Zhao , S. Wang and K. Yen IEEE International Conference on Acoustics , Speech , and Signal Processing , ICASSP-2001 .", "label": "", "metadata": {}, "score": "51.042812"}
{"text": "Using query - specific variance estimates to combine Bayesian classifiers C. Lee , R. Greiner and S. Wang The 23th International Conference on Machine Learning , ICML-2006 .[ pdf ] .An online discriminative approach to background subtraction L. Cheng , S. Wang , D. Schuurmans , T. Caelli and S. Vishwanathan IEEE International Conference on Advanced Video and Signal Based Surveillance , AVSS-2006 .", "label": "", "metadata": {}, "score": "51.05352"}
{"text": "In the case of fuzzy spherical shell clustering , the fuzzy shell thick- ness of a cluster is defined in Krishnapuram et al .( 1992 ) .The av- erage shell thickness of all clusters can be used as a cluster validity measure for shell clustering .", "label": "", "metadata": {}, "score": "51.05721"}
{"text": "Boosting methods have been crowned as the most accurate available off - the - shelf classifiers on a wide variety of datasets [ 107 ] .But , it is observed that boosting methods are sensitive to noise and outliers , especially for small datasets [ 46 , 56 , 107 ] .", "label": "", "metadata": {}, "score": "51.07887"}
{"text": "Xu , R. , & Wunsch , D. , II ( 2005 ) .Survey of clustering algorithms .IEEE Transactions on Neural Networks , 16(3 ) , 645 - 678 .Yager , R. , & Filev , D. ( 1994a ) .", "label": "", "metadata": {}, "score": "51.09987"}
{"text": "26 ] .The basic reason for adopting this taxonomy is its simplicity , popularity , and it covers basic aspects for building diverse pool of base classifiers .The author highlighted that diverse pool of classifiers can be generated by using different methods at four levels .", "label": "", "metadata": {}, "score": "51.13063"}
{"text": "A hybrid strategy can loop back and forth multiple times between methods or can embed one method within another method .In this study , we adopted and presented the taxonomy proposed by Kuncheva [ 46 ] and additional aspects borrowed from Jain et al .", "label": "", "metadata": {}, "score": "51.146973"}
{"text": "418 - 435 , 1992 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. Domingos and M. Pazzani , \" On the optimality of the simple Bayesian classifier under zero - one loss , \" Machine Learning , vol .", "label": "", "metadata": {}, "score": "51.150032"}
{"text": "418 - 435 , 1992 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. Domingos and M. Pazzani , \" On the optimality of the simple Bayesian classifier under zero - one loss , \" Machine Learning , vol .", "label": "", "metadata": {}, "score": "51.150032"}
{"text": "When it is used to fine - tune the SOM , one should start with a small \u03b7(0 ) , usually less than 0.1 .This algorithm tends to reduce the point density of ciaround the Bayesian decision surfaces .The OLVQ1 is an optimized version of N2 ?", "label": "", "metadata": {}, "score": "51.155006"}
{"text": "Multiple fault identification ability : The ability to identify multiple faults , which is difficult due to the interacting nature of most faults .Adaptability : The ability to adapt to changes in external inputs or structural changes .Reasonable storage and computational requirement : Achieve a balance in the trade - off between the computational complexity and system performance .", "label": "", "metadata": {}, "score": "51.160378"}
{"text": "7 , no . 3 , pp .788 - 792 , 1996 .G. Giacinto and F. Roli , \" Approach to the automatic design of multiple classifier systems , \" Pattern Recognition Letters , vol .22 , no . 1 , pp .", "label": "", "metadata": {}, "score": "51.1891"}
{"text": "133 - 151 , John Wiley & Sons .T. Joachims , \" Making large - scale SVM learning practical , \" in Advances in Kernel Methods - Support Vector Learning , B. Sch\u00f6lkopf , C. Burges , and A. Smola , Eds . , MIT - Press , 1999 .", "label": "", "metadata": {}, "score": "51.189194"}
{"text": "The cost must be provided by the user and depends solely on the class .The main aim of this paper is to introduce object - dependent costs given with the training objects .This allows the use of these costs locally for the construction of an interval I ( defining a region in the feature space together with the intervals of the other attributes on the path ) and independently of experts ' subjective estimates .", "label": "", "metadata": {}, "score": "51.257313"}
{"text": "K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 91 function is biologically more reasonable than a rectangular one .TheSOMusingtheGaussianneighborhoodconvergesmorequickly than that using a rectangular one ( Lo & Bavarian , 1991 ) .ck(0 ) can be selected as random values , or from available sam- ples , or any ordered initial state .", "label": "", "metadata": {}, "score": "51.317074"}
{"text": "While in bagging each instance is drawn with equal probability from the available training dataset , in wagging each instance is extracted according to a weight stochastically assigned .( iii ) Random Forest ( RF ) .This method is a version of bagging which comprised of decision trees ( DTs ) [ 95 ] .", "label": "", "metadata": {}, "score": "51.328766"}
{"text": "44 - 51 , 2010 .View at Google Scholar .G. Kumar and K. Kumar , \" An information theoretic approach for feature selection , \" Security and Communication Networks , vol .5 , pp .178 - 185 , 2012 .", "label": "", "metadata": {}, "score": "51.329136"}
{"text": "44 - 51 , 2010 .View at Google Scholar .G. Kumar and K. Kumar , \" An information theoretic approach for feature selection , \" Security and Communication Networks , vol .5 , pp .178 - 185 , 2012 .", "label": "", "metadata": {}, "score": "51.329136"}
{"text": "Robust fuzzy clustering of relational data .IEEE Transactions on Fuzzy Systems , 10(6 ) , 713 - 727 .Davies , D.L.,&Bouldin , D.W.(1979 ) .Aclusterseparationmeasure .IEEETransactions on Pattern Analysis and Machine Intelligence , 1(4 ) , 224 - 227 .", "label": "", "metadata": {}, "score": "51.359547"}
{"text": "But unfortunately for both the flat clustering like k - means and term - based clustering like LDA , there is no specific way to automatically set the right K ( # Clusters , or # Topics ) .Is there anyone has any idea how to identify topics in dynamic text ?", "label": "", "metadata": {}, "score": "51.36425"}
{"text": "Constructive clustering techniques Conventional partitional clustering algorithms assume a net- work with a fixed number of clusters ( nodes ) K. However , select- ing the appropriate value of K is a difficult task without a prior knowledge of the input data .", "label": "", "metadata": {}, "score": "51.374878"}
{"text": "The fuzzy ART ( Carpenter et al . , 1991a ) simply extends the logical AND in the ART 1 to the fuzzy AND .Both the fuzzy ART and the fuzzy AHN have an analog architecture , and function like the ART 1 but for analog input patterns .", "label": "", "metadata": {}, "score": "51.393127"}
{"text": "6 , no.3 , pp .21 - 45 , 2006 .Statistical Inference .Rajnarayan , D. , and Wolpert , D. H. \" Bias - Variance trade - offs : Novel Applications \" , invited contribution to Encyclopedia of Machine Learning , in press .", "label": "", "metadata": {}, "score": "51.421013"}
{"text": "G. Kumar and K. Kumar , \" A novel evaluation function for feature selection based upon information theory , \" in Proceedings of the IEEE International Conference on Electrical and Computer Engineering ( CCECE ' 11 ) , pp .000395- 000399 , Niagara Falls , Canada , May 2011 .", "label": "", "metadata": {}, "score": "51.42552"}
{"text": "G. Kumar and K. Kumar , \" A novel evaluation function for feature selection based upon information theory , \" in Proceedings of the IEEE International Conference on Electrical and Computer Engineering ( CCECE ' 11 ) , pp .000395- 000399 , Niagara Falls , Canada , May 2011 .", "label": "", "metadata": {}, "score": "51.42552"}
{"text": "In the first layer , there are five ANFIS modules which are trained to explore the intrusive activity from the input data .Each ANFIS module belongs to one of the classes in the dataset each providing an output which specifies the degree of relativity of the data to the specific class .", "label": "", "metadata": {}, "score": "51.43273"}
{"text": "Korber , B.T. , Farber , R.M. , Wolpert , D.H. , and Lapedes , A.S. , \" Covariation of Mutations in the V3 Loop of HIV-1 : An Information - Theoretic Analysis \" , Proceedings of the National Academy of Sciences , 90 , 7176 - 7180 , 1993 .", "label": "", "metadata": {}, "score": "51.46489"}
{"text": "As a gradient - descent technique , the C - means achieves a lo- cal optimum solution that depends on the initial selection of the cluster prototypes .The number of clusters must also be prespec- ified .Numerous improvements on the C - means have been made . 1 Nk ?", "label": "", "metadata": {}, "score": "51.5112"}
{"text": "2212 , pp .85 - 103 , 2001 .View at Google Scholar .P. Garc\u00eda - Teodoro , J. D\u00edaz - Verdejo , G. Maci\u00e1 - Fern\u00e1ndez , and E. V\u00e1zquez , \" Anomaly - based network intrusion detection : techniques , systems and challenges , \" Computers & Security , vol .", "label": "", "metadata": {}, "score": "51.514477"}
{"text": "2212 , pp .85 - 103 , 2001 .View at Google Scholar .P. Garc\u00eda - Teodoro , J. D\u00edaz - Verdejo , G. Maci\u00e1 - Fern\u00e1ndez , and E. V\u00e1zquez , \" Anomaly - based network intrusion detection : techniques , systems and challenges , \" Computers & Security , vol .", "label": "", "metadata": {}, "score": "51.514477"}
{"text": "Dynamic Cell Structure .In G. Tesauro , D. S. Touretzky , & T. K. Leen ( Eds . ) , Advances in neural information processing systems : vol . 7 ( pp .497 - 504 ) .Cambridge ( MA ) : MIT Press .", "label": "", "metadata": {}, "score": "51.582855"}
{"text": "Clusters are dense regions of objects in the data space and are separated by regions of low den- sity .The method is robust against outliers since an outlier affects clustering only in the neighborhood of this data point .It can han- dle outliers and discover clusters of arbitrary shape .", "label": "", "metadata": {}, "score": "51.642006"}
{"text": "J. 1948 , 27 .[ Google Scholar ] .Ramakrishnan , N. C4.5 .In The Top Ten Algorithms in Data Mining ; Wu , X. , Kumar , V. , Eds . ; Chapman & Hall / CRC : London , UK , 2009 ; pp . 1 - 19 .", "label": "", "metadata": {}, "score": "51.651844"}
{"text": "[ pdf ] .Direct 0 - 1 loss minimization and margin maximization with boosting S. Zhai , T. Xia , M. Tan and S. Wang Advances in Neural Information Processing Systems , NIPS-2013 , [ pdf ] .Consistency and generalization bounds for maximum entropy density estimation S. Wang , R. Greiner and S. Wang .", "label": "", "metadata": {}, "score": "51.67982"}
{"text": "1424 of Lecture Notes in Computer Science , pp .222 - 230 , Springer , Berlin , Germany , June 1998 .P. Geibel and F. Wysotzki , \" Perceptron based learning with example dependent and noisy costs , \" in Proceedings of the 20th International Conference on Machine Learning ( ICML ' 03 ) , Washington , DC , USA , 2003 .", "label": "", "metadata": {}, "score": "51.771374"}
{"text": "A linear classifier , one that is capable of learning linear boundaries , can not learn this complex non - linear boundary .However , appropriate combination of an ensemble of such linear classifiers can learn any non - linear boundary .", "label": "", "metadata": {}, "score": "51.78263"}
{"text": "The MSV algorithm minimizes the determinant of the sum of the scatter matrices of the clusters , while the MCV minimizes the sum of the volumes of the individual clusters .The behavior of the MSV is similar to that of the C - means , whereas the MCV is more versatile .", "label": "", "metadata": {}, "score": "51.782658"}
{"text": "Ensemble learning process has three phases : ( 1 ) ensemble generation ; ( 2 ) ensemble selection ; ( 3 ) ensemble integration .Ensemble generation is homogenous if the same induction algorithm is used to generate all the classifiers of the ensemble , otherwise it is said to be heterogeneous .", "label": "", "metadata": {}, "score": "51.80322"}
{"text": "The authors are not aware of any work in the literature on the application of binarization strategies to the specific context of machinery fault diagnostics for our purpose .In this paper , the OVA class binarization strategy is adopted on all single - defect classes and samples of the healthy class are added to the relabeled class , to predict concurrent defects from normal and single - defect training data .", "label": "", "metadata": {}, "score": "51.815285"}
{"text": "Ensemble learning is the process by which multiple models , such as classifiers or experts , are strategically generated and combined to solve a particular computational intelligence problem .Ensemble learning is primarily used to improve the ( classification , prediction , function approximation , etc . ) performance of a model , or reduce the likelihood of an unfortunate selection of a poor one .", "label": "", "metadata": {}, "score": "51.815796"}
{"text": "Manuscript .On determination of domains of convergence for the EM algorithm S. Wang and Y. Zhao [ ps ] Clustering is a fundamental data analysis method .It is widely used for pattern recognition , feature extraction , vector quantization ( VQ ) , image segmentation , function approximation , and data mining .", "label": "", "metadata": {}, "score": "51.819496"}
{"text": "Thresholds are fixed independently for each application - specific module .Perdisci et al .[ 88 ] proposed a clustering - based fusion module to combine multiple alarms that help to reduce the volume of alarms produced by IDSs .The produced meta - alarms provide the system administrator with a concise high - level description of the attack .", "label": "", "metadata": {}, "score": "51.821205"}
{"text": "View at Publisher \u00b7 View at Google Scholar .N. T\u00f3th and B. Pataki , \" Classification confidence weighted majority voting using decision tree classifiers , \" International Journal of Intelligent Computing and Cybernetics , vol .1 , no . 2 , pp . 169 - 192 , 2008 .", "label": "", "metadata": {}, "score": "51.89046"}
{"text": "Many researchers also used these methods to reduce the false alarms by correlating similar alarms [ 18 , 88 ] .These methods are employed to analyze root cause of false alarms [ 17 ] .( v ) Statistical Selection Method .", "label": "", "metadata": {}, "score": "51.929176"}
{"text": "ART 1 ThesimplestandmostpopularARTmodelistheART1(Carpen- ter & Grossberg , 1987a ) for learning to categorize arbitrarily many , complex binary input patterns presented in an arbitrary order .A popular fast learning implementation is given by Du and Swamy ( 2006 ) , Moore ( 1988 ) , Massey ( 2003 ) and Serrano - Gotarredona and Linares - Barranco ( 1996 ) .", "label": "", "metadata": {}, "score": "51.941532"}
{"text": "Classifier level may consider different models and may design base learners for specific ensemble methods .At third level , different subsets of features can be used for the classifiers .Finally , different data subsets , so that each base classifier in the ensemble is trained on its own data , can be used to build up the committee of learning machines .", "label": "", "metadata": {}, "score": "51.95806"}
{"text": "Remark 2 .As mentioned in the introduction , the results obtained here are applied in cognitive science for a theoretical foundation of cost - controlled human behavior .One application of the explanation of the generation and possible control of psychopathological behavior is described in a paper written together with a well - known German psychotherapist and researcher in psychoanalysis [ 25 ] .", "label": "", "metadata": {}, "score": "52.004368"}
{"text": "The classification error increased from 16.45 % to 16.85 % .Note that the classification error must increase for classes with different costs of misclassification , here within each class .Figure 5 : Classifier for MULTI_OC dataset ( with object - dependent costs ) .", "label": "", "metadata": {}, "score": "52.020912"}
{"text": "This level focuses on ensemble generation phase of ensemble learning process .Here , pool of classifiers is generated by using different feature subsets of dataset for the training of the base classifiers .Basic reason behind this level is to improve the computational efficiency of the ensemble and to increase the accuracy [ 46 ] .", "label": "", "metadata": {}, "score": "52.064327"}
{"text": "The authors are not aware of any work in the literature that studies this practical problem .In this paper , a strategy based on one- versus -all ( OVA ) class binarization is proposed to improve fault diagnostics accuracy while reducing the number of scenarios for data collection , by predicting concurrent defects from training data of normal and single defects .", "label": "", "metadata": {}, "score": "52.098915"}
{"text": "Different ensemble members were generated by training from reduced dataset .The final outputs were decided as follows : each classifier 's output is given a weight ( 0 - 1 scale ) depending on the generalization performance during the training process .", "label": "", "metadata": {}, "score": "52.121906"}
{"text": "[5 ] .Recent advances in the field of AI led many researchers to apply AI - based techniques for ID successfully .The major difference between AI - based and traditional IDSs is that only AIs can learn new rules automatically , whereas in traditional systems the security administrator must add new rules for each new attack type or each new allowed program .", "label": "", "metadata": {}, "score": "52.139915"}
{"text": "( 1 ) Decision optimization : it refers to methods to choose and optimize the combiner for a fixed ensemble of base classifiers .This method corresponds to level A ( combination level as described above ) , ( 2 ) Coverage optimization : it refers to methods for creating diverse base classifiers assuming a fixed combiner .", "label": "", "metadata": {}, "score": "52.1431"}
{"text": "The classifiers are generated by using training on KDD99 dataset .They observed in the experiments that different models provided complementary information about the patterns to be classified .The final prediction of ensemble is computed based upon highest score of base classifiers .", "label": "", "metadata": {}, "score": "52.16249"}
{"text": "The modules are network to monitor , Data collection & storage unit , Data analysis & processing unit , and signal [ 4 , 5 ] as depicted in Figure 1 .Based upon these modules , IDSs can be categorized into different classes like host - based IDS ( HIDS ) versus network - based IDS ( NIDS ) , misuse- or signature - based IDS versus anomaly - based IDS , Passive IDS versus Active IDS , and so forth [ 5 ] .", "label": "", "metadata": {}, "score": "52.246365"}
{"text": "The application of the OVO binarization strategy splits the original problem into .classifiers each with two classes , i.e. , C1 versus C2 ; C2 versus C3 ; C3 versus C4 .These class binarization strategies can also be useful in other situations .", "label": "", "metadata": {}, "score": "52.295494"}
{"text": "Someone else also wants to search about another topic in the same repository and get the subtopics .What I 'm going to do is : developing a tool which is able to identify the topics for a data which returned by search query .", "label": "", "metadata": {}, "score": "52.31497"}
{"text": "Measurement 2013 , 46 , 1551 - 1564 .[ Google Scholar ] .Boser , B.E. ; Guyon , I.M. ; Vapnik , V.N. A training algorithm for optimal margin classifiers .Proceedings of the Fifth Annual Workshop on Computational Learning Theory ( ACM ) , Pittsburgh , PA , USA , 27 - 29 July 1992 ; pp .", "label": "", "metadata": {}, "score": "52.44101"}
{"text": "Themethodincorporatesthehypervolumeanddensity criteriaasclustervaliditymeasuresandperformswellinsituations of large variability of cluster shapes , densities , and number of data points in each cluster .The C - means and the FCM are based on the minimization of the trace of the ( fuzzy ) within - cluster scatter matrix .", "label": "", "metadata": {}, "score": "52.452652"}
{"text": "The performance variation of various classifiers for different intrusions may be described by two aspects .The first aspect is the different design principles of classifiers which work to optimize different parameters .For example , SVM is designed to minimize structural risk based upon statistical theory whereas ANN to minimize empirical risk in which classification function is derived by minimizing the mean square error over the training dataset .", "label": "", "metadata": {}, "score": "52.495388"}
{"text": "Addingaconsciencetocompetitivelearning .InProcIEEEintconf neural netw , vol . 1 ( pp .117 - 124 ) .Ding , C. , & He , X. ( 2004 ) .Cluster structure of k - means clustering via principal component analysis .In : Proc 8th Pacific - Asia conf on advances in knowledge discov data mining ( PAKDD 2004 ) , ( pp .", "label": "", "metadata": {}, "score": "52.534176"}
{"text": "G. Kumar , K. Kumar , and M. Sachdeva , \" The use of artificial intelligence based techniques for intrusion detection - a review , \" Artificial Intelligence Review , vol .34 , no .4 , pp .369 - 387 , 2010 .", "label": "", "metadata": {}, "score": "52.58412"}
{"text": "G. Kumar , K. Kumar , and M. Sachdeva , \" The use of artificial intelligence based techniques for intrusion detection - a review , \" Artificial Intelligence Review , vol .34 , no .4 , pp .369 - 387 , 2010 .", "label": "", "metadata": {}, "score": "52.58412"}
{"text": "Some cluster validity measures are described and compared in Bezdek and Pal ( 1998 ) .i ?Measures based on minimal hypervolume and maximal density of clusters A good partitioning of the data usually leads to a small total hypervolume and a large average density of the clusters .", "label": "", "metadata": {}, "score": "52.599144"}
{"text": "Here , each member is trained by the same dataset with all features .To determine final prediction of ensemble , the combiner applies some method to combine the predictions of ensemble members in certain way to get final ensemble prediction , for example , average or majority vote ( most popular ) method .", "label": "", "metadata": {}, "score": "52.74437"}
{"text": "If both classifiers agree then the output is decided accordingly .If there is a conflict then the decision given by the classifier with the highest weight is taken into account .By using hybrid approach , the authors reported that Normal , Probe , and DOS could be detected with 100 % accuracy and U2R and R2L with 84 % and 99.47 % accuracies , respectively .", "label": "", "metadata": {}, "score": "52.748737"}
{"text": "703 - 711 ) .San Mateo , CA : Morgan Kaufmann .Leski , J. ( 2003a ) .Towards a robust fuzzy clustering .Fuzzy Sets and Systems , 137 , 215 - 233 .Leski , J. M. ( 2003b ) .", "label": "", "metadata": {}, "score": "52.754005"}
{"text": "Sugumaran , V. ; Ramachandran , K. Effect of number of features on classification of roller bearing faults using SVM and PSVM .Expert Syst .Appl .[ Google Scholar ] .Schwabacher , M. ; Goebel , K. A Survey of Artificial Intelligence for Prognostics .", "label": "", "metadata": {}, "score": "52.777954"}
{"text": "Iteratively , support vectors are calculated and the SVM is tested against a stopping criterion to determine if a desirable threshold of accuracy has been achieved .Otherwise the iterative process continues .The authors reported 91 % , 97 % , 23 % , and 43 % detection of Probe , DoS , U2R , and R2L attack classes .", "label": "", "metadata": {}, "score": "52.787323"}
{"text": "The concurrent - defect classification performance is then evaluated on the potential to enable multiple - defect bearing diagnostics from single - defect training data .The diagnosis accuracy of random guess classification and worst - case classification are also considered .", "label": "", "metadata": {}, "score": "52.810165"}
{"text": "Researchers also proposed that there are trainable and nontrainable ensembles .Trainable ensembles need additional training to create the ensemble ( either during the base classifier training or after all base classifiers is trained ) [ 33 ] .On the other hand , nontrainable ensembles do not need training after the base classifiers have been induced [ 55 , 65 ] .", "label": "", "metadata": {}, "score": "52.831913"}
{"text": "A robust semi - supervised boosting method using linear programming S. Zhai , T. Xia , M. Tan , S. Wang and P. Zhang IEEE GlobalSIP Symposium on Optimization in Machine Learning and Signal Processing , GlobalSIP-2013 .Direct optimization of ranking measures for learning to rank models M. Tan , T. Xia , L. Guo and S. Wang The 19th ACM SIGKDD Conference on Knowledge Discovery and Data Mining , KDD-2013 , [ pdf ] .", "label": "", "metadata": {}, "score": "52.84628"}
{"text": "IEEETransactionsonNeural Networks , 10(1 ) , 64 - 71 .Swamy , M. N. S. , & Thulasiraman , K. ( 1981 ) .Graphs , networks , and algorithms .New York : Wiley .Tam , P.K.S. , Sum , J. , Leung , C.S. , & Chan , L.W. ( 1996 ) .", "label": "", "metadata": {}, "score": "52.863087"}
{"text": "For any given instance , the class chosen by most number of classifiers is the ensemble decision .Since the training datasets may overlap substantially , additional measures can be used to increase diversity , such as using a subset of the training data for training each classifier , or using relatively weak classifiers ( such as decision stumps ) .", "label": "", "metadata": {}, "score": "52.87409"}
{"text": "63 - 77 , 2006 .View at Google Scholar . H. Zhao , F. Min , and W. Zhu , \" A backtracking approach to minimal cost feature selection of numerical data , \" Journal of Information & Computational Science .", "label": "", "metadata": {}, "score": "52.88028"}
{"text": "The penalized FCM ( Yang , 1993 ) is a convergent generalized FCM obtained by adding a penaltytermassociatedwith\u00b5ji .ThecompensatedFCM(Lin,1999 ) speeds up the convergence of the penalized FCM by modifying the penalty .A weighted FCM ( Tsekouras , Sarimveis , Kavakli , & Bafas , 2004 ) is used for fuzzy modeling towards developing a Takagi - Sugeno - Kang ( TSK ) fuzzy model of optimal structure .", "label": "", "metadata": {}, "score": "52.89892"}
{"text": "( vi ) Metalearning Method .The method employs a second level of combiner to fuse the predictions of base classifiers for determining final ensemble prediction , for example , stacking .In stacking , the predictions of base classifiers are fed to an intermediate combiner to perform trained combinations of predictions of base classifiers [ 79 ] .", "label": "", "metadata": {}, "score": "52.90094"}
{"text": "These methods try to choose the best classifiers among the set of the available base classifiers .The final prediction of ensemble is the prediction of selected base classifier or fused prediction of subset of base classifiers as described in aforementioned text .", "label": "", "metadata": {}, "score": "52.947266"}
{"text": "In Advances in Kernel Methods - Support .Vector Learning ; Schoelkopf , B. , Burges , C. , Smola , A. , Eds . ; MIT Press : Cambridge , MA , USA , 1998 .[ Google Scholar ] .", "label": "", "metadata": {}, "score": "52.949776"}
{"text": "The distributed vs. the WTA - coding representation is a primary factor differenti- ating the various ARTMAP networks .Fuzzy clustering xp , yp ? ?During training , ARTareceives a yp stream ? xp ? and ARTbreceives a stream ?During generaliza- Fuzzy clustering is an important class of clustering algorithms .", "label": "", "metadata": {}, "score": "52.953636"}
{"text": "Divisive clustering reverses the 14.2 .Distance measures and cluster representations Theinter - clusterdistanceisusuallycharacterizedbythesingle- linkage or the complete - linkage technique .The single - linkage technique calculates the inter - cluster distance using the two clos- estdatapointsindifferentclusters .Themethodismoresuitablefor finding well - separated stringy clusters .", "label": "", "metadata": {}, "score": "52.971"}
{"text": "Two recent tutorials written by the current curator of this article also provide a comprehensive overview of ensemble systems ( Polikar 2006 , Polikar 2007 ) .Diversity .The success of an ensemble system - that is , its ability to correct the errors of some of its members - rests squarely on the diversity of the classifiers that make up the ensemble .", "label": "", "metadata": {}, "score": "53.019295"}
{"text": "Calvert , B. D. , & Marinov , C. A. ( 2000 ) .Another K - winners - take - all analog neural network .IEEE Transactions on Neural Networks , 11(4 ) , 829 - 838 .Camastra , F. , & Verri , A. ( 2005 ) .", "label": "", "metadata": {}, "score": "53.058746"}
{"text": "ACM SIGKDD Explor .Newsl .[ Google Scholar ] .Provost , F. ; Kolluri , V. A survey of methods for scaling up inductive algorithms .Data Min .Knowl .Discov .[ Google Scholar ] .Roddick , J. ; Spiliopoulou , M. A survey of temporal knowledge discovery paradigms and methods .", "label": "", "metadata": {}, "score": "53.11242"}
{"text": "[ pdf ] .Probabilistic marginal cost curve and its applications S. Wang , S. Shahidehpour and N. Xiang IEEE Trans . on Power Systems , Vol . 10 , No . 3 , pp 1321 - 1328 , August 1995 .", "label": "", "metadata": {}, "score": "53.16665"}
{"text": "Wolpert , D.H. , \" On the Connection Between In - Sample Testing and Generalization Error \" , Complex Systems , 6 , 47 - 94 , 1992 .PDF or Postscript .Wolpert , D.H. , \" The Relationship Between Occam 's Razor and Convergent Guessing \" , Complex Systems , 4 , 319 - 368 , 1990 .", "label": "", "metadata": {}, "score": "53.26291"}
{"text": "The main advantage of CAL5 is the construction of smaller trees as compared to algorithms using backward pruning [ 1 ] .This results in better interpretability and rules that are easier to understand .The reason for this might lie in the use of confident probability estimates and the possibility of constructing discrete - valued attributes with a potentially arbitrary number of values .", "label": "", "metadata": {}, "score": "53.26499"}
{"text": "In the latter case , classifier outputs are often normalized to the [ 0 , 1 ] interval , and these values are interpreted as the support given by the classifier to each class , or as class - conditional posterior probabilities .", "label": "", "metadata": {}, "score": "53.268974"}
{"text": "In the first stage it combines all base classifiers using specialist classifiers which have a dichotomous model .Second stage contains k metaclassifiers which are used to learn the prediction characteristics of the specialist classifiers .Each metaclassifier is in charge of one class only and will combine all the specialist classifiers which are able to classify their own particular class .", "label": "", "metadata": {}, "score": "53.279797"}
{"text": "In the case of attributes with continuous ( real ) values , an appropriate discretization has to be performed ( see Section 3 for details ) .The information about the classes carried ( coded ) by a single attribute . is measured .", "label": "", "metadata": {}, "score": "53.29605"}
{"text": "Constrained classification on structured data C. Lee , M. Brown , R. Greiner , S. Wang and A. Murtha The 23th AAAI Conference on Artificial Intelligence , AAAI-2008 .Unsupervised discovery of compound entities for relationship extraction C. Ramakrishnan , P. Mendes , S. Wang and A. Sheth The 16th International Conference on Knowledge Engineering and Knowledge Management Knowledge Patterns , EKAW-2008 .", "label": "", "metadata": {}, "score": "53.315887"}
{"text": "The ART 2A and the ART - C 2A have clustering quality comparable to that of the C - means and the SOM , but with less computational time He et al .( 2004 ) .Other ART models The ART 3 ( Carpenter & Grossberg , 1990 ) carries out parallel searches by testing hypotheses about distributed recognition codes in a multilevel network hierarchy .", "label": "", "metadata": {}, "score": "53.339294"}
{"text": "Page 10 .98 K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 term to its distance from the input signal .This leads to an entropy maximization , that is , each unit wins at an approximately equal probability .", "label": "", "metadata": {}, "score": "53.362602"}
{"text": "These metrics depend on the ordering of the cases , not the actual predicted values .As long as ordering is preserved , it makes no difference .These metrics measure how well the attack instances are ordered before normal instances and can be viewed as a summary of model performance across all possible thresholds .", "label": "", "metadata": {}, "score": "53.38488"}
{"text": "In the cost - dependent case introduced here , this process can also be controlled by a factor of subjective importance defined by the cost of false decisions .This article is structured as follows .Section 2 introduces the new , cost - dependent information measure .", "label": "", "metadata": {}, "score": "53.43287"}
{"text": "These methods are also referred to as ' intelligent ' bearing fault diagnostics in some papers [ 23 , 24 ] .Data mining techniques applied to vibration - based bearing diagnostics include Bayesian inference [ 25 ] , HMM [ 26 ] , hidden semi - Markov model [ 27 ] , SVM [ 28 ] , ANN and GA [ 29 ] , PCA and decision tree [ 30 ] .", "label": "", "metadata": {}, "score": "53.44641"}
{"text": "In this way the base classifier focuses on the hardest instances .Then the boosting algorithm combines the base rules taking a weighted majority vote of the base classifiers which are based on the accuracy of the classifiers [ 46 ] .", "label": "", "metadata": {}, "score": "53.497005"}
{"text": "Gao , J. Digital Analysis of Remotely Sensed Imagery ; McGraw - Hill Professional : New York , NY , USA , 2008 .[ Google Scholar ] .Chen , M. ; Zheng , A. ; Lloyd , J. ; Jordan , M. ; Brewer , E. Failure diagnosis using decision trees .", "label": "", "metadata": {}, "score": "53.514275"}
{"text": "Abstract [ ps ] , [ ps ] .Almost sure convergence of Titterington 's recursive estimator for finite mixture models S. Wang and Y. Zhao IEEE International Symposium on Information Theory , ISIT-2002 .Predicting oral reading miscues J. Mostow , J. Beck , V. Winter , S. Wang and B. Tobin International Conference on Spoken Language Processing , ICSLP-2002 .", "label": "", "metadata": {}, "score": "53.555626"}
{"text": "( i ) Bagging .Bagging ( bootstrap aggregating ) is originally proposed by Breiman [ 61 ] .The method is dependent on the instability of the base classifiers .The instability of base classifiers refers to sensitivity to configuration of base classifier and/or training data .", "label": "", "metadata": {}, "score": "53.580376"}
{"text": "Tsui , K. ; Chen , V. ; Jiang , W. ; Aslandogan , Y. ; Pham , H. Data Mining Methods and Applications .In Springer Handbook of Engineering Statistics ; Springer : London , UK , 2006 ; pp .", "label": "", "metadata": {}, "score": "53.647503"}
{"text": "15 , No . 12 , pp .5439 - 5463 , 2013 .[ pdf ] .Improving alignment of system combination by using multi - objective optimization T. Xia , Z. Ji , S. Zhai , Y. Chen , Q. Liu and S. Wang Conference on Empirical Methods in Natural Language Processing , EMNLP-2013 , [ pdf ] .", "label": "", "metadata": {}, "score": "53.658882"}
{"text": "ReducingthetimecomplexityofthefuzzyC - means algorithm .IEEE Transactions on Fuzzy Systems , 10(2 ) , 263 - 267 .Krishna , K. , & Murty , M. N. ( 1999 ) .Genetic k - means algorithm .IEEE Transactions on Systems Man and Cybernetics - B , 29(3 ) , 433 - 439 .", "label": "", "metadata": {}, "score": "53.77204"}
{"text": "Learning mixture models with the latent maximum entropy principle S. Wang , D. Schuurmans , F. Peng and Y. Zhao The 20th International Conference on Machine Learning , ICML-2003 .[ ps ] .Semantic n - gram language modeling with the latent maximum entropy principle S. Wang , D. Schuurmans , F. Peng and Y. Zhao International Conference on Acoustics , Speech , ans Signal Processing , ICASSP-2003 .", "label": "", "metadata": {}, "score": "53.838436"}
{"text": "T , so as to obtain an improved distribution of the cluster centers by an unsupervised clustering ( Chen , Chen , & Chang , 1993 ; Pedrycz , 1998 ; Runkler & ? xTi , \u03b2yT i ?T(Pedrycz , 1998 ) . cT x , j , cT y , j ?", "label": "", "metadata": {}, "score": "53.903404"}
{"text": "Fusion - Based Combination Methods .These methods combine the predictions of the base classifiers to determine ensemble prediction .The major methods proposed in literature are described below .( i ) Majority Voting Method .In majority voting ensemble , each base classifier votes for specific class and the class that collects majority of vote is predicted as ensemble final prediction [ 70 - 72 ] .", "label": "", "metadata": {}, "score": "54.02584"}
{"text": "Combination Level .This level focuses on ensemble integration phase of ensemble learning process .Here , predictions of base classifiers are combined in some way to improve the performance of ensemble .The researchers proposed that there are three main ways in combining classifiers , namely , fusion , selection , and Mixture of expert systems [ 33 ] .", "label": "", "metadata": {}, "score": "54.150635"}
{"text": "In other words , it corresponds with the objects \" arriving \" at a certain node in the tree for which the next attribute is to be selected .with identical characteristics ; that is , either there is the same dominant class , there is no dominant class , or no decision was possible in either interval .", "label": "", "metadata": {}, "score": "54.170517"}
{"text": "The three classifiers are combined through a three - way majority vote .The pseudocode and implementation detail of boosting is shown in Figure 5 . \\ )Also , the ensemble error is a training error bound .Hence , a stronger classifier is generated from three weaker classifiers .", "label": "", "metadata": {}, "score": "54.21734"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. Moreira and E. Mayoraz , \" Improved pairwise coupling classification with correcting classifiers , \" in Proceedings of the 10th European Conference on Machine Learning , C. Nedellec and C. Rouveirol , Eds . , vol .", "label": "", "metadata": {}, "score": "54.464592"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. Moreira and E. Mayoraz , \" Improved pairwise coupling classification with correcting classifiers , \" in Proceedings of the 10th European Conference on Machine Learning , C. Nedellec and C. Rouveirol , Eds . , vol .", "label": "", "metadata": {}, "score": "54.464592"}
{"text": "If , during tree construction , a terminal node ( leaf ) representing an interval in which no class dominates is reached , it will be refined by using the next attribute .for branching .The attribute is selected using the transinformation measure ( see Section 2 ) to decide which is the ( locally ) best discriminating attribute , that is , which one transfers maximum information on the classes at this node .", "label": "", "metadata": {}, "score": "54.494328"}
{"text": "The predictions are combined by a majority vote .The performance of RF is comparable to AdaBoost , but is more robust to noise [ 57 , 95 ] .( iv ) Boosting .Boosting [ 96 ] is popular meta - algorithm for generating ensemble [ 33 ] .", "label": "", "metadata": {}, "score": "54.536953"}
{"text": "The ART 2A is also fast at intermediate learning rates , which captures many desirable properties of slow learning of the ART 2 such as noise tolerance .In Carpenter and Grossberg ( 1987b ) , F2 initially contains a number of uncommitted nodes , which get committed one by one upon the input presentation .", "label": "", "metadata": {}, "score": "54.55964"}
{"text": "IEEE Transactions on Computers , 20 , 68 - 86 .Zhang , T. , Ramakrishnan , R. , & Livny , M. ( 1996 ) .BIRCH :An efficient data clustering method for very large databases .In : Proc ACM SIGMOD conf on management of data ( pp .", "label": "", "metadata": {}, "score": "54.593796"}
{"text": "Growing cell structures - A self - organizing neural networks for unsupervised and supvised learning .Neural Networks , 7(9 ) , 1441 - 1460 .Fritzke , B. ( 1995a ) .A growing neural gas network learns topologies .In G. Tesauro , D. S. Touretzky , & T. K. Leen ( Eds . ) , Advances in neural information processing systems : 7 ( pp .", "label": "", "metadata": {}, "score": "54.595882"}
{"text": "4 , pp .361 - 377 , 2002 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . A. C. Tan , D. Gilbert , and Y. Deville , \" Multi - class protein fold classification using a New Ensemble Machine Learning Approach , \" Genome Informatics , vol .", "label": "", "metadata": {}, "score": "54.63748"}
{"text": "4 , pp .361 - 377 , 2002 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . A. C. Tan , D. Gilbert , and Y. Deville , \" Multi - class protein fold classification using a New Ensemble Machine Learning Approach , \" Genome Informatics , vol .", "label": "", "metadata": {}, "score": "54.63748"}
{"text": "Threshold Plurality Vote Method .This method is further generalization of majority vote method proposed by Xu et al .[ 73 ] .( iii ) Na\u00efve Bayes Decision Method : This method assumes the conditional independence between classifiers .The method selects the class with the highest posterior probability computed through the estimated class conditional probabilities and Bayes ' theorem [ 74 , 75 ] .", "label": "", "metadata": {}, "score": "54.648445"}
{"text": "2001 - 2006 , December 2006 .[ pdf ] .Stochastic analysis of lexical and semantic enhanced structural language model S. Wang , S. Wang , L. Cheng , R. Greiner and D. Schuurmans The 8th International Colloquium on Grammatical Inference , ICGI-2006 .", "label": "", "metadata": {}, "score": "54.748978"}
{"text": "347 - 352 , 1993 .L. Xu , A. Krzyzak , and C.Y. Suen , Methods for combining multiple classifiers and their applications to handwriting recognition , IEEE Trans . on Systems , Man , and Cyb . , Vol .", "label": "", "metadata": {}, "score": "54.806576"}
{"text": "Fuzzy clusteringcandealwithoverlappingclusterboundaries .Partitional clustering is dynamic , where points can move from one cluster to another .Knowledge of the shape or size of the clusters can be incorporated by using appropriate prototypes and distance measures .Partitional clustering is susceptible to local minima of its objective function , and the number of clusters K is usually requiredtobeprespecified .", "label": "", "metadata": {}, "score": "54.822372"}
{"text": "San Mateo , CA : Morgan Kaufmann .Odorico , R.(1997 ) .Learningvectorquantizationwithtrainingcount(LVQTC ) .Neural Networks , 10(6 ) , 1083 - 1088 .Pal , N. R. , Bezdek , J. C. , & Tsao , E. C. K. ( 1993 ) .", "label": "", "metadata": {}, "score": "54.846416"}
{"text": "However , there is no comprehensive review of ensembles in general and AI - based ensembles for ID to examine and understand their current research status to solve the ID problem .Here , an updated review of ensembles and their taxonomies has been presented in general .", "label": "", "metadata": {}, "score": "54.864964"}
{"text": "Fuzzy clustering with volume prototypes and adaptive cluster merging .IEEE Transactions on Fuzzy Systems , 10(6 ) , 705 - 712 .Kersten , P. R. ( 1999 ) .Fuzzy order statistics and their application to fuzzy clustering .IEEE Transactions on Fuzzy Systems , 7(6 ) , 708 - 712 .", "label": "", "metadata": {}, "score": "54.866375"}
{"text": "Comput .Chem .Eng .[ Google Scholar ] .Ko\u015bcielny , J.M. Methods of Pattern Recognition .In Fault Diagnosis Models , Artificial Intelligence , Applications ; Springer : Berlin , Germany , 2004 ; pp .89 - 91 .", "label": "", "metadata": {}, "score": "54.916786"}
{"text": "4 , pp .507 - 521 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Google Scholar .Z. S. Pan , S. C. Chen , G. B. Hu , and D. Q. Zhang , \" Hybrid neural network and C4.5 for misuse detection , \" in Proceedings of the International Conference on Machine Learning and Cybernetics , pp .", "label": "", "metadata": {}, "score": "54.942875"}
{"text": "4 , pp .507 - 521 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Google Scholar .Z. S. Pan , S. C. Chen , G. B. Hu , and D. Q. Zhang , \" Hybrid neural network and C4.5 for misuse detection , \" in Proceedings of the International Conference on Machine Learning and Cybernetics , pp .", "label": "", "metadata": {}, "score": "54.942875"}
{"text": "553 - 568 , 1997 .View at Google Scholar \u00b7 View at Scopus .L. Xu , A. Krzyzak , and C. Y. Suen , \" Methods of combining multiple classifiers and their applications to handwriting recognition , \" IEEE Transactions on Systems , Man and Cybernetics , vol .", "label": "", "metadata": {}, "score": "54.96167"}
{"text": "553 - 568 , 1997 .View at Google Scholar \u00b7 View at Scopus .L. Xu , A. Krzyzak , and C. Y. Suen , \" Methods of combining multiple classifiers and their applications to handwriting recognition , \" IEEE Transactions on Systems , Man and Cybernetics , vol .", "label": "", "metadata": {}, "score": "54.96167"}
{"text": "doi:10.1016/j.neunet.2009.08.007 .Page 2 . 90 K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 Fig . 1 .Architecture of the competitive learning network .In Section 11 , the under - utilization problem as well as strategies for avoiding this problem is narrated .", "label": "", "metadata": {}, "score": "54.967587"}
{"text": "The EM technique is derived by maximizing the log likelihood of the probability density function of the mixture model .The C - means is equivalent to the classification EM ( CEM ) algorithm corresponding to the uniform spherical Gaussian model ( Celeux & Govaert , 1992 ; Xu & Wunsch II , 2005 ) .", "label": "", "metadata": {}, "score": "55.00392"}
{"text": "Inthispaper , wegiveacomprehensive overview of competitive learning based clustering methods .Associated topics such as the under - utilization problem , fuzzy clustering , robust clustering , clustering based on non-Euclidean distance measures , supervised clustering , hierarchical clustering as well as cluster validity are also described .", "label": "", "metadata": {}, "score": "55.067947"}
{"text": "Smyth , P. and Wolpert , D. H. , \" Linearly Combining Density Estimators via Stacking \" , Machine Learning Journal , 36 , 59 - 83 , 1999 .PDF or Postscript .Wolpert , D.H. , and Macready , W.G. , \" An Efficient Method to Estimate Bagging 's Generalization Error \" , Machine Learning Journal , 35 , 41 - 55 , 1999 .", "label": "", "metadata": {}, "score": "55.080414"}
{"text": "Clustering using non - Euclidean distance measures Due to the Euclidean distance measure , conventional clustering methods favor hyperspherically shaped clusters of equal size , but have the undesirable property of splitting big and elongated clusters ( Duda & Hart , 1973 ) .", "label": "", "metadata": {}, "score": "55.181923"}
{"text": "If a vast majority of the classifiers agree with their decisions , such an outcome can be interpreted as the ensemble having high confidence in its decision .If , however , half the classifiers make one decision and the other half make a different decision , this can be interpreted as the ensemble having low confidence in its decision .", "label": "", "metadata": {}, "score": "55.2513"}
{"text": "The iris classification : ( a )The iris data set and the class information .( b )The clustering result by the FCM .( c )The clustering result by the subtractive clustering .and topology - preserving by producing a grid of cells .", "label": "", "metadata": {}, "score": "55.35618"}
{"text": "Instead , the cost values are naturally specified for individual customers .In the case of the German credit dataset , however , we did not have access to these values .In the following , we examine the example - dependent costs defined by the cost function above as the real costs of individual cases .", "label": "", "metadata": {}, "score": "55.380974"}
{"text": "R. Polikar , L. Udpa , S. S. Udpa , and V. Honavar , \" Learn++ : An incremental learning algo - rithm for supervised neural networks , \" IEEE Transactions on Systems , Man and Cybernetics Part C : Applications and Reviews , vol .", "label": "", "metadata": {}, "score": "55.394547"}
{"text": "Neural Processing Letters , 5(1 ) , 35 - 45 .Fukushima , K. ( 1980 ) .Neocognitron : A self - organizing neural network model for a mechanism of pattern recognition unaffected by shift in position .Biological Cybernetics , 36 , 193 - 202 .", "label": "", "metadata": {}, "score": "55.4011"}
{"text": "PCA based dimen- sionalityreductionsareparticularlyeffectivefortheC - meansclus- tering .Lower bounds for the C - means objective function ( 12 ) are derived as the total variance minus the eigenvalues of the data co- variance matrix ( Ding & He , 2004 ) .", "label": "", "metadata": {}, "score": "55.41577"}
{"text": "Everything else being equal , one may be tempted to choose at random , but with that decision comes the risk of choosing a particularly poor model .Using an ensemble of such models - instead of choosing just one - and combining their outputs by - for example , simply averaging them - can reduce the risk of an unfortunate selection of a particularly poorly performing classifier .", "label": "", "metadata": {}, "score": "55.42505"}
{"text": "103 - 130 , 1997 .View at Google Scholar \u00b7 View at Scopus .R. O. Duda , P. E. Hart , and D. G. Stork , Pattern Classification , John Wiley & Sons , New York , NY , USA , 2nd edition , 2001 .", "label": "", "metadata": {}, "score": "55.462124"}
{"text": "103 - 130 , 1997 .View at Google Scholar \u00b7 View at Scopus .R. O. Duda , P. E. Hart , and D. G. Stork , Pattern Classification , John Wiley & Sons , New York , NY , USA , 2nd edition , 2001 .", "label": "", "metadata": {}, "score": "55.462124"}
{"text": "Incremental learning refers to the ability of an algorithm to learn from new data that may become available after a classifier ( or a model ) has already been generated from a previously available dataset .Hence , an incremental learning algorithm must learn the new information , and retain previously acquired knowledge , without having access to previously seen data .", "label": "", "metadata": {}, "score": "55.49273"}
{"text": "Carpenter , G.A.,&Markuzon , N.(1998 ) .ARTMAP - ICandmedicaldiagnosis : Instance counting and inconsistent cases .Neural Networks , 11 , 323 - 336 .Carpenter , G. A. , & Ross , W. D. ( 1995 ) .ART - EMAP : A neural network architecture for object recognition by evidence accumulation .", "label": "", "metadata": {}, "score": "55.503025"}
{"text": "146 - 156 , 2002 .R. E. Schapire , Y. Freund , P. Bartlett , and W. S. Lee , \" Boosting the Margin : A New Explanation for the Effectiveness of Voting Methods , \" Annals of Statistics , vol .", "label": "", "metadata": {}, "score": "55.513844"}
{"text": "We think that , in practice , these cost vectors per example might be difficult to obtain , whereas a single cost value per example ( as it is used by CAL5_OC ) could be given as the cost that occurred for the respective example in the past .", "label": "", "metadata": {}, "score": "55.5412"}
{"text": "195 - 204 , 2008 .View at Publisher \u00b7 View at Google Scholar .J. Xiao and H. Song , \" A novel intrusion detection method based on adaptive resonance theory and principal component analysis , \" in Proceedings of the International Conference on Communications and Mobile Computing ( CMC ' 09 ) , pp .", "label": "", "metadata": {}, "score": "55.623756"}
{"text": "195 - 204 , 2008 .View at Publisher \u00b7 View at Google Scholar .J. Xiao and H. Song , \" A novel intrusion detection method based on adaptive resonance theory and principal component analysis , \" in Proceedings of the International Conference on Communications and Mobile Computing ( CMC ' 09 ) , pp .", "label": "", "metadata": {}, "score": "55.623756"}
{"text": "Wolpert , D.H. , \" On Bias plus Variance \" , Neural Computation , 9 , 1997 .PDF or Postscript .Wolpert , D.H. , \" The Lack of A Priori Distinctions between Learning Algorithms \" , Neural Computation , 8 , 1341 - 1390 , 1996 .", "label": "", "metadata": {}, "score": "55.636986"}
{"text": "The trees are built top - down in the usual manner through stepwise branching with new attributes to improve the discrimination .An interval in a new dimension .is formed if the hypothesis \" one class dominates in the interval \" or the alternative hypothesis \" no class dominates \" can be decided on using a user - defined confidence level by means of the estimated conditional class probabilities . \" Dominates \" means that the class probability exceeds some threshold given by the user .", "label": "", "metadata": {}, "score": "55.77569"}
{"text": "Assume that the interactions between different defect types are small , the defect types can be formulated as independent non - exclusive classes .As mentioned , the OVA class binarization strategy is adopted on all single - defect classes and samples of the healthy class are added to the relabeled class .", "label": "", "metadata": {}, "score": "55.778885"}
{"text": "Different models are generated by using a wide range of different features of client queries .The system derives automatically the parameter profiles associated with web applications ( e.g. , length and structure of parameters ) and relationships between queries ( e.g. , access times and sequences ) from the analyzed data .", "label": "", "metadata": {}, "score": "55.786583"}
{"text": "Conditional fuzzy clustering in the design of radial basis function neural networks .IEEE Transactions on Neural Networks , 9(4 ) , 601 - 612 .Richardt , J. , Karl , F. , & Muller , C. ( 1998 ) .", "label": "", "metadata": {}, "score": "55.788246"}
{"text": "The learning algorithm constructs intervals for an attribute x in order to determine its cost - sensitive transinformation as explained in Section 2 and for the splitting procedure .The best attribute for a given training set has the highest transinformation and is used to construct the next branch , followed by a recursive application of the algorithm .", "label": "", "metadata": {}, "score": "55.830788"}
{"text": "226 - 231 ) .Etzioni , O. ( 1996 ) .The World - Wide Web : Quagmire or gold mine ?Communications of the ACM , 39(11 ) , 65 - 68 .Flanagan , J. A. ( 1996 ) .", "label": "", "metadata": {}, "score": "55.834213"}
{"text": "I. Corona , D. Ariu , and G. Giacinto , \" HMM - web : a framework for the detection of attacks against web applications , \" in Proceedings of the IEEE International Conference on Communications ( ICC ' 09 ) , June 2009 .", "label": "", "metadata": {}, "score": "55.84257"}
{"text": "I. Corona , D. Ariu , and G. Giacinto , \" HMM - web : a framework for the detection of attacks against web applications , \" in Proceedings of the IEEE International Conference on Communications ( ICC ' 09 ) , June 2009 .", "label": "", "metadata": {}, "score": "55.84257"}
{"text": "26 ] grouped different classifier combination schemes into three main categories according to their architecture : ( 1 ) parallel ; ( 2 ) cascading ( or serial combination ) ; ( 3 ) hierarchical ( tree like ) .In the parallel architecture , all the individual classifiers are invoked independently , and their results are then combined by a combiner .", "label": "", "metadata": {}, "score": "55.848114"}
{"text": "( 1996 ) .Addition of training counters to individual neurons can effec- tively record the training statistics of the LVQ ( Odorico , 1997 ) .This allows for dynamic self - allocation of the neurons to classes during the course of training .", "label": "", "metadata": {}, "score": "55.863655"}
{"text": "Table 2 summarizes how the data are used in training each of the OVA binarized classifier .Note that applying the same strategy to normal cases simply generates the fault detection classifier that handles Normal versus notNormal .Table 3 illustrates how outputs of three classifiers , namely isBPFO ; isBPFI ; isBSF , can be interpreted together to determine the state - of - health of a bearing with all possible single defects and multiple defects .", "label": "", "metadata": {}, "score": "55.95072"}
{"text": "The error of this hypothesis with respect to the current distribution is calculated as the sum of distribution weights of the instances misclassified by \\(h_t\\ ) ( Equation 4 ) .AdaBoost . M1 requires that this error be less than \\(1/2\\ .", "label": "", "metadata": {}, "score": "55.959373"}
{"text": "[42 ] proposed a 3-tier hybrid approach to detect intrusions .First tier of system is a signature - based approach to filter the known attacks using black list concept .Second tier of system is anomaly detector that uses the white list concept to distinguish the normal and attack traffic that has by passed first tier .", "label": "", "metadata": {}, "score": "55.9657"}
{"text": "Finally , Section 6 concludes the paper and presents future research directions .Intrusion Detection .An intrusion detection system ( IDS ) defined as \" an effective security technology , which can detect , prevent and possibly react to the computer attacks \" is one of the standard components in security infrastructures .", "label": "", "metadata": {}, "score": "56.00182"}
{"text": "A particular limitation of boosting is that it applies only to binary classification problems .This limitation is removed with the AdaBoost algorithm .AdaBoost .Arguably the best known of all ensemble - based algorithms , AdaBoost ( Adaptive Boosting ) extends boosting to multi - class and regression problems ( Freund 2001 ) .", "label": "", "metadata": {}, "score": "56.007935"}
{"text": "Wolpert , D.H. , \" The Relationship Between the Various Supervised Learning Formalisms \" , in The Mathematics of Generalization , Ed . D. Wolpert , Addison - Wesley , 1994 .PDF or Postscript .Wolpert , D.H. , and Lapedes , A.S. , \" A Rigorous Investigation of Exhaustive Learning \" , in The Mathematics of Generalization , Ed . D. Wolpert , Addison - Wesley , 1994 .", "label": "", "metadata": {}, "score": "56.015743"}
{"text": "The use of OVA class binarization in our proposed way increases the overall bearing fault diagnostic accuracy , from 33.3 % to 66.7 % for normal and single defect types , and from 0 % to 100 % for COMB .The overall test accuracy of 75 % of the proposed method is also much better than the random guess among eight classes ( 12.5 % ) and the worst - case classification of classifying all cases to the majority class , i.e. , Normal ( 37.5 % ) .", "label": "", "metadata": {}, "score": "56.035038"}
{"text": "The KDD 99 derived from DARPA 1998 & 1999 datasets are main benchmarks used to evaluate the performance of network intrusion detection systems .However , they are suffering from a fatal drawback : failing to realistically simulate a real - world network [ 102 , 121 ] .", "label": "", "metadata": {}, "score": "56.084267"}
{"text": "This procedure is repeated recursively until all intervals of x are constructed after which the transinformation for the discretized attribute x is computed ( see Section 2 ) .Note that the statistics for a constructed interval I , that is , the set of class probabilities estimated from the training objects it includes , must be retained for the sake of computing the transinformation , even in case .", "label": "", "metadata": {}, "score": "56.08951"}
{"text": "Each cluster is represented by a mean and a J1\u00d7 J1covariance matrix , where J1 is the dimension of an input vector .Each pattern belongs to all the clusters with the probabilities of membership determined by the distributions of the corresponding clusters .", "label": "", "metadata": {}, "score": "56.10737"}
{"text": "Three different classification strategies illustrated with a 3-class problem ( a ) Simple multi - class classification ; ( b ) One- versus -one ( OVO ) class binarization ; ( c ) One- versus -all ( OVA ) class binarization .", "label": "", "metadata": {}, "score": "56.145233"}
{"text": "Pattern Recognition Letters , 24 , 2883 - 2893 .Chiang , J. , & Hao , P. ( 2003 ) .A new kernel - based fuzzy clustering approach : Support vector clustering with cell growing .IEEE Transactions on Fuzzy Systems , 11(4 ) , 518 - 527 .", "label": "", "metadata": {}, "score": "56.175022"}
{"text": "18 - 28 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. C. Ponce , \" Intrusion detection system with artificial intelligence , \" in Proceedings of the FIST Conference , Universidad Pontificia Comillas de Madrid , 2004 , edition : 1/28 .", "label": "", "metadata": {}, "score": "56.23086"}
{"text": "18 - 28 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. C. Ponce , \" Intrusion detection system with artificial intelligence , \" in Proceedings of the FIST Conference , Universidad Pontificia Comillas de Madrid , 2004 , edition : 1/28 .", "label": "", "metadata": {}, "score": "56.23086"}
{"text": "ART models ART model family includes a series of unsupervised learning models .ART networks employ a J - K recurrent architecture , which is a different form of Fig . 1 .The input layer F1 , called the comparing layer , hasJ neuronswhiletheoutputlayerF2,calledtherecognizing layer , has K neurons .", "label": "", "metadata": {}, "score": "56.249348"}
{"text": "Learning continuous latent variable models with Bregman divergence S. Wang and D. Schuurmans The 14th International Conference on Algorithmic Learning Theory , ALT-2003 .[ pdf ] .Boltzmann machine learning with the latent maximum entropy principle S. Wang , D. Schuurmans , F. Peng and Y. Zhao The Nineteenth Conference on Uncertainty in Artificial Intelligence , UAI-2003 .", "label": "", "metadata": {}, "score": "56.25776"}
{"text": "The information gain ratio is the default splitting criterion of C4.5 and C5.0 decision trees , which attempts to correct this bias by scaling information gain with the entropy of X j : . C4.5 decision tree starts modeling with the whole training set D , and each time chooses the attribute with maximum information gain ration to split the data set .", "label": "", "metadata": {}, "score": "56.272377"}
{"text": "The clustering behavior of the ART 2 was found to be similar to that of the C - means clustering ( Burke , 1991 ) .The ART 2 is computationally expensive and has difficulties in parameter selection .The ART 2A ( Carpenter et al . , 1991b ) employs the same architecture as the ART 2 , and can accurately reproduce the behavior of the ART 2 in the fast learning limit .", "label": "", "metadata": {}, "score": "56.319954"}
{"text": "Results and Discussion .The structure of this subsection is the same as Section 4.2 for the other data set , except that the worst - case classification accuracy for this data set is the same as the random guess classification accuracy .", "label": "", "metadata": {}, "score": "56.386703"}
{"text": "Figure 8 shows a particular code matrix for a 5-class problem that uses 15 encodings .This encoding , suggested in ( Dietterich 1995 ) , is a ( pseudo ) exhaustive coding because it includes all possible non - trivial and non - repeating codes .", "label": "", "metadata": {}, "score": "56.68803"}
{"text": "View at Google Scholar .N. Johnson and S. Kotz , Continuous Distributions , John Wiley , New York , NY , USA .R. A. Johnson and D. W. Wichern , Applied Multivariate Statistical Analysis , vol .4 , Prentice Hall , Englewood Cliffs , NJ , USA , 3rd edition , 1992 .", "label": "", "metadata": {}, "score": "56.697296"}
{"text": "Each classifier 's training set is generated by randomly drawing , with replacement , N examples - where N is the size of the original training dataset ; many of the original examples may be repeated in the resulting training set while others may be left out .", "label": "", "metadata": {}, "score": "56.78934"}
{"text": "PDF or Postscript .Wolpert , D.H. , \" Reconciling Bayesian and non - Bayesian analysis \" , in Maximum Entropy and Bayesian Methods 1993 , Ed .G. Heidbreder , Kluwer Academic press , 1996 .PDF or Postscript .Kohavi , R. , and Wolpert , D.H. , \" Bias Plus Variance Decomposition for Zero - One Loss Functions \" , Proceedings of the International Machine Learning Conference 13 , Ed .", "label": "", "metadata": {}, "score": "56.791412"}
{"text": "Figure 1 graphically illustrates this concept , where each classifier - trained on a different subset of the available training data - makes different errors ( shown as instances with dark borders ) , but the combination of the ( three ) classifiers provides the best decision boundary .", "label": "", "metadata": {}, "score": "56.855263"}
{"text": "The main difference between both algorithms compared with CAL5 is their application of \" backward pruning \" motivated by \" overfitting , \" since the tree construction has a priori no stopping criterion .( Overfitting is the process of inferring more structure in the tree than justified by the population from which it is drawn ( see [ 1 , Sections 5.1.5 - 5.1.7 ] for details ) .", "label": "", "metadata": {}, "score": "56.879852"}
{"text": "The task of a model is to assign a probability value to either a query as a whole or one of the query 's attributes .This probability value reflects the probability of the occurrence of the given feature value with regards to an established profile .", "label": "", "metadata": {}, "score": "56.967934"}
{"text": "Important methods proposed in the literature are described in the following section .( i )The Test and Select Method .This method describes a greedy method which adds a new classifier to ensemble if it reduces the squared error [ 71 ] .", "label": "", "metadata": {}, "score": "56.9853"}
{"text": "So , for a particular instance to be classified if all of them have different opinions , then their scores are considered .The classifier having the highest score is declared as winner and used to predict the final output of the ensemble .", "label": "", "metadata": {}, "score": "57.0931"}
{"text": "Diversity of classifiers in bagging is obtained by using bootstrapped replicas of the training data .That is , different training data subsets are randomly drawn - with replacement - from the entire training dataset .Each training data subset is used to train a different classifier of the same type .", "label": "", "metadata": {}, "score": "57.103127"}
{"text": "When K is larger than the number of actual clusters , all the actual clusters can be found and some clusters will coincide .In the noise clustering , there is only one noise cluster , while in the PCM there are K noise clusters .", "label": "", "metadata": {}, "score": "57.176556"}
{"text": "338 - 345 , 1995 .M. V. Mahoney and P. K. Chan , \" An analysis of the 1999 DARPA / Lincoln laboratory evaluation data for network anomaly detection , \" Tech .Rep. CS-200302 , Computer Science Department , Florida Institute of Technology , 2003 .", "label": "", "metadata": {}, "score": "57.21601"}
{"text": "338 - 345 , 1995 .M. V. Mahoney and P. K. Chan , \" An analysis of the 1999 DARPA / Lincoln laboratory evaluation data for network anomaly detection , \" Tech .Rep. CS-200302 , Computer Science Department , Florida Institute of Technology , 2003 .", "label": "", "metadata": {}, "score": "57.21601"}
{"text": "An equivalent way of thinking about these methods consists in encoding each class as a bit string ( named codeword ) and in training a different two - class base classifier in order to separately learn each codeword bit .When the classifiers are applied to classify new points , a suitable measure of dissimilarity between the codeword computed by the ensemble and the codeword classes is used to predict the class ( e.g. , Hamming distance ) [ 100 ] .", "label": "", "metadata": {}, "score": "57.220512"}
{"text": "Minimum rule .\\(\\alpha\\rightarrow \\infty \\Rightarrow\\ ) maximum rule .Voting based methods .The ensemble then chooses class J that receives the largest total vote : .Majority ( plurality ) voting .Under the condition that the classifier outputs are independent , it can be shown the majority voting combination will always lead to a performance improvement .", "label": "", "metadata": {}, "score": "57.248085"}
{"text": "For non - linear classification tasks , the application of kernel functions is required to transform the problem into a higher dimensional feature space to make linear separation possible .The choice of the appropriate kernel function is very important .A common choice is a polynomial kernel with the kernel parameters and the penalty margin C selected by cross - validation .", "label": "", "metadata": {}, "score": "57.262024"}
{"text": "Sensors 2012 , 12 , 5919 - 5939 .[ Google Scholar ] .Zhang , S. ; Mathew , J. ; Ma , L. ; Sun , Y. Best basis - based intelligent machine fault diagnosis .Mech .Syst .", "label": "", "metadata": {}, "score": "57.290653"}
{"text": "A comparison will be given here in after .C4.5 uses its information measure for subtree splitting in the same sense as our CAL5 , which is why our new , cost - dependent version introduced above could apply in cases where costs are given .", "label": "", "metadata": {}, "score": "57.335842"}
{"text": "4544 - 4566 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. P. W. Duin , \" The combining classifier : to train or not to train ? \" in Proceedings of 16th International Conference on Pattern Recognition ( ICPR ' 02 ) , pp .", "label": "", "metadata": {}, "score": "57.337322"}
{"text": "4544 - 4566 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. P. W. Duin , \" The combining classifier : to train or not to train ? \" in Proceedings of 16th International Conference on Pattern Recognition ( ICPR ' 02 ) , pp .", "label": "", "metadata": {}, "score": "57.337322"}
{"text": "However , decision trees allow symbolic rules to be derived and are therefore important in data mining applications .This can not be achieved in an easy manner with either neural networks or kernel methods .Moreover , it has been shown in the STATLOG project that the performance of CAL5 is comparable to that of C4.5 and even somewhat better in terms of the average rank achieved [ 26 ] .", "label": "", "metadata": {}, "score": "57.363823"}
{"text": "The only difference with the VQ algorithm is that the winning neuron is found by Ahalt et al .( 1990 ) ?In ( 22 ) , uj selecting the fairness function as F ? codewords initially and gradually turns into competitive learning as training proceeds to minimize the MSE function .", "label": "", "metadata": {}, "score": "57.432903"}
{"text": "The paper clearly shows that some researchers have applied their knowledge to address different issues at these phases for intrusion detection .But still there is a need to focus more on issues of each phase of ensemble learning .It is expected that new discoveries and a deepened understanding of different techniques suitable for different phases in ensemble learning of ID problem will be the subject of future work .", "label": "", "metadata": {}, "score": "57.465446"}
{"text": "5 , pp . 1651 - 1686 , 1998 .Y. S. Huang and C. Y. Suen , \" Behavior - knowledge space method for combination of mul - tiple classifiers , \" Proc . of IEEE Computer Vision and Pattern Recog .", "label": "", "metadata": {}, "score": "57.505585"}
{"text": "166 , no . 1 , pp .212 - 220 , 2005 .View at Google Scholar .J. A. Pomyka\u0142a , \" Approximation operations in approximation space , \" Bulletin of the Polish Academy of Sciences : Mathematics , vol .", "label": "", "metadata": {}, "score": "57.51529"}
{"text": "The predictors used in the OVA formulation are the same as that in the multi - class classification .The 18 features are fed into three SVMs that model binary decisions of whether each of them belongs to each single - defect , as in Table 2 .", "label": "", "metadata": {}, "score": "57.526855"}
{"text": "The method selects those base classifiers which perform better performance than others .Then the method combines the selected base classifiers through majority voting method ( described in previous section ) [ 89 ] .Mixture of Expert Systems .This method is a general method similar to ensemble selection [ 90 ] .", "label": "", "metadata": {}, "score": "57.571663"}
{"text": "More extensive survey of these methods can be found in the machine prognostics literature such as [ 35 , 36 ] .Fault Diagnostic Systems for Industrial Applications .No matter which approach is used in the fault diagnosis , some common requirements exist for an ideal fault diagnostic system .", "label": "", "metadata": {}, "score": "57.597736"}
{"text": "Recent examples of research papers applying SVM to bearing fault diagnostics include [ 46 - 48 ] .SVM methods have also been applied in other bearing PHM formulations such as one - class anomaly detection [ 49 ] , two - class fault detection [ 50 ] , prognostics and RUL prediction [ 51 ] .", "label": "", "metadata": {}, "score": "57.604733"}
{"text": "Typically , \u03b5 is selected as 0.15 .The training data xiis recommended to be scaled before ap- plying the method for easy selection of \u03b1 and \u03b2 .Since it is difficult to select a suitable \u03b5 for all data patterns , additional criteria for accepting / rejecting cluster centers can be used .", "label": "", "metadata": {}, "score": "57.681755"}
{"text": "The weighted majority voting then chooses the class \\(\\omega\\ ) receiving the highest total vote from all classifiers .This result may appear to go against the conventional wisdom ( see Occam 's razor ) indicating that adding too many classifiers - beyond a certain limit - would eventually lead to overfitting of the data .", "label": "", "metadata": {}, "score": "57.703983"}
{"text": "PDF or Postscript .Wolpert , D.H. , and Wolf , D.R. , \" Estimating Functions of Probability Distributions from a Finite Set of Samples \" , Physical Review E , 52 , p. 6841 , 1995 .PDF or Postscript .", "label": "", "metadata": {}, "score": "57.908134"}
{"text": "The C - means is a special case of the FCM , when \u00b5jiis unity for only one class and zero for all the other classes .Like the C - means , the FCM may find a local optimum solution , and the result is dependent on the initialization of U or cj(0 ) .", "label": "", "metadata": {}, "score": "57.918297"}
{"text": "View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .T. G. Dietterich , \" Ensemble methods in machine learning , \" in Proceedings of the Multiple Classifier Systems .First International Workshop ( MCS ' 00 ) , J. Kittler and F. Roli , Eds . , vol .", "label": "", "metadata": {}, "score": "57.92213"}
{"text": "View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .T. G. Dietterich , \" Ensemble methods in machine learning , \" in Proceedings of the Multiple Classifier Systems .First International Workshop ( MCS ' 00 ) , J. Kittler and F. Roli , Eds . , vol .", "label": "", "metadata": {}, "score": "57.92213"}
{"text": "The ART models are characterized by a set of short - term mem- ory ( STM ) and long - term memory ( LTM ) time - domain nonlinear differential equations .In the full mode , both the STM and LTM differential equations are realized .", "label": "", "metadata": {}, "score": "57.94181"}
{"text": "If a noisy point is far away from all the K clusters , it is attracted to the noise cluster .In the noise clustering approach ( Dave , 1991 ) , the constraint term is given by ?K ?The second term in the denominator , due to outliers , lowers \u00b5ji .", "label": "", "metadata": {}, "score": "57.974358"}
{"text": "We applied all four approaches to the modified version of the German credit dataset described in Section 5.3 .Table 1 shows the costs for the different classifiers estimated by 10-fold cross - validation .It should be noted that CAL5_OC performs better than DIPOL_OC and the resampling method , and slightly better than the SVMLight .", "label": "", "metadata": {}, "score": "57.991077"}
{"text": "Fuzzy c - means clustering of incomplete data .IEEE Transactions on Systems Man and Cybernetics - B , 31(5 ) , 735 - 744 .He , J. , Tan , A. H. , & Tan , C. L. ( 2004 ) .", "label": "", "metadata": {}, "score": "58.060936"}
{"text": "View at Google Scholar \u00b7 View at Scopus . Y. Guan , C. L. Myers , D. C. Hess , Z. Barutcuoglu , A. A. Caudy , and O. G. Troyanskaya , \" Predicting gene function in a hierarchical context with an ensemble of classifiers , \" Genome Biology , vol .", "label": "", "metadata": {}, "score": "58.195465"}
{"text": "View at Google Scholar \u00b7 View at Scopus . Y. Guan , C. L. Myers , D. C. Hess , Z. Barutcuoglu , A. A. Caudy , and O. G. Troyanskaya , \" Predicting gene function in a hierarchical context with an ensemble of classifiers , \" Genome Biology , vol .", "label": "", "metadata": {}, "score": "58.195465"}
{"text": "On - line Bayesian speaker adaptation by using tree - structured transformation and robust priors S. Wang and Y. Zhao IEEE International Conference on Acoustics , Speech , and Signal Processing , ICASSP-2000 .On - line Bayesian tree - structured transformation of hidden Markov models for speaker adaptation S. Wang and Y. Zhao IEEE Workshop on Automatic Speech Recognition and Understanding , ASRU-1999 .", "label": "", "metadata": {}, "score": "58.198605"}
{"text": "The classifiers obtained highest accuracies on different categories of intrusions are used to detect corresponding category of intrusions .They reported that classifier combination results the improvement of classification performance .They reported that probability of detection of 88.7 % , 97.3 % , 29.8 % , and 9.6 % with 0.4 % false alarm rate for Probe , DoS , U2R , and 0.1 % for R2L attack classes , respectively .", "label": "", "metadata": {}, "score": "58.211155"}
{"text": "This allows a wide range of classification techniques to be applied to the prognostics problem .Diagnosis with a regression method [ 42 ] is also computationally possible , though there is no physical meaning to a decimal regression estimate in between different defect types .", "label": "", "metadata": {}, "score": "58.23458"}
{"text": "The main objective of IDS is to classify intrusive and nonintrusive network activities in an efficient manner .The process of intrusion detection involves the tasks : ( 1 ) data acquisition/ collection ; ( 2 ) data Preprocessing & feature selection ; ( 3 ) model selection for data analysis ; ( 4 ) classification and result analysis [ 3 ] .", "label": "", "metadata": {}, "score": "58.286247"}
{"text": "[ Google Scholar ] .Di Maio , F. ; Ng , S. ; Tsui , K. ; Zio , E. Na\u00efve bayesian classifier for on - line remaining useful life prediction of degrading bearings .Proceedings of the 7th International Conference on Mathematical Methods in Reliability ( MMR ) , Beijing , China , 1 - 12 January 2011 .", "label": "", "metadata": {}, "score": "58.304306"}
{"text": "In this method , the ensembles are populated one classifier at the time .Each classifier is trained on selective subset of data from the original dataset .For the first base classifier , the data is selected uniformly .For successive classifiers , the sampling distribution is continuously updated so that instances that are more difficult to classify are selected more often than those that are easy to classify .", "label": "", "metadata": {}, "score": "58.311146"}
{"text": "In particular , the diagnosis accuracy of combined fault samples using C4.5 with OVA is much better than that using SVM with on the same data set ( which performed worse than the worst case classification accuracy on the COMB samples ) .", "label": "", "metadata": {}, "score": "58.321938"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .W. B. Langdon and B. F. Buxton , \" Genetic programming for improved receiver operating characteristics , \" in Proceedings of the 2nd International Conference on Multiple Classifier System , J. Kittler and F. Roli , Eds . , pp .", "label": "", "metadata": {}, "score": "58.40587"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .W. B. Langdon and B. F. Buxton , \" Genetic programming for improved receiver operating characteristics , \" in Proceedings of the 2nd International Conference on Multiple Classifier System , J. Kittler and F. Roli , Eds . , pp .", "label": "", "metadata": {}, "score": "58.40587"}
{"text": "Researchers have proposed different taxonomies to categorize ensembles .Since research of ensemble is continuously evolving , there is no existing taxonomy that covers every aspect of ensembles .The literature review of important taxonomies is as follows .Jain et al .", "label": "", "metadata": {}, "score": "58.43426"}
{"text": "Distributedlearning , recognition , andpredictionbyARTand ARTMAP neural networks .Neural Networks , 10 , 1473 - 1494 .Carpenter , G.A. ( 2003 ) .Default ARTMAP .In Proc int joint conf neural netw , vol . 2 ( pp .", "label": "", "metadata": {}, "score": "58.45418"}
{"text": "Page 12 .100 K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 point - symmetrydistanceasthedissimilaritymeasure .Themethod can effectively find clusters with symmetric shapes , such as the human face .Anumberofalgorithmsfordetectingcirclesandhyperspherical shells have been proposed as extensions of the C - means and FCM algorithms .", "label": "", "metadata": {}, "score": "58.464752"}
{"text": "The details can be further explored in [ 7 ] .KDD cup 1999 dataset is most popular publically available evaluation benchmarked dataset .But , the dataset is critically discussed in the literature for being nowadays outdated due to the type of attacks and background traffic used and for the methodology implemented for building it [ 14 ] .", "label": "", "metadata": {}, "score": "58.48831"}
{"text": "3541 , pp .326 - 335 , Seaside .Monterey , CA , June 2005 .M. Muhlbaier , A. Topalis , R. Polikar , \" Learn++ .NC : Combining Ensemble of Classifiers with Dynamically Weighted Consult - and - Vote for Efficient Incremental Learning of New Classes , \" IEEE Transactions on Neural Networks , In press , 2008 .", "label": "", "metadata": {}, "score": "58.496468"}
{"text": "It does not stop branching until it correctly classifies all instances , or each leaf node contains a minimum number of records .Note that this split is a greedy choice and the effect of future decisions is not taken into account .", "label": "", "metadata": {}, "score": "58.500053"}
{"text": "In AdaBoost . M1 , bootstrap training data samples are drawn from a distribution \\(D\\ ) that is iteratively updated such that subsequent classifiers focus on increasingly difficult instances .This is done by adjusting \\(D\\ ) such that previously misclassified instances are more likely to appear in the next bootstrap sample .", "label": "", "metadata": {}, "score": "58.5321"}
{"text": "The set of activities that violates security objectives is called intrusion .Out of these phases , the perfect detection of an intrusion is the most important .As only after correct detection of intrusion , correct reaction and recovery phase of information security can be implemented .", "label": "", "metadata": {}, "score": "58.688313"}
{"text": "[ Google Scholar ] .Elwany , A. ; Gebraeel , N. Sensor - driven prognostic models for equipment replacement and spare parts inventory .IIE Trans .[ Google Scholar ] .Chen , N. ; Tsui , K.L. Condition monitoring and remaining useful life prediction using degradation signals : Revisited .", "label": "", "metadata": {}, "score": "58.753296"}
{"text": "View at Publisher \u00b7 View at Google Scholar .V. Engen , Machine learning for network based intrusion detection [ Ph.D. thesis ] , Bournemouth University , June 2010 .G. D. Guvenir , \" Classification by voting feature intervals , \" in Proceedings of the European Conference on Machine Learning , pp .", "label": "", "metadata": {}, "score": "58.762184"}
{"text": "View at Publisher \u00b7 View at Google Scholar .V. Engen , Machine learning for network based intrusion detection [ Ph.D. thesis ] , Bournemouth University , June 2010 .G. D. Guvenir , \" Classification by voting feature intervals , \" in Proceedings of the European Conference on Machine Learning , pp .", "label": "", "metadata": {}, "score": "58.762184"}
{"text": "Data mining is to automatically search large stores of data for consistent patterns and/or relationships between variables so as to predict future behavior .The process of data mining consists of three phases , namely , data preprocessing and exploration , model selection and validation , as well as final deployment .", "label": "", "metadata": {}, "score": "58.875816"}
{"text": "Given new training data , a new pool of HMMs is generated from newly acquired data using different HMM states and initializations .The responses from these newly trained HMMs are then combined with those of the previously trained HMMs in ROC space using the incremental Boolean combination ( incrBC ) technique .", "label": "", "metadata": {}, "score": "58.906967"}
{"text": "View at Publisher \u00b7 View at Google Scholar .T. Y. Lin , \" Granular computing on binary relations - analysis of conflict and chinese wall security policy , \" in Proceedings of Rough Sets and Current Trends in Computing , vol .", "label": "", "metadata": {}, "score": "58.93564"}
{"text": "However , for the costs - sensitive versions of DIPOL and the SVM , diagrams corresponding to the ones for CAL5_OC ( Figures 4 and 5 ) can be found in [ 13 , 14 ] .The specific shape of the class borders differs : CAL5_OC computes axis - parallel borders and DIPOL_OC finds separate hyperplanes in a general position , while the shape of the borders computed by the SVM is determined by the kernel used .", "label": "", "metadata": {}, "score": "58.93604"}
{"text": "IEEE Transactions on Pattern Analysis and Machine Intelligence , 27(5 ) , 801 - 805 .Cao , Y. , & Wu , J. ( 2002 ) .Projective ART for clustering data sets in high dimensional spaces .Neural Networks , 15 , 105 - 120 .", "label": "", "metadata": {}, "score": "58.995575"}
{"text": "173 - 180 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . E. L. Allwein , R. E. Schapire , and Y. Singer , \" Reducing multiclass to binary : a unifying approach for margin classifiers , \" Journal of Machine Learning Research , vol .", "label": "", "metadata": {}, "score": "59.015152"}
{"text": "173 - 180 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . E. L. Allwein , R. E. Schapire , and Y. Singer , \" Reducing multiclass to binary : a unifying approach for margin classifiers , \" Journal of Machine Learning Research , vol .", "label": "", "metadata": {}, "score": "59.015152"}
{"text": "Final prediction of ensemble is generated by fusing different predictions of individual base classifiers .Generally fusion of predictions is performed by using majority voting method .However , this is not always possible due to the size of the dataset .", "label": "", "metadata": {}, "score": "59.017456"}
{"text": "The confidence bounds .used in the decisions are based on the parameter \u03b1 defining the confidence interval , which must be optimized .Another difference is that CAL5 is able to construct more than two values ( intervals ) of a numerical attribute used for splitting , whereas C4.5 and CART only allow binary splits .", "label": "", "metadata": {}, "score": "59.02707"}
{"text": "The hyperbolic lattice provides more freedom to map a complex information space such as language into spatial relations .Extraction of knowledge from databases is an essential task of dataanalysisanddatamining .Themulti - dimensionaldatamayin- volvequantitativeandqualitative(nominal , ordinal)variablessuch as categorical data , which is the case in survey data .", "label": "", "metadata": {}, "score": "59.027294"}
{"text": "These probabilities , accompanied by the predictions of each of the classifiers , are passed on to the selector , which then determines the final output .These probabilities can be used to stochastically select the expert , or to choose the expert according to a winner - takes - all paradigm , or as weights to combine the outputs of the multiple base classifiers [ 33 , 46 ] .", "label": "", "metadata": {}, "score": "59.0318"}
{"text": "\" [ Show abstract ] [ Hide abstract ] ABSTRACT : When no prior knowledge is available , clustering is a useful technique for categorizing data into meaningful groups or clusters .In this paper , a modified fuzzy min - max ( MFMM ) clustering neural network is proposed .", "label": "", "metadata": {}, "score": "59.042625"}
{"text": "[ Google Scholar ] .Yang , Z. ; Cai , L. ; Gao , L. ; Wang , H. Adaptive redundant lifting wavelet transform based on fitting for fault feature extraction of roller bearings .Sensors 2012 , 12 , 4381 - 4398 .", "label": "", "metadata": {}, "score": "59.067513"}
{"text": "After the support vectors are selected , the rest of features are not required .With consideration of the not completely separable case , the SVM modeling can be expressed as an optimization problem with slack variables \u03be i and error penalty C : .", "label": "", "metadata": {}, "score": "59.072273"}
{"text": "( 3 ) Since ensemble use the multiple classifiers , so it helps to find the global solution that leads to reduce the false alarm rate and increase the detection accuracy .( 4 ) Unstable base classifiers help to generate the diverse set of base classifiers for efficient ensemble .", "label": "", "metadata": {}, "score": "59.129425"}
{"text": "Data mining techniques are grouped under different names in the machine diagnostics literature .In a more recent overview [ 22 ] , data mining techniques used in mechanical systems research were grouped under the term natural computing if they were motivated or suggested by biological systems or processes .", "label": "", "metadata": {}, "score": "59.16767"}
{"text": "918 - 924 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .N. B. Anuar , H. Sallehudin , A. Gani , and O. Zakari , \" Identifying false alarm for network intrusion detection system using hybrid data mining and decision tree , \" Malaysian Journal of Computer Science , vol .", "label": "", "metadata": {}, "score": "59.19673"}
{"text": "918 - 924 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .N. B. Anuar , H. Sallehudin , A. Gani , and O. Zakari , \" Identifying false alarm for network intrusion detection system using hybrid data mining and decision tree , \" Malaysian Journal of Computer Science , vol .", "label": "", "metadata": {}, "score": "59.19673"}
{"text": "In Proc 5th Berkeley symp on math statistics and probability , Univ of California Press , Berkeley ( pp .281 - 297 ) .Majani , E. , Erlanson , R. , & Abu - Mostafa , Y. ( 1989 ) .", "label": "", "metadata": {}, "score": "59.219383"}
{"text": "We describe an integrated approach for statistical modeling of discourse structure for natural conversational speech .We developed several models and algorithms to automatically detect dialog acts from transcribed or automatically recognized words and from prosodic properties of the speech signal , and by using a statistical discourse grammar .", "label": "", "metadata": {}, "score": "59.232292"}
{"text": "Special heuristics ( decision for a majority class ) are applied in the case where an interval remains in dimension x , which satisfies neither hypothesis . , and no extension of the interval is possible due to the finite training set .", "label": "", "metadata": {}, "score": "59.26198"}
{"text": "Scaling EM ( Expectation- maximization ) clustering to large databases .MSR - TR-98 - 35 , Microsoft Re- search .Bradley , P. S. , Mangasarian , O. L. , & Steet , W. N. ( 1996 ) .Clustering via Concave minimization .", "label": "", "metadata": {}, "score": "59.300102"}
{"text": "Real - world problems often involve multiple classes , but some classification algorithms , such as SVM , are inherently binary .Class binarization strategies reduce a k - class problem into a series of binary problems for classification .Two most common strategies in the literature are one- versus -one ( OVO ) and one- versus -all ( OVA ) [ 64 ] , also named one - against - one ( OAO ) and one - against - all ( OAA ) [ 65 ] .", "label": "", "metadata": {}, "score": "59.31716"}
{"text": "[ Google Scholar ] .Li , Z. ; Wu , Z. ; He , Y. ; Fulei , C. Hidden Markov model - based fault diagnostics method in speed- up and speed - down process for rotating machinery .Mech .", "label": "", "metadata": {}, "score": "59.33721"}
{"text": "Each region is rep- resented by a codebook vector , which is the nearest neighbor to any point within the region .All vectors in each region constitute a Voronoi set .For a smooth underlying probability density p(x ) and a large K , all regions in an optimal Voronoi partition have the same within - region variance \u03c3k(Gersho , 1979 ) .", "label": "", "metadata": {}, "score": "59.380474"}
{"text": "Heterogeneous ensembles exploit the characteristics of different classifiers to improve the results over single classifier .It is supported by the fact that different base classifiers perform differently upon different categories of intrusions ( e.g. , DoS , Probe , U2R , R2L , etc . )", "label": "", "metadata": {}, "score": "59.417023"}
{"text": "73 , no . 7 - 9 , pp .1533 - 1537 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. K. Chan and S. J. Stolfo , \" On the accuracy of meta - learning for scalable data mining , \" Journal of Intelligent Information Systems , vol . 8 , no . 1 , pp .", "label": "", "metadata": {}, "score": "59.431255"}
{"text": "73 , no . 7 - 9 , pp .1533 - 1537 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. K. Chan and S. J. Stolfo , \" On the accuracy of meta - learning for scalable data mining , \" Journal of Intelligent Information Systems , vol . 8 , no . 1 , pp .", "label": "", "metadata": {}, "score": "59.431255"}
{"text": "Intell . Rev. 2008 , 30 , 19 - 37 .[ Google Scholar ] .Rifkin , R. ; Klautau , A. In defense of one- vs -all classification .J. Mach .Learn .Res .[ Google Scholar ] .", "label": "", "metadata": {}, "score": "59.43273"}
{"text": "This decision is reached by calculating a number of anomaly scores : one for the query itself and one for each attribute .A query is reported as anomalous if at least one of these anomaly scores is above the corresponding detection threshold .", "label": "", "metadata": {}, "score": "59.449097"}
{"text": "The different methods cited in the above section can be summarized in Table 1 .Fusion is the simples and popular method to combine different base classifiers .This method works on the assumption that all base classifiers are of same importance but practically it may not be true , whereas in selection method , generally , only one classifier is chosen to label an unclassified instance .", "label": "", "metadata": {}, "score": "59.458977"}
{"text": "Value of RMSE lies in range from 0 to 1 .The metric is minimized when the predicted value for each attack class coincides with the true conditional probability of that class being normal class .Generally , these metrics are computed from confusion matrix .", "label": "", "metadata": {}, "score": "59.475792"}
{"text": "This update rule ensures that the weights of all correctly classified instances and the weights of all misclassified instances always add up to \\ ( 1/2\\ .\\ )More specifically , the requirement for the training error of the base classifier to be less than \\ ( 1/2\\ ) forces teh algorithm to correct at least one mistake made by the previous base model .", "label": "", "metadata": {}, "score": "59.565323"}
{"text": "3100 , pp .232 - 253 , 2004 .View at Google Scholar . H. Zhao , F. Min , and W. Zhu , \" Test - cost - sensitive attribute reduction of data with normal distribution measurement errors , \" Mathematical Problems in Engineering , vol .", "label": "", "metadata": {}, "score": "59.61159"}
{"text": "This means that learning with CAL5 was based on a cost matrix , while learning with CAL5_OC was based on the example - dependent costs .However , evaluation was performed in regard to the example - dependent costs , since we viewed them as the real costs of the examples .", "label": "", "metadata": {}, "score": "59.648296"}
{"text": "To cover various aspects of ensembles , many researchers proposed different taxonomies for ensembles .Keeping the advantages of AI - based techniques over other techniques and ensembles , many researchers proposed AI - based ensembles for ID .However , there exists no comprehensive review of taxonomies of ensembles ( in general ) and AI - based ensembles for intrusion detection ( ID ) ( in specific ) .", "label": "", "metadata": {}, "score": "59.673668"}
{"text": "Majority of research works described here were trained & tested on KDD cup 1999 dataset .Since these works are evaluated in different environments using different training and test datasets extracted from KDD cup 1999 dataset , these studies can not be critically analyzed based upon these reported results .", "label": "", "metadata": {}, "score": "59.770927"}
{"text": "A high cost for misclassification leads to a low threshold for the corresponding class .Description of the CAL5_OC Algorithm .The following offers a concise summary and description of the cost - dependent construction of decision trees with CAL5_OC .The algorithm has the following input and parameters : . , and each branch originating from it is labeled with an interval I resulting from the interval construction , that is , discretization process as described in Section 4.1 .", "label": "", "metadata": {}, "score": "59.776897"}
{"text": "Language and task independent text categorization with simple language models F. Peng , D. Schuurmans , S. Wang North American Chapter of the Association for Computational Linguistics , NAACL-2003 .Language independent authorship attribution with character level n - Gram language modeling F. Peng , D. Schuurmans , S. Wang The 10th Conference of the European Chapter of the Association for Computational Linguistics , EACL-2003 .", "label": "", "metadata": {}, "score": "59.80699"}
{"text": "The OLVQ1 converges at a rate up to one order of magnitude faster than the LVQ1 .LVQ2 and LVQ3 comply better with the Bayesian decision sur- face .In LVQ1 , only one codebook vector ciis updated at each step , while LVQ2 and LVQ3 change two codebook vectors simultane- ously .", "label": "", "metadata": {}, "score": "59.82444"}
{"text": "If the interactions between different defect types are small enough to be ignored in modeling , a combined defect of BPFO and BPFI shall give positive for classifiers isBPFO and isBPFI , and negative for isBSF .In this case , classifiers for combined defects will not be needed and hence training data of combined defects need not be collected .", "label": "", "metadata": {}, "score": "59.84059"}
{"text": "Wang , H. ; Chen , P. A feature extraction method based on information theory for fault diagnosis of reciprocating machinery .Sensors 2009 , 9 , 2415 - 2436 .[ Google Scholar ] .Xia , Z. ; Xia , S. ; Wan , L. ; Cai , S. Spectral regression based fault feature extraction for bearing accelerometer sensor signals .", "label": "", "metadata": {}, "score": "59.84608"}
{"text": "Knowl .Data Eng .[ Google Scholar ] .Bishop , C.M. ; Nasrabadi , N.M. Pattern Recognition and Machine Learning ; Springer : New York , NY , USA , 2006 .[ Google Scholar ] .Adriaans , P. ; Zantinge , D. Data Mining ; Addison - Wesley : Harlow , UK , 1996 .", "label": "", "metadata": {}, "score": "59.847084"}
{"text": "Statistical machine learning , natural language processing and cloud computing .Education .Ph .D in Electrical Engineering , University of Illinois at Urbana - Champaign .M.S in Mathematics , University of Illinois at Urbana - Champaign .Publications .", "label": "", "metadata": {}, "score": "59.887333"}
{"text": "in the second case .For optimization , a systematic search and evaluation with 10-fold cross - validation were conducted .As a result , we arrived at a mean cost of 0.165 in the first case and 0.150 in the second .", "label": "", "metadata": {}, "score": "59.966705"}
{"text": "Early detection and diagnosis ability : Achieve a balance in the trade - off between quick response and high false alarm rate .Fault isolation ability : Be able to discriminate between different failures at different locations and different levels .Robustness : To maintain performance at an acceptable level under noise and uncertainty .", "label": "", "metadata": {}, "score": "59.976467"}
{"text": "In the baseline method , multiple classes are handled by pairwise classification as in typical SVM .The data are neither normalized nor standardized .Table 6 shows the prediction results of the multi - class classification with SVM .The correct fault diagnoses are highlighted in bold .", "label": "", "metadata": {}, "score": "59.977947"}
{"text": "The distribution \\(D\\ ) starts out as uniform ( Equation 3 in Figure 6 ) , so that all instances have equal probability to be drawn into the first data subset \\(S_1\\ .\\ )At each iteration t , a new training set is drawn , and a weak classifier is trained to produce a hypothesis \\(h_t\\ .", "label": "", "metadata": {}, "score": "60.123077"}
{"text": "177 - 189 , Springer , Cagliari , Italy , 2000 .X. Yao and M. Md.Islam , \" Evolving artificial neural network ensembles , \" IEEE Computational Intelligence Magazine , vol .3 , pp .31 - 42 , 2008 .", "label": "", "metadata": {}, "score": "60.151245"}
{"text": "177 - 189 , Springer , Cagliari , Italy , 2000 .X. Yao and M. Md.Islam , \" Evolving artificial neural network ensembles , \" IEEE Computational Intelligence Magazine , vol .3 , pp .31 - 42 , 2008 .", "label": "", "metadata": {}, "score": "60.151245"}
{"text": "If a classifier can not meet this requirement , the algorithm aborts .The normalized error \\(\\beta_t\\ , \\ ) is then computed ( Equation 5 ) so that the actual error that is in the [ 0 0.5 ] interval is mapped to [ 0 1 ] interval .", "label": "", "metadata": {}, "score": "60.23426"}
{"text": "In the batch C - means , the initial partition is arbitrarily defined by placing each input pattern into a randomly selected cluster , and the prototypes are defined to be the average of the patterns in the individual clusters .When the C - means is performed , at each step the patterns keep changing from one cluster to the closest cluster ckaccording to the nearest - neighbor rule and the prototypes are then recalculated as the mean of the samples in the clusters .", "label": "", "metadata": {}, "score": "60.24746"}
{"text": "Constructive clustering methods and other clustering methods are introduced in Sections 15 and 16 , re- spectively .Some cluster validity criteria are given in Section 17 .Two examples are given in Section 18 to demonstrate the use of the clustering methods .", "label": "", "metadata": {}, "score": "60.260395"}
{"text": "The CFA increases the den- sity of the prototypes in the input areas where the target function presents a more variable response , rather than just in the zones with more input examples ( Gonzalez et al . , 2002 ) .", "label": "", "metadata": {}, "score": "60.260887"}
{"text": "Many definitions exist to evaluate similarity between an alarm and a meta - alarm .In fact , the distance between an alarm and a meta - alarm is defined in terms of correlation between them , which is in turn defined as an application of a distance function to features characterizing each of the raised alarms .", "label": "", "metadata": {}, "score": "60.273064"}
{"text": "The prototypes ckare initialized by randomly assigning vectors from the training set .Unlike the SOM , which uses predefined static neighborhood relations , the NG determines a dynamical neighborhood relation as learning proceeds .The NG is an efficient and reliable cluster- ing algorithm , which is not sensitive to the neuron initialization .", "label": "", "metadata": {}, "score": "60.323654"}
{"text": "However , both LVQ2 and LVQ3 have the problem of refer- ence vector divergence ( Sato & Yamada , 1995 ) .In a generalization of the LVQ2 ( Sato & Yamada , 1995 ) , this problem is eliminated by applying gradient descent on a nonlinear cost function .", "label": "", "metadata": {}, "score": "60.416367"}
{"text": "Themethodisespeciallyvaluableinhandlingstrongly overlapping class distributions in the pattern space .C - means clustering Themostwell - knowndataclusteringtechniqueisthestatistical C - means , also known as the k - means ( MacQueen , 1967 ; Moody & Darken , 1989 ; Tou & Gonzalez , 1976 ) .", "label": "", "metadata": {}, "score": "60.49224"}
{"text": "For tree construction in the case of attributes with continuous values , these must be discretized to transform them into attributes with discrete values .The discrete values constructed represent intervals . is the cost - dependent transinformation which can be regarded as a generalization of Shannon information and will be used in the construction of cost - dependent decision trees .", "label": "", "metadata": {}, "score": "60.517563"}
{"text": "Application such systems has been reported in chemical systems , manufacturing systems , mechanical systems , electrical systems , telecommunication systems , automobile control and computer disk drive control .The nonlinear continuous dynamic in NHDS will change due to occurrence of some unknown discrete events .", "label": "", "metadata": {}, "score": "60.545097"}
{"text": "Tse , P. ; Peng , Y. ; Yam , R. Wavelet analysis and envelope detection for rolling element bearing fault diagnosis their effectiveness and flexibilities .J. Vib .Acoust .[ Google Scholar ] .Peng , Z. ; Tse , P.W. ; Chu , F. A comparison study of improved Hilbert - Huang transform and wavelet transform : Application to fault diagnosis for rolling bearing .", "label": "", "metadata": {}, "score": "60.639893"}
{"text": "206 - 217 , 2003 .View at Google Scholar .R. Moskovitch , Y. Elovici , and L. Rokach , \" Detection of unknown computer worms based on behavioral classification of the host , \" Computational Statistics and Data Analysis , vol .", "label": "", "metadata": {}, "score": "60.696808"}
{"text": "206 - 217 , 2003 .View at Google Scholar .R. Moskovitch , Y. Elovici , and L. Rokach , \" Detection of unknown computer worms based on behavioral classification of the host , \" Computational Statistics and Data Analysis , vol .", "label": "", "metadata": {}, "score": "60.696808"}
{"text": "Winner - take - all cellular neural networks .IEEE Transactions on Circuits and Systems - II , 40(3 ) , 184 - 190 .Serrano - Gotarredona , T. , & Linares - Barranco , B. ( 1996 ) .A modified ART 1 algorithm more suitable for VLSI implementations .", "label": "", "metadata": {}, "score": "60.92097"}
{"text": "Output code method works by manipulating the coding of classes in multiclass classification problems .Here ensembles are designed to partially correct errors performed by the base classifiers by exploiting the redundancy in the bit - string representation of the classes [ 25 , 105 ] .", "label": "", "metadata": {}, "score": "60.92321"}
{"text": "In Section 4.2 , a detailed description of the algorithm CAL5_OC is provided based on the ideas presented in Section 4.1 .Using Cost - Dependent Decision Thresholds in the Case of Object - Dependent Costs .This means that we have a training set .", "label": "", "metadata": {}, "score": "61.0744"}
{"text": "the excitation response or neighbor function , which defines the response of neuron k when cwis the excitation center .If hkw(t ) takes \u03b4kw , ( 8) reduces to the SCL .2 \u03c32(t ) ( 9 ) \u03c4 , \u03c30being a positive constant and\u03c4 a .", "label": "", "metadata": {}, "score": "61.19187"}
{"text": "Errors of type 1 correspond to misclassifications for both classes occurring in intervals for which a class decision was made .Errors of type 2 correspond to misclassifications in intervals where no confident class decision could be made and the final class was assigned based on a majority decision .", "label": "", "metadata": {}, "score": "61.27931"}
{"text": "It has a fixed number of processing units , K , with no lateral connection .A data optimal topological ordering is achieved by using nei- ghborhood ranking within the input space at each training step .To find its neighborhood rank , each neuron compares its distance to the input vector with those of all the other neurons to the input vector .", "label": "", "metadata": {}, "score": "61.30712"}
{"text": "L. Lam and C. Y. Suen , \" Application of majority voting to pattern recognition : an analysis of its behavior and performance , \" IEEE Transactions on Systems , Man , and Cybernetics A , vol .27 , no .", "label": "", "metadata": {}, "score": "61.556152"}
{"text": "L. Lam and C. Y. Suen , \" Application of majority voting to pattern recognition : an analysis of its behavior and performance , \" IEEE Transactions on Systems , Man , and Cybernetics A , vol .27 , no .", "label": "", "metadata": {}, "score": "61.556152"}
{"text": "Wolpert , D.H. , \" The Bootstrap is Inconsistent with Probability Theory \" , in Maximum Entropy and Bayesian Methods 1995 , Ed . K. Hanson and R. Silver , Kluwer Academic press , 1996 .PDF or Postscript .Wolpert , D.H. , Strauss , C.E. , \" What Bayes has to say about the evidence procedure \" , in Maximum Entropy and Bayesian Methods 1993 , Ed .", "label": "", "metadata": {}, "score": "61.580803"}
{"text": "96K.-L. The condition must be valid ? \u00b5ji ? m determines the fuzziness of the partition produced , and reduces the influence of small membership values .By minimizing ( 18 ) subject to ( 19 ) , the optimal solution is derived as ?", "label": "", "metadata": {}, "score": "61.605576"}
{"text": "First objective is to present an updated review of ensembles and their taxonomies in general for supervised classification .Third objective is to highlight research gaps and directions in developing efficient ensemble for ID .Paper Overview The rest of paper is organized as follows .", "label": "", "metadata": {}, "score": "61.789368"}
{"text": "HIDSs and NIDSs have been designed to perform misuse detection and anomaly detection .Anomaly based ID allows detecting unknown attacks for which the signatures have not yet been extracted [ 2 ] .In practice , anomaly detectors generate false alarms due , in large part , to the limited data used for training and to the complexity of underlying data distributions that may change dynamically over time .", "label": "", "metadata": {}, "score": "61.904865"}
{"text": "Since humans achieve 84 % on this task ( with chance performance at 35 % ) we find these results encouraging .A New Information Measure Based on Example - Dependent Misclassification Costs and Its Application in Decision Tree Learning .Faculty of Electrical Engineering and Computer Science , University of Technology Berlin , Sekr .", "label": "", "metadata": {}, "score": "61.965527"}
{"text": "Outliers can be easily identified in hierarchical clustering , since they merge with other points less often due to their larger distances from the other points and the number of outliers is typically much less than that in a cluster .The number of clusters K need not be specified , and the local minimum problem arising from initialization does not occur .", "label": "", "metadata": {}, "score": "61.99287"}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : Clustering is a fundamental data analysis method .It is widely used for pattern recognition , feature extraction , vector quantization ( VQ ) , image segmentation , function approximation , and data mining .", "label": "", "metadata": {}, "score": "62.056995"}
{"text": "Supervisor classifier selects the most suitable member of the ensemble on the basis of the available input data .Two additional components are incorporated in mixture of expert 's model : ( 1 ) a gating network ; ( 2 ) selector .", "label": "", "metadata": {}, "score": "62.06198"}
{"text": "In W. Gerstner , A. Germond , M. Hasler , & J. D. Nicoud ( Eds . ) , LNCS : vol.1327 .ProcIntconfartificialneuralnetw , Lausanne , Switzerland(pp.613 - 618 ) .Berlin : Springer .Fritzke , B. ( 1997b ) .", "label": "", "metadata": {}, "score": "62.167725"}
{"text": ", 1996 ) .All these robust algorithms are highly dependent on the initial values and adjustment of \u03b2j .The robust competitive agglomeration ( RCA ) algorithm ( Frigui & Krishnapuram , 1999 ) combines the advantages of both the hierarchical and partitional clustering techniques .", "label": "", "metadata": {}, "score": "62.205086"}
{"text": "Syst .Signal Process .[ Google Scholar ] .Tran , V. ; Yang , B. ; Oh , M. ; Tan , A. Fault diagnosis of induction motor based on decision trees and adaptive neuro - fuzzy inference .Expert Syst .", "label": "", "metadata": {}, "score": "62.207024"}
{"text": "\" [ Show abstract ] [ Hide abstract ] ABSTRACT : This paper proposes a revised counter - propagation network ( CPN ) model by integrating rough set in structural damage detection , applicable for processing redundant and uncertain information as well as assessing structural health states .", "label": "", "metadata": {}, "score": "62.24848"}
{"text": "k - winners - take - all ( k - WTA ) is a process of se- lecting the k largest components from an N - dimensional vector .It is a key task in decision making , pattern recognition , associative memories , or competitive learning networks .", "label": "", "metadata": {}, "score": "62.336365"}
{"text": "In the interval algorithm , this triggers the extension of a tentative interval for x so that more examples can be included .Now we focus on a single attribute x and describe the cost - sensitive interval construction for it .", "label": "", "metadata": {}, "score": "62.353752"}
{"text": "Above \u03b5 , ckis definitely accepted as a cluster center , while below \u03b5 it is definitely rejected .If P(k ) falls between the two thresholds , a trade - off between a reasonable potential and its distance to the existing cluster centers must been examined .", "label": "", "metadata": {}, "score": "62.494106"}
{"text": "Results and Discussion .The testing performance in terms of prediction accuracy of the proposed method is compared with that of a simple multi - class classification using the same data split .The confusion matrices are shown in the corresponding subsections , followed by discussions of the results .", "label": "", "metadata": {}, "score": "62.497974"}
{"text": "ART models are char- acterizedbysystemsofdifferentialequationsthatformulatestable self - organizing learning methods .Instar and outstar learning rules are the two learning rules used .The ART has the ability to adapt , yet not forget the past training , and it overcomes the so - called stability - plasticity dilemma ( Carpenter & Grossberg , 1987a ; Grossberg , 1976 ) .", "label": "", "metadata": {}, "score": "62.5036"}
{"text": "The reason may be either class imbalance in training dataset or 11 attack types in these two classes only appear in the test dataset , not the training set , and they constitute more than 50 % of the data .However , ensembles utilized the combined knowledge of multiple classifiers to improve the performance in these minority attacks classes .", "label": "", "metadata": {}, "score": "62.613712"}
{"text": "( Ed . ' s ) , 2001 , in press .PDF or Postscript .Wolpert , D.H. \" The Supervised Learning No - Free - Lunch Theorems , \" invited contribution to World conference on Soft Computing 2001 , in press .", "label": "", "metadata": {}, "score": "62.73372"}
{"text": "IEEE Transactions on Neural Networks , 14(1 ) , 89 - 102 .Karypis , G. , Han , E. H. , & Kumar , V. ( 1999 ) .Chameleon : Hierarchical clustering using dynamic modeling cover feature .Computer , 12 , 68 - 75 .", "label": "", "metadata": {}, "score": "62.760883"}
{"text": "This level focuses on ensemble selection phase of ensemble learning process .It determines which base classifiers are used to constitute the ensemble prediction .Many researchers investigated the combination of base classifiers at this level very advantageous particularly for ID [ 23 , 28 - 30 , 32 - 44 ] .", "label": "", "metadata": {}, "score": "62.842476"}
{"text": "The inter - ART vigilance resetting sig- nal is a form of backpropagation of information .Given a stream of input - output pairs ? ? tion , when a pattern x is presented to ARTa , its prediction is pro- duced at ARTb .", "label": "", "metadata": {}, "score": "62.87181"}
{"text": "Selection is guaranteed by design to give at least the same training accuracy as the best individual classifier .However , the model might overtrain , giving a deceptively low training error .To guard against overtraining we may use confidence intervals and nominate a classifier only when it is significantly better than the others [ 46 ] .", "label": "", "metadata": {}, "score": "62.927658"}
{"text": "There are several scenarios where using an ensemble based system makes statistical sense , which are discussed below in detail .For example , we typically ask the opinions of several doctors before agreeing to a medical procedure , we read user reviews before purchasing an item ( particularly big ticket items ) , we evaluate future employees by checking their references , etc .", "label": "", "metadata": {}, "score": "63.040916"}
{"text": "This problem is caused by the fact that only the winning prototype is updated for every input .Initializing the prototypes with random input vectors can reduce the probability of the under - utilization problem , but does not eliminate it .", "label": "", "metadata": {}, "score": "63.091885"}
{"text": "In other words , there are interactions between different bearing defect types and this complicates the bearing fault diagnosis process .However , in terms of problem formulation , if the interaction between defect types is small enough , combined defects can be identified from single defect classifiers , with an OVA class binarization strategy .", "label": "", "metadata": {}, "score": "63.095474"}
{"text": "x .i .b . ) for .i .n .The optimal separating hyperplane is the separating hyperplane with greatest distance between the plane and the nearest data points on both sides , i.e. , the boundary in the middle of the maximum geometrical margin between the two classes .", "label": "", "metadata": {}, "score": "63.1148"}
{"text": "In each case , a final decision is made by combining the individual decisions of several experts .In doing so , the primary goal is to minimize the unfortunate selection of an unnecessary medical procedure , a poor product , an unqualified employee or even a poorly written and misguiding article .", "label": "", "metadata": {}, "score": "63.204643"}
{"text": "101 - 115 , 2008 .View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . A. N. Toosi and M. Kahani , \" A new approach to intrusion detection based on an evolutionary soft computing model using neuro - fuzzy classifiers , \" Computer Communications , vol .", "label": "", "metadata": {}, "score": "63.213787"}
{"text": "101 - 115 , 2008 .View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . A. N. Toosi and M. Kahani , \" A new approach to intrusion detection based on an evolutionary soft computing model using neuro - fuzzy classifiers , \" Computer Communications , vol .", "label": "", "metadata": {}, "score": "63.213787"}
{"text": "As in any modeling problems , the actual formulation used in the diagnosis / prognosis depends on the data available and how the analyst formulates the problem .For example , bearing diagnostics can also be modeled as a clustering problem [ 40 ] for unsupervised learning .", "label": "", "metadata": {}, "score": "63.222347"}
{"text": "2475 of Lecture Notes in Computer Science , 2002 .Shaojun Wang is a faculty member at Kno.e.sis Center with research interest in statistical machine learning , natural language processing and cloud computing .He directs Machine Learning and Natural Language Processing Lab , where the research projects are funded by NSF , AFOSR , DoD and Google with all emphasizing on scalability and parallel / distributed approaches to process extremely large scale datasets .", "label": "", "metadata": {}, "score": "63.242287"}
{"text": "Decision Template Method .The main concept of decision template is to compare a prototypical answer of ensemble for prediction of class of a given instance .The method may use different similarity measure to evaluate the matching between matrix of classifiers output and matrix of templates .", "label": "", "metadata": {}, "score": "63.24492"}
{"text": "Error - correcting Output Coding ( ECOC ) [ 100 ] , and data - driven ECOC [ 101 ] .( vii ) Troika .Troika is an improvement to stacking proposed by Menahem et al .[ 106 ] .", "label": "", "metadata": {}, "score": "63.408638"}
{"text": "The process is known as winner - take - all ( WTA ) .2 ( 5 ) ( 6 ) ( 7 ) i ?There are also some circuits for realizing the WTA function ( Lazzaro , Lyckebusch , Mahowald , & Mead , 1989 ; Tam et al .", "label": "", "metadata": {}, "score": "63.41758"}
{"text": "[ Google Scholar ] .Barkov , A. ; Barkova , N. Condition assessment and life prediction of rolling element bearings .Sound Vib .[ Google Scholar ] .Figure 1 .Three different classification strategies illustrated with a 3-class problem ( a ) Simple multi - class classification ; ( b ) One- versus -one ( OVO ) class binarization ; ( c ) One- versus -all ( OVA ) class binarization .", "label": "", "metadata": {}, "score": "63.4656"}
{"text": "The Use of Artificial - Intelligence - Based Ensembles for Intrusion Detection : A Review . 1 Department of Computer Application , Shaheed Bhagat Singh State Technical Campus , Ferozepur , Punjab 152004 , India 2 Department of Computer Science & Engineering , Punjab Institute of Technology , Kapurthala , Punjab 144601 , India .", "label": "", "metadata": {}, "score": "63.513355"}
{"text": "This is achieved for .( and no costs ) constructs two discriminating straight lines parallel to the x -axis .The region between them indicates that no statistically safe decision is possible here due to the nonseparability and equal probabilities of both classes , as attribute .", "label": "", "metadata": {}, "score": "63.520897"}
{"text": "[ pdf ] .Boosting with incomplete information G. Haffari , Y. Wang , S. Wang , G. Mori and F. Jiao The 25th International Conference on Machine Learning , ICML-2008 .[ pdf ] .Segmenting brain tumors using pseudo -- conditional random fields C. Lee , S. Wang , A. Murtha , M. Brown and R. Greiner The 11th International Conference on Medical Image Computing and Computer Assisted Intervention , MICCAI-2008 .", "label": "", "metadata": {}, "score": "63.56916"}
{"text": "Baseline : Multi - Class Classification .Table 9 shows the prediction results of the multi - class classification with C4.5 .The correct fault diagnoses are highlighted in bold .Multiple Defects : One- Versus -All ( OVA ) Class Binarization Performance .", "label": "", "metadata": {}, "score": "63.71471"}
{"text": "The goal of this stage is to produce Troika 's final prediction .The inputs of the super classifier are the outputs produced by the metaclassifiers from the previous stage .In the training phase , the super classifier learns the conditions which enable one or more of the metaclassifiers to predict correctly or incorrectly .", "label": "", "metadata": {}, "score": "63.784367"}
{"text": "In this case , the interactions between different defect types have to be modeled and vibration data of different combinations of defects need to be collected , if fault diagnostics of multiple defects ( which occur at a late stage of bearing degradation ) is desired .", "label": "", "metadata": {}, "score": "63.839127"}
{"text": "In Section 5 it will be shown that high costs of misclassification lead to an enlargement of the decision regions for the corresponding classes .Comparison with Other Decision Tree Algorithms .CAL5 has been compared with other algorithms for classification learning , particularly within the scope of the famous European STATLOG project described in detail in the book [ 1 ] .", "label": "", "metadata": {}, "score": "63.868607"}
{"text": "Summary Clustering is one of the most important data analysis methods .Inthispaper , weprovideastate - of - the - artsurveyandintroduction to neural network based clustering .Various aspects of clustering are addressed .Two examples are given to illustrate the application of clustering .", "label": "", "metadata": {}, "score": "63.889935"}
{"text": "Most of attacks are likely to generate multiple related alarms .This flood of mostly false alarms makes it very difficult to identify the hidden true positives ( i.e. , those alarms that correctly flag attacks ) [17 ] .Current intrusion - detection systems do not make it easy for network administrator to logically group related alerts .", "label": "", "metadata": {}, "score": "63.932182"}
{"text": "The IDSs are evaluated by comparing the true - positive rate ( i.e. , the percentage of attacks that were correctly recognized ) and the false - positive rate ( i.e. , the percentage of legitimate traffic flagged as an attack ) .", "label": "", "metadata": {}, "score": "63.964752"}
{"text": "This means that there is some overgeneralization of class 0 increasing the error , yet optimizing the mean risk ( cost ) .Application in a Real - Life Domain : German Credit Dataset .We conducted experiments with the German credit dataset from the STATLOG project [ 1 ] .", "label": "", "metadata": {}, "score": "64.13992"}
{"text": "[ Google Scholar ] .Jardine , A. ; Lin , D. ; Banjevic , D. A review on machinery diagnostics and prognostics implementing condition - based maintenance .Mech .Syst .Signal Process .[ Google Scholar ] .Worden , K. ; Staszewski , W. ; Hensman , J. Natural computing for mechanical systems research : A tutorial overview .", "label": "", "metadata": {}, "score": "64.14856"}
{"text": "Selection of base classifiers may be done from pool of classifiers , which are trained using different induction algorithms ( called heterogeneous ensembles ) or the same induction algorithm ( called homogeneous ensembles ) .Many researcher generated ensemble by selecting heterogeneous base classifiers [ 23 , 24 , 27 - 29 , 36 ] .", "label": "", "metadata": {}, "score": "64.21977"}
{"text": "View at Scopus .W. Leigh , R. Purvis , and J. M. Ragusa , \" Forecasting the NYSE composite index with technical analysis , pattern recognizer , neural network , and genetic algorithm : a case study in romantic decision support , \" Decision Support Systems , vol .", "label": "", "metadata": {}, "score": "64.45993"}
{"text": "View at Scopus .W. Leigh , R. Purvis , and J. M. Ragusa , \" Forecasting the NYSE composite index with technical analysis , pattern recognizer , neural network , and genetic algorithm : a case study in romantic decision support , \" Decision Support Systems , vol .", "label": "", "metadata": {}, "score": "64.45993"}
{"text": "PDF or Postscript .Wolpert , D.H. , \" On the Bayesian ' Occam Factors ' Argument for Occam 's Razor \" , in Computational Learning Theory and Natural Learning Systems III , Ed .T. Petsche et al . , MIT Press , 1995 .", "label": "", "metadata": {}, "score": "64.48439"}
{"text": "( viii ) Boolean Combination ( BC ) Methods .Boolean functions especially the conjunction AND and disjunction OR operations have recently been investigated to combine predictions of different classifiers within the ROC space [ 2 ] .These methods were shown to improve performance .", "label": "", "metadata": {}, "score": "64.509636"}
{"text": "Several other metrics are utilized by researchers to measure the performance of IDS .These metrics can be divided into three classes : threshold , ranking , and probability metrics [ 7 , 8 ] .Threshold metrics include classification rate ( CR ) , F - measure ( FM ) , and cost per example ( CPE ) .", "label": "", "metadata": {}, "score": "64.66142"}
{"text": "Each grid point is a potential cluster center .The potential for each grid is calculated based on the density of the surrounding data points .The grid with the highest potential is selected as the first cluster center and then the potential values of all the other grids are reduced according to their distances to the first cluster center .", "label": "", "metadata": {}, "score": "64.68007"}
{"text": "The codebook can be designed by minimizing the expected squared quantization error ? where c is a function of x and ci .E - mail addresses : kldu@ieee.org , kldu@ece.concordia.ca .Voronoi tessellation , also called Voronoi diagram , is useful for demonstrating VQ results .", "label": "", "metadata": {}, "score": "64.745605"}
{"text": "Polygonal shape description of plane boundaries .In : Troncale L ( ed ) .Systems science and science , 1 , SGSR , Louisville , KY ( pp .295 - 301 ) .Andrew , L. ( 1996 ) .", "label": "", "metadata": {}, "score": "64.7749"}
{"text": "The negative sign converts the distance metric into a support value , whose largest value can be zero in case of a perfect match .Note that this output does not match any of the code words exactly , and this is where the error correcting ability of the ECOC lies .", "label": "", "metadata": {}, "score": "65.00921"}
{"text": "The loss occurring in a single case can be seen as the misclassification costs for that example in a natural way .In the case of a good customer , the cost is the bank 's loss if that customer has been rejected .", "label": "", "metadata": {}, "score": "65.04984"}
{"text": "The classifiers are generated by using different feature subset of training dataset .They proved empirically that result of the proposed method is improved .They performed experiments by using 41 features and 12 features of KDD dataset .They reported 98.39 % , 98.75 % , 99.70 % , and 99.09 % detection of Probe , DoS , U2R , and R2L attack classes using 41 features of KDD dataset .", "label": "", "metadata": {}, "score": "65.1492"}
{"text": "View at Google Scholar .J. McHugh , \" Testing intrusion detection systems : a critique of the 1998 and 1999 DARPA intrusion detection system evaluations as performed by Lincoln laboratory , \" ACM Transactions on Information and System Security , vol .", "label": "", "metadata": {}, "score": "65.19434"}
{"text": "View at Google Scholar .J. McHugh , \" Testing intrusion detection systems : a critique of the 1998 and 1999 DARPA intrusion detection system evaluations as performed by Lincoln laboratory , \" ACM Transactions on Information and System Security , vol .", "label": "", "metadata": {}, "score": "65.19434"}
{"text": "[ Google Scholar ] .Farrar , C.R. ; Worden , K. Support Vector Machines .In Structural Health Monitoring : A Machine Learning Perspective ; John Wiley & Sons : Chichester , UK , 2013 ; pp .377 - 380 .", "label": "", "metadata": {}, "score": "65.29708"}
{"text": "Bagging works well if classifier predictions of base classifiers were independent and classifiers had the same individual accuracy , and then the majority vote is guaranteed to improve on the individual performance [ 46 ] .( ii ) Wagging .Wagging method is a variant of bagging .", "label": "", "metadata": {}, "score": "65.32544"}
{"text": "M. P. Perrone and L. N. Cooper , \" When networks disagree : ensemble methods for hybrid neural networks , \" in Artificial Neural Networks for Speech and Vision , R. J. Mammone , Ed . , pp .126 - 142 , Chapman & Hall , London , UK , 1993 .", "label": "", "metadata": {}, "score": "65.377304"}
{"text": "M. P. Perrone and L. N. Cooper , \" When networks disagree : ensemble methods for hybrid neural networks , \" in Artificial Neural Networks for Speech and Vision , R. J. Mammone , Ed . , pp .126 - 142 , Chapman & Hall , London , UK , 1993 .", "label": "", "metadata": {}, "score": "65.377304"}
{"text": "Algebraic combiners .Algebraic combiners are non - trainable combiners , where continuous valued outputs of classifiers are combined through an algebraic expression , such as minimum , maximum , sum , mean , product , median , etc .Specifically .", "label": "", "metadata": {}, "score": "65.37755"}
{"text": "As an example , consider the multi - class bearing fault diagnosis of normal and three fault types ( BPFI , BPFO , BSF ) .Applying the proposed OVA diagnostic approach to the three fault types , the 4-class classification problem among Normal , BPFI , BPFO , BSF is transformed into three 2-class classification sub - problems .", "label": "", "metadata": {}, "score": "65.48926"}
{"text": "Signal Process .[ Google Scholar ] .Dong , M. ; He , D. A segmental hidden semi - Markov model ( HSMM)-based diagnostics and prognostics framework and methodology .Mech .Syst .Signal Process .[ Google Scholar ] .", "label": "", "metadata": {}, "score": "65.49353"}
{"text": "F2 acts as a WTA network .The feedforward weights connecting to the F2 neuron j are represented by the vector wj , while the feedback weights from the same neuron are represented by the vector cjthat stores the prototype of cluster j.", "label": "", "metadata": {}, "score": "65.650185"}
{"text": "The clustering results for the FCM and the subtractive clustering are , respectively , shown in Fig .4b , c. A comparison of Fig .4b , c with Fig .4a reveals that there are 14 classification errors for the FCM and 24 classification errors for the subtractiveclustering .", "label": "", "metadata": {}, "score": "65.70721"}
{"text": "In a real application such as machinery fault diagnostics and prognostics in a factory , the first phase i.e. , the initial establishment of the process involves identifying how many and which critical components to monitor , based on expert knowledge ; maintenance history ; costs and budget .", "label": "", "metadata": {}, "score": "65.91477"}
{"text": "For example , fault feature extraction from bearing accelerometer sensor signals is discussed in [ 31 - 33 ] .The effect of number of features used in bearing fault diagnostics with SVM and proximal support vector machine ( PSVM ) is discussed in [ 34 ] .", "label": "", "metadata": {}, "score": "65.93182"}
{"text": "With the confidence interval , the following \" metadecision \" is made for each tentative . is attached as a final class label to this newly created terminal node when x becomes the attribute with maximum transinformation for the current decision node ( see below ) .", "label": "", "metadata": {}, "score": "65.98629"}
{"text": "Figure 6a shows a temporal signal of a BPFI bearing data sample and Figure 6b shows the corresponding frequency spectra .The BPFI characteristic defect frequency and harmonics are not as obvious as the BPFO , but there are numerous sidebands equal to the shaft rotation frequency ( 1\u00d7 ) in the spectrum , which are caused by modulation .", "label": "", "metadata": {}, "score": "66.07991"}
{"text": "The most appealing way to reduce false alarms is to develop better IDSs that generate fewer false alarms .The process of reducing the false alarms is very challenging because the false alarms are the result of many problems .These causes require IDS to be faster , flexible ( instead of strict thresholds ) , and adaptive ( instead of fixed rules ) , and dynamic learning of new patterns and aggregate logically corelated false alarms to identify root cause of alarms .", "label": "", "metadata": {}, "score": "66.2332"}
{"text": "After a fixed number of iterations , a new node is inserted between the node with the largest signal counter and its farthest neighbor .The algorithm occasionally prunes a node with its signal counter below a specified threshold during a complete epoch .", "label": "", "metadata": {}, "score": "66.2511"}
{"text": "The diversity in ensembles refers to different errors made by different base classifiers on data records .In order to produce diverse classifiers , researchers used two types of methods : ( 1 ) Implicit ; ( 2 ) Explicit [ 47 , 49 ] .", "label": "", "metadata": {}, "score": "66.300964"}
{"text": "For example , \" large \" might become \" medium large \" and \" very large \" if the attribute x means \" size .\" If the costs for not recognizing some classes are given , the original CAL5 uses class dependent thresholds .", "label": "", "metadata": {}, "score": "66.81211"}
{"text": "LVQ ( Kohonen , 1990 ) employs the same network architecture xp , yp ?Page 4 . 92 K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 the LVQ1 ( Kohonen , Kangas , Laaksonen , & Torkkola , 1992 ) .", "label": "", "metadata": {}, "score": "66.88179"}
{"text": "Growing radial basis neural networks : Merg- ing supervised and unsupervised learning with network growth techniques .IEEE Transactions on Neural Networks , 8(6 ) , 1492 - 1506 .Page 18 .106 K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 Karayiannis , N. B. , & Randolph - Gips , M. M. ( 2003 ) .", "label": "", "metadata": {}, "score": "66.90513"}
{"text": "In Information theory , a probabilistic method for quantifying information is developed by Shannon [ 55 ] .The entropy H(Y ) of the distribution p(y ) , a measure of the uncertainty about Y , is defined as : .The entropy ranges from zero to infinity .", "label": "", "metadata": {}, "score": "67.01909"}
{"text": "Computer simulations In this section , we give two examples to illustrate the applica- tion of clustering algorithms .An artificial example Given a data set of 1000 random data points in the two- dimensional space : In each of the two half rings there are 500 uniformly random data points .", "label": "", "metadata": {}, "score": "67.066055"}
{"text": "Section 4 describes the modification of CAL5 in the case of object dependent costs .Experiments with two artificial domains and the above - mentioned credit problem can be found in Section 5 .In Section 6 , a comparison with the results of three other algorithms is presented and Section 7 concludes the article .", "label": "", "metadata": {}, "score": "67.18866"}
{"text": "The paper will help the better understanding of different directions in which research of ensembles has been done in general and specifically : field of intrusion detection systems ( IDSs ) .Introduction .The threat of Internet attacks is quite real and frequent so this has increased a need for securing information on any network on the Internet .", "label": "", "metadata": {}, "score": "67.4755"}
{"text": "Syst .Signal Process .[ Google Scholar ] .Sugumaran , V. ; Sabareesh , G. ; Ramachandran , K. Fault diagnostics of roller bearing using kernel based neighborhood score multi - class support vector machine .Expert Syst .Appl .", "label": "", "metadata": {}, "score": "67.49655"}
{"text": "Its performance averaged on the 24 datasets used in STATLOG was similar to that of C4.5 ( even a little better [ 26 ] ) .In one case ( Australian credit dataset ) , it even achieved the best performance ( see the tables of results in [ 1 ] ) .", "label": "", "metadata": {}, "score": "67.695435"}
{"text": "Cross validation type selection is typically used for training the Tier 1 classifiers : the entire training dataset is divided into T blocks , and each Tier-1 classifier is first trained on ( a different set of ) T -1 blocks of the training data .", "label": "", "metadata": {}, "score": "67.71129"}
{"text": "The authors reported superior performance of Troika over other stacking methods .Discussion .Which is better bagging or boosting ?Many researchers compared the two methods including some large - scale experiments [ 56 , 57 , 107 , 108 ] .", "label": "", "metadata": {}, "score": "67.90764"}
{"text": "The attribute that delivers the maximum transinformation is used for branching .Branching stops if either terminal nodes of the branch contain a unique class label or the statistics in an interval is too poor to make either decision .and the transinformation both depend on the path from the root of the tree to the actual node ( not indicated here for easier reading ) .", "label": "", "metadata": {}, "score": "68.05522"}
{"text": "Sections 5 - 7 deal with the C - means , mountain / subtractive , and neural gas clustering meth- ods , respectively .ARTandARTMAPmodelsaretreatedinSection8 . be decreasing monotonically in time .For example , one can select ? 0893- 6080/$ - see front matter \u00a9 2009 Elsevier Ltd.", "label": "", "metadata": {}, "score": "68.17027"}
{"text": "Remark 1 .An attribute x which is irrelevant , that is , does not discriminate between the classes ( gives no information about the classes ) , can become relevant in cost - dependent classification because its values might be associated with different costs .", "label": "", "metadata": {}, "score": "68.2243"}
{"text": "Figures 8a , 9a , 10a show a temporal signal of a Normal ; BPFO ; and BPFI bearing data sample respectively .The two vibration signals from vertical and horizontal plane are transformed by FFT to the frequency spectra .Figures 8b , 9b , 10b show the corresponding frequency spectra of the three samples .", "label": "", "metadata": {}, "score": "68.29932"}
{"text": "Mech .Syst .Signal Process .[ Google Scholar ] .Lei , Y. ; He , Z. ; Zi , Y. ; Hu , Q. Fault diagnosis of rotating machinery based on multiple ANFIS combination with GAs .Mech .", "label": "", "metadata": {}, "score": "68.38228"}
{"text": "Page 15 .K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 103 ci,1 1000 epochs ci,2 a 1000 epochs -3 -2 -1 0 1 2 ci,2 b -3 -2 -1 0 1 2 -3 -2 - 10123 ci,1 -3 -2 - 10123 Fig .", "label": "", "metadata": {}, "score": "68.596405"}
{"text": "The fuzzy ARTMAP in- corporates two fuzzy ART modules .The fuzzy ARTMAP is capable of fast , but stable , on - line recognition learning , hypothesis testing , and adaptive naming in response to an arbitrary stream of ana- log or binary input patterns .", "label": "", "metadata": {}, "score": "68.70933"}
{"text": "Syst .Signal Process .[ Google Scholar ] .Lei , Y. ; He , Z. ; Zi , Y. Application of an intelligent classification method to mechanical fault diagnosis .Expert Syst .Appl .[ Google Scholar ] .", "label": "", "metadata": {}, "score": "68.804276"}
{"text": "If a bad customer is incorrectly classified as a good costumer , we assumed that 75 % of the entire credit amount will be lost ( normally a customer will pay back at least part of the loan ) .When averaging the example - dependent costs for each class , we arrived at a ratio close to that originally given by experts , 1 : 5 , which underpins the plausibility of our model .", "label": "", "metadata": {}, "score": "68.95876"}
{"text": "ART 2 The ART 2 ( Carpenter & Grossberg , 1987b ) is designed to categorize analog or binary random input sequences .It is similar to the ART 1 , but has a more complex F1 field so as to allow the ART 2 to stably categorize sequences of analog inputs that can be arbitrarily close to one another .", "label": "", "metadata": {}, "score": "68.969124"}
{"text": "Random data points in the two - dimensional space .In each of the two quarters , there are 1000 uniformly random points .( a )The out cells are arranged in a 10 \u00d7 10 grid .( b )", "label": "", "metadata": {}, "score": "69.1066"}
{"text": "Signal Process .[ Google Scholar ] .Lee , H. ; Nguyen , N. ; Kwon , J. Bearing Diagnosis Using Time - Domain Features and Decision Tree .In Advanced Intelligent Computing Theories and Applications .With Aspects of Artificial Intelligence ; Springer : Berlin / Heidelberg , Germay , 2007 ; Volume 4682 , pp . 952 - 960 .", "label": "", "metadata": {}, "score": "69.12578"}
{"text": "A bearing diagnostic method that is able to identify both single and multiple defects is more useful in real - world applications .In classification , training data for all system states to be recognized by a model are usually necessary [ 38 ] .", "label": "", "metadata": {}, "score": "69.12786"}
{"text": "[ Google Scholar ] .McFadden , P. ; Smith , J. Vibration monitoring of rolling element bearings by the high - frequency resonance technique - A review .Tribol .Int .[ Google Scholar ] .McInerny , S. ; Dai , Y. Basic vibration signal processing for bearing fault detection .", "label": "", "metadata": {}, "score": "69.23127"}
{"text": "Conflicts of Interest .The authors declare no conflict of interest .References .Nandi , S. ; Toliyat , H.A. ; Li , X. Condition monitoring and fault diagnosis of electrical motors - a review .IEEE Trans .Energy Convers .", "label": "", "metadata": {}, "score": "69.23369"}
{"text": "Its value is at its maximum if and only if all possible values for Y are equally probable .H .Y .X .j . ) j .d .i .n .p .y .i .", "label": "", "metadata": {}, "score": "69.30174"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . Y. Freund and R. E. Schapire , \" Experiments with a new boosting algorithm , \" in Proceedings of the 30th International Conference on Machine Learning , pp .", "label": "", "metadata": {}, "score": "69.30449"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . Y. Freund and R. E. Schapire , \" Experiments with a new boosting algorithm , \" in Proceedings of the 30th International Conference on Machine Learning , pp .", "label": "", "metadata": {}, "score": "69.30449"}
{"text": "[ Google Scholar ] .Sakthivel , N. ; Sugumaran , V. ; Babudevasenapati , S. Vibration based fault diagnosis of monoblock centrifugal pump using decision tree .Expert Syst .Appl .[ Google Scholar ] .Sun , W. ; Chen , J. ; Li , J. Decision tree and PCA - based fault diagnosis of rotating machinery .", "label": "", "metadata": {}, "score": "69.30745"}
{"text": "2 . triangulation .The Delaunay triangulation is represented by a mix of thick and thick dashedlines , theinducedDelaunaytriangulationbythicklines , Voronoitessellation by thin lines , prototypes by circles , and a data distribution P(x ) by shaded regions .An illustration of the Delaunay triangulation and the induced Delaunay the induced Delaunay triangulation by masking the Delaunay triangulation with a data distribution P(x ) .", "label": "", "metadata": {}, "score": "69.48703"}
{"text": "For example , the lateral feedback used in the SOM can be selected as the Mexican hat function , which is found in the visual cortex .The SOM is more successful in classification and pattern recognition .The self - organizing map The SOM computes the Euclidean distance of the input pattern x to each neuron k , and find the winning neuron , denoted neuron w withprototypecw , usingthenearest - neighborrule .", "label": "", "metadata": {}, "score": "69.78967"}
{"text": "j . ) log .y .i .x .j . )v .D .x .j .v .D .H .Y .x .j .v . )Information gain Gain ( Y , X j ) , or average mutual information I ( X j ; Y ) , is a measure of reduction in uncertainty about Y due to the knowledge on a feature X j , quantified by the change in entropy : .", "label": "", "metadata": {}, "score": "69.944275"}
{"text": "Keywords : . bearing ; multiple defects ; fault diagnostics ; class binarization ; support vector machine ( SVM ) ; decision tree .Introduction .In bearing diagnostics using a data - driven modeling approach , a concern is the need for data from all possible scenarios to build a practical model for all operating conditions .", "label": "", "metadata": {}, "score": "69.99106"}
{"text": "The existence of a fault is indicated by the occurrence of the impulses at the characteristic defect frequency , and the impulse amplitude provides some information about how serious the fault is .The same information also occurs as sidebands in the high resonant frequency bands .", "label": "", "metadata": {}, "score": "70.13965"}
{"text": "It is based on a pair of ART mod- ules , namely , ARTaand ARTb .ARTaand ARTbcan be fast learning ART 1 modules coding binary input vectors .These modules are connectedbyaninter - ARTmodulethatresemblesART1 .Theinter-ART module includes a map field that controls the learning of an associative map from ARTarecognition categories to ARTbrecogni- tion categories .", "label": "", "metadata": {}, "score": "70.17407"}
{"text": "Page 16 .104 K.-L. Du / Neural Networks 23 ( 2010 ) 89 - 107 18.2 .Iris classification In the iris data set , 150 patterns are classified into 3 classes .The Iris data set and the corresponding classification are shown in Fig . 4a .", "label": "", "metadata": {}, "score": "70.24627"}
{"text": "As shown in Figures 8b , 9b , 10b , the frequency range consists of a number of different distributions .Consequently , features are extracted from two frequency ranges , namely low frequency between the 4th to 10th harmonics of the bearing characteristics frequencies ( Table 8 ) , and high frequency between 7 - 10 kHz in the resonant frequency bands where sidebands may occur .", "label": "", "metadata": {}, "score": "70.39932"}
{"text": "[5 ] .The additional use of attribute costs is a possibility to extend CAL5 ( if the costs are known a priori ) and CAL5_OC if example dependent attribute costs are given , too .The Algorithm CAL5_OC .In this section , we describe an extended version of CAL5 capable of handling example - dependent costs .", "label": "", "metadata": {}, "score": "70.455185"}
{"text": "Nonavailability of signatures of novel attacks in databases leads to high false alarm rate and low detection accuracy .In fact , practitioners as well as researchers have observed that IDSs can easily trigger thousands of alarms per day , upto 99 % of which are false positives ( i.e. , alarms that were mistakenly triggered by benign events ) [", "label": "", "metadata": {}, "score": "71.08864"}
{"text": "In contrast , for instance , to the cost - sensitive extension of DIPOL , CAL5_OC in its current form is not able to handle misclassification costs that depend not only on the original class of the example but also on the class into which it might be classified incorrectly .", "label": "", "metadata": {}, "score": "71.194046"}
{"text": "Either of the bearings on the left and right of the shaft can be at fault and we assume that the faulty bearing has been located in the isolation stage .Vibration data were collected from the accelerometers at vertical and horizontal direction of the bearing either on the left or the right of the rotors , i.e. , either positions C and D , or E and F in Figure 7 .", "label": "", "metadata": {}, "score": "71.2393"}
{"text": "Table 5 shows the list of samples in this data set .The first eight samples were used in training and the last eight samples were used in testing .In other words , part of the bearing data collected at normal state and each of the single defect states are selected randomly for modeling training .", "label": "", "metadata": {}, "score": "71.24864"}
{"text": "It will help build more practical classifiers with less data , for improved performance under more operating conditions .These help provide advanced failure warning and reduce unexpected failures in real applications .This paper is a study on vibration - based bearing diagnostics with the data - driven approach .", "label": "", "metadata": {}, "score": "71.60602"}
{"text": "Conclusions .In real - world applications of bearing diagnostics , multiple defect types may occur at the same time .While many data - driven modeling methods naturally handle mutually exclusive groups of data , no discussions on the handling of non - exclusive concurrent faults in bearing diagnostics are found in the literature .", "label": "", "metadata": {}, "score": "71.75944"}
{"text": "One example of application is the classification of a bank 's credit applicants as either \" good customers \" ( who will pay back their credit ) or \" bad customers \" ( who are not likely to pay back their loans in full ) .", "label": "", "metadata": {}, "score": "71.94695"}
{"text": "107 - 114 .Heng , A. ; Zhang , S. ; Tan , A. ; Mathew , J. Rotating machinery prognostics : State of the art , challenges and opportunities .Mech .Syst .Signal Process .[ Google Scholar ] .", "label": "", "metadata": {}, "score": "72.44827"}
{"text": "Performance Evaluation .The prediction performance of normal and single - defect bearings is first compared .When one- versus -all ( OVA ) formulation is used , the diagnosis accuracy increases from 93.8 % to 100 % .The classification accuracies of both methods are much higher than the accuracy of random guess among four single - defect classes ( 25 % ) .", "label": "", "metadata": {}, "score": "72.73767"}
{"text": "[ Google Scholar ] .Tandon , N. ; Choudhury , A. A review of vibration and acoustic measurement methods for the detection of defects in rolling element bearings .Tribol .Int .[ Google Scholar ] .Mitchell , J. From vibration measurements to condition - based maintenance .", "label": "", "metadata": {}, "score": "72.9513"}
{"text": "Questions & Answers about this publication .I have a big dataset ( repository ) which contains text data .The repository contains a data related to many different domains so that I can search about any domain or general topic .", "label": "", "metadata": {}, "score": "72.96865"}
{"text": "Appl .Artif .Intell .[ Google Scholar ] .Kim , H.E. ; Tan , A.C. ; Mathew , J. ; Choi , B.K. Bearing fault prognosis based on health state probability estimation .Expert Syst .Appl .[ Google Scholar ] .", "label": "", "metadata": {}, "score": "73.11635"}
{"text": "Balderston , H. Incipient Failure Detection : Incipient Failure Detection in Ball Bearings ; Technical report ; Defense Technical Information Center : Ft .Belvoir , VA , USA , 1969 .[ Google Scholar ] .Gupta , P. Dynamics of rolling - element bearings - Part III , IV .", "label": "", "metadata": {}, "score": "73.487526"}
{"text": "2732 - 2752 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .S. Axelsson , \" Research in intrusion detection system - a survey , \" Tech .Rep. CMU / SEI , 1999 .", "label": "", "metadata": {}, "score": "73.94441"}
{"text": "2732 - 2752 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .S. Axelsson , \" Research in intrusion detection system - a survey , \" Tech .Rep. CMU / SEI , 1999 .", "label": "", "metadata": {}, "score": "73.94441"}
{"text": "\u00a9 2009 Elsevier Ltd.All rights reserved .Codebook design can be performed by using clustering .Once the codebook is spec- ified , approximation of x is to find the reference vector c from the codebook that is closest to x ( Kohonen , 1989 , 1997 ) .", "label": "", "metadata": {}, "score": "74.38707"}
{"text": "When the OVA formulation is used , eight of the 20 COMB test samples are correctly classified as BPFO + BPFI .The diagnosis accuracy increases from 0 % for the baseline to 40 % , also much higher than the random guess among eight classes ( 12.5 % ) .", "label": "", "metadata": {}, "score": "74.49982"}
{"text": "PDF or Postscript .PDF or Postscript .Smyth , P. and Wolpert , D. H. , \" Anytime Exploratory Data Analysis for Massive Data Sets \" , The Third International Conference on Knowledge Discovery and Data Mining , AAAI Press , 1997 .", "label": "", "metadata": {}, "score": "74.55971"}
{"text": "They generated HMMs models as base classifiers by training them using different number of HMM states and random initializations .They applied multiple HMM to dataset and final prediction is computed by exploiting all Boolean functions applied to the ROC curves .", "label": "", "metadata": {}, "score": "74.96169"}
{"text": "There are a lot of other possible applications where major costs resulting from false decisions have to be avoided .For example , a medical diagnosis may not overlook a dangerous disease like cancer , something that might not be very likely ; yet not detecting it could lead to high costs ( e.g. , the death of the patient in an extreme case ) .", "label": "", "metadata": {}, "score": "75.20685"}
{"text": "Syst .Signal Process .[ Google Scholar ] .Wang , D. ; Tse , P.W. ; Tsui , K.L. An enhanced Kurtogram method for fault diagnosis of rolling element bearings .Mech .Syst .Signal Process .[ Google Scholar ] .", "label": "", "metadata": {}, "score": "75.36968"}
{"text": "The following section provides an overview of how a decision tree is constructed with CAL5 .A comparison with other decision tree algorithms can be found in Section 3.2 .Overview of CAL5 .The CAL5 algorithm [ 1 , 20 - 22 , 26 ] for learning decision trees for classification and prediction converts real - valued attributes into discrete - valued ones by defining intervals on the real dimension through the use of statistical considerations .", "label": "", "metadata": {}, "score": "75.457214"}
{"text": "The BPFO and BPFI combined defect is used in the subsequent empirical analyses in this paper .Performance Evaluation - Bearing Fault Motor .In this section , the proposed OVA strategy is evaluated with experimental data from a bearing motor test bed .", "label": "", "metadata": {}, "score": "75.521255"}
{"text": "36 - 43 .Sugumaran , V. ; Ramachandran , K. Automatic rule learning using decision tree for fuzzy classifier in fault diagnosis of roller bearing .Mech .Syst .Signal Process .[ Google Scholar ] .Sugumaran , V. ; Muralidharan , V. ; Ramachandran , K. Feature selection using Decision Tree and classification through Proximal Support Vector Machine for fault diagnostics of roller bearing .", "label": "", "metadata": {}, "score": "76.10342"}
{"text": "The problem of bearing fault diagnostics is formulated to diagnose multiple defects from normal and single defect training data .The accuracy of the proposed OVA strategy on bearing diagnosis of unseen observations is evaluated with vibration data collected from laboratory .", "label": "", "metadata": {}, "score": "76.357376"}
{"text": "The value of threshold metrics lies in range from 0 to 1 .Ranking metrics include false - positive rate ( FPR ) , detection rate ( DR ) , precision ( PR ) , and area under ROC curve ( ROC ) .", "label": "", "metadata": {}, "score": "76.53056"}
{"text": "International Journal of Systems Science , 30(3 ) , 295 - 307 .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .", "label": "", "metadata": {}, "score": "76.77722"}
{"text": "The time between impulses in the vibration plot is the period of the defect which is the reciprocal of the characteristic defect frequency .The same information is shown as peaks at the characteristic defect frequency and its harmonics ( marked with green arrows in Figure 5b .", "label": "", "metadata": {}, "score": "76.91287"}
{"text": "If a good customer is incorrectly classified as a bad customer , we assumed a cost of .where the attribute duration is the duration of the loan in months , and amount is the credit amount .Duration and amount are just two of the 24 attributes used for the sample description in the German credit dataset mentioned above .", "label": "", "metadata": {}, "score": "77.07675"}
{"text": "18 , no .6 , pp .1369 - 1378 , 2007 .View at Google Scholar .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .J. R. Quinlan , C4.5 Programs for Machine Learning , Morgan Kaufmann , San Mateo , Calif , USA , 1997 .", "label": "", "metadata": {}, "score": "77.10914"}
{"text": "18 , no .6 , pp .1369 - 1378 , 2007 .View at Google Scholar .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .J. R. Quinlan , C4.5 Programs for Machine Learning , Morgan Kaufmann , San Mateo , Calif , USA , 1997 .", "label": "", "metadata": {}, "score": "77.10914"}
{"text": "The literature concerning the use of acceleration signals obtained from piezoelectric sensors in bearing diagnostics is so huge that a review is not the most useful format in summarizing recent research developments .Below is an overview of the logic behind vibration - based bearing fault diagnostics and some literature highlights of two approaches to the analysis , with focus on the statistical and data mining approach .", "label": "", "metadata": {}, "score": "77.33394"}
{"text": "An accelerometer was connected at vertical direction of the bearing .Vibration data were collected at a sampling rate of 4,000 Hz .Two samples were extracted for each experimental condition .Each sample consists of one temporal signal of 0.5 s length .", "label": "", "metadata": {}, "score": "77.53553"}
{"text": "The signal processing approach constitutes a major part of the literature in vibration - based bearing fault diagnostics .This approach has been developed for decades with a huge literature and is not the focus of this paper .A useful review in this classic approach is given in [ 11 ] , which summarizes various topics in bearing condition monitoring , from the underlying science to signal processing techniques that can be used with signals from accelerometers .", "label": "", "metadata": {}, "score": "77.84926"}
{"text": "Examples of research papers applying C4.5 decision trees to bearing fault diagnostics include [ 30 , 48 , 59 , 60 ] .They have also been applied in other machinery fault diagnostics problems such as motor [ 61 ] , pump [ 62 ] and shaft rotor [ 63 ] .", "label": "", "metadata": {}, "score": "77.96318"}
{"text": "Figure 4a shows a temporal signal of a normal bearing data sample and Figure 5a shows the plot of a BPFO bearing data sample .For each sample in this data set , the vibration signal is transformed by FFT to the frequency spectrum .", "label": "", "metadata": {}, "score": "78.09705"}
{"text": "Technol .[ Google Scholar ] .McFadden , P. ; Smith , J. The vibration produced by multiple point defects in a rolling element bearing .J. Sound Vib .[ Google Scholar ] .McFadden , P. ; Smith , J. Model for the vibration produced by a single point defect in a rolling element bearing .", "label": "", "metadata": {}, "score": "78.230835"}
{"text": "More details of how this procedure is applied are discussed in the next section .The Proposed Methodology .In practice , incipient faults first detected from vibration signals are usually BPFO ; BPFI ; or BSF .Multiple types of defects can develop on the same bearing concurrently i.e. , the defect types are non - exclusive classes .", "label": "", "metadata": {}, "score": "78.3279"}
{"text": "The vibration data were collected at a sampling rate of 32,768 Hz .Ten samples were extracted for each combination of experimental conditions .Each sample consists of two temporal signals of one second length , collected from the sensors along the vertical and horizontal directions .", "label": "", "metadata": {}, "score": "79.88689"}
{"text": "In practice , vibration signals due to defect impacts mix together with those generated by normal rotation of the same component , other components of the same rotating machinery and other random vibrations .Another complication is that the actual frequency is affected by the tightness - of - fit of the components and there are generally some differences between the measured frequencies and the theoretical characteristic defect frequency values due to random slip [ 8 ] .", "label": "", "metadata": {}, "score": "79.90474"}
{"text": "Table 7 shows the results of the OVA formulation and the correct fault diagnoses are highlighted in bold .Performance Evaluation .The prediction performance of normal and single - defect bearings is first compared .When one- versus -all ( OVA ) formulation is used , the number of correct classification is 66.7 % .", "label": "", "metadata": {}, "score": "81.13023"}
{"text": "w .C .i .n .i .Subject to .y .i . w .T .x .i .b . )i .i . for .i .n . where \u03be i measures the distance between a data point x i and the boundary , for any x i that lies on the wrong side of the margin .", "label": "", "metadata": {}, "score": "81.147156"}
{"text": "In rotating machinery , whenever a defect makes contact with another surface , a high - level short - duration vibration impulse is excited .The effect is a damped signal which comprises of a sharp rise corresponding to the impact and approximately exponential decay [ 8 , 9 ] .", "label": "", "metadata": {}, "score": "81.19763"}
{"text": "Abstract . :In bearing diagnostics using a data - driven modeling approach , a concern is the need for data from all possible scenarios to build a practical model for all operating conditions .This paper is a study on bearing diagnostics with the concurrent occurrence of multiple defect types .", "label": "", "metadata": {}, "score": "82.1663"}
{"text": "The occurrence of impulses is pseudo - cyclostationary [ 10 ] , i.e. , they can be modeled as cyclostationary , although in reality the impulse due to a particular fault may not be excited in every cycle of rotation .Since the rotation of the machinery is periodic , impulses and the damped signals due to a particular defect also tend to be generated periodically .", "label": "", "metadata": {}, "score": "84.1703"}
{"text": "In this paper , we have proposed a formulation strategy to improve diagnostics performance and reduce the number of scenarios needed in the training data , with focus on multiple defects that may occur concurrently .Better formulation in bearing diagnostics helps build more practical classifiers with less data , for improved performance at more operating conditions .", "label": "", "metadata": {}, "score": "84.66821"}
{"text": "Full - text \u00b7 Article \u00b7 Aug 2009 \u00b7 Neural networks : the official journal of the International Neural Network Society all Addendum Article Book Review Case Report Comment Commentary Communication Concept Paper Conference Report Correction Creative Data Descriptor Discussion Editorial Erratum Essay Interesting Images Letter New Book Received Obituary Opinion Project Report Reply Retraction Review Short Note Technical Note .", "label": "", "metadata": {}, "score": "85.252106"}
{"text": "The Data Set .The data set used in this empirical analysis was collected from a bearing fault motor as shown in Figure 3 .The bearing physical parameters and the bearing characteristic defect frequencies calculation are shown in Table 4 .", "label": "", "metadata": {}, "score": "85.82354"}
{"text": "Educ .[ Google Scholar ] .Randall , R. ; Antoni , J. Rolling element bearing diagnostics - A tutorial .Mech .Syst .Signal Process .[ Google Scholar ] .Howard , I. A Review of Rolling Element Bearing Vibration \" Detection , Diagnosis and Prognosis \" ; Defence Science and Technology Oganisation : Melbourne , Australia , 1994 .", "label": "", "metadata": {}, "score": "86.72023"}
{"text": "Finally , this paper closes with the conclusions in Section 6 .Bearing Fault Diagnostics .Bearings are one of the most widely used components in machines and bearing failure is one of the most frequent reasons for machine breakdown .According to [ 1 ] , almost 40%-50 % of motor failures are bearing - related .", "label": "", "metadata": {}, "score": "86.721054"}
{"text": "f .X . ) w .T .x .b .i .n .w .i .x .i .b .y .i .f .x .i . )y .i . w .", "label": "", "metadata": {}, "score": "90.9088"}
{"text": "Department of Systems Engineering and Engineering Management ( SEEM ) , City University of Hong Kong , Tat Chee Avenue , Kowloon , Hong Kong , China .Author to whom correspondence should be addressed ; Tel . : +852 - 3442 - 2584 ; Fax : +852 - 3442 - 0173 .", "label": "", "metadata": {}, "score": "93.36398"}
{"text": "Laboratory of Granular Computing , Zhangzhou Normal University , Zhangzhou 363000 , China .Received 24 December 2012 ; Accepted 22 March 2013 .Copyright \u00a9 2013 Hong Zhao et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "97.74517"}
{"text": "Academic Editor : Farid Melgani .Copyright \u00a9 2012 Gulshan Kumar and Krishan Kumar .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "108.85515"}
{"text": "Academic Editor : Farid Melgani .Copyright \u00a9 2012 Gulshan Kumar and Krishan Kumar .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "108.85515"}
{"text": "Received 29 December 2008 ; Revised 2 June 2009 ; Accepted 21 July 2009 .Copyright \u00a9 2009 Fritz Wysotzki and Peter Geibel .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "123.095795"}
