{"text": "Efficient parsing algorithms for answering particular queries about a PCFG ( i.e. , calculating the probability of a given sentence , or finding the most likely parse ) have been applied to a variety of pattern - recognition problems .Our method works by constructing a Bayesian network to represent the distribution of parse trees induced by a given PCFG .", "label": "", "metadata": {}, "score": "30.678593"}
{"text": "We show that the automatically induced latent variable grammars of Petrov et al .2006 vary widely in their underlying representations , depending on their EM initialization point .We use this to our advantage , combining multiple automatically learned grammars into an unweighted product model , which gives significantly improved performance over state - of - the - art individual grammars .", "label": "", "metadata": {}, "score": "33.143257"}
{"text": "Previous algorithms are expensive due to two factors : the exponential number of rules that must be generated and the use of a Monte Carlo p arsing algorithm .In this paper we solve the first problem by a novel reduction of the DOP model toga small , equivalent probabilistic context - free grammar .", "label": "", "metadata": {}, "score": "35.405304"}
{"text": "This paper outlines our participation in the 2007 CoNLL Shared Task on Domain Adaptation ( Nivre et al . , 2007 ) .The goal was to adapt a parser trained on a single source domain to a new target domain us- ing only unlabeled data .", "label": "", "metadata": {}, "score": "35.715714"}
{"text": "It could play a key role in NLP tasks like Information Extraction , Question Answering and Summarization .We propose a machine learning algorithm for semantic role parsing , extending the work of Gildea and Jurafsky ( 2002 ) , Surdeanu et al .", "label": "", "metadata": {}, "score": "37.892906"}
{"text": "The algorithm uses a similarity graph to encourage similar n - grams to have similar POS tags .We demonstrate the efficacy of our approach on a domain adaptation task , where we assume that we have access to large amounts of unlabeled data from the target domain , but no additional labeled data .", "label": "", "metadata": {}, "score": "37.95398"}
{"text": "Our method does not assume any knowledge about the target language ( in particular no tagging dictionary is assumed ) , making it applicable to a wide array of resource - poor languages .We use graph - based label propagation for cross - lingual knowledge transfer and use the projected labels as features in an unsupervised model ( Berg - Kirkpatrick et al .", "label": "", "metadata": {}, "score": "38.54946"}
{"text": "Our algorithm is based on Support Vector Machines which we show give large improvement in performance over earlier classifiers .We show performance improvements through a number of new features designed to improve generalization to unseen data , such as automatic clustering of verbs .", "label": "", "metadata": {}, "score": "38.850372"}
{"text": "In addition , our discriminative approach integrally admits features beyond local tree configurations .We present a multi - scale training method along with an efficient CKY - style dynamic program .On a variety of domains and languages , this method produces the best published parsing accuracies with the smallest reported grammars .", "label": "", "metadata": {}, "score": "39.438877"}
{"text": "We present a novel approach which employs a randomized sequence of pruning masks .Formally , we apply auxiliary variable MCMC sampling to generate this sequence of masks , thereby gaining theoretical guarantees about convergence .Because each mask is generally able to skip large portions of an underlying dynamic program , our approach is particularly compelling for high - degree algorithms .", "label": "", "metadata": {}, "score": "39.54949"}
{"text": "To achieve these results we need to mitigate the lack of domain knowledge in the model by providing it with a large amount of automatically parsed data .We extend and improve upon recent work in structured training for neural network transition - based dependency parsing .", "label": "", "metadata": {}, "score": "39.58284"}
{"text": "Unfortunately , existing algorithms are both computationally intensive and difficult to implement .Previous algorithms are expensive due to two factors : the exponential number of rules that mus ... \" .Excellent results have been reported for DataOriented Parsing ( DOP ) of natural language texts ( Bod , 1993c ) .", "label": "", "metadata": {}, "score": "39.685608"}
{"text": "We reformulate the task as a combined chunking and classification problem , thus allowing our algorithm to be applied to new languages or genres of text for which statistical syntactic parsers may not be available . \" ...Probabilistic Context - Free Grammars ( PCFGs ) and variations on them have recently become some of the most common formalisms for parsing .", "label": "", "metadata": {}, "score": "39.772438"}
{"text": "However , our results were obtained without adap- tation .Given our position in the ranking , this sug- gests that no team was able to significantly improve performance on either test domain beyond that of a state - of - the - art parser .", "label": "", "metadata": {}, "score": "40.865242"}
{"text": "We present a new approach to learning a semantic parser ( a system that maps natural language sentences into logical form ) .Unlike previous methods , it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .", "label": "", "metadata": {}, "score": "40.98629"}
{"text": "The main innovation of the algorithm is its use of state - of - the - art statistical machine translation techniques .A statistical word alignment model is used for lexical acquisition , and the parsing model itself can be seen as an instance of a syntax - based translation model .", "label": "", "metadata": {}, "score": "41.201508"}
{"text": "Or the software can be used simply as an accurate unlexicalized stochastic context - free grammar parser .Either of these yields a good performance statistical parsing system .A GUI is provided for viewing the phrase structure tree output of the parser .", "label": "", "metadata": {}, "score": "42.244896"}
{"text": "For future work , I propose to extend our PCFG induction model in several ways : improving the lexicon learning algorithm , discriminative re - ranking of top - k parses , and integrating the meaning representation language ( MRL ) grammar for extra structural information .", "label": "", "metadata": {}, "score": "43.063892"}
{"text": "We highlight the use of this resource via two experiments , including one that reports competitive accuracies for unsupervised grammar induction without gold standard part - of - speech tags .We present an online learning algorithm for training structured prediction models with extrinsic loss functions .", "label": "", "metadata": {}, "score": "43.337048"}
{"text": "A mixture grammar fit with the EM algorithm shows improvement over a single PCFG , both in parsing accuracy and in test data likelihood .We argue that this improvement comes from the learning of specialized grammars that capture non - local correlations .", "label": "", "metadata": {}, "score": "43.428238"}
{"text": "Our first- , second- , and third - order models achieve accuracies comparable to those of their unpruned counterparts , while exploring only a fraction of the search space .We observe speed - ups of up to two orders of magnitude compared to exhaustive search .", "label": "", "metadata": {}, "score": "43.45327"}
{"text": "Second , how can we efficiently infer optimal structures within them ?Hierarchical coarse - to - fine methods address both questions .Coarse - to - fine approaches exploit a sequence of models which introduce complexity gradually .At the top of the sequence is a trivial model in which learning and inference are both cheap .", "label": "", "metadata": {}, "score": "43.50107"}
{"text": "Nonetheless , the resulting grammars encode many linguistically interpretable patterns and give the best published parsing accuracies on three German treebanks .We demonstrate that log - linear grammars with latent variables can be practically trained using discriminative methods .Central to efficient discriminative training is a hierarchical pruning procedure which allows feature expectations to be efficiently approximated in a gradient - based procedure .", "label": "", "metadata": {}, "score": "43.580666"}
{"text": "However , it is not always possible to restrict the set of possible alignments to such limited numbers .Thus , we present another system that allows each sentence to be aligned to one of exponentially many connected subgraphs without explicitly enumerating them .", "label": "", "metadata": {}, "score": "43.727036"}
{"text": "First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .", "label": "", "metadata": {}, "score": "43.741173"}
{"text": "For example , our clus- tering algorithm grouped first names in one group and measurements in another .We then added the cluster membership as a lexical feature to the parser .None of the resulting features helped adaptation .3.2Diversity Training diversity may be an effective source for adaptation .", "label": "", "metadata": {}, "score": "44.156296"}
{"text": "We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches .Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic - based approach .", "label": "", "metadata": {}, "score": "44.293648"}
{"text": "Our best results show a 26-fold speedup compared to a sequential C implementation .We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data .We first demonstrate that delexicalized parsers can be directly transferred between languages , producing significantly higher accuracies than unsupervised parsers .", "label": "", "metadata": {}, "score": "44.799316"}
{"text": "This paper presents an algorithm for automatically assigning phrase breaks to unrestricted text for use in a text - to - speech synthesizer .Text is first converted into a sequence of part - of - speech tags .Next a Markov model is used to give the most likely sequence of phrase breaks for the input part - of ... \" .", "label": "", "metadata": {}, "score": "44.99713"}
{"text": "Unlike previous work , our final model does not require any additional resources at run - time .Compared to a state - of - the - art approach , we achieve more than 20 % relative error reduction .Additionally , we annotate a corpus of search queries with part - of - speech tags , providing a resource for future work on syntactic query analysis .", "label": "", "metadata": {}, "score": "45.055344"}
{"text": "We describe some challenges of adaptation in the 2007 CoNLL Shared Task on Domain Adaptation .Our error analysis for this task suggests that a primary source of error is differences in annotation guidelines between treebanks .Our suspicions are supported by the observation that no team was able to improve target domain performance substantially over a state of the art baseline .", "label": "", "metadata": {}, "score": "45.38306"}
{"text": "We also show that our techniques can be applied to full - scale parsing applications by demonstrating its effectiveness in learning state - split grammars .Treebank parsing can be seen as the search for an optimally refined grammar consistent with a coarse training treebank .", "label": "", "metadata": {}, "score": "45.384556"}
{"text": "Our suspicions are supported by the observation that no team was able to im- prove target domain performance substan- tially over a state of the art baseline . 1 Introduction Dependency parsing , an important NLP task , can be done with high levels of accuracy .", "label": "", "metadata": {}, "score": "45.40042"}
{"text": "In what follows , we provide an er- ror analysis that attributes domain loss for this task to a difference in annotation guidelines between do- mains .We then overview our attempts to improve adaptation .While we were able to show limited adaptation on reduced training data or with first- order features , no modifications improved parsing with all the training data and second - order features .", "label": "", "metadata": {}, "score": "45.711132"}
{"text": "Because we do not have gold - standard references for training a secondary conditional reranker , we incorporate weak supervision of evaluations against the perceptual world during the process of improving model performance .All these approaches are evaluated on the two publicly available domains that have been actively used in many other grounded language learning studies .", "label": "", "metadata": {}, "score": "45.717262"}
{"text": "If you want to obtain the same results , you can either POS - tag your corpus before tagging it ( see # 12 ) or you can disable the POS tagger in CoreNLP by updating the list of annotators : .", "label": "", "metadata": {}, "score": "45.77752"}
{"text": "We present experiments with sequence models on part - of - speech tagging and named entity recognition tasks , and with syntactic parsers on dependency parsing and machine translation reordering tasks .Low - latency solutions for syntactic parsing are needed if parsing is to become an integral part of user - facing natural language applications .", "label": "", "metadata": {}, "score": "45.849026"}
{"text": "We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process ( HDP ) .Our HDP - PCFG model allows the complexity of the grammar to grow as more training data is available .In addition to presenting a fully Bayesian model for the PCFG , we also develop an efficient variational inference procedure .", "label": "", "metadata": {}, "score": "46.016743"}
{"text": "3.3.3 Questions about Word Identities .Instead , we view the word identities as a further refinement of the POS tags .We start the clustering algorithm wit ... . ... ssible values of P w i c(w i i\\Gamman+1 ) are bucketed .", "label": "", "metadata": {}, "score": "46.059532"}
{"text": "It makes it easy to describe parsers that compute a wide variety of interesting quantities , including the inside and outside probabilities , as well as related quantities such as Viterbi probabilities and n - best lists .We also present three novel uses for the inside and outside probabilities .", "label": "", "metadata": {}, "score": "46.073692"}
{"text": "Our methods result in state - of - the - art performance on the task of executing sequences of natural language instructions , achieving up to 25 % error reduction , with lexicons that are up to 70 % smaller and are qualitatively less noisy .", "label": "", "metadata": {}, "score": "46.334934"}
{"text": "Specifically , an ini- tial hypothesis lattice is constrcuted using local features .Candidate sentences are then assigned syntactic language model scores .These global syntactic scores are combined with local low - level scores in a log - linear model .", "label": "", "metadata": {}, "score": "46.805027"}
{"text": "Yes , you can .However , for good results , you should make sure that you provide correctly tokenized input and use exactly the correct tag names .( That is , the input must be tokenized and normalized exactly as the material in the treebank underlying the grammar is . )", "label": "", "metadata": {}, "score": "46.889435"}
{"text": "Next , I present a PCFG induction model for grounded language learning that extends the model of Borschinger , Jones , and Johnson ( 2011 ) by utilizing a semantic lexicon .Our model overcomes such limitations by employing a semantic lexicon as the basic building block for PCFG rule generation .", "label": "", "metadata": {}, "score": "46.927902"}
{"text": "It has implementations of probabilistic natural language parsers , both highly optimized PCFG and lexicalized dependency parsers , and a lexicalized PCFG parser .It 's has a full GNU GPL license .OpenFST - A package for manipulating weighted finite state automata .", "label": "", "metadata": {}, "score": "47.213852"}
{"text": "You can use it as follows : .There are several options , including one for batch - processing lots of files ; see the Javadoc documentation of the main method of PTBTokenizer .Parsing speed depends strongly on the distribution of sentence lengths - and on your machine , etc .", "label": "", "metadata": {}, "score": "47.437717"}
{"text": "When the model is finished training , or when you want to test one of the intermediate models , you can run it using the standard LexicalizedParser commands .In our experiments , we found that simpler PCFG models actually make better underlying PCFG models .", "label": "", "metadata": {}, "score": "47.451126"}
{"text": "The paper gives a very efficient algorithm to compute it .This kernel is also an improvement over the word subsequence kernel because it only counts linguistically meaningful word subsequences which are based on word dependencies .It overcomes some of the difficulties encountered by syntactic tree kernels as well .", "label": "", "metadata": {}, "score": "47.51313"}
{"text": "However , it does not scale to problems with a large set of potential meanings for each sentence , such as the navigation instruction following task studied by Chen and Mooney ( 2011 ) .This paper presents an enhancement of the PCFG approach that scales to such problems with highly - ambiguous supervision .", "label": "", "metadata": {}, "score": "47.583588"}
{"text": "Our work is also the first attempt to use the same automatically - learned grammar for both parsing and generation .Unlike previous systems that require manually - constructed grammars and lexicons , our systems require much less knowledge engineering and can be easily ported to other languages and domains .", "label": "", "metadata": {}, "score": "47.686554"}
{"text": "We describe experiments on learning latent variable grammars for various German treebanks , using a language - agnostic statistical approach .In our method , a minimal initial grammar is hierarchically refined using an adaptive split - and - merge EM procedure , giving compact , accurate grammars .", "label": "", "metadata": {}, "score": "47.83924"}
{"text": "In particular , we introduce set - valued features to encode the predicted morphological properties and part - of - speech confusion sets of the words being parsed .We also investigate the use of joint parsing and part - of - speech tagging in the neural paradigm .", "label": "", "metadata": {}, "score": "47.857536"}
{"text": "Besides being robust , this approach is also flexible and able to learn under a wide range of supervision , from extra to weaker forms of supervision .It can easily utilize extra supervision given in the form of syntactic parse trees for natural language sentences by using a syntactic tree kernel instead of a string kernel .", "label": "", "metadata": {}, "score": "47.88383"}
{"text": "Previous sentence segmentation systems have typically been very local , using low - level prosodic and lexical features to independently decide whether or not to segment at each word boundary position .In this work , we leverage global syntactic information from a syn- tactic parser , which is better able to capture long distance depen- dencies .", "label": "", "metadata": {}, "score": "48.00537"}
{"text": "We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser .Existing methods incrementally expand the lexicon by greedily adding entries , considering a single training datapoint at a time .We propose using corpus - level statistics for lexicon learning decisions .", "label": "", "metadata": {}, "score": "48.04499"}
{"text": "Starting from a mono - phone model , we learn increasingly refined models that capture phone internal structures , as well as context - dependent variations in an automatic way .Our approaches reduces error rates compared to other baseline approaches , while streamlining the learning procedure .", "label": "", "metadata": {}, "score": "48.173172"}
{"text": "Initial experiments show that this approach is able to construct accurate parsers which generalize well to novel sentences and significantly outperform previous approaches to learning case - role mapping based on connectionist techniques .Planned extensions of the general framework and the specific applications as well as plans for further evaluation are also discussed .", "label": "", "metadata": {}, "score": "48.372543"}
{"text": "Unlike previous work on projecting syntactic resources , we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers .The projected parsers from our system result in state - of - the - art performance when compared to previously studied unsupervised and projected parsing systems across eight different languages .", "label": "", "metadata": {}, "score": "48.43986"}
{"text": "The best setup correctly identifies 79 % of breaks in the test corpus .\u00a9 1998 Academic Press Limited 1 . ... cause syntactic parses themselves are unhelpful .These have been shown to significantly outperform rule - driven parsers .", "label": "", "metadata": {}, "score": "48.475403"}
{"text": "We observe redundancy levels of about 30 % and non - standard distribution of both words and concepts .We measure the impact of redundancy on two standard text - mining applications : collocation identification and topic modeling .We compare the results of these methods on synthetic data with controlled levels of redundancy and observe significant performance variation .", "label": "", "metadata": {}, "score": "48.53573"}
{"text": "In this thesis , we focus on the task of semantic parsing , which maps a natural language sentence into a complete , formal meaning representation in a meaning representation language .We present two novel state - of - the - art learned syntax - based semantic parsers using statistical syntactic parsing techniques , motivated by the following two reasons .", "label": "", "metadata": {}, "score": "49.023617"}
{"text": "Next , we describe two PCFG induction models for grounded language learning that extend the previous grounded language learning model of Borschinger , Jones , and Johnson ( 2011 ) .Borschinger et al .'s approach works well in situations of limited ambiguity , such as in the sportscasting task .", "label": "", "metadata": {}, "score": "49.06211"}
{"text": "The paper proposes a simple informationtheoretic characterization of processing difficulty as the work incurred by resource reallocation during parallel , incremental , probabi ... \" .This paper investigates the role of resource allocation as a source of processing difficulty in human sentence comprehension .", "label": "", "metadata": {}, "score": "49.257027"}
{"text": "This paper presents a general framework , learning search - control heuristics for logic programs , which can be used to improve both the efficiency and accuracy of knowledge - based systems expressed as definite - clause logic programs .The approach combines techniques of explanation - based learning and recent advances in inductive logic programming to learn clause - selection heuristics that guide program execution .", "label": "", "metadata": {}, "score": "49.273598"}
{"text": "This paper presents an approach for inducing transformation rules that map natural - language sentences into a formal semantic representation language .The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .", "label": "", "metadata": {}, "score": "49.40207"}
{"text": "First , there may be room for adaptation with our domains if a common annotation scheme is used .Second , we have stressed that typical adaptation , modifying a model trained on the source domain , will fail but there may be unsupervised parsing techniques that improve performance after adaptation , such as a rule based NP parser for BIO based on knowledge of the annotations .", "label": "", "metadata": {}, "score": "49.45698"}
{"text": "Unlike existing preordering models , we train feature - rich discriminative classifiers that directly predict the target - side word order .Our approach combines the strengths of lexical reordering and syntactic preordering models by performing long - distance reorderings using the structure of the parse tree , while utilizing a discriminative model with a rich set of features , including lexical features .", "label": "", "metadata": {}, "score": "49.5375"}
{"text": "The CoNLL In Proc .Lawrence Saul and Fernando Pereira . gate and mixed - order markov models for statistical language modeling .In EMNLP . Aggre-1055 .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .", "label": "", "metadata": {}, "score": "49.563793"}
{"text": "The parsing and generation algorithms learn all of their linguistic knowledge from annotated corpora , and can handle natural - language sentences that are conceptually complex .A nice feature of our algorithms is that the semantic parsers and tactical generators share the same learned synchronous grammars .", "label": "", "metadata": {}, "score": "49.57977"}
{"text": "In this proposal , we present a new approach to semantic parsing based on string - kernel - based classification .Our system takes natural language sentences paired with their formal meaning representations as training data .For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .", "label": "", "metadata": {}, "score": "49.681435"}
{"text": "Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with lambda - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain .", "label": "", "metadata": {}, "score": "49.70958"}
{"text": "By using a top - down approach to heuristically guide the construction of generalizations of a bottom clause , Beth combines the strength of both approaches .Learning patterns for detecting potential terrorist activity is a current challenge problem for relational data mining .", "label": "", "metadata": {}, "score": "49.820786"}
{"text": "If POS - tagging sentences prior to parsing is an option , that speeds things up ( less possibilities to search ) .The main tool remaining is to run multiple parsers at once in parallel .If you have a machine with enough memory and multiple cores , you can very usefully run several parsing threads at once .", "label": "", "metadata": {}, "score": "50.217934"}
{"text": "Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning .This work describes systems for detecting semantic categories present in news video .", "label": "", "metadata": {}, "score": "50.27584"}
{"text": "Given this fixed network representation , we learn a final layer using the structured perceptron with beam - search decoding .On the Penn Treebank , our parser reaches 94.26 % unlabeled and 92.41 % labeled attachment accuracy , which to our knowledge is the best accuracy on Stanford Dependencies to date .", "label": "", "metadata": {}, "score": "50.3291"}
{"text": "I will first present a system we completed that can describe events in RoboCup 2D simulation games by learning only from sample language commentaries paired with traces of simulated activities without any language - specific prior knowledge .By applying an EM - like algorithm , the system was able to simultaneously learn a grounded language model as well as align the ambiguous training data .", "label": "", "metadata": {}, "score": "50.440445"}
{"text": "When these probabilities are multiplied together and normalized , they produce the probabili ... \" .Probabilistic Context - Free Grammars ( PCFGs ) and variations on them have recently become some of the most common formalisms for parsing .It is common with PCFGs to compute the inside and outside probabilities .", "label": "", "metadata": {}, "score": "50.44075"}
{"text": "However , I believe that logical approaches may have the most relevance and impact at the level of semantic interpretation , where a logical representation of sentence meaning is important and useful .We have explored the use of inductive logic programming for learning parsers that map natural - language database queries into executable logical form .", "label": "", "metadata": {}, "score": "50.518776"}
{"text": "Training the RNN parser is a two step process .First , because the RNN parser uses the parsings of a simpler PCFG parser to train , it is useful to precache the results of that parser before training the RNN parser .", "label": "", "metadata": {}, "score": "50.728874"}
{"text": "It first runs a ( simpler ) PCFG parser and then an untyped dependency parser , and then runs a third parser which finds the parse with the best joint score across the two other parsers via a product model .This is described in the NIPS Fast Exact Inference paper .", "label": "", "metadata": {}, "score": "50.866737"}
{"text": "Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .", "label": "", "metadata": {}, "score": "50.900826"}
{"text": "We present several models to this end ; in particular a partially observed conditional random field model , where coupled token and type constraints provide a partial signal for training .Averaged across eight previously studied Indo - European languages , our model achieves a 25 % relative error reduction over the prior state of the art .", "label": "", "metadata": {}, "score": "50.91755"}
{"text": "To address conflicting annota-1053 .Page 4 . tions , we added slack variables to the MIRA learn- ing algorithm ( Crammer et al . , 2006 ) used to train the parsers , without success .We measured diversity by comparing the parses of each model .", "label": "", "metadata": {}, "score": "50.95764"}
{"text": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .", "label": "", "metadata": {}, "score": "50.987"}
{"text": "The conversion code generally expects Penn Treebank style trees which have been stripped of functional tags and empty elements .This generally corresponds to the output of the Stanford , Charniak or Collins / Bikel parsers .The exception is that it gets value from the -TMP annotation on bare temporal NPs in order to recognize them as having temporal function ( tmod ) .", "label": "", "metadata": {}, "score": "51.045395"}
{"text": "For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .", "label": "", "metadata": {}, "score": "51.10444"}
{"text": "Most of the other parsing and generation algorithms presented in this thesis are extensions of WASP or its inverse .We demonstrate the effectiveness of our parsing and generation algorithms by performing experiments in two real - world , restricted domains .", "label": "", "metadata": {}, "score": "51.12446"}
{"text": "We present an algorithm for constructing Bayesian networks from PCFGs , and show how queries or patterns of queries on the network correspond to interesting queries on PCFGs .A natural language parser is a program that works out the grammatical structure of sentences , for instance , which groups of words go together ( as \" phrases \" ) and which words are the subject or object of a verb .", "label": "", "metadata": {}, "score": "51.16332"}
{"text": "The model is formally a latent variable CRF grammar over trees , learned by iteratively splitting grammar productions ( not categories ) .Different regions of the grammar are refined to different degrees , yielding grammars which are three orders of magnitude smaller than the single - scale baseline and 20 times smaller than the split - and - merge grammars of Petrov et al .", "label": "", "metadata": {}, "score": "51.21215"}
{"text": "The traditional use of these probabilities is to improve the probabilities of grammar rules .In this thesis we show that these values are useful for solving many other problems in Statistical Natural Language Processing .We give a framework for describing parsers .", "label": "", "metadata": {}, "score": "51.310097"}
{"text": "We extract LFG subcategorisation frames and paths linking LDD reentrancie ... \" .This paper shows how finite approximations of long distance dependency ( LDD ) resolution can be obtained automatically for wide - coverage , robust , probabilistic Lexical - Functional Grammar ( LFG ) resources acquired from treebanks .", "label": "", "metadata": {}, "score": "51.474304"}
{"text": "Or it may be because the parser made a mistake .While our goal is to improve the parser when we can , we ca n't fix individual examples .The parser is just choosing the highest probability analysis according to its grammar .", "label": "", "metadata": {}, "score": "51.52524"}
{"text": "We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system .We use a corpus of weakly - labeled reference reorderings to guide parser training .Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress .", "label": "", "metadata": {}, "score": "51.696823"}
{"text": "These classifiers are further refined using EM - type iterations based on their performance on the training data .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .Our experiments on two real - world data sets that have deep meaning representations show that this approach compares favorably to other existing systems in terms of accuracy and coverage .", "label": "", "metadata": {}, "score": "51.841732"}
{"text": "References Shai Ben - David , John Blitzer , Koby Crammer , and Fer- nando Pereira .Analysis of representations for domain adaptation .In NIPS .Leo Breiman .Learning , 24(2):123 - 140 .Bagging predictors .Machine R. Brown .", "label": "", "metadata": {}, "score": "51.91617"}
{"text": "They can also provide insight into important issues in human language acquisition .However , within AI , computational linguistics , and machine learning , there has been relatively little research on developing systems that learn such semantic parsers .This paper briefly reviews our own work in this area and presents semantic - parser acquistion as an important challenge problem for AI .", "label": "", "metadata": {}, "score": "52.011482"}
{"text": "This HeadFinder will give consistent left - branching binarization .If you would like to also get out the true probabilities that a vanilla PCFG parser would produce , there are a couple more options that you need to set : . -smoothTagsThresh", "label": "", "metadata": {}, "score": "52.104614"}
{"text": "The k best parses are extracted efficiently using the algorithm of Huang and Chiang ( 2005 ) .This may be because the parser chose an incorrect structure for your sentence , or because the phrase structure annotation conventions used for training the parser do n't match your expectations .", "label": "", "metadata": {}, "score": "52.46872"}
{"text": "In this proposal , we present a novel statistical approach to semantic parsing , WASP , which can handle meaning representations with a nested structure .The WASP algorithm learns a semantic parser given a set of sentences annotated with their correct meaning representations .", "label": "", "metadata": {}, "score": "52.529606"}
{"text": "Our generative self - trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without self - training .Additionally , we show that multiple self - trained grammars can be combined in a product model to achieve even higher accuracy .", "label": "", "metadata": {}, "score": "52.64857"}
{"text": "Our research further demonstrates the breadth of the applicability of neural network methods to dependency parsing , as well as the ease with which new features can be added to neural parsing models .We present structured perceptron training for neural network transition - based dependency parsing .", "label": "", "metadata": {}, "score": "52.693474"}
{"text": "Two new integrated ILP systems for these tasks that overcome limitations of existing methods will be presented .Cocktail is a new ILP algorithm for inducing semantic parsers .For this task , two features of a parse state , functional structure and context , provide important information for disambiguation .", "label": "", "metadata": {}, "score": "52.932716"}
{"text": "But how does the observed EHR redundancy affect text mining ?Does such redundancy introduce a bias that distorts learned models ?Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?( iii )How can one mitigate the impact of redundancy on text mining ?", "label": "", "metadata": {}, "score": "52.985878"}
{"text": "These statistical parsers still make some mistakes , but commonly work rather well .Their development was one of the biggest breakthroughs in natural language processing in the 1990s .You can try out our parser online .This package is a Java implementation of probabilistic natural language parsers , both highly optimized PCFG and lexicalized dependency parsers , and a lexicalized PCFG parser .", "label": "", "metadata": {}, "score": "53.048233"}
{"text": "Demos of learned natural - language database interfaces : .Tutorial on semantic parsing presented at ACL 2010 : .Using natural language to write programs is a touchstone problem for computational linguistics .We present an approach that learns to map natural - language descriptions of simple \" if - then \" rules to executable code .", "label": "", "metadata": {}, "score": "53.141445"}
{"text": "Standard inference can be used at test time .Our approach is able to scale to very large problems and yields significantly improved target domain accuracy .It is well known that parsing accuracies drop significantly on out - of - domain data .", "label": "", "metadata": {}, "score": "53.172234"}
{"text": "Instead , we scaled each feature 's value by a factor proportional to its frequency in the target do- main and trained the parser on these scaled feature values .We obtained small improvements on small amounts of training data .Target Focused Learning 4 Future Directions Given our pessimistic analysis and the long list of failed methods , one may wonder if parser adapta- tion is possible at all .", "label": "", "metadata": {}, "score": "53.304913"}
{"text": "Because each refinement introduces only limited complexity , both learning and inference can be done in an incremental fashion .In this dissertation , we describe several coarse - to - fine systems .In the domain of syntactic parsing , complexity is in the grammar .", "label": "", "metadata": {}, "score": "53.3769"}
{"text": "Programmatically , you can do the same things by creating a TokenizerFactory with the appropriate options , such as : .getWordsFromString(str ) ) ; .There is nevertheless a potential cost of making tokenization changes .This normalization was added in the first place because the parser is trained on American English , normalized according to Penn Treebank conventions .", "label": "", "metadata": {}, "score": "53.386726"}
{"text": "A simple extension using transductive SVMs enables the system to do semi - supervised learning and improve its performance utilizing unannotated sentences which are usually easily available .Another extension involving EM - like retraining makes the system capable of learning under ambiguous supervision in which the correct meaning representation for each sentence is not explicitly given , but instead a set of possible meaning representations is given .", "label": "", "metadata": {}, "score": "53.44104"}
{"text": "People are often confused about how to get from that example to parsing paragraphs of text .You need to split the text into sentences first and then to pass each sentence to the parser .To do that , we use the included class DocumentPreprocessor .", "label": "", "metadata": {}, "score": "53.52239"}
{"text": "In addition , the theory leads to a number of specific predictions about the role of expectation in syntactic comprehension , including the reversal of locality - based difficulty patterns in syntactically constrained contexts , and conditions under which increased ambiguity facilitates processing .", "label": "", "metadata": {}, "score": "53.641945"}
{"text": "The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .The learned transformation rules incrementally map a natural - language sentence or its syntactic parse tree into a parse - tree for the target formal language .", "label": "", "metadata": {}, "score": "53.689056"}
{"text": "Finally , we test the system on an alternate sentence representation , and on a set of large , artificial corpora with varying levels of ambiguity and synonymy .One difficulty in using machine learning methods for building natural language interfaces is building the required annotated corpus .", "label": "", "metadata": {}, "score": "53.731094"}
{"text": "Unlike conventional reranking used in syntactic and semantic parsing , gold - standard reference trees are not naturally available in a grounded setting .Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .", "label": "", "metadata": {}, "score": "53.768093"}
{"text": "In future work , we intend to pursue several directions in developing accurate semantic parsers for a variety of application domains .This will involve exploiting prior knowledge about the natural - language syntax and the application domain .We also plan to construct a syntax - aware word - based alignment model for lexical acquisition .", "label": "", "metadata": {}, "score": "53.83027"}
{"text": "Often , that works out okay , but , overall , results wo n't be quite as good .The default character encoding depends on the language that you are parsing .It is defined in the appropriate TreebankLanguagePack class .That is , it will never default to your platform default character encoding .", "label": "", "metadata": {}, "score": "54.012474"}
{"text": "We found certain scaling techniques obtained tiny improvements on the target domain that , while significant compared to competition results , are not statistically significant .We also attempted a sim- ilar approach on the feature level .A very predic- tive source domain feature is not useful if it does not appear in the target domain .", "label": "", "metadata": {}, "score": "54.045826"}
{"text": "Combining multiple grammars that were self - trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5\\% on the WSJ test set and 89.6\\% on our Broadcast News test set .This work shows how to improve state - of - the - art monolingual natural language processing models using unannotated bilingual text .", "label": "", "metadata": {}, "score": "54.116756"}
{"text": "( 2006 ) , which achieved top results in the 2006 We were given around CoNLL - X shared task .Preliminary experiments in- dicated that the edge labeler was fairly robust to do- main adaptation , lowering accuracy by 3 % in the de- velopment domain as opposed to 2 % in the source , so we focused on unlabeled dependency parsing .", "label": "", "metadata": {}, "score": "54.202106"}
{"text": "Unlike ( Collins , 1999 ; Johnson , 2002 ) , in our approach resolution of LDDs is done at f - structure ( attribute - value structure representations of basic predicate - argument or dependency structure ) without empty productions , traces and coindexation in CFG parse trees . ... tation .", "label": "", "metadata": {}, "score": "54.314754"}
{"text": "There is a call , setConstraints , which you can make before using the LexicalizedParserQuery to run the parser .If you add a ParserConstraint object spanning a set of words , the parser will only produce parse trees which include that span of words as a constituent .", "label": "", "metadata": {}, "score": "54.604862"}
{"text": "This partitions local subtrees of depth one ( corresponding to CFG rules ) into left and right contexts ( relative to head ) .The annotation al .. \" ...Interactive spoken dialogue provides many new challenges for natural language understanding systems .", "label": "", "metadata": {}, "score": "54.650208"}
{"text": "Meanwhile , Graphics Processor Units ( GPUs ) have become widely available , offering the opportunity to alleviate this bottleneck by exploiting the fine - grained data parallelism found in the CKY algorithm .In this paper , we explore the design space of parallelizing the dynamic programming computations carried out by the CKY algorithm .", "label": "", "metadata": {}, "score": "54.67595"}
{"text": "One notable exception is Brill 's TransformationBased Error Driven system ( Brill , 1993 ) , which induces a set of transformations designed to maximize the Consistent ... . by Aoife Cahill , Michael Burke , Josef Van Genabith , Andy Way - In Proceedings of the 42nd Meeting of the ACL , 2004 . \" ...", "label": "", "metadata": {}, "score": "54.832386"}
{"text": "Many studies have indeed shown that cross - domain learned corpora yield poor language models [ 35].The field of domain adaptation attempts to compensate for the poor quality of cross - domain data , by adding carefully picked text from other domains [ 36,37 ] or other statistical mitigation techniques .", "label": "", "metadata": {}, "score": "54.846928"}
{"text": "Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing computing systems that understand natural language input .This thesis presents a new machine learning approach for semantic parsing based on string - kernel - based classification .", "label": "", "metadata": {}, "score": "55.197517"}
{"text": "The words that are replaced or repeated are no longer part of the intended utterance , and so need to be identified .Segmenting turns and resolving repairs are strongly intertwined with a third task : identifying discourse markers .Because of the interactions , and interactions with POS tagging and speech recognition , we need to address these tasks together and early on in the processing stream .", "label": "", "metadata": {}, "score": "55.215744"}
{"text": "To manage this complexity , we translate into target language clusterings of increasing vocabulary size .This approach gives dramatic speed - ups while additionally increasing final translation quality .The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .", "label": "", "metadata": {}, "score": "55.35845"}
{"text": "Existing hand - crafted systems can provide in - depth analysis of domain sub - languages , but are often notoriously fragile and costly to build .Existing machine - learned systems are considerably more robust , but are limited to relatively shallow NLP tasks .", "label": "", "metadata": {}, "score": "55.40918"}
{"text": "In this paper , we explored a learning approach which combines different learning methods in inductive logic programming ( ILP ) to allow a learner to produce more expressive hypothese than that of each individual learner .Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method .", "label": "", "metadata": {}, "score": "55.57587"}
{"text": "We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .", "label": "", "metadata": {}, "score": "55.60571"}
{"text": "We tried a number of criteria to weigh sentences without suc- cess , including sentence length and number of verbs .Next , we trained a discriminative model on the pro- vided unlabeled data to predict the domain of each sentence based on POS n - grams in the sentence .", "label": "", "metadata": {}, "score": "55.62241"}
{"text": "We also intend to broaden the scope of application domains , for example , domains where the sentences are noisy as typical in speech , or domains where corpora available for training do not have natural language sentences aligned with their unique meaning representations .", "label": "", "metadata": {}, "score": "55.646477"}
{"text": "On full - scale treebank parsing experiments , the discriminative latent models outperform both the comparable generative latent models as well as the discriminative non - latent baselines .We present a maximally streamlined approach to learning HMM - based acoustic models for automatic speech recognition .", "label": "", "metadata": {}, "score": "55.724403"}
{"text": "Latent variable grammars take an observed ( coarse ) treebank and induce more fine - grained grammar categories , that are better suited for modeling the syntax of natural languages .Estimation can be done in a generative or a discriminative framework , and results in the best published parsing accuracies over a wide range of syntactically divergent languages and domains .", "label": "", "metadata": {}, "score": "55.965935"}
{"text": "We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .", "label": "", "metadata": {}, "score": "56.131893"}
{"text": "Automating the construction of semantic grammars is a difficult and interesting problem for machine learning .This paper shows how the semantic - grammar acquisition problem can be viewed as the learning of search - control heuristics in a logic program .", "label": "", "metadata": {}, "score": "56.186104"}
{"text": "The two models we present overcome such limitations by employing a learned semantic lexicon as a basic correspondence unit between NL and MR for PCFG rule generation .Finally , we present a method of adapting discriminative reranking to grounded language learning in order to improve the performance of our proposed generative models .", "label": "", "metadata": {}, "score": "56.224083"}
{"text": "Across various hierarchical encoding schemes and for multiple language pairs , we show speed - ups of up to 50 times over single - pass decoding while improving BLEU score .Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram - to - trigram decoder .", "label": "", "metadata": {}, "score": "56.306683"}
{"text": "In the future , we intend to pursue several directions in developing more accurate semantic parsing algorithms and automating the annotation process .This work will involve exploring alternative tree representations for better generalization in parsing .We also plan to apply discriminative reranking methods to semantic parsing , which allows exploring arbitrary , potentially correlated features not usable by the baseline learner .", "label": "", "metadata": {}, "score": "56.34953"}
{"text": "This process is described in the several papers on the topic by Marie - Catherine de Marneffe .Confusingly , the current code to generate Stanford Dependencies requires a phrase structure ( CFG ) parse .It does n't require or use a dependency parse .", "label": "", "metadata": {}, "score": "56.4245"}
{"text": "These fine grained tags provide more information than coarse tags ; experiments that removed fine grained tags 1052 .Page 3 . hurt WSJ performance but did not affect BIO .Finally , we examined the effect of unknown words .Not surprisingly , the most significant dif- ferences in error rates concerned dependencies be- tween words of which one or both were unknown to the parser .", "label": "", "metadata": {}, "score": "56.575985"}
{"text": "Memory usage expands roughly with the square of the sentence length .You may wish to set a -maxLength and to skip long sentences .The factored parser requires several times as much memory as just running the PCFG parser , since it runs 3 parsers .", "label": "", "metadata": {}, "score": "56.619633"}
{"text": "We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .The main innovation of WASP is its use of state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}, "score": "56.788605"}
{"text": "Machine learning and data mining .Weka - is a collection of machine learning algorithms for data mining .It is one of the most popular text classification frameworks .It contains implementations of a wide variety of algorithms including Naive Bayes and Support Vector Machines ( SVM , listed under SMO ) [ Note : Other commonly used non - Java SVM implementations are SVM - Light , LibSVM , and SVMTorch].", "label": "", "metadata": {}, "score": "56.816193"}
{"text": "4 The parallel corpus is aligned at the word level using the GIZA++ implementation of the IBM statistical translation models ( Brown et al . ... . by Sameer Pradhan , Kadri Hacioglu , Valerie Krugler , Wayne Ward , James H. Martin , Daniel Jurafsky , 2005 . \" ...", "label": "", "metadata": {}, "score": "56.918"}
{"text": "Tawlk / osae - A python library for sentiment classification on social text .The end - goal is to have a simple library that \" just works \" .It should have an easy barrier to entry and be thoroughly documented .", "label": "", "metadata": {}, "score": "56.957504"}
{"text": "Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations .Finally , we show that hybridizing these two approaches results in still more accurate generation systems .Automatic and human evaluation of generated sentences are presented across two domains and four languages .", "label": "", "metadata": {}, "score": "56.968052"}
{"text": "We added features indicating when an edge was predicted by another parser and if an edge crossed a predicted edge , as well as conjunctions with edge types .This failed to improve BIO accuracy since these features were less reliable at test time .", "label": "", "metadata": {}, "score": "57.005516"}
{"text": "Parsing With Compositional Vector Grammars .Proceedings of ACL 2013 .For the PCFG parser : Dan Klein and Christopher D. Manning .Accurate Unlexicalized Parsing .Proceedings of the 41stMeeting of the Association for Computational Linguistics , pp .423 - 430 .", "label": "", "metadata": {}, "score": "57.028557"}
{"text": "In a complete database - query application , parsers learned by CHILL outperform an existing hand - crafted system , demonstrating the promise of empricial techniques for automating the construction certain NLP systems .ML ID : 71 .Semantic Lexicon Acquisition for Learning Parsers [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney 1997 .", "label": "", "metadata": {}, "score": "57.12989"}
{"text": "The need for NLIs has become more pronounced given the widespread access to complex databases now available through the Internet .However , such systems are difficult to build and must be tailored to each application .A current research topic involves using machine learning methods to automate the development of NLI 's .", "label": "", "metadata": {}, "score": "57.15043"}
{"text": "Invited paper .Semantic parsing is the task of mapping a natural language sentence into a complete , formal meaning representation .Over the past decade , we have developed a number of machine learning methods for inducing semantic parsers by training on a corpus of sentences paired with their meaning representations in a specified formal language .", "label": "", "metadata": {}, "score": "57.151604"}
{"text": "The best accuracies were in the 80 - 84\\% range for F1 and LAS ; even part - of - speech accuracies were just above 90\\% .Coarse - to - fine inference has been shown to be a robust approximate method for improving the efficiency of structured prediction models while preserving their accuracy .", "label": "", "metadata": {}, "score": "57.2611"}
{"text": "The performance of SCISSOR is further improved by using discriminative reranking for incorporating non - local features .The second semantic parser , SYNSEM , exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .", "label": "", "metadata": {}, "score": "57.304855"}
{"text": "We focus on two important sub - tasks , semantic parsing and tactical generation .The key idea is that both tasks can be treated as the translation between natural languages and formal meaning representation languages , and therefore , can be performed using state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}, "score": "57.32039"}
{"text": "They are used to model text for speech recognition , OCR error correction , machine translation , and a variety of other tasks .The library was developed by contributors from Google Research and NYU .It is a C++ library that is meant to be fast and scalable .", "label": "", "metadata": {}, "score": "57.371124"}
{"text": "For most natural language processing tasks , a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well - formed strings .This paper reviews our work on using inductive logic programming methods to learn deterministic shift - reduce parsers that translate natural language into a semantic representation .", "label": "", "metadata": {}, "score": "57.63995"}
{"text": "The parser also requires a reasonable amount of memory ( at least 100 MB to run as a PCFG parser on sentences up to 40 words in length ; typically around 500 MB of memory to be able to parse similarly long typical - of - newswire sentences using the factored model ) .", "label": "", "metadata": {}, "score": "57.662354"}
{"text": "However , constructing such corpora can be expensive and time - consuming due to the expertise it requires to annotate such data .In this thesis , we explore alternative ways of learning which do not rely on direct human supervision .", "label": "", "metadata": {}, "score": "57.68537"}
{"text": "I first present a historical view of the shifting emphasis of research on various tasks in natural language processing and then briefly review our own work on learning for semantic interpretation .I will then attempt to encourage others to study such problems and explain why I believe logical approaches have the most to offer at the level of producing semantic interpretations of complete sentences .", "label": "", "metadata": {}, "score": "57.695755"}
{"text": "ML ID : 273 . \"Grounded \" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts .Borschinger et al .( 2011 ) introduced an approach to grounded language learning based on unsupervised PCFG induction .", "label": "", "metadata": {}, "score": "57.814354"}
{"text": "This paper presents approaches for automatically transforming a meaning representation grammar ( MRG ) to conform it better with the natural language semantics .It introduces grammar transformation operators and meaning representation macros which are applied in an error - driven manner to transform an MRG while training a semantic parser learning system .", "label": "", "metadata": {}, "score": "57.843582"}
{"text": "We began with the first ap- proach and removed a large number of features that we believed transfered poorly , such as most features for noun - noun edges .We obtained a small improve- ment in BIO performance on limited data only .", "label": "", "metadata": {}, "score": "57.919125"}
{"text": "If you call the parser programmatically and then convert the parse tree to a list of grammatical relations , you have to call setGenerateOriginalDependencies(true ) on your instance of TreebankLanguagePack as shown in the following snippet : .Alternatively , if you use SemanticGraphFactory.makeFromTree ( ) to build a SemanticGraph from a constitueny tree , then use the following method with originalDependencies set to true .", "label": "", "metadata": {}, "score": "57.954742"}
{"text": "The resulting grammars are extremely compact com- pared to other high - performance parsers , yet the parser gives the best published accuracies on several languages , as well as the best generative parsing numbers in English .In addi- tion , we give an associated coarse - to - fine inference scheme which vastly improves inference time with no loss in test set accuracy .", "label": "", "metadata": {}, "score": "58.028873"}
{"text": "In recent years there has been considerable interest in corpus - based methods for constructing natural language parsers .These empirical approaches replace hand - crafted grammars with linguistic models acquired through automated training over language corpora .A common thread among such methods to date is the use of propositional or probablistic representations for the learned knowledge .", "label": "", "metadata": {}, "score": "58.138462"}
{"text": "Using ithe optimizations , experiments yield a 97 % crossing brackets rate and 88 % zero crossing brackets rate .This differs significantly from the results reported by Bod , and is compara- ble to results from a duplication of Pereira and Schabes 's ( 1992 ) experiment on the same data .", "label": "", "metadata": {}, "score": "58.263336"}
{"text": "Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers .ML ID : 200 .Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus [ Details ] [ PDF ] Yuk Wah Wong and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL-2007 ) , Prague , Czech Republic , June 2007 .", "label": "", "metadata": {}, "score": "58.287582"}
{"text": "We show that our method performs overall better and faster than previous approaches in both domains .ML ID : 160 .Learning Transformation Rules for Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate , Yuk Wah Wong , Ruifang Ge , and Raymond J. Mooney April 2004 .", "label": "", "metadata": {}, "score": "58.288765"}
{"text": "Experimental results are presented that demonstrate WOLFIE 's ability to learn useful lexicons for a realistic domain .The lexicons learned by WOLFIE are also compared to those learned by another lexical acquisition system , that of Siskind ( 1996 ) .", "label": "", "metadata": {}, "score": "58.430702"}
{"text": "Despite the much simplified training process , our acoustic model achieves state - of - the - art results on phone classification ( where it outperforms almost all other methods ) and competitive performance on phone recognition ( where it outperforms standard CD triphone / subphone / GMM approaches ) .", "label": "", "metadata": {}, "score": "58.48275"}
{"text": "In this thesis , we focus on devising effective models for simultaneously disambiguating such supervision and learning the underlying semantics of language to map NL sentences into proper logical MRs .We present probabilistic generative models for learning such correspondences along with a reranking model to improve the performance further .", "label": "", "metadata": {}, "score": "58.550426"}
{"text": "State - of - the - art natural language processing models are anything but compact .Syntactic parsers have huge grammars , machine translation systems have huge transfer tables , and so on across a range of tasks .With such complexity come two challenges .", "label": "", "metadata": {}, "score": "58.572647"}
{"text": "For example , noun phrases might be split into subcategories for subjects and objects , singular and plural , and so on .This splitting process admits an efficient incremental inference scheme which reduces parsing times by orders of magnitude .Furthermore , it produces the best parsing accuracies across an array of languages , in a fully language - general fashion .", "label": "", "metadata": {}, "score": "58.66906"}
{"text": "An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job - search queries .ML ID : 75 .An Inductive Logic Programming Method for Corpus - based Parser Construction [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney January 1997 .", "label": "", "metadata": {}, "score": "58.73234"}
{"text": "We first present a system that learned to sportscast for RoboCup simulation games by observing how humans commentate a game .Using the simple assumption that people generally talk about events that have just occurred , we pair each textual comment with a set of events that it could be referring to .", "label": "", "metadata": {}, "score": "58.7657"}
{"text": "Toward this goal , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .", "label": "", "metadata": {}, "score": "58.947945"}
{"text": "3 Adaptation Approaches We survey the main approaches we explored for this task .While some of these approaches provided a modest performance boost to a simple parser ( lim- ited data and first - order features ) , no method added any performance to our best parser ( all data and second - order features ) .", "label": "", "metadata": {}, "score": "58.98208"}
{"text": "Our er- ror analysis suggests that the primary cause of loss from adaptation is from differences in the annotation guidelines themselves .Therefore , significant im- provements can not be made without specific knowl- edgeofthetargetdomain'sannotationstandards .No amount of source training data can help if no rele- vant structure exists in the data .", "label": "", "metadata": {}, "score": "59.040276"}
{"text": "Empirical results show that the learned parsers generalize well to novel sentences and out - perform previous approaches based on connectionist techniques .ML ID : 25 .Learning Search - Control Heuristics for Logic Programs : Applications to Speedup Learning and Language Acquisition [ Details ] [ PDF ] John M. Zelle March 1993 .", "label": "", "metadata": {}, "score": "59.134567"}
{"text": "We have developed methods for automatically learning semantic parsers from annotated corpora using inductive logic programming and other learning methods .We have explored learning semantic parsers for mapping natural - language sentences to case - role analyses , formal database queries , and formal command languages ( i.e. the Robocup coaching language for use in advice - taking learners ) .", "label": "", "metadata": {}, "score": "59.255592"}
{"text": "In general , though , you should not use this part of the feature and simply use \" .Yes , for the PCFG parser ( only ) .With a PCFG parser , you can give the option -printPCFGkBest n and it will print the n highest - scoring parses for a sentence .", "label": "", "metadata": {}, "score": "59.341423"}
{"text": "Many different metrics exist for evaluating parsing results , including Viterbi , Crossing Brackets Rate , Zero Crossing Brackets Rate , and several others .However , most parsing algorithms , including the Viterbi algorithm , attempt to optimize the same metric , namely the probability of getting the correct labelled tree .", "label": "", "metadata": {}, "score": "59.385357"}
{"text": "Thus , within a longitudinal patient record , one expects to observe heavy redundancy .In this paper , we ask three research questions : ( i ) How can redundancy be quantified in large - scale text corpora ?( ii )", "label": "", "metadata": {}, "score": "59.40058"}
{"text": "It does not attempt to determine grammaticality , though it will normally prefer a \" grammatical \" parse for a sentence if one exists .This is appropriate in many circumstances , such as when wanting to interpret user input , or dealing with conversational speech , web pages , non - native speakers , etc . .", "label": "", "metadata": {}, "score": "59.435787"}
{"text": ".. by Rebecca Hwa , Philip Resnik , Amy Weinberg , Clara Cabezas , Okan Kolak - Natural Language Engineering , 2005 . \" ...Broad coverage , high quality parsers are available for only a handful of languages .A prerequisite for developing broad coverage parsers for more languages is the annotation of text with the desired linguistic representations ( also known as \" treebanking \" ) .", "label": "", "metadata": {}, "score": "59.486755"}
{"text": "Empirical methods for building natural language systems has become an important area of research in recent years .Most current approaches are based on propositional learning algorithms and have been applied to the problem of acquiring broad - coverage parsers for relatively shallow ( syntactic ) representations .", "label": "", "metadata": {}, "score": "59.61401"}
{"text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural - language interface for database queries .CHILL treats parser acquisition as the learning of search - control rules within a logic program representing a shift - reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge .", "label": "", "metadata": {}, "score": "59.763145"}
{"text": "Control rules are induced using a novel ILP algorithm which handles difficult issues arising in the induction of search - control heuristics .Both the control - rule framework and the induction algorithm are crucial to CHILL 's success .The main advantage of CHILL over propositional counterparts is its flexibility in handling varied representations .", "label": "", "metadata": {}, "score": "59.80018"}
{"text": "This ' universal ' treebank is made freely available in order to facilitate research on multilingual dependency parsing .We consider the construction of part - of - speech taggers for resource - poor languages .Recently , manually constructed tag dictionaries from Wiktionary and dictionaries projected via bitext have been used as type constraints to overcome the scarcity of annotated data in this setting .", "label": "", "metadata": {}, "score": "60.01268"}
{"text": "An example command line for this process , with some of the most useful flags , is java -mx4 g edu.stanford.nlp.parser.dvparser.CacheParseHypotheses -model /path / to / pcfg / pcfg.ser.gz -treebank /path / to / wsj 200 - 2199 -output cached.wsj.ser.gz -numThreads 6 .", "label": "", "metadata": {}, "score": "60.161694"}
{"text": "Text - mining methods in particular can help disease modeling by mapping named - entities mentions to terminologies and clustering semantically related terms .EHR corpora , however , exhibit specific statistical and linguistic characteristics when compared with corpora in the biomedical literature domain .", "label": "", "metadata": {}, "score": "60.352997"}
{"text": "To confirm that nouns were problem- atic , we modified a first - order parser ( no second or- der features ) by adding a feature indicating correct noun - noun edges , forcing the parser to predict these edges correctly .", "label": "", "metadata": {}, "score": "60.366512"}
{"text": "Broad coverage , high quality parsers are available for only a handful of languages .A prerequisite for developing broad coverage parsers for more languages is the annotation of text with the desired linguistic representations ( also known as \" treebanking \" ) .", "label": "", "metadata": {}, "score": "60.435463"}
{"text": "Participants were to build a single parsing system that is robust to domain changes and can handle noisy text that is commonly encountered on the web .There was a constituency and a dependency parsing track and 11 sites submitted a total of 20 systems .", "label": "", "metadata": {}, "score": "60.44601"}
{"text": "For best results , we recommend that you first segment input text with a high quality word segmentation system which provides word segmentation according to Penn Chinese Treebank conventions ( note that there are many different conventions for Chinese word segmentation ... ) .", "label": "", "metadata": {}, "score": "60.482727"}
{"text": "Tools . by Joshua Goodman - IN PROCEEDINGS OF THE 34TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS , 1996 . \" ...Many different metrics exist for evaluating parsing results , including Viterbi , Crossing Brackets Rate , Zero Crossing Brackets Rate , and several others .", "label": "", "metadata": {}, "score": "60.742516"}
{"text": "We present two new algorithms : the \" Labelled Recall Algorithm , \" which maximizes the expected Labelled Recall Rate , and the \" Bracketed Recall Algorithm , \" which maximizes the Bracketed Recall Rate .Experimental results are given , showing that the two new algorithms have improved performance over the Viterbi algorithm on many criteria , especially the ones that they optimize . \" ...", "label": "", "metadata": {}, "score": "60.743534"}
{"text": "For distributors of proprietary software , commercial licensing is available .( Fine print : The traditional ( dynamic programmed ) Stanford Parser does part - of - speech tagging as it works , but the newer constituency and neural network dependency shift - reduce parsers require pre - tagged input .", "label": "", "metadata": {}, "score": "60.74734"}
{"text": "While we believe this is not enough diversity , it was not feasible to repeat our experiment with a large number of parsers . 3.3Another approach to adaptation is to favor training examples that are similar to the target .We first mod- ified the weight given by the parser to each training sentence based on the similarity of the sentence to target domain sentences .", "label": "", "metadata": {}, "score": "60.802177"}
{"text": "Future work includes extending the algorithm and performing tests on a more realistic corpus .ML ID : 56 .Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers [ Details ] [ PDF ] John M. Zelle PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , 1995 .", "label": "", "metadata": {}, "score": "60.91028"}
{"text": "ML ID : 45 .Learning Semantic Grammars With Constructive Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In Proceedings of the 11th National Conference on Artificial Intelligence , 817 - 822 , 1993 .", "label": "", "metadata": {}, "score": "60.999752"}
{"text": "ILP algorithms , which learn relational ( first - order ) rules , are used in a parser acquisition system called CHILL that learns rules to control the behavior of a traditional shift - reduce parser .Using this approach , CHILL is able to learn parsers for a variety of different types of analyses , from traditional syntax trees to more meaning - oriented case - role and database query forms .", "label": "", "metadata": {}, "score": "61.056335"}
{"text": "Therefore , the generators are said to be the inverse of the parsers , an elegant property that has been widely advocated .Furthermore , we show that our parsers and generators can handle formal meaning representation languages containing logical variables , including predicate logic .", "label": "", "metadata": {}, "score": "61.16491"}
{"text": "In particular , you can now download a version of our CRF - based word segmenter ( similar to the system we used in the Second Sighan Bakeoff ) from our software page .However , for convenience , we also provide an ability for the parser to do word segmentation .", "label": "", "metadata": {}, "score": "61.219193"}
{"text": "The Inverse Entailment approach to ILP , implemented in the Progol and Aleph systems , starts with the construction of a bottom clause , the most specific hypothesis covering a seed example .When mining relational data with a large number of background facts , the bottom clause becomes intractably large , making learning very inefficient .", "label": "", "metadata": {}, "score": "61.30282"}
{"text": "For the most common 1While only 8 teams participated in the closed track with us , our score beat all of the teams in the open track .Page 2 .The parser was trained on the provided WSJ data .Digits are less than 4 % of the tokens in BIO .", "label": "", "metadata": {}, "score": "61.306587"}
{"text": "The penalty for a recognition failure is often small : if two con- figurations are confused , they are often similar to each other , and the illusion works well enough , for instance , to drive a graphics animation of the moving hand .", "label": "", "metadata": {}, "score": "61.309933"}
{"text": "Experimental results with a complete database - query application for U.S. geography show that CHILL is able to learn parsers that outperform a pre - existing , hand - crafted counterpart .These results demonstrate the ability of a corpus - based system to produce more than purely syntactic representations .", "label": "", "metadata": {}, "score": "61.35473"}
{"text": "You pass to the parse method a List .If the items in this list implement HasTag , such as being of type TaggedWord or CoreLabel , and the tag value is not null , then the parser will use the tags that you provide .", "label": "", "metadata": {}, "score": "61.446945"}
{"text": "Adaptation techniques focus on the former since it is impossible to determine the lat- ter without knowledge of the labeling function .In parsing adaptation , the former corresponds to a dif- ference between the features seen in each domain , such as new words in the target domain .", "label": "", "metadata": {}, "score": "61.452652"}
{"text": "If your file is extremely large , splitting it into multiple files and parsing them sequentially will reduce memory usage .A 64-bit application requires more memory than a 32-bit application ( Java uses lots of pointers ) .", "label": "", "metadata": {}, "score": "61.453938"}
{"text": "Most recent work on semantic analysis of natural language has focused on ' ' shallow ' ' semantics such as word - sense disambiguation and semantic role labeling .Our work addresses a more ambitious task we call semantic parsing where natural language sentences are mapped to complete formal meaning representations .", "label": "", "metadata": {}, "score": "61.563904"}
{"text": "ML ID : 68 .Learning to Parse Database Queries using Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In AAAI / IAAI , 1050 - 1055 , Portland , OR , August 1996 .", "label": "", "metadata": {}, "score": "61.637344"}
{"text": "We divided the available WSJ data into a train and test set , trained a parser on the train set and compared errors on the test set and BIO .Accuracy dropped from 90 % on WSJ to 84 % on BIO .", "label": "", "metadata": {}, "score": "61.798626"}
{"text": "The supplied file makeSerialized.csh shows exactly what options we used to train the parsers that are included in the distribution .If you want to train the parser on a new language and/or treebank format , you can ( and people have done so ) , but you need to spend a while learning about the code , especially if you wish to develop language - specific features .", "label": "", "metadata": {}, "score": "61.860077"}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .", "label": "", "metadata": {}, "score": "61.87567"}
{"text": "Active learning methods attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .However , existing results for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to two non - classification tasks in natural language processing : semantic parsing and information extraction .", "label": "", "metadata": {}, "score": "61.91131"}
{"text": "You will need a collection of syntactically annotated data such as the Penn Treebank to train the parser .If they are not in the same format as currently supported Treebanks , you may need to write classes to read in the trees , etc .", "label": "", "metadata": {}, "score": "61.94996"}
{"text": "Unlike many current corpus - based approaches that use propositional or probabilistic learning algorithms , CHILL uses techniques from inductive logic programming ( ILP ) to learn relational representations .The reported experiments compare CHILL 's performance to that of a more naive application of ILP to parser acquisition .", "label": "", "metadata": {}, "score": "61.9769"}
{"text": "Text is first converted into a sequence of part - of - speech tags .Next a Markov model is used to give the most likely sequence of phrase breaks for the input part - of - speech tags .In the Markov model , states represent types of phrase break and the transitions between states represent the likelihoods of sequences of phrase types occurring .", "label": "", "metadata": {}, "score": "62.000656"}
{"text": "In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .Active learning methods ( Cohn , Atlas , & Ladner , 1994 ) attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .", "label": "", "metadata": {}, "score": "62.231236"}
{"text": "You may use the parse method that takes a String argument to have this done for you or you may be able to use of classes in the process package , such as DocumentPreprocessor and PTBTokenizer for tokenization , much as the main method of the parser does .", "label": "", "metadata": {}, "score": "62.32632"}
{"text": "Despite its simplicity , a product of eight automatically learned grammars improves parsing accuracy from 90.2 % to 91.8 % on English , and from 80.3 % to 84.5 % on German .Pruning can massively accelerate the computation of feature expectations in large models .", "label": "", "metadata": {}, "score": "62.397457"}
{"text": "By solving these simultaneously , we obtain better results on each task than addressing them separately .Our model is able to identify 72 % of turn - internal intonational boundaries with a precision of 71 % , 97 % of discourse markers with 96 % precision , and detect and correct 66 % of repairs with 74 % precision . .", "label": "", "metadata": {}, "score": "62.42428"}
{"text": "Reference ...Syntactic parsing is a fundamental problem in computational linguistics and natural language processing .Traditional approaches to parsing are highly complex and problem specific .Recently , Sutskever et al .( 2014 ) presented a task - agnostic method for learning to map input sequences to output sequences that achieved strong results on a large scale machine translation problem .", "label": "", "metadata": {}, "score": "62.500244"}
{"text": "Preliminary experimental results show that this system can learn correct and useful mappings .The correctness is evaluated by comparing a known lexicon to one learned from the training input .The usefulness is evaluated by examining the effect of using the lexicon learned by WOLFIE to assist a parser acquisition system , where previously this lexicon had to be hand - built .", "label": "", "metadata": {}, "score": "62.54402"}
{"text": "This paper reviews our recent work on applying inductive logic programming to the construction of natural language processing systems .We have developed a system , CHILL , that learns a parser from a training corpus of parsed sentences by inducing heuristics that control an initial overly - general shift - reduce parser .", "label": "", "metadata": {}, "score": "62.5511"}
{"text": "Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing user - friendly natural language interfaces to computing systems .Most of the research in natural language understanding , however , has mainly focused on shallow semantic analysis like case - role analysis or word sense disambiguation .", "label": "", "metadata": {}, "score": "62.65002"}
{"text": "Source is included .The package includes components for command - line invocation , a Java parsing GUI , and a Java API .The parser code is dual licensed ( in a similar manner to MySQL , etc . ) .", "label": "", "metadata": {}, "score": "62.788467"}
{"text": "On a side note : Would you recommend the twitter streaming or the get API ?As it currently stands , this question is not a good fit for our Q&A format .We expect answers to be supported by facts , references , or expertise , but this question will likely solicit debate , arguments , polling , or extended discussion .", "label": "", "metadata": {}, "score": "62.79463"}
{"text": "PTBEscapingProcessor .If calling the parser within your own program , the main parse methods take a List of words which should already be correctly tokenized and escaped before calling the parser .You do n't need to and can not give the -tokenized option .", "label": "", "metadata": {}, "score": "62.829853"}
{"text": "In this article , we explore using parallel text to help solving the problem of creating syntactic annotation in more languages .The central idea is to annotate the English side of a parallel corpus , project the analysis to the second language , and then train a stochastic analyzer on the resulting noisy annotations .", "label": "", "metadata": {}, "score": "62.896545"}
{"text": "The parser uses considerable amounts of memory .If you see a java.lang.OutOfMemoryError , you either need to give the parser more memory or to take steps to reduce the memory needed .( You give java more memory at the command line by using the -mx flag , for example -mx500 m . )", "label": "", "metadata": {}, "score": "62.963"}
{"text": "Across eight European languages , our approach results in an average absolute improvement of 10.4 % over a state - of - the - art baseline , and 16.7 % over vanilla hidden Markov models induced with the Expectation Maximization algorithm .", "label": "", "metadata": {}, "score": "63.0185"}
{"text": "By default , DocumentPreprocessor uses PTBTokenizer for tokenization .If you need to change that , either because you have a better Tokenizer for your domain or because you have already tokenized your text , you can do that by passing in a TokenizerFactory such as a WhitespaceTokenizerFactory for no tokenization beyond splitting on whitespace .", "label": "", "metadata": {}, "score": "63.02858"}
{"text": "Experimental results are presented demonstrating WOLFIE 's ability to learn useful lexicons for a database interface in four different natural languages .The lexicons learned by WOLFIE are compared to those acquired by a competing system developed by Siskind ( 1996 ) .", "label": "", "metadata": {}, "score": "63.229774"}
{"text": "Workshop on Statistical Parsing of Morphologically - Rich Languages at NAACL HLT 2010 , 5 June 2010 , Los Angeles , CA , USA .Abstract .This paper presents a study of the impact of using simple and complex morphological clues to improve the classification of rare and unknown words for parsing .", "label": "", "metadata": {}, "score": "63.23311"}
{"text": "In our method the first , monolingual view consists of supervised predictors learned separately for each language .The second , bilingual view consists of log - linear predictors learned over both languages on bilingual text .Our training procedure estimates the parameters of the bilingual model using the output of the monolingual model , and we show how to combine the two models to account for dependence between views .", "label": "", "metadata": {}, "score": "63.23405"}
{"text": "The option -smoothTagsThresh 0 stops any probability mass being reserved for unknown words .Naturally , such a parser will be unable to parse any sentence with unknown words in it .The 2003 unlexicalized parsing paper lists several modifications that gradually improve the performance of the Stanford parser for English .", "label": "", "metadata": {}, "score": "63.35917"}
{"text": "Either form of list will pass the tags to the parser .Or you can do this with code that you write .Here 's an example that very manually makes the List in question : . ; List .There are other constraints which can be added , but they have to be added programmatically .", "label": "", "metadata": {}, "score": "63.35998"}
{"text": "Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .", "label": "", "metadata": {}, "score": "63.47084"}
{"text": "For English , the parser by default now produces Universal Dependencies , which are extensively documented on that page .You can also have it produce the prior Stanford Dependencies representation .For this , and for the Chinese dependencies , you can find links to documentation on the Stanford Dependencies page .", "label": "", "metadata": {}, "score": "63.55636"}
{"text": "We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language ( NL ) sentences into their formal meaning representations ( MRs ) .Given NL sentences annotated with their MRs , the initial supervised semantic parser learns the mapping by training Support Vector Machine ( SVM ) classifiers for every production in the MR grammar .", "label": "", "metadata": {}, "score": "63.60669"}
{"text": "This gives a reasonable , but not excellent , Chinese word segmentation system .( It 's performance is n't as good as the Stanford CRF word segmenter mentioned above . )To use it , you use the -segmentMarkov option or a grammar trained with this option .", "label": "", "metadata": {}, "score": "63.932854"}
{"text": "Semantic parsing , on the other hand , involves deep semantic analysis in which word senses , semantic roles and other components are combined to produce useful meaning representations for a particular application domain ( e.g. database query ) .Prior research in machine learning for semantic parsing is mainly based on inductive logic programming or deterministic parsing , which lack some of the robustness that characterizes statistical learning .", "label": "", "metadata": {}, "score": "64.01632"}
{"text": "Instead , we use distributional semantics to generate only the relevant part of an on - the - fly ontology .Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .", "label": "", "metadata": {}, "score": "64.1282"}
{"text": "With 100 K unlabeled and 2 K labeled questions , uptraining is able to improve parsing accuracy to 84 % , closing the gap between in - domain and out - of - domain performance .We study self - training with products of latent variable grammars in this paper .", "label": "", "metadata": {}, "score": "64.15323"}
{"text": "Building natural language parsing systems by hand is a tedious , error - prone undertaking .We build on previous research in automating the construction of such systems using machine learning techniques .The result is a combined system that learns semantic lexicons and semantic parsers from one common set of training examples .", "label": "", "metadata": {}, "score": "64.16542"}
{"text": "In addition to a change in the annotation guide- lines for NPs , we observed an important difference in the distribution of POS tags .NN tags were almost twice as likely in the BIO domain ( 14 % in WSJ and 25 % in BIO ) .", "label": "", "metadata": {}, "score": "64.18819"}
{"text": "This tool measures scores for dependency trees , doing F1 and labeled attachment scoring .The included usage message gives a detailed description of how to use the tool .Usage notes .The current version of the parser requires Java 8 ( JDK1.8 ) or later .", "label": "", "metadata": {}, "score": "64.204735"}
{"text": "For future work , I am proposing to solve the more complex task of learning how to give and receive navigation instructions in a virtual environment .In this setting , each instruction corresponds to a navigation plan that is not directly observable .", "label": "", "metadata": {}, "score": "64.25879"}
{"text": "Specifically , I will present two probabilistic generative models for learning such correspondences .The models are applied to two publicly available datasets in two different domains , sportscasting and navigation , and compared with previous work on the same data .", "label": "", "metadata": {}, "score": "64.31741"}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "64.3394"}
{"text": "SYNSEM also significantly improves results with limited training data , and is shown to be robust to syntactic errors .ML ID : 246 .Training a Multilingual Sportscaster : Using Perceptual Context to Learn Language [ Details ] [ PDF ] David L. Chen , Joohyun Kim , Raymond J. Mooney Journal of Artificial Intelligence Research , 37:397 - -435 , 2010 .", "label": "", "metadata": {}, "score": "64.356705"}
{"text": "Integrating Top - down and Bottom - up Approaches in Inductive Logic Programming : Applications in Natural Language Processing and Relational Data Mining [ Details ] [ PDF ] Lappoon R. Tang PhD Thesis , Department of Computer Sciences , University of Texas , Austin , TX , August 2003 .", "label": "", "metadata": {}, "score": "64.36933"}
{"text": "On the task of assigning semantic labels to the PropBank ( Kingsbury , Palmer , & Marcus , 2002 ) corpus , our final system has a precision of 84 % and a recall of 75 % , which are the best results currently reported for this task .", "label": "", "metadata": {}, "score": "64.382774"}
{"text": "This process entails identifying groups of words in a sentence ... \" .The natural language processing community has recently experienced a growth of interest in domain independent shallow semantic parsing - the process of assigning a WHO did WHAT to WHOM , WHEN , WHERE , WHY , HOW etc . structure to plain text .", "label": "", "metadata": {}, "score": "64.53084"}
{"text": "However , if you want to use these parsers under a commercial license , then you need a license to both the Stanford Parser and the Stanford POS tagger .Or you can get the whole bundle of Stanford CoreNLP . )", "label": "", "metadata": {}, "score": "64.5869"}
{"text": "ML ID : 269 .Learning to Interpret Natural Language Navigation Instructions from Observations [ Details ] [ PDF ] [ Slides ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th AAAI Conference on Artificial Intelligence ( AAAI-2011 ) , 859 - 865 , August 2011 .", "label": "", "metadata": {}, "score": "64.6393"}
{"text": "More precisely , an inductive logic programming ( ILP ) method , TABULATE , is developed for learning multiple models that are integrated via linear weighted combination to produce probabilistic models for statistical semantic parsing .Initial experimental results from three different domains suggest that an integration of statistical and logical approaches to semantic parsing can outperform a purely logical approach .", "label": "", "metadata": {}, "score": "64.72329"}
{"text": "The main technical ideas behind how these parsers work appear in these papers .Feel free to cite one or more of the following papers depending on what you are using .Since the parser is regularly updated , we appreciate it if papers with numerical results reflecting parser performance mention the version of the parser being used .", "label": "", "metadata": {}, "score": "64.72429"}
{"text": "Harvard University Press .Koby Crammer , Ofer Dekel , Joseph Keshet , Shai Shalev-Shwartz , and Yoram Singer .Online passive- aggressive algorithms .Journal of Machine Learning Research , 7:551 - 585 , Mar. R. Johansson and P. Nugues .", "label": "", "metadata": {}, "score": "64.76279"}
{"text": "Semantic parsing is the construction of a complete , formal , symbolic meaning representation of a sentence .While it is crucial to natural language understanding , the problem of semantic parsing has received relatively little attention from the machine learning community .", "label": "", "metadata": {}, "score": "64.78967"}
{"text": "Automatic Construction of Semantic Lexicons for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixteenth National Conference on Artificial Intelligence ( AAAI-99 ) , 487 - 493 , Orlando , FL , July 1999 .", "label": "", "metadata": {}, "score": "64.9456"}
{"text": "At the API level , with the factored parser , if you ask for getBestDependencyParse ( ) , then you will get the best untyped dependency parse .If you call that method with englishPCFG.ser.gz , it will return null , as there is no dependency parse .", "label": "", "metadata": {}, "score": "65.00142"}
{"text": "In general , with appropriate grammars loaded , you can parse with and ask for output of the PCFG , ( untyped ) dependency , or factored parsers .For English , although the grammars and parsing methods differ , the average quality of englishPCFG.ser.gz and englishFactored.ser.gz is similar , and so many people opt for the faster englishPCFG.ser.gz , though englishFactored.ser.gz sometimes does better because it does include lexicalization .", "label": "", "metadata": {}, "score": "65.07887"}
{"text": "The annotations are produced automatically with statistical models that are specifically adapted to historical text .The corpus will facilitate the study of linguistic trends , especially those related to the evolution of syntax .Syntactic analysis of search queries is important for a variety of information- retrieval tasks ; however , the lack of annotated data makes training query analysis models difficult .", "label": "", "metadata": {}, "score": "65.121796"}
{"text": "We show that dependency parsers have more difficulty parsing questions than constituency parsers .In particular , deterministic shift - reduce dependency parsers , which are of highest interest for practical applications because of their linear running time , drop to 60 % labeled accuracy on a question test set .", "label": "", "metadata": {}, "score": "65.66658"}
{"text": "For a semantic parser to work well , conformity between natural language and meaning representation grammar is necessary .However meaning representation grammars are typically designed to best suit the application which will use the meaning representations with little consideration for how well they correspond to natural language semantics .", "label": "", "metadata": {}, "score": "65.75488"}
{"text": "International Conference on Computational Linguistics ( COLING 2010 ) , 543 - -551 , Beijing , China , August 2010 .We present a probabilistic generative model for learning semantic parsers from ambiguous supervision .Our approach learns from natural language sentences paired with world states consisting of multiple potential logical meaning representations .", "label": "", "metadata": {}, "score": "65.84941"}
{"text": "It is known for it 's speed , stability , and scalability .One of its best features is the extensive collection of well - written tutorials to help you get started .They have a list of links to competition , both academic and industrial tools .", "label": "", "metadata": {}, "score": "65.918915"}
{"text": "We present a system that learns to transform natural - language navigation instructions into executable formal plans .Given no prior linguistic knowledge , the system learns by simply observing how humans follow navigation instructions .The system is evaluated in three complex virtual indoor environments with numerous objects and landmarks .", "label": "", "metadata": {}, "score": "65.95415"}
{"text": "See especially the sample invocation in the parser.lexparser package documentation .The included file makeSerialized.csh effectively documents how the included grammars were made .The included file ParserDemo.java gives a good first example of how to call the parser programmatically , including getting Tree and typedDependencies output .", "label": "", "metadata": {}, "score": "65.98322"}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .Training the system requires sentences annotated with augmented parse trees .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .", "label": "", "metadata": {}, "score": "66.07634"}
{"text": "We introduce a dialog agent for mobile robots that understands human instructions through semantic parsing , actively resolves ambiguities using a dialog manager , and incrementally learns from human - robot conversations by inducing training data from user paraphrases .Our dialog agent is implemented and tested both on a web interface with hundreds of users via Mechanical Turk and on a mobile robot over several days , tasked with understanding navigation and delivery requests through natural language in an office environment .", "label": "", "metadata": {}, "score": "66.20456"}
{"text": "While multiple LexicalizedparserQuery threads share the same grammar ( LexicalizedParser ) , the memory space savings are n't huge , as most of the memory goes to the transient data structures used in chart parsing .So , if you are running lots of parsing threads concurrently , you will need to give a lot of memory to the JVM .", "label": "", "metadata": {}, "score": "66.232925"}
{"text": "If you want to display the output in a command window , you separately also need to work out what character set your computer supports for display .If that is different to the encoding of the file , you will need to convert the encoding for display .", "label": "", "metadata": {}, "score": "66.342155"}
{"text": "Here are example commands for parsing two of the test files , one in UTF-8 and one in GB18030 .The ( Linux ) computer that this is being run on is set up to work with UTF-8 ( and this webpage is also in UTF-8 ) , so for the case of GB18030 , the output is piped through the Unix iconv utility for display .", "label": "", "metadata": {}, "score": "66.39314"}
{"text": "It is such an ambitious task that it sometimes is referred to as an AI - complete problem , implying that its difficulty is equivalent to solving the central artificial intelligence problem -- making computers as intelligent as people .Despite its complexity , natural language understanding continues to be a fundamental problem in natural language processing in terms of its theoretical and empirical importance .", "label": "", "metadata": {}, "score": "66.41651"}
{"text": "ML ID : 314 .Semantic Parsing using Distributional Semantics and Probabilistic Logic [ Details ] [ PDF ][Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .", "label": "", "metadata": {}, "score": "66.5239"}
{"text": "In Conference on Natural Language Learning ( CoNLL ) .J. Nivre , J. Hall , S. K\u00a8 ubler , R. McDonald , J. Nils- son , S. Riedel , and D. Yuret .2007 shared task on dependency parsing . of the CoNLL 2007 Shared Task .", "label": "", "metadata": {}, "score": "66.567276"}
{"text": "A new system , Wolfie , learns semantic lexicons to be used as background knowledge by a previously developed parser acquisition system , Chill .The combined system is tested on a real world domain of answering database queries .We also compare this combination to a combination of Chill with a previously developed lexicon learner , demonstrating superior performance with our system .", "label": "", "metadata": {}, "score": "66.90664"}
{"text": "ML ID : 95 .Active Learning for Natural Language Parsing and Information Extraction [ Details ] [ PDF ] Cynthia A. Thompson , Mary Elaine Califf and Raymond J. Mooney In Proceedings of the Sixteenth International Conference on Machine Learning ( ICML-99 ) , 406 - 414 , Bled , Slovenia , June 1999 .", "label": "", "metadata": {}, "score": "67.11369"}
{"text": "We use separate buckets for each n - gram model being interpolated .In performing this bucketing , we create an array containing how many n - grams occur for each value of P w i c(w i i\\Gamman+1 ) up to ... . \" ...", "label": "", "metadata": {}, "score": "67.290726"}
{"text": "This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with representations of their meaning , and allows for both synonymy and polysemy .", "label": "", "metadata": {}, "score": "67.47191"}
{"text": "All of these tasks are accomplished within the same framework , using a single , general learning method that can acquire new syntactic and semantic categories for resolving ambiguities .Experimental evidence from both aritificial and real - world corpora demonstrate that CHILL learns parsers as well or better than previous artificial neural network or probablistic approaches on comparable tasks .", "label": "", "metadata": {}, "score": "67.6356"}
{"text": "There is n't a separate included tagger ; the parser does POS tagging as part of parsing .Yes , you can .You can use the main method of EnglishGrammaticalStructure ( for English , or the corresponding class for Chinese ) .", "label": "", "metadata": {}, "score": "68.07506"}
{"text": "To turn these off , you can use the following options : .At present , we do n't have any documentation beyond what you get in the download and what 's on this page .If you would like to help by producing better documentation , feel free to write to parser-support@lists.stanford.edu .", "label": "", "metadata": {}, "score": "68.144196"}
{"text": "The ATIS corpus of airline information queries was used to test the acquisition of syntactic parsers , and CHILL performed competitively with recent statistical methods .English queries to a small database on U.S. geography were used to test the acquisition of a complete natural language interface , and the parser that CHILL acquired was more accurate than an existing hand - coded system .", "label": "", "metadata": {}, "score": "68.41452"}
{"text": "Further experiments showed that any decrease in training data hurt parser perfor- mance .It would seem that the parser has no dif- ficulty learning important training sentences in the presence of unimportant training examples .A related idea focused on words , weighing highly tokens that appeared frequently in the target domain .", "label": "", "metadata": {}, "score": "68.555984"}
{"text": "Since the guidelines differ , we observe no corresponding structure in the WSJ .It is telling that the parser labels this BIO example by attaching ev- ery token to the final proper noun \" P1 - 1 \" , exactly as the WSJ guidelines indicate .", "label": "", "metadata": {}, "score": "68.60005"}
{"text": "A brief demo program included with the download will demonstrate how to load the tool and start processing text .When using this demo program , be sure to include all of the appropriate jar files in the classpath .For part - of - speech tags and phrasal categories , this depends on the language and treebank on which the parser was trained ( and was decided by the treebank producers not us ) .", "label": "", "metadata": {}, "score": "68.66795"}
{"text": "Learning Language Semantics from Ambiguous Supervision [ Details ] [ PDF ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the 22nd Conference on Artificial Intelligence ( AAAI-07 ) , 895 - 900 , Vancouver , Canada , July 2007 .", "label": "", "metadata": {}, "score": "68.94334"}
{"text": "Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .On the other hand , our grammars are much more compact and substantially more accurate than previous work on automatic annotation .Despite its simplicity , our best grammar achieves an F1 of 89.9 % on the Penn Treebank , higher than most fully lexicalized systems .", "label": "", "metadata": {}, "score": "69.0529"}
{"text": "Experimental results show that the number of examples needed to reach a given level of performance can be significantly reduced with this method .ML ID : 90 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixth Workshop on Very Large Corpora , Montreal , Quebec , Canada , August 1998 .", "label": "", "metadata": {}, "score": "69.226654"}
{"text": "The CHILL Prolog code is available via anonymous ftp .See the INDEX file there for details .Pointers to papers on CHILL and CHILLIN can be found on our Natural - Language Learning and ILP research page .Below are some standard references ( click on the open book image ) .", "label": "", "metadata": {}, "score": "69.229965"}
{"text": "The problem occurs in the domain of lexical acquisition .The ambiguous and synonymous nature of words causes the difficulty of using standard induction techniques to learn a lexicon .Additionally , negative examples are typically unavailable or difficult to construct in this domain .", "label": "", "metadata": {}, "score": "69.6757"}
{"text": "Integrating Statistical and Relational Learning for Semantic Parsing : Applications to Learning Natural Language Interfaces for Databases [ Details ] [ PDF ] Lappoon R. Tang May 2000 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .", "label": "", "metadata": {}, "score": "69.844666"}
{"text": "The lexicon , or the mapping from words to meanings , is one component that is typically difficult to update and that changes from one domain to the next .Therefore , automating the acquisition of the lexicon is an important task in automating the acquisition of NLP systems .", "label": "", "metadata": {}, "score": "69.868935"}
{"text": "Extras includeExtras , boolean threadSafe , Predicate . filter , . boolean originalDependencies )So , for a research project of mine ( Bachelor thesis )I need to analyze the sentiment of tweets about certain companies and brands .For this purpose I will need to script my own program / use some sort of modified open source code ( no APIs ' - I need to understand what is happening ) .", "label": "", "metadata": {}, "score": "69.92628"}
{"text": "Inductive Logic Programming for Natural Language Processing [ Details ] [ PDF ] Raymond J. Mooney In Stephen Muggleton , editors , Inductive Logic Programming : Selected papers from the 6th International Workshop , 3 - 22 , Berlin , 1996 .", "label": "", "metadata": {}, "score": "70.09273"}
{"text": "The relevant options are -sentences ( see above ) , -tokenized , -tokenizerFactory , -tokenizerMethod , and -tagSeparator .If , for example , you want to denote a POS tag by appending /POS on a word , you would include the options -tokenized -tagSeparator / -tokenizerFactory edu.stanford.nlp.process.WhitespaceTokenizer -tokenizerMethod newCoreLabelTokenizerFactory in your invocation of LexicalizedParser .", "label": "", "metadata": {}, "score": "70.37804"}
{"text": "With this code , you should be able to parse the sentence in a file with a command like this ( details depending on your shell , OS , etc . ) : . java -mx200 m -cp \" stanford - parser .", "label": "", "metadata": {}, "score": "70.57265"}
{"text": "Semantic lexicons can also be learned from semantically annotated sentences and are an important source of knowledge for semantic parsing .Learning for semantic parsing is part of our research on natural language learning .\" The fish trap exists because of the fish .", "label": "", "metadata": {}, "score": "70.57525"}
{"text": "Below are some statistics for 32-bit operation with the supplied englishPCFG and englishFactoredGrammars .We have parsed sentences as long as 234 words , but you need lots of RAM and patience .You can use the -outputFormat wordsAndTags option .", "label": "", "metadata": {}, "score": "70.6094"}
{"text": "ML ID : 171 .Learning to Transform Natural to Formal Languages [ Details ] [ PDF ] [ Slides ] Rohit J. Kate , Yuk Wah Wong and Raymond J. Mooney In Proceedings of the Twentieth National Conference on Artificial Intelligence ( AAAI-05 ) , 1062 - 1068 , Pittsburgh , PA , July 2005 .", "label": "", "metadata": {}, "score": "70.655945"}
{"text": "For some sentences the parse tree output by the standalone parser and the tree output by the CoreNLP pipeline can be different .The reason for this is that if you run the CoreNLP pipeline with the default annotators , it will run a part - of - speech ( POS ) tagger before running the parser .", "label": "", "metadata": {}, "score": "70.66641"}
{"text": "Genia ( biomedical English ) .Originally we used the treebank beta version reformatted by Andrew Clegg , his training split , but more recently ( 1.6.5 + ? ) we 've used the official Treebank , and David McClosky 's splits .", "label": "", "metadata": {}, "score": "70.729256"}
{"text": "Of course , parsing will suffer unless your tokenization accurately matches the tokenization of the underlying treebank , for instance Penn Treebank tokenization .A common occurrence is that your text is already correctly tokenized but does not escape characters the way the Penn Treebank does ( turning parentheses into -LRB- and -RRB- , and putting a backslash in front of forward slashes and asterisks - presumably a holdover from Lisp ) .", "label": "", "metadata": {}, "score": "70.78463"}
{"text": "An example of this command line is java -mx12 g edu.stanford.nlp.parser.dvparser.DVParser -cachedTrees /path / to / cached .wsj.ser.gz -train -testTreebank /path / to / wsj 2200 - 2219 -debugOutputFrequency 500 -trainingThreads 8 -parser /path / to / pcfg / pcfg.ser.gz -dvIterations 40 -dvBatchSize 25 -wordVectorFile /path / to / embedding -model /scr / nlp / data / dvparser / wsj / train / averaged / averaged . ser.gz .", "label": "", "metadata": {}, "score": "71.03288"}
{"text": "aFor text mining , preprocessing the EHR corpus with fingerprinting yields significantly better results .Conclusions Before applying text - mining techniques , one must pay careful attention to the structure of the analyzed corpora .While the importance of data cleaning has been known for low - level text characteristics ( e.g. , encoding and spelling ) , high - level and difficult - to - quantify corpus characteristics , such as naturally occurring redundancy , can also hurt text mining .", "label": "", "metadata": {}, "score": "71.25339"}
{"text": "Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind ( 1996 ) , with results favorable to Wolfie .", "label": "", "metadata": {}, "score": "71.26405"}
{"text": "Starting with version 1.6.2 of the parser , there is a fairly flexible scheme for options in tokenization style .You can give options such as this one to turn off Americanization of spelling : .Or this one to change several options : .", "label": "", "metadata": {}, "score": "71.4099"}
{"text": "ML ID : 272 .Learning Language from Ambiguous Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .Building a computer system that can understand human languages has been one of the long - standing goals of artificial intelligence .", "label": "", "metadata": {}, "score": "71.42447"}
{"text": "The development data was 200 sentences of labeled biomedical oncology text ( BIO , the ONCO portion of the Penn Biomedical Treebank ) , as well as 200 K unlabeled sentences ( Kulick et al ., 2004 ) .The two test domains were a collection of medline chem- istry abstracts ( pchem , the CYP portion of the Penn Biomedical Treebank ) and the Child Language Data Exchange System corpus ( CHILDES ) ( MacWhin- ney , 2000 ; Brown , 1973 ) .", "label": "", "metadata": {}, "score": "71.472275"}
{"text": "Finally , we also show that ensembles of different semantic parser learning systems can obtain the best overall performance .ML ID : 215 .Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}, "score": "71.48188"}
{"text": "Four of the parsers assume input that has already been word segmented , while the fifth does word segmentation internal to the parser .This is discussed further below .The parser also comes with 3 Chinese example sentences , in files whose names all begin with chinese .", "label": "", "metadata": {}, "score": "71.48485"}
{"text": "Experiments show the potential of the approach .ML ID : 301 .Grounded Language Learning Models for Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joo Hyun Kim PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2013 .", "label": "", "metadata": {}, "score": "71.578"}
{"text": "Around 2009 , we parsed large volumes of text at a rate of about 1,000,000 sentences a day by distributing the work over 6 dual core / dual processor machines .Sure ! !These instructions concentrate on parsing from the command line , since you need to use that to be able to set most options .", "label": "", "metadata": {}, "score": "71.58267"}
{"text": "CHILL .CHILL ( Constructive Heuristics Induction for Language Learning ) is a general approach to the problem of inducing natural language parsers .Given a suitably annotated corpus , CHILL produces a parser for mapping subsequent sentences into representations .It treats parser induction as the problem of learning rules to control the actions of a shift - reduce parser expressed as a Prolog program .", "label": "", "metadata": {}, "score": "71.61729"}
{"text": "The download is a 261 MB zipped file ( mainly consisting of included grammar data files ) .If you unpack the zip file , you should have everything needed .Simple scripts are included to invoke the parser on a Unix or Windows system .", "label": "", "metadata": {}, "score": "71.70032"}
{"text": "See the parser.lexparser package documentation , the LexicalizedParser.main method documentation , the TreePrint class , and the documentation of variables in the Train , Test , and Options classes , and appropriate language - particular TreebankLangParserParams .For the rest , you need to look at the source code .", "label": "", "metadata": {}, "score": "71.726715"}
{"text": "By allowing both approaches to induce program clauses and choosing the best combination of their results , Cocktail learns more effective parsers .Experimental results on learning natural - language interfaces for two databases demonstrate that it learns more accurate parsers than Chillin , the previous best method for this task .", "label": "", "metadata": {}, "score": "71.80597"}
{"text": "This study is applied to three languages that exhibit different levels of morphological expressiveness : Arabic , French and English .We integrate information about Arabic affixes and morphotactics into a PCFG - LA parser and obtain stateof - the - art accuracy .", "label": "", "metadata": {}, "score": "72.005486"}
{"text": "Compared to a previous generative model for semantic alignment , it also supports full semantic parsing .Experimental results on the Robocup sportscasting corpora in both English and Korean indicate that our approach produces more accurate semantic alignments than existing methods and also produces competitive semantic parsers and improved language generators .", "label": "", "metadata": {}, "score": "72.053375"}
{"text": "This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with meaning representations .", "label": "", "metadata": {}, "score": "72.05589"}
{"text": "Primary acoustic , speech , and vision systems were trained to discriminate instances of the categories .Higher - level systems exploited correlations among the categories , incorporated sequential context , and combined the joint evidence from the three information sources .", "label": "", "metadata": {}, "score": "72.08481"}
{"text": "This is an element of the dependency analysis we adopted .It 's not uncontroversial , and it could have been done differently , but we 'll try to explain briefly why we did things the way we did .The general philosophy of the grammatical relations design is that main predicates should be heads and auxiliaries should not .", "label": "", "metadata": {}, "score": "72.130936"}
{"text": "We compare a number of semantic parsing approaches on the highly noisy training data collected from ordinary users , and find that loosely synchronous systems perform best .ML ID : 317 .Intelligent robots frequently need to understand requests from naive users through natural language .", "label": "", "metadata": {}, "score": "72.153915"}
{"text": "Since these annotations are new with respect to the WSJ guidelines , it is impossi- ble to parse these without injecting knowledge of the annotation guidelines.3 common , comprising 33 % of BIO and 30 % of WSJ tokens , the most popular POS tag by far .", "label": "", "metadata": {}, "score": "72.20279"}
{"text": "In Proc . of the 16th Nordic Conference on Computational Linguistics ( NODALIDA ) .Extended Sandra K\u00a8 ubler . schemes influence parsing results ? or how not to com- pare apples and oranges .In RANLP .How do treebank annotation 1054 .", "label": "", "metadata": {}, "score": "72.22688"}
{"text": "Training data consists of natural language sentences annotated with multiple potential meaning representations , only one of which is correct .Such ambiguous supervision models the type of supervision that can be more naturally available to language - learning systems .Given such weak supervision , our approach produces a semantic parser that maps sentences into meaning representations .", "label": "", "metadata": {}, "score": "72.33453"}
{"text": "Publications : Learning for Semantic Parsing .Semantic parsing is the process of mapping a natural - language sentence into a formal representation of its meaning .A shallow form of semantic representation is a case - role analysis ( a.k.a . a semantic role labeling ) , which identifies roles such as agent , patient , source , and destination .", "label": "", "metadata": {}, "score": "72.37673"}
{"text": "Integrated annotation for biomedical information ex- traction .In Proc . of the Human Language Technol- ogy Conference and the Annual Meeting of the North American Chapter of the Association for Computa- tional Linguistics ( HLT / NAACL ) .B. MacWhinney .", "label": "", "metadata": {}, "score": "72.60208"}
{"text": "ML ID : 99 .Learning for Semantic Interpretation : Scaling Up Without Dumbing Down [ Details ] [ PDF ] Raymond J. Mooney In Workshop Notes for the Workshop on Learning Language in Logic , 7 - 15 , Bled , Slovenia , 2000 .", "label": "", "metadata": {}, "score": "72.792786"}
{"text": "By only observing how humans follow navigation instructions , the system was able to infer the corresponding hidden navigation plans and parse previously unseen instructions in new environments for both English and Chinese data .With the rise in popularity of crowdsourcing , we also present results on collecting additional training data using Amazon 's Mechanical Turk .", "label": "", "metadata": {}, "score": "72.81958"}
{"text": "If this question can be reworded to fit the rules in the help center , please edit the question . 1 Answer 1 .I 'm not sure how much I can help , but I have worked with hand - rolled NLP before .", "label": "", "metadata": {}, "score": "72.84215"}
{"text": "Computers fail to track these in fast video , but sleight of hand fools humans as well : what happens too quickly we just can not see .We show a 3D tracker for these types of motions that relies on the recognition of familiar configurations in 2D images ( classification ) , and fills the gaps in - between ( interpolation ) .", "label": "", "metadata": {}, "score": "72.87362"}
{"text": "Lawrence Erlbaum .M. Marcus , B. Santorini , and M. Marcinkiewicz .Building a large annotated corpus of English : the Penn Treebank .Computational Linguistics , 19(2):313 - 330 .Ryan McDonald , Kevin Lerman , and Fernando Pereira .", "label": "", "metadata": {}, "score": "72.87475"}
{"text": "Parsing file : chinese-onesent-unseg.txt with 1 sentences .Parsing [ sent .1 len .falling back to PCFG parse .Parsed 5 words in 1 sentences ( 6.08 wds / sec ; 1.22 sents / sec ) .1 sentences were parsed by fallback to PCFG .", "label": "", "metadata": {}, "score": "72.88846"}
{"text": "Behavior Control : Finally we show how all these elements can be incorporated into a goal keeping robot .We develop simple behaviors that can be used in a layered architecture and enable the robot to block most balls that are being shot at the goal .", "label": "", "metadata": {}, "score": "73.18969"}
{"text": "Learning for Semantic Parsing Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] [ Slides ] Ruifang Ge PhD Thesis , Department of Computer Science , University of Texas at Austin , Austin , TX , May 2010 .165 pages .", "label": "", "metadata": {}, "score": "73.24577"}
{"text": "Tree least general generalizations ( TLGGs ) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences .The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears .", "label": "", "metadata": {}, "score": "73.271286"}
{"text": "Yes .The parser treats a filename as - as meaning to read from stdin and by default writes to stdout ( this can be changed with the -writeOutputFiles option ) .Note : the tokenizer uses lookahead , so you will either need to close the input to get the last sentence parsed , or use another option like -sentences newline .", "label": "", "metadata": {}, "score": "73.33589"}
{"text": "Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .A long - standing goal for the field of artificial intelligence is to enable computer understanding of human languages .A core requirement in reaching this goal is the ability to transform individual sentences into a form better suited for computer manipulation .", "label": "", "metadata": {}, "score": "73.52421"}
{"text": "Apache Lucene Mahout - An incubator project to created highly scalable distributed implementations of common machine learning algorithms on top of the Hadoop map - reduce framework .NLP Tools .LingPipe - ( not technically ' open - source , see below ) Alias - I 's Lingpipe is a suite of java tools for linguistic processing of text including entity extraction , speech tagging ( pos ) , clustering , classification , etc ..", "label": "", "metadata": {}, "score": "73.68082"}
{"text": "This answer is specific to English .It mostly applies to other languages although some components are missing in some languages .The file englishPCFG.ser.gz comprises just an unlexicalized PCFG grammar .It is basically the parser described in the ACL 2003 Accurate Unlexicalized Parsing paper .", "label": "", "metadata": {}, "score": "73.86047"}
{"text": "It contains a set of tutorials and data sets for experimentation .It is written by Steven Bird , from the University of Melbourne .Opinion Finder - A system that performs subjectivity analysis , automatically identifying when opinions , sentiments , speculations and other private states are present in text .", "label": "", "metadata": {}, "score": "74.046104"}
{"text": "In the area of program optimization , a prototype system , DOLPHIN , is able to transform some intractable specifications into polynomial - time algorithms , and outperforms competing approaches in several benchmark speedup domains .A prototype language acquisition system , CHILL , is also described .", "label": "", "metadata": {}, "score": "74.11435"}
{"text": "By default , our Chinese parser uses GB18030 ( the native character encoding of the Penn Chinese Treebank and the national encoding of China ) for input and output .However , it is very easy to parse text in another character encoding : you simply give the flag -encoding encoding to the parser , where encoding is a character set encoding name recognized within Java , such as : UTF-8 , Big5-HKSCS , or GB18030 .", "label": "", "metadata": {}, "score": "74.17407"}
{"text": "There are two major ILP approaches : top - down and bottom - up .The former searches the hypothesis space from general to specific while the latter the other way round .Integrating both approaches has been demonstrated to be more effective .", "label": "", "metadata": {}, "score": "74.19429"}
{"text": "Experimental results are presented on learning to map English coaching instructions for Robocup soccer into an existing formal language for coaching simulated robotic agents .ML ID : 140 .Learning Semantic Parsers : An Important But Under - Studied Problem [ Details ] [ PDF ] Raymond J. Mooney In Papers from the AAAI 2004 Spring Symposium on Language Learning : An Interdisciplinary Perspective , 39 - -44 , Stanford , CA , March 2004 .", "label": "", "metadata": {}, "score": "74.20882"}
{"text": "Without the temporal annotation , some simple temporals like today will still be recognized , but a bare temporal like last week in I left last week will be tagged as an object ( dobj ) .With the Stanford parser , you can get marking of temporal NPs in the tree output by giving the option -retainTmpSubcategories , either on the command line or by passing it to the setOptionFlags(String [ ] ) method of the parser .", "label": "", "metadata": {}, "score": "74.277435"}
{"text": "NN , NNP - NNP - NNP , NN - IN - NN , and IN - NN - NN .However , when we examine the coarse POS tags , which do not distinguish between nouns , these dif- ferences disappear .", "label": "", "metadata": {}, "score": "74.308014"}
{"text": "One core issue toward this goal is \" grounded \" language learning , a process of learning the semantics of natural language with respect to relevant perceptual inputs .In order to ground the meanings of language in a real world situation , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .", "label": "", "metadata": {}, "score": "74.48747"}
{"text": "You can invoke it with the -escaper flag , by using a command like the following ( which also shows output being sent to a file ) : . stp .Word segmentation : Chinese is not normally written with spaces between words .", "label": "", "metadata": {}, "score": "74.63166"}
{"text": "ML ID : 47 .Acquisition of a Lexicon from Semantic Representations of Sentences [ Details ] [ PDF ] Cynthia A. Thompson In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL-95 ) , 335 - 337 , Cambridge , MA , 1995 .", "label": "", "metadata": {}, "score": "74.6882"}
{"text": "The parser is supplied with 5 Chinese grammars ( and , with access to suitable training data , you could train other versions ) .You can find them inside the supplied stanford - parser- YYYY - MM - DD -models.jar file ( in the GUI , select this file and then navigate inside it ; at the command line , use jar -tf to see its contents ) .", "label": "", "metadata": {}, "score": "74.72866"}
{"text": "Ball Tracking :The reliable tracking of the ball is vital in robot soccer .Therefore a Kalman - filter based system for estimating the ball position and velocity in the presence of occlusions is developped . -Sensor Fusion : The robot perceives its environment through several independent sensors ( camera , odometer , etc . ) , which have different delays .", "label": "", "metadata": {}, "score": "74.808655"}
{"text": "This frequently seems to confuse people , because the main predicate of the clause is now not a verb .But we believe that this is the best thing to do for several reasons : .Consistency of treatment of auxiliary / copula between English periphrastic verb forms and adjectival / nominal predications .", "label": "", "metadata": {}, "score": "74.817955"}
{"text": "There is considerable Javadoc documentation included in the javadoc/ directory of the distribution .You should start by looking at the javadoc for the parser.lexparser package and the LexicalizedParser class .( The documentation appearing on the nlp.stanford.edu website refers to code under development and is not necessarily consistent with the released version of the parser . )", "label": "", "metadata": {}, "score": "74.82352"}
{"text": "This decision effectively removes NNP from the BIO domain and renders all features that depend on the NNP tag ineffective .In our above BIO NP example , all nouns are labeled NN , whereas the WSJ example contains NNP tags .", "label": "", "metadata": {}, "score": "74.866875"}
{"text": "As of version 3.4 in 2014 , the parser includes the code necessary to run a shift reduce parser , a much faster constituent parser with competitive accuracy .Models for this parser are linked below .Neural - network dependency parser .", "label": "", "metadata": {}, "score": "75.12838"}
{"text": "ML ID : 66 .Corpus - Based Lexical Acquisition For Semantic Parsing [ Details ] [ PDF ] Cynthia Thompson February 1996 .Ph.D. proposal .Building accurate and efficient natural language processing ( NLP ) systems is an important and difficult problem .", "label": "", "metadata": {}, "score": "75.26868"}
{"text": "Yes , you can .Various tokenizers are included .The one used for English is called PTBTokenizer .It is a hand - written rule - based ( FSM ) tokenizer , but is quite accurate over newswire - style text .", "label": "", "metadata": {}, "score": "75.45399"}
{"text": "We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task .For languages from different families the improvements often exceed 2 BLEU .Many of these gains are also significant in human evaluations .We present a new collection of treebanks with homogeneous syntactic dependency annotation for six languages : German , English , Swedish , Spanish , French and Korean .", "label": "", "metadata": {}, "score": "75.45588"}
{"text": "We selected with replacement 2000 training examples from the training data and trained three parsers .Each parser then tagged the remain- ing 13 K sentences , yielding 39 K parsed sentences .We then shuffled these sentences and trained a final parser .", "label": "", "metadata": {}, "score": "75.48602"}
{"text": "Generative Models of Grounded Language Learning with Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joohyun Kim Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , June 2012 . \"", "label": "", "metadata": {}, "score": "75.83281"}
{"text": "Both words were unknown only 5 % of the time in BIO , while one of the words being un- known was more common , reflecting 27 % of deci- sions .Upon further investigation , the majority of unknown words were nouns , which indicates that unknown word errors were caused by the problems discussed above .", "label": "", "metadata": {}, "score": "76.17943"}
{"text": "Initially , the system will passively observe a human giving instruction to another human , and try to learn the correspondences between the instructions and the intended plan .After the system has a decent understanding of the language , it can then participate in the interactions to learn more directly by playing either the role of the instructor or the follower .", "label": "", "metadata": {}, "score": "76.23543"}
{"text": "5 Acknowledgments We thank Joel Wallenberg and Nikhil Dinesh for their informative and helpful linguistic expertise , Kevin Lerman for his edge labeler code , and Koby Crammer for helpful conversations .Dredze is sup- ported by a NDSEG fellowship ; Ganchev and Taluk- dar by NSF ITR EIA-0205448 ; and Blitzer by DARPA under Contract No . NBCHD03001 .", "label": "", "metadata": {}, "score": "76.25963"}
{"text": "Learning Language from Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen December 2009 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .Most current natural language processing ( NLP ) systems are built using statistical learning algorithms trained on large annotated corpora which can be expensive and time - consuming to collect .", "label": "", "metadata": {}, "score": "76.39503"}
{"text": "ML ID : 130 .Acquiring Word - Meaning Mappings for Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Journal of Artificial Intelligence Research , 18:1 - 44 , 2003 .This paper focuses on a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .", "label": "", "metadata": {}, "score": "76.52904"}
{"text": "An example is the above BIO NP , in which the phrase \" glutathione transferase P1 - 1 \" is an appositive indicating which \" enzyme \" is meant .However , since there are no commas , the parser thinks \" P1 - 1 \" is the head .", "label": "", "metadata": {}, "score": "76.534164"}
{"text": "The parser outputs typed dependency parses for English and Chinese .The models for this parser are included in the general Stanford Parser models package .Dependency scoring .The package includes a tool for scoring of generic dependency parses , in a class edu.stanford.nlp.trees.", "label": "", "metadata": {}, "score": "76.56883"}
{"text": "For example , this command ( with appropriate paths ) will convert a Penn Treebank file to uncollapsed typed dependencies : . java -cp stanford-parser.jar edu.stanford.nlp.trees.EnglishGrammaticalStructure -treeFile wsj/02/wsj_0201 .mrg -basic .Also , here is a sample Java class that you can download that converts from an input file of trees to typed dependencies .", "label": "", "metadata": {}, "score": "76.614136"}
{"text": "Attia , Mohammed and Foster , Jennifer and Hogan , Deirdre and Le Roux , Joseph and Tounsi , Lamia and van Genabith , Josef ( 2010 ) Handling unknown words in statistical latent - variable parsing models for Arabic , English and French .", "label": "", "metadata": {}, "score": "76.73884"}
{"text": "Second , adopting a syntax - based approach allows us to directly leverage the enormous progress made in statistical syntactic parsing .The first semantic parser , SCISSOR , adopts an integrated syntactic - semantic parsing approach , in which a statistical syntactic parser is augmented with semantic parameters to produce a semantically - augmented parse tree ( SAPT ) .", "label": "", "metadata": {}, "score": "77.02326"}
{"text": "We feel that this is more useful for most semantic interpretation applications , because it directly connects the main predicate with its arguments , while the auxiliary is rendered as modifying the verb ( aux(singing , is ) ) .Most people seem to agree .", "label": "", "metadata": {}, "score": "77.08296"}
{"text": "Eve ... \" .Interactive spoken dialogue provides many new challenges for natural language understanding systems .One of the most critical challenges is simply determining the speaker 's intended utterances : both segmenting a speaker 's turn into utterances and determining the intended words in each utterance .", "label": "", "metadata": {}, "score": "77.14837"}
{"text": "To facilitate future research in unsupervised induction of syntactic structure and to standardize best - practices , we propose a tagset that consists of twelve universal part - of - speech categories .In addition to the tagset , we develop a mapping from 25 different treebank tagsets to this universal set .", "label": "", "metadata": {}, "score": "77.19488"}
{"text": "These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .", "label": "", "metadata": {}, "score": "77.42403"}
{"text": "These results support the claim that ILP techniques as implemented in CHILL represent a viable alternative with significant potential advantages over neural - network , propositional , and probablistic approaches to empirical parser construction .ML ID : 48 .This paper presents results from recent experiments with CHILL , a corpus - based parser acquisition system .", "label": "", "metadata": {}, "score": "77.425735"}
{"text": "( Since these parsers were written , direct typed dependency parsers have been increasingly explored .Both us and others have now built parsers that directly parse to Stanford Dependencies .See the Stanford Dependencies page for more information . )For Chinese ( and Arabic , German , and \" WSJ \" ) , you can look at the included file makeSerialized.csh , and easily see exactly what files the models are trained on , in terms of LDC or Negra file numbers .", "label": "", "metadata": {}, "score": "77.4869"}
{"text": "They are : .PCFG .Factored .Factored , segmenting .Xinhua ( mainland , newswire ) .xinhuaPCFG.ser.gz . xinhuaFactored.ser.gz .xinhuaFactoredSegmenting.ser.gz .Mixed Chinese .chinesePCFG.ser.gz . chineseFactored.ser.gz .The PCFG parsers are smaller and faster .But the Factored parser is significantly better for Chinese , and we would generally recommend its use .", "label": "", "metadata": {}, "score": "77.61394"}
{"text": "Learning for Semantic Parsing [ Details ] [ PDF ] Raymond J. Mooney In A. Gelbukh , editors , Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , 311 - -324 , Mexico City , Mexico , February 2007 .", "label": "", "metadata": {}, "score": "77.870445"}
{"text": "ML ID : 180 .A Statistical Semantic Parser that Integrates Syntax and Semantics [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of CoNLL-2005 , Ann Arbor , Michigan , June 2005 .We introduce a learning semantic parser , Scissor , that maps natural - language sentences to a detailed , formal , meaning - representation language .", "label": "", "metadata": {}, "score": "78.06504"}
{"text": "Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries .ML ID : 219 .Learning for Semantic Parsing with Kernels under Various Forms of Supervision [ Details ] [ PDF ] [ Slides ] Rohit J. Kate PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}, "score": "78.103836"}
{"text": "LingPipe is released under a royalty - free commercial license that includes the source code , but it 's not technically ' open - source ' .OpenNLP - hosts a variety of java - based NLP tools which perform sentence detection , tokenization , part - of - speech tagging , chunking and parsing , named - entity detection , and co - reference analysis using the Maxent machine learning package .", "label": "", "metadata": {}, "score": "78.22395"}
{"text": "The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .", "label": "", "metadata": {}, "score": "78.256615"}
{"text": "We would recommend their use for parsing material from mainland China .The chinese grammars also include some training material from Hong Kong SAR and Taiwan .We 'd recommend their use if parsing material from these areas or a mixture of text types .", "label": "", "metadata": {}, "score": "78.631256"}
{"text": "The new Viewer adds three features for more powerful search : wildcards , morphological inflections , and capitalization .These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text .", "label": "", "metadata": {}, "score": "78.78649"}
{"text": "For instance : .Parsing file : chinese - onesent with 1 sentences .Parsing [ sent .1 len .Parsed 10 words in 1 sentences ( 7.10 wds / sec ; 0.71 sents / sec ) .There are many kinds of ' vanilla ' , but , providing your treebank is in Penn Treebank format , then , yes , this is easy to do .", "label": "", "metadata": {}, "score": "78.82654"}
{"text": "Finally , we also plan to investigate ways to combine our semantic parser with some recently developed semantic parsers to form committees in order to get the best overall performance .ML ID : 181 .Learning for Semantic Parsing Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong 2005 .", "label": "", "metadata": {}, "score": "78.86398"}
{"text": "This paper reviews our prior work on this topic and discusses directions for future research .ML ID : 196 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .", "label": "", "metadata": {}, "score": "78.88179"}
{"text": "ML ID : 229 .A Dependency - based Word Subsequence Kernel [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the conference on Empirical Methods in Natural Language Processing ( EMNLP-2008 ) , 400 - -409 , Waikiki , Honolulu , Hawaii , October 2008 .", "label": "", "metadata": {}, "score": "78.97355"}
{"text": "ML ID : 222 .Learning to Sportscast : A Test of Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] [ Video ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .", "label": "", "metadata": {}, "score": "79.02092"}
{"text": "By default , the tokenizer used by the English parser ( PTBTokenizer ) performs various normalizations so as to make the input closer to the normalized form of English found in the Penn Treebank .One of these normalizations is the Americanization of spelling variants ( such as changing colour to color ) .", "label": "", "metadata": {}, "score": "79.398346"}
{"text": "Scripts are included for linux ( lexparser - gui . sh ) and Windows ( lexparser - gui . bat ) .Take a look at the Javadoc lexparser package documentation and LexicalizedParser class documentation .( Point your web browser at the index.html file in the included javadoc directory and navigate to those items . )", "label": "", "metadata": {}, "score": "79.45263"}
{"text": "DVParser with no flags .The memory requirements of the parser is not actually that high , but the more threads added with -trainingThreads , the more memory will be required to train .As the parser is training , it will output intermediate models every 20 minutes ( by default ) .", "label": "", "metadata": {}, "score": "79.55881"}
{"text": "GATE - GATE is over 15 years old and is in active use for all types of computational task involving human language .GATE excels at text analysis of all shapes and sizes .From large corporations to small startups , from \u20ac multi - million research consortia to undergraduate projects , our user community is the largest and most diverse of any system of this type , and is spread across all but one of the continents1 . textir - A suite of tools for text and sentiment mining .", "label": "", "metadata": {}, "score": "79.561745"}
{"text": "In recent distributions , the models are included in a jar file inside the parser distribution .For example , in the 2012 - 11 - 12 distribution , the models are included in stanford - parser-2.0.4-models.jarThe easiest way to access these models is to include this file in your classpath .", "label": "", "metadata": {}, "score": "80.52028"}
{"text": "Hebrew : UTF-8 .However , the parser is able to parse text in any encoding , providing you pass the correct encoding option on the command line , for example : .-encoding ISO_8859 - 15 .( Or , when used within a program , it is your job to open files with the right kind of Reader / Writer . ) caseless.ser.gz - Loading parser from serialized file edu / stanford / nlp / models / lexparser / englishPCFG .", "label": "", "metadata": {}, "score": "80.58638"}
{"text": "ML ID : 223 .Transforming Meaning Representation Grammars to Improve Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the Twelfth Conference on Computational Natural Language Learning ( CoNLL-2008 ) , 33 - -40 , Manchester , UK , August 2008 .", "label": "", "metadata": {}, "score": "80.61273"}
{"text": "ML ID : 57 .Lexical Acquisition : A Novel Machine Learning Problem [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Technical Report , Artificial Intelligence Lab , University of Texas at Austin , January 1996 .", "label": "", "metadata": {}, "score": "80.72415"}
{"text": "This indicates that most of the loss comes from missing these edges .The primary problem for nouns is the difference between structures in each domain . tion guidelines for the Penn Treebank flattened noun phrases to simplify annotation ( Marcus et al . , 1993 ) , so there is no complex structure to NPs . K\u00a8 ubler ( 2006 ) showed that it is difficult to compare the Penn Treebank to other treebanks with more com- plexnounstructures , suchasBIO.ConsidertheWSJ phrase \" the New York State Insurance Department \" .", "label": "", "metadata": {}, "score": "80.90871"}
{"text": "The lexicon learned consists of words paired with meaning representations .Wolfie is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .", "label": "", "metadata": {}, "score": "81.11403"}
{"text": "There 's not much in the way of secret sauce to speed that up ( partly by the design of the parsers as guaranteed to find model optimal solutions ) .If you 're not using englishPCFG.ser.gz for English , then you should be - it 's much faster than the Factored parser .", "label": "", "metadata": {}, "score": "81.24776"}
{"text": "You can give the options -outputFormat typedDependencies or -outputFormat typedDependenciesCollapsed to get typed dependencies ( or grammatical relations ) output ( for English and Chinese only , currently ) .You can print out lexicalized trees ( head words and tags at each phrasal node with the -outputFormatOptions lexicalize option .", "label": "", "metadata": {}, "score": "81.418106"}
{"text": "Nouns are far more The annota- 2We measured these drops on several other dependency parsers and found similar results .ery token is headed by \" Department \" .In contrast , a similar BIO phrase has a very different structure , pursuant to the BIO guidelines .", "label": "", "metadata": {}, "score": "81.463905"}
{"text": "The default HeadFinder is written specifically for the PTB .If you train a parser on trees that use a different set of productions , the default HeadFinder will not know how to handle this and will throw this exception .The easiest way to get around this problem is to use LeftHeadFinder instead .", "label": "", "metadata": {}, "score": "81.64368"}
{"text": "We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior knowledge .Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .", "label": "", "metadata": {}, "score": "81.72955"}
{"text": "Further possible applications of the presented approaches include summarized machine translation tasks and learning from real perception data assisted by computer vision and robotics .ML ID : 291 .Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .", "label": "", "metadata": {}, "score": "81.933426"}
{"text": "We present a new edition of the Google Books Ngram Corpus , which describes how often words and phrases were used over a period of five centuries , in eight languages ; it reflects 6 % of all books ever published .", "label": "", "metadata": {}, "score": "82.29071"}
{"text": "For ex- ample , trained on in - domain data , nouns that occur more often tend to be heads .However , none of these features transfered between domains .A final type of feature we added was based on the behavior of nouns , adjectives and verbs in each domain .", "label": "", "metadata": {}, "score": "83.180016"}
{"text": "There are rules which help identify plurals , but there are also lots of exceptions .I 'm talking about English here of course , my very poor spoken German does n't help me understand that grammar I 'm afraid .", "label": "", "metadata": {}, "score": "83.83695"}
{"text": "The system learns to parse and generate commentaries without any engineered knowledge about the English language .Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games .The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model .", "label": "", "metadata": {}, "score": "83.89833"}
{"text": "LexicalizedParser -encoding utf-8 /u / nlp / data / lexparser / chineseFactored .ser.gz chinese-onesent-utf8.txt Loading parser from serialized file /u / nlp / data / lexparser / chineseFactored . ser.gz ... done [ 20.7 sec].Parsing file : chinese-onesent-utf8.txt with 2 sentences .", "label": "", "metadata": {}, "score": "84.349915"}
{"text": "Experimental results show the improvements obtained over the purely supervised parser , particularly when the annotated training set is small .ML ID : 198 .This paper explores the use of statistical machine translation ( SMT ) methods for tactical natural language generation .", "label": "", "metadata": {}, "score": "84.50115"}
{"text": "By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser , the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus .ML ID : 264 .", "label": "", "metadata": {}, "score": "85.43582"}
{"text": "Proper nouns have initial capitals and a string of such words ( possibly including \" of \" ) is an example of a noun phrase .A word preceeded by \" a / an / my / his / hers / the / this / these / those \" is going to be either an adjective or a noun .", "label": "", "metadata": {}, "score": "85.504906"}
{"text": "The system does not use any prior language knowledge and was able to learn to sportscast in both English and Korean .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans .", "label": "", "metadata": {}, "score": "86.19164"}
{"text": "Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable .\" One of the main challenges in natural language processing ( NLP ) is to correct for biases in the manually annotated data available to system engineers .", "label": "", "metadata": {}, "score": "86.23752"}
{"text": "Finally , we will investigate the impact of different statistical syntactic parsers on semantic parsing using the automated SAPT - generation process .ML ID : 184 .A Kernel - based Approach to Learning Semantic Parsers [ Details ] [ PDF ] [ Slides ] Rohit J. Kate 2005 .", "label": "", "metadata": {}, "score": "86.255424"}
{"text": "For part of speech and phrasal categories , here are relevant links : .Please read the documentation for each of these corpora to learn about their tagsets and phrasal categories .You can often also find additional documentation resources by doing web searches .", "label": "", "metadata": {}, "score": "87.08676"}
{"text": "Again using January 2014 version 3.3.1 as an example , you would not make your classpath -cp stanford - parser-3.3.1.jar Instead , you would make it Windows : -cp stanford - parser-3.3.1 . jar : stanford - parser-3.3.1-models.jar .In order to see exactly which models are available , you can use jar tvf stanford - parser-3.3.1-models.jar This will show you that to access the Arabic Factored model , for example , you would use the path edu / stanford / nlp / models / lexparser / arabicFactored . ser.gz .", "label": "", "metadata": {}, "score": "87.422134"}
{"text": "1 len .2 len .Parsed 14 words in 2 sentences ( 6.55 wds / sec ; 0.94 sents / sec ) .Parsing file : chinese - onesent with 1 sentences .Parsing [ sent .1 len .Parsed 10 words in 1 sentences ( 10.78 wds / sec ; 1.08 sents / sec ) .", "label": "", "metadata": {}, "score": "88.03431"}
{"text": "My Question now is which one and which approach would you recommend ?And which one does not require long nights adjusting the code ?Which software is smart enough to understand that the focused is on iPod and not the weather ?", "label": "", "metadata": {}, "score": "88.03987"}
{"text": "ML ID : 107 .The development of natural language interfaces ( NLI 's ) for databases has been a challenging problem in natural language processing ( NLP ) since the 1970 's .The need for NLI 's has become more pronounced due to the widespread access to complex databases now available through the Internet .", "label": "", "metadata": {}, "score": "88.35988"}
{"text": "ILP , which investigates the learning of relational ( first - order ) rules , provides an empirical method for acquiring knowledge within traditional , symbolic parsing frameworks .This dissertation details the architecture , implementation and evaluation of CHILL a computer system for acquiring natural language parsers by training over corpora of parsed text .", "label": "", "metadata": {}, "score": "88.84578"}
{"text": "The cause for this is clear when the annotation guide- lines are considered .The proper nouns in WSJ are names of companies , people and places , while in BIO they are names of genes , proteins and chemi- cals .", "label": "", "metadata": {}, "score": "89.43114"}
{"text": "A Chinese parser based on the Chinese Treebank , a German parser based on the Negra corpus and Arabic parsers based on the Penn Arabic Treebank are also included .The parser has also been used for other languages , such as Italian , Bulgarian , and Portuguese .", "label": "", "metadata": {}, "score": "89.584755"}
{"text": "The / DT quick / JJ brown / JJ fox / NN jumped / VBD over / IN the / DT lazy / JJ dog / NN .with the command : . ser.gz fox.txt .Partially - tagged input ( only indicating the POS of some words ) is also OK .", "label": "", "metadata": {}, "score": "91.18048"}
{"text": "ML ID : 92 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia Ann Thompson PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , December 1998 .", "label": "", "metadata": {}, "score": "91.381165"}
{"text": "Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .One of the main goals of natural language processing ( NLP ) is to build automated systems that can understand and generate human languages .", "label": "", "metadata": {}, "score": "92.51022"}
{"text": "We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .ML ID : 187 .", "label": "", "metadata": {}, "score": "92.55976"}
{"text": "To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance .ML ID : 121 .", "label": "", "metadata": {}, "score": "92.568085"}
{"text": "NLP Toolsuite - The JULIE Lab here offers a comprehensive NLP tool suite for the application purposes of semantic search , information extraction and text mining .Most of our continuously expanding tool suite is based on machine learning methods and thus is domain- and language independent . .", "label": "", "metadata": {}, "score": "94.32332"}
{"text": "The rabbit snare exists because of the rabbit .Once you 've gotten the rabbit , you can forget the snare .Words exist because of meaning .Once you 've gotten the meaning , you can forget the words .", "label": "", "metadata": {}, "score": "95.457184"}
{"text": "That is , they will just say Jill busy .Connection to logical representations : If you were to translate these sentences into a simple predicate logic form , you would presumably use busy(jill ) and teacher(jill ) .The treatment of the adjective or noun as the predicate in a predicate logic form parallels what we do in our grammatical relations representation .", "label": "", "metadata": {}, "score": "95.53898"}
{"text": "This Master 's thesis describes parts of the control software used by the soccer robots of the Free University of Berlin , the so called FU - Fighters .The FU - Fighters compete in the Middle Sized League of RoboCup and reached the semi - finals during the 2004 RoboCup World Cup in Lisbon , Portugal .", "label": "", "metadata": {}, "score": "96.71915"}
{"text": "That is , sentences like Jill is busy or Jill is a teacher .We continue to regard the adjective or noun as the predicate of which the subject is the argument , rather than changing and now regarding the copular verb is as the head and busy / teacher as a complement .", "label": "", "metadata": {}, "score": "97.00356"}
{"text": "Proceedings of the CoNLL Shared Task Session of EMNLP - CoNLL 2007 , pp .1051 - 1055 , Prague , June 2007 .c ?upenn.edu 2L2F - INESC - ID Lisboa / IST , Rua Alves Redol 9 , 1000 - 029 , Lisboa , Portugal javg@l2f.inesc-id.pt Abstract We describe some challenges of adaptation in the 2007 CoNLL Shared Task on Domain Adaptation .", "label": "", "metadata": {}, "score": "98.90752"}
{"text": "For example , consider the text : .The strongest rain ever recorded in India shut down the financial hub of Mumbai , snapped communication lines , closed airports and forced thousands of people to sleep in their offices or walk home during the night , officials said today .", "label": "", "metadata": {}, "score": "99.007965"}
{"text": "Parsing file : - i ca n't believe @mistamau does n't know who channing tatum is ... # loser Parsing [ sent .1 len .Parsed 14 words in 1 sentences ( 4.29 wds / sec ; 0.31 sents / sec ) .", "label": "", "metadata": {}, "score": "104.9292"}
{"text": "All of these are different views of the output of the parser .The / DT strongest / JJS rain / NN ever / RB recorded / VBN in / IN India / NNP shut / VBD down / RP the / DT financial / JJ hub / NN of / IN Mumbai / NNP , / , snapped / VBD communication / NN lines / NNS , / , closed / VBD airports / NNS and / CC forced / VBD thousands / NNS of / IN people / NNS to / TO sleep / VB in / IN their / PRP$ offices / NNS or / CC walk / VB home / NN during / IN the / DT night / NN , / , officials / NNS said / VBD today / NN .", "label": "", "metadata": {}, "score": "105.478745"}
{"text": "If you 're planning on analysing German tweets , it 's going to be important that your selected product is able to handle the German language .Obvious I know , but easy to forget .Then there 's the fact that it 's twitter where contractions and acronyms abound , and the language structure is constrained by the character limit which means that the grammar wo n't always match the expected structure of the language .", "label": "", "metadata": {}, "score": "106.25545"}
{"text": "Another problem concerns appositives .For ex- ample , the phrase \" Howard Mosher , president and chief executive officer , \" has \" Mosher \" as the head of \" Howard \" and of the appositive NP delimited by commas .", "label": "", "metadata": {}, "score": "107.124954"}
