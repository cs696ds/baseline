{"text": "Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , ... \" .This paper is a comparative study of feature selection methods in statistical learning of text categorization .", "label": "", "metadata": {}, "score": "26.051792"}
{"text": "Feature selection attempts to remove less representative words from the feature space in order to improve categorization effectiveness , reduce computational complexity and avoid overfitting .Feature selection is based on a thresholded criterion to achieve a desired degree of term elimination from the full vocabulary of a document corpus .", "label": "", "metadata": {}, "score": "31.72582"}
{"text": "The two ways of measuring performance are complementary to each other , and both are informative .Other evaluation metrics include utility functions defined over weighted TP , FP , TN and FN , and rank - based metrics like Mean Average Precision ( MAP ) which evaluates the ability of a system to rank categories for a given document .", "label": "", "metadata": {}, "score": "33.58159"}
{"text": "Therefore , we enriched the BOS features with word forms shorter than p - 2 .Feature selection .We employed two feature selection methods for dimensionality reduction .The first is Information Gain ( IG ) which has proved useful in TC [ 33 ] .", "label": "", "metadata": {}, "score": "33.808624"}
{"text": "Text classification rules are typically evaluated using performance measures from information retrieval .Common metrics for text categorization evaluation include recall , precision , accuracy and error rate and F1 .Given a test set of N documents , a two - by - two contingency table with four cells can be constructed for each binary classification problem .", "label": "", "metadata": {}, "score": "34.69969"}
{"text": "We introduce a formalization for this class of models , which allows linguistic knowledge to guide the construction process .We evaluate our framework on a range of tasks relevant for cognitive science and natural language processing : semantic priming , synonymy detection , and word sense disambiguation .", "label": "", "metadata": {}, "score": "35.377308"}
{"text": "This in turn requires mapping concepts in Web service descriptions to ontological concepts .By having both the description and query explicitly declare their semantics , the results will be more relevant than keyword matching based information retrieval [ 10].", "label": "", "metadata": {}, "score": "35.532913"}
{"text": "w . )i . m .Pr .c . i . w . ) log .Pr .c . i . w . ) where the probabilities are calculated by sums over all documents .Information gain measures the uncertainty reduction of category prediction by partitioning the examples according to the word .", "label": "", "metadata": {}, "score": "36.58055"}
{"text": "The feature vector was normalized before inputting into L - SVM , because the scaling is important for SVM [ 39 ] .LIBLINEAR [ 40 ] was used for the implementation of L - SVM .Results .Annotation tasks .", "label": "", "metadata": {}, "score": "36.610832"}
{"text": "The result of the multinomial in this work is almost identical to the result reported by Joachims [ 21 ] , while Allison [ 9 ] and Madsen et al .[ 7 ] reported much worse values .The origin of this difference might be attributable to the differences in preprocessing ( stop word removal and stemming ) and vocabulary size .", "label": "", "metadata": {}, "score": "36.7972"}
{"text": "Such a structure can be automatically extracted from a set of documents and uses a method for term extraction based on the probabilistic Topic Model [ 2].Samer Hassan et.al describes a new approach for estimating term weights in a document , and shows how the new weighting scheme can be used to improve the accuracy of a text classifier .", "label": "", "metadata": {}, "score": "36.996346"}
{"text": "5 is a flow chart of a reclassification process according to the present invention .FIG .6 is a feature vector of a document .FIG .7 is a table showing examples of information gain .FIG .8 is a support vector machine in feature space .", "label": "", "metadata": {}, "score": "37.704037"}
{"text": "Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , a \u00d8 2 -test ( CHI ) , and term strength ( TS ) .", "label": "", "metadata": {}, "score": "37.7443"}
{"text": "Each distinct word corresponds to an element of the vector whose numerical value is the number of occurrences of the word in the document .FIG .6 shows an example feature vector of a particular document .Notice that word order is lost in this representation , only word frequency is retained .", "label": "", "metadata": {}, "score": "37.933628"}
{"text": "Of course , documents are different from one another in length , and thus normalization , which will be described later , is necessary .A further step of text modeling is possible by extending the simple Poisson to a hierarchical gamma - Poisson description .", "label": "", "metadata": {}, "score": "38.23614"}
{"text": "Instead of manually classifying documents or hand - crafting automatic classification rules , statistical text categorization uses machine learning methods to learn automatic classification rules based on human - labeled training documents .A specific version of this approach is the TF - IDF term weighting scheme .", "label": "", "metadata": {}, "score": "38.383152"}
{"text": "It not only clearly defines different sets of text .categorization algorithms but also compare and contrast them for . different datasets so as to help system designers chose an appropriate .algorithm given their system constraints and application domains .( see .", "label": "", "metadata": {}, "score": "38.485626"}
{"text": "Using this training sample , a supervised learning algorithm aims to find the optimal classification rule , i.e. , a function mapping from the p - dimensional feature space to the one - dimensional class label .Optimal generally means that the classification rule can both accurately classify training documents and generalize well to new documents beyond the training set .", "label": "", "metadata": {}, "score": "38.553062"}
{"text": "LSCS.2013.3.559 Fig 4 : Results of Query Classification For approximate query processing , web semantics and spelling error strategies ( when we can have false negatives ) we measure two parameters : First we measure the performance gain , as before .", "label": "", "metadata": {}, "score": "38.92484"}
{"text": "While decision trees , logical rules , and instance - based rules have been explored for text classification , the most commonly used type of classification rules are linear rules .Often an additional feature that always takes value 1 is added to simulate a constant offset .", "label": "", "metadata": {}, "score": "38.964798"}
{"text": "TS compares favorably with the other methods with up to 50 % vocabulary redu ... . ... to thes2 distribution ) if any cell in the contingency table is lightly populated , which is the case for low frequency terms . 2.5 Term strength ( TS ) Term strength is originally proposed and evaluated by Wilbur and Sirotkin [ 22 ] for vocabulary reduction in text retrieval , and later applied by Yang and Wilbur to text categor ... . \" ...", "label": "", "metadata": {}, "score": "39.170403"}
{"text": "However , such a system is useless .For this reason , recall , precision and F1 are more commonly used instead of accuracy and error in text categorization evaluations .In multi - label classification , the simplest method for computing an aggregate score across categories is to average the scores of all binary task .", "label": "", "metadata": {}, "score": "39.23522"}
{"text": "For document vectors , we use normalized vectors in the . sense while more sophisticated term frequency - inverse document frequency ( TF - IDF ) was used by Kibriya et al .[ 22 ] .All parameters were set to be their default values in the study by Allison [ 9 ] , whereas we used a large value of . to obtain higher accuracy .", "label": "", "metadata": {}, "score": "39.240814"}
{"text": "We performed a small experiment to investigate the usefulness of MeSH for supplementing our current classification .MeSH terms were first retrieved for each abstract using EFetch [ 56 ] and then appended to the BOS feature vector .The best features were selected using fscore and classified using L - SVM .", "label": "", "metadata": {}, "score": "39.413643"}
{"text": "Joseph M. Hellerstein defines a query cost framework that incorporates both selectivity and cost estimates for selections .The algorithm is called Predicate Migration , and proves that it produces optimal plans for queries with expensive methods [ 12].Francesco Colace et.al proposes a query expansion method to improve accuracy of a text retrieval system .", "label": "", "metadata": {}, "score": "39.79329"}
{"text": "An automated system for measuring semantic orientation would have application in text classification , text filtering , tracking opinions in online discussions , analysis of survey responses , and automated chat systems ( chatbots ) .This article introduces a method for inferring the semantic orientation of a word from its statistical association with a set of positive and negative paradigm words .", "label": "", "metadata": {}, "score": "39.891014"}
{"text": "There are different feature selection techniques are available for textual data classification but in the paper , Information Gain ( IG ) feature selection technique to reduce the dimensionality of dictionary to 2000 items with the highest information gain score .IG is proven to be a very good feature selection technique along with CHI square and document frequency thresholding [ 21 ] 6 .", "label": "", "metadata": {}, "score": "40.494576"}
{"text": "It is also an important task since most current TM approaches rely on annotated corpora and are therefore dependent on the quality of these resources .Various annotation schemes have been proposed which involve either linguistic or expert annotation .As highlighted by Kim et al [ 46 ] , expert annotation is more challenging and more prone to inter - annotator disagreement than better - constrained linguistic annotation .", "label": "", "metadata": {}, "score": "40.576294"}
{"text": "To satisfy the conditions for using the gamma - Poisson description , documents must be normalized in length .Although several methods for normalizing document vectors have been proposed [ 12 , 14 , 15 ] , we choose the simplest one that normalize a resulting vector in terms of .", "label": "", "metadata": {}, "score": "40.843155"}
{"text": "The algorithm shows a precision of 21.3 % and a recall of 41.73 % which is comparatively higher when compared with other algorithms in the Table I. VI .QUERY CLASSIFICATION The task of query classification is to assign a Web search query to one or more predefined categories , based on its topics .", "label": "", "metadata": {}, "score": "41.03784"}
{"text": "In this way , the deployment of the analysis in a genuine CRA scenario was able to be quickly tested .A screenshot illustrating the annotation tool is provided in Figure 1 .Annotation guidelines .The three experts agreed on the guidelines of document relevance and keyword annotation .", "label": "", "metadata": {}, "score": "41.039223"}
{"text": "Section 4 describes our experiments on automatic text classification .We summarize these results in Section 5 and discuss the characteristics of gamma - Poisson modeling in Section 6 .In the last section , we give our conclusions .Related Work .", "label": "", "metadata": {}, "score": "41.064903"}
{"text": "Adrian D. Thurston et.al presents two enhancements to a basic backtracking LR approach which enable the parsing of computer languages that are both context - dependent and ambiguous [ 11].Kaarthik Sivashanmugam et.al develops a semantic Web services where by the Web services are annotated based on shared ontologies , and use these annotations for semanticsbased discovery of relevant Web services .", "label": "", "metadata": {}, "score": "41.38002"}
{"text": "We introduce a new model for describing word frequency distributions in documents for automatic text classification tasks .In the model , the gamma - Poisson probability distribution is used to achieve better text modeling .The framework of the modeling and its application to text categorization are demonstrated with practical techniques for parameter estimation and vector normalization .", "label": "", "metadata": {}, "score": "41.838413"}
{"text": "Web - page Taxonomy ( 2004 ) exhibits a power law .The scale of real - world text classification applications , both in terms of the number of classes as well as the ( often highly unbalanced ) number of training examples , poses interesting research challenges .", "label": "", "metadata": {}, "score": "41.869507"}
{"text": "Our expectation , however , is betrayed as seen in Figures 2 , 5 , and 7 .A possible interpretation of this result is that the better performance of the gamma - Poisson model is attributable to the normalization of document vectors .", "label": "", "metadata": {}, "score": "41.947227"}
{"text": "The origin of the superiority of the proposed gamma - Poisson modeling was discussed in terms of its flexibility in describing various patterns of word distributions and the effectiveness of vector normalization .We also showed that the proposed classifier is most suitable for applications in which continuous incremental learning tasks are required .", "label": "", "metadata": {}, "score": "42.020317"}
{"text": "In this paper an attempt is made to evaluate the performance of query processing algorithms in each of the category .The evaluation was based on dataset as specified by Forum for Information Retrieval [ FIRE15].The criteria used for evaluation are precision and relative recall .", "label": "", "metadata": {}, "score": "42.099476"}
{"text": "The reasoning for this is that some measures are better aimed toward feature selection / extraction , while others are preferable for feature weighting specifically in your document vectors ( i.e. the indexed data ) .This is generally due to dimension reduction measures being determined on a per category basis , whereas index weighting measures tend to be more document orientated to give superior vector representation .", "label": "", "metadata": {}, "score": "42.1996"}
{"text": "150 - 161 , 2008 .B. Allison , \" An improved hierarchical Bayesian Model of Language for document classification , \" in Proceedings of the 22nd International Conference on Computational Linguistics , pp .25 - 32 , 2008 .S. Eyheramendy , D. Lewis , and D. Madigam , \" On the naive bayes model for text categorization , \" in Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics , pp .", "label": "", "metadata": {}, "score": "42.369682"}
{"text": "Features are first ranked using the simple fscore criterion [ 34 ] , and N is selected based on the performance of the SVM classifier using the N features .Classification .We experimented with three well - known classifiers : Naive Multinomial Bayesian ( NMB ) , Complement Naive Bayesian ( CNB ) [ 35 ] and Linear Support Vector Machines ( L - SVM ) [ 36 ] .", "label": "", "metadata": {}, "score": "42.527256"}
{"text": "1457 - 1466 , 2006 .View at Google Scholar .T. Joachims , Learning to Classify Text Using Support Vector Machines [ Ph.D. thesis ] , Kluwer , 2002 .J. Grim , J. Novovi\u010dov\u00e1 , and P. Somol , \" Structural Poisson mixtures for classification of documents , \" in Proceedings of the 19th International Conference on Pattern Recognition ( ICPR ' 08 ) , pp . 1 - 4 , December 2008 .", "label": "", "metadata": {}, "score": "42.58563"}
{"text": "the document and , in this context , its impact can be compared with . state - of - the - art feature selection techniques especially devised to .provide good categorization performance .Such a framework provides for .a better assessment of the expected performance of a categorizer if .", "label": "", "metadata": {}, "score": "42.638878"}
{"text": "Thus the differences among these methods only come from their loss functions .\\ ] .\\ ] .\\ ] .Those experiments also showed that removing the regularization term in the objective functions of these classifiers resulted in significant performance degradation .", "label": "", "metadata": {}, "score": "42.74161"}
{"text": "Feature extraction , foundations and applications ( Edited by : Guyon I , Gunn S , Nikravesh M , Zadeh L ) .Berlin / Heidelberg : Springer 2006 , 315 - 324 .View Article .Rennie JDM , Karger D : Tackling the Poor Assumptions of Naive Bayes Text Classifiers .", "label": "", "metadata": {}, "score": "42.812454"}
{"text": "The micro - average scores tend to be dominated by the classifier 's performance on those categories that contain more documents , and the macro - average scores are influenced equally by the performance on all categories regardless of the number of documents they contain .", "label": "", "metadata": {}, "score": "42.957497"}
{"text": "As explained below , this was gradually extended as the annotation progressed further .The tool permits annotating any number of relevant keywords in the abstracts , attaching them to any ( leaf or internal ) node in the taxonomy , and classifying the same text in more than one way .", "label": "", "metadata": {}, "score": "42.99907"}
{"text": "CrossRef .[ 6 ] .Harris Drucker , Vladimir Vapnik , and Dongui Wu .Automatic text categorization and its applications to text retrieval .IEEE Transactions on Neural Networks , 10(5 ) , 1999 .[ 7 ] .Norbert G\u00f6vert , Mounia Lalmas , and Norbert Fuhr .", "label": "", "metadata": {}, "score": "43.35263"}
{"text": "Even the simplest kinds of languagespecific knowledge , such as the distinction between content words and function words , are shown to reliably boost translation model performance on some tasks .Statistical models that reflect knowledge about the model domain combine the best of both the rationalist and empiricist paradigms . \" ...", "label": "", "metadata": {}, "score": "43.41826"}
{"text": "A substantial improvement to describe the word burstiness phenomena has been achieved by introducing the Dirichlet - multinomial model , which models texts in a hierarchical manner to capture the burstiness [ 7 ] .In the model , the word count vector representing each document is generated by a multinomial distribution whose parameters are generated by its conjugate prior , that is , the Dirichlet distribution .", "label": "", "metadata": {}, "score": "43.44323"}
{"text": "Subject - matter knowledge and sematic priming . are in LSA .Predictive learning and text comprehension for humans .The research compares the effectiveness of five different text . algorithms ( Rocchio 's Algorithm , Decision Tree , Naive Bayes , Bayes .", "label": "", "metadata": {}, "score": "43.46834"}
{"text": "Both annotations are plausible given the current model , but future work should focus on refining the taxonomy further to obtain clearer distinctions .Automatic classification .We evaluated the automatic classification against the expert annotated CRA corpus .We used the standard evaluation measures of recall ( R ) , precision ( P ) and F measure ( F ) to evaluate the rate with which the classification assigned abstracts to the correct taxonomy classes .", "label": "", "metadata": {}, "score": "43.56819"}
{"text": "Effective Incremental Learning of the Gamma - Poisson Classifier .As mentioned above , the gamma - Poisson classifier can be used for a wide array of practical systems in which continuous incremental learning tasks are required .Typical examples are spam - filtering and adaptive news - alert systems .", "label": "", "metadata": {}, "score": "43.85849"}
{"text": "In Figure 1 , the best performance is seen for SVM , but the classifiers using the beta - binomial and gamma - Poisson models are almost equivalent and are highly competitive with SVM ; they are inferior to SVM only in the range of limited vocabulary size below 20,000 words .", "label": "", "metadata": {}, "score": "43.863766"}
{"text": "And also uses the approach for UDDI to store these semantic annotations and search for Web services based on them [ 10].Graeme Hirst et.al proposes a method for detecting and correcting many such errors by identifying tokens that are semantically unrelated to their context and are spelling variations of words that would be related to the context .", "label": "", "metadata": {}, "score": "44.063133"}
{"text": "We did 20 random selections for each way of splitting the data , ran our experiments on them and averaged the results separately for the two splits .On the Reuters-21578 collection , we obtained precision / recall breakeven point for the 10 most common categories using Na\u00efve Bayes , k - Nearest Neighbor and Support Vector Machines .", "label": "", "metadata": {}, "score": "44.088287"}
{"text": "give better classifier performance compared with other types of . features .SUMMARY .The paper addresses the problem of evaluating the effectiveness of .summarization techniques for the task of document categorization .It . is argued that for a large class of automatic categorization . algorithms , extraction - based document categorization can be viewed as .", "label": "", "metadata": {}, "score": "44.139214"}
{"text": "[21]. Y. Yang and J. O. Pedersen , \" A comparative study on feature selection in text categorization , \" in Proceedings of the Fourteenth International Conference on Machine Learning , ser .ICML ' 97 , 1997 , pp .", "label": "", "metadata": {}, "score": "44.20378"}
{"text": "K. Tzeras and S. Artman .Automatic indexing based on bayesian inference networks .In SIGIR 93 , pages 22 - 34 , 1993 .[19 ] . Y.Yang .An evaluation of statistical approaches to text categorization .Information Retrieval Journal , 1999 .", "label": "", "metadata": {}, "score": "44.24276"}
{"text": "BOS has proved promising in recent biomedical TC experiments [ 31 , 32 ] and unlike a traditional grammatical stemmer , it does not require domain tuning for optimal performance .Because it generates substrings with a fixed length p , a word shorter than p - 2 can get obscured by its context 3 .", "label": "", "metadata": {}, "score": "44.35503"}
{"text": "Next , documents are assumed to be generated by repeatedly drawing words from a fixed multinomial distribution for a given class , and word emissions are thus independent .From the first assumption , documents can be represented as vectors of count - valued random variables .", "label": "", "metadata": {}, "score": "44.41496"}
{"text": "It has been empirically observed that linear classifiers with proper regularization are often sufficient for solving practical text categorization problems , with performance comparable or better than non - linear classifiers .Furthermore , linear methods are generally computationally efficient , both at training as well as at classification .", "label": "", "metadata": {}, "score": "44.57238"}
{"text": "Note that separate specification is also possible in the case of the gamma distribution ; under the notations used in ( 12 ) , the mean and variance of the gamma distribution are expressed as .Equations ( 23 ) and ( 24 ) give us the separate specification which guarantees a more flexible description of word occurrence in gamma - Poisson modeling compared with the description in Dirichlet - multinomial modeling .", "label": "", "metadata": {}, "score": "45.103233"}
{"text": "TABLE VI : SEMANTIC WEB TABLE VII .SPELLING ERRORS Spelling errors that happen to result in a real word in the lexicon can not be detected by a conventional spelling checker .A method is presented for detecting and correcting many such errors by identifying tokens that are semantically unrelated to their context and are spelling variations of words that would be related to the context .", "label": "", "metadata": {}, "score": "45.13347"}
{"text": "Our random baseline is .Document preprocessing .We first evaluated the BOW preprocessing technique with and without the use of ( i ) the Porter stemmer [ 29 ] , ( ii )TFIDF , ( iii ) stop word removal , and ( iv ) their combinations .", "label": "", "metadata": {}, "score": "45.327225"}
{"text": "The optimal value of \u03bb is typically determined via cross - validation .To analyze the differences and similarities among popular classifiers , let us look at three of the more successful linear classification methods in text categorization as examples : linear SVM , ridge regression and regularized logistic regression .", "label": "", "metadata": {}, "score": "45.396515"}
{"text": "[ 15]. A. Borthwick , \" A maximum entropy approach to named entity recognition , \" Ph.D. dissertation , New York University , 1999 .[ 16]. E. Brill , \" Transformation - based error - driven learning and natural language processing : A case study in part - of - speech tagging , \" Computational linguistics , vol .", "label": "", "metadata": {}, "score": "45.48996"}
{"text": "This technique avoids the computational burden of .explicitly representing the feature vectors .Latent Semantic Analysis .Latent Semantic Analysis ( LSA ) analyzes word - word , word - passage , and . passage - passage relationships .There 's a good relationship between .", "label": "", "metadata": {}, "score": "45.497223"}
{"text": "The output of this extraction and classification system can be viewed as a single - document summary in its own right ; alternatively , it can be used to generate task - oriented and user - tailored summaries designed to give users an overview of a scientific field . by Niyu Ge , John Hale , Eugene Charniak - In Proceedings of the Sixth Workshop on Very Large Corpora , 1998 . \" ...", "label": "", "metadata": {}, "score": "45.532326"}
{"text": "The point is that these three classifiers perform differently ; nevertheless , they have similar structures in terms of hierarchical text modeling with utilizing conjugate priors .This result probably arises from a difference in the properties of the conjugate priors used .", "label": "", "metadata": {}, "score": "45.594765"}
{"text": "9 is a plot of a transducive solution in feature space .FIG .10 is a contingency table for a category .FIG .11 is a table showing the number of documents and various categories .FIG .12 is a plot of precision recall break - even point versus various topics .", "label": "", "metadata": {}, "score": "45.640194"}
{"text": "Furthermore , the advantage of the proposed model in incremental learning tasks that are frequently needed in practical application will be reported in detail .The rest of the paper is organized as follows .Section 2 summarizes related works on the improvement of the generative probabilistic classifier in which some conjugate priors are utilized for better text modeling .", "label": "", "metadata": {}, "score": "45.660538"}
{"text": "When the number of categories reaches the magnitude of tens of thousands or higher , the conventional approach of using all the documents to train a two - way classifier per category is no longer computationally feasible .Liu et al .", "label": "", "metadata": {}, "score": "45.675865"}
{"text": "Journal of Machine Learning Research 2008 , 9 : 1871 - 1874 .Cohen J : A Coefficient of Agreement for Nominal Scales .Educational and Psychological Measurement 1960 , 20 : 37 - 46 .View Article .Artstein R , Poesio M : Inter - coder agreement for computational linguistics .", "label": "", "metadata": {}, "score": "45.687904"}
{"text": "LSA is an automatic mathematical algorithm for extracting . relationships in word usage in passages .It does n't use dictionaries , . external knowledge , or grammar rules .First , represent words as a . matrix , each row is a word , and each column is a text passage or . context .", "label": "", "metadata": {}, "score": "45.691803"}
{"text": "In other words , recall is a measure of how much of the valuable information that is available is returned .Lowering the threshold used to determine whether or not a document belongs in a given class has the effect of increasing the recall , but decreasing the precision .", "label": "", "metadata": {}, "score": "45.7201"}
{"text": "query - document similarity for relevant documents , and will . simultaneously minimize .query - document similarity for non relevant documents .If we look at the basic formula for the Ricchio 's Algorithm , the .intuitive idea of Ricchio 's Algorithm is to iteratively increase the . weights of those terms contained in labeled relevant documents while .", "label": "", "metadata": {}, "score": "45.86652"}
{"text": "In this paper , we have proposed a novel classifier in which the gamma - Poisson distribution is utilized as a new tool for text modeling .The gamma - Poisson was introduced in order to improve the insufficient description of word occurrences from the original Poisson distribution .", "label": "", "metadata": {}, "score": "45.868076"}
{"text": "Since multinomial modeling is based on the assumption of independent word emissions with a fixed multinomial distribution for a considered class , the resultant word distribution fails to capture the burstiness especially for the words with moderate and low frequencies [ 7 ] .", "label": "", "metadata": {}, "score": "45.989708"}
{"text": "Fig - 4.1 : System Architecture .But in this paper , since we are interested in retrieving information related only to a particular domain , a problem arises what to define as the negative training examples for the classifier .As a solution we have chosen the Centroid algorithm as the classifier and the cosine similarity measure to determine the relevance of a newly crawled web page to the centroid using a threshold value .", "label": "", "metadata": {}, "score": "46.139534"}
{"text": "2 , p. 55 , 1960 .View at Google Scholar .J. D. M. Rennie , L. Shih , J. Teevan , and D. Karger , \" Tackling the poor assumptions of naive bayes text classifiers , \" in Proceedings of the 20th International Conference on Machine Learning , pp .", "label": "", "metadata": {}, "score": "46.161808"}
{"text": "For example , one might want to classify documents by sentiment ( Pang & Lee , 2002 ) : is a review positive or negative ?Or one might want to classify a message as deceptive or not .While representations and methods developed for topic - based classification are applicable to these classification problems as well , special considerations reflecting the nature of the classification task will probably lead to improved performance .", "label": "", "metadata": {}, "score": "46.28756"}
{"text": "This is an undesirable property of the Dirichlet for text modeling because we aim to model different words as having the same expected value but different variances in order to describe various word occurrence patterns .Allison [ 9 ] addressed this problem with the following assumptions .", "label": "", "metadata": {}, "score": "46.50261"}
{"text": "Note that the computation time of gamma - Poisson , which gives the second best classification accuracy as in the case of the Industry Sector dataset , is about ten times faster than that of SVM .Performance of the Probabilistic Classifiers . \" should be read as \" better than \" and \" better than or equivalent to \" , respectively .", "label": "", "metadata": {}, "score": "46.592323"}
{"text": ", must be evaluated for each possible class .For the evaluation , we use the leave - one - out likelihood maximization method proposed by Minka [ 13 ] which offers a convergent fixed - point iteration for the update as .", "label": "", "metadata": {}, "score": "46.652805"}
{"text": "I examined and experimented all the methods you bring forward and others .Pre - processing is also an important aspect for this task as you mentioned .I used certain types of string elimination for refining the data as well as morphological parsing and stemming .", "label": "", "metadata": {}, "score": "46.748543"}
{"text": "The model can be applied without modification on new collections .( + )The model gives a very good retrieval quality in the SMART environment .( - )It is not ( yet ) clear what happens if the model is applied to documents that are longer and more complicated than the short documents ( abstracts ) for which it was developed .", "label": "", "metadata": {}, "score": "46.80776"}
{"text": "Results .In this study , we use the simplest measure of classification performance , that is , accuracy , which is simply defined as a ratio of the total number of correct decisions to the total number of test documents in the dataset used .", "label": "", "metadata": {}, "score": "46.88499"}
{"text": "ACM Special Interest Group of Information Retrieval ( SIGIR ) : 42 - 49 .Zhang T and Oles F. ( 2001 )Text Categorization Based on Regularized Linear Classification Methods .Information Retrieval 4(1):5 - 31 .Gamma - Poisson Distribution Model for Text Categorization .", "label": "", "metadata": {}, "score": "46.899147"}
{"text": "For our results , we show the data obtained with all the words in the initial vocabulary .As shown in the table , our results agree reasonably well with those by the other authors .A detailed comparison is given below .", "label": "", "metadata": {}, "score": "46.913517"}
{"text": "This is the case for binary classification .I need at least 90 % at both cases and can not figure how to increase it : via optimizing training parameters or via optimizing feature selection ?I have read articles about feature selection in text classification and what I found is that three different methods are used , which have actually a clear correlation among each other .", "label": "", "metadata": {}, "score": "46.939835"}
{"text": "These values are solid proofs of the success of the model I used .This is what I have done so far .Now working on clustering and reduction models , have tried LDA and LSI and moving on to moVMF and maybe spherical models ( LDA + moVMF ) , which seems to work better on corpus those have objective nature , like news corpus .", "label": "", "metadata": {}, "score": "46.96267"}
{"text": "Pr .x .C .c . k . )i .Pr .x .i .C .c . k . )While this assumption is generally not true for word appearance in documents , research has shown that there is n't obvious improvement when word dependency is taken into account .", "label": "", "metadata": {}, "score": "46.981125"}
{"text": "The method handles high dimensional data efficiently , and has been shown to perform well in TC [ 38 ] .Cost parameter C was estimated within range 2 2 , ... , 2 5 on training data using cross validation .", "label": "", "metadata": {}, "score": "47.001553"}
{"text": "The criteria used for evaluation are precision and relative recall .The analysis is based on the importance of each step in query processing .The experimental results show that the significance of each step in query processing and also the relevance of web semantics and spelling correction in the user query .", "label": "", "metadata": {}, "score": "47.00746"}
{"text": "Therefore , before looking into more complicated feature selection measures there are a number of much simpler possibilities that will typically require much lower resource consumption .Do you pre - process the documents before performing tokensiation / representation into the bag - of - words format ?", "label": "", "metadata": {}, "score": "47.03733"}
{"text": "Another way of averaging is to sum over TP , FP , TN , FN and N over all the categories first , and then compute each of the above metrics .The resulted scores are called micro - averaged .Macro - averaging gives an equal weight to each category , and is often dominated by the system 's performance on rare categories ( the majority ) in a power - law like distribution .", "label": "", "metadata": {}, "score": "47.077682"}
{"text": "Measured 10 values of computation time through 10-fold cross validation are averaged and used as a final result in these figures .In Figures 3(a ) and 4(a ) the horizontal and the vertical axes are represented in linear scales while they are shown logarithmically in Figures 3(b ) and 4(b ) in order to show the lower vocabulary region clearly .", "label": "", "metadata": {}, "score": "47.105415"}
{"text": "However , in vectors normalized in the . sense , the event of a word occurrence has remarkably different weight according to the original document length , and in our experiments these normalized vectors are only used for the gamma - Poisson and the SVM classifiers as training and test vectors .", "label": "", "metadata": {}, "score": "47.187332"}
{"text": "Both approaches are plausible ( given the annotation guidelines ) and both resulted in annotations useful for CRA .The error analysis revealed that some classes are not specific enough to yield unique distinctions and as a consequence , some keywords are even assigned to different sub - taxonomies .", "label": "", "metadata": {}, "score": "47.358955"}
{"text": "No class has F lower than 0.46 , which is much higher than the average random baseline of 0.11 .Table 10 .Mean F and random baseline for taxonomic classes in three frequency ranges .In sum , these experiments demonstrate that the taxonomy we have created is machine learnable with high accuracy for the classes for which sufficient corpus data is available .", "label": "", "metadata": {}, "score": "47.36163"}
{"text": "The most commonly used and often most effective method is the information gain criterion .Information gain is employed from the entropy concept in information theory .Let C be a random variable over all classes and W be a random variable over the absence or presence of word w in a document , where C takes on values .", "label": "", "metadata": {}, "score": "47.38664"}
{"text": "A boosting - based system for text categorization .Machine Learning , 39(2/3):135 - 168 .Sebastiani F. ( 2002 ) Machine learning in automated text categorization .ACM Computing Surveys , 34(1):1 - 47 .Yang Y. , Liu X. ( 1999 )", "label": "", "metadata": {}, "score": "47.57676"}
{"text": "Using IG thresholding with a knearest neighbor classifier on the Reuters corpus , removal of up to 98 % removal of unique terms actually yielded an improved classification accuracy ( measured by average precision ) .DF thresholding performed similarly .Indeed we found strong correlations between the DF , IG and CHI values of a term .", "label": "", "metadata": {}, "score": "47.754387"}
{"text": "The conversion in this manner is reasonable and considered to bring about the better performance because short documents usually have fewer unnecessary terms that are irrelevant to the topic , and the ratio of informative terms that represent a concept of the topic is higher than in long documents .", "label": "", "metadata": {}, "score": "47.82"}
{"text": "To find out whether the classification created by experts provides a good representation of the corpus data and is machine learnable , we conducted a series of abstract classification experiments .A number of standard feature extraction , feature selection and machine learning methods were used and compared in these first experiments to identify optimal methodology for our data and task .", "label": "", "metadata": {}, "score": "47.848347"}
{"text": "The massive and heterogeneous web document collections as well as the unpredictable querying behaviours of typical web searchers exacerbate Information Retrieval ( IR ) problems [ 13].Hence categorization of queries allows for increased effectiveness , efficiency , and revenue potential in general - purpose web search systems .", "label": "", "metadata": {}, "score": "47.86395"}
{"text": "In this article we present a novel framework for constructing semantic spaces that takes syntactic relations into account .We introduce a formalization for this class of m ... \" .Traditionally , vector - based semantic space models use word co - occurrence counts from large corpora to represent lexical meaning .", "label": "", "metadata": {}, "score": "48.092262"}
{"text": "Latent Semantic Analysis is a model of language learning , based on the . exposure to texts .It predicts to which extent semantic similarities .between words are learned from reading texts .variety of topics on this issue .Thanks , . leader - ga .", "label": "", "metadata": {}, "score": "48.147552"}
{"text": "Such a tool should be developed in close collaboration with risk assessors .The interface should be easy to use , interactive , support search in a graphical manner , include a helpful statistical summariser , and enable the storage of interesting results in specific collections .", "label": "", "metadata": {}, "score": "48.162903"}
{"text": "This may include features like document meta information , frequency of words and phrases in the corpus and entity co - reference and alias among several others .SYSTEM DESIGN Our system consists of mainly 5 modules .Web pages are downloaded and their content is extracted .", "label": "", "metadata": {}, "score": "48.303448"}
{"text": "However , even in these extended formulations the problem of tuning its parameters is still neglected .In this paper , a study on parameters of the Rocchio text classifier has been carried out to achieve its maximal accuracy .The result is a model for the automatic selection of parameters .", "label": "", "metadata": {}, "score": "48.32908"}
{"text": "488 - 499 , 2005 .View at Scopus .N. Slonim , G. Bejerano , S. Fine , and N. Tishby , \" Discriminative feature selection via multiclass variable memory Markov model , \" Eurasip Journal on Applied Signal Processing , vol .", "label": "", "metadata": {}, "score": "48.428192"}
{"text": "[16 ] One approach is to develop semantic Web services where by the Web services are annotated based on shared ontologies , and use these annotations for semantics - based discovery of relevant Web services .The Ontologies have been identified as the basis for semantic annotation that can be used for discovery .", "label": "", "metadata": {}, "score": "48.449295"}
{"text": "Implementation Issues .Except SVM , all the classifiers are implemented in the Java programming language .Supplementary information is as follows .( i )In the learning phase of the classifier utilizing the Dirichlet - multinomial model , initial values of . in ( 18 ) .", "label": "", "metadata": {}, "score": "48.49037"}
{"text": "Precision is the proportion of relevant documents among the retrieved documents .Precision is defined as follows The method for estimating the recall of the algorithms is counting the number of full evaluations required to return a certain number of top results .", "label": "", "metadata": {}, "score": "48.51541"}
{"text": "The results of our inter - annotator agreement tests , automatic classification experiments and the user test all demonstrate that the taxonomy created by risk assessors is accurate , well - defined , and can be useful in practice .This is particularly encouraging considering that the taxonomy is based on expert annotation of biomedical texts .", "label": "", "metadata": {}, "score": "48.524292"}
{"text": "We believe that this is worthwhile for the following reasons .To the best of our knowledge , the gamma - Poisson distribution has not yet been used to construct a generative probabilistic text classifier .As mentioned above , since the model using the gamma - Poisson distribution can be regarded as one of the most fundamental and natural for modeling texts , it is useful to illustrate its framework .", "label": "", "metadata": {}, "score": "48.56281"}
{"text": "In this way the new query is strongly related to the original query , containing terms closely related to all of the original terms .This contrasts with query expansion through pseudo - relevance feedback , which is costly and can lead to query drift .", "label": "", "metadata": {}, "score": "48.575382"}
{"text": "Larger tests using several experts are required to investigate the full performance of automatic classification on unseen corpus data .We plan to conduct such tests after we have extended the initial taxonomy further to cover additional , finer - grained MOA types ( as described in the following section ) .", "label": "", "metadata": {}, "score": "48.60064"}
{"text": "A query parser , simply put , translates users search string into specific instructions for the search engine .It stands between user and the documents users are seeking , and so its role in text retrieval is vital .The Web is rich with various sources of information .", "label": "", "metadata": {}, "score": "48.69995"}
{"text": "Fit ( LLSF ) mapping and a NaiveBayes ( NB ) classifier .We focus on the robustness of these methods in dealing .with a skewed category distribution , and their performance .as function of the training - set category frequency .", "label": "", "metadata": {}, "score": "48.77306"}
{"text": "There is no sound theoretical basis for the assumption that documents that resemble the query , are relevant for the question .It s main advantage over the others is that it is easy to learn and implement although the classification accuracy may not be of the highest quality .", "label": "", "metadata": {}, "score": "48.780533"}
{"text": "For the second case , first we need to recognize the NEs appearing on text before its extraction .For that , we used the popular Stanford NER [ 20 ] for the recognition of NEs which is trained on news data and is fairly robust across domains .", "label": "", "metadata": {}, "score": "48.796345"}
{"text": "This is a clear advantage of gamma - Poisson modeling for incremental learning for the following reasons .( i )The time complexity of retraining the classifier using beta - binomial modeling in the same situation is given as .because it uses the method of moments for the estimation of parameters .", "label": "", "metadata": {}, "score": "48.80008"}
{"text": "The other two evaluated the outcome , the disagreement cases were discussed , and the annotation principles were improved where possible .This process ( crucial for maintaining quality ) was repeated on a subset of the corpus for several times .", "label": "", "metadata": {}, "score": "48.80249"}
{"text": "Thanks .SUMMARY Vector Space Model The vector space model , is the most popular model and is claimed to be the best performing model for general document collections .Advantages and disadvantages : ( + )The model is relatively easy to understand .", "label": "", "metadata": {}, "score": "48.824326"}
{"text": "Words that are common among the training documents do not appreciably help to distinguish between the documents , and therefore have small IDF weights .In order to minimize effects of document length and enhance classification accuracy , each document vector d i is normalized to unit length .", "label": "", "metadata": {}, "score": "48.889328"}
{"text": "Because it was found that one of the original 105 categories was empty , the remaining 104 categories having documents were used in our experiments . )The largest and smallest categories have 105 and 27 documents , respectively , and the average number of documents per category is 91.9 .", "label": "", "metadata": {}, "score": "48.9047"}
{"text": "Morgan Kaufmann , 1997 .[ 11 ] .Ron Kohavi and George H. John .Wrappers for feature subset selection .Artificial Intelligence , 97(1 - 2):273 - 324 , 1997 .MATH CrossRef .[ 12 ] .Wai Lam and Chao Y. Ho .", "label": "", "metadata": {}, "score": "48.91137"}
{"text": "your reduction already removed necessary information .SVM is quire good in handling a lot of dimensions .did you try bigger feature sets ?what is the sample size you use in training ? if you can not train with more features , try to train the second most frequent 20.000 to verify there is no information left there .", "label": "", "metadata": {}, "score": "48.98549"}
{"text": "The normalized document vectors are supplied to the classifier with gamma - Poisson modeling that inherently requires the normalization .For SVM , we use both types of document vectors and find that the normalized vectors give better classification performance .We will thus show the performance of SVM with only normalized vectors .", "label": "", "metadata": {}, "score": "49.002953"}
{"text": "The second functionality enables the experts to annotate such keywords ( words and phrases ) in abstracts and their titles which indicate scientific evidence relevant for examining the carcinogenic properties of chemicals .This annotation is grounded in actual pieces of text .", "label": "", "metadata": {}, "score": "49.204315"}
{"text": "Each . word frequency in the Next , LSA applies singular value decomposition .( SVD ) to the matrix , which is factor analysis .The decomposition .results in dimensionality reduction .Extract words from the passage . into a word matrix , do a linear decomposition of the matrix , then . reduce the dimensionality of the matrix .", "label": "", "metadata": {}, "score": "49.22036"}
{"text": "Also how do you index the data , are you using the Vector Space Model with simple boolean indexing or a more complicated measure such as TF - IDF ?Considering the low number of categories in your scenario a more complex measure will be beneficial as they can account for term importance for each category in relation to its importance throughout the entire dataset .", "label": "", "metadata": {}, "score": "49.297394"}
{"text": "With the threshold T the classification of x is determined by .c .j .i . k . cosine .x .x .i . ) x .i .c .j . )The approach of Na\u00efve Bayes is to use the training data to estimate the probability of each category given the document feature values of a new instance .", "label": "", "metadata": {}, "score": "49.308083"}
{"text": "Porter MF : An algorithm for suffix stripping .Program 1980 , 14 ( 3 ) : 130 - 137 .Kibriya AM , Frank E , Pfahringer B , Holmes G : Multinomial Naive Bayes for Text Categorization Revisited .Australian Conference on AI 2004 .", "label": "", "metadata": {}, "score": "49.3329"}
{"text": "A user looking to fulfil information need has to formulate a query usually consisting of a small set of keywords summarizing the information need .Queries are posed by interactive users and can be ambiguous in nature .An interactive query goes through the entire path of query parser , expansion , optimization , and processing [ 1].", "label": "", "metadata": {}, "score": "49.337685"}
{"text": "Features help learning algorithms in identifying phrases containing named entities .Features can be divided into 3 categories namely , word level features , list lookup features and document and corpus features [ 19].Word level features are related to the character makeup of words .", "label": "", "metadata": {}, "score": "49.366905"}
{"text": "According to the above calculation it has information gain equal to 0 .So information gain is used as a measure to select terms that best represent the categorization .Given a training document set , for each unique term we compute the information gain , and remove from the feature space those terms whose information gain is less than some predetermined threshold .", "label": "", "metadata": {}, "score": "49.43676"}
{"text": "For the sake of completeness and later reference , we then review the original generative probabilistic classifier and its descendants , in which conjugate priors are used for better text modeling .Except for the beta - negative binomial model , all the models described in this section will be used in corresponding classifiers , and their performance will be compared with that of our new classifier through experiments .", "label": "", "metadata": {}, "score": "49.516594"}
{"text": "In this sense , the performance comparison between the classifier using the gamma - Poisson model and those using other models are our primary result in this work .Figure 1 shows the performance comparison of various classifiers in the text classification task for the 20 Newsgroups dataset , and Figure 2 shows the same for the Reuters-21578 data collection .", "label": "", "metadata": {}, "score": "49.520985"}
{"text": "Feature extraction .The first step of our text categorization ( TC ) approach is to transform documents into a feature vector representation .We experimented with two document representation techniques .The first one is the simple ' bag of words ' approach ( BOW ) which considers each word in the abstract as a separate feature .", "label": "", "metadata": {}, "score": "49.56715"}
{"text": "In Proceedings of SIGIR-98 , 1998 .[ 13 ] .G : Salton and C. Buckley .Term - weighting approaches in automatic text retrieval .Information Processing and Management , 24(5):513 - 523 , 1988 .CrossRef .[14 ] .", "label": "", "metadata": {}, "score": "49.63452"}
{"text": "The efficiency of the proposed classifier was examined through experiments on automatic text categorization of the 20 Newsgroups , Reuters-21578 , Industry Sector , and TechTC-100 datasets .For comparison , classifiers using three other distributions , namely , multinomial , Dirichlet - multinomial and beta - binomial distributions , were also applied to the same datasets , and in addition we also used SVM as a standard discriminative classifier with state - of - the - art classification accuracy .", "label": "", "metadata": {}, "score": "49.684917"}
{"text": "We build an initial vocabulary from all words left after stop word , punctuation , and number token removals .Capital letters are transformed to lowercase letters and no stemming algorithm is applied .Here , words are defined as alphabetical strings enclosed by whitespace .", "label": "", "metadata": {}, "score": "49.693542"}
{"text": "We define a scale for evaluating query substitution , and show that our method performs well at generating new queries related to the original queries .We build a model for selecting between candidates , by using a number of features relating the query - candidate pair , and by fitting the model to human judgments of relevance of query suggestions .", "label": "", "metadata": {}, "score": "49.70877"}
{"text": "the majority of training documents are unlabelled , and .most of the events have a short duration in time .We . adapted several supervised text categorization methods , . specifically several new variants of the k - Nearest Neighbor .", "label": "", "metadata": {}, "score": "49.72585"}
{"text": "Web is modeled as a layered graph with seed URLs as the first layer and their backlinks forming other layers .They use an ordinal regressor to find the corresponding rank of a newly fetched web page .In [ 13 ] , Liu et al .", "label": "", "metadata": {}, "score": "49.774803"}
{"text": "In our experiments , the support vector machine ( SVM ) is also used as a standard discriminative classifier because previous comparative studies on classifiers [ 14 , 18 ] have consistently shown that SVM is the state of the art in terms of classification accuracy .", "label": "", "metadata": {}, "score": "49.77834"}
{"text": "These datasets are generated from web pages .As mentioned earlier , the textual advertisements included in the web pages can make term distributions noisy because the same kind of advertisements tend to appear across multiple categories .( ii )The numbers of classes , 104 for the Industry Sector and 40 for the TechTC-100 , are much larger than those of the other two datasets .", "label": "", "metadata": {}, "score": "49.7917"}
{"text": "C. Manning , P. Raghavan , and H. Schutze , Introduction to Information Retrieval , Cambridge University Press , 2008 .A classification system ( 10 ) having a controller ( 12 ) , a document storage memory ( 14 ) , and a document input ( 16 ) is used to classify documents ( 20 ) .", "label": "", "metadata": {}, "score": "49.822838"}
{"text": "You can use it on the raw and/or processed data to give an estimate of how aggressively you should aim to prune features ( or unprune them as the case may be ) .A paper describing it can be found here : .", "label": "", "metadata": {}, "score": "49.827984"}
{"text": "By finding the precision / recall breakeven point , the threshold at which precision and recall are equal , both measures are given equal weight in the analysis .When there are many categories to learn , a separate classifier is trained for each .", "label": "", "metadata": {}, "score": "49.878487"}
{"text": "Comparison of Gamma - Poisson Classifier and SVM .Although the proposed classifier using gamma - Poisson modeling fails to outperform the SVM classifier as seen in the previous section , we believe that it is still useful for the following two reasons .", "label": "", "metadata": {}, "score": "49.918762"}
{"text": "We will show the results only for the rational approximation in the next section .is the standard deviation calculated through 10-fold cross - validation .Performance Comparison in Text Classification Tasks for 20 Newsgroups and Reuters-21578 .Classification Accuracy .", "label": "", "metadata": {}, "score": "49.933384"}
{"text": "For a small number of cases near the boundaries , misclassifications do occur .These situations can be handled by human intervention .It is also possible to introduce a degree of confidence measure to identify boundary cases .However , we note that the bulk of the classification task can be reliably automated , greatly reducing the work load for the experienced individuals who now perform these tasks .", "label": "", "metadata": {}, "score": "49.984955"}
{"text": "The beta - negative binomial model is derived from consideration of the adequate empirical fit of the negative binomial distribution for text modeling [ 8 ] .The classifier using the model has been proved to be comparable to the multinomial naive Bayes in terms of classification performance , and this has been confirmed experimentally [ 8 ] .", "label": "", "metadata": {}, "score": "50.021576"}
{"text": "We provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics with human judgements of rhetorical status and relevance .We present several experiments measuring our judges ' agreement on these annotations .", "label": "", "metadata": {}, "score": "50.13067"}
{"text": "Note that the negative binomial distribution , which is the resultant posterior distribution of the gamma - Poisson pair [ 6 ] , has been used for text modeling [ 5 ] and for text categorization [ 10 ] .In those studies , however , the hierarchical structure of gamma - Poisson modeling of texts was not taken into account , and the negative binomial distribution was merely used as a simple tool for describing word distributions .", "label": "", "metadata": {}, "score": "50.217888"}
{"text": "The report discusses a variety of ways of evaluating the effectiveness . of text categorization systems .This is a very detailed study of machine learning in Automated Text .Classification , different algorithms and issue pertaining to document .representation , classifier construction and classifier evaluation .", "label": "", "metadata": {}, "score": "50.231316"}
{"text": "Let x i /y i be the precision / recall breakeven for category i which represents x i documents among y i documents in category i are classified to the category by the system .The micro - average is the average of total number of documents properly classified for all categories by the system over all the documents that are in the categories .", "label": "", "metadata": {}, "score": "50.26012"}
{"text": "K. Church and W. A. Gale , \" Inverse Document Frequency ( IDF ) : a measure of deviations from poisson , \" in Proceedings of the 3rd Workshop on Very Large Corpora , pp .121 - 130 , 1995 .", "label": "", "metadata": {}, "score": "50.292633"}
{"text": "Precision : The fraction of retrieved documents that are relevant to the user query intent .Recall : The fractions of relevant documents that are retrieved are in context with user query .with much longer n - grams .The paper uses these frequencies to find \" interesting \" substrings .", "label": "", "metadata": {}, "score": "50.304314"}
{"text": "Term frequency is an integer between 0 and N ; document frequency is an integer between 0 and D , the number of documents in the corpus .An algorithm based on suffix arrays is used for computing tf and dr and many functions of these quantities for all IV .", "label": "", "metadata": {}, "score": "50.35538"}
{"text": "Web page is represented in Vector Space Model ( VSM ) with TF - IDF weighting .Centroid Algorithm Centroid algorithm creates a classifier ( centroid ) based on the training data set .Then this classifier is used to determine the similarity of a new instance to the centroid using a similarity measure .", "label": "", "metadata": {}, "score": "50.37667"}
{"text": "LSA captures .synonymity by knowledge . of captured vocabularies .TOEFL vocabulary simulates human performance .between word choice .LSA errors were compared to student errors .The . role of dimension reduction was analyzed .LSA simulates word sorting .", "label": "", "metadata": {}, "score": "50.405113"}
{"text": "To optimize a tree , all predicates are pushed down as far as possible , and then repeatedly apply the Series - Parallel Algorithm Using Parallel Chains to each stream in the tree , until no more progress can be made .", "label": "", "metadata": {}, "score": "50.50785"}
{"text": "The method is experimentally tested with 3,596 words ( including adjectives , adverbs , nouns , and verbs ) that have been manually labeled positive ( 1,614 words ) and negative ( 1,982 words ) .The method attains an accuracy of 82.8 % on the full test set , but the accuracy rises above 95 % when the algorithm is allowed to abstain from classifying mild words . \" ...", "label": "", "metadata": {}, "score": "50.54693"}
{"text": "This paper reports a controlled study with statistical significant . tests on five text categorization methods and their robustness in . dealing with different situations .This paper focuses on a comparative evaluation of a wide - range of text .categorization methods , including previously published results on the .", "label": "", "metadata": {}, "score": "50.604153"}
{"text": "Each combination of classifiers ( NMB / CNB / SVM ) , document representations ( BOW , BOS ) and settings for N ( dynamic, ... ,83098 ) was evaluated .The results showed that the dynamic setting yields consistent improvement for all the setups ( although the impact on SVM ' s is not big ) and that the optimal N varies by the data and the classifier ( the data not shown ) .", "label": "", "metadata": {}, "score": "50.63467"}
{"text": "The classifiers with the Dirichlet - multinomial exhibit the worst performance in both cases .Computation Time .Figures 3 and 4 , respectively , show comparisons of computation times for various classifiers in the tasks for the 20-Newsgroups and Reuters-21578 datasets .", "label": "", "metadata": {}, "score": "50.662895"}
{"text": "Algorithms for the alignment of words in translated texts are well established .However , only recently new approaches have been proposed to identify word translations from non - parallel or even unrelated texts .This task is . \" ...This article presents methods for biasing statistical translation models to reflect these properties .", "label": "", "metadata": {}, "score": "50.742325"}
{"text": "P. D. Bra , G. jan Houben , Y. Kornatzky , and R. Post , \" Information retrieval in distributed hypertexts , \" in In RIAO , 1994 , pp .481 - 491 .[ 2].M. Hersovici , M. Jacovi , Y. Maarek , D. Pelleg , M. Shtalhaim , and S. Ur , \" The shark - search algorithm - an application : tailored web site mapping , \" in Proceedings of the 7th World Wide Web Conference , 1998 .", "label": "", "metadata": {}, "score": "50.79128"}
{"text": "So that a particular web pages is represented by its NEs only .Once the features are extracted a dictionary is created .For that we first consider the 4000 highest frequent terms ( or NEs or combined ) in the dataset after the removal of stop words .", "label": "", "metadata": {}, "score": "50.81727"}
{"text": "The framework of the multinomial classifier described above usually works well in practical text classification tasks [ 11 ] .It has been pointed out , however , that the multinomial distribution used in the multinomial naive Bayes can not describe the word burstiness phenomena that are inherently encountered in natural language documents [ 7 ] .", "label": "", "metadata": {}, "score": "50.886707"}
{"text": "There are 40 training documents and 10 test documents in each class .Na\u00efve - bayes , kNN , inductive and transductive SVMs were applied .All methods produce 100 % classification accuracy .It was found that SVM is the most accurate classifier on all trials among all the classifiers considered .", "label": "", "metadata": {}, "score": "50.889687"}
{"text": "The experimental results show that the significance of each step in query processing and also the relevance of web semantics and spelling correction in the user query .Key words - query expansion , query optimization , query parsing , web semantics and query classification I. INTRODUCTION The main purpose of an IR system is to retrieve all the documents which are relevant to a user query while retrieving as few non - relevant documents as possible .", "label": "", "metadata": {}, "score": "50.9152"}
{"text": "A randomwalk model is applied on a graph encoding words and cooccurrence dependencies , resulting in scores that represent a quantification of how a particular word feature contributes to a given context [ 5].Mikio Yamamoto et.al describes techniques for working \u00a9 2013 ACEEE DOI : 03 .", "label": "", "metadata": {}, "score": "50.98156"}
{"text": "Dimensionality is reduced to approximate human cognition .LSA is a . theory of knowledge representation .Dimensionality reduction solves .the problem of \" insufficient evidence \" or \" poverty of the stimulus \" .LSA uses a matrix decomposition algorithm to reduce the . dimensionality .", "label": "", "metadata": {}, "score": "51.019806"}
{"text": "( ii )The time complexity for retraining the classifier using multinomial modeling is . , exactly the same as in the case of gamma - Poisson modeling .( If the total counts for each term over original training vectors are stored in the classifier , then the counts are simply updated by adding the corresponding counts in the newly provided training vector and the new set of parameters .", "label": "", "metadata": {}, "score": "51.023346"}
{"text": "Joachims , T. ( 1998 ) .Text categorization with Support Vector Machines : Learning with many relevant features .In Machine Learning : ECML-98 , Tenth European Conference on Machine Learning , pp .137 - -142 .Lewis D.L. , Yang Y. , Rose T.G. , Li F. ( 2004 ) : RCV1 : A New Benchmark Collection for Text Categorization Research .", "label": "", "metadata": {}, "score": "51.03581"}
{"text": "142 - 150 .[ 9].M. Diligenti , F. Coetzee , S. Lawrence , C. L. Giles , and M. Gori , \" Focused crawling using context graphs , \" in Proceedings of the 26th International Conference on Very Large Data Bases , ser .", "label": "", "metadata": {}, "score": "51.047585"}
{"text": "The probability of the occurrence of a document . is a product of independent terms , each of which represents the probability of the number of emissions ( i.e. , the count ) of an individual word .( ii )The probability of the number of emissions is the average of a product .", "label": "", "metadata": {}, "score": "51.083836"}
{"text": "Although the number of support vectors is much smaller than . are sufficient for the update .This indicates that the gamma - Poisson classifier is suitable for incremental learning in terms of not only time complexity but also space complexity .", "label": "", "metadata": {}, "score": "51.135487"}
{"text": "We can vary the decision threshold to get higher precision at the cost of lower recall or higher recall at the cost of lower precision .Human intervention can also be involved to further improve the classification accuracy .Some confidence scores may be given to documents to aid the human confirmation .", "label": "", "metadata": {}, "score": "51.136467"}
{"text": "We incorporate multiple anaphora resolution factors into a statistical framework -- specifically the distance between the pronoun and the proposed antecedent , gender / number / animaticity ... \" .This paper presents an algorithm for identifying pronominal anaphora and two experiments based upon this algorithm .", "label": "", "metadata": {}, "score": "51.192196"}
{"text": "Principles of taxonomy creation .The keyword annotation resulted in lists of words and phrases indicating evidence for CRA .The next task was to classify this evidence and organize it into a taxonomy .We mentioned earlier that initially only a very shallow taxonomy was implemented inside the annotation tool .", "label": "", "metadata": {}, "score": "51.21647"}
{"text": "We combine them into a single probability that enables hs to identify the referent .Our first experiment shows the relative contribution of each source Of information and demonstrates a success rate of 82.9 % for all sources combined .The second experiment investigates a method for unsuper- vised learning of gender / number / animaticity information .", "label": "", "metadata": {}, "score": "51.22511"}
{"text": "w .When the problem is not linearly separable this method can be augmented by introducing a soft margin and mapping the training data nonlinearly into a higher - dimensional feature space via a function \u03a6 , then construct an optimal hyperplane in the feature space .", "label": "", "metadata": {}, "score": "51.250984"}
{"text": "The random - walk model is applied on a graph encoding words and co - occurrence dependencies , resulting in scores that represent a quantification of how a particular word feature contributes to a given context .Term frequency ( tf ) is the standard notion of frequency in corpus - based natural language processing ( NLP ) ; it counts the number of times that a type ( term / word / n- gram ) appears in a corpus .", "label": "", "metadata": {}, "score": "51.261803"}
{"text": "Tree is PolyAnalyst 's fastest algorithm when dealing with large .amounts of attributes .Decision Tree report provides an easily .interpreted decision tree diagram and a predicted versus real table .Problems to Solve : .Classification of cases into multiple categories .", "label": "", "metadata": {}, "score": "51.264954"}
{"text": "SVMs elegantly sidestep both difficulties .They avoid overfitting by .choosing the maximum margin separating hyperplane from among the many .that can separate the positive from negative examples in the feature . space .Also , the decision function for classifying points with respect .", "label": "", "metadata": {}, "score": "51.444534"}
{"text": "The computation time of SVM can be intolerably deteriorated as in Figures 6 and 8 , for the Industry Sector and the TechTC-100 datasets , respectively , while the gamma - Poisson classifier offers the second best classification performance with moderate computation times even for these two cases .", "label": "", "metadata": {}, "score": "51.466682"}
{"text": "In Proceedings of CIKM-99 .[ 8 ] .David J. Ittner , David D. Lewis , and David D. Ahn .Text categorization of low quality images .In Proceedings of SDAIR-95 , pages 301 - 315 , Las Vegas , US , 1995 .", "label": "", "metadata": {}, "score": "51.488914"}
{"text": "Text classification / categorization is defined as the task of classifying documents into a fixed number of predefined categories .Categories are also called classes .Let .( Note that to simplify the problem , we consider here the categorization where each document is assigned to only one class .", "label": "", "metadata": {}, "score": "51.556557"}
{"text": "Consequently , the task is applying one of the 8 possible labels to each of test documents .In contrast to the 20 Newsgroups , the class distribution of this dataset is quite imbalanced ; the largest topic category \" earn \" has 3,923 documents while the smallest \" grain \" has only 51 documents .", "label": "", "metadata": {}, "score": "51.570526"}
{"text": "Matrix transformations are used in .information retrieval and human cognition models .A web site provides .LSA based word or passage vectors , similarities between words and .words , words and passages , and passages and passages .LSA is able to .", "label": "", "metadata": {}, "score": "51.743706"}
{"text": "Ideally , it should be designed in a way that it facilitates also the subsequent steps of CRA , e.g. the analysis of the retrieved data , the discussion among the CRA team and the subsequent generation of the CRA report .", "label": "", "metadata": {}, "score": "51.773075"}
{"text": "Taxonomic classification .We ran two sets of experiments on the corpus , using 1 ) BOW and 2 ) BOS for feature extraction .Without feature selection , BOW had c. 9000 features and BOS c. 83000 .Features were selected using fscore .", "label": "", "metadata": {}, "score": "51.77816"}
{"text": "SUMMARY .Automated tracking of events from chronologically ordered .document streams is a new challenge for statistical . text classification .Existing learning techniques . must be adapted or improved in order to effectively . handle difficult situations where the number of positive .", "label": "", "metadata": {}, "score": "51.787773"}
{"text": "If each document has almost the same length , then the normalization does not change the weight of word occurrences and thus does not contribute to the improvement of accuracy .Therefore , the normalization of document vectors can be effective in the situation where the distribution of document length is scattered in a considered dataset .", "label": "", "metadata": {}, "score": "51.815872"}
{"text": "This model is used in a parsing system by finding the parse for the sentence with the highest probability .This system outperforms previou ... \" .We describe a parsing system based upon a language model for English that is , in turn , based upon assigning probabilities to possible parses for a sentence .", "label": "", "metadata": {}, "score": "51.85477"}
{"text": "in the passage , like human minor knowledge acquisition .LSA is .intuitively sensible , with a three - fourths gain in total comprehension . vocabulary inferred from knowledge about words not in the passage or . paragraph .Human children have a rapid growth of vocabulary and .", "label": "", "metadata": {}, "score": "51.898506"}
{"text": "URL DB may contain a local copy of the downloaded pages and will also serve the indexing process .Fig - 1.1 : Harvest ratio variation for focused and generic crawler Fig - 1.2 : System overview of a simple focused crawler 2 . RELATED WORK Early work on focused crawling was based on simple keyword matching , regular expression matching or binary classifiers .", "label": "", "metadata": {}, "score": "51.92898"}
{"text": "The taxonomy we have constructed provides the practical means to identify key evidence in CRA literature and to classify this evidence in semantically meaningful classes .In the future , we plan to develop and extend the taxonomy further .The taxonomy can be extended using manual annotation , by supplementing it with additional information in knowledge resources and/or using automatic methods .", "label": "", "metadata": {}, "score": "51.980713"}
{"text": "The disadvantages of using such a function is that it is slow in . sorting out queries and irrelevant attributes can fool the neighbor .Decision Tree .The Decision Tree exploration engine , new to PolyAnalyst 4.1 , helps .solve the task of classifying cases into multiple categories .", "label": "", "metadata": {}, "score": "52.02094"}
{"text": "Preferably , only selected words are used in the weighting system .As will be further described below , various nouns and verbs may be given different weight than other parts of speech .Referring now to .FIG .5 , a method 30 for classifying documents is described .", "label": "", "metadata": {}, "score": "52.046944"}
{"text": "The materials we have produced can thus provide valuable support for manual CRA as well as facilitate the development of an approach based on TM .We discuss refining and extending the taxonomy further via manual and machine learning approaches , and the subsequent steps required to develop TM to support the entire CRA workflow .", "label": "", "metadata": {}, "score": "52.071716"}
{"text": "View Article PubMed .Karamanis N , Seal R , Lewin I , McQuilton P , Vlachos A , Gasperin C , Drysdale R , Briscoe E : Natural Language Processing in aid of FlyBase curators .BMC Bioinformatics 2008 , 9 : 193 .", "label": "", "metadata": {}, "score": "52.1128"}
{"text": "In a further aspect of the invention , a classification system including a controller , a document storage memory , and a document input is used to unclassify documents .The controller is programmed to generate a theme score from a plurality of source documents in a plurality of predefined source documents .", "label": "", "metadata": {}, "score": "52.23548"}
{"text": "The results show that the model allows performance comparable to that of the support vector machine and clearly exceeding that of the multinomial model and the Dirichlet - multinomial model .The time complexity of the proposed classifier and its advantage in practical applications are also discussed .", "label": "", "metadata": {}, "score": "52.23705"}
{"text": "The Results section describes first the annotation work and the resulting taxonomy .The results of the inter - annotator agreement tests , the automatic classification experiments and the user - test are then reported .The Discussion and Conclusion section concludes the paper with comparison to related research and directions for future work .", "label": "", "metadata": {}, "score": "52.237732"}
{"text": "the input space occupied by the training examples .With an .appropriately chosen feature space of sufficient dimensionality , any .consistent training set can be made separable .However , translating .the training set into a higher - dimensional space incurs both . computational and learning - theoretic costs .", "label": "", "metadata": {}, "score": "52.265953"}
{"text": "\\ ) Empirical evaluations have shown the performance of those non - linear classifiers comparable to stronger linear classifiers ( Lewis , 1994 ; Yang , 1994 , 1999 ; Wiener et al . , 1995 ; Joachims , 1998 , Li & Yang , 2003 ) .", "label": "", "metadata": {}, "score": "52.357994"}
{"text": "The query processing can be divided into four categories i.e. query expansion , query optimization , query classification and query parsing .In this paper an attempt is made to evaluate the performance of query processing algorithms in each of the category .", "label": "", "metadata": {}, "score": "52.397224"}
{"text": "Known as an instance - based or lazy learning method , kNN uses the k nearest neighbors of each new document in the training set to estimate the local likelihood of each category for the new document .Just as in the case of linear classifiers , it is important to find the right trade - off between empirical risk and model complexity for non - linear classifiers as well .", "label": "", "metadata": {}, "score": "52.399147"}
{"text": "Although this demonstrates the potential usefulness of additional manually built resources , given the rapidly evolving nature of CRA data , the best approach long term is to develop technology for automatic updating of the taxonomy from literature .Given the basic resources we have constructed and presented in this paper , the development of such technology is now realistic and can be done using unsupervised or semi - supervised machine learning techniques , e.g. [ 1 , 57 ] .", "label": "", "metadata": {}, "score": "52.40746"}
{"text": "In general , the problem is linearly separable for SVM if each term in the vocabulary is almost peculiar to one of the all possible categories and , in this case , the SVM can be easily trained within a short time .", "label": "", "metadata": {}, "score": "52.48825"}
{"text": "We propose a strategy which concentrates on the rhetorical status of statements in the article : Material for summaries is selected in such a way that summaries can highlight the ... \" .this paper we argue that scientific articles require a different summarization strategy than , for instance , news articles .", "label": "", "metadata": {}, "score": "52.524303"}
{"text": "List lookup features involves referring a list ( also called gazetteer , lexicon and dictionary ) containing common words occurring in named entities ( e.g. , \" association \" mostly relates to organization names ) , ambiguous words that can be named entities or lists containing famous named entities .", "label": "", "metadata": {}, "score": "52.526855"}
{"text": "In many cases , however , a document may have more than one associated category in a classification scheme , e.g. , a journal article could belong to computational biology , machine learning and some sub - domains in both categories .", "label": "", "metadata": {}, "score": "52.54203"}
{"text": "The space has been bound by giving a feature selection interpretation of the Rocchio parameters .The benefit of the approach has been assessed via extensive cross evaluation over three corpora in two languages .Comparative analysis shows that the performances achieved are relatively close to the best TC models ( e.g. Support Vector Machines ) .", "label": "", "metadata": {}, "score": "52.588753"}
{"text": "Thanks a lot , and if you need any additional info for help , just let me know .@larsmans : Frequency Threshold : I am looking for the occurrences of unique words in examples , such that if a word is occurring in different examples frequently enough , it is included in the feature set as a unique feature .", "label": "", "metadata": {}, "score": "52.60937"}
{"text": "In such an environment , the proposed classifier is more appropriate for practical systems rather than other complex learning models including SVM because our classifier ensures effective incremental learning .To show the effectiveness , we consider a situation in which one new training document belonging to a class .", "label": "", "metadata": {}, "score": "52.61172"}
{"text": "In the Nineth Text REtrieval Conference ( TREC-9 ) , Gaithersburg , Maryland , 2000 .[ 3 ] .Christopher Buckley and Gerald Salton .Optimization of relevance feedback weights .In Proceedings of SIGIR-95 , pages 351 - 357 , Seattle , US , 1995 .", "label": "", "metadata": {}, "score": "52.656902"}
{"text": "In order to estimate recall and precision we need to identify the set of values in a sample that represent a single real world object .In our approach these sets correspond to the result of the query processing .The experiments show that the result of the query processing may be used to improve efficiency of the search process .", "label": "", "metadata": {}, "score": "52.709476"}
{"text": "linearly ) with increasing number of data columns .At the same time , it . grows more than linearly with the growing number of data records - as .Yet , for data of about . 100,000 records , the DT algorithm is often the fastest exploration . algorithm of PolyAnalyst .", "label": "", "metadata": {}, "score": "52.71517"}
{"text": "Keyword annotation .The aim of the keyword annotation is to highlight such keywords ( words or phrases ) in abstracts which indicate relevant evidence for hazard identification and MOA assessment of chemicals .The experts found keyword annotation easy to understand since they typically look for words and phrases while reading abstracts , and since existing CRA guidelines provide some sample keyword lists to support data gathering .", "label": "", "metadata": {}, "score": "52.742195"}
{"text": "Zweigenbaum P , Demner - Fushman D , Yu H , Cohen KB : New frontiers in biomedical text mining .Pacific Symposium on Biocomputing 2007 , 205 - 208 .Muller HM , Kenny EE , Sternberg PW : Textpresso : An Ontology - Based Information Retrieval and Extraction System for Biological Literature .", "label": "", "metadata": {}, "score": "52.77771"}
{"text": "Our technique uses modifications based on typical substitutions web searchers make to their queries .In this way the new query is strongly related to the original query , containi ... \" .We introduce the notion of query substitution , that is , generating a new query to replace a user 's original search query .", "label": "", "metadata": {}, "score": "52.92737"}
{"text": "Web page taxonomy .They found the divide - and - conquer strategy not only addressed the scaling issue but also yielded better classification performance because of local optimization of classifiers based on domains and sub - domains .Finally , there are interesting challenges in new applications of text classification .", "label": "", "metadata": {}, "score": "52.96234"}
{"text": "To accomplish this in a manual fashion would require searchers a substantial amount of time to re - read the patents or other documents in a class and classify them into a new class or a subclass .It would therefore be desirable to provide a classification system capable of automatically determining the classifications of documents and capable of reclassifying documents when reclassification or division of classes is desired .", "label": "", "metadata": {}, "score": "52.98937"}
{"text": "The two main approaches to modern focused crawling are based on content analysis and link structure analysis .Focused crawling based on content analysis is heavily dependent of automatic text classification techniques to determine the relevance of a retrieved web page to the crawling domain .", "label": "", "metadata": {}, "score": "53.11308"}
{"text": "Classification based upon Support Vector Machines ( SVM ) has developed rapidly in the last several years .It was introduced by Vapnik in 1995 for solving two - class pattern recognition problems [ 25].FIG . 8 ) .", "label": "", "metadata": {}, "score": "53.117676"}
{"text": "527 - 534 .[ 10].G. T. De Assis , A. H. F. Laender , M. A. Gonc\u00b8alves , and A. S. Da Silva , \" Exploiting genre in focused crawling , \" in Proceedings of the 14th international conference on String processing and information retrieval , ser .", "label": "", "metadata": {}, "score": "53.123062"}
{"text": "For our experiments , we use four different datasets that are chosen to represent a wide spectrum of text classification tasks .The first one is the 20 Newsgroups dataset which was originally collected with a netnews - filtering system [ 19 ] and contains approximately 20,000 documents being partitioned ( nearly ) evenly across 20 different UseNet newsgroups .", "label": "", "metadata": {}, "score": "53.178288"}
{"text": "Experiments show that our techniques significantly increase coverage and effectiveness in the setting of sponsored search . ...Therefore we work with ... . \" ...Algorithms for the alignment of words in translated texts are well established .However , only recently new approaches have been proposed to identify word translations from non - parallel or even unrelated texts .", "label": "", "metadata": {}, "score": "53.18875"}
{"text": "We measure the inter - annotator agreement of both relevance and keyword annotation tasks .In addition , we report a series of experiments which involve training and testing automatic classifiers to assign PubMed abstracts to taxonomy classes .Finally , a simple user test in a near real - world CRA scenario is reported .", "label": "", "metadata": {}, "score": "53.217705"}
{"text": "Harvest ratio is initially high for all the crawlers due to the presence of more topic relevant web pages near the seed URLs and gradually decreases before it gets stabilized .Conclusions and Future Work Current approaches to focused crawling are based solely on lexical terms when making relevance judgments and they disregard the information contained in NEs .", "label": "", "metadata": {}, "score": "53.262"}
{"text": "Based on the new information , it sounds as though you are on the right track and 84%+ accuracy ( F1 or BEP - precision and recall based for multi - class problems ) is generally considered very good for most datasets .", "label": "", "metadata": {}, "score": "53.27063"}
{"text": "database marketing , to automatically diagnosing patient in medicine , . and to determining customer attrition causes . in banking and insurance .Target Attribute : .The target attribute of a Decision Tree exploration must be of a .Boolean ( yes / no ) or categorical data type .", "label": "", "metadata": {}, "score": "53.30639"}
{"text": "If it is considered relevant , all the outlinks from that page is extracted and the crawling is continued .We have used crawler4j4 , which is a Java based open source web crawler as the baseline crawler and custom modules are added to it to make it a focused crawler .", "label": "", "metadata": {}, "score": "53.31017"}
{"text": "A method for classifying a document using a classification system comprising the steps of : . establishing a plurality of classes and a plurality of subclasses ; . identifying source documents of each of said plurality of classes and said plurality of subclasses ; . generating a classification theme score for each class and each subclass in response to the source documents ; . entering an unclassified document into the system ; . generating an unclassified theme score for the unclassified document ; and .", "label": "", "metadata": {}, "score": "53.33567"}
{"text": "[ 13]. H. Liu , J. Janssen , and E. Milios , \" Using hmm to learn user browsing patterns for focused web crawling , \" Data & Knowledge Engineering , vol .59 , pp .270 - 291 , November 2006 .", "label": "", "metadata": {}, "score": "53.344467"}
{"text": "After .Hersovici et al .[ 2 ] improves this algorithm into Shark - search in which the page relevance is calculated as a similarity between document and query in Vector Space Model ( VSM ) .Cho et al .", "label": "", "metadata": {}, "score": "53.3649"}
{"text": "View Article PubMed .Yang Y , Pedersen JO : A Comparative Study on Feature Selection in Text Categorization .ICML ' 97 : Proceedings of the Fourteenth International Conference on Machine Learning San Francisco , CA , USA : Morgan Kaufmann Publishers Inc 1997 , 412 - 420 .", "label": "", "metadata": {}, "score": "53.415398"}
{"text": "Two different types of document vectors , namely , count - valued and normalized , are used to represent each document .A count - valued document vector is constructed from document term frequency ( number of occurrences of a considered word in a document ) for each word , and then each component in the vector is converted by use of ( 14 ) to give the normalized vector .", "label": "", "metadata": {}, "score": "53.417946"}
{"text": "For applications in which enough numbers of training and test documents are required , the top 10 categories ( the 10 categories with the highest number of positive training examples in the ModApte split ) are usually used [ 2 ] .", "label": "", "metadata": {}, "score": "53.567345"}
{"text": "One problem with such a system is that the searchers must be familiar with the classification system and the underlying technology to properly classify the document .This is a very labor intensive and costly process because a substantial amount of time is required to classify the documents .", "label": "", "metadata": {}, "score": "53.642933"}
{"text": "545 - 552 , August 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .S. Clinchant and E. Gaussier , \" The BNB distribution for text modeling , \" in Proceedings of the Advances in Information Retrieval .", "label": "", "metadata": {}, "score": "53.691822"}
{"text": "14].G. Zhou and J. Su , \" Named entity recognition using an hmm - based chunk tagger , \" in Proceedings of the 40th Annual Meeting on Association for Computational Linguistics .Association for Computational Linguistics , 2002 , pp .", "label": "", "metadata": {}, "score": "53.79492"}
{"text": "order of words to capture relationships in word choice .LSA uses a . pre - processing step for word correlation over many passages and .contexts .LSA uses a very large number of relationships .Theories of .human cognition can not be settled by theoretical and philosophical .", "label": "", "metadata": {}, "score": "53.843018"}
{"text": "The Dirichlet - multinomial classifier is the slowest because of the iterative procedures for estimating parameters .Performance Comparison in Text Classification Tasks for Industry Sector Dataset .Figures 5 and 6 show the classification accuracy and the computation time , respectively , in text classification for the Industry Sector dataset .", "label": "", "metadata": {}, "score": "53.844486"}
{"text": "transformation .Save the log word frequency , and the entropy for each .row and column of the word .Weight each word occurrence by an estimate . of its importance in the passage .Knowing a word provides information .", "label": "", "metadata": {}, "score": "53.895515"}
{"text": "For the SVM classifier , we use . of the multi - class support vector machine In the training phase of SVM , the trade - off parameter between training error and margin , . , is set to 5,000 to obtain high accuracy .", "label": "", "metadata": {}, "score": "53.910053"}
{"text": "The Ricchio 's Algorithm is based on the Relevancy Feedback Algorithms . for Document Relevancy .Relevancy Feedback Models are an effective way . of modifying and expanding user queries ( such as search engines ) .Ricchio 's Algorithm is one of the earliest methods used for queries .", "label": "", "metadata": {}, "score": "53.932064"}
{"text": "Wang H , Huang M , Ding S , Zhu X : Exploiting and integrating rich features for biological literature classification .BMC Bioinformatics 2008 ., 9 ( Suppl 3 ) : .Han B , Obradovic Z , Hu ZZ , Wu CH , Vucetic S : Substring selection for biomedical document classification .", "label": "", "metadata": {}, "score": "53.96488"}
{"text": "559 III .QUERY OPTIMIZATION Query optimization is a function of many relational database management systems in which multiple query plans for satisfying a query are examined and a good query plan is identified .It also considers global costs .Algorithm for optimizing n relations performs a large number of local optimizations .", "label": "", "metadata": {}, "score": "53.992867"}
{"text": "Given the dynamic nature of CRA data , the best approach long term would be to develop technology for automatic acquisition and updating of such a resource from CRA literature [ 1 , 2 ] .However , the very development of such technology requires target specification of the scientific evidence more comprehensive than that currently provided .", "label": "", "metadata": {}, "score": "53.99521"}
{"text": "Since the improvement of accuracy with the vector normalization is more effective in short documents , the largest .for the Industry Sector dataset is consistent with our hypothesis .The superiority of the gamma - Poisson over the beta - binomial observed for the Reuters-21578 , Industry Sector , and TechTC-100 datasets is therefore explained , at least partially , in terms of the effectiveness of the vector normalization .", "label": "", "metadata": {}, "score": "54.140045"}
{"text": "hyperplane will lead to maximal generalization when predicting the . classification of previously unseen examples ( Vapnik , Statistical .Learning Theory , 1998 ) .The SVM algorithm can also be extended to cope .with noise in the training set and with multiple classes ( Cristianini . and Shawe - Taylor , An Introduction to Support Vector Machines , 2000 ) .", "label": "", "metadata": {}, "score": "54.1511"}
{"text": "In this sense , our approach is fundamentally different from the previous works .To demonstrate that the proposed modeling is useful in practical applications , the classification accuracy and the computation time of the algorithm are examined using four standard datasets .", "label": "", "metadata": {}, "score": "54.18483"}
{"text": "This means that if a statistical classifier requires approximately 100 positive training examples per category for learning sufficiently accurate models , then we can only solve the classification problem for only 1 % of the categories even if we use the entire set of 800,000 pages as training examples .", "label": "", "metadata": {}, "score": "54.268944"}
{"text": "Bazarganigilani et al .[ 11 ] propose a novel approach which uses genetic programming ( GP ) to efficiently discover the best similarity function which is a combination of Bag - of- words , Cosine , Okapi similarity measures .This is achieved with the fitness function used by the genetic algorithm .", "label": "", "metadata": {}, "score": "54.317703"}
{"text": "All these methods have fairly standard implementations that you can get access to and run --- if you let us know which language you 're using , I or someone else will be able to point you in the right direction .", "label": "", "metadata": {}, "score": "54.387012"}
{"text": "Words with very low or very high frequency of occurrence in the document set , as well as a list of non - informative \" stop words \" are not included in the document vectors .A typical stop word list contains about 300 or 400 words including prepositions , articles , pronouns and conjunctions like \" the \" and \" of \" .", "label": "", "metadata": {}, "score": "54.421005"}
{"text": "represents the difference in performance in percent between the gamma - Poisson and the beta - binomial , we can test our hypothesis on the vector normalization described above by examining the correlation between . and other statistic measures .As confirmed from the values of interquartile range ( IQR ) and standard deviation ( SD ) in Table 3 and also as intuitively seen in Figure 9 , 20 Newsgroups has the sharpest distribution , and it consistently has the smallest . in relation to its IQR and SD values .", "label": "", "metadata": {}, "score": "54.43107"}
{"text": "13 is a table of correctly classified documents in various categories .FIG .14 is a plot of precision / recall break - even point for various systems .FIG .15 is a plot of precision / recall break - even point for various systems .", "label": "", "metadata": {}, "score": "54.46604"}
{"text": "Naive Bayes classifier has been used in other topical crawlers as well [ 7 ] , [ 8 ] , [ 9 ] to name a few .Assis et at .[ 10 ] use genre related information as well as the content related information .", "label": "", "metadata": {}, "score": "54.485382"}
{"text": "The Output : .The Decision Tree report starts of by giving measures resulting from .the decision tree .These measures are the Number of non - terminal .nodes , Number of leaves , and depth of the constructed tree .", "label": "", "metadata": {}, "score": "54.49438"}
{"text": "Figure 2 : Performance of various classifiers for Reuters-21578 dataset .In Figure 2 , SVM is again the best performer .An important difference between Figures 1 and 2 is that the classifier with the gamma - Poisson is superior to that with the beta - binomial in Figure 2 , whereas they are almost equivalent in Figure 1 .", "label": "", "metadata": {}, "score": "54.532616"}
{"text": "A few of them have also been evaluated for their practical usefulness in a real - world scenario [ 8 , 9 ] .Such tools and evaluations act as an important proof of concept for biomedical TM as well as enable improving existing technology according to the needs of practical applications .", "label": "", "metadata": {}, "score": "54.705227"}
{"text": "View at Scopus .K. Lang , \" NewsWeeder : learning to filter netnews , \" in Proceedings of the 12th International Machine Learning Conference , pp .331 - 339 , Morgan Kaufmann , 1995 .View at Scopus .T. Joachims , \" A probabilistic analysis of the Rocchio algorithm with TF - IDF for text categorization , \" in Proceedings of the 40th International Conference on Machine Learning , pp .", "label": "", "metadata": {}, "score": "54.755836"}
{"text": "Summary Statistics - to deselect attributes that contain to many .values to provide any useful insight to the exploration engine .Underlying Algorithms : .Information Gain splitting criteria .Shannon information theory and statistical significance tests .The Data Used : .", "label": "", "metadata": {}, "score": "54.75728"}
{"text": "Usually , harvest ratio is computed at different points during the crawl to obtain a trajectory of crawler performance .hubs are places which have many links to other pages which might contain relevant information .Jon Kleinberg - the introducer of these two terms - argued that hubs and authorities exhibit a mutually reinforcing relationship [ 6 ] i.e. a good hub will point to many authorities and a good authority will be pointed at by many hubs .", "label": "", "metadata": {}, "score": "54.8268"}
{"text": "Vector Creation .To investigate the effect of vocabulary size on classification performance , we use a simple feature selection method based on the collection term frequency as follows .First , we count the collection term frequency , . is one of the simplest methods , but is sufficient for the task at hand , namely , comparing different classifiers at each vocabulary size .", "label": "", "metadata": {}, "score": "54.827038"}
{"text": "\\ ) Na\u00efve Bayes is \" na\u00efve \" in that it assumes conditional independence between all feature values in a feature vector .Which this assumption is clearly violated to text classification , Na\u00efve Bayes nevertheless produces fairly accurate classification rules in many cases .", "label": "", "metadata": {}, "score": "54.852547"}
{"text": "Although in this paper relevance score is based on web pages , new scoring mechanisms like site based scoring and root directory based scoring are open to investigation .It is also worth investigating the behavior of the crawler on large scale crawls on different , NE rich domains as well .", "label": "", "metadata": {}, "score": "54.88127"}
{"text": "The measure we tentatively use here is a ratio of nonzero components defined as .For this ratio , we expect that when the distribution of the ratio becomes broader , the difference in accuracy between the gamma - Poisson and the beta - binomial will become increasingly evident .", "label": "", "metadata": {}, "score": "54.88732"}
{"text": "Like the recent user - centered annotation scheme of Wilbur et al .[ 6 ] it can support the classification of biomedical literature along various qualitative dimensions .However , with the focus on CRA , our scheme is specifically aimed at classifying cancer related evidence .", "label": "", "metadata": {}, "score": "54.981808"}
{"text": "T. Mitchell , Machine Learning , McGraw Hill , 1997 .S. Kim , K. Han , H. Rim , and H. Myaeng , \" Some effective techniques for naive Bayes text classification , \" IEEE Transactions on Knowledge and Data Engineering , vol .", "label": "", "metadata": {}, "score": "55.03586"}
{"text": "Recent studies have shown that Ricchio 's Algorithm has a poor .performance when the proportion of relevant documents in the whole .corpus is low .Naive Bayes .Naive Byes algorithms are among the most successful known algorithms .for learning to classify text documents .", "label": "", "metadata": {}, "score": "55.051273"}
{"text": "\" , and we did not use a stop list .The resulting vocabulary has 64,680 words .Because this test collection was generated from the web directory in a fully automated manner [ 20 ] , it is noisier than the other three test collections ; for example , textual advertisements included in the web pages can be noise that affects the classification accuracy .", "label": "", "metadata": {}, "score": "55.26078"}
{"text": "Other objects and features of the present invention will become apparent when viewed in light of the detailed description of the preferred embodiment when taken in conjunction with the attached drawings and appended claims .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .", "label": "", "metadata": {}, "score": "55.334866"}
{"text": "1 , pp .163 - 190 , 1995 .View at Google Scholar . A. Gelman , B. Carlin , S. Stern , and B. Rubin , Bayesian Data Analysis ( Texts in Statistical Science ) , Chapman and Hall / CRC , 2nd edition , 2003 .", "label": "", "metadata": {}, "score": "55.39676"}
{"text": "Text categorization ( a.k.a . text classification ) is the task of assigning predefined categories to free - text documents .It can provide conceptual views of document collections and has important applications in the real world .Another widespread application of text categorization is spam filtering , where email messages are classified into the two categories of spam and non - spam , respectively .", "label": "", "metadata": {}, "score": "55.41346"}
{"text": "The first enables the experts to classify abstracts using the classical IR concept of Document Relevance .The judgements are made at the document level .An abstract is marked as relevant or irrelevant if the expert deems after reading the title and the abstract that it is not relevant for CRA .", "label": "", "metadata": {}, "score": "55.496178"}
{"text": "The final set of features includes around 20.000 features , which is actually a 90 % decrease , but not enough for intended accuracy of test - prediction .I am using LibSVM and SVM - light in turn for training and prediction ( both linear and RBF kernel ) and also Python and Bash in general .", "label": "", "metadata": {}, "score": "55.50141"}
{"text": "The resulting taxonomy relies solely on expert knowledge .Experts were merely advised on the main principles of taxonomy creation : the classes should be conceptually coherent and their hierarchical organization should be in terms of coherent sub- and superordinate relations .", "label": "", "metadata": {}, "score": "55.529907"}
{"text": "Thus , the theme score of the unclassified document is used for comparison with the theme score for the new subclass .The other documents in the class may be re - evaluated to determined if they should be included in the new subclass .", "label": "", "metadata": {}, "score": "55.546196"}
{"text": "If term densities are not taken into account this information is lost and the fewer categories you have the more impact this loss with have .On a similar note , it is not always prudent to only retain terms that have high frequencies , as they may not actually be providing any useful information .", "label": "", "metadata": {}, "score": "55.623302"}
{"text": "Recall is the proportion of retrieved documents among the relevant documents .Fig 1 : result of Query Optimization In query optimization , Algorithm for optimization nrelations from Fig 1 , provides a better results in both IR criteria precision and recall when compared to other implemented algorithms .", "label": "", "metadata": {}, "score": "55.65251"}
{"text": "This article ... \" .This article presents methods for biasing statistical translation models to reflect these properties .Evaluation with respect to independent human judgments has confirmed that translation models biased in this fashion are significantly more accurate than a baseline knowledge - free model .", "label": "", "metadata": {}, "score": "55.695965"}
{"text": "The main source of disagreement was the different annotation style of the two annotators .A1 annotated as many words as possible , aiming for a maximum number of taxonomy classes per abstract .A2 annotated just one or a few words that classify the abstract as precisely as possible .", "label": "", "metadata": {}, "score": "55.738144"}
{"text": "30 , no . 1 - 7 , pp .161 - 172 , 1998 .[ 4].B. D. Davison , \" Topical locality in the web , \" in Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval , ser .", "label": "", "metadata": {}, "score": "55.743507"}
{"text": "The user query being on an average restricted to two or three keywords makes the query ambiguous to the search engine .Given the user query , the goal of an Information Retrieval [ IR ] system is to retrieve information which might be useful or relevant to the information need of the user .", "label": "", "metadata": {}, "score": "55.803024"}
{"text": "Residual inverse document frequency ( RIDF ) compares document frequency to another model of chance where terms with a particular term frequency are distributed randomly throughout the collection .MI tends to pick out phrases with non - compositional semantics ( which often violate the independence assumption ) whereas RIDF tends to highlight technical terminology , names , and good keywords for information retrieval [ 7].", "label": "", "metadata": {}, "score": "55.81077"}
{"text": "Wesley T. Chuang , Asok Tiyyagura , Jihoon Yang , and Giovanni Giuffrida .A fast algorithm for hierarchical text classification .In Proceedings of DaWaK-00 , 2000 .[5 ] .William W. Cohen and Yoram Singer .Context - sensitive learning methods for text categorization .", "label": "", "metadata": {}, "score": "55.863144"}
{"text": "In query parsing when Labelled Recall algorithm is implemented along with the Bracketed , from Fig 3 , its observed that the recall parameter increases considerably .In query classification , the Compute Term Document Frequency algorithm is implemented along with the Compute Term Frequency .", "label": "", "metadata": {}, "score": "55.915474"}
{"text": "93 - 102 , 2003 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .N. A. Syed , H. Liu , and K. K. Suang , \" Incremental learning with support vector machines , \" in Proceedings of the Workshop on Support Vector Machines at the International Joint Conference on Artificial Intelligence , pp .", "label": "", "metadata": {}, "score": "55.993874"}
{"text": "Based on my experience the ultimate limitation of SVM accuracy depends on the positive and negative \" features \" .You can do a grid search ( or in the case of linear svm you can just search for the best cost value ) to find the optimal parameters for maximum accuracy , but in the end you are limited by the separability of your feature - sets .", "label": "", "metadata": {}, "score": "55.99897"}
{"text": "The algorithm of our classifier using gamma - Poisson modeling is shown in Algorithm 1 for the training and test phases .In the training phase , the classifier estimates the values of parameters .for each class , from given training vectors ; in the test phase , the classifier assigns the most probable label to a given test vector .", "label": "", "metadata": {}, "score": "56.013638"}
{"text": "These data points are called support vectors .The quadratic optimization problem stated above can be solved by a quadratic programming ( QP ) solver .However , many QP methods can be very slow for large problems such as text categorization .", "label": "", "metadata": {}, "score": "56.064766"}
{"text": "Figure 6 : Computation time of text classification task for Industry Sector dataset .Performance Comparison in Text Classification Tasks for TechTC-100 .Figures 7 and 8 show the results of classification accuracy and those of computation time , respectively , at the task on the TechTC-100 dataset .", "label": "", "metadata": {}, "score": "56.074867"}
{"text": "Corpus annotation and classification schemes applicable to a wider variety of biomedical literature have been developed to support biologists with diverse TM needs [ 6 , 7 ] .Shared tasks ( e.g. BioCreative and the TREC Genomics track ) targeting the actual workflow of biomedical researchers have appeared , along with studies exploring the TM needs of specific tasks ( e.g. literature curation , library services for biomedical applications ) [ 8 , 9 ] .", "label": "", "metadata": {}, "score": "56.09877"}
{"text": "The breakeven point for the two methods for the 10 most frequent categories is summarized in .FIG .12 .Support Vector Machines works the best on all ten categories , the micro - average of breakeven for the ten categories is 92.93 % and the macro - average of breakeven is 85.8 % .", "label": "", "metadata": {}, "score": "56.126377"}
{"text": "The results were evaluated using precision ( P ) ( recall could not be calculated as not all of the positive polulation was known ) .Table 11 shows the average P per each ( i ) chemical and ( ii ) sub - taxonomy .", "label": "", "metadata": {}, "score": "56.163788"}
{"text": "Experimental .To investigate the behavior of the proposed gamma - Poisson model described in the previous section , we perform experiments on automatic text categorization .In the experiments , the performance of a classifier using gamma - Poisson modeling is compared with the performance of other classifiers that also use probabilistic modeling but with different distributions .", "label": "", "metadata": {}, "score": "56.176987"}
{"text": "given image is , say , the number 9 .The SVM algorithm operates by mapping the given training set into a .possibly high - dimensional feature space and attempting to locate in .that space a plane that separates the positive from the negative . examples .", "label": "", "metadata": {}, "score": "56.18631"}
{"text": "Half of the disagreements ( 12 ) were due to one of the annotators failing to notice keywords in text , and thus erroneously judging abstracts as irrelevant .These disagreements do not warrant improving the annotation guidelines but are likely to decrease when the annotators gain more experience .", "label": "", "metadata": {}, "score": "56.226303"}
{"text": "Demaine J , Martin J , Wei L , de Bruijn B : LitMiner : integration of library services within a bio - informatics application .Biomedical Digital Libraries 2006 , 3 : 11 .View Article PubMed .Shah P , Jensen L , Boue S , Bork P : Extraction of transcript diversity from scientific literature .", "label": "", "metadata": {}, "score": "56.29794"}
{"text": "View Article PubMed .Cohen KB , Yu H , Bourne PE , Hirschman L : Translating Biology : text mining tools that work .Pacific Symposium on Biocomputing 2008 , 551 - 555 .Lewin I , Silins I , Korhonen A , Hogberg J , Stenius U : A New Challenge for Text Mining :", "label": "", "metadata": {}, "score": "56.329044"}
{"text": "In Figures 3 and 4 the computation times of all the classifiers except SVM show almost linear dependence on the vocabulary size which is consistent with the time complexities of these classifiers described in Section 4.3 .Clearly , SVM is very fast except in the limited vocabulary region .", "label": "", "metadata": {}, "score": "56.3478"}
{"text": "Figure 10 depicts the noisy nature of the Industry Sector and the TechTC-100 datasets .To obtain the figure , the following procedures were applied .( 1 ) All the terms in the vocabulary were sorted by the collection term frequency , . that is larger than 20 % .", "label": "", "metadata": {}, "score": "56.411446"}
{"text": "Relevance annotation .The aim of the relevance annotation is to classify each abstract in the corpus as relevant , irrelevant or unsure with regard to hazard identification and MOA assessment .Since current CRA guidelines do not provide clear advice for this step , the experts agreed on the annotation principles based on their experience with CRA literature .", "label": "", "metadata": {}, "score": "56.448467"}
{"text": "Taxonomy .The keyword annotation of the first two chemicals ( one genotoxic and one non - genotoxic ) resulted in several updates in the classification and considerable extension of the initial taxonomy implemented inside the annotation tool .During the annotation of the subsequent six chemicals , only minor changes were required : some classes were combined , divided or refined following the discussion among the experts .", "label": "", "metadata": {}, "score": "56.458305"}
{"text": "Relatively efficient implementations of SVMs include the SVM light system by Joachims and the Sequential Minimal Optimization ( SMO ) algorithm by Platt .In addition to regular SVMs Joachims also introduced transductive SVMs .When there is very little training data it is crucial that the method can generalize well .", "label": "", "metadata": {}, "score": "56.49659"}
{"text": "Figure 2 shows an example of an annotated abstract where keywords indicating different types of evidence are highlighted in blue , red , and green fonts .Since the experts were not required to annotate every single relevant keyword , calculating inter - annotator agreement was not meaningful .", "label": "", "metadata": {}, "score": "56.527428"}
{"text": "Referring now to .FIG .5 , one advantage of the system is that subclasses and reclassification may be performed automatically to create a new subclass .A new subclass is defined in step 52 .In step 54 , selected documents from the class to be divided are selected for the subclass .", "label": "", "metadata": {}, "score": "56.583153"}
{"text": "Many abstracts focus on several chemicals and/or refer to results conducted in previously published experiments .It was agreed that the experts would focus only on the chemical of interest and on new rather than previously published results .For maximum accuracy , the experts were not required to annotate every potentially relevant keyword but only the ones which they perceived as the most important or dominant .", "label": "", "metadata": {}, "score": "56.59587"}
{"text": "[ 31 , 32 ] , semantically related biological terms sharing the same stem are not always reducible to the stem form .Feature selection .We evaluated the feature selection methods with two taxonomy classes : the most balanced class ' animal study ' ( positive / negative 1:1.4 ) and an imbalanced class ' adducts ' ( positive / negative 1:6.5 ) .", "label": "", "metadata": {}, "score": "56.656784"}
{"text": "Annotation tool .Risk assessors typically ( i ) read each abstract retrieved by PubMed to determine its relevance for CRA , and ( ii ) classify each relevant abstract based on the types of evidence it provides for CRA .We designed a tool for expert annotation which imitates this process as closely as possible .", "label": "", "metadata": {}, "score": "56.66236"}
{"text": "Because the algorithm that finds a separating .hyperplane in the feature space can be stated entirely in terms of . vectors in the input space and dot products in the feature space , a .support vector machine can locate the hyperplane without ever . representing the space explicitly , simply by defining a function , . called a kernel function , that plays the role of the dot product in .", "label": "", "metadata": {}, "score": "56.690712"}
{"text": "Results show that the meaning similarities are . close to that of humans , LSA 's rate of knowledge acquisition . approximates that of humans , and LSA depends on the dimensionality .LSA can be use to test theories of human cognition .", "label": "", "metadata": {}, "score": "56.697136"}
{"text": "Use of ontologies to provide underpinning for information sharing and semantic interoperability has been long realized .By mapping concepts in a Web resource ( whether data or Web service ) to ontological concepts , users can explicitly define the semantics of that resource in that domain .", "label": "", "metadata": {}, "score": "56.72682"}
{"text": "For SVM , a dataset is regarded as noisy if the latter case occurs while the computation times of all the other probabilistic classifiers are not affected by the noisy nature because optimization procedures are not included in these classifiers .Concerning the origin of the noisy nature for the Industry Sector and the TechTC-100 datasets , we can consider following reasons .", "label": "", "metadata": {}, "score": "56.784782"}
{"text": "Given the basic resources described in this paper and the proposed extensions , our long term goal is to develop a TM tool to support the entire CRA workflow .Such a tool could significantly increase the productivity and consistency of CRA and enable risk assessors to concentrate on what they are best at : the expert judgement .", "label": "", "metadata": {}, "score": "56.794327"}
{"text": "19].30 , no . 1 , pp .3 - 26 , 2007 .[ 20].T. G. Jenny Rose Finkel and C. Manning , \" Incorporating non - local information into information extraction systems by gibbs sampling , \" in Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics ( ACL 2005 ) , 2005 , pp .", "label": "", "metadata": {}, "score": "56.835934"}
{"text": "Na\u00efve Bayes gives the lowest breakeven point , its micro - average over the ten categories is 82.81 and the macro - average is 70.39 % .The numbers included in are from the precision / recall breakeven calculation .From the recall perspective we can see that for category Earn , 1075 out of 1088 documents in Earn category are correctly classified only 13 documents are misclassified .", "label": "", "metadata": {}, "score": "56.866203"}
{"text": "In Naive Bayes , Work well on numeric and textual data .What is the relevance for text classification ?Hello : Following is the explanation : In KNN , a decision boundary is the space or boundary , which separates different class samples from each other in the data .", "label": "", "metadata": {}, "score": "56.895535"}
{"text": "This collection has a vocabulary of 103,003 words .For all four datasets , we use 10-fold cross - validation to make maximal use of the data and to allow comparison with the previous work by Allison [ 9 ] .", "label": "", "metadata": {}, "score": "56.902534"}
{"text": "View Article PubMed .Ananiadou S , McNaught J : Text Mining for Biology And Biomedicine Norwood , MA , USA : Artech House , Inc 2005 .Hunter L , Cohen KB : Biomedical Language Processing : What 's Beyond PubMed ?", "label": "", "metadata": {}, "score": "56.905624"}
{"text": "View Article PubMed .Rud\u00e9n C : What influences a health risk assessment ?Toxicology Letters 2006 , 167 ( 3 ) : 201 - 204 .View Article PubMed .Cohen KB , Fox L , Ogren PV , Hunter L : Corpus Design For Biomedical Natural Language Processing .", "label": "", "metadata": {}, "score": "56.928894"}
{"text": "However , the understanding of user needs is still one of the neglected areas of biomedical TM , and further user - centered evaluations and systems grounded in real - life tasks are required to determine which tools and services are actually useful [ 14 ] .", "label": "", "metadata": {}, "score": "56.946053"}
{"text": "The columns A1 and A2 correspond to the annotators 1 and 2 , respectively .The values shown are the number of annotations by the annotator .The last two columns show the statistics of agreement and disagreement .Rows 2 - 4 show the results for the three sub - taxonomies and the last row indicates the number of irrelevant abstracts among the relevant ones .", "label": "", "metadata": {}, "score": "56.9493"}
{"text": "Accordingly , it is intended that the invention be limited only in terms of the appended claims .Method and apparatus for automated procedure initiation in a data processing system including soliciting an evaluation vote from users automatically determined in response to identification of a functional area associated with a document .", "label": "", "metadata": {}, "score": "56.962414"}
{"text": "Harvest ratio varied among different domains and seed sets , probably due to the linkage density of pages under a particular domain or the quality of the seed URLs .Based on the results , we can see NE based focused crawler performs better than standard focused crawler ( lexical terms based approach ) and the breadth first crawler for all the three domains .", "label": "", "metadata": {}, "score": "57.1092"}
{"text": "Request for Answer Clarification by mcsemorgan - ga on 28 Aug 2003 12:48 PDT .I have some questions in the advantages and disadvantages part : 1 .Do you have a reference for this statement ?In Rocchio 's Algorithm , what is \" Constant and are empirical \" ? ?", "label": "", "metadata": {}, "score": "57.1293"}
{"text": "As a global observation , kNN , LLSF and neural network .method had the best performance , except for a Naive Bayes approach , .the other algorithms performed relatively well .The paper describes four machine learning techniques that are common .", "label": "", "metadata": {}, "score": "57.132545"}
{"text": "Link analysis based approaches build a web graph and this graph is used to identify potential URLs that can lead to topic relevant pages .The underlying premise of them is the topical locality of web [ 4].Chakrabarti et al .", "label": "", "metadata": {}, "score": "57.196556"}
{"text": "The unclassified document is thus categorized into the classification having the closest theme score .If the classification has subclasses , the theme score of the subclasses is compared with the theme score of the unclassified document .Once a classification and subclassification have been determined , the documents are stored along with its classification and subclassification into the document storage memory 14 .", "label": "", "metadata": {}, "score": "57.2918"}
{"text": "The most basic instance - based method is the k - Nearest Neighbor algorithm ( kNN ) .The idea is very simple .Given a test document , the system finds the k nearest neighbors among the training documents , and the categories associated with the k neighbors are weighted based on the distances or the similarities of the test document and the k nearest neighbors from the training set .", "label": "", "metadata": {}, "score": "57.293877"}
{"text": "The theme score represents a particular value for the subject matter of the class .Various known methods may be used to generate the theme value .For example , numerous algorithms for natural language searching may be used .The natural language search terms are developed from the source documents .", "label": "", "metadata": {}, "score": "57.312733"}
{"text": "FIG .2 is a classification hierarchy illustration according to the present invention .FIG .3 is a block diagram of a document according to the present invention .FIG .4 is a flow chart classification process according to the present invention .", "label": "", "metadata": {}, "score": "57.326195"}
{"text": "At the same time , if desired , a number of subclasses may also be developed in step 34 .In step 36 , a number of source documents are identified for each of the classes and if desired subclasses .These source documents are meant to suitably represent the technology or field of the particular class .", "label": "", "metadata": {}, "score": "57.348595"}
{"text": "When searchers or other users of the information in the system find documents that have been misclassified they may be identified and provided a negative weight in the system .This negative weight will prevent like documents from being classified in the similar wrong class .", "label": "", "metadata": {}, "score": "57.40502"}
{"text": "There are three approaches to NER3 : ( a ) rule based NER : is the earliest approach to NER .It detects NEs by writing regular expressions to suit the user needs .Some relevant classification algorithms include HMMs [ 14 ] , Maximum Entropy ( ME ) [ 15 ] , Transformation Based error - driven Learning ( TBL ) [ 16 ] , SVMs [ 17 ] Conditional Random Fields ( CRF ) [ 18 ] etc .", "label": "", "metadata": {}, "score": "57.440163"}
{"text": "Li F. , Yang Y. ( 2003 )A Loss Function Analysis for Classification Methods in Text Categorization .International Conference on Machine Learning ( ICML ) : 472 - 479 .Liu T. , Yang Y. , Wan H. , Zeng H. , Chen Z. , Ma W. ( 2005 ) Support vector machines classification with a very large - scale taxonomy .", "label": "", "metadata": {}, "score": "57.513058"}
{"text": "-Yavar May 14 ' 13 at 5:49 .I would recommend dimensionality reduction instead of feature selection .Consider either singular value decomposition , principal component analysis , or even better considering it 's tailored for bag - of - words representations , Latent Dirichlet Allocation .", "label": "", "metadata": {}, "score": "57.57863"}
{"text": "I would like to know following methods that when to apply a method , how they compare in performance .give me the answer such a discussion . \" for example , few documents need to be classify , they are not multi - modality and simple , so we can apply which method , and why we choose this method ... like this ! !", "label": "", "metadata": {}, "score": "57.59652"}
{"text": "The risk assessors were unanimous about the need to increase the productivity of their work to meet the current CRA demand .They reported that locating and classifying the scientific evidence in literature is the most time consuming phase of their work and that a tool capable of assisting this phase and ensuring that all the potentially relevant evidence is found would be particularly helpful .", "label": "", "metadata": {}, "score": "57.666565"}
{"text": "The third test collection is the Industry Sector dataset which is a collection of corporate web pages organized into hierarchical categories based on what a company produces or does .Although it has a hierarchy with three levels of depth , we do not take the hierarchy into account and use a flattened version of the dataset .", "label": "", "metadata": {}, "score": "57.680893"}
{"text": "It is useful to differentiate text classification problems by the number of classes a document can belong to .If there are exactly two classes ( e.g. spam / non - spam ) , this is called a \" binary \" text classification problem .", "label": "", "metadata": {}, "score": "57.74923"}
{"text": "The third column shows the total number of unique keyword annotations for each class .The count does not include the annotations for sub - classes , except for the three top level classes where the number of all keywords ( also those of sub - classes ) are included .", "label": "", "metadata": {}, "score": "57.773956"}
{"text": "Blaschko MB , Gretton A : Learning Taxonomies by Dependence Maximization .Twenty - Second Annual Conference on Neural Information Processing Systems ( Edited by : Koller D , Schuurmans D , Bengio Y , Bottou L ) .Cambridge , MA , USA : MIT Press 2009 , 153 - 160 .", "label": "", "metadata": {}, "score": "57.79006"}
{"text": "5 , pp .604 - 632 , 1999 .[ 7].[ 8].G. Pant , K. Tsioutsiouliklis , J. Johnson , and C. L. Giles , \" Panorama : extending digital libraries with topical crawlers , \" in Proceedings of the 4th ACM / IEEE - CS joint conference on Digital libraries , ser .", "label": "", "metadata": {}, "score": "57.814926"}
{"text": "A classification system ( 10 ) having a controller ( 12 ) , a document storage memory ( 14 ) , and a document input ( 16 ) is used to classify documents ( 20 ) .The controller ( 12 ) is programmed to generate a theme score from a plurality of source documents in a plurality of predefined source documents .", "label": "", "metadata": {}, "score": "57.830368"}
{"text": "It indicated that during any time of the crawl , the collection built using NE approach is rich in content than the lexical terms based focused crawler .Since NE recognition is performed on top of the main classifier used to guide the crawler , our approach is independent and allows to use with any focused crawler for improved harvest ratio when crawling narrow domains .", "label": "", "metadata": {}, "score": "57.850883"}
{"text": "In the Relations Learning stage , where graph relation weights are learned by computing probabilities between word pairs and in the Structure Learning stage , where an initial WWP graph , which contains all possible relations between aggregate roots and aggregates , is optimized by performing an iterative procedure .", "label": "", "metadata": {}, "score": "57.894016"}
{"text": "B Pang , L Lee , S Vaithyanathan ( 2002 ) .Thumbs up ?Sentiment Classification using Machine Learning Techniques , Proceeding of the ACM Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 79 - 86 .", "label": "", "metadata": {}, "score": "57.916084"}
{"text": "View Article PubMed .Horn F , Lau AL , Cohen FE : Automated extraction of mutation data from the literature : application of MuteXt to G protein - coupled receptors and nuclear hormone receptors .Bioinformatics 2004 , 20 ( 4 ) : 557 - 568 .", "label": "", "metadata": {}, "score": "57.923344"}
{"text": "Squares Fit mapping are the top - performing classifiers , while the .Rocchio approaches had rela ... .SUMMARY .We report text categorization accuracy for different types of features . and different types of feature weights .The comparison of these .", "label": "", "metadata": {}, "score": "57.94944"}
{"text": "Here we take the first step towards the development of TM technology for the task : identifying and organizing the scientific evidence required for CRA in a taxonomy which is capable of supporting extensive data gathering from biomedical literature .Results .", "label": "", "metadata": {}, "score": "57.97458"}
{"text": "These preprocessing steps are applied to web pages in the training dataset as well as when running the crawling online , by the Parser module .Web Page Representation In order to apply any machine learning algorithm on the data , we need to vectorize the data in some format .", "label": "", "metadata": {}, "score": "58.022415"}
{"text": "In step 40 , an unclassified document is entered into the system .The unclassified document is preferably in digitally readable form and may comprise a word processing document , an Internet file , or other type of digitally readable file .", "label": "", "metadata": {}, "score": "58.07002"}
{"text": "16 is a plot of precision / recall break - even point for various systems .DESCRIPTION OF THE PREFERRED EMBODIMENT .In the following figures , specific examples of various uses of the present invention are illustrated .Although patent classification is a highly suitable use , other uses of the present invention will be evident to those skilled in the art .", "label": "", "metadata": {}, "score": "58.086067"}
{"text": "This success has recently led to two major modeling approaches along the lines of hierarchical modeling of texts : beta - binomial modeling and beta - negative binomial modeling .Beta - Binomial Model .The beta - binomial distribution model is derived with consideration of a serious drawback in Dirichlet - multinomial modeling [ 9 ] .", "label": "", "metadata": {}, "score": "58.112286"}
{"text": "This is due to an under - studied bias effect .that shrinks weights for classes with few training examples .ANother .systematic problem with Naive Bayes is that features are assumed to be . independent .As a result , even when the words are dependent , each word . contributes evidence individually .", "label": "", "metadata": {}, "score": "58.294563"}
{"text": "There is a clear correlation between frequency and performance : the average F decreases with descending frequency range , revealing increased classification difficulty .Classes with more than 300 abstracts have the highest average F ( 0.80 with standard deviation ( SD ) 0.08 ) .", "label": "", "metadata": {}, "score": "58.403084"}
{"text": "Categorical or Boolean ( Yes / No ) attribute .Output Format : .Classification statistics .Predicted versus Real table ( confusion matrix ) .Decision Tree diagram .Optimal Number of Records : .Minimum of 100 records .Maximum of 5,000,000 records .", "label": "", "metadata": {}, "score": "58.488983"}
{"text": "x .i .i .y .i . ) . . .The macro - average is just the average of the individual category ratios over all the categories , .n .i .x .i .y .", "label": "", "metadata": {}, "score": "58.495064"}
{"text": "In Text REtrieval Conference , pages 227 - 232 , 1997 .[17 ] .Amit Singhal , Mandar Mitra , and Christopher Buckley .Learning routing queries in a query zone .In Proceedings of SIGIR-97 , pages 25 - 32 , Philadelphia , US , 1997 .", "label": "", "metadata": {}, "score": "58.534256"}
{"text": "I am currently working on a project , a simple sentiment analyzer such that there will be 2 and 3 classes in separate cases .I am using a corpus that is pretty rich in the means of unique words ( around 200.000 ) .", "label": "", "metadata": {}, "score": "58.590553"}
{"text": "Complex queries are becoming commonplace , with the growing use of decision support systems .These complex queries often have a lot of common sub - expressions , either within a single query , or across multiple such queries run as a batch .", "label": "", "metadata": {}, "score": "58.6168"}
{"text": "URL is assigned a relevance score which is the same score of its parent page ( page where the URL is extracted ) as assigned by the classifier .So the URLs extracted from highly relevant pages are given priority and crawled first .", "label": "", "metadata": {}, "score": "58.677113"}
{"text": "Boosting and Rocchio applied to text filtering .In W. Bruce Croft , A. Moffat , C. J. van Rijsbergen , R. Wilkinson , and J. Zobel , editors , Proceedings of SIGIR-98 , pages 215 - 223 , Melbourne , AU , 1998 .", "label": "", "metadata": {}, "score": "58.705185"}
{"text": "For example , \" human study / epidemiology \" has several sub - classes corresponding to different types of human studies : \" polymorphism \" , \" biomarkers \" , \" tumor related effects \" , \" morphological effects on tissues and organs \" , and \" biochemical and cellbiological effects \" .", "label": "", "metadata": {}, "score": "58.791313"}
{"text": "Have you considered altering your bag - of - words representation to use , for example , word pairs or n - grams instead ?You may find that you have more dimensions to begin with but that they condense down a lot further and contain more useful information .", "label": "", "metadata": {}, "score": "58.79426"}
{"text": "This system outperforms previous schemes .Introduction We present a statistical parser that induces its grammar and probabilities from a hand - parsed corpus ( a tree - bank ) .Parsers induced from corpora are of interest both as simply exercises in machine learning and also because they are often the best parsers obtainable by any method .", "label": "", "metadata": {}, "score": "58.795517"}
{"text": "The keyword annotation was done for the 1164 abstracts deemed relevant during the relevance annotation .Keywords mentioned in existing CRA guideline documents were identified along with many novel ones missing in them ( these are illustrated together with the taxonomy in the following section ) .", "label": "", "metadata": {}, "score": "58.799294"}
{"text": "Frequency approach of bag - of - words ( BOW ) .Information Gain ( IG ) .X^2 Statistic ( CHI ) .The first method is already the one I use , but I use it very simply and need guidance for a better use of it in order to obtain high enough accuracy .", "label": "", "metadata": {}, "score": "58.80204"}
{"text": "Please let me know if these are the kind of papers that you will consider .Thanks for being patient with me .SUMMARY .This paper reports a controlled study with statistical significance . tests on five text categorization methods : the Support .", "label": "", "metadata": {}, "score": "58.803345"}
{"text": "2006 ) , with a total of approximately 800,000 documents and a vocabulary of over 4 million unique words .Figure 1 shows the power - law correspondence between the category size ( in terms of the number of documents ) on the X - axis and the number of same - sized categories on the Y - axis .", "label": "", "metadata": {}, "score": "58.905704"}
{"text": "( ii )Each term can be expressed as the average of a product .where the parameters are replaced with class - specific ones .In the last expression of ( 13 ) , we can see that each term of the products becomes a mass function of the negative binomial distribution when .", "label": "", "metadata": {}, "score": "58.915436"}
{"text": "FIG .1 , a classification system 10 has a controller 12 that is coupled to a document storage memory 14 .Controller 12 is also coupled to a document input 16 .Controller 12 preferably consists of a computer that is programmed to perform the theme - based classification as described below .", "label": "", "metadata": {}, "score": "58.994316"}
{"text": "TABLE IV : Q UERY CLASSIFICATION In the query classification comparisons of various algorithms in Table 4 , the computed term frequency ( tf ) algorithm when implemented along with compute term document frequency ( dr ) there is remarkable increase in recall and precision parameter .", "label": "", "metadata": {}, "score": "59.00156"}
{"text": "Our result for the beta - binomial is similar to the result reported by Allison [ 9 ] .This is because we made efforts to ensure maximal comparability with the work of Allison [ 9 ] for fair comparison .( iii )", "label": "", "metadata": {}, "score": "59.03578"}
{"text": "The gamma - Poisson classifier can be conveniently used for a wide range of practical systems in which continuous incremental learning tasks are required .In the following , we first try to explain the origin of the slow computation times of SVM for the Industry Sector and the TechTC-100 datasets and then describe the effective incremental learning of the gamma - Poisson classifier which is suitable in practical systems .", "label": "", "metadata": {}, "score": "59.115505"}
{"text": "For example , \" strand breaks \" , \" adducts \" , \" chromosomal changes \" ( \" micronucleus \" and \" chromosomal aberrations \" ) , \" mutations \" and \" other DNA modifications \" each provide different types of evidence for the genotoxic MOA .", "label": "", "metadata": {}, "score": "59.117966"}
{"text": "LSA links information retrieval and human semantic memory .Latent .Semantic Indexing ( LSI ) , like LSA , was tested against pre - examined . documents .Direct comparisons were muddied by preprocessing words .LSA .does synonym tests , since most near neighbors are related by the . cosine .", "label": "", "metadata": {}, "score": "59.157066"}
{"text": "classes can be differentiated from one another by searching for . similarities between the data provided .The K - Nearest Neighbor is suitable for data streams .KNN does not . build a classifier in advance .When a new sample arrives , KNN finds .", "label": "", "metadata": {}, "score": "59.167984"}
{"text": "It is clear that focused crawlers should always maintain a high harvest ratio than generic crawlers .Figure 2 gives the high level overview of a simple focused crawler .URLs extracted from these relevant pages will be added to the crawler frontier thus to continue with the crawling process .", "label": "", "metadata": {}, "score": "59.171177"}
{"text": "Precision and recall are two fundamental measurements used to evaluate the performance of classifiers .Precision is the percentage of the documents classified by the system to the class that actually belong in that class .In other words , precision is a measure of how much junk is returned with the valuable information .", "label": "", "metadata": {}, "score": "59.19426"}
{"text": "I need info especially to setup an interface ( python oriented , open - source ) between feature space dimension reduction methods ( LDA , LSI , moVMF etc . ) and clustering methods ( k - means , hierarchical etc . ) .", "label": "", "metadata": {}, "score": "59.228394"}
{"text": "The implementation enables PubMed abstracts to be viewed inside a familiar web - browsing environment and also to be classified according to the specialized taxonomy .Previous work has observed that integrating custom functions within a familiar document browsing environment greatly encourages user uptake [ 8 ] .", "label": "", "metadata": {}, "score": "59.261215"}
{"text": "However , bias in estimating probabilities often may not . make a difference in practice -- it is the order of the probabilities , . not their exact values , that determine the classifications .Studies comparing classification algorithms have found the Na\u00efve .", "label": "", "metadata": {}, "score": "59.290443"}
{"text": "It has been well established , however , that the Poisson model does not fit observed data [ 1 , 2 ] .The reason for the failure of the Poisson model is that , for most words , the predicted variance , which is equal to the Poisson mean ( the expected number of occurrences during the given interval ) , systematically underestimates the actual variance .", "label": "", "metadata": {}, "score": "59.294743"}
{"text": "A controlled . study using three classifiers , kNN , LLSF and WORD , was conducted to . examine the impact of configuration variations in five versions of .Reuters on the observed performance of classifiers .Analysis and empirical evidence suggest that the evaluation results on .", "label": "", "metadata": {}, "score": "59.332355"}
{"text": "They can support current manual CRA as well as facilitate the development of an approach based on TM .We discuss extending the taxonomy further via manual and machine learning approaches and the subsequent steps required to develop TM technology for the needs of CRA .", "label": "", "metadata": {}, "score": "59.654144"}
{"text": "Therefore , these two datasets are noisy for SVM in the sense that we have described above compared with the other two datasets .Furthermore , the fast computation time of SVM for a linearly separable dataset as demonstrated in Figures 3 and 4 can not be expected with other kernels ( the . is optimized for the linear kernel so that the runtime can be scaled linearly with the number of training examples by use of a cutting - plane algorithm ) .", "label": "", "metadata": {}, "score": "59.65547"}
{"text": "Yutaka S , Montemagni S , Pezik P , Schuhmann DR , McNaught J , Ananiadou S : BioLexicon : A Lexical Resource for the Biology Domain .Proceedings of the Third International Symposium on Semantic Mining in Biomedicine ( SMBM 2008 ) , Turku , Finland 2008 .", "label": "", "metadata": {}, "score": "59.737534"}
{"text": "Note e - work notify - active notification i.e. prompting .Affiliated with .Abstract .Background .One of the most neglected areas of biomedical Text Mining ( TM ) is the development of systems based on carefully assessed user needs .", "label": "", "metadata": {}, "score": "59.74188"}
{"text": "The result shows \u02dc\u00b12.5 % variation on the average breakeven .All three methods are very stable with respect to variation in feature dimensionality .With reasonable number of features selected both SVM and kNN generalize well .The results are not shown here .", "label": "", "metadata": {}, "score": "59.78276"}
{"text": "\\ ] .Term \\(G(h_\\theta ) \\ ) is called the ' ' regularization term ' ' , measuring the complexity of any rule \\(h_\\theta\\ .\\ ) Exact definitions of the empirical risk term and the regularization term may differ in various classification methods .", "label": "", "metadata": {}, "score": "59.79753"}
{"text": "Although there are 100 different combinations of positive and negative categories in the datasets , we only use positive documents because positive documents for each class are sufficient to define a multiclass classification problem .We found that 40 distinct positive categories in the 100 pairs of positive and negative categories , and therefore the task becomes applying one of the 40 possible labels to each of test documents .", "label": "", "metadata": {}, "score": "59.84053"}
{"text": "Yiming Yang and Jan O. Pedersen .A comparative study on feature selection in text categorization .In Proceedings of ICML-97 , pages 412 - 420 , Nashville , US , 1997 .Tools . \" ...This paper is a comparative study of feature selection methods in statistical learning of text categorization .", "label": "", "metadata": {}, "score": "59.94026"}
{"text": "5 ] was the first to utilize machine learning into focused crawling .They used an existing document taxonomy ( Yahoo ! ) to train a Naive Bayes classifier and to classify retrieved web pages into categories .Use of a taxonomy helps in better modeling of irrelevant pages ( the negative class ) .", "label": "", "metadata": {}, "score": "59.954315"}
{"text": "So extracting useful textual content out of them is challenging .Parser extracts the textual content and URLs out of web pages .Parser can deal with typos in html , inconsistent html tags , comments and variety of other html errors .", "label": "", "metadata": {}, "score": "59.9591"}
{"text": "Only ( iii ) improved the performance of all the classifiers ( data not shown here ) and was thus adopted for the main experiments .The poor performance of ( i ) demonstrates that a standard stemmer is not optimal for biomedical data .", "label": "", "metadata": {}, "score": "59.98458"}
{"text": "In this context , a related issue is handling query imprecision- most users of online databases tend to pose imprecise queries which admit answers with varying degrees of relevance .We have described the experiments that empirically validate our approaches in various stages of query processing .", "label": "", "metadata": {}, "score": "60.038406"}
{"text": "i .x .x . i .To state the method formally , let x be a test document vector .Let x 1 , x 2 , . . ., x k be the k nearest neighbors of x in terms of the cosines between two document vectors , and let c 1 , c 2 , . . .", "label": "", "metadata": {}, "score": "60.213085"}
{"text": "BMC Bioinformatics 2008 , 9 ( 10 ) : 1471 - 2105 .Chen ES , George H , Hua X , Marianthi M , Friedman C : Automated acquisition of disease drug knowledge from biomedical and clinical documents : an initial study .", "label": "", "metadata": {}, "score": "60.220276"}
{"text": "All of these methods showed significant improvement .( up to 71 % reduction in weighted error rates ) .over the performance of the original kNN algorithm on .TDT benchmark collections , making kNN among the . top - performing systems in the recent TDT3 official evaluation .", "label": "", "metadata": {}, "score": "60.287567"}
{"text": "event tracking system over different ... .SUMMARY .This paper explores the use of Support Vector Machines SVMs for .learning text classifiers from examples It analyzes the particular .properties of learning with text data and identifies why SVMs are . appropriate for this task Empirical results support the theoretical . findings SVMs achieve substantial improvements over the currently best .", "label": "", "metadata": {}, "score": "60.350437"}
{"text": "Poster Paper Proc . of Int .Conf . on Advances in Computer Science and Application 2013 java .A Collection of the TREC WebTrack [ 13 ] and we measured precision and recall over a set Indian statistical institute , Kolkata .", "label": "", "metadata": {}, "score": "60.39173"}
{"text": "SVM will assign to each new input vector x a target value 1 if .i .l .y .i .i .T .x . ) x .i . )b .T . or .i .", "label": "", "metadata": {}, "score": "60.39322"}
{"text": "It was agreed that the experts would annotate all the keywords which jointly identify the types of scientific data offered by the abstract .Mode of Action ( MOA ) .A MOA is a core concept in CRA .It specifies the key events leading to cancer , explaining the genetic and cellular alterations which result in the appearance of the scientific data mentioned above .", "label": "", "metadata": {}, "score": "60.584846"}
{"text": "TABLE V : SPELLING ERRORS IX .EXPERIMENTAL EVALUATION The experiments were conducted on the FIRE system ; all the algorithms in each category of query processing , web semantics and spelling errors in query were implemented in \u00a9 2013 ACEEE DOI : 03 .", "label": "", "metadata": {}, "score": "60.621613"}
{"text": "Predictions from a SVM are not Probabilistic .In regression the SVM outputs a point estimate , and in classification , a ' hard ' binary decision .The initial SVM model was designed to separate two classes .In other words there was n't originally a SVM that was designed for multiple class separation .", "label": "", "metadata": {}, "score": "60.638977"}
{"text": "\\ )A commonly used loss functions is the 0/1-loss , which returns 0 if the prediction matches the true label , and 1 otherwise .In this case , the risk is equal to the probability that the classification rule will misclassify an example .", "label": "", "metadata": {}, "score": "60.660637"}
{"text": "II . RELATED WORK Amit Goyal et.al analyses exponential growth in number of possible strategies with the increase in number of relations in a query has been identified as a major problem in the field of query optimization of relational databases .", "label": "", "metadata": {}, "score": "60.660965"}
{"text": "As PCB has a well - known neuro - behavioural effect , the data includes many abstracts irrelevant for CRA .The good performance can be observed across the whole taxonomy : TOX has the best P ( 0.99 ) , and CA and MOA have 0.94 and 0.95 P , respectively .", "label": "", "metadata": {}, "score": "60.678627"}
{"text": "This assumption is made throughout this work . )We are given a set of training documents .The Generative Probabilistic Classifier .The simplicity is mainly due to the following two assumptions .First , an individual document is assumed to be represented as a vector of word counts ( bag - of - words representation ) .", "label": "", "metadata": {}, "score": "60.693306"}
{"text": "In the same way , focused crawlers can be used to generate data for an individual user or a community in their interested topic or automated building of web directories like Yahoo!1 , Open Directory Project2 which still uses human expertise for the categorization .", "label": "", "metadata": {}, "score": "60.710403"}
{"text": "Decision Tree algorithm helps solving the task of classifying cases . into multiple categories .In many cases , this is the fastest , as well . as easily interpreted machine learning algorithm of PolyAnalyst .The .DT algorithm provides intuitive rules for solving a great variety of .", "label": "", "metadata": {}, "score": "60.796196"}
{"text": "Although some such abstracts may turn out to be irrelevant after reading the full article , experts agreed that since they are potentially relevant , they should be included for further assessment as not to lose data valuable for CRA .Appendix 1 shows sentences from some abstracts judged as relevant where the evidence for relevance is highlighted using bold font .", "label": "", "metadata": {}, "score": "60.82092"}
{"text": "Multi - label and multi - class tasks are often handled by reducing them to \\(k\\ ) binary classification tasks , one for each category .For each such binary classification tasks , members of the respective category are designated as positive examples , while all others are designated as negative examples .", "label": "", "metadata": {}, "score": "60.895294"}
{"text": "A Study on Optimal Parameter Tuning for Rocchio Text Classifier .Abstract .Current trend in operational text categorization is the designing of fast classification tools .Several studies on improving accuracy of fast but less accurate classifiers have been recently carried out .", "label": "", "metadata": {}, "score": "60.917503"}
{"text": "I have researched several articles and compiled a summary of the advantages and disadvantages of the models .I am unable to find any article that specifically relates to the comparison of each model and than prove for various situations , which is the best for each .", "label": "", "metadata": {}, "score": "60.939476"}
{"text": "Html META tags contain useful information about a particular page ; we consider META title tag and the META description tag .Named Entity Recognizer ( NER ) : This module extracts NEs appearing on a page it receives .It recognizes NEs in three categories , namely , LOCATION , PERSON and ORGANIZATION .", "label": "", "metadata": {}, "score": "60.945747"}
{"text": "Proceedings of the ISMB BioLINK Special Interest Group on Text Data Mining 2008 .Sun L , Korhonen A , Silins I , Stenius U : User - driven development of text mining resources for Cancer Risk Assessment .Proceedings of the NAACL workshop on BIO - NLP 2009 .", "label": "", "metadata": {}, "score": "61.01313"}
{"text": "The Decision Tree exploration engine is used for task such as .classifying records or predicting outcomes .You should use decision .trees when you goal is to assign your records to a few broad . categories .Decision Trees provide easily understood rules that can .", "label": "", "metadata": {}, "score": "61.13595"}
{"text": "272 - 279 .[5].31 , no .11 - 16 , pp .1623- 1640 , 1999 .[ 6].J. Kleinberg , \" Authoritative sources in a hyperlinked environment , \" Journal of the ACM ( JACM ) , vol .", "label": "", "metadata": {}, "score": "61.147545"}
{"text": "Of course , various other means for coupling controller 12 to documents would be evident to those skilled in the art including different document sources .Input 16 may , for example , comprise a CD ROM having a plurality of unclassified or crudely classified documents thereon .", "label": "", "metadata": {}, "score": "61.161453"}
{"text": "NMB yields the best overall R with BOS ( 0.82 ) but its P is notably lower than that of SVM .Table 9 shows the average P , R and F for the three sub - taxonomies using the best performing feature set BOS with the three classifiers . \"", "label": "", "metadata": {}, "score": "61.247246"}
{"text": "Rocchio 's Algorithm 2 .Naive Bayes 3.K - Nearest Neighbor(KNN ) 4 .Decision Tree 5 .Support Vector Machine(SVM ) 6 .Voted classification 7 .Latent Semantic Analysis .Subject : Re : categorization Answered By : leader - ga on 25 Jul 2003 00:05 PDT Rated : .", "label": "", "metadata": {}, "score": "61.31756"}
{"text": "The algorithm for detecting and correcting malapropisms does show some improvement in recall and precision when implemented alone .But when its implemented with other algorithm it can make considerable difference in recall and precision parameters of query processing .In the web semantics from Table VI , its observed that when semantics is added to the WSDL , UDDI and Web Service Discovery there is considerable increase in the precision and recall parameters .", "label": "", "metadata": {}, "score": "61.343605"}
{"text": "Li L , Chase HS , Patel CO , Friedman C , Weng C : Comparing ICD9-Encoded Diagnoses and NLP - Processed Discharge Summaries for Clinical Trials Pre - Screening : A Case Study .AMIA Annual Symposium , Washington , DC , USA 2008 .", "label": "", "metadata": {}, "score": "61.47831"}
{"text": "The evaluative character of a word is called its semantic orientation .Positive semantic orientation indicates praise ( e.g. , \" honest \" , \" intrepid \" ) and negative semantic orientation indicates criticism ( e.g. , \" disturbing \" , \" superfluous \" ) .", "label": "", "metadata": {}, "score": "61.717876"}
{"text": "The evaluative character of a word is called its semantic orientation .Positive semantic orientation indicates praise ( e.g. , \" honest \" , \" intrepid \" ) and negative semantic orientation indicates criticism ( e.g. , \" disturbing \" , \" superfluous \" ) .", "label": "", "metadata": {}, "score": "61.717876"}
{"text": "Bayes Theorem to estimate the posterior probabilities of all . qualifications .For each . instance of the example language a classification with the highest .posterier probability is chosen . as the prediction .Example : .Suppose your data consist of fruits , described by their color and . shape .", "label": "", "metadata": {}, "score": "61.737198"}
{"text": "reclassifying documents with said plurality of classes into the plurality of new classes when the classified document theme score is equal to one of the respective new class theme scores ; . storing the reclassified documents in a document storage memory .", "label": "", "metadata": {}, "score": "61.782238"}
{"text": "View Article PubMed .Ananiadou S , Kell D , Tsujii J : Text mining and its potential applications in systems biology .Trends in Biotechnology 2006 , 24 ( 12 ) : 571 - 579 .View Article PubMed .Zweigenbaum P , Demner - Fushman D , Yu H , Cohen KB : Frontiers of biomedical text mining : current progress .", "label": "", "metadata": {}, "score": "61.822227"}
{"text": "how to access the quality of each .The paper surveys the machine learning text classification algorithms .and measure their efficiency to predict the best classification .method .This is a thesis written by one of the doctorate candidates of the .", "label": "", "metadata": {}, "score": "61.9142"}
{"text": "Parameter Estimation for Gamma - Poisson Modeling .We begin by considering the validity of the parameter estimation methods for gamma - Poisson modeling that were described in Section 3.3 .As seen in Table 2 , the accuracy values obtained for the two estimation methods are almost equivalent , indicating that the precision of the rational approximation and the convergence of the iterative method are both sufficient .", "label": "", "metadata": {}, "score": "61.922607"}
{"text": "Given the user query , the goal of an Information Retrieval [ IR ] system is to retrieve information which might be useful or relevant to the information need of the user .Hence , the query processing plays an important role in IR system .", "label": "", "metadata": {}, "score": "61.96851"}
{"text": "However , using 10/40 split , the transductive SVM does n't provide superior performance as expected with very few training documents .This could be because the entire data set is too small to show its difference from SVM .Naive Bayes has the lowest accuracy .", "label": "", "metadata": {}, "score": "62.022987"}
{"text": "When classes are distinct , classifiers can be very accurate .When classes are similar , classifiers will generalize well only if sufficient training data is available .From literature and our experiments using software provided sample data , transductive SVM shows its advantage , when there is minimal training data but plentiful test data .", "label": "", "metadata": {}, "score": "62.15195"}
{"text": "Most child nodes in this sub - taxonomy have a type of relation with their parent class .For example , \" polymorphism \" is here a type of \" human study \" .The only exceptions are \" study length \" and \" the type of animals \" under \" animal studies \" class .", "label": "", "metadata": {}, "score": "62.37343"}
{"text": "Harvest ratio has been used as the primary metric to evaluate the crawler performance which has been calculated at constant intervals during the crawl .Experimental results are based on the same classifier ( Centroid classifier ) which was used to guide the crawler .", "label": "", "metadata": {}, "score": "62.379517"}
{"text": "Power Point presentation of five text classifiers ( Read the . conclusion ) .Hope this will help you .I will try to post more resources if I come .across any .Please clarify if you have any questions regarding this . research or if you need more help .", "label": "", "metadata": {}, "score": "62.5095"}
{"text": "Subclass A contains only 8 documents and subclass D , the largest subclass , has 99 documents .Only 5 documents in subclass A are selected as positive training examples when classifiers are trained for subclass A , 88 documents from other two subclasses are used as negative training examples .", "label": "", "metadata": {}, "score": "62.547768"}
{"text": "Although not a fully ideal measure ( see e.g. [ 42 ] for a discussion and criticism ) , we adopted it for this first annotation effort due to its familiarity .The Kappa statistics was calculated on data which two experts annotated independently 4 . 26 abstracts per chemical were selected randomly from the 15 and 16 journals listed in Table 1 and Appendix 3 , respectively .", "label": "", "metadata": {}, "score": "62.560287"}
{"text": "Input 16 may comprise various types of input such as a scanner or a direct interface to the Internet .Input 16 provides digitally readable documents to controller 12 for classification .In one embodiment , input 16 may be coupled to the Patent Office through a web browser .", "label": "", "metadata": {}, "score": "62.60845"}
{"text": "difficult to interpret and leading to considerable confusions in the . literature .Using the results evaluated on the other versions of .Reuters which exclude the unlabelled documents , the performance of .twelve methods are compared directly or indirectly .", "label": "", "metadata": {}, "score": "62.71888"}
{"text": "They also agreed that the abstracts of articles focussed only on exposure assessment should not be included because they are not suitable for hazard identification .Any other abstracts should be examined carefully for their relevance for CRA using expert judgement .", "label": "", "metadata": {}, "score": "62.78299"}
{"text": "The metrics for binary - decisions are defined as : .Due to the often highly unbalance number of positive vs. negative examples , note that TN often dominates the accuracy and error of a system , leading to miss - interpretation of the results .", "label": "", "metadata": {}, "score": "62.82897"}
{"text": "A small user test was finally carried out to investigate the practical usefulness of the automatic classification in a near real - world CRA scenario .The abstracts were downloaded from the set of 15 journals listed in Table 1 .As with the CRA corpus , only abstracts from years 1998 - 2008 were included .", "label": "", "metadata": {}, "score": "63.008385"}
{"text": "These vectors may be thought of as .points in an m - dimensional space .In theory , a simple way to build a . binary classifier is to construct a hyperplane ( i.e. , a plane in a . space with more than three dimensions ) separating class members .", "label": "", "metadata": {}, "score": "63.092"}
{"text": "There are times we get irrelevant information or information at best marginally relevant .As a result , vertical search engines ( a.k.a . topical search engines ) have gained its popularity in recent years which are specifically designed to provide topic specific information .", "label": "", "metadata": {}, "score": "63.108543"}
{"text": "Pr ( C ) can be estimated from the frequency of documents in C .CNB extends NMB by addressing the problems it has e.g. with imbalanced data and the weight magnitude error .The class c of a document is : . is the number of times term i occurs in classes other than c .", "label": "", "metadata": {}, "score": "63.1177"}
{"text": "@larsmans This is already what I ask for .As I explained above , I am looking for a better \" feature selection \" method , which you advise me to do .Yes , I need to select my features to obtain better accuracy results , but how ?", "label": "", "metadata": {}, "score": "63.11952"}
{"text": "Preprocessing Preprocessing is very important especially when it comes to web pages .Web pages are inherently noisy ; to obtain the textual content that crawler is interested in , good parsing techniques are required .In this paper we remove all the JavaScript code inside SCRIPT tags , content within STYLE tags and all the other CSS code appearing on a page .", "label": "", "metadata": {}, "score": "63.15098"}
{"text": "Regarding your use of document frequency , are you merely using the probability / percentage of documents that contain a term or are you using the term densities found within the documents ?If category one has only 10 douments and they each contain a term once , then category one is indeed associated with the document .", "label": "", "metadata": {}, "score": "63.17785"}
{"text": "4 , pp .543- 565 , 1995 .[17].Association for Computational Linguistics , 2002 , pp . 1 - 7 .[ 18].Association for Computational Linguistics , 2003 , pp .188 - 191 .", "label": "", "metadata": {}, "score": "63.22202"}
{"text": "In algorithm for detecting and correcting Malapropism there is seen a marginal increase in precision and recall form the Fig 5 .But when implemented with the other query processing categories it can help increase in overall precision and recall parameters .", "label": "", "metadata": {}, "score": "63.309475"}
{"text": "show that SVM , kNN and LLSF significantly outperform .NNet and NB when the number of positive training . instances per category are small ( less than ten ) , and that all .the methods perform comparably when the categories are . sufficiently common ( over 300 instances ) .", "label": "", "metadata": {}, "score": "63.311386"}
{"text": "you have more than a few variables and classes -- you would require an .enormous number of observations ( records ) to estimate these .probabilities .Naive Bayes classification gets around this problem by .not requiring that you have lots of observations for each possible . combination of the variables .", "label": "", "metadata": {}, "score": "63.367138"}
{"text": "To illustrate the information gain concept , consider the small example of .FIG . 7 .In general , there should be enough examples to show the distribution of the probabilities .We picked four words \" wheat \" , \" trade \" \" increase \" and \" export \" to calculate their information gains based on the given categorization of the four documents .", "label": "", "metadata": {}, "score": "63.37576"}
{"text": "Other sections may also be used such as the international or U.S. patent classifications .Of course , other sections may be delineated depending on the type of document used .As will be further described below , each document area may have different weight in the classification scheme .", "label": "", "metadata": {}, "score": "63.441895"}
{"text": "Referring now to .FIG .2 , an unclassified document 20 is classified into a plurality of classes ; class 1 , class 2 , and class 3 .Class 1 has two subclasses ; subclass 1 and subclass 2 .", "label": "", "metadata": {}, "score": "63.452023"}
{"text": "report provides classification statistics on the decision tree .Problems : .The drawback of this algorithm is that large number of gini indices . have to be computed at each node of the decision tree .In order to . decide which attribute is to be split at each node , the gini indices . have to be computed for all the attributes and for each successive . pair of values for all patterns which have not been classified .", "label": "", "metadata": {}, "score": "63.5051"}
{"text": "They are also capable of giving a more up to date crawl since the crawling is focused ; detection of changes are far more nimble than generic crawlers .What is a Domain ?In web and data mining , a domain can be loosely defined as information specializing a particular area of interest .", "label": "", "metadata": {}, "score": "63.52459"}
{"text": "CrossRef .[ 15 ] .Fabrizio Sebastiani .Machine learning in automated text categorization .ACM Computing Surveys , 34(1):1 - 47 , 2002 .CrossRef .[ 16 ] .Amit Singhal , John Choi , Donald Hindle , and Fernando C. N. Pereira .", "label": "", "metadata": {}, "score": "63.593807"}
{"text": "We also varied the number of nearest neighbors for kNN .The results show that optimal number of nearest neighbors is small relative to the size of training data set and feature length .For example , on Reuters-21578 collection 50 nearest neighbors were used for kNN where 500 features were chosen and the total number of training documents is 7780 .", "label": "", "metadata": {}, "score": "63.76705"}
{"text": "IDF(w i ) is defined as : .IDF . w .i . ) log .N .n .i . ) where N is the total number of training documents and n i is the number of documents that contain word w i .", "label": "", "metadata": {}, "score": "63.857155"}
{"text": "Its positive population is the highest ( positive / negative : 5:1 ) . \"Toxicokinetics \" ( TOX ) with a lower positive population ( 1:2.6 ) has still good F ( 0.78 ) .In these results , R and P are balanced with an average difference of 0.06 .", "label": "", "metadata": {}, "score": "63.872482"}
{"text": "The DT algorithm is .well - poised for analyzing very large databases because it does not . require loading all the data in machine main memory simultaneously .PolyAnalyst takes a full advantage of this feature by implementing . incremental DT learning with the help of the OLE DB for Data Mining . mechanism .", "label": "", "metadata": {}, "score": "63.938835"}
{"text": "The user queries generally suffer from low precision , or low quality document retrieval .To overcome this problem , scientists proposed methods to expand the 36 \u00a9 2013 ACEEE DOI : 03 .LSCS.2013.3.559 original query with other topic - related terms extracted from exogenous ( e.g. ontology , WordNet , data mining ) or endogenous knowledge ( i.e. extracted only from the documents contained in the collection ) .", "label": "", "metadata": {}, "score": "63.97635"}
{"text": "for classes with strong word dependencies is larger than for classes .with weak word dependencies .K - Nearest Neighbor .The goal of this clustering method is to simply separate the data . based on the assumed similarities between various classes .", "label": "", "metadata": {}, "score": "63.985344"}
{"text": "This is not ideal since chemical carcinogenesis is such a complex process that even the most experienced risk assessor is incapable of memorizing the wide range of relevant evidence without the support of a thorough specification .Here we report the work we did on obtaining a more adequate specification of the scientific evidence for CRA .", "label": "", "metadata": {}, "score": "64.153656"}
{"text": "p a measures the observed level of agreement while p e measures the chance agreement between two annotators .Our Kappa result is 0.68 .According to the scale of [ 45 ] , this value indicates substantial agreement between the annotators .", "label": "", "metadata": {}, "score": "64.20962"}
{"text": "Adding Semantics in WSDLIs to develop semantic Web services where by the Web services are annotated based on shared ontologies , and use these annotations for semanticsbased discovery of relevant Web services .One such approach that involves adding semantics to WSDL is using DAML+OIL ontologies .", "label": "", "metadata": {}, "score": "64.22336"}
{"text": "( vi )The experiments are conducted on a PC with a Phenom II X4 3.4 GHz processor and 8 GB of RAM .( vii )A pilot implementation of the gamma - Poisson classifier using the C programming language is about 2.5 times faster than that using the Java .", "label": "", "metadata": {}, "score": "64.31096"}
{"text": "Recent research has revealed that conflicting risk assessments of the same chemical are surprisingly common [ 22 , 23 ] .Inadequate or imbalanced data may give rise to such problems .Extensive data gathering is therefore essential not only for the coverage but also for the accuracy of CRA .", "label": "", "metadata": {}, "score": "64.34537"}
{"text": "Negative evidence includes , for example , diseases or endpoints unrelated to cancer ( e.g. effects on muscle contraction or loss of hearing ) .Appendix 2 shows example sentences from irrelevant abstracts with negative evidence highlighted .Not all the abstracts are clearly relevant or irrelevant according to these criteria .", "label": "", "metadata": {}, "score": "64.34807"}
{"text": "journal/2001WordsSenses .pdf .SUMMARY .This paper is a comparative study of text categorization methods .Fourteen methods are investigated , based on .previously published results and newly obtained results from .additional experiments .Corpus biases in commonly .", "label": "", "metadata": {}, "score": "64.4028"}
{"text": "Because the classes are hierarchically organized , disagreement on a child class may still mean agreement on the parent class .For example , annotator 1 ( A1 ) may select \" type of animal \" while annotator 2 ( A2 ) may select \" animal study \" .", "label": "", "metadata": {}, "score": "64.51256"}
{"text": "AGAIN , As far as I can assume you may already have knowledge of the algorithms , therefore instead of Repeating the information or writing my own review , I tried hard to find the type of papers that can help you with your research .", "label": "", "metadata": {}, "score": "64.564705"}
{"text": "p ( \u03b8 c ) is the prior distribution of class c .We used WEKA software environment [ 37 ] for the implementation of NMB and CNB .SVMs have been reported to outperform other TC methods on many TM tasks and have the benefit that they work well even when the data is sparse .", "label": "", "metadata": {}, "score": "64.59362"}
{"text": "Some questions I 'm still not understand .Why is non English ? ?In Rocchio 's Algorithm , you have n't answer me what is \" Constant and are empirical \" ? ?For instance news messages .Request for Answer Clarification by mcsemorgan - ga on 27 Sep 2003 17:48 PDT . ragingacademic , I would like to thank leader - ga , his answer was very well .", "label": "", "metadata": {}, "score": "64.61307"}
{"text": "BFC , which is a general crawler , was also run along with focused crawlers for the purpose of comparing focused crawling to general crawling .Seeds in each case were considered the root web pages in each category .As there is an infinite number of candidates to seed URLs , for each domain we have selected a few URLs , which we considered relevant to the domain .", "label": "", "metadata": {}, "score": "64.82337"}
{"text": "The unclassified document is classified into the class and/or subclasses that correspond most closely with the theme score thereof .Referring now to .FIG .3 , unclassified document 20 may have a variety of sections represented by reference numerals 22 , 24 , and 26 .", "label": "", "metadata": {}, "score": "64.95161"}
{"text": "This process is called the tunneling .Seed set is the set of URLs that are known to be highly relevant to the particular topic of interest .It is collected manually or by the crawler with the help of an existing search engine / portal .", "label": "", "metadata": {}, "score": "64.965744"}
{"text": "LSA does n't use .first - hand knowledge of the world , but extracts from \" episodes \" of .word content .LSA does n't use word order or logic relationships .LSA .uses unitary expressions of meaning instead of relationships between . successive words .", "label": "", "metadata": {}, "score": "65.03041"}
{"text": "classification trees and with neural network classifiers .They have . also exhibited high accuracy and speed when applied to large . databases .The problem with multinomial Naive Bayes is that when one class has .more training examples than another , Naive Bayes selects poor weights .", "label": "", "metadata": {}, "score": "65.04783"}
{"text": "Feature Extraction and Selection In this section we will discuss about feature extraction and the selection process .Feature extraction is done for 3 cases : ( 1 ) lexical terms ( 2 ) lexical terms + NEs ( 3 ) only NEs .", "label": "", "metadata": {}, "score": "65.18739"}
{"text": "Berlin , Heidelberg : Springer - Verlag , 2007 , pp .62 - 73 .[ 11].M. Bazarganigilani , A. Syed , and S. Burkir , \" Focused web crawling using decay concept and genetic programming , \" vol .", "label": "", "metadata": {}, "score": "65.1944"}
{"text": "Gamma - Poisson Modeling of Text .Framework of the Model .As stated above , the Poisson distribution expresses the probability of a number of events occurring in a fixed period of time or in a specified unit of space .", "label": "", "metadata": {}, "score": "65.27307"}
{"text": "Three experts ( experienced risk assessors ) agreed on the annotation guidelines and produced a corpus which contains 1164 abstracts judged as relevant and annotated for 1742 unique keywords ( words or phrases ) indicating the evidence they offer for CRA .", "label": "", "metadata": {}, "score": "65.34546"}
{"text": "First , users ' browsing patterns are used to build a web graph , then this graph is clustered and the link structure among pages from different clusters is used to learn patterns which lead to topic specific pages .NAMED ENTITY RECOGNITION Named Entities ( NE ) are phrases that contain names of persons , organizations , locations , numeric expressions including time , date , money , percent expressions and names of other miscellaneous things .", "label": "", "metadata": {}, "score": "65.46483"}
{"text": "With \" toxicokinetics \" it is significantly lower ( 62 % ) .The overall agreement is 76 % .These results are good , particularly considering that the annotation was done using a relatively high number of classes and the chance agreement is low at 1.5 % .", "label": "", "metadata": {}, "score": "65.4832"}
{"text": "Do you know how to optimize the implementation of term - frequency method ? - clancularius Nov 29 ' 12 at 6:47 .I 'm sure this is way too late to be of use to the poster , but perhaps it will be useful to someone else .", "label": "", "metadata": {}, "score": "65.52936"}
{"text": "The nearest neighbors can be found by inner products , cosines or other distance metrics .In our implementation we used cosine to measure the similarity of vectors which is defined by .cosine .x .x .i . ) x .", "label": "", "metadata": {}, "score": "65.56055"}
{"text": "R. Babaria , J. S. Nath , S. Krishnan , K. R. Sivaramakrishnan , C. Bhattacharyya , and M. N. Murty , \" Focused crawling with scalable ordinal regression solvers , \" in International Conference on Machine Learning , 2007 , pp .", "label": "", "metadata": {}, "score": "65.637665"}
{"text": "The word stem is derived from the occurrence form of a word by removing case and stripping suffix information .For example \" compute \" , \" computes \" and \" computing \" are all mapped to the same stem \" compute \" .", "label": "", "metadata": {}, "score": "65.65207"}
{"text": "Poster Paper Proc . of Int .Conf . on Advances in Computer Science and Application 2013 Performance Evaluation of Query Processing Techniques in Information Retrieval 1 Prakasha S , 2Shashidhar HR , 3Dr .G T Raju , 4Prajna Krishnan and 5Shivaram K 1 Research Scholar , 2Asst .", "label": "", "metadata": {}, "score": "65.77103"}
{"text": "Each of the documents in the system may then be re - evaluated to determine the particular new class into which they should be categorized .EXAMPLE .An example of the present invention is set forth below : .Documents , which typically are strings of characters , have to be transformed into a representation suitable for the learning algorithms and the classification tasks .", "label": "", "metadata": {}, "score": "65.77261"}
{"text": "( iii )In the case of SVM , it has been clarified that the support vectors , which can be regarded as summarized information of original training vectors , are sufficient for incremental learning [ 24 ] .Along the line of this framework , the new set of training vectors becomes the union of support vectors obtained from original training vectors and one newly provided training vector ; we can thus retrain SVM with this new training set for incremental learning .", "label": "", "metadata": {}, "score": "65.811005"}
{"text": "I am using python and bash scripts .I have had a quick search on singular value decomposition , principal component analysis and specifically LDA , but I need time in order to understand how to use them . - clancularius Nov 30 ' 12 at 12:14 .", "label": "", "metadata": {}, "score": "65.934784"}
{"text": "In other words , Na\u00efve Bayes classifiers assume that the effect of an .variable value on a given class is independent of the values of other . variable .This assumption is called class conditional independence .It . is made to simplify the computation and in this sense considered to be .", "label": "", "metadata": {}, "score": "65.95109"}
{"text": "The Semantic Web is a collaborative movement led by the international standards body , the World Wide Web Consortium ( W3C ) .The standard promotes common data formats on the World Wide Web [ 17].By encouraging the inclusion of semantic content in web pages , the Semantic Web aims at converting the current web dominated by unstructured and semi - structured documents into a \" web of data \" .", "label": "", "metadata": {}, "score": "65.95921"}
{"text": "It can be observed that in Table 2 that precision has almost increased by 22 % and recall parameter doubled by 20 % .\u00a9 2013 ACEEE DOI : 03 .LSCS.2013.3.559 PARSING 38 .Poster Paper Proc . of Int .", "label": "", "metadata": {}, "score": "66.0498"}
{"text": "This weighting will establish an importance level for various sections with respect to developing the theme score for the unclassified document .In step 44 , the theme score for the unclassified document is developed .The theme score is developed in a corresponding manner to the theme score for the classification .", "label": "", "metadata": {}, "score": "66.20677"}
{"text": "View Article PubMed .Wilbur WJ , Rzhetsky A , Shatkay H : New directions in biomedical text annotation : definitions , guidelines and corpus construction .BMC Bioinformatics 2006 , 7 : 356 .View Article PubMed .Shatkay H , Pan F , Rzhetsky A , Wilbur WJ : Multi - dimensional classification of biomedical text : Toward automated , practical provision of high - utility text to diverse users .", "label": "", "metadata": {}, "score": "66.49334"}
{"text": "REFERENCES [ 1 ] Prakasha S , H R Shashidhar , Dr. G T Raju A Survey on Various Architectures , Models and Methodologies for Information Retrieval \" , IAEME , 2013 .Partially supported by the National Science Foundation under Grants IRI-9113736 and IRI-9157368 ( PYI Award ) and by grants from DEC , IBM , HP , AT&T , Informix , and Oracle [ 7 ] Mikio Yamamoto et.al .", "label": "", "metadata": {}, "score": "66.57593"}
{"text": "claim 3 wherein said document input comprises the Internet .A system as recited in .claim 3 wherein said document input comprises a scanner .Description .TECHNICAL FIELD .The present invention relates generally to the field of document classification , and more particularly , to a method and system for classifying documents automatically using themes of a predetermined classification .", "label": "", "metadata": {}, "score": "66.57741"}
{"text": "View Article .Eugenio B , Glass M : The kappa statistic : A second look .Computational linguistics 2004 , 30 : 95 - 101 .View Article .Siegel S , Castellan N : Nonparametric statistics for the behavioral sciences McGraw - Hill New York 1956 .", "label": "", "metadata": {}, "score": "66.68482"}
{"text": "Minus 2 because of space characters .Since our third expert was not available during the inter - annotator agreement tests , the tests were conducted using two experts only .The classes with less than 20 abstracts may have less than 2 positive abstracts in each fold of 10 fold CV , which is not representative of the class population .", "label": "", "metadata": {}, "score": "66.88679"}
{"text": "T. Joachims .Text categorization with support vector machines : Learning with many relevant features .In In Proceedings of ECML-98 , pages 137 - 142 , 1998 .[ 10 ] .Thorsten Joachims .A probabilistic analysis of the rocchio algorithm with tfidf for text categorization .", "label": "", "metadata": {}, "score": "67.02721"}
{"text": "TABLE III : Q UERY In the query parsing when labelled recall algorithm is implemented with the Bracketed recall algorithm considerably improves in the recall parameter by approximately 3 % even though the precision parameter remains almost the same and shown in Table III .", "label": "", "metadata": {}, "score": "67.046776"}
{"text": "learning tasks Furthermore they are fully automatic eliminating the .need for manual parameter tuning .Sincerely , . leader - ga .Request for Answer Clarification by mcsemorgan - ga on 17 Aug 2003 08:11 PDT .In the advantages and disadvantages part , you made research on Vector Space Model but what I needed is Support Vector Machine .", "label": "", "metadata": {}, "score": "67.066734"}
{"text": "Our result for the Dirichlet - multinomial is similar to that reported by Madsen et al .[ 7 ] , whereas the same model was found to perform worse in the study of Allison [ 9 ] .This disagreement is attributed to the difference in the estimation of parameters ; the iterative methods used in [ 7 ] and in this work give , in general , a better estimation than the method of moments used by Allison [ 9 ] .", "label": "", "metadata": {}, "score": "67.08444"}
{"text": "The model is trained on a mixture of CoNLL , MUC-6 , MUC-7 and ACE named entity corpora , and thus the model is fairly robust across domains .Classification : Classification phase is a very important stage in the system .", "label": "", "metadata": {}, "score": "67.33366"}
{"text": "Unfortunately , most real - world problems involve non - separable .data for which there does not exist a hyperplane that successfully . separates the positive from the negative examples .One solution to the .inseparability problem is to map the data into a higher - dimensional . space and define a separating hyperplane there .", "label": "", "metadata": {}, "score": "67.47482"}
{"text": "Share .References .[ 1 ] .Pivoted document length normalization .Technical Report TR95 - 1560 , Cornell University , Computer Science , 1995 .[ 2 ] .Avi Arampatzis , Jean Beney , C. H. A. Koster , and T. P. van der Weide .", "label": "", "metadata": {}, "score": "67.524734"}
{"text": "All authors have read and accepted the final manuscript .Authors ' Affiliations .Computer Laboratory , University of Cambridge .Institute of Environmental Medicine , Karolinska Institutet .References .Cohen A , Hersh W : A survey of current work in biomedical text mining .", "label": "", "metadata": {}, "score": "67.59531"}
{"text": "Humans draw conclusions from missing data .Reducing the . dimensionality of representation is useful when the representation .matches the data .The data should not be perfectly regenerated .The . similarity of dimensionality reduction is the cosine between vectors .", "label": "", "metadata": {}, "score": "67.63253"}
{"text": "Carcinogenic activity .Various types of human , animal ( in vivo ) , cellular ( in vitro ) and other mechanistic data provide evidence for CRA .Risk assessors pay attention to a variety of keywords indicating different study types in texts when aiming to locate this data .", "label": "", "metadata": {}, "score": "67.660675"}
{"text": "They classified 89.4 % of the abstracts as relevant , 10.1 % as irrelevant and 0.5 % as unsure .The small proportion of unsure abstracts can be explained by the general CRA principle which the risk assessors followed which encourages them to collect all the data of potential relevance for further assessment [ 17 , 20 ] .", "label": "", "metadata": {}, "score": "67.67555"}
{"text": "Poster Paper Proc . of Int .Conf . on Advances in Computer Science and Application 2013 classification by implementing some of the algorithm from each of the mentioned categories .Experimental results shows that the significance of each steps in query processing .", "label": "", "metadata": {}, "score": "67.730255"}
{"text": "KNN is a good choice when simplicity and accuracy are the predominant . issues .KNN can be superior when a resident , trained and tested .classifiers has a short useful lifespan , such as in the case with the .", "label": "", "metadata": {}, "score": "67.78414"}
{"text": "The Poisson distribution is one of the most commonly used models for describing the number of random occurrences of a phenomenon in a specified unit of space or time .This means that if we want to model the number of discrete occurrences that take place during a given length , we should first check whether or not the Poisson distribution provides a good approximation .", "label": "", "metadata": {}, "score": "67.84402"}
{"text": "Pr .C .c . k . x . )Pr .x .C .c . k . )Pr .C .c . k . )Pr .x . )The category with maximum probability determines the classification of the instance .", "label": "", "metadata": {}, "score": "67.91009"}
{"text": "Much of the SVM 's power comes from its criterion for selecting a . separating plane when many candidates planes exist : the SVM chooses .the plane that maintains a maximum margin from any point in the .training set .", "label": "", "metadata": {}, "score": "67.93425"}
{"text": "Unfortunately I 've also not worked with Turkish datasets or the python language .I answered you in my question above .Please take a look .Thanks for your answer btw . - clancularius Mar 18 ' 13 at 14:17 .", "label": "", "metadata": {}, "score": "67.94402"}
{"text": "Biomedical Text Mining ( TM ) has become increasingly popular due to the great need to provide access to the tremendous body of texts available in biomedical sciences .The major current challenge is to extend TM techniques with richer and deeper analysis and to apply them to support real - world tasks in biomedicine .", "label": "", "metadata": {}, "score": "68.06454"}
{"text": "A number of works have been reported on disease- and drug - related TM which have involved similar knowledge acquisition and classification efforts as our work , e.g. [ 47 - 49 ] among others .No prior work has been done ( to the best of our knowledge ) on specifying such a wide range of cancer - related evidence or developing TM for risk assessment of potentially carcinogenic substances .", "label": "", "metadata": {}, "score": "68.07199"}
{"text": "Motivation Web searching has been evolving ever since the start of the World Wide Web ( WWW ) .Various searching techniques have been introduced since then to increase the popularity of web the among people .Web crawlers play a vital role inside a search engine , such as finding new pages to be indexed , periodically recrawling and updating the index with fresh information etc .", "label": "", "metadata": {}, "score": "68.110435"}
{"text": "META keywords tag could also be used but it is ignored here as it can be susceptible to keyword spamming which can mislead the classifier .We remove all the numerical values in the dataset and finally remove all the files less than 400 byes .", "label": "", "metadata": {}, "score": "68.335686"}
{"text": "We present a method for extracting parts of objects from wholes ( e.g. \" speedometer \" from \" car \" ) .Given a very large corpus our method finds part words with 55 % accuracy for the top 50 words as ranked by the system .", "label": "", "metadata": {}, "score": "68.44124"}
{"text": "We present a method for extracting parts of objects from wholes ( e.g. \" speedometer \" from \" car \" ) .Given a very large corpus our method finds part words with 55 % accuracy for the top 50 words as ranked by the system .", "label": "", "metadata": {}, "score": "68.44124"}
{"text": "For example , if you have a . series of mRNA expression level measurements for each of a large . number of genes , the SVM can learn to answer questions such as , ' ' Does .the given gene belong to functional class X ? ' ' where X is some . category such as ' ' ribosomal genes ' ' or ' ' sugar and carbohydrate . transporters . ' '", "label": "", "metadata": {}, "score": "68.61858"}
{"text": "It also respects the Robots Exclusion Protocol which allows site owners to give specific instructions to web crawlers whether the site is crawlable or only some parts .Crawl Frontier : is the data structure which contains the URLs to be crawled and is implemented as a priority queue .", "label": "", "metadata": {}, "score": "68.76039"}
{"text": "( We first used the binary version of . on Windows . )The worst computation time of SVM indicates that this dataset has fundamentally different , undesirable characteristics for SVM .As will be discussed in the next section , the slow computation time of SVM is attributable to this dataset being not linearly separable because of its noisy nature .", "label": "", "metadata": {}, "score": "68.89363"}
{"text": "WEB SEMANTICS substrings in a corpus in O(NlogN ) time , even though there are N(N + 1)/2 such substrings in a corpus of size N. The algorithm groups the N ( N + 1)/2 substrings into at most 2N - 1 equivalence classes .", "label": "", "metadata": {}, "score": "68.954834"}
{"text": "We consider that further quantitative discussion is possible through analysis of the decision functions of the classifiers .An investigation along the line of such quantitative analysis is reserved for future research .Acknowledgment .The authors would like to acknowledge Dr. Yusuke Higuchi for useful discussion and illuminating suggestions .", "label": "", "metadata": {}, "score": "68.984146"}
{"text": "Poster Paper Proc . of Int .Conf . on Advances in Computer Science and Application 2013 process .In future we can work on larger dataset and also find the minimum dataset size required to estimate the precision and recall problem .", "label": "", "metadata": {}, "score": "68.98768"}
{"text": "Natarajan J , Berrar D , Dubitzky W , Hack C , Zhang Y , DeSesa C , Van Brocklyn J , Bremer E : Text mining of full - text journal articles combined with gene expression analysis reveals a relationship between sphingosine-1-phosphate and invasiveness of a glioblastoma cell line .", "label": "", "metadata": {}, "score": "69.183945"}
{"text": "As we go into the deeper levels of the taxonomy , the number of abstracts associated with individual classes gets increasingly small .The first column shows the name of a class in the taxonomy .The second column shows the total number abstracts classified in the class ( or its sub - classes ) .", "label": "", "metadata": {}, "score": "69.26013"}
{"text": "Considering the processing time and the training time we used a lower number of word stems to do the experiments .For all the methods we selected 500 words with highest information gain .For kNN we used the number of nearest neighbors equal to 50 .", "label": "", "metadata": {}, "score": "69.278694"}
{"text": "The three cost - based heuristic algorithms : Volcano - SH and 37 .Poster Paper Proc . of Int .Conf . on Advances in Computer Science and Application 2013 Volcano - RU , which are based on simple modifications to the Volcano search strategy , and a greedy heuristic .", "label": "", "metadata": {}, "score": "69.312294"}
{"text": "We present our annotation guidelines and a tool which we have designed for expert annotation of PubMed abstracts .A corpus annotated for keywords and document relevance is also presented , along with the taxonomy which organizes the keywords into classes defining core evidence for CRA .", "label": "", "metadata": {}, "score": "69.59686"}
{"text": "Appendix 2 Example sentences containing evidence for irrelevance .Example sentences containing information ( indicated in bold font ) which suggests that the abstract is irrelevant for CRA .Exposure to 600 ppm styrene caused a 3 dB hearing loss only at the highest test frequency ( 8 kHz ) .", "label": "", "metadata": {}, "score": "69.72531"}
{"text": "They were included to make the annotation task harder , given the high proportion of relevant abstracts among the 15 journals used for corpus creation .The resulting test data contains 208 abstracts in total .The test set was kept intentionally small to facilitate thorough error analysis .", "label": "", "metadata": {}, "score": "69.78192"}
{"text": "Proceedings of the 22nd SIGIR , New York , NY , USA 1999 .Hsu CW , Chang CC , Lin CJ : A practical guide to support vector classification .Tech . rep National Taiwan University , Taipei 2003 .Fan RE , Chang KW , Hsieh CJ , Wang XR , Lin CJ : LIBLINEAR :", "label": "", "metadata": {}, "score": "69.890076"}
{"text": "We next consider the reason that the gamma - Poisson gives somewhat better performance than the beta - binomial .As described in any textbook on probability distribution , the binomial can be approximated by the Poisson when the number of trials goes to infinity and the expected number of successes remains fixed .", "label": "", "metadata": {}, "score": "70.064926"}
{"text": "A number of genes ( e.g. oncogenes and tumor suppressor genes ) are known to be involved in cancer development and are therefore used as evidence .Some of these are shown in Table 4 , together with proteins regulated by them .", "label": "", "metadata": {}, "score": "70.09123"}
{"text": "Also their requirements are very demanding in network bandwidth and storage if such a task is to be carried out .As a result a new research area called focused web crawling emerged , where the crawler is specifically designed to crawl only a subset of the web graph that is of interest .", "label": "", "metadata": {}, "score": "70.21683"}
{"text": "y .i .i . k . x .x .i . )b .T .minimize : . w .i .l .i .i .l .j .l .y .i .", "label": "", "metadata": {}, "score": "70.27645"}
{"text": "Notice that SVM is a two - class classifier .To extend it to multiple classes we used a one class versus all other classes scheme , training a separate SVM classifier for each class .Note that different k - class classification schemes based on two - class classifiers have been developed .", "label": "", "metadata": {}, "score": "70.33892"}
{"text": "Taxonomy for carcinogenic activity : A flow chart displaying taxonomy for carcinogenic activity .Mode of Action .The second sub - taxonomy focuses on MOA and specifies the types of scientific evidence required for MOA classification .Shown in Figure 4 , this sub - taxonomy currently covers the two most frequent MOA types .", "label": "", "metadata": {}, "score": "70.44472"}
{"text": "The eight chemicals are shown in Table 2 .They were selected by the experts on the basis that they are ( i ) well - researched using a range of scientific tests and ( ii ) represent the two most common MOAs - genotoxic and non - genotoxic 2 .", "label": "", "metadata": {}, "score": "70.47456"}
{"text": "KNN does not rely on prior probabilities , and it is . computationally efficient .The main computation is the sorting of the .training documents in order to find out the K nearest neighbors for .the test document .K - Nearest Neighbor is useful when their are less than 20 attributes . per instance , there is lots of training data , training is very fast , .", "label": "", "metadata": {}, "score": "70.66876"}
{"text": "Appendix .Appendix 1 Sentences from abstracts relevant for CRA .Keywords representing evidence for relevance are indicated in bold font .Measurements of Hprt mutant frequencies ( via the T cell cloning assay ) showed that repeated exposures to 18 and 36 ppm BD - diol were significantly mutagenic in mice and rats .", "label": "", "metadata": {}, "score": "70.73212"}
{"text": "A support vector machine is a supervised learning algorithm developed .over the past decade by Vapnik and others ( Vapnik , Statistical .Learning Theory , 1998 ) .The algorithm addresses the general problem of .learning to discriminate between positive and negative members of a .", "label": "", "metadata": {}, "score": "70.8342"}
{"text": "FIG .7 it may be observed that the presence and absense of words \" wheat \" and \" trade \" can correctly categorize the documents and this agrees with the fact that \" wheat \" and \" trade \" have high information gain .", "label": "", "metadata": {}, "score": "71.006935"}
{"text": "FIGS .14 and 15 .In the 40/10 split , SVM shows better performance than transductive SVM and both are better than kNN .In the 10/40 split SVM performs the best among three methods .From the literature , transductive SVM works better than inductive SVM when there is very few training data and sufficient amount of testing data .", "label": "", "metadata": {}, "score": "71.02791"}
{"text": "We can see that one annotator ( A1 ) produced significantly more annotations than the other one ( A2 ) : 78 in total .This applies to the \" carcinogenic activity \" sub - taxonomy and in particular to \" toxicokinetics \" for which A1 produced 1.67 times more annotations than A2 .", "label": "", "metadata": {}, "score": "71.23452"}
{"text": "Even though Na\u00efve Bayes is very efficient , it does n't produce as accurate classification as SVM and kNN do .Results also indicate that classification with modestly lower or higher feature dimension does not appreciably affect the results .From the above discussion we can conclude that SVM and kNN are efficient , robust and stable methods that give good classification performance .", "label": "", "metadata": {}, "score": "71.23865"}
{"text": "For each of the eight chemicals ( see Table 2 ) , 10 abstracts from 15 journals listed in Table 1 were randomly retrieved from PubMed by using the chemical name as the search term .Two experts performed both relevance and keyword annotation using the final taxonomy in the annotation tool , and we investigated the agreement with which they associated the same abstracts with the same classes .", "label": "", "metadata": {}, "score": "71.274445"}
{"text": "Problems in previously published .experiments are analyzed , and the results of flawed experiments are .excluded from the cross - method evaluation .As . a result , eleven out of the fourteen methods are remained .A . k - nearest neighbor ( kNN ) classifier was chosen for .", "label": "", "metadata": {}, "score": "71.31206"}
{"text": "We bring together Scientists , Academician , Field Engineers , Scholars and Students of related fields of Engineering and Technology .Focused web crawling using named entity recognition for narrow domains .As a result , focused web crawlers have gained its popularity which is focused only on a particular domain .", "label": "", "metadata": {}, "score": "71.52623"}
{"text": "instances/81d91e93-df4da3c279 .Thanks for the clarifications .I am still trying to find the relevant .documents or papers .Sincerely , . leader - ga .Request for Answer Clarification by mcsemorgan - ga on 06Aug 2003 00:21 PDT .", "label": "", "metadata": {}, "score": "71.63225"}
{"text": "For example , the CRA corpus has only 27 abstracts in \" DNA repair ( damage ) \" class , while the data for new chemicals have many .The expert found this evaluation easy to conduct .She felt that if such an automatic classification system was available to support real - world CRA , it could significantly increase the productivity and also lead to more consistent and thorough CRA since manual gathering of such a wide range of scientific evidence from abstracts is very difficult .", "label": "", "metadata": {}, "score": "71.659935"}
{"text": "I 'm afraid I ca n't help much more at the moment as I 'm nearing the deadline for my PhD thesis ... which ironically is based on streamlining , interfacing and standardising the stages used in Text Categorisation !", "label": "", "metadata": {}, "score": "71.66522"}
{"text": "Toxicokinetics .The third sub - taxonomy focuses on toxicokinetics , shown in Figure 5 , specifying the different parts of this process .It consists of four main classes : \" absorption , uptake , distribution , excretion \" , \" bioaccumulation / lipophility \" , \" metabolism \" , and \" toxicokinetic modelling \" .", "label": "", "metadata": {}, "score": "71.815216"}
{"text": "We calculated the agreement based on both explicit agreement and implicit ( parent ) agreement .However , the same parent agreement was counted only once for each abstract .For example , if A1 selected \" animal study \" and A2 \" type of animal \" and \" study length \" , the two implicit parent agreements on \" animal study \" were counted as one agreement only .", "label": "", "metadata": {}, "score": "71.90016"}
{"text": "A system as recited in .claim 3 wherein said controller is programmed to assign a weight to sections of an unclassified document .A system as recited in .claim 3 wherein said controller is programmed to classify documents into a subclass .", "label": "", "metadata": {}, "score": "71.93446"}
{"text": "Important Disclaimer : Answers and comments provided on Google Answers are general information , and are not intended to substitute for informed professional medical , psychiatric , psychological , tax , legal , investment , accounting , or other professional advice .", "label": "", "metadata": {}, "score": "72.20794"}
{"text": "Vapnik VN : The nature of statistical learning theory New York , NY , USA : Springer - Verlag New York , Inc 1995 .Witten I , Frank E : Data Mining : Practical machine learning tools and techniques 2 Edition San Francisco : Morgan Kaufmann 2005 .", "label": "", "metadata": {}, "score": "72.21343"}
{"text": "To gain an understanding of how TM could best assist CRA , we conducted an initial study where we interviewed 14 experienced risk assessors working for different national and international CRA authorities in Sweden 1 [ 16 ] .These steps are conducted largely manually , relying on standard literature search engines ( e.g. provided with PubMed ) and word processors as technical support .", "label": "", "metadata": {}, "score": "72.32705"}
{"text": "A page from which a link was extracted is called the parent page and the page pointed by the url is called the child page or the target page .Due to the complexity of web an irrelevant web page might refer to a highly relevant page .", "label": "", "metadata": {}, "score": "72.32925"}
{"text": "The toxicokinetics taxonomy : A flow chart displaying the toxicokinetics taxonomy .The resulting taxonomy , consisting of the three sub - taxonomies , includes 48 classes in total .Table 6 shows the total number of abstracts and annotated keywords belonging to each class .", "label": "", "metadata": {}, "score": "72.38567"}
{"text": "URL Downloader : downloads html pages from the web .Initially , the downloading is started with the user provided seed URLs and later refers the Crawler Frontier to get URLs for crawling .Implemented as a multi threaded application , makes web page downloading faster .", "label": "", "metadata": {}, "score": "72.42914"}
{"text": "It classifies 1742 unique keywords found in the corpus to 48 classes which specify core evidence required for CRA .We report promising results with inter - annotator agreement tests and automatic classification of PubMed abstracts to taxonomy classes .A simple user test is also reported in a near real - world CRA scenario which demonstrates along with other evaluation that the resources we have built are well - defined , accurate , and applicable in practice .", "label": "", "metadata": {}, "score": "72.445366"}
{"text": "The training and testing data of 50 documents were separated in two different ways .In the 40/10 split each class contains 40 training documents , in the 10/40 split there are 10 training documents in each class .The number of nearest neighbors for kNN for both splits is chosen to be 5 .", "label": "", "metadata": {}, "score": "72.5981"}
{"text": "The literature search was limited to recent 10 years .Since many of the selected chemicals are well - studied , this yielded a sufficient number of abstracts for annotation .All the retrieved abstracts were included , except for benzo(a)pyrene for which only the latest 200 ( out of the c. 900 in total ) were considered .", "label": "", "metadata": {}, "score": "72.74756"}
{"text": "j .i .j .k . x .i .x .j . ) subject to : . i .l .y .i . i .The kernel function can be the following types of functions : . linear function . polynomial ( x\u00b7y+c ) d of degree d . sigmoid function tanh(\u03ba(x\u00b7y)+\u0398 ) .", "label": "", "metadata": {}, "score": "72.8312"}
{"text": "[ 1 ] proposed the Fish - search algorithm in which , crawling is simulated by a group of fish migrating the web .Each URL corresponds to a fish whose survivability is dependent on visited page relevance and remote server speed .", "label": "", "metadata": {}, "score": "72.839294"}
{"text": "Table 8 shows the average performance across the whole taxonomy .The performance of BOS is better than that of BOW according to all the three measures .On average , BOS outperforms BOW by 4 % in P and F , and 3 % in R. SVM yields the best overall P and F ( 0.71 and 0.74 ) with BOS .", "label": "", "metadata": {}, "score": "72.98857"}
{"text": "All four authors participated equally in the work reported in this paper .AK wrote most of the paper and together with US designed , supervised and coordinated the project .IS conducted the annotation work , designed the taxonomies , and conducted the inter - annotator agreement tests and the user test with the assistance of US .", "label": "", "metadata": {}, "score": "73.136475"}
{"text": "Data Collection Training data plays a vital role in any supervised learning model and can directly affect the test results as well .In this paper , the training data has been collected manually from online news providers in 3 domains : baseball , football and American politics .", "label": "", "metadata": {}, "score": "73.14429"}
{"text": "It is therefore one object of the invention to provide a classification system capable of automatically classifying documents .In one aspect of the invention a method for classifying documents comprises the steps of : . defining a plurality of classes ; . identifying source documents of each of said plurality of classes ; . generating a classification theme for each of said classes ; . entering an unclassified document into the system ; . generating an unclassified document theme corresponding to said source documents ; and .", "label": "", "metadata": {}, "score": "73.48465"}
{"text": "The unclassified document theme score and the theme scores for the various classes are compared and the unclassified document is classified into the classification having the nearest theme score .One advantage of the invention is that preclassified documents may be reclassified into various classes or subclasses automatically .", "label": "", "metadata": {}, "score": "73.58341"}
{"text": "The unclassified document theme score and the theme scores for the various classes are compared and the unclassified document is classified into the classification having the nearest theme score .A method for classifying a document using a classification system comprising the steps of : . defining a plurality of classes ; . generating a classification theme score for each of said classes from the source documents for each of the plurality of classes ; . entering an unclassified document into the system ; . generating an unclassified document theme score corresponding to said unclassified document ; . classifying the unclassified document into one of said plurality of classes when the unclassified document theme score is substantially equal to the classification theme score ; . reclassifying a plurality of classes into a plurality of new classes by : . identifying source documents for each of said plurality of new classes ; . generating a respective plurality of new class theme scores for each of said plurality of new classes ; .", "label": "", "metadata": {}, "score": "73.6139"}
{"text": "Following the recommended practices of biomedical corpus design by Cohen et al .[ 24 ] as far as practical , we constructed a representative , balanced CRA corpus of 1297 MEDLINE abstracts from a set of journals typically used for CRA .", "label": "", "metadata": {}, "score": "73.8434"}
{"text": "Document storage memory 14 may be comprised of various types of storage including a hard disk drive or plurality of hard disk drives coupled together .Document storage memory 14 should be capable of storing a number of documents and capable of storing further documents as documents are classified .", "label": "", "metadata": {}, "score": "74.09167"}
{"text": "AMIA Annual Symposium 2008 .Ongenaert M , Van Neste L , De Meyer T , Menschaert G , Bekaert S , Van Criekinge W : PubMeth : a cancer methylation database combining text - mining and expert annotation .Nucleic Acids Research 2008 , 36 : D842 - 846 .", "label": "", "metadata": {}, "score": "74.276184"}
{"text": "Thus , in terms of mutagenic efficiency , stereochemical configurations of EB and DEB are not likely to play a significant role in the mutagenicity and carcinogenicity of BD .Thus , in mouse liver , the trihalomethanes administered by gavage enhanced cell proliferation and decreased the methylation of the c - myc gene , consistent with their carcinogenic activity .", "label": "", "metadata": {}, "score": "74.40285"}
{"text": "Yannis E. Ioannidis primarily discuss the core problems in query optimization and their solutions , and only touch upon the wealth of results that exist beyond that .Prasan Roy et.al demonstrates that multi - query optimization using heuristics is practical , and provides significant benefits .", "label": "", "metadata": {}, "score": "74.412"}
{"text": "The number of training and testing examples in these 10 categories are shown in .FIG .11 .For each category in .FIG .11 the numbers show the positive training and testing examples and the remaining extracted stories from the training and testing set are used as negative examples .", "label": "", "metadata": {}, "score": "74.70032"}
{"text": "Request for Answer Clarification by mcsemorgan - ga on 28 Jul 2003 08:59 PDT .I will pay you more , if the answer is nice ! !Could you also tell me how they compare in performance(I mean how can you proof which method in which condition would be best ; we can accord this result to apply each method ) ! !", "label": "", "metadata": {}, "score": "74.734375"}
{"text": "Table 4 .Examples of cancer related genes and proteins regulated by these genes .Toxicokinetics .Toxicokinetics describes the process of uptake of chemicals by the body : the metabolism and biotransformation , and the distribution and excretion .Accurate MOA classification of some chemicals requires evidence for a certain type of toxicokinetics .", "label": "", "metadata": {}, "score": "74.84128"}
{"text": "Could you try to list them item by item ? ?Hello mcsemorgan - ga : Thanks for the clarification .I will start working on your clarification tommorow 28th July ( EST ) .I will keep you informed of the progress .", "label": "", "metadata": {}, "score": "75.43794"}
{"text": "that is red and round , which type of fruit is it most likely to be , . based on the observed data sample ?In future , classify red and round . fruit as that type of fruit . \"A difficulty arises when you have more than a few variables and . classes -- you would require an enormous number of observations .", "label": "", "metadata": {}, "score": "75.75867"}
{"text": "i . m .I .C .W . )H .C . )H .C .W . )i . m .Pr .c . i . ) log .Pr .c . i . ) w .", "label": "", "metadata": {}, "score": "75.769615"}
{"text": "The expert was invited to imagine that she had submitted a query to a TM system , the system had classified each abstract of each chemical to relevant taxonomy class(es ) , and the task is to judge whether the proposed classification is correct .", "label": "", "metadata": {}, "score": "75.79979"}
{"text": "ICICIC ' 07 : Proceedings of the Second International Conference on Innovative Computing , Informatio and Control Washington , DC , USA : IEEE Computer Society 2007 .Nelson S , Powell T , Humphreys B : The Unified Medical Language System ( UMLS )", "label": "", "metadata": {}, "score": "76.071236"}
{"text": "And this was true for all the three domains considered .INTRODUCTION As of today , the indexed web contains billions of web pages and continues to grow at a rapid pace .With such a large web space , exhaustive crawling has almost become impossible with traditional general purpose web crawlers .", "label": "", "metadata": {}, "score": "76.39865"}
{"text": "We ran experiments on three different data sets .The biggest data set is the reuters-21578 collection .This data set consists of newswire articles on a wide range of topics .Some of the topics include earnings , money / foreign currency exchange , grain , trade , etc .", "label": "", "metadata": {}, "score": "76.53392"}
{"text": "Environmental studies can provide important evidence for CRA , but it is unclear what kind of environmental studies should be included in CRA ( e.g. measurements of exposure levels in specific cities , areas , or ethnic / occupational groups ) .", "label": "", "metadata": {}, "score": "76.55104"}
{"text": "Naive Bayes classification gets around this problem by not requiring .that you have lots of observations for each possible combination of .the variables .Rather , the variables are assumed to be independent of . one another and , therefore the probability that a fruit that is red , . round , firm , 3 \" in diameter , etc . will be an apple can be calculated .", "label": "", "metadata": {}, "score": "76.70797"}
{"text": "CRA is a task which involves examining existing published evidence to determine the relationship between exposure to a chemical and the likelihood of developing cancer from that exposure [ 17 ] .It has become increasingly important over the past years as the link between environmental chemicals and cancer has become evident and tight legislations governing chemical safety have been introduced worldwide .", "label": "", "metadata": {}, "score": "76.99843"}
{"text": "kiew.cs.uni-dortmund .de:8001/mlnet/ instances/81d91eaa - da14013dc6 .Sorry !I had an emergency situation and could n't reply .Please refer .to the reference papers and you can have a very good idea of the . advantages and disadvantages related to SVM .", "label": "", "metadata": {}, "score": "76.99979"}
{"text": "In this paper we discuss a new approach to focus crawling based on named entities for narrow domains .We have conducted experiments in focused web crawling in three narrow domains : baseball , football and American politics .A classifier based on the centroid algorithm is used to guide the crawler which is trained on web pages collected manually from online news articles for each domain .", "label": "", "metadata": {}, "score": "77.670074"}
{"text": "Performed manually by experts in health related institutions , CRA is a demanding exercise which requires combining scientific knowledge with elaborate literature review .It involves searching , locating and interpreting relevant information in repositories of scientific peer reviewed journal articles - a process which can be extremely time - consuming because the data required for CRA of just a single carcinogen may be scattered across thousands of articles .", "label": "", "metadata": {}, "score": "78.15396"}
{"text": "Panhellenic Conference on Informatics , of Lecture Notes in Computer Science ( Edited by : Bozanis P , Houstis EN ) .Springer 2005 , 3746 : 382 - 392 .Corbett P , Batchelor C , Teufel S : Annotation of Chemical Named Entities .", "label": "", "metadata": {}, "score": "78.69794"}
{"text": "For example , the most recent EPA CRA guideline was published in 2005 and the data requirements have not been updated since then .The same guidelines emphasise , however , the importance of investigating all the published scientific data on the chemical in question which might be of potential relevance for CRA .", "label": "", "metadata": {}, "score": "78.815704"}
{"text": "In the two patent data sets the classes in each data set are very similar which makes it very hard to achieve high performance scores .However , if classes are distinct enough it is easy to get very high accuracy .", "label": "", "metadata": {}, "score": "78.98151"}
{"text": "But as web crawling is an offline process , the tradeoff between improved harvest ratio to efficiency is worth at the end .Future Work This research brings up several themes for future research as well .We recognize NEs in web pages , but there is a possibility that some of them are unrelated to the crawling domain .", "label": "", "metadata": {}, "score": "79.53423"}
{"text": "\u00a9 Korhonen et al .2009 .This article is published under license to BioMed Central Ltd.IJRET : International Journal of Research in Engineering and Technology is an international peer reviewed , online journal published by eSAT Publishing House for the enhancement of research in various disciplines of Engineering and Technology .", "label": "", "metadata": {}, "score": "79.54875"}
{"text": "Here , a Poisson mixture is a probability density function that is expressed as a sum of infinite Poisson distributions with a certain weighting function .A reasonable choice of the weighting function is the conjugate prior of the Poisson , that is , the gamma distribution , because it greatly simplifies mathematical treatments [ 6 ] , and this choice leads to the joint gamma - Poisson distribution .", "label": "", "metadata": {}, "score": "79.611145"}
{"text": "View Article PubMed .Lee CH , Chiu HC , Yang HC : A Platform of Biomedical Literature Mining for Categorization of Cancer Related Abstracts .ICICIC ' 07 : Proceedings of the Second International Conference on Innovative Computing , Informatio and Control Washington , DC , USA : IEEE Computer Society 2007 .", "label": "", "metadata": {}, "score": "79.696045"}
{"text": "i need your answer very urgent .Request for Answer Clarification by mcsemorgan - ga on 23 Aug 2003 12:41 PDT .SVM ADVANTAGES Reduced computational complexity due to discrete kernel function Faster training times Good classification accuracy , Fast to classify new instances DISSADVANTAGES There is currently no on - line learning version of the SVM .", "label": "", "metadata": {}, "score": "80.25238"}
{"text": "Carcinogenic activity .The first sub - taxonomy , shown in Figure 3 , specifies the types of data which provide evidence for carcinogenic activity .Five main classes are included : \" human study / epidemiology \" , \" animal study \" , \" cell experiments \" , \" study on micro - organisms \" , and \" subcellular systems \" .", "label": "", "metadata": {}, "score": "80.2654"}
{"text": "TheManWithNoName Mar 19 ' 13 at 20:56 .I appreciate your effort and thank you .I will have a look at the paper you included and try to make a use of it . - clancularius Mar 21 ' 13 at 8:28 . @TheManWithNoName : Great Answer !", "label": "", "metadata": {}, "score": "80.40234"}
{"text": "Thanks for your comments mcsemorgan - ga .I wish you a very good luck in the future .I will also like to thank ragingacadam - ga for pointing out to his answer .I hope it helps mcsemorgan - ga .", "label": "", "metadata": {}, "score": "80.81534"}
{"text": "Acknowledgements .The work reported in this paper was funded by the Royal Society ( UK ) , the Medical Research Council ( G0601766 ) ( UK ) , and the Swedish Council for Working Life and Social Research .LS was supported by a British Telecom sponsored Dorothy Hodgkin Postgraduate Award .", "label": "", "metadata": {}, "score": "80.81743"}
{"text": "Could you give me more answers that I wanted before tuesday ? ?I need it very urgent , otherwise I have to looking for other peopele .Hello mcsemorgan - ga : My research revealed some additional papers that you may like .", "label": "", "metadata": {}, "score": "80.99023"}
{"text": "Some contain conflicting ( both positive and negative ) evidence .For example , effects on cell death ( relevant for CRA ) may occur in the same abstract with plants ( irrelevant for CRA ) .Others include evidence whose association with cancer development is currently unclear or evidence which focuses on studies on single chemicals in complex mixtures such as tobacco smoke .", "label": "", "metadata": {}, "score": "81.074135"}
{"text": "Collectively , our results indicated that chloroform directly and concentration - dependently provoked muscle contraction in swine tracheal smooth muscle .These results demonstrate that BaP / DMBA causes a loss of bone mass and bone strength , possibly through an increase in bone turnover .", "label": "", "metadata": {}, "score": "81.30395"}
{"text": "the performance scores of other methods were .normalized using the score of kNN .This provides a common basis for a . global observation on methods whose results . are only available on individual collections .Widrow - Hoff , k - nearest .", "label": "", "metadata": {}, "score": "82.04538"}
{"text": "However , several problems are still open .Further , the size of the samples obviously affects the results of the estimation \u00a9 2013 ACEEE DOI : 03 .LSCS.2013.3 .Subject : categorization Category : Computers Asked by : mcsemorgan - ga List Price : $ 100.00 .", "label": "", "metadata": {}, "score": "82.2571"}
{"text": "- stefan Dec 2 ' 12 at 16:30 .4 Answers 4 .As Bee points out and you are already aware , the use of SVM as a classifier is wasted if you have already lost the information in the stages prior to classification .", "label": "", "metadata": {}, "score": "82.33069"}
{"text": "Based on the Lewis split we extracted 10802 stories in which 7780 are in the training set and 3022 are in the testing set .The number of stories in each category varied widely .For example the \" earnings \" category contains 3965 documents while many other categories contain only one document .", "label": "", "metadata": {}, "score": "82.38325"}
{"text": "Companies , and in particular , companies in technical fields classify various information to various classifications for the company archives and for other purposes .One such other purpose is for patent searching .Companies may obtain various patents to store into a company archive .", "label": "", "metadata": {}, "score": "82.441475"}
{"text": "He is working as a Senior Lecturer at the University of Colombo School of Computing ( UCSC ) , University of Colombo .His research interest includes Multimedia Information Management , Multimedia Databases , Intelligent Human - Web Interaction , Web Information Management and Retrieval , and Web Search Optimization .", "label": "", "metadata": {}, "score": "82.57302"}
{"text": "Request for Answer Clarification by mcsemorgan - ga on 27 Jul 2003 14:42 PDT .Thanks for your research , they are quite detailed .But could you try to answer my question ? ?Actually , I have read many references that you researched before .", "label": "", "metadata": {}, "score": "83.3808"}
{"text": "To obtain training and testing data we split the two classes of 50 patents in two ways .One is randomly selecting 40 patents from each class as training documents and using the remaining 10 patents in each class as testing documents .", "label": "", "metadata": {}, "score": "83.53982"}
{"text": "Cancer Risk Assessment Taxonomy .CRA corpus .As PubMed is by far the most frequently used resource in CRA , we selected 15 journals available via this system which are used frequently for CRA and jointly provide a good coverage of the main types of scientific evidence relevant for the task .", "label": "", "metadata": {}, "score": "83.65892"}
{"text": "Also when the training data set gets very large kNN slows down significantly .In general , Transductive SVM takes much longer to train than inductive SVM , but the classification times of both inductive and transductive SVM are efficient .In addition both SVM and KNN are very stable with different model parameters .", "label": "", "metadata": {}, "score": "84.896805"}
{"text": "Figure 6.3 shows the variation of the harvest ratio with the number of pages crawled .Figure 6.4 shows the number of relevant pages downloaded against the total number of pages downloaded .Focused Web Crawling in American Politics Domain Finally we conducted experiments for the American politics domain .", "label": "", "metadata": {}, "score": "85.33258"}
{"text": "In this paper , we presented an extensive comparative study of the effect of named entities in focused web crawling for narrow domains .Our experiments with focused crawling for three narrow domains -- baseball , football , American politics - showed that NEs enhance the crawler accuracy in terms of the harvest ratio .", "label": "", "metadata": {}, "score": "85.559906"}
{"text": "Figure 6.5 shows the variation of harvest ratio with number of pages crawled and figure 6.6 shows the variation of relevant pages with the total number of pages crawled for all the 3 cases .Fig - 6.5 : Harvest ratio variation for American politics domain Fig - 6.6 : Variation of number of pages downloaded for American politics domain 6.4 .", "label": "", "metadata": {}, "score": "86.21514"}
{"text": "Hello again : I am sorry .Yes , I did a mistake .Instead of posting the results for SVM , I accidentely posted the results for this model .I have started doing research on SVM and will post my results anytime tonight or tommorow before afternoon .", "label": "", "metadata": {}, "score": "86.8386"}
{"text": "Helsinki 2008 .International Agency for Research on Cancer ( IARC ) : Monographs on the Evaluation of Carcinogenic Risks to Humans Lyon , France 2006 .Rud\u00e9n C : The Use and Evaluation of Primary Data in 29 Trichloroethylene Carcinogen Risk Assessments .", "label": "", "metadata": {}, "score": "88.144196"}
{"text": "Broad domain describes a topic in general while narrow domain describes a topic more specifically and detail .Often , a broad domain can be thought as a collection of narrow domains .For instance , Sports and Music can be considered as broad domains while relatively , baseball , football and Sri Lankan music can be thought as narrow domains .", "label": "", "metadata": {}, "score": "88.395996"}
{"text": "Also , each subclass may have further subclasses .Each class has a respective theme score : theme score 1 , theme score 2 and theme score 3 .Each subclass also has a respective theme score : theme score A and theme score B. The theme scores identify the theme of the class and subclass .", "label": "", "metadata": {}, "score": "88.40416"}
{"text": "I think you have work hard on it , but they are not something that I needed .I know something that I wanted are difficult to search .Hope you can still working on it , and give me the answer as soon as possible .", "label": "", "metadata": {}, "score": "88.4082"}
{"text": "BIOGRAPHIES : Sameendra Samarawickrama is currently a fourth year computer science undergraduate at University of Colombo School of Computing , Sri Lanka .His research interests include web mining , data mining , information retrieval and automatic text classification .Lakshman Jayaratne obtained his B.Sc ( Hons ) in Computer Science from the University of Colombo , Sri Lanka in 1992 .", "label": "", "metadata": {}, "score": "88.44133"}
{"text": "Since we needed a set of properly classified technical patents with engineering terms , we chose some US patents on engineering from US PTO database .To reflect the real situation where categories can be very similar and for some categories there can be very few classified patents , we chose those patents from subclasses 31 and 32 in class 706 on neural networks in particular , with 50 patents in each class .", "label": "", "metadata": {}, "score": "89.065475"}
{"text": "Then we combine NEs that are longer than one word with an underscore sign , so that during tokenization we get all the NEs as well as .For example , the recognized NE , \" New York Yankees \" is reformatted to \" New_York_Yankees \" .", "label": "", "metadata": {}, "score": "91.842285"}
{"text": "Blood .Toxicologic Pathology .International Journal of Toxicology .Risk Analysis .Cell Death and Differentiation .American Journal of Epidemiology .American Journal of Industrial Medicine .Toxicology .European Journal of Pharmacology .Appendix 4 Footnotes .Institute of Environmental Medicine at Karolinska Institutet , Swedish Chemical Inspectorate , Scientific Committee on Occupational Exposure Limits ( EU ) , Swedish Criteria Group .", "label": "", "metadata": {}, "score": "92.88565"}
{"text": "C . wheat .Pr .c . log .Pr .c .Pr .c . log .Pr .c .Pr . wheat .i .Pr .c .i . wheat . log .Pr .", "label": "", "metadata": {}, "score": "94.04905"}
{"text": "Figure 6.2 shows the number of topic relevant pages downloaded with number of pages crawled .Fig - 6.1 : Harvest ratio variation for baseball domain Fig - 6.2 : Variation of number of pages downloaded for baseball domain 6.2 .Focused Web Crawling in Football Domain Second experiment was to investigate the effect of NEs in focused crawling related to football domain .", "label": "", "metadata": {}, "score": "95.47745"}
{"text": "Two main types of MOA can be distinguished : genotoxic and non - genotoxic ( both can be further divided into various subtypes ) .Chemicals acting by a genotoxic MOA interact with DNA , while chemicals acting by a non - genotoxic MOA induce cancer without interfering directly with DNA .", "label": "", "metadata": {}, "score": "97.86874"}
{"text": "Sincerely , leader - ga .Request for Answer Clarification by mcsemorgan - ga on 17 Aug 2003 10:52 PDT .Hope you can post the answer as soon as possible , because I need the answer very urgent .Request for Answer Clarification by mcsemorgan - ga on 20 Aug 2003 03:33 PDT .", "label": "", "metadata": {}, "score": "100.64192"}
{"text": "Please read carefully the Google Answers Terms of Service .Thank you .", "label": "", "metadata": {}, "score": "103.78204"}
{"text": "Received 29 January 2013 ; Accepted 4 March 2013 .Copyright \u00a9 2013 Hiroshi Ogura et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "105.2043"}
{"text": "i . wheat .Pr . not . wheat .i .Pr .c . i . not . wheat . log .Pr .c . i . not . wheat . log . log . log . log . log . log .", "label": "", "metadata": {}, "score": "114.423004"}
