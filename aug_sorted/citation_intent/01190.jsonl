{"text": "Each occurrence of the query phrase is highlighted .We briefly describe what happens when the user clicks the \" Adjacent Entities \" link , which \" explains \" the result .We believe that when complex ranking methods like BM25 and CO are employed , the users need information about why certain results are ranked high .", "label": "", "metadata": {}, "score": "35.686806"}
{"text": "Note that this approach provides highly relevant documents even if the documents do not contain a high frequency of the input query terms q , since related phrase information was used to both identify relevant documents , and then rank these documents .", "label": "", "metadata": {}, "score": "37.439186"}
{"text": "Note that S(d , u ) represents the importance of web page d and doesnot depend on a query .On the one hand , topic - based methods may be applicable to more queries thanclick - based and term - based methods .", "label": "", "metadata": {}, "score": "37.839226"}
{"text": "3 ( b ) of the form P - P to a coarser granularity .All other entries , however , have an S word which can be replaced by its corresponding higher level semantic concept .This will result in a reduction in the size of co - occurrence index and will speed - up query processing .", "label": "", "metadata": {}, "score": "38.69007"}
{"text": "( 1 ) the frequency of occurrence in the data base of his search terms ; .( 2 ) the number of documents likely to be retrieved by his query ; .( 3 ) alternative and related terms to be the ones used in his search ; .", "label": "", "metadata": {}, "score": "39.336784"}
{"text": "These and other actions manifest a higher level of interest in the document .When another query is received from the user , the related query phrases Qr are retrieved .These related query phrases Qr are intersected with the phrases listed in the user model to determine which phrases are present in both the query and the user model .", "label": "", "metadata": {}, "score": "40.059612"}
{"text": "These latter documents are then included in the search results .This eliminates the need for the system to then separately process the posting list of the second query phrase , thereby providing faster search times .Of course , this approach may be extended to any number of phrases in a query , yielding in significant computational and timing savings .", "label": "", "metadata": {}, "score": "40.512024"}
{"text": "Ideally , this value should be derived from the occurrence and co - occurrence distributions of words in a document 's paragraphs , to prevent randomly co - occurring words from receiving high values of WPP .We did not compute such distributions for the BioCreative data , but rather used our results from other datasets used by the Active Recommendation Project , where , typically , a value of 3 dramatically reduces the chances of artificially high values of WPP .", "label": "", "metadata": {}, "score": "40.738083"}
{"text": "2 ( a ) by replacing each word ( which is not a proper noun ) by its higher level semantic concept .The index table FIG .4 ( b ) is obtained by combining the words in FIG .2 ( b ) into their corresponding higher level semantic concept and merging the respective document list entries .", "label": "", "metadata": {}, "score": "41.26506"}
{"text": "More particularly , given a document accessed by user , the related phrases that are present in this document , are included in a user model or profile .During subsequent searches , the phrases in the user model are used to filter the phrases of the search query and to weight the document scores of the retrieved documents .", "label": "", "metadata": {}, "score": "41.757618"}
{"text": "Second , due to many reasons , relevant documents may notbe included in the ranking list to the query .The na\u00a8\u0131ve method does not work insuch a situation .We need to employ more appropriate methods to learn users ' preference on web - pages from click - through data .", "label": "", "metadata": {}, "score": "42.295662"}
{"text": "If we assume that the clusters are derived from a cluster method based on a dissimilarity measure , then we can represent each cluster at some level of dissimilarity by a graph ( see Figure 5.2 ) .Here A and B are two clusters .", "label": "", "metadata": {}, "score": "42.655697"}
{"text": "Finally , in accordance with the present invention , all of the tables except FIG .3 ( b ) are required .On the other hand , the rudimentary query expansion scheme will need tables in FIGS . 2 and 3 .", "label": "", "metadata": {}, "score": "42.8299"}
{"text": "It has been found that 0.85 is a good value for d [ 7 ] .The CO ranking algorithm is an extension of PageRank to account for the various entity types and also create a query - specific and not global ranking of the entities .", "label": "", "metadata": {}, "score": "42.857018"}
{"text": "Thus , the majority of clicks with respect tothe query should be on a single URL in the click - through data .If aquery is navigational and also exists in the anchor texts in a web collection , then themajority of the anchor texts should be linked to the same URL .", "label": "", "metadata": {}, "score": "42.862377"}
{"text": "In tf , words that occur multiple times in a document are considered salient .In idf , words that appear in many documents are considered \" common denominators \" and do not especially indicate document content .In dl , when collections have documents of varying lengths , longer documents tend to score higher since they contain more words and word repetitions .", "label": "", "metadata": {}, "score": "43.338654"}
{"text": "Bergsma and Wang [ 2007 ] proposed to view the query segmentation task as aproblem of making a segmentation decision at each adjacent word pair .Features like whether the left word is \" the \" and part of speech of theleft word are used .", "label": "", "metadata": {}, "score": "43.450623"}
{"text": "For example , this appeared to be true for query # 3 ( data not shown ) .In contrast , the presence of the query phrase in multiple neighboring records could lead to a higher CO ranking than a query phrase found only in a result record .", "label": "", "metadata": {}, "score": "43.54318"}
{"text": "Ranking .a )Ranking Documents Based on Contained Phrases .The search system 120 provides a ranking stage 604 in which the documents in the search results are ranked , using the phrase information in each document 's related phrase bit vector , and the cluster bit vector for the query phrases .", "label": "", "metadata": {}, "score": "43.639355"}
{"text": "In those cases , the related phrase bit vectors can be directly accessed , and then used next to retrieve corresponding documents .This process is more fully described as follows .Given any two query phrases Q 1 and Q 2 , there are three possible cases of relations : . 1 ) Q 2 is a related phrase of Q 1 ; . 2 ) Q 2 is not a related phrase of Q 1 and their respective related phrases Qr 1 and Qr 2 do not intersect ( i.e. , no common related phrases ) ; and .", "label": "", "metadata": {}, "score": "43.66147"}
{"text": "a)(v ) removing any redundant ones of the syntactically related words and higher granularity concepts from the expanded query ; .b ) executing the logically expanded query to retrieve documents associated , through the index , with the corresponding ones of the higher granularity concepts ; and .", "label": "", "metadata": {}, "score": "43.669273"}
{"text": "b)(ii ) adding syntactically related words for each of the corresponding ones of the higher granularity concepts ; .b)(iii ) adding syntactically related words for each of the words in the query failing to meet the predetermined criterion ; .b)(iv ) replacing ones of the syntactically related words meeting the predetermined criterion with associated ones of the higher granularity concepts ; and .", "label": "", "metadata": {}, "score": "43.72213"}
{"text": "The ranking scheme is based on the following two principles : .Based on the above ranking scheme using a query with two keyword terms , a two - dimensional ranking graph can be generated for the documents for a query with two words as shown in FIG .", "label": "", "metadata": {}, "score": "43.872414"}
{"text": "2011].The average length of search queries is about 1.66 - 2.6 words , which is muchshorter than in traditional IR ( 6 - 9 words ) ( cf.,[Jansen et al .2007 ] ) .Thisobservation implies that the relevance of the top ten results is critically importantfor a web search engine .", "label": "", "metadata": {}, "score": "43.897175"}
{"text": "For a given user , the lists will be empty the first time the user provides a query .Next , a query q is received from the user .The related phrases Qr of q are retrieved , along with the phrase extensions , in the manner described above .", "label": "", "metadata": {}, "score": "44.018513"}
{"text": "As a preliminary matter , it is useful to define a user 's interests ( e.g. , a user model ) in terms of queries and documents , both of which can be represented by phrases .For an input search query , a query is represented by the query phrases Q , the related phrases of Qr , and phrase extensions Qe of the query phrases Qp .", "label": "", "metadata": {}, "score": "44.267094"}
{"text": "In this situation , words drawn from such documents and added to the query are often unrelated to the information being sought and the quality of the documents retrieved using such an expanded query is typically poor .[0008 ]In another example , some query expansion techniques extract noun groups or \" concepts \" from a set of top - ranked documents .", "label": "", "metadata": {}, "score": "44.43422"}
{"text": "No redundant data is stored and storage costs for pointers are very low .However , the data structure is extendible .Semantic groupings other than what has been presented above may also be taken into consideration .In FIG .4 , only query expansion by synonym is considered .", "label": "", "metadata": {}, "score": "44.554688"}
{"text": "2 illustrates an example of indices which are traditionally used in exact match information retrieval systems .FIG .3 illustrates an example of indices derived by grouping words into semantically similar concepts and syntactically related extensions for use in traditional information retrieval systems .", "label": "", "metadata": {}, "score": "44.658234"}
{"text": "For example , a syntactic parse results in different structures for the two ' ' victim ' ' sentences ; if matching during search included parsing and unification , these two structures would not match , thus boosting precision .Conceptual Querying :", "label": "", "metadata": {}, "score": "44.686176"}
{"text": "Next , the inlink score is determined as follow .For each inlink to URL 1 containing the anchor phrase A , the indexing system 110 scans URL 1 , and determines whether phrase A appears in the body of URL 1 .", "label": "", "metadata": {}, "score": "44.692627"}
{"text": "This technique is based on the hypothesis that a common term from the top - ranked documents will tend to co - occur with all query terms within the top - ranked documents .This hypothesis is not always true and often leads to improper query expansion .", "label": "", "metadata": {}, "score": "44.801025"}
{"text": "If the number of proper names per word is small in the table of FIG .4 ( c ) , then the query complexity in the present expansion scheme reduces by a factor of f. .Turning now to query processing , in traditional query processing , based on exact matching , the search process can be terminated as soon as it can be determined that search predicate associated with the query can not be satisfied .", "label": "", "metadata": {}, "score": "44.889275"}
{"text": "In one implementation , probabilistic correlations between query terms and document terms from the query logs 210 are pre - computed offline prior to evaluating terms of a newly submitted query 214 for expansion .When a new query comes arrives , the terms in the query ( with stop words being removed ) are extracted .", "label": "", "metadata": {}, "score": "44.90814"}
{"text": "First , the presentation system 130 ranks the sentences of the document by the number of instances of query phrases Q , related query phrases Qr , and phrase extensions Qp , thereby maintaining for each sentence of a document counts of these three aspects .", "label": "", "metadata": {}, "score": "44.98091"}
{"text": "b)(iii ) further logically expanding the query by adding syntactically related words for each of the words in the query failing to meet the predetermined criterion ; .b)(iv ) replacing ones of the syntactically related words meeting the predetermined criterion with associated ones of the higher granularity concepts ; and .", "label": "", "metadata": {}, "score": "44.982777"}
{"text": "From the related phrase bit vector , we can determine primary and secondary topics for the document d. A primary topic is indicated by a bit pair ( 1,1 ) , and a secondary topic is indicated by a bit pair ( 1,0 ) .", "label": "", "metadata": {}, "score": "45.03682"}
{"text": "Phrases are also used to cluster documents in the search results , create document descriptions , and eliminate duplicate documents from the search results , and from the index . selecting a first document and a second document from a set of documents ; . comparing , by operation of a processor adapted to manipulate data within a computer system , a document description of the first document with a document description of the second document , . wherein the document description of the first document comprises a selected subset of sentences of the first document , the sentences being selected and ordered in the document description as a function of a number of related phrases in the selected sentences , . wherein the document description of the second document comprises a selected subset of sentences of the second document , the sentences being selected and ordered in the document description as a function of a number of related phrases in the selected sentences , . responsive to the document description of the first document matching the document description of the second document , identifying the first document and the second document as duplicate documents in the set of documents .", "label": "", "metadata": {}, "score": "45.26367"}
{"text": "c)(iv ) replacing ones of the syntactically related words meeting the predetermined criterion with associated ones of the higher granularity concepts ; and .c)(v ) removing any redundant ones of the syntactically related words and higher granularity concepts from the expanded query .", "label": "", "metadata": {}, "score": "45.34018"}
{"text": "FIG .8 a ) , then a different step is taken to determine the inlink score .In this case , the indexing system 110 creates a related phrase bit vector for URL 1 for phrase A ( as if phrase A was present in URL 1 ) and indicating which of the related phrases of phrase A appear in URL 1 .", "label": "", "metadata": {}, "score": "45.46549"}
{"text": "For purposes of explanation , a current document d being processed will be referred to as URL 0 , and the target document of an outlink on document d will be referred to as URL 1 .That is , each link in the document collection has a pair of scores , an outlink score and an inlink score .", "label": "", "metadata": {}, "score": "45.58828"}
{"text": "Again , this process is repeated for the documents in the search results ( either on demand or aforehand ) .For each such document then the resulting document description comprises the N top ranked sentences from the document .Duplicate Document Detection and Elimination .", "label": "", "metadata": {}, "score": "45.62222"}
{"text": "Popular scoring functions that make use of tf\u00d7idf information include the Vector Space Model [ 21 ] and the Okapi BM25 metric [ 19].Many others are possible [ 24].For each term that occurs in T ( the set of which forms the vocabulary ) , an inverted index stores a list of documents that contain that term .", "label": "", "metadata": {}, "score": "45.82029"}
{"text": "The term - based methods may not be applicable toa query and a user , if none of the terms in the query occurs in the user 's searchhistory .In such cases , we may consider employing topic - based methods .", "label": "", "metadata": {}, "score": "45.8292"}
{"text": "We present two new algorithms for ranking documents against a query without making any assumptions on the structure of the underlying text .We build on existing theoretical techniques , which we have implemented and compared empirically with new approaches introduced in this pa- per .", "label": "", "metadata": {}, "score": "45.92208"}
{"text": "5(b ) gives pseudocode for the final method .To derive a top - k listing algorithm , we apply Obs . 1 in rounds .As the al- gorithm proceeds , we will accumulate candidates for the top - k documents in a min - heap of at most k pairs of the form ( d , tfq , d ) , keyed on tfq , d .", "label": "", "metadata": {}, "score": "46.138206"}
{"text": "The intersection of the document lists from the two rows forms the answer to the query .Although this approach is feasible , it results in introducing significant query processing overhead .In particular , instead of two lookups of the index table in FIG .", "label": "", "metadata": {}, "score": "46.15255"}
{"text": "In fact , the new ranked document search algo- rithms are three times faster than a highly tuned inverted file implementation that assumes terms to be English words .Our approach is to build data structures that allow us to efficiently calculate the frequency of a query pattern in a document ( tf ) on the fly , unlike traditional inverted indexes that stores precomputed tf values for specific query patterns ( usually words ) .", "label": "", "metadata": {}, "score": "46.16812"}
{"text": "For one term queries , the value of idf is simply a constant multiplier to the final ranking score , and so not useful for discriminating documents .If these data structures are to be used for bag - of - strings search , then the idf factor may become important , and can be easily extracted using method WT , which is still faster than Zet - io in our experiments .", "label": "", "metadata": {}, "score": "46.245605"}
{"text": "Take the example where a user issues a query with two keywords and requests that the top 50 results be retrieved .Referring to FIG .10 , the query processor can initially produce the results in class 0 .If the number of results is greater than 50 , the query processor can stop without performing the query expansion task .", "label": "", "metadata": {}, "score": "46.357822"}
{"text": "FIG .3 ( b ) illustrates the index that captures this information .By using , the traditional IR indices of FIG .2 in conjunction with the auxiliary indices of FIG .3 , a rudimentary query expansion scheme can be supported in an IR system .", "label": "", "metadata": {}, "score": "46.37805"}
{"text": "We present two new algorithms for ranking documents against a query without making any assumptions on the structure of the underlying text .We build on existing theoretical techniques , which we have implemented and compared empirically with new approaches introduced in this paper .", "label": "", "metadata": {}, "score": "46.45311"}
{"text": "S(p ) : Number of all instances of the possible phrase ; and .M(p ) : Number of interesting instances of the possible phrase .These ( and other ) distinguishing appearances are indicated by various HTML markup language tags and grammatical markers .", "label": "", "metadata": {}, "score": "46.508774"}
{"text": "b ) a user interface for providing a query to be applied to the database of documents ; and . c)(i ) wherein the higher granularity concepts are higher granularity semantic concepts , and wherein logically expanding the query further comprises ; .", "label": "", "metadata": {}, "score": "46.557846"}
{"text": "Nevertheless , we did not identify any particular qualities in the dataset that would suggest such a strong limitation .Applying the CO ranking paradigm to other domains or datasets has several challenges .First , the appropriate entities must be identified .", "label": "", "metadata": {}, "score": "46.561096"}
{"text": "In some cases , a selected portion of a text of a document is presented to provide the user with a glimpse of the document 's content .Direct \" Boolean \" matching of query terms has well known limitations , and in particular does not identify documents that do not have the query terms , but have related words .", "label": "", "metadata": {}, "score": "46.597046"}
{"text": "Removing these weak good phrases results in a very robust likely of good phrases .To identify good phrases , a predictive measure is used which expresses the increased likelihood of one phrase appearing in a document given the presence of another phrase .", "label": "", "metadata": {}, "score": "46.653397"}
{"text": "In order to deal with the problem of word mismatch , a query processing scheme needs to expand the query words with relevant words .As a result , an additional task for ranking the documents by their relevance to the original query words may be performed .", "label": "", "metadata": {}, "score": "46.669342"}
{"text": "The remaining documents can then be scored .This means further that it is unnecessary for the search system 120 to process the posting lists of Q 2 to see which documents it is present in as well , thereby saving compute time .", "label": "", "metadata": {}, "score": "46.767273"}
{"text": "The reason may be that the purpose of PageRank on the Web is to create a global ranking , whereas in CO we create a query - specific ranking , and hence the authority should not flow far from the entities that contain the actual query terms .", "label": "", "metadata": {}, "score": "46.84155"}
{"text": "[0007 ]In another example , some query expansion techniques automatically assume that the top - ranked document(s ) that are returned to the user in response to a query are relevant .The original queries from the user are then expanded with term(s ) extracted from such top - ranked document(s ) .", "label": "", "metadata": {}, "score": "46.851826"}
{"text": "The ranking scheme requires information on which words in the documents match the query and the word frequency in the documents .Now the lookup costs associated with processing a query under the two schemes will be analyzed .Note that the basic difference in the processing cost will arise due to two factors : .", "label": "", "metadata": {}, "score": "46.877075"}
{"text": "The notion of conceptual querying for English is not new .The FERRET system ( Mauldin , 1991b ) presented the idea of matching on the conceptual structure of a text , rather than keywords , to improve precision and recall .", "label": "", "metadata": {}, "score": "46.943"}
{"text": "While these approaches have different theoretical bases , their similarity scoring functions all employ some variant of tf\u00d7idf information . are the weight of the query term t in document d and query q , respectively .Using a tf\u00d7idf metric ensures that a high term frequency in an individual document increases the similarity contribution , while a high frequency across all documents reduces its contribution .", "label": "", "metadata": {}, "score": "46.99186"}
{"text": "A system of querying a database of documents , the database including an index of reduced index size of the documents , higher granularity concepts and associations there between , the higher granularity concepts corresponding to words of original granularity contained in the documents , the system comprising : . a ) a user interface for providing a query to be applied to the database of documents ; and .", "label": "", "metadata": {}, "score": "47.014843"}
{"text": "The document IDs represent each document selected from a list generated by the search engine in response to searching for information relevant to corresponding ones of the query terms . times .f ik ( q ) ( w i ( q ) , D k ) f ( q ) ( w i ( q ) ) ) , wherein w.sub.j.sup .", "label": "", "metadata": {}, "score": "47.027206"}
{"text": "2 ) are represented in FIG .3 via directional arrows .In particular , such paths map new query terms 302 via previous query session terms 306 and selected documents 308 to selected document terms 216 .If there is at least one path between a newly submitted term and one document term , the query expansion module 202 establishes a probabilistic link between the two terms .", "label": "", "metadata": {}, "score": "47.04531"}
{"text": "Turning now to the ranking scheme of the present invention , in the query processing phase , word representations at a coarser granularity are used for filtering out unrelated documents .However , the candidate documents have the same ranking since they all satisfy both conditions , car and dealer at a coarser granularity level .", "label": "", "metadata": {}, "score": "47.062447"}
{"text": "Then the number of words in Q under basic query expansion ( BQ ) is the total expansion that occurs in steps 1 , 2 , and 3 : . where the first term arises since each of the m dictionary words is replaced by f semantically similar words .", "label": "", "metadata": {}, "score": "47.15344"}
{"text": "This may be accomplished by check - box selection , enumeration , or otherwise indicating that particular ones of the documents in the list are more relevant that others .[ 0006 ] If the user volunteers and manually ranks the documents in the list , subsequent queries submitted to the search engine are then expanded with term(s ) extracted from the documents that the user specifically marked as being relevant .", "label": "", "metadata": {}, "score": "47.21644"}
{"text": "N , April 2013 .16 \u00b7 2.4 Query SegmentationA query q can be viewed as a sequence of words ( w1 , w2 , \u00b7 \u00b7 \u00b7 , wk ) .A segmentationof query q is a sequence of phrases that can compose the query .", "label": "", "metadata": {}, "score": "47.222908"}
{"text": "For each of these related phrases , the presentation system 130 ranks the sentences of the document according to the frequency of occurrence of each of these phrases , and then selects the top N ( e.g. , 5 to 10 ) ranking sentences .", "label": "", "metadata": {}, "score": "47.22573"}
{"text": "The documents or links to them are then output in decreasing order of their IR score .Traditional IR ranking methods , like Okapi BM25 [ 2 ] , ignore the associations among entities and instead view each entity as an individual , disconnected document .", "label": "", "metadata": {}, "score": "47.348213"}
{"text": "Depending on the implementation , either of these components can be the primary sort key , and the other can be the secondary sort key .The sorted results are then presented to the user .Sorting the documents on the outbound score component makes documents that have many related phrases to the query as anchor hits , rank most highly , thus representing these documents as \" expert \" documents .", "label": "", "metadata": {}, "score": "47.51348"}
{"text": "2 demonstrates that this is more than recouped whenever k is small , relative to the total number of documents containing q. Table 2 shows that the average docc is well above 10 for all pattern lengths in the current experimental setup .", "label": "", "metadata": {}, "score": "47.621704"}
{"text": "a)(ii ) further logically expanding the query by adding syntactically related words for each of the corresponding ones of the higher granularity concepts ; .a)(iii ) further logically expanding the query by adding syntactically related words for each of the words in the query failing to meet the predetermined criterion ; .", "label": "", "metadata": {}, "score": "47.6254"}
{"text": "Because of the lexicographic ordering , all the suffixes starting with a given substring t of T form a range A[sp .Self - indexes [ 13 ] offer the same functionality as a suffix array but are heavily compressed .More formally , they can ( 1 ) extract any text substring T [ i .. Wavelet Trees .", "label": "", "metadata": {}, "score": "47.688545"}
{"text": "For each keyword query , the top 5 results from each algorithm ( BM25 , CO085 , CO030 , and CO085BM25 ) were computed and merged to a single list of results for that query .The information about results and the corresponding algorithms was hidden from the users .", "label": "", "metadata": {}, "score": "47.707127"}
{"text": "The initial query words can then be used to rank the documents in the answer set on the basis of exact , semantic and syntactic matches and also to perform progressive query processing .A method of querying a database of documents , the database including a preliminary index of the documents , words contained in the documents and associations therebetween , the words in the preliminary index being of an original granularity , the method comprising the steps of : . a ) replacing the words in the preliminary index with corresponding higher granularity concepts , resulting in a coarser granularity index of reduced index size ; . b)(i ) wherein the higher granularity concepts are higher granularity semantic concepts , .", "label": "", "metadata": {}, "score": "47.79631"}
{"text": "In the clusters A and B illustrated , there are pointers to the candidates .As one would expect in some cases the representative is not unique .For example , in cluster B we have two candidates .To deal with this , one either makes an arbitrary choice or one maintains a list of cluster representatives for that cluster .", "label": "", "metadata": {}, "score": "47.947533"}
{"text": "This high threshold is used to identify the co - occurrences of good phrases that are well beyond the statistically expected rates .Statistically , it means that phrases g j and g k co - occur 100 times more than the expected co - occurrence rate .", "label": "", "metadata": {}, "score": "48.042484"}
{"text": "These target language segments are indexed in the chart based on the positions of the corresponding source language segments .Thus the chart contains multiple , possibly overlapping , alternative translations .Since the scores produced by the engines are estimates of variable accuracy , we use statistical language modelling techniques adapted from speech recognition research to select the best set of outputs that completely account for the source language input ( Brown and Frederking 95 ) .", "label": "", "metadata": {}, "score": "48.055443"}
{"text": "As a result the size of this table remains comparable to the table in FIG .2 ( b ) .Note that the tables in FIGS .4 ( a ) and ( b ) are the two tables of FIGS . 2 ( a ) and ( b ) , respectively , at a higher level of granularity .", "label": "", "metadata": {}, "score": "48.0851"}
{"text": "Most IR formulas combine tf , idf , and dl , to assign a unique score to each document given a query .Okapi weighting [ 4 ] and pivoted normalization weighting [ 5 ] are widely used weighting methods .Many IR researchers currently use a variant of these two weightings .", "label": "", "metadata": {}, "score": "48.2501"}
{"text": "[2005 ] examined individual users ' implicitfeedback in some click - through data .In a ranked list of webpages d1 , . . ., dn withrespect to a query q , let C be the set of clicked webpages .", "label": "", "metadata": {}, "score": "48.29458"}
{"text": "We see this work as an important first step toward practical ranked retrieval for large general - text collections , and an extension of current indexing methods beyond traditional algorithms that assume a lexicon of terms a priori .2 Basic Concepts Relevance Ranking .", "label": "", "metadata": {}, "score": "48.315845"}
{"text": "For example , if the user specifies that keyword 1 is more important than keyword 2 , a horizontal query processing order within classes can be derived , as shown in FIG .11 .Then , in the example , the query processor would produce the results in slot ( 3,2 ) first .", "label": "", "metadata": {}, "score": "48.344276"}
{"text": "In a second embodiment , the search system 120 scores each document in the result set according which related phrases of the query phrase Q it contains .This is done as follows : .Given each query phrase Q , there will be some number N of related phrases Qr to the query phrase , as identified during the phrase identification process .", "label": "", "metadata": {}, "score": "48.394897"}
{"text": "Next , these counts themselves are used as weights are also used to multiply the related phrases for each document that is being scored .This approach has the benefit of allowing documents that do not have the query phrases as related phrases to still score appropriately .", "label": "", "metadata": {}, "score": "48.422054"}
{"text": "Relevance weighting of search terms .JASIST , 27:129 - 146 , 1976 .S. E. Robertson , S. Walker , S. Jones , M. Hancock - Beaulieu , and M. Gatford .Okapi at TREC-3 .In D. K. Harman , editor , Proc . 3rd TREC , 1994 .", "label": "", "metadata": {}, "score": "48.482998"}
{"text": "However , the focus in the past has been to evaluate the improvements in retrieval measures , i.e. , precision and recall , as a result of query expansion .Another research focus has been in the direction of building dictionaries so as to identify a set of similar terms for a given query word .", "label": "", "metadata": {}, "score": "48.523987"}
{"text": "Given these parameters , the size of table in FIG .2 ( a ) is : .Similarly , the size of the table in FIG .2 ( b ) is given as : .Each row in this table needs , on average , d pointers for the document identifiers in the document list and one pointer for the word itself .", "label": "", "metadata": {}, "score": "48.581795"}
{"text": "That is , instead of expanding the query word list physically by including in the list semantically similar and syntactically related words , the query is expanded conceptually by replacing the query words by their corresponding higher level semantic concept and syntactic relationship ( e.g. co - occurrence ) .", "label": "", "metadata": {}, "score": "48.589447"}
{"text": "2 ( a ) .On the other hand the size of the table in FIG .4 ( b ) is : .The number of dictionary word entries reduce by a factor of f due to the words collapsing into semantic concept .", "label": "", "metadata": {}, "score": "48.732754"}
{"text": "If a user asks a query q and clicks a webpage p in the result list , then it is likely that p is relevant to q in one way or another .Consequently , q canbe used as an annotation of page", "label": "", "metadata": {}, "score": "48.7557"}
{"text": "This merge mechanism is illustrated in FIGS .5 ( a ) and 5 ( b ) .Entries in S - S form can be merged in two ways : .Simple merge : 1-to - many / many - to-1 types of merge as shown in FIGS .", "label": "", "metadata": {}, "score": "48.78823"}
{"text": "This approach essentially requires that a document have the query phrases that are included in the user model in order to be highly ranked .As an alternative embodiment , which does not impose the foregoing tight constraint , the mask bit vector can be cast into array , so that each bit is used to weight the cluster counts for the related phrases in the user model .", "label": "", "metadata": {}, "score": "48.80516"}
{"text": "Thus , the search engine has no idea whether or not the user considered one document to be more relevant than another .This means that the search engine has no indication of any term that can be considered more relevant than another to a particular query .", "label": "", "metadata": {}, "score": "48.84365"}
{"text": "These sets of terms together , with each term weighted by TFIDF to represent its significance , form the input items for subsequent processing .We employ the GOC term categorization method to predict GO annotations ( up to the provided limit of n annotations in a specific branch of the GO ) .", "label": "", "metadata": {}, "score": "48.86683"}
{"text": "This term categorization draws on lexical overlaps with the terms in GO node labels and terms additionally identified as related to those nodes .The system also incorporates Natural Language Processing ( NLP ) components such as a morphological normalizer , a named entity recognizer , and a statistical term frequency analyzer .", "label": "", "metadata": {}, "score": "48.875458"}
{"text": "calculated to determine if there is a document number of interest in the left and right child .Again , this approach produces the document numbers in increasing docu- ment number order .These can obviously be post - processed to extract the k documents with the highest tfq , dvalues by sorting the docc values .", "label": "", "metadata": {}, "score": "48.927284"}
{"text": "V , No .N , April 2013 .Theanchor texts of web pages can be utilized as external tags to pages .The HTMLformatting information of web pages is useful for identifying titles as well as keyphrases of pages .Furthermore , the link graph of the web pages can be used tojudge page importance by applying the PageRank or HITS algorithms .", "label": "", "metadata": {}, "score": "49.021782"}
{"text": "As a further refinement , the search system 120 can cull certain documents from the result set .In some cases documents may be about many different topics ; this is particularly the case for longer documents .In many cases , users prefer documents that are strongly on point with respect to a single topic expressed in the query over documents that are relevant to many different topics .", "label": "", "metadata": {}, "score": "49.059708"}
{"text": "One of the most prominent instantiations of the function is as follows .Given a query Q containing keywords q 1 , ... , q n , the BM25 score of a document D is : . where tf ( q i ) is q i 's term frequency in the document D , dl is the length of the document D in words , and avdl is the average document length in the text collection from which documents are drawn . idf ( q i ) is the idf weight of the query term q i .", "label": "", "metadata": {}, "score": "49.110847"}
{"text": "The choice of entities is critical , given that it determines the authority flow and the ranking .Also , CO parameters must be calibrated to fit the application needs .In our past work on authority flow we have proposed the ObjectRank ranking paradigm for bibliographic data [ 12 , 15 ] .", "label": "", "metadata": {}, "score": "49.123882"}
{"text": "This user model is intersected with a list of phrases related to the query phrases , to identify phrases common to both groups .The common set is then ordered according to the related phrase information .The resulting set of related phrases is then used to rank the sentences of a document according to the number of instances of these related phrases present in each document .", "label": "", "metadata": {}, "score": "49.182575"}
{"text": "A navigational search is to reach a particular site , an informational searchis to acquire information assumed to be present on one or more web pages , anda transactional search is to perform some web - mediated activity .Then , given a query , is it possible to identifyits dominating search goal ?", "label": "", "metadata": {}, "score": "49.183178"}
{"text": "Supporting web - query expansion efficiently using multi - granularity indexing and query processing US 6480843 B2 .Abstract .A method and apparatus for efficient query expansion using reduced size indices and for progressive query processing .Queries are expanded conceptually , using semantically similar and syntactically related words to those specified by the user in the query to reduce the chances of missing relevant documents .", "label": "", "metadata": {}, "score": "49.208797"}
{"text": "Also , a thesaurus like facility such as an on - line dictionary is needed to expand the query terms to their semantically similar counterparts .These observations have led to the development , in accordance with the present invention , of a more efficient scheme to support query expansion in querying document collections .", "label": "", "metadata": {}, "score": "49.291157"}
{"text": "The result is that clusters can be characterized \" local \" to each good phrase , and some clusters will then overlap by having one or more common related phrases .For a given good phrase g j then the ordering of the related phrases by information gain provides a taxonomy for naming the clusters of the phrase : the cluster name is the name of the related phrase in the cluster having the highest information gam .", "label": "", "metadata": {}, "score": "49.33165"}
{"text": "The indexing of documents by phrases and use of the clustering information provides yet another advantage of the indexing system 110 , which is the ability to determine the topics that a document is about based on the related phrase information .", "label": "", "metadata": {}, "score": "49.335384"}
{"text": "Impor - tant web pages should be ranked high in the answer list of web pages to a query .Traditionally , the importance of web pages is calculated by link analysis .A linkfrom one page p1 to another page p2 is regarded as an endorsement of p2 fromp1 .", "label": "", "metadata": {}, "score": "49.40254"}
{"text": "QUERY UNDERSTANDINGQuery understanding aims at understanding intent of queries , performing betterdocument ranking , and providing better search result presentation .It is also usefulin tasks such as query completion ( for example , [ Shokouhi and Radinsky 2012])and query suggestion ( for example , [ Ozertem et al .", "label": "", "metadata": {}, "score": "49.410336"}
{"text": "Section 3 will survey how search and browse log mining can improve web searchthrough query annotation and page importance calculation.1.3.4 Enhancing document ranking .The key functionality of a web search en - gine is to rank documents according to their relevance to a given query .", "label": "", "metadata": {}, "score": "49.439766"}
{"text": "The term q represents the average number of entries in the document list per co - occurrence term .The worst case size in the table in FIG .3 ( b ) is given by the following expressions : .In Equation ( 7 ) the first term corresponds to the word co - occurrences of the form P - P , the second to S - P or P - S , and the last corresponds to the co - occurrences of the form S - S. The term q represents the average number of entries in the document list per co - occurrence term .", "label": "", "metadata": {}, "score": "49.443233"}
{"text": "We do not know the sets A and ' A in advance , in fact A is the set we hope to retrieve .However , given a query formulation Q and the documents retrieved by it we can ask the user to tell the system which of the documents retrieved were relevant and which were not .", "label": "", "metadata": {}, "score": "49.453262"}
{"text": "This requires a general data structure of O(nlogn ) bits , plus a specific one of O((n / f)logn ) bits .This approach does not exactly solve the ranked document search problem .Gagie et al .introduce their method as .", "label": "", "metadata": {}, "score": "49.46757"}
{"text": "If the user is willing to provide relevance judgements on the SL retrieved documents from the parallel corpus , then the process is full translinguistic relevance feedback .Then , new documents in either SL or TL can be retrieved via a single common set of index terms .", "label": "", "metadata": {}, "score": "49.52425"}
{"text": "The probabilistic correlations indicate the conditional probability of the appearance of a document term when a query term is used .For instance , if a document that has been selected by a user more than once for a query consisting of the same terms , then the document is correlated to the terms in the query .", "label": "", "metadata": {}, "score": "49.60232"}
{"text": "Next , the search system 120 adjusts the valid phrases Qp for capitalization .When parsing the query , the search system 120 identifies potential capitalizations in each valid phrase .This may be done using a table of known capitalizations , such as \" united states \" being capitalized as \" United States \" , or by using a grammar based capitalization algorithm .", "label": "", "metadata": {}, "score": "49.687115"}
{"text": "The exact savings will depend on the various values of the parameters discussed above .In the worst case the extra storage will be significantly less than twice that in the rudimentary query expansion scheme .The indexing scheme presented above has been discussed with the assumption that a word has only a single sense .", "label": "", "metadata": {}, "score": "49.697784"}
{"text": "That is , the original matrix lists only the words actually in each document , whereas we might be interested in all words related to each document - generally a much larger set due to synonymy .The consequence of the rank lowering is that some dimensions are combined and depend on more than one term : .", "label": "", "metadata": {}, "score": "49.70079"}
{"text": "N , April 2013 .It assumes that the user views searchresults from top to bottom and decides whether to click eachurl .Once a click is issued , documents below the clicked re - sult are not examined regardless of the position .", "label": "", "metadata": {}, "score": "49.743813"}
{"text": "N , April 2013 .4 \u00b7 Fig . 2 .An example of query histogram , which consists of queries and their frequencies.of queries .In a query , a user may open several web pages .Finally , a user mayfurther follow the hyperlinks in the web pages of search results and browse moreweb pages .", "label": "", "metadata": {}, "score": "49.80979"}
{"text": "FIG .8 b illustrates this case , where phrase A appears in both URL 0 ( as anchor text ) and in the body of URL 1 .In this case , the related phrase bit vector for phrase A for URL 1 is used as the inlink score for the link from URL 0 to URL 1 containing phrase A. .", "label": "", "metadata": {}, "score": "49.827065"}
{"text": "Other works [ 16 , 17 ] perform non - authority - based keyword search on databases , where the focus is on finding connections between the query keywords and non on finding the most relevant entities .We next give an overview of ObjectRank [ 12 , 15 ] , which is the base of our CO system .", "label": "", "metadata": {}, "score": "49.872204"}
{"text": "Fuxman et al .[2008 ] proposed a method for classifying queries using a click - through bipartite graph .Their method views a click - through bi - partite as an undi - rected graph .In the graph , there is a special node called the null node .", "label": "", "metadata": {}, "score": "49.893646"}
{"text": "This query phrase and all of its sub - phrases is removed from the list of candidates , and the list is resorted and the process repeated .The result of this process is a set of valid query phrases Qp .", "label": "", "metadata": {}, "score": "49.896564"}
{"text": "b )Personalized Topic Based Document Descriptions .In embodiments where personalization of the search results is provided , the document descriptions can likewise be personalized to reflect the user interests as expressed in the user model .The presentation system 130 does this as follows .", "label": "", "metadata": {}, "score": "49.93186"}
{"text": "The list of relevant documents is communicated to the client computing device ( e.g. , the remote device 182 of FIG .1 that communicated the newly submitted query ) .At block 514 , the query expansion module , responsive to an indication of user selection of a document from the list of relevant documents , generates a new or updates a previous query session 208 ( FIG .", "label": "", "metadata": {}, "score": "49.980404"}
{"text": "Given the variable efficiency of two - word queries with WT ( due to the diverse number of possible document matches for each query ) , it is difficult to draw definitive conclusions on the relative algorithm performance .When the phrase length is increased , the two standard Zettair methods get slower per query , as expected , because they now have to intersect more inverted lists to produce the final ranked result .", "label": "", "metadata": {}, "score": "50.103462"}
{"text": "If a phrase p does not qualify for the good phrase list 208 , then it is checked for qualification for being a bad phrase .A phrase p is a bad phrase if : .These conditions indicate that the phrase is both infrequent , and not used as indicative of significant content and again these thresholds may be scaled per number of documents in the partition .", "label": "", "metadata": {}, "score": "50.14514"}
{"text": "4 illustrates the index structures required for more efficient query processing in accordance with the present invention .FIG .5 illustrates the merging of co - occurring word index entries .FIG .6 illustrates query expansion processing in a traditional information retrieval system .", "label": "", "metadata": {}, "score": "50.18178"}
{"text": "c ) executing the logically expanded query to retrieve ones of the documents associated , through the coarser granularity index , with the corresponding ones of the higher granularity concepts ; and .The method according to . claim 1 , wherein in the replacing step , the higher granularity concepts are higher granularity semantic concepts .", "label": "", "metadata": {}, "score": "50.242393"}
{"text": "With such judgements , we can construct a better term - weighted query for the TL search , essentially producing true translingual RF .Of course , this RF process can also be used to enhance the SL query and search other SL databases at no extra cost to or involvement from the analyst .", "label": "", "metadata": {}, "score": "50.244633"}
{"text": "The process of constructing and using the user model for personalized ranking is as follows .First , for a given user , a list of the last K queries and P documents accessed is maintained , where K and P are preferably about 250 each .", "label": "", "metadata": {}, "score": "50.27694"}
{"text": "So in other words a keyword will be assigned to a cluster representative if it occurs in more than half the member documents .This treats errors of prediction caused by absence or presence of keywords on an equal basis .Croft [ 7 ] has shown that it is more reasonable to differentiate the two types of error in IR applications .", "label": "", "metadata": {}, "score": "50.378788"}
{"text": "Another way of saying this is that the accuracy of the predication is 99.999 % because the occurrence rate is 100:1 .Accordingly , any entry ( g j , g k ) that is less the Related Phrase threshold is zeroed out , indicating that the phrases g j , g k are not related .", "label": "", "metadata": {}, "score": "50.38624"}
{"text": "We considered possible explanations as to why CO 's sensitivity varied among the queries .In simplest terms , the sequence of keywords that define a query might be contained in an result record , neighboring records , or both result and neighboring records .", "label": "", "metadata": {}, "score": "50.430588"}
{"text": "A na\u00a8\u0131ve method may intentionally put unevaluated webpages in the toppositions .Those unevaluated webpages , however , may be irrelevant to the query , and thus may seriously hurt user satisfaction .The authors developed a principledapproach to overcome the problem using a Bayesian method .", "label": "", "metadata": {}, "score": "50.46689"}
{"text": "The second bit position stores a flag that indicates whether a related phrase g l of g k is also present in document d. It is useful to note that for a given phrase g , the length of the related phrase bit vector , and the association of the related phrases to the individual bits of the vector , will be the same with respect to all documents containing g. This implementation has the property of allowing the system to readily compare the related phrase bit vectors for any ( or all ) documents containing g , to see which documents have a given related phrase .", "label": "", "metadata": {}, "score": "50.48188"}
{"text": "By representing D with a wavelet tree , values C[i ] can calculated on de- mand , rather than stored explicitly [ 22].The CSA is used to find D[sp .Page 5 .O(logN ) time .Gagie et al .", "label": "", "metadata": {}, "score": "50.49916"}
{"text": "V , No .N , April 2013 .22 \u00b7 Now , the question is how we can use the users ' click - through data to derive pref - erence information between queries and documents and how to use the preferenceinformation to improve search relevance .", "label": "", "metadata": {}, "score": "50.577362"}
{"text": "N , April 2013 . \u00b7 19p5Queries Web pagesq1q2q3q4p1p2p3p4Fig .Here , two webpages are considered similar if they are clicked in the searchesof the same set of queries .For example , consider the queries and the webpages inFigure 7 .", "label": "", "metadata": {}, "score": "50.577633"}
{"text": "This third term corresponds to each of n proper names adding g+h co - occurrences .Similarly , the number of words and concepts in Q under the multi - granularity query expansion ( MGQ ) is as follows : .Essentially , the main distinction is that the compression factor f arises since we are using the higher level semantic representation of the set of similar words is being used .", "label": "", "metadata": {}, "score": "50.614727"}
{"text": "First , therelation between a webpage and the webpages clicked so far is an indicator onwhether the user is likely to click the webpage .Second , there is no distinctionbetween navigational queries and informational queries .For navigational queriesusers tend to stop at the most relevant webpages , while for the informational queriesACM Transactions on Computational Logic , Vol .", "label": "", "metadata": {}, "score": "50.61512"}
{"text": "The nature of the query language often dictates the nature of the search strategy .For example , a query language which allows search statements to be expressed in terms of logical combinations of keywords normally dictates a Boolean search .This is a search which achieves its results by logical ( rather than numerical ) comparisons of the query with the documents .", "label": "", "metadata": {}, "score": "50.78812"}
{"text": "N , April 2013 .They askedhuman subjects to manually label queries as navigational or informational and tookmajority votes on the labeled results .Since queries are shortand ambiguous , this approach does not work well .In the search result of each search engine , the semantic categories of the web pages , as well as the titles and snippets of theweb pages are collected .", "label": "", "metadata": {}, "score": "50.79235"}
{"text": "The document descriptions can be either general or personalized to the user .a ) General Topic Document Descriptions .As before , given a query , the search system 120 has determined the related query phrases Qr and the phrase extensions of the query phrases as well , and then identified the relevant documents for the query .", "label": "", "metadata": {}, "score": "50.802925"}
{"text": "In the indexing phase , semantically similar words are grouped into a concept which results in a substantial index size reduction due to the coarser granularity of semantic concepts .During query processing , the words in a query are mapped into their corresponding semantic concepts and syntactic extensions , resulting in a logical expansion of the original query .", "label": "", "metadata": {}, "score": "50.93815"}
{"text": "4 shows the time for searching for two- and four - word patterns .Page 11 .than the new methods , as expected from Fig . 2 .The Zet - ph has better performance , on average , than Zet , and Zet - io is the most efficient of all word - based inverted indexing methods tested .", "label": "", "metadata": {}, "score": "50.987167"}
{"text": "If the first case applies to Q 2 , the search system 120 scans the related phrase bit vector for each document d in Q 1 's posting list to determine if it has a bit set for Q 2 .If this bit is not set in for document d in Q 1 's posting list , then it means that Q 2 does not appear in that document .", "label": "", "metadata": {}, "score": "51.005257"}
{"text": "For that , we created new ranking variants , as described below , to better suit this domain .Our recent book [ 1 ] on information discovery on EHRs briefly discusses the possibility of applying authority flow techniques on EHRs , but without specific algorithms or experiments .", "label": "", "metadata": {}, "score": "51.046757"}
{"text": "Consequently , the click - throughdata recorded by a search engine in a passive way are strongly biased toward web - pages that are already ranked high .Those webpages highly relevant to a querybut initially ranked low may never be viewed or evaluated by any users .", "label": "", "metadata": {}, "score": "51.08468"}
{"text": "There is a positive correlation between the semantic similarity of two words ( as measured by LSA ) and the probability that the words would be recalled one after another in free recall tasks using study lists of random common nouns .", "label": "", "metadata": {}, "score": "51.08875"}
{"text": "Since the more sophisticated symbolic methods we are considering require both additional processing time ( impacting the user ) and development time ( impacting start - up cost ) , it is important to determine whether the improvements in recall , precision , and multilinguality are sufficient payoff .", "label": "", "metadata": {}, "score": "51.1201"}
{"text": "\" This helps ensure that the user 's most likely search is in fact executed .The related phrase information may also be used by the system to identify or select which documents to include in the search result .The related phrase information indicates for a given phrase and a given document , which related phrases of the given phrase are present in the given document .", "label": "", "metadata": {}, "score": "51.12107"}
{"text": "The choice of entities is critical , given that it determines the authority flow graph and the ranking .Second , the CO parameters must be calibrated .In particular , the damping factor d and the authority transfer rates must be calibrated .", "label": "", "metadata": {}, "score": "51.136665"}
{"text": "However , in many new search domains the requirement to choose terms prior to indexing is either not easily accomodated , or leads to unacceptable restrictions on queries .For example , several Far East languages are not easily parsed into words , and a user may adopt a different parsing as that used to create the index .", "label": "", "metadata": {}, "score": "51.155903"}
{"text": "Term frequency analysis .As a pre - processing step , we performed a frequency analysis on the morphologically normalized documents to establish baseline frequencies for terms in documents throughout the corpus .In the dynamic processing of an input document , we selected representative terms for the document using a TFIDF filter ( term frequency inverse document frequency , [ 4 ] ) .", "label": "", "metadata": {}, "score": "51.190636"}
{"text": "This may be interpreted to mean that the author of the document d used several related phrases g j , g k , and g l together in drafting the document .A bit pair of ( 1,0 ) indicates that both g j and g k are present , but no further secondary related phrases from g k are present , and thus this is a less significant topic .", "label": "", "metadata": {}, "score": "51.23519"}
{"text": "( 1 ) the matching function is given a suitable threshold , retrieving the documents above the threshold and discarding the ones below .( 2 ) the documents are ranked in increasing order of matching function value .The hope in each case is that the relevant documents are contained in the retrieved set .", "label": "", "metadata": {}, "score": "51.252842"}
{"text": "2009].Log data mining canhelp to substantially improve this document ranking process .First , we can derivepreference on webpages with respect to queries from click - through data .Second , wecan use the preference information to improve search relevance , for example , usingit as training data or feature in learning to rank [ Li 2011].", "label": "", "metadata": {}, "score": "51.263657"}
{"text": "Unfortunately , there does not appear to be any work to remedy the situation except that of Ardnaudov and Govorun [ 10 ] .Finally , it should be noted that cluster methods which proceed directly from document descriptions to the classification without first computing the intermediate dissimilarity coefficient , will need to make a choice of cluster representative ab initio .", "label": "", "metadata": {}, "score": "51.274204"}
{"text": "This makes the comparison between CO and BM25 fairer .Notice that the filtering step is very trivial as it simply involves removing non - hospitalization entities from the result list and is not part of the search method since it is just a post - processing step conducted after the results are ranked .", "label": "", "metadata": {}, "score": "51.31156"}
{"text": "Next , the storage overhead of multi - granularity indexing in accordance with the present invention , which groups semantically similar set of terms into a unique semantic concept , is estimated .As before , in order to compute the sizes of index tables in FIG .", "label": "", "metadata": {}, "score": "51.317627"}
{"text": "Queries may have time intents as well .In the context of recency ranking in web search , Donget al .[2010 ] proposed a method for identifying whether a query is time sensitive , ACM Transactions on Computational Logic , Vol .", "label": "", "metadata": {}, "score": "51.317917"}
{"text": "The figure gives a better picture of why this entity was ranked higher for query \" respiratory distress \" and its relationship with other entities that contain the query keywords .Detail descriptions of each entity are displayed as tool tip texts when the user points at them .", "label": "", "metadata": {}, "score": "51.32644"}
{"text": "Raising the threshold over 1.0 serves to reduce the possibility that two otherwise unrelated phrases co - occur more than randomly predicted .As noted the computation of information gain is repeated for each column k of the matrix G with respect to a given row j. Once a row is complete , if the information gain for none of the good phrases g k exceeds the information gain threshold , then this means that phrase g j does not predict any other good phrase .", "label": "", "metadata": {}, "score": "51.43296"}
{"text": "We describe them indetail.2.1 Query StatisticsLet us start with some basic statistics of queries , as matter of fact .For other statistics on queries , see[Beitzel et al .2004 ; Beitzel et al .2007 ; Backstrom et al .", "label": "", "metadata": {}, "score": "51.443535"}
{"text": "Finally , the top N ( e.g. , 5 ) sentences following the sort are used as the description of the document .This set of sentences can be formatted and included in the presentation of the document in the modified search results 703 .", "label": "", "metadata": {}, "score": "51.5174"}
{"text": "In this case , we again consider the terms reported by GOC to be used in the selection of the relevant GO node .We evaluate the proximity of those terms to individual paragraphs in the document , using the document matrix R. The closest match using the vector intersection operation ( Figure 2 , step 4 ) is selected as the evidence .", "label": "", "metadata": {}, "score": "51.595432"}
{"text": "This set of sentences is considered to be the contextual neighborhood of the protein , and all ( morphologically normalized ) terms are extracted from these sentences to establish a set of document - derived context terms for the protein .These terms are in turn associated with TFIDF weights calculated for each term in the document , and filtered to select the highest - ranked terms according to these weights .", "label": "", "metadata": {}, "score": "51.677002"}
{"text": "Sadakane [ 20 ] offers a different space - time tradeoff .He builds a compressed suffix arrayA , and a parentheses representation of C in order to run RMQ queries on it without accessing C. Furthermore , he stores a bitvector B indicating the points of T where documents start .", "label": "", "metadata": {}, "score": "51.702602"}
{"text": "As we can see , users ' click - through activities can be regarded as users ' implicitfeedback about the search results .The click - through activities , however , provide hintsabout the users ' preference on the webpages with respect to queries .", "label": "", "metadata": {}, "score": "51.765614"}
{"text": "Ranking retrieved documents , query - relevant summarization , assimilation of retrieved information , and system evaluation are all discussed in turn .Introduction : Beyond Traditional Information Retrieval .Traditional information retrieval ( IR ) offers a suite of very useful technologies , such as inverted key - word files , word - weighting methods including TF - IDF , precision and recall metrics , vector - space document modeling , relevance feedback , controlled - vocabulary indexing of text collections , and so on .", "label": "", "metadata": {}, "score": "51.766724"}
{"text": "This approach is to cluster words based on co - occurrence in documents and to use these clusters to expand queries .Since the co - occurrence is a binary relationship , the size of such index is usually extremely large .", "label": "", "metadata": {}, "score": "51.777542"}
{"text": "In turn , this will remove the restriction that IR system users must express their information needs as terms in the language chosen by the system , rather than in a more intuitive way .Our methods return the top - k documents in tf order , which departs from the tf\u00d7idf framework of most information retrieval systems .", "label": "", "metadata": {}, "score": "51.7965"}
{"text": "This results in a set of related phrases which related to the query or the user , called set Qu .Now , the presentation system 130 uses this ordered list of phrases as the basis for ranking the sentences in each document in the search results , in a manner similar to the general document description process described above .", "label": "", "metadata": {}, "score": "51.82042"}
{"text": "( 5 ) the terms used to index the citations in ( 4 ) .All this can be conveniently provided to a user during his search session by an interactive retrieval system .If he discovers that one of his search terms occurs very frequently he may wish to make it more specific by consulting a hierarchic dictionary which will tell him what his options are .", "label": "", "metadata": {}, "score": "51.831223"}
{"text": "The document description can then be presented to the user when the document is included in search results , so that the user obtains a better understanding of the document , relative to the query .A further refinement of this process of generating document descriptions allows the system to provide personalized descriptions , that reflect the interests of the user .", "label": "", "metadata": {}, "score": "51.846733"}
{"text": "For example , assume the following phrases are initially present in URL 0 and URL 1 : .( In the above , and following tables , the secondary related phrase bits are not shown ) .The URL 0 row is the outlink score of the link from anchor text A , and the URL 1 row is the inlink score of the link .", "label": "", "metadata": {}, "score": "51.869164"}
{"text": "Two issues become paramount in supporting such query expansion : the size of index tables and the query processing overhead .In accordance with the present invention , the notion of a multi - granularity information and processing structure is used to support efficient query expansion , which involves an indexing phase , a query processing and a ranking phase .", "label": "", "metadata": {}, "score": "51.870705"}
{"text": "Wecan capture the pair - wise preferences .That is , given webpages a and b , we tryto learn from the click - through data which one is more preferable .Alternatively , we can learn the user preference order on a set of webpages .", "label": "", "metadata": {}, "score": "51.901905"}
{"text": "Conclusions .In comparison of two fundamentally different techniques for keyword search in an EHR system -- the traditional Information Retrieval BM25 technique and an authority flow ranking technique , CO -- all CO variants outperform BM25 in terms of sensitivity , while achieving similar specificity .", "label": "", "metadata": {}, "score": "51.91435"}
{"text": "The summation is onlytaken from the segments of more than one word .Named entity recognition in queriesis helpful for search result presentation .Pa\u00b8sca [ 2007 ] and Pa\u00b8sca and Alfonseca [ 2009 ] conducted a series of research onthe problem and proposed several methods for the task .", "label": "", "metadata": {}, "score": "51.991074"}
{"text": "For each document , there is a list of counts of the number of occurrences of the related phrases R of phrase g j that also appear in document d. .In one embodiment , the related phrase information is a related phase bit vector .", "label": "", "metadata": {}, "score": "51.998928"}
{"text": "V , No .N , April 2013 . \u00b7 21user browsing graph , web pages are represented as vertices and the transitionsbetween pages are represented as edges .The staying time on web pages is also con - sidered .Zhu and Mishne [ 2009 ] viewed a session as a sequence of hopsthrough the web graph by a user , and computed ClickRank as the importance ofeach web page in the session .", "label": "", "metadata": {}, "score": "52.03171"}
{"text": "Because at any level we can have more than one document , the documents are said to be partially ranked by the co - ordination levels .Co- ordination level . 3 D 1 , D 2 . 2 D 3 . 1 D 4 .", "label": "", "metadata": {}, "score": "52.03202"}
{"text": "He is immediately faced with two issues for which NLP techniques provide assistance : .Determining the set of relevant keywords .Keyword search will perform an exact match , but in many cases the information gatherer is interested in finding documents which match keyword synonyms , as well .", "label": "", "metadata": {}, "score": "52.054184"}
{"text": "In practice , alist L only includes the top N URLs .Compared with a click - through bipartite , click patterns contain richer information .A click - through bipartite only representsaggregated clicks of URLs , while click patterns further represent the positions of theclicked URLs as well as unclicked URLs .", "label": "", "metadata": {}, "score": "52.061806"}
{"text": "We refer to these techniques as authority flow ranking techniques , since the authority ( importance ) \" flows \" along associated entities .We sought to compare the effectiveness of two fundamentally different techniques for keyword search on EHRs : the traditional BM25 technique and a newly proposed authority flow ranking technique , Clinical ObjectRank ( CO ) .", "label": "", "metadata": {}, "score": "52.11396"}
{"text": "This update identifies that the good phrase g i appears in this specific document .In one embodiment , the posting list for a phrase g j takes the following logical form : .Phrase g j : list : ( document d , [ list : related phase counts ] [ related phrase information ] ) .", "label": "", "metadata": {}, "score": "52.131287"}
{"text": "On the other hand , topics may be too coarse torepresent users ' search needs .Consequently , the accuracy of topic - based methodsmay not be as high as that of click - based and term - based methods [ Dou et al .", "label": "", "metadata": {}, "score": "52.138966"}
{"text": "However , savings are realized since user queries can be processed more efficiently .In order to process the expanded queries as described above , the index tables are modified as shown in FIG .4 .In particular , the index table in FIG .", "label": "", "metadata": {}, "score": "52.143387"}
{"text": "The number of times that either phrase g j or phrase g k appears as distinguished text in a secondary window ; and .C(j , k ) : Conjunctive Interesting count : the number of times that both g j and phrase g k appear as distinguished text in a secondary window .", "label": "", "metadata": {}, "score": "52.16281"}
{"text": "To address those issues , Dupret and Piwowarski [ 2008 ] examined several userbrowsing models .In the single browsing model , the probability that a user examinesa webpage depends on the distance from that page to the position of the last clickedwebpage .", "label": "", "metadata": {}, "score": "52.19229"}
{"text": "The resulting dimensions might be difficult to interpret .For instance , in .However , it is very likely that cases close to . will occur .This leads to results which can be justified on the mathematical level , but have no interpretable meaning in natural language .", "label": "", "metadata": {}, "score": "52.217888"}
{"text": "If the total number of results is greater than 50 , the query processor can stop without producing the results in slot ( 3,2 ) .The query processor can continue producing additional results from the remaining slots and classes as described , until the total number of results is greater than 50 , or until the last class is reached .", "label": "", "metadata": {}, "score": "52.232777"}
{"text": "However , this task was not rigorously evaluated in BioCreAtIve , and so we do not report here on this component of the system .As mentioned previously , morphological normalization , TFIDF - based term weighting , and proximity - based GO node word expansion are performed during preprocessing for each document .", "label": "", "metadata": {}, "score": "52.255318"}
{"text": "Shepelyansky DL , Zhirov OV : Google matrix , dynamical attractors , and Ulam networks .Physical Review E , Statistical Nonlinear Soft Matter Physics 2010 , 81 ( 3 Pt 2 ) : 036213 .( 8) View Article .Balmin A , Hristidis V , Papakonstantinou Y : ObjectRank : Authority - Based Keyword Search in Databases .", "label": "", "metadata": {}, "score": "52.318535"}
{"text": "Given a search query , the system identifies the phrases present in the query , along with their related phrases , and their phrase extensions .For a given document , each sentence of the document has a count of how many of the query phrases , related phrases , and phrase extensions are present in the sentence .", "label": "", "metadata": {}, "score": "52.32676"}
{"text": "It so happens that in the case where M is the cosine correlation function , i.e. . corresponds to a linear discriminant function used to linearly separate two sets A and ' A in R[t].Nilsson [ 14 ] has discussed in great detail how functions such as this may be ' trained ' by modifying the weights qi to discriminate correctly between two categories .", "label": "", "metadata": {}, "score": "52.40219"}
{"text": "LSA can use a term - document matrix which describes the occurrences of terms in documents ; it is a sparse matrix whose rows correspond to terms and whose columns correspond to documents .This matrix is also common to standard semantic models , though it is not necessarily explicitly expressed as a matrix , since the mathematical properties of matrices are not always used .", "label": "", "metadata": {}, "score": "52.419228"}
{"text": "Discussion , GOC - based runs .Due to the \" unknown proteins \" problem described above , the protein neighborhood terms input to GOC were in most instances the top TFIDF - ranked terms for the document as a whole , rather than coming from a coherent textual neighborhood around the protein .", "label": "", "metadata": {}, "score": "52.419388"}
{"text": "When summed and sorted over the search results , the most frequently occurring related phrases Qr will be indicated , each of which will be a cluster of documents .The most frequently occurring related phrase is the first cluster , which takes as its name its related phrase Qr , and so on for the top three to five clusters .", "label": "", "metadata": {}, "score": "52.431805"}
{"text": "Sadakane [ 20 ] proposes a 2n+o(n ) bit data structure built over the suffix array to compute idftfor a given t. Nbits .Other 3.2Top - k Retrieval In IR it is typical that only the top k ranked documents are required , for some k , as for example in Web search .", "label": "", "metadata": {}, "score": "52.435524"}
{"text": "[2005 ] proposed the CubeSVD algorithm , which conducts three - ordersingular value decomposition on the query - document - user cube .We can also usethe algorithm to calculate the relevance score of a document with respect to a queryand a user , which turns out to be another click - based method .", "label": "", "metadata": {}, "score": "52.447876"}
{"text": "A slight modification of the full Boolean search is one which only allows AND logic but takes account of the actual number of terms the query has in common with a document .This number has become known as the co - ordination level .", "label": "", "metadata": {}, "score": "52.46698"}
{"text": "In fact , it can be argued that this number will be comparable to w. Based on these parameters , the additional storage overhead of multi - granularity indexing can be computed .The computation for the table in FIG .4 ( a ) is : .", "label": "", "metadata": {}, "score": "52.47469"}
{"text": "During query processing , the words in a query are mapped into their corresponding semantic concepts and syntactic extensions , using a dictionary and actual data contents , resulting in a logical expansion of the original query .Additionally , the processing overhead can be avoided .", "label": "", "metadata": {}, "score": "52.52041"}
{"text": "A possible phrase p on the possible phrase list 206 is moved to the good phrase list 208 if the frequency of appearance of the phrase and the number of documents that the phrase appears in indicates that it has sufficient usage as semantically meaningful phrase .", "label": "", "metadata": {}, "score": "52.540104"}
{"text": "Having a system that can automatically determine the right set of morphological variants would cut down on the human effort that is otherwise required to boost recall .Linguistic Relations : Linguistic generalization techniques like those sketched above can help recall , but they do not necessarily help precision .", "label": "", "metadata": {}, "score": "52.55049"}
{"text": "Accordingly , in one embodiment , the search system 120 sorts the documents in the search results according to the value of their related phrase bit vectors .The documents containing the most related phrases to the query phrases Q will have the highest valued related phrase bit vectors , and these documents will be the highest - ranking documents in the search results .", "label": "", "metadata": {}, "score": "52.62143"}
{"text": "Consequently , the user receives a much more diversified and robust set of results , and does not have to waste time reviewing documents that are duplicates of each other .The presentation system 130 provides the functionality as follows .The presentation system 130 processes each document in the search result set 701 .", "label": "", "metadata": {}, "score": "52.6227"}
{"text": "There are some additional ways to build on our results .We could calculate a global word proximity matrix , rather than one matrix per document , which should strengthen our confidence in the relationships between words , as well as relating any given word to more words due to consideration of its occurrence across the document corpus .", "label": "", "metadata": {}, "score": "52.663567"}
{"text": "According toWelch and Cho [ 2008 ] , about 30 % of queries are location sensitive , which are calledlocalizable queries .Their method makes use of featuresderived from search log data and a dictionary of locations .The method takes ad - vantage of the fact that a location sensitive query is likely to co - occur with locationnames in other queries .", "label": "", "metadata": {}, "score": "52.666748"}
{"text": "Persin et al .[14 ] give different heuristics to support top - k ranked retrieval ( under the tf\u00d7idf model ) when inverted lists are sorted by decreasing tf .Anh and Moffat [ 1 ] study various generalizations of this idea under the name \" impact ordering \" .", "label": "", "metadata": {}, "score": "52.711346"}
{"text": "Each of the references discussed herein , is hereby incorporated by reference .However , as noted above , the past work has failed to address the problem of efficient processing of queries when they undergo query expansion or of reducing the size of the indices used to perform query expansion and processing .", "label": "", "metadata": {}, "score": "52.782753"}
{"text": "This suggests two possible problems .The first is that perhaps the names that we do have in our database are inadequate for effective protein reference identification and we should explore more shopisticated protein reference recognition techniques ( such as those explored in BioCreAtIvE Task 1 ) .", "label": "", "metadata": {}, "score": "52.828003"}
{"text": "As the use of EHRs becomes more widespread , so does the need to search and provide effective information discovery within them .Querying by keyword has emerged as one of the most effective paradigms for searching .Most work in this area is based on traditional Information Retrieval ( IR ) techniques , where each document is compared individually against the query .", "label": "", "metadata": {}, "score": "52.874752"}
{"text": "ii ) compute the actual co - occurrence rate A(j , k ) of g j and g k .This is the raw co - occurrence count R(j , k ) divided by T , the total number of documents ; . iii ) g j is said to predict g k where the actual co - occurrence rate A(j , k ) exceeds the expected co - occurrence rate E(j , k ) by a threshold amount .", "label": "", "metadata": {}, "score": "52.934746"}
{"text": "There is some evidence to show that both these methods of representation are effective when used in conjunction with appropriate search strategies ( see , for example , van Rijsbergen [ 4 ] and Murray [ 5 ] ) .Obviously there are further variations on obtaining cluster representatives but as in the case of association measures it seems unlikely that retrieval effectiveness will change very much by varying the cluster representatives .", "label": "", "metadata": {}, "score": "52.974236"}
{"text": "A short summary is produced for each selected document , and that summary is translated to the source ( query ) language ; .Information about each document ( origin , language , score , summary ) is presented to the user in an interface which allows him to select specific documents for additional processing ( such as selective assimilation , described below ) .", "label": "", "metadata": {}, "score": "53.040585"}
{"text": "In each phrase window 302 , each candidate phrase is checked in turn to determine if it is already present in the good phrase list 208 or the possible phrase list 206 .If the candidate phrase is not present in either the good phrase list 208 or the possible phrase list 206 , then the candidate has already been determined to be \" bad \" and is skipped .", "label": "", "metadata": {}, "score": "53.072674"}
{"text": "The architecture of the complete system is shown in Figure 4 .For BioCreAtIvE tasks 2.1 and 2.2 , the document selection portion is not relevant , as the documents were manually selected by the evaluators and provided in the input queries .", "label": "", "metadata": {}, "score": "53.07435"}
{"text": "Furthermore , the issue of ranking documents on the basis of exact and similarity matches remains a difficult problem .SMART is one of the best known advanced information retrieval systems .In SMART , each document is represented by a vector of terms .", "label": "", "metadata": {}, "score": "53.11945"}
{"text": "4 illustrates a method of identifying related phrases .FIG .5 illustrates a method of indexing documents for related phrases .FIG .6 illustrates a method of retrieving documents based on phrases .FIG .7 illustrates operations of the presentation system to present search results .", "label": "", "metadata": {}, "score": "53.133904"}
{"text": "2 ) .CONCLUSION .[ 0057 ] The described systems and methods expand queries .Although the systems and methods have been described in language specific to structural features and methodological operations , the subject matter as defined in the appended claims are not necessarily limited to the specific features or operations described .", "label": "", "metadata": {}, "score": "53.24261"}
{"text": "Multiple tables of the form shown in FIG .4 ( a ) can be created for various semantic groupings ( for example , one for ISA and one for IS_PART_OF ) .Alternatively , a single table can be used for the various semantic groupings .", "label": "", "metadata": {}, "score": "53.270546"}
{"text": "[0004 ] One limitation , for example , is that global analysis query expansion techniques do not typically address term mismatch .Global analysis techniques are based on the analysis of a corpus of data to generate statistical similarity matrixes of term pair co - occurrences .", "label": "", "metadata": {}, "score": "53.306313"}
{"text": "Other types of queries are possible , but the work described herein relies on queries defined as sequences of keywords .The goodness of a result depends on factors like relevance to the query , specificity , and importance .The simplest notion of relevance could be defined as a query string that appears verbatim in a document .", "label": "", "metadata": {}, "score": "53.33609"}
{"text": "It is to be noted that in the present context , the term document may refer to text , images or a combination of text and images .The indices are illustrated in FIG .2 .Note that the table in FIG .", "label": "", "metadata": {}, "score": "53.346832"}
{"text": "These accessed documents for the basis for selecting which phrases will become part of the user model .For each such accessed document , the search system 120 retrieves the document model for the document , which is a list of phrases related to the document .", "label": "", "metadata": {}, "score": "53.37978"}
{"text": "The retrieved SL / TL document pairs are first given back to the analyst , in order to scan the SL documents for relevance ; then the Rocchio formula is used for both SL and TL document database search .If desired , the retrieved TL documents are summarized and/or translated for analyst inspection .", "label": "", "metadata": {}, "score": "53.392212"}
{"text": "The numbers in brackets indicate the original evaluation results for those runs .It is clear that the re - evaluation resulted in significantly more positive results , so that we can assume that the reported numbers for the runs 1 and 3 are also lower than the actual ( corrected ) results would indicate .", "label": "", "metadata": {}, "score": "53.427864"}
{"text": "If g i appears later in the document , and the related phrase is found again within the later secondary window , again the count is incremented .If any of these secondary related phrases counts / bits are set , then this indicates that the secondary related phrases of g j are also present in document d. .", "label": "", "metadata": {}, "score": "53.489624"}
{"text": "But none of these techniques apply directly to search [ D T ] with Q S .Possible approaches include : .Translate the collection -- Convert [ D T ] into a collection in the source language [ D ' S ] by manual or machine translation .", "label": "", "metadata": {}, "score": "53.51527"}
{"text": "For example , the word \" old \" which appears quite frequently would have a high term frequency but a very low inverse document frequency and hence is not a good term for judging document relevance .Hence it would given a low tf\u00b7idf score .", "label": "", "metadata": {}, "score": "53.522255"}
{"text": "FIG .3 illustrates the additional data - structures that are needed to facilitate query expansion in traditional IR systems .In particular , FIG .3 is a table derived from a lexical - semantic on - line dictionary where words are grouped into semantically similar concepts .", "label": "", "metadata": {}, "score": "53.560158"}
{"text": "For more details about the evaluation of cluster representative ( 3 ) for this purpose the reader should consult the work of Yu et al .[ 8,9 ] .One major objection to most work on cluster representatives is that it treats the distribution of keywords in clusters as independent .", "label": "", "metadata": {}, "score": "53.572487"}
{"text": "Translingual Relevance Feedback .If even a modest parallel corpus of documents can be located ( or created ) for the source and target language pair , then we can exploit the tried - and - true relevance feedback method to perform translingual query , as outlined in Figure 2 .", "label": "", "metadata": {}, "score": "53.57869"}
{"text": "( 1 ) We implement , empirically validate and compare existing theoretical proposals for document listing search on general texts , and include a new variant of our own .( 2 ) We propose two novel algorithms for ranked document search using general query patterns .", "label": "", "metadata": {}, "score": "53.644386"}
{"text": "Initially , the notion of multi - granularity will be discussed , as well as how it can be adapted in conjunction with the traditional indexing employed by most TR systems .Then , the storage overhead of multi - granularity indexing for a given document collection will be evaluated .", "label": "", "metadata": {}, "score": "53.661488"}
{"text": "V , No .N , April 2013 . 10 \u00b7 more than half of the sessions consist of only one query .The major topical categories of queries are \" people and place \" , \" commerce\",\"health \" , \" entertainment \" , \" internet and computer \" , and \" pornography \" .", "label": "", "metadata": {}, "score": "53.663048"}
{"text": "Many of the differences in ratings seem to reflect somewhat subtle variations in how the raters subjectively assess the importance of the nodes .An opportunity for the future might then be \" tuning \" or appending to the algorithm , to reflect individual users ' weights or priorities in how the ranking is done ( e.g. , relative importance of query phrase vs. other terms , core description vs. nodes ) .", "label": "", "metadata": {}, "score": "53.685127"}
{"text": "That is , each good phrase is used with sufficient frequency and independence to represent meaningful concepts or ideas expressed in the corpus .Unlike existing systems which use predetermined or hand selected phrases , the good phrase list reflects phrases that actual are being used in the corpus .", "label": "", "metadata": {}, "score": "53.69912"}
{"text": "We should therefore experiment with the size of left and right context windows around protein references to achieve better results .Assessing annotation accuracy .The methodology followed by the evaluators of Task 2.2 focused on the evidence text selection , measuring whether the selected evidence text for a given query mentioned both the protein of interest , and the function / process / component indicated by the target GO node .", "label": "", "metadata": {}, "score": "53.752197"}
{"text": "There are also some othersurveys on the topic , such as [ Baeza - Yates 2004 ; Agichtein 2010].-Query understanding is performed online .A ranking modelACM Transactions on Computational Logic , Vol .V , No .N , April 2013 . \u00b7", "label": "", "metadata": {}, "score": "53.80061"}
{"text": "Only the loosest forms of linguistic relation -- strict adjacency and/or near adjacency -- are typically supported in current on - line search systems , and highly - frequent function words ( like the preposition ' ' of ' ' ) are often ignored .", "label": "", "metadata": {}, "score": "53.804497"}
{"text": "If the possible phrase is present in the good phrase list 208 , then a phrase number is returned for phrase ; the possible phrase is now a candidate phrase .After all possible phrases in each window have been tested to determine if they are good candidate phrases , the search system 120 will have a set of phrase numbers for the corresponding phrases in the query .", "label": "", "metadata": {}, "score": "53.808685"}
{"text": "We shall see that this was an improper choice , with stronger results for moderate levels of specificity .For each query we were instructed to provide a certain number n of annotations , and after the fact we were told what those correct annotations were .", "label": "", "metadata": {}, "score": "53.810417"}
{"text": "At best , some prior systems will index documents with respect to a predetermined and very limited set of ' known ' phrases , which are typically selected by a human operator .Indexing of phrases is typically avoided because of the perceived computational and memory requirements to identify all possible phrases of say three , four , or five or more words .", "label": "", "metadata": {}, "score": "53.827095"}
{"text": "Next , the meaning of a document is represented by the phrases associated with the page .As described above , given a query and document , the relevant phrases for the document are determined from the body scores ( the related bit vectors ) for all phrases indexed to the document .", "label": "", "metadata": {}, "score": "53.854977"}
{"text": "Users can search documents using terms from the accepted vocabularies , together with appropriate boolean operators between them .In this type of system , an exact match strategy is used .Although this approach has many advantages , such as simplicity and high precision , it suffers from the problem of word mismatch .", "label": "", "metadata": {}, "score": "53.86112"}
{"text": "Abstract .An information retrieval system uses phrases to index , retrieve , organize and describe documents .Phrases are identified that predict the presence of other phrases in documents .Documents are the indexed according to their included phrases .Related phrases and phrase extensions are also identified .", "label": "", "metadata": {}, "score": "53.883636"}
{"text": "More specifically , a prediction measure is used that relates the actual co - occurrence rate of two phrases to an expected co - occurrence rate of the two phrases .Information gain , as the ratio of actual co - occurrence rate to expected co - occurrence rate , is one such prediction measure .", "label": "", "metadata": {}, "score": "53.887592"}
{"text": "V , No .N , April 2013 .For example , search logscan be exploited to build a caching mechanism to reduce the workload of searchengine .The data can also be leveraged to make a balanced partition of documentsand terms within the distributed system of search engine .", "label": "", "metadata": {}, "score": "53.88851"}
{"text": "Despite the differences in ratings , this pilot study shows that ObjectRank results are more valued ( i.e. , selected ) by the raters than BM25 results .Discussion .For many types of automated searching of EHRs , maintaining a high sensitivity is important .", "label": "", "metadata": {}, "score": "53.91133"}
{"text": "Shepelyansky et .al [ 11 ] discusses an approximation of PageRank that is more efficient , by creating directed networks constructed by Ulam method with characteristics being rather similar to those of the World Wide Web .All of the above described works apply to the Web and do not address the unique characteristics of structured databases .", "label": "", "metadata": {}, "score": "53.917496"}
{"text": "Words are then compared by taking the cosine of the angle between the two vectors ( or the dot product between the normalizations of the two vectors ) formed by any two rows .Values close to 1 represent very similar words while values close to 0 represent very dissimilar words .", "label": "", "metadata": {}, "score": "53.97322"}
{"text": "Hence , we propose to perform an expansion translation , in which all meanings of all query terms are generated , properly weighed for base - line and co - occurrence statistics , so that no meaning is lost .On a preliminary experiment using Lycos \u00ae , this method yielded recall results comparable to a carefully hand crafted target - language query , though at some degradation in precision .", "label": "", "metadata": {}, "score": "53.989037"}
{"text": "Unfortunately the extent of the effectiveness is rather difficult to gauge , since it is rather difficult to separate the contribution to increased retrieval effectiveness produced when individual documents move up in rank from the contribution produced when new documents are retrieved .", "label": "", "metadata": {}, "score": "53.99877"}
{"text": "1975 ; Baeza - Yates and Ribeiro - Neto1999].Webpages contain hypertexts and thus are more than just words .There is richinformation on the web , which can help to enhance the representations of webpages .For example , the anchor text of a webpage , pointed from another webpage , oftengives a compact and precise description of the page .", "label": "", "metadata": {}, "score": "53.998863"}
{"text": "In addition the various lists , a co - occurrence matrix 212 ( G ) for the good phrases is maintained .The matrix G has a dimension of m\u00d7m , where m is the number of good phrases .Each entry G(j , k ) in the matrix represents a pair of good phrases ( g j , g k ) .", "label": "", "metadata": {}, "score": "54.001118"}
{"text": "The preferences can not lead to a ranked list among the three web pages .To overcome the problem , click models are learned and exploited , which can pro - duce a ranking of web pages for a given query on the basis of the click - throughdata of the query .", "label": "", "metadata": {}, "score": "54.001545"}
{"text": "However , the effect is often lessened due to words having a predominant sense throughout a corpus ( i.e. not all meanings are equally likely ) .", "label": "", "metadata": {}, "score": "54.061302"}
{"text": "In the traditional IR systems , the syntactic association is generally captured through co - occurrence relationship .Since word co - occurrences in the same document are one to one relationships , if there are n words identified , the worst case for the index size is . associations .", "label": "", "metadata": {}, "score": "54.061592"}
{"text": "Id. Many advanced techniques have also been proposed .Based on the experimental results , automatic query expansion , on average , improve effectiveness of retrieval by 7 % to 25 % .See C. Buckley et al . , \" Automatic Query Expansion Using SMART , \" supra .", "label": "", "metadata": {}, "score": "54.091816"}
{"text": "The assumption is that this will improve retrieval on the next run by virtue of the fact that its performance is better on a sample .Once again this is not the whole story .It is often difficult to fix the threshold T in advance so that instead documents are ranked in decreasing matching value on output .", "label": "", "metadata": {}, "score": "54.106277"}
{"text": "The posting list include sa list of documents d ( by their document identifiers , e.g. a document number , or alternatively a URL ) in which the phrase occurs .In addition , the co - occurrence matrix 212 is updated , as further explained below .", "label": "", "metadata": {}, "score": "54.113037"}
{"text": "A query histogram represents the number of times eachquery is submitted to a search engine .As shown in Figure 3 , query histogramcontains query strings and their frequencies .As a simple statistics , query histogramcan be used in a wide variety of applications , such as query auto completion andquery suggestion.1.2.2 Click - through bipartite .", "label": "", "metadata": {}, "score": "54.12326"}
{"text": "Each of these operations is now described in detail .First , recall that the co - occurrence matrix 212 contains good phrases g j , each of which predicts at least one other good phrase g k with an information gain greater than the information gain threshold .", "label": "", "metadata": {}, "score": "54.13035"}
{"text": "But the other methods have not yet been investigated in any depth , nor have there been many systematic cross - method comparisons .In addition to Davis & Dunning 's work ( Davis & Dunning 1996 ) , we have recently performed an experiment systematically comparing various methods ( Carbonell et al .", "label": "", "metadata": {}, "score": "54.13703"}
{"text": "Ahonen - Myka , H. et al . , \" Finding Co - Occurring Text Phrases by Combining Sequence and Frequent Set Discovery \" , Proceedings of 16th International Joint Conference on Artificial Intelligence IJCAI-99 Workshop on Text Mining : Foundations Techniques and Applications , Jul. 31 , 1999-Aug .", "label": "", "metadata": {}, "score": "54.147366"}
{"text": "[0037 ]The query expansion module 202 generates a database of probabilistic correlations 212 between previous query terms and document terms .These probabilistic correlations are made between each pair of a previous query term and a document term , as a function of statistics of the whole query logs The document terms are terms in the documents selected by a system responsive to search engine queries .", "label": "", "metadata": {}, "score": "54.178173"}
{"text": "II .Indexing System .In one embodiment , the indexing system 110 provides three primary functional operations : 1 ) identification of phrases and related phrases , 2 ) indexing of documents with respect to phrases , and 3 ) generation and maintenance of a phrase - based taxonomy .", "label": "", "metadata": {}, "score": "54.18473"}
{"text": "1990].The core tensorS can capture the major latent factors among the users , queries , and documents inC.Finally , the CubeSVD method derives a new tensor \u02c6C from the core tensor S.An element \u02c6Cuqp in the new tensor \u02c6A represents the personalized relevance score ofdocument p with respect to user u and query q. Since the correlation among usersis encoded in the core tensor S , even if user u never raises query q , her preferenceon page p with respect to query q can still be estimated .", "label": "", "metadata": {}, "score": "54.193268"}
{"text": "[ 2005a ] [ 2005b ] proposed two contextualization methodsACM Transactions on Computational Logic , Vol .V , No .N , April 2013 .A method and apparatus for efficient query expansion using reduced size indices and for progressive query processing .", "label": "", "metadata": {}, "score": "54.201935"}
{"text": "The first two are implementations of V\u00a8 alim\u00a8 aki and M\u00a8 akinen [ 22 ] and Sadakane [ 20 ] as described in Section 3 , labelled VM and Sada respectively .It is described in detail in Appendix C. Experimental Data .", "label": "", "metadata": {}, "score": "54.218803"}
{"text": "T. Gagie , S. Puglisi , and A. Turpin .Range quantile queries : Another virtue of wavelet trees .In Proc . 16thSPIRE , LNCS 5721 , pp\u02d91 - 6 , 2009 .R. Grossi , A. Gupta , and J. Vitter .", "label": "", "metadata": {}, "score": "54.222305"}
{"text": "An information retrieval system may also use the phrase information to identify and eliminate duplicate documents , either while indexing ( crawling ) the document collection , or when processing a search query .For a given document , each sentence of the document has a count of how many related phrases are present in the sentence .", "label": "", "metadata": {}, "score": "54.24199"}
{"text": "The system according to . claim 26 , wherein ones of the words in the preliminary index having multiple meanings are replaced by multiple ones of the corresponding higher granularity concepts .The system according to . claim 26 , wherein words failing to meet the predetermined criterion are proper nouns .", "label": "", "metadata": {}, "score": "54.26839"}
{"text": "Alternatively , this value can directly obtained by the search system 120 by looking up each query phrase Q in the index 150 , accessing the document from the posting list of the query phrase Q , and then accessing the related phrase bit vector .", "label": "", "metadata": {}, "score": "54.27127"}
{"text": "Then , we can conduct random walk on theclick - through graph by multiplying the matrices .Take the click - through bipartitegraph in Figure 7 as an example .Without the expansion , webpage p1 is only asso - ciated with query q2 .", "label": "", "metadata": {}, "score": "54.28131"}
{"text": "Moreover , as log data are accumulated , the annotations from the userswill be dynamically and continuously updated .Poblete and Baeza - Yates [ 2008 ] developed two query - based webpage represen - tation models using click - through data .", "label": "", "metadata": {}, "score": "54.324646"}
{"text": "Mathematically , they modeled both theattractiveness and examination as Bernoulli variables .Navigational queries and informational queries can be regarded as two extremesin a wide spectrum of queries .Theirexperimental results on real data show that the single browsing model has clearlybetter performance .", "label": "", "metadata": {}, "score": "54.332405"}
{"text": "It requires distinctive difference between the cluster of relevant documents and that of nion - relevant documents in the retrieval result .This is true for many cases but does not hold some time , especially for those inherently ambiguous queries .", "label": "", "metadata": {}, "score": "54.377792"}
{"text": "N , April 2013 .26 \u00b7 The dynamic Bayesian network model can closely mimic the user 's search be - havior .It is assumed that a user clicks a webpage if and only if she looks at thesnippet and thinks that it is attractive ( Equation 3(a ) ) .", "label": "", "metadata": {}, "score": "54.38539"}
{"text": "The number of entries in the respective tables over which the lookup will be performed is different under the two schemes .Now the lookup costs for the query Q considered above will be estimated .Assuming that the tables are organized in the form of a balanced search structures , the operation of table lookup will be logarithmic in the number of rows in the table .", "label": "", "metadata": {}, "score": "54.426697"}
{"text": "FIG .1 is block diagram of the software architecture of one embodiment of the present invention .FIG .2 illustrates a method of identifying phrases in documents .FIG .3 illustrates a document with a phrase window and a secondary window .", "label": "", "metadata": {}, "score": "54.43395"}
{"text": "Existing IR systems achieve partial success through the use of general thesauri , which can be less useful in specialized semantic domains ( for example , linking ' ' acquire ' ' to ' ' get ' ' may not help precision or recall in a joint venture domain ) .", "label": "", "metadata": {}, "score": "54.498383"}
{"text": "9 .FIG .10 shows how such a ranking may be accomplished .The result slots are further classified into classes , where results in slots in the same class have the same ranking .With the class structure of FIG .", "label": "", "metadata": {}, "score": "54.551285"}
{"text": "Let the words found in a dictionary be denoted as S ( semantically meaningful ) and all other words be denoted as P ( proper names ) .Based on the above classification of dictionary and non - dictionary words , the co - occurrence relationship between words can be classified into three different categories : .", "label": "", "metadata": {}, "score": "54.5688"}
{"text": "However , with query expansion , query lengths increase substantially .As a result , most existing search engines on the Web do not provide query expansion functionality .An overview of existing work in the area of query expansion will now be presented .", "label": "", "metadata": {}, "score": "54.584152"}
{"text": "Building a graph of co - occurrence proximity allows us to capture network associations rather than just pair - wise co - occurrence .Therefore , we expect concepts or themes ( e.g. [ 9 ] ) to be organized in more interconnected sub - graphs , or clusters of words .", "label": "", "metadata": {}, "score": "54.596786"}
{"text": "159 - 165 .Mauldin , M. L. , 1991 . ''Retrieval Performance in FERRET : A Conceptual Information Retrieval System ' ' , Proceedings of the 14th International Conference on Research and Development in Information Retrieval , Chicago .Mitamura , T. , E. Nyberg and J. Carbonell .", "label": "", "metadata": {}, "score": "54.597427"}
{"text": "To store this information , two basic representations are available .First , as indicated above , the information may be stored in the co - occurrence matrix 212 , wherein : .Alternatively , the matrix representation can be avoided , and all information stored in the good phrase list 208 , wherein each row therein represents a good phrase g j : .", "label": "", "metadata": {}, "score": "54.615524"}
{"text": "In typical embodiment , the good phrase list 208 will include about 6.5\u00d710 5 phrases .A list of bad phrases is not necessary to store , as the system need only keep track of possible and good phrases .By the final pass through the document collection , the list of possible phrases will be relatively short , due to the expected distribution of the use of phrases in a large corpus .", "label": "", "metadata": {}, "score": "54.63459"}
{"text": "A document is retrieved in response to a query containing a number of query terms , typically based on having some number of query terms present in the document .The retrieved documents are then ranked according to other statistical measures , such as frequency of occurrence of the query terms , host domain , link analysis , and the like .", "label": "", "metadata": {}, "score": "54.670925"}
{"text": "Often , however , selected keywords are not always good descriptors of relevant document contents .[ 0003 ] One reason for this is that most words in natural language have inherent ambiguity .Such ambiguity often results in search engine keyword / document term mismatch problems .", "label": "", "metadata": {}, "score": "54.714603"}
{"text": "Accordingly , each phrase g j remaining on the good phrase list 208 will predict some number of other phrases , based on the information gain threshold previously discussed .Now , for each phrase g j the indexing system 110 performs a string match with each of the phrases g k that is predicts .", "label": "", "metadata": {}, "score": "54.737553"}
{"text": "[ 0014 ]FIG .3 shows that correlations between terms of newly submitted queries and document terms can be established via information maintained in query sessions from a query log .[ 0015 ] FIG .4 shows exemplary probabilistic correlations between query terms and document terms .", "label": "", "metadata": {}, "score": "54.74118"}
{"text": "For example , the word bank can be interpreted as a financial institution or as a riverbank .To consider words with multiple senses , a word in the Sem_word_list ( shown in FIG .3 ) may belong to multiple Concept # in FIG .", "label": "", "metadata": {}, "score": "54.744263"}
{"text": "If user u who is similar to user u searches withquery q before , then the click information from user u can be leveraged to estimateS(q , p , u ) .The similarity betweenusers is then determined by the similarity between their topic preferences .", "label": "", "metadata": {}, "score": "54.833992"}
{"text": "We expect that a multi - stage design will be necessary in many actual real - world applications , with fast but crude techniques performing an intial filter before higher - quality but slower techniques are applied .Specific Translingual Information Retrieval techniques .", "label": "", "metadata": {}, "score": "54.855255"}
{"text": "Thus , when it comes to crafting a useful product for IR , even a sensitive one can unlikely compensate for a poorly formulated query .We also analyzed how much agreement occurred between raters and what might account for differences between raters .", "label": "", "metadata": {}, "score": "54.880043"}
{"text": "In addition , for each such cluster , a counter is maintained and incremented each time a phrase in that cluster is added to the user model .These counts may be used as weights , as described below .Thus , the user model is built from phrases included in clusters that are present on a document that the user has expressed an interest in by accessing the document .", "label": "", "metadata": {}, "score": "54.886127"}
{"text": "Moreover , users should be able to easilyopt out from browse log data collection.1.2 Frequently Used Data SummarizationsAlthough search and browse log data provide great opportunities for enhancingweb search , there are several challenges before such data can be used in variousapplications .", "label": "", "metadata": {}, "score": "54.89087"}
{"text": "Page 2 . contain errors .Other types of text simply do not have a standard definition of a term , such as biological sequences ( DNA , protein ) and multimedia signals .With this in mind , in this paper we take the view of a text database ( or collection ) T as a string of n symbols drawn from an alphabet \u03a3. Queries are also strings ( or sets of strings ) composed of symbols drawn from \u03a3. Here , the symbols in \u03a3 may be bytes , letters , nucleotides , or even words if we so desire ; and the documents may be articles , chromosomes or any other texts in which we need to search .", "label": "", "metadata": {}, "score": "54.949368"}
{"text": "The main difference being that provision must be made for back - tracking .This will occur when the search strategy estimates ( based on the current value of the matching function ) that further progress down a branch is a waste of time , at which point it may or may not retrieve the current cluster .", "label": "", "metadata": {}, "score": "54.966778"}
{"text": "Clearly , these methods increase in complexity , and the techniques range from using statistical learning , to crude translation for indexing , to precise conceptual analysis for both indexing and translation .It seems to us that an appropriate research strategy is to begin by protoyping the simpler methods , based on current technology .", "label": "", "metadata": {}, "score": "54.979385"}
{"text": "Finally , a few comments about the technique of relevance feedback in general .It appears to me that its implementation on an operational basis may be more problematic .It is not clear how users are to assess the relevance , or non - relevance of a document from such scanty evidence as citations .", "label": "", "metadata": {}, "score": "55.12856"}
{"text": "A system for detecting a duplicate document , comprising : . a document description system , executed by a processor , and configured to associate a set of documents with a set of corresponding document descriptions and store the associations in a memory , . wherein a document description of the first document comprises a selected subset of sentences of the first document , the sentences being selected and ordered in the document description as a function of a number of related phrases in the selected sentences ; . wherein the document description of the second document comprises a selected subset of sentences of the second document , the sentences being selected and ordered in the document description as a function of a number of related phrases in the selected sentences , . a duplicate detection system , executed by a processor and configured to : . select a first document and a second document from the document description system ; . compare the document description corresponding to the first document with the document description corresponding to the second document , and . responsive to the document description corresponding to the first document matching the document description corresponding to the second document , indentifying the first document and the second document as duplicate documents in the set of documents .", "label": "", "metadata": {}, "score": "55.135994"}
{"text": "This process is depicted in Figure 2 .GO node Word Expansion via proximity measure .( 1 )For each document , a Boolean matrix of word occurrence in paragraphs ( R ) is created .( 2 ) Co- occurrence proximity network WPP is computed .", "label": "", "metadata": {}, "score": "55.169777"}
{"text": "D[sp .ep],1 + ?By traversing to nodes with larger ranges in a greedy fashion , we will reach the document leaves in tf order , and reach the first k leaves potentially having explored much less of the tree than we would have using a depth - first - style traversal .", "label": "", "metadata": {}, "score": "55.181416"}
{"text": "If the candidate phrase is not in the good phrase list 208 then it is added to the possible phrase list 206 , unless it is already present therein .Each entry p on the possible phrase list 206 has three associated counts : .", "label": "", "metadata": {}, "score": "55.18322"}
{"text": "For example , the search system 120 can remove any documents that contain more than two clusters .This cluster threshold can be predetermined , or set by the user as a search parameter .b )Ranking Documents Based on Anchor Phrases .", "label": "", "metadata": {}, "score": "55.183567"}
{"text": "ACM Transactions on Computational Logic , Vol .V , No .N , April 2013 .24 \u00b7 4.3 Click ModelsPairwise preferences are relatively easy to learn .Such preferences , however , maynot generate a ranked list in general .", "label": "", "metadata": {}, "score": "55.20099"}
{"text": "0054 ]At block 506 , the query expansion module 202 ( FIG .2 ) selects one or more document terms from the probabilistic correlation database 212 ( FIG .2 ) .Each selected document term 216 ( FIG .", "label": "", "metadata": {}, "score": "55.233303"}
{"text": "Additionally , vocabularies used by Web content authors can vary greatly .In light of this , generating a search engine query that will result in return of a document list of relevance to a user is a difficult problem .In efforts to address this problem , search engine services typically expand queries ( i.e. , add terms / keywords ) .", "label": "", "metadata": {}, "score": "55.298244"}
{"text": "Only the bitvectors ( preprocessed for rank and select ) are present in the actual structure , the numbers above each bitvector are included only to aid explanation .It stores an array D[1 .n ] , aligned to the suffix array A[1 .", "label": "", "metadata": {}, "score": "55.30396"}
{"text": "A Boolean search strategy retrieves those documents which are ' true ' for the query .This formulation only makes sense if the queries are expressed in terms of index terms ( or keywords ) and combined by the usual logical connectives AND , OR , and NOT .", "label": "", "metadata": {}, "score": "55.30594"}
{"text": "In that case we can still use a centroid type of cluster representative but the normalisation is replaced with a process which thresholds the components of the sum [ [ Sigma ] ] Di .To be more precise , let Di now be a binary vector , such that a 1 in the j th position indicates the presence of the j th keyword in the document and a 0 indicates the contrary .", "label": "", "metadata": {}, "score": "55.310406"}
{"text": "Fig .2 shows the total time for 200 queries of each query length for all methods .The document listing method of Gagie et al .with our optimizations ( number 4 on the graphs ) is clearly the fastest method for finding all documents and tfq , d values that contain the query q in document number order .", "label": "", "metadata": {}, "score": "55.363495"}
{"text": "Anew classic paper on the limitations of a Boolean search is Verhoeff et al .[ 18 ] .Miller [ 19 ] has tried to get away from a simple Boolean search by introducing a form of weighting although maintaining essentially a Boolean search .", "label": "", "metadata": {}, "score": "55.372818"}
{"text": "If the simpler methods prove insufficient , we propose to explore more complex and methods , rather than scaling up the simpler methods .To date , the LSI method has been investigated for cross - linguistic query , starting with work at Bellcore by Landauer & Littman and later Dumais , with partial success ( Dumais et al .", "label": "", "metadata": {}, "score": "55.382706"}
{"text": "Next , given the phrases related to an accessed document , the clusters associated with these phrases can be determined from the cluster bit vectors for each phrase .For each cluster , each phrase that is a member of the cluster is determined by looking the phrase up in its related phrase table that contains the cluster number , or cluster bit vector representation as described above .", "label": "", "metadata": {}, "score": "55.399834"}
{"text": "At the end of ( b ) the heap contains the top - k document numbers and tf values .Page 15 .components , and treating each component as a term .The index is comprised of two pieces .To save space , the lists are compressed by storing the block numbers in increasing order and encoding only the difference ( gap ) between adjacent items with a suitable integer code .", "label": "", "metadata": {}, "score": "55.455223"}
{"text": "The sample of citations and their indexing will give him some idea of what kind of documents are likely to be retrieved and thus some idea of how effective his search terms have been in expressing his information need .He may modify his query in the light of this sample retrieval .", "label": "", "metadata": {}, "score": "55.49801"}
{"text": "In particular , the user may want to see results with partial matches to their search criterion .Therefore , for a query with N words , N lookups are needed which are independent of the boolean conditions in the search predicate .", "label": "", "metadata": {}, "score": "55.57908"}
{"text": "First , the search system 120 determines a score adjustment value for each document .The score adjustment value is a mask formed from the bits in the positions corresponding to the query phrases Q 1 and Q 2 in the related phrase bit vector for a document .", "label": "", "metadata": {}, "score": "55.6006"}
{"text": "Since completion of the formal BioCreAtIvE evaluation , we have refined , improved , and measured our annotation results in a number of ways .First , there is a free parameter s to GOC called the specificity , which represents the extent to which the user values results which are either \" low \" or \" high \" in the GO hierarchy ( see the Appendix and elsewhere [ 3 ] ) .", "label": "", "metadata": {}, "score": "55.600998"}
{"text": "This implementation has the property that related phrases that have multiple or one - way information gain appear in the same cluster .An example of the cluster bit vectors are as follows , using the above phrases : .To summarize then , after this process there will be identified for each good phrase g j , a set of related phrases R , which are sorted in order of information gain I(g j , g k ) from highest to lowest .", "label": "", "metadata": {}, "score": "55.617817"}
{"text": "6 illustrates the main functional operations of the search system 120 : .600 : Identify phrases in the query .602 : Retrieve documents relevant to query phrases .604 : Rank documents in search results according to phrases .The details of each of these of these stages is as follows .", "label": "", "metadata": {}, "score": "55.61946"}
{"text": "This is a module which compiles the list of names into a finite state recognizer for the set of names , so that when a document is analyzed by the module each occurrence of a name in the list is identified in the document .", "label": "", "metadata": {}, "score": "55.646545"}
{"text": "2009;Guo et al .2009 ; Guo et al .2009 ; Wang et al .2010 ; Hu et al .2011].5 .USER UNDERSTANDINGWe describe two tasks in user understanding , namely , personalization and contextu - alization .Teevan et al .", "label": "", "metadata": {}, "score": "55.65811"}
{"text": "Discussion , proximity network - based word expansion and evidence text selection .While the proximity network - based word expansion proved to be a very useful technique , giving us good results on Task 2.1 , the evaluator comments indicated that they were often unhappy with paragraphs as the basic unit for evidence text .", "label": "", "metadata": {}, "score": "55.666313"}
{"text": "Direct and indirect associations are counted as distinct \" hits \" on a node and can be weighted differently .Evidence text selection .We make use of two mechanisms for evidence text selection .The first is a simple sentence selection algorithm aimed at selecting one sentence out of the set of sentences containing a relevant protein reference to serve as the evidence text .", "label": "", "metadata": {}, "score": "55.69626"}
{"text": "A similarity metric,\u02c6S(q , di ) , is used to evaluate each document direlative to a user query q ( often a list of terms or words ) .If docu- ments are treated as \" bags of terms \" , similarity can be measured using simple statistical properties of the vocabulary [ 23].", "label": "", "metadata": {}, "score": "55.701077"}
{"text": "See e.g. , E. Voorhees , \" Query Expansion Using Lexical - Semantic Relations , \" Proceedings of the 17th Annual International ACM SIGIR Conference , Dublin , Ireland , 1994 .One approach uses a thesaurus to expand the query to increase the chances of matching words in relevant documents .", "label": "", "metadata": {}, "score": "55.760796"}
{"text": "For four word queries , all of the self - indexing methods are clearly more efficient than the inverted file methods .Adding an idf computation to Greedy and Quantile will not make them less efficient than WT .6 Discussion We have implemented document listing algorithms that , to date , had only been theoretical proposals .", "label": "", "metadata": {}, "score": "55.834896"}
{"text": "The data for training the CFRmodel can be mined from session data using a method developed by Jones et al.[2006].Normally , about 10 % of queries contain spelling errors and thus spellingerror correction is a very important component for web search [ Guo et al .", "label": "", "metadata": {}, "score": "55.855766"}
{"text": "The kind of search that is of interest , is not the usual kind where the result of the search is clear cut , either yes , the item is present , or no , the item is absent .Good discussions of these may be found in Knuth [ 1 ] and Salton [ 2 ] .", "label": "", "metadata": {}, "score": "55.87353"}
{"text": "2008].That is , giventwo adjacent queries in a query stream , decide whether they belong to two sessionsor not .See also [ He et al .2002 ; Lucchese et al .2011 ] for other approaches tosession segmentation.1.3 Log Mining Technologies and Applications in Web SearchWith the abundance of search and browse log data , numerous log mining technolo - gies have been developed .", "label": "", "metadata": {}, "score": "55.92842"}
{"text": "At block 504 , responsive to receiving a newly submitted query 214 from a client computing device ( e.g. , a remote device 182 of FIG .1 ) , the query expansion module extracts every term that is not a stop term from the newly submitted query .", "label": "", "metadata": {}, "score": "55.967262"}
{"text": "Note that the column j for the phrase g j is not removed , as this phrase itself may be predicted by other good phrases .This step is concluded when all rows of the co - occurrence matrix 212 have been evaluated .", "label": "", "metadata": {}, "score": "56.037937"}
{"text": "Thus , p2 and p4 are considered similar because they may sat - isfy the similar information needs .The method performsrandom walk on the click - through graph .Since Equations ( 1 ) and ( 2 ) are recursive , we can propagate the similaritiesACM Transactions on Computational Logic , Vol .", "label": "", "metadata": {}, "score": "56.041344"}
{"text": "In each row g j of the matrix , there will be one or more other phrases that are related to phrase g j .For each related phrase m in R j , the indexing system 110 determines if each of the other related phrases in R is also related to g j .", "label": "", "metadata": {}, "score": "56.04943"}
{"text": "( q ) ) and P(w.sub.j.sup.d ) .[0048 ] Where f.sub.ik.sup .( q)(w.sub.i.sup .( q ) , D.sub.k ) is the number of the query sessions in which the query word w.sub.i.sup .( q ) and the document D k appear together . f.sup .", "label": "", "metadata": {}, "score": "56.07231"}
{"text": "The value for E(g j ) can be updated each time the counts for g j are incremented , or during this third stage .Next , for each other good phrase g k ( e.g. , the columns of the matrix ) , it is determined whether g j predicts g k .", "label": "", "metadata": {}, "score": "56.117767"}
{"text": "The search system 120 then makes a second pass through the capitalized phrases , and selects only those phrases are leftmost and capitalized where both a phrase and its subphrase is present in the set .For example , a search on \" president of the united states \" will be capitalized as \" President of the United States \" .", "label": "", "metadata": {}, "score": "56.12565"}
{"text": "FIG .7 , the order of these operations is independent , and may be varied as desired for a given embodiment , and thus the inputs may be pipelined instead of being in parallel as shown .Dynamic Taxonomy Generation for Presentation .", "label": "", "metadata": {}, "score": "56.165718"}
{"text": "The data objectsmay include users , sessions , queries , search result pages , clicks on search results , and follow - up clicks .At thetop level , each user has a series of sessions , where each session contains a sequenceACM Transactions on Computational Logic , Vol .", "label": "", "metadata": {}, "score": "56.17838"}
{"text": "For this purpose clusters are represented by some kind of profile ( a much overworked word ) , which here will be called a cluster representative .It attempts to summarise and characterise the cluster of documents .A cluster representative should be such that an incoming query will be diagnosed into the cluster containing the documents relevant to the query .", "label": "", "metadata": {}, "score": "56.19967"}
{"text": "If all of the predicted phrases g k are phrase extensions of phrase g j , then phrase g j is incomplete , and is removed from the good phrase list 208 , and added to an incomplete phrase list 216 .", "label": "", "metadata": {}, "score": "56.203754"}
{"text": "The basic idea is embodied in these steps : .The user specifies a query in his native language ; .The query is parsed into conceptual form , preserving relevant linguistic relations in corresponding semantic slots ( semantic roles ) ; .", "label": "", "metadata": {}, "score": "56.21817"}
{"text": "In essence , we do Bayesian - style training to maximize the probability of a correct translation given the available options , their estimated quality , and the well - formedness of the output translation as determined by a trigram language model .", "label": "", "metadata": {}, "score": "56.232147"}
{"text": "Alternatively , the user model for a given user may be persisted over time , and then down - weighted or aged .IV .Result Presentation .The presentation system 130 receives the scored and sorted search results from the search system 120 , and performs further organizational , annotation , and clustering operations prior to presenting the results to the user .", "label": "", "metadata": {}, "score": "56.322422"}
{"text": "Given a query Q involving both dictionary and non - dictionary words , the query Q can be represented as : .In this equation , s i , represents a dictionary word and p j represents a non - dictionary word .", "label": "", "metadata": {}, "score": "56.351257"}
{"text": "If d does not already have an entry in the heap,3then we add the pair ( d , tfq , d ) to the heap , with priority tfq , d .This ends the first round .We continue , in round 2 , to probe the ele- ments X[m/4 ] and X[3m/4 ] , and their frequencies fX[m/4]and fX[3m/4].", "label": "", "metadata": {}, "score": "56.37259"}
{"text": "The query - document model uses a vector of query termsweighted by TF - IDF .The frequency of a term is calculated as the frequency of thequeries containing the term associated with the page .A drawback of the query - document model is that it assumes terms are indepen - dent from each other .", "label": "", "metadata": {}, "score": "56.372658"}
{"text": "The first stage 600 of the search system 120 is to identify any phrases that are present in the query in order to effectively search the index .The following terminology is used in this section : . q : a query as input and receive by the search system 120 .", "label": "", "metadata": {}, "score": "56.377525"}
{"text": "It can also be used inquery suggestion .Query transformation can be performed by using click - throughdata and session data .It can also be performed by models trained with click - through data and session data.2.3.1 Query Transformation Using Click - through Bipartites .", "label": "", "metadata": {}, "score": "56.40296"}
{"text": "Next , for each of the referencing documents R , the related phrase bit vector for each anchor phrase Q is obtained .This is a measure of how topical the anchor phrase Q is to the document R. This value is here called the outbound score component .", "label": "", "metadata": {}, "score": "56.419605"}
{"text": "Qr : related phrases of Qp .Qe : phrase extensions of Qp .Q : the union of Qp and Qr .A query q is received from a client 190 , having up to some maximum number of characters or words .", "label": "", "metadata": {}, "score": "56.42763"}
{"text": "0038 ]The probabilistic correlations are based on an assumption that each document that is returned to a user in response to a query and that is also selected or \" clicked \" by the user will be \" relevant \" to the particular query .", "label": "", "metadata": {}, "score": "56.47087"}
{"text": "Accordingly , a given document will appear in the posting lists of many different phrases , and in each such posting list , the related phrase vector for that document will be specific to the phrase that owns the posting list .", "label": "", "metadata": {}, "score": "56.495235"}
{"text": "While using queries to annotate webpagesis an intuitive idea , there are several technical challenges .Click - through data aresparse .Many webpages may have very few or even no clicks .For example , Gao et al.[2009 ] reported that , in a real data set of 2.62 million query - document pairs , 75%of them do not have any click .", "label": "", "metadata": {}, "score": "56.540222"}
{"text": "Although the set - up discussed above can be used for processing queries with query expansion , this approach results in a high processing overhead .In accordance with the present invention , additional index structures that would allow the queries to be processed more efficiently are employed .", "label": "", "metadata": {}, "score": "56.562225"}
{"text": "The selected expansion terms are added to the terms of the newly submitted query .In this manner , high - quality expansion terms are added to the terms ( i.e. , expanding ) of a newly submitted query before sending it to the search engine ( see , the search engine of \" other modules \" 204 ) .", "label": "", "metadata": {}, "score": "56.57177"}
{"text": "2 ( a ) .In FIG .2 , the indices are shown as tables for ease of explanation .In actual implementation , classes on top of the NEC PERCIO OODBMS may be used , for example .Taking a sample query , if a user initiates a query with the words \" car \" and \" dealer \" the IR system fetches the list of documents from the corresponding rows in FIG .", "label": "", "metadata": {}, "score": "56.576202"}
{"text": "The recommended paragraph is selected by comparing the W GOProx , with each column of the document 's word occurrence perparagraph matrix R. The comparison was implemented by a vector intersection operation ( step 4 in Figure 2 ) .The columns of R are vectors of words occurring in a paragraph .", "label": "", "metadata": {}, "score": "56.599964"}
{"text": "This is the simple matching coefficient mentioned in Chapter 3 .Many of the more sophisticated search strategies are implemented by means of a matching function .This is a function similar to an association measure , but differing in that a matching function measures the association between a query and a document or cluster profile , whereas an association measure is applied to objects of the same king .", "label": "", "metadata": {}, "score": "56.623108"}
{"text": "For this sake we generated 44,693 additional queries aligned on English word boundaries from the wsj collection .Statistics of these phrase queries of word length 2 to 15 are given in Appendix D. Short of implementing an in - memory search engine , it is difficult to choose a baseline inverted file implementation that will efficiently solve the top - k doc- ument listing problem .", "label": "", "metadata": {}, "score": "56.626526"}
{"text": "A widely used simple method is theACM Transactions on Computational Logic , Vol .V , No .N , April 2013 . 6 \u00b7 Fig .5 .An illustration of click patterns .Click patterns summarize positions of clicked URLs insearch results of queries.so-called \" 30 minute rule \" .", "label": "", "metadata": {}, "score": "56.65345"}
{"text": "During the in - block scanning phase , as we locate positions of pattern oc- currence , these positions must be mapped to document numbers and tf values accumulated .Clearly once all blocks have been scanned we will also know idf .", "label": "", "metadata": {}, "score": "56.76068"}
{"text": "This is because each the first word in the phrase window 302 is always a candidate phrase , and the appropriate instance counts will be accumulated .Thus , the indexing system 110 can automatically index both individual words ( i.e. , phrases with a single word ) and multiple word phrases .", "label": "", "metadata": {}, "score": "56.79409"}
{"text": "But more importantly we can now treat the term and document vectors as a \" semantic space \" .The vector then has entries mapping it to a lower - dimensional space dimensions .These new dimensions do not relate to any comprehensible concepts .", "label": "", "metadata": {}, "score": "56.820427"}
{"text": "Problem 1 .Problem 2 .In the ranked document search problem , we focus on the specific case where\u02c6S(q , di ) is the tf\u00d7idf measure .tf\u00d7idf is the basic building block for a large class of similarity measures used in the most successful IR systems .", "label": "", "metadata": {}, "score": "56.83457"}
{"text": "The original term - document matrix is presumed noisy : for example , anecdotal instances of terms are to be eliminated .From this point of view , the approximated matrix is interpreted as a de - noisified matrix ( a better matrix than the original ) .", "label": "", "metadata": {}, "score": "56.844368"}
{"text": "Rocchio [ 15 ] in his thesis defined the optimal query Q0 as one which maximised : .By analogy to the linear classifier used before , we now add this vector to the query formulation on the i th step to get : . where wi and w2 are weighting coefficients .", "label": "", "metadata": {}, "score": "56.879227"}
{"text": "III .Search System .The search system 120 operates to receive a query and search for documents relevant to the query , and provide a list of these documents ( with links to the documents ) in a set of search results .", "label": "", "metadata": {}, "score": "56.88251"}
{"text": "Search logs provide users ' implicitfeedbacks on ranking .Thesecond approach builds a sequential click model to characterize user 's click behavioron the list of search result.1.3.5 Enhancing user understanding .Search consists of three major factors : queries , documents , and users .", "label": "", "metadata": {}, "score": "56.91428"}
{"text": "The importance score of a page is thencalculated as the sum of its scores over all the sessions containing the page.4 .DOCUMENT RANKINGIn web search , given a query , a ranking list of webpages is returned , where thewebpages are ranked in the descending order of the degrees of relevance to thequery ( that is , degrees of matching to the query ) .", "label": "", "metadata": {}, "score": "56.930748"}
{"text": "View Article .Rocha LM : Semi - metric Behavior in Document Networks and its Application to Recommendation Systems .Soft Computing Agents : A New Perspective for Dynamic Information Systems ( Edited by : Loia V ) .International Series Frontiers in Artificial Intelligence and Applications .", "label": "", "metadata": {}, "score": "56.948784"}
{"text": "For example , bank may be associated with Sem 10 and Sem 20 .To perform query expansion with consideration of multiple senses , when a query contains a word which is located in multiple Concept # , each of the different Concept # should be taken into account during query processing .", "label": "", "metadata": {}, "score": "56.997078"}
{"text": "The ObjectRank equation is then given as follows : .Regardless of whether one uses Equation 2 or Equation 3 , the PageRank algorithm solves this recursive equation using a simple iterative method , where the values of the ( k+1)-th execution are calculated as follows : .", "label": "", "metadata": {}, "score": "57.032875"}
{"text": "[ 7 ] .Another model , termed Word Association Spaces ( WAS ) is also used in memory studies by collecting free association data from a series of experiments and which includes measures of word relatedness for over 72,000 distinct word pairs .", "label": "", "metadata": {}, "score": "57.082127"}
{"text": "See J. Callan et al . , \" Trec and tipster experiments with inquery , \" Information Processing and Management , 31:327 - 332 , 1995 .Latent Semantic Indexing ( LSI ) is a technique which relies on statistically derived conceptual indices instead of individual term retrieval in lexical matching .", "label": "", "metadata": {}, "score": "57.088875"}
{"text": "3 is simplified for ease of exposition .For example , the set of similar terms \" car \" , \" auto \" \" automobile \" and \" sedan \" is represented as a symbolic entity sem 1 .Unlike for semantic similarity , which is based on a dictionary or a thesaurus , syntactic relationships in IR are determined from the document collection itself .", "label": "", "metadata": {}, "score": "57.11499"}
{"text": "The architecture of a web search system .In recent years , theimportance of users is emphasized and the component of user understanding isalso considered .De - spite this , search systems , in general , have not focused on explicitly representingquery intents .", "label": "", "metadata": {}, "score": "57.172997"}
{"text": "In this manner multiple word phrases , for example phrases of four , five , or more terms , can be identified .This avoids the problem of having to identify and index every possible phrases resulting from the all of the possible sequences of a given number of words .", "label": "", "metadata": {}, "score": "57.223717"}
{"text": "( q ) , D.sub.k ) is the number of query sessions in which w.sub.i.sup .( q ) and document D.sub.k appear together , f.sup .( q)(w.sub.i.sup .( q ) ) is a number of query sessions that contain term w.sub.i.sup .", "label": "", "metadata": {}, "score": "57.224846"}
{"text": "( q ) , D.sub.k ) is the number of query sessions in which w.sub.i.sup .( q ) and document D.sub.k appear together , f.sup .( q)(w.sub.i.sup .( q ) ) is a number of query sessions that contain term w.sub.i.sup .", "label": "", "metadata": {}, "score": "57.224846"}
{"text": "However , we are more interested in search strategies in which the documents retrieved may be more or less relevant to the request .All search strategies are based on comparison between the query and the stored documents .Sometimes this comparison is only achieved indirectly when the query is compared with clusters ( or more precisely with the profiles representing the clusters ) .", "label": "", "metadata": {}, "score": "57.27855"}
{"text": "7 illustrates query expansion processing using the multi - granularity query expansion scheme of the present invention .FIG .8 illustrates the ranking process in accordance with the present invention .FIG .9 illustrates a two dimensional ranking graph for a query having two words .", "label": "", "metadata": {}, "score": "57.32743"}
{"text": "Our hypothesis is that the effective use of the associations among clinical entities ( patient , hospitalization , clinical test , and so on ) in EHRs can improve the quality of search in EHRs .Before describing our methods , we provide additional background details about searching .", "label": "", "metadata": {}, "score": "57.335613"}
{"text": "ep ] is very fast , and about the same for all the query lengths tested .A low occ value means this range is smaller , and so less work for the document listing methods .Fig .3 summarizes the time per document listed , and clearly shows that the top - k methods ( Quantile and Greedy ) do more work per document listed .", "label": "", "metadata": {}, "score": "57.35749"}
{"text": "The most important difference being that there is an option to generate Qi+1 from Qi , or Q , the original query .The effect of all these adjustments may be summarised by saying that the query is automatically modified so that index terms in relevant retrieved documents are given more weight ( promoted ) and index terms in non - relevant documents are given less weight ( demoted ) .", "label": "", "metadata": {}, "score": "57.400185"}
{"text": "If only we could reduce or eliminate this redundancy we would have a much more manageable subset of relevant documents that nonetheless span the information space .The MMR formula below gives a credit for relevance and a penalty for redundancy , with a tunable parameter lambda ( where DB is the total document database , and RL the already produced ranked list of documents ) : .", "label": "", "metadata": {}, "score": "57.417164"}
{"text": "[ 0039 ] When the query expansion module 202 receives a newly submitted query 214 , each keyword term that is not a stop term , is extracted .Stops term are those terms that appear frequently in documents and do not provide any ability to discriminate one document from another .", "label": "", "metadata": {}, "score": "57.43351"}
{"text": "The similarity matrixes are used to expand a query with additional terms that are most similar to the terms already in the query .By only adding \" similar \" terms to the query , and by not addressing the ambiguities that are inherent between words in language , this global analysis approach to query expansion does not address term mismatch , which is one of the most significant problems in query expansion .", "label": "", "metadata": {}, "score": "57.441856"}
{"text": "Such abrute - force method , however , leaves much information unused .Importantly , nopreference is derived between any two clicked webpages .Similarly , no preference isderived between any two non - clicked webpages , either .We need a systematic wayto model preference pairs .", "label": "", "metadata": {}, "score": "57.44925"}
{"text": "A decision rule is not required ; we only need a stopping rule which could be simply a cut - off .A typical search would seek the largest cluster containing the document represented by the starting node and not exceeding the cut - off in size .", "label": "", "metadata": {}, "score": "57.466263"}
{"text": "We store a list for each keyword in the vocabulary , and in each list put the addresses ( or numbers ) of the documents containing that particular word .To satisfy a query we now perform the set operations , corresponding to the logical connectives , on the Ki -lists .", "label": "", "metadata": {}, "score": "57.478798"}
{"text": "The training data for Task 2 supported this strategy - a large majority ( about 70 % ) of the training queries contained proteins that had names in our database .The identification of occurrences of any known variant of a protein name facilitates identifying terms in the contextual neighborhood of the protein .", "label": "", "metadata": {}, "score": "57.48893"}
{"text": "Next , an example estimate will be calculated regarding the additional storage overhead that is needed to support index - tables based on semantic concepts , in accordance with the present invention , in addition to the traditional word - based indices .", "label": "", "metadata": {}, "score": "57.514236"}
{"text": "Figure 6 shows the explaining graphs , as shown in our user interface for CO .For better clarity , we use colour coding to differentiate the entities , as can be seen in Figure 6 .Sample explaining sub graph of an ObjectRank2 result - HospitalizationID 2406 for query \" respiratory distress \" .", "label": "", "metadata": {}, "score": "57.53604"}
{"text": "The bit vector value may also be used as a component in a more complex scoring function , and additionally may be weighted .The documents can then be ranked according to their document scores .Phrase information may also be used in an information retrieval system to personalize searches for a user .", "label": "", "metadata": {}, "score": "57.59006"}
{"text": "36 , No . 4 , pages 57 - 71 , April , 1993 .Based on this ranking scheme , the results in the slot at the top of FIG .9 have higher ranking scores than the results at the bottom .", "label": "", "metadata": {}, "score": "57.5945"}
{"text": "Note we can insert zero to two new elements in the queue .Fig .5(a ) gives pseudo code .In the worst case , this approach will explore almost as much of the tree as would be explored during the constrained depth- first traversal of Gagie et al . , and so requires O(docclogN ) time .", "label": "", "metadata": {}, "score": "57.595623"}
{"text": "Thoserules are extensions of the methods by Joachims et al .[ 2005].Thus , it is important to develop position bias free methods forthe learning task .Then , the list R with the above changes is presentedto the users and the user clicks are recorded .", "label": "", "metadata": {}, "score": "57.598045"}
{"text": "From the R matrices , we calculated a word in paragraph proximity matrix , WPP , for each document , using the co - occurrence probability measure below , as defined in [ 2 ] : .WPP denotes the association strength between pairs of words ( w i , w j ) , based on how often they co - occur in the paragraphs of a given document .", "label": "", "metadata": {}, "score": "57.618675"}
{"text": "An information retrieval system indexes documents in the document collection by the valid or good phrases .For each phrase , a posting list identifies the documents that contain the phrase .In addition , for a given phrase , a second list , vector , or other structure is used to store data indicating which of the related phrases of the given phrase are also present in each document containing the given phrase .", "label": "", "metadata": {}, "score": "57.621674"}
{"text": "Additional file 1 : Table s1 presents the sensitivity and specificity for each query and algorithm variant .All CO variants outperform BM25 in terms of sensitivity , while achieving similar specificity .Additional file 2 : Table s2 presents the sensitivity and specificity of individual raters for each query and algorithm variant .", "label": "", "metadata": {}, "score": "57.62912"}
{"text": "For a systematic evaluation of bottom - up searches in terms of efficiency and effectiveness see Croft [ 7 ] .If we now abandon the idea of having a multi - level clustering and accept a single - level clustering , we end up with the approach to document clustering which Salton and his co - workers have worked on extensively .", "label": "", "metadata": {}, "score": "57.66007"}
{"text": "In such an implementation , the tables in FIGS . 2 ( a ) , 3 ( a ) and 4 ( c ) are classes with contents .The other tables are classes with only pointers .Update , delete , and insert operations on indices may be carried out by the OODBMS through automatic view maintenance or programs to propagate among classes .", "label": "", "metadata": {}, "score": "57.66266"}
{"text": "2007 ] showed that users often repeat - edly visit the same web pages by conducting searches at search engines .In otherwords , users submit the same queries and click on the same search results .V , No .N , April 2013 . \u00b7 27user u clicks on documents with respect to query q , and \u03b2 is a smoothing factor .", "label": "", "metadata": {}, "score": "57.67694"}
{"text": "Compressed representa- tions of sequences and full - text indexes .ACM TALG , 3(2):article 20 , 2007 .J. Fischer and V. Heun .A new succinct representation of RMQ - information and improvements in the enhanced suffix array .In Proc .", "label": "", "metadata": {}, "score": "57.690247"}
{"text": "Automatic Taxonomy Generation in Search Results Using Phrases , application Ser .No .10/900,259 , filed on Jul. 26 , 2004 ; and .Phrase - Based Generation of Document Descriptions , application Ser .No .10/900,075 , filed on Jul. 26 , 2004 ; all of which are co - owned , and incorporated by reference herein .", "label": "", "metadata": {}, "score": "57.69139"}
{"text": "0009 ] In light of the above , further innovation to select relevant terms for query expansion is greatly desired .SUMMARY . [0010 ] Systems and methods for query expansion are described .In one aspect , new terms are extracted from a newly submitted query .", "label": "", "metadata": {}, "score": "57.704636"}
{"text": "This window is then shifted right M - N times , where M is the number of terms in the query .At each window position , there will be N terms ( or fewer ) terms in the window .These terms constitute a possible query phrase .", "label": "", "metadata": {}, "score": "57.743904"}
{"text": "Rickman [ 21 ] has described a way of introducing automatic feedback into a Boolean search .Goffman [ 22 ] has investigated an interesting search strategy based on the idea that the relevance of a document to a query is conditional on the relevance of other documents to that query .", "label": "", "metadata": {}, "score": "57.750153"}
{"text": "Session patterns summarize transitions among queries , clicks , and browses within search sessions .For example , Cao et al .[2008]and Boldi et al .[2008 ] take sequences of queries as sessions , and extract frequentquery sequences as session patterns .", "label": "", "metadata": {}, "score": "57.752968"}
{"text": "Given thecurrent instance , the algorithm compares it with the centroids of all the existingclusters .If the instance is close enough to one of the clusters , then it is added intothe cluster ; otherwise , a new cluster is created for the instance .", "label": "", "metadata": {}, "score": "57.805847"}
{"text": "Notice that the vector e acts as a rank source , the set of nodes where the surfer jumps when concluding that relevance is low .In the original PageRank [ 7 ] , all pages in the web graph act as rank sources .", "label": "", "metadata": {}, "score": "57.811394"}
{"text": "A more sophisticated type of keyword generalization might involve category switch ( to a different part of speech ) ; for example , nominalization would yield noun forms : ' ' acquisition ' ' , ' ' purchase ' ' , ' ' takeover ' ' , etc .", "label": "", "metadata": {}, "score": "57.891815"}
{"text": "Conclusion .We have attempted to present a coherent vision of a translingual information retrieval system , illustrating the broad range of possibilities with two specific examples .While we have already conducted initial experiments in this area ( Carbonell et al .", "label": "", "metadata": {}, "score": "57.907448"}
{"text": "Although the main reason for constructing these cluster representatives is to lead a search strategy to relevant documents , it should be clear that they can also be used to guide a search to documents meeting some condition on the matching function .", "label": "", "metadata": {}, "score": "57.962273"}
{"text": "4 ( b ) .Similarly , the rows corresponding to \" dealer \" , \" showroom \" , and \" SalesOffice \" in FIG .2 ( b ) collapse into a single row labeled sem 2 .The index for syntactically related words is usually much larger than the index for semantically related words because of several reasons .", "label": "", "metadata": {}, "score": "57.984703"}
{"text": "Web search takes into account two important aspects ofwebpages : representation and importance .The vector can then be indexed in a search systemand used in the vector space model , the BM25 model , or language model for IRfor relevance ranking .", "label": "", "metadata": {}, "score": "57.992752"}
{"text": "ep ] if that subarray were sorted .To get the first unique document number in D[sp .ep],1 ) .ep],1 + tfq , d1 ) .This lists the documents and their tf values in increasing document number order .", "label": "", "metadata": {}, "score": "58.028904"}
{"text": "Nguyen , H. et al . , \" Mining ' Hidden Phrase ' Definitions from the Web \" , Proceedings of the 5th Asian - Pacific Web Conference , Apr. 23 , 2002-Apr .Pretschner , A. et al . , \" Ontology Based Personalized Search \" , Tools with Artificial Intelligence , Proceedings of the 11th IEEE International Conference , Nov. 9 , 1999-Nov .", "label": "", "metadata": {}, "score": "58.05154"}
{"text": "The average sensitivity and selectivity values of each algorithm variant are presented at the end .( XLS 23 KB ) .1472 - 6947 - 10 - 64-S2 .XLS Additional file 2 : Table s2 - Sensitivity and Specificity of algorithms with respect to individual raters .", "label": "", "metadata": {}, "score": "58.08596"}
{"text": "Note that step 2 may be performed before step 1 .Additionally , steps 1 and 2 of the algorithm may be iteratively performed until no further merges are possible .When multiple entries are merged , the respective syn_doc_list for each of the entries is also merged accordingly by a union operation .", "label": "", "metadata": {}, "score": "58.101875"}
{"text": "However , such a na\u00a8\u0131ve method has some fatal drawbacks .First , thereexists position bias from the ranking list of webpages .Users usually scan the web - pages from the top .Those webpages ranked at higher positions may have a betterchance to be clicked .", "label": "", "metadata": {}, "score": "58.18298"}
{"text": "The overseeding may have worsened the impact of an additional difficulty .The number of terms from the GOC input set used to rank a GO node was typically very small - normally 1 - 3 terms - and only this subset of terms was passed on to the two evidence selection algorithms .", "label": "", "metadata": {}, "score": "58.202866"}
{"text": "The fallback case was to use the name filled in from the EBI TrEMBL human data .A script was applied to the TrEMBL names that generated variants of strings containing mismatched punctuation and parentheticals such as \" ( precursor ) \" or \" ( fragment ) \" which were felt not to be likely to occur directly in the text .", "label": "", "metadata": {}, "score": "58.238037"}
{"text": "FIG .7 illustrates the main functional operations of the presentation system 130 : .700 : Cluster documents according to topic clusters .702 : Generate document descriptions .704 : Eliminate duplicate documents .Each of these operations takes as an input the search results 701 and outputs modified search results 703 .", "label": "", "metadata": {}, "score": "58.25394"}
{"text": "The related phrase information of a given phrase is preferably stored in a format , such as a bit vector , which expresses the relative significance of each related phrase to the given phrase .For example , a related phrase bit vector has a bit for each related phrase of the given phrase , and the bits are ordered according to the prediction measures ( e.g. , information gain ) for the related phrases .", "label": "", "metadata": {}, "score": "58.274117"}
{"text": "V , No .N , April 2013 . \u00b7 23preferences learned from click - through data .Therefore , we can use a sequence of queries , called a query chain , and thecorresponding clicks in a search session by a user as an instance in learning ofpreferences .", "label": "", "metadata": {}, "score": "58.297657"}
{"text": "Selective Assimilation of the Results .Retrieved documents which are of interest are fully translated from the target language to the source ( query ) language , for assimilation by the analyst .This may itself be a multiple - stage process , as described below .", "label": "", "metadata": {}, "score": "58.339413"}
{"text": "A user confronted with an automatic retrieval system is unlikely to be able to express his information need in one go .He is more likely to want to indulge in a trial - and - error process in which he formulates his query in the light of what the system can tell him about his query .", "label": "", "metadata": {}, "score": "58.385265"}
{"text": "Searchers sometimes issue sim - ilar queries in the same search sessions .Jones et al .[2006 ] developed a method for discovering sim - ilar query pairs from session data .V , No .N , April 2013 .", "label": "", "metadata": {}, "score": "58.48164"}
{"text": "First , GOC may have been \" overseeded \" - since the input terms were derived from across the document , they may have matched very dispersed nodes in the GO .This would make it difficult for the GOC algorithm to confidently select a covering node for the input terms .", "label": "", "metadata": {}, "score": "58.516487"}
{"text": "Without query expansion , only documents in the slot ( E , E ) are retrieved .With both semantically and syntactical query expansion , all relevant documents are retrieved unless the documents are in the slot ( X , X ) .", "label": "", "metadata": {}, "score": "58.519905"}
{"text": "N , April 2013 .Given a new query in the current time slot , the method estimatesthe likelihoods of the query being generated from each of the models .A query is considered similar to another query if they share similarsearch intents .", "label": "", "metadata": {}, "score": "58.56863"}
{"text": "Table 1 shows the memory use of the methods on the two data sets .The Sada method exhibits a higher than expected memory usage because the protein collection has a high proportion of short documents .The .Page 10 .", "label": "", "metadata": {}, "score": "58.60734"}
{"text": "Now , documents from each cluster can be presented to the user in various ways .In one application , a fixed number of documents from each cluster can be presented , for example , the 10 top scoring documents in each cluster .", "label": "", "metadata": {}, "score": "58.60961"}
{"text": "As a result , when a search query using the anchor text is entered , the desired page is typically returned , even if in fact this page has little or nothing to do with the anchor text .Each phrase in the index 150 is also given a phrase number , based on its frequency of occurrence in the corpus .", "label": "", "metadata": {}, "score": "58.618973"}
{"text": "The system according to .claim 39 , wherein the execution of the query progresses in successive stages until a predetermined number of the ones of the documents associated with the corresponding ones of the higher granularity concepts are retrieved .The method according to . claim 47 , wherein each of the stages represents a class of expansion .", "label": "", "metadata": {}, "score": "58.622314"}
{"text": "Most work in this area is based on traditional Information Retrieval ( IR ) techniques , where each document is compared individually against the query .We compare the effectiveness of two fundamentally different techniques for keyword search of EHRs .Methods .", "label": "", "metadata": {}, "score": "58.63839"}
{"text": "The total number of elements probed ( and hence quantile queries ) to list all documents is at most 4m / fmin , where fminis the k - th highest frequency in the result .3We can determine this easily in O(1 ) time by maintaining a bitvector of size N. .", "label": "", "metadata": {}, "score": "58.66269"}
{"text": "A possible phrase p is removed from the possible phrase list 206 and placed on the good phrase list 208 if : .These thresholds are scaled by the number of documents in the partition ; for example if 2,000,000 documents are crawled in a partition , then the thresholds are approximately doubled .", "label": "", "metadata": {}, "score": "58.679733"}
{"text": "that their corresponding documents are less dissimilar than some specified level of dissimilarity .Now , one way of representing a cluster is to select a typical member from the cluster .A simple way of doing this is to find that document which is linked to the maximum number of other documents in the cluster .", "label": "", "metadata": {}, "score": "58.745308"}
{"text": "Starting with the highest phrase number as the first candidate phrase , the search system 120 determines if there is another candidate phrase within a fixed numerical distance within the sorted list , i.e. , the difference between the phrase numbers is within a threshold amount , e.g. 20,000 .", "label": "", "metadata": {}, "score": "58.74824"}
{"text": "To deal with the problem , the authors proposed the second model , the query - setmodel .The model uses frequent query term sets as annotations .Each frequent term combination is called arelevant set .Then , the webpage is represented by a vector of relevant sets weightedby TF - IDF .", "label": "", "metadata": {}, "score": "58.75249"}
{"text": "In many cases , certain documents , while having different content from each other , are sufficiently related to form a meaningful group of related documents , essentially a cluster .Most users however , do not review beyond the first 30 or 40 documents in the search results .", "label": "", "metadata": {}, "score": "58.76476"}
{"text": "Efficient algorithms for document retrieval problems .In Proc . 13thSODA , pp\u02d9657 - 666 , 2002 .G. Navarro and V. M\u00a8 akinen .Compressed full - text indexes .Surveys , 39(1):article 2 , 2007 .M. Persin , J. Zobel , and R. Sacks - Davis .", "label": "", "metadata": {}, "score": "58.80018"}
{"text": "As a result , this data - driven clustering of related phrases avoids the biases that are inherent in any manually directed \" editorial \" selection of related terms and concepts , as is common in many systems .Indexing Documents with Phrases and Related Phrases .", "label": "", "metadata": {}, "score": "58.825466"}
{"text": "The analyst types in a source language query Q S ; .Parallel corpus ( source half ) is searched by an IR engine using Q S ; .One of the following methods is used to search the TL document database : .", "label": "", "metadata": {}, "score": "58.876694"}
{"text": "right child ) .Thus , two wavelet tree rank operations are avoided ; an important practical improvement .We now recast Gagie et al . 's algorithm .When listing all distinct documents in D[sp .ep ] , the algorithm of Gagie et al . can be thought of as a depth - first traversal of the wavelet tree that does not follow paths which do not lead to document numbers not occurring in D[sp .", "label": "", "metadata": {}, "score": "58.931206"}
{"text": "The indexing system 110 operates on an index 150 and data repository 160 of phrase data .These data repositories are further described below .Phrase Identification .The phrase identification operation of the indexing system 110 identifies \" good \" and \" bad \" phrases in the document collection that are useful to indexing and searching documents .", "label": "", "metadata": {}, "score": "58.93557"}
{"text": "There are many examples of matching functions in the literature .Perhaps the simplest is the one associated with the simple matching search strategy .If M is the matching function , D the set of keywords representing the document , and Q the set representing the query , then : . is another example of a matching function .", "label": "", "metadata": {}, "score": "58.945892"}
{"text": "( 13 ) PubMed View Article .Varadarajan R , Hristidis V , Raschid L : Explaining and Reformulating Authority Flow Queries .In Proceedings of IEEE International Conference on Data Engineering ( ICDE ) .Cancun ; 2008:883 - 892 .", "label": "", "metadata": {}, "score": "58.977154"}
{"text": "In this manner , for a given document and a given phrase , the related phrase information can be used to score the document .The value of the bit vector itself ( as a value ) may be used as the document score .", "label": "", "metadata": {}, "score": "58.988472"}
{"text": "The system according to . claim 27 , wherein the higher granularity semantic concepts each contain synonyms .The system according to . claim 26 , wherein in the indexer replaces only ones of the words in the preliminary index meeting a predetermined criterion by the corresponding higher granularity concepts .", "label": "", "metadata": {}, "score": "59.00809"}
{"text": "The cosine correlation is now simply .Although serial searches are acknowledge to be slow , they are frequently still used as parts of larger systems .They also provide a convenient demonstration of the use of matching functions .Suppose there are N documents Di in the system , then the serial search proceeds by calculating N values M(Q , Di ) the set of documents to be retrieved is determined .", "label": "", "metadata": {}, "score": "59.07738"}
{"text": "User behavior is the most intensively studiedcontext information in the state - of - the - art literature .In this case , contextualization is very similar to personalization .Therefore , all the personalized techniques discussed in Section 5.1,including the click - based methods , term - based methods , and topic - based methodsare applicable here .", "label": "", "metadata": {}, "score": "59.09282"}
{"text": "For each pair of query phrases the search system 120 determines the appropriate case by looking up the related phrase bit vector of the query phrases Qp .The search system 120 proceeds by retrieving the posting list for query phrase Q 1 , which contains the documents containing Q 1 , and for each of these documents , a related phrase bit vector .", "label": "", "metadata": {}, "score": "59.1052"}
{"text": "A further aspect of the indexing system 110 is the ability to annotate 504 each document d during the indexing process with information that provides for improved ranking during subsequent searches .The annotation process 506 is as follows .A given document d in the document collection may have some number of outlinks to other documents .", "label": "", "metadata": {}, "score": "59.112587"}
{"text": "It starts with a brief explanation about the survey and then query results are displayed .Each result displays a brief description of the clinical entity in tabular format along with links to the complete description and adjacent entities .Sample \" Full Description \" of HospitalizationID 2406 for query \" respiratory distress \" .", "label": "", "metadata": {}, "score": "59.12242"}
{"text": "2002].5.2 ContextualizationContextualization is a complementary task to personalization .Personalization methods takeinto account an individual user 's preference over a long search history .Suppose that a userraises query qt .A contextualization method characterizes the search context andleverages the context information in search .", "label": "", "metadata": {}, "score": "59.15397"}
{"text": "J. Zobel and A. Moffat .Inverted files for text search engines .ACM Computing Surveys , 38(2):1 - 56 , 2006 .In Proc . 4thACM Computing Filtered document retrieval with .Page 13 .A Basic IR Concepts Relevance Ranking .", "label": "", "metadata": {}, "score": "59.17209"}
{"text": "V . qf . )V .W .f . qf . )W .W .f .Basically , all the co - occurrence terms involving the S form are compressed by a factor of f and result in substantial savings in this table when compared to that in FIG .", "label": "", "metadata": {}, "score": "59.19881"}
{"text": "N , April 2013 .18 \u00b7 webpage .Furthermore , the distri - bution of anchor texts also follows the zipf 's distribution , and the tail webpages(unpopular ) webpages usually do not have enough anchor texts .Thus , queries asannotations are explored.3.1.1 Queries as Annotations .", "label": "", "metadata": {}, "score": "59.215187"}
{"text": "In order to evaluate the usefulness of more advanced techniques in a given domain , experiments must be undertaken to measure the recall and precision of existing methods ( e.g. , keyword search ) vs. more sophisticated techniques such as template matching and partial template matching .", "label": "", "metadata": {}, "score": "59.252586"}
{"text": "[ 10 ] MATLAB and Python implementations of these fast algorithms are available .Unlike Gorrell and Webb 's ( 2005 ) stochastic approximation , Brand 's algorithm ( 2003 ) provides an exact solution .In recent years progress has been made to reduce the computational complexity of SVD ; for instance , by using a parallel ARPACK algorithm to perform parallel eigenvalue decomposition it is possible to speed up the SVD computation cost while providing comparable prediction quality .", "label": "", "metadata": {}, "score": "59.259308"}
{"text": "In this case , the user transits from the browse stateto the search state .On the other way , a user may also transit from the searchstate to the browse state .V , No .N , April 2013 . \u00b7", "label": "", "metadata": {}, "score": "59.26362"}
{"text": "The sequence is over the documents inthe search result list .The probability of being attracted depends only onthe url ( 5b ) .In other words , measures the perseverance ofthe user4 .If the user did not examine the position i , he willnot examine the subsequent positions ( 5 g ) .", "label": "", "metadata": {}, "score": "59.276634"}
{"text": "A proportional presentation would use a proportionate number of documents from each cluster , relative to the total number of documents .Topic Based Document Descriptions .A second function of the presentation system 130 is the creation 702 of a document description that can inserted into the search result presentation for each document .", "label": "", "metadata": {}, "score": "59.286392"}
{"text": "Guo et al .[2008 ] developed a discriminative approach .Duan and Hsu [ 2011 ] pro - posed generative approaches to spelling error correction .See also [ Li et al .2012].ACM Transactions on Computational Logic , Vol .", "label": "", "metadata": {}, "score": "59.304314"}
{"text": "Hwang H , Hristidis V , Papakonstantinou Y : ObjectRank : A System for Authority - based Search on Databases .In Proceedings of Association for Computing Machinery Special Interest Group in Management of Data ( SIGMOD ) .Chicago ; 2006:796 - 798 .", "label": "", "metadata": {}, "score": "59.345314"}
{"text": "Consider the example tree of Fig .1 , where we list the distinct numbers in D[3 . .13].A depth - first traversal begins by following the leftmost path to leaf 8 .As we step left to a child , we take note of the number of 0-bits in the range used in its parent node , labelled n0on each branch .", "label": "", "metadata": {}, "score": "59.363983"}
{"text": "CROSS REFERENCE TO RELATED APPLICATIONS .The application is related to the following co - pending applications : .Phrase Identification in an Information Retrieval System , application Ser .No .10/900,021 , filed on Jul. 26 , 2004 ; .", "label": "", "metadata": {}, "score": "59.394714"}
{"text": "The method according to .claim 6 , wherein the higher granularity syntactical concepts each contain words co - occurring in ones of the documents above a threshold level of frequency .The method according to . claim 1 , wherein in the replacing step , ones of the words in the preliminary index having multiple meanings are replaced by multiple ones of the corresponding higher granularity concepts .", "label": "", "metadata": {}, "score": "59.413452"}
{"text": "( 7 ) View Article .Brin S , Page L : The anatomy of a large - scale hypertextual web search engine .Computer Networks 1998 , 30 ( 1 - 7 ) : 107 - 117 .Haveliwala T : Topic - Sensitive PageRank .", "label": "", "metadata": {}, "score": "59.451477"}
{"text": "Differing provisions from the publisher 's actual policy or licence agreement may be applicable . \"However , the IR indexes suffer from some drawbacks such as big size , search performance and security .Indexing plays very important role in databases performances and now the same concept can be used for developing secure databases[13,14,15].", "label": "", "metadata": {}, "score": "59.46434"}
{"text": "This is a tall order , and unfortunately there is no theory enabling one to select the right kind of cluster representative .One can only proceed experimentally .There are a number of ' reasonable ' ways of characterising clusters ; it then remains a matter for experimental test to decide which of these is the most effective .", "label": "", "metadata": {}, "score": "59.469307"}
{"text": "It will always be arbitrary since there is no way of telling in advance what value for each query will produce the best retrieval .Before we can sensibly talk about search strategies applied to clustered document collections , we need to say a little about the methods used to represent clusters .", "label": "", "metadata": {}, "score": "59.52422"}
{"text": "f ik ( q ) ( w i ( q ) , D k ) f ( q ) ( w i ( q ) ) ) , wherein w.sub.j.sup .( d ) and w.sub.i.sup .( q ) are an arbitrary document term and query term respectively , and P(w.sub.j.sub .", "label": "", "metadata": {}, "score": "59.53387"}
{"text": "In practice , given the small and weakly coherent sets of terms that were generated , this created great difficulty for reliably selecting a contiguous chunk of text focused on that GO node .This would have impacted the quality of the evidence text selected , and hence our overall evaluation results .", "label": "", "metadata": {}, "score": "59.544296"}
{"text": "We therefore decided to pursue a strategy in which lexical overlaps between terms in the document and terms in the set of GO node labels were used to identify relevant GO nodes .The GO , however , has a hierarchical structure such that evidence for the relevance of a particular GO node is also evidence for the relevance of its parent node .", "label": "", "metadata": {}, "score": "59.596146"}
{"text": "Paired precision ( P ) and recall ( R ) results as a function of specificity broken out by inclusive \" family groups \" as mentioned in the text .Note that recall is bounded above by precision , due to the need to cut off the number of GOC cluster heads considered based on the number of requested results .", "label": "", "metadata": {}, "score": "59.61022"}
{"text": "Text search engines return a set of k documents ranked by similarity to a query .Typically , documents and queries are drawn from natural language text , which can readily be partitioned into words , allowing optimizations of data structures and algorithms for ranking .", "label": "", "metadata": {}, "score": "59.61123"}
{"text": "It also mitigates the problem with polysemy , since components of polysemous words that point in the \" right \" direction are added to the components of words that share a similar meaning .Conversely , components that point in other directions tend to either simply cancel out , or , at worst , to be smaller than components in the directions corresponding to the intended sense .", "label": "", "metadata": {}, "score": "59.659355"}
{"text": "One way to do this is to concatenate the selected sentences , and then take use a hash table to store the document identifier .For example , the presentation system 130 can hash the concatenated sentences , and if the hash table already has an entry for the hash value , then this indicates that the current document and presently hashed document are duplicates .", "label": "", "metadata": {}, "score": "59.67886"}
{"text": "Each node represents an object of the database and contains excerpts which are attribute values of the object in the source relational database .CO assumes that each node has a set of attribute name - value pairs .For example , the \" Hospitalization \" nodes of Figure 1 have TimeStampCreated , history , and allergies attributes .", "label": "", "metadata": {}, "score": "59.74607"}
{"text": "JASIS , 47(10):749 - 764 , 1996 .J. M. Ponte and W. B. Croft .A language modeling approach to information retrieval .In Proc . 21th ACM SIGIR , pp\u02d9275 - 281 , 1998 .S. Puglisi , W. Smyth , and A. Turpin .", "label": "", "metadata": {}, "score": "59.755226"}
{"text": "Each document ID substantially uniquely identifies a particular document that was selected by the user from a document list .In one implementation , one or more of the documents IDs are Universal Resource Locators ( URLs ) .The document list was returned to the user by a search engine ( i.e. , see the search engine 204 of \" other modules \" ) responsive to searching for information that includes keywords indicated by the term(s ) of the query .", "label": "", "metadata": {}, "score": "59.818123"}
{"text": "The choice of this prior is naturalbecause the beta distribution is conjugate to the binomialdistribution .Track : Data Mining / Session : Click Models3Fig .A user 's search behavior can be modeled by the Dynamic Bayesian network model ( ex - tracted from [ Chapelle and Zhang 2009 ] ) .", "label": "", "metadata": {}, "score": "59.824776"}
{"text": "The priority of a pair favors larger ranges , and ties are broken in favor of deeper nodes .Page 7 . one or more 0-bits ( resp .1-bits ) then at least one document to report lies on the left subtree ( resp .", "label": "", "metadata": {}, "score": "59.835506"}
{"text": "10 illustrates a sequence for progressive query processing .FIG .11 illustrates a sequence for progressive query processing where a keyword may be assigned a level of importances .FIG .12 illustrates a physical embodiment which may be used to implement the present invention .", "label": "", "metadata": {}, "score": "59.8365"}
{"text": "[ 0042 ] FIG .3 shows that correlations between terms of newly submitted queries and document terms can be established via information maintained in query sessions from a query log .Paths between respective terms 302 of a newly submitted query 214 ( FIG .", "label": "", "metadata": {}, "score": "59.855194"}
{"text": "The method of . claim 2 , wherein the document discarded has a lower document significance measure than the other document .The method of .claim 3 , wherein the document significance measure includes a page rank of the document .", "label": "", "metadata": {}, "score": "59.856247"}
{"text": "Else we check the frequency of the the minimum item .If it is less than fX[m/4 ] , we extract the minimum and insert ( X[m/4],fX[m/4 ] ) .We then perform the same check and update with ( X[3m/4],fX[3m/4 ] ) .", "label": "", "metadata": {}, "score": "59.87359"}
{"text": "Hagen et al .[2011 ] proposed an unsupervised approach to query segmentation .The advantage of unsupervised approach is that no training is needed .Althoughthe method proposed by them is very simple , it works very well in experimentations .", "label": "", "metadata": {}, "score": "59.89634"}
{"text": "( d ) .vertline . D.sub.k ) depends on the frequency of occurrence of w.sub.j.sup .( d ) in the document D.sub.k , as well as the occurrence of the term w.sub.j.sup .( d ) in the whole document collection .", "label": "", "metadata": {}, "score": "59.940594"}
{"text": "It is the aim of every retrieval strategy to retrieve the relevant documents A and withhold the non - relevant documents ' A. Unfortunately relevance is defined with respect to the user 's semantic interpretation of his query .From the point of view of the retrieval system his formulation of it may not be ideal .", "label": "", "metadata": {}, "score": "59.9573"}
{"text": "Summarization is particularly useful for TIR because document access is far faster if only the summaries of retrieved target language documents need be translated , with further material only translated upon drill - down requests .( Translation is a much more computation - intensive and time - consuming process than summarization . )", "label": "", "metadata": {}, "score": "59.96528"}
{"text": "To find the document a given position i is contained in we simply ( binary ) search for the smallest value greater than i in this array .Because we scan text blocks left - to - right , positions of occurrence are mapped to documents in increasing order , allowing the amount of the mapping array searched to be reduced as block scanning proceeds : a small optimization .", "label": "", "metadata": {}, "score": "59.978966"}
{"text": "A few remarks about this strategy are in order : .( 1 ) we assume that effective retrieval can be achieved by finding just one cluster ; .( 2 ) we assume that each cluster can be adequately represented by a cluster represent- ative for the purpose of locating the cluster containing the relevant documents ; .", "label": "", "metadata": {}, "score": "59.991962"}
{"text": "Evaluation results on the evidence text selected for Task 2.1 .A \" perfect \" evaluation indicates that the evidence text refers to both the correct protein and the correct GO node .A \" generally \" evaluation indicates that it refers to the correct protein and that the reference to a GO node is somewhat too general .", "label": "", "metadata": {}, "score": "60.013706"}
{"text": "As in monolingual IR , the documents retrieved must be ranked .We believe a new metric , MMR , described below , is much better suited to the current deluge of information than previous techniques .Summarization of the Results .", "label": "", "metadata": {}, "score": "60.041008"}
{"text": "The users were asked to select the top 5 results that were both relevant and important for each query .These relevance / non - relevance ratings of users for the results of various ranking algorithms were used to compute specificity and sensitivity scores .", "label": "", "metadata": {}, "score": "60.043144"}
{"text": "Using sequences of keywords as queries , sensitivity and specificity were measured by two physicians for a set of 11 queries related to congenital cardiac disease .Results .Our pilot evaluation showed that CO outperforms BM25 in terms of sensitivity ( 65 % vs. 38 % ) by 71 % on average , while maintaining the specificity ( 64 % vs. 61 % ) .", "label": "", "metadata": {}, "score": "60.04589"}
{"text": "Some techniques have been proposed for stemming .Such techniques include analysis of occurrence frequency , and employing morphological rules ( e.g. converting all words to root form ) or lexical dictionaries .However , the size of indices for words associated by syntactical co - occurrence relationships is too large to search efficiently .", "label": "", "metadata": {}, "score": "60.053444"}
{"text": "Notice that the rest of the 14,242 entities are non - hospitalization ones comprising of patient , employee , medication , diagnosis , diagnostics , cardiac , events , and lab records .Pilot User Study .A pilot user study was conducted to compare the effectiveness , by evaluating the quality of results produced by two different techniques for keyword search in EHRs : traditional BM25 technique and CO -- a newly proposed authority flow ranking technique .", "label": "", "metadata": {}, "score": "60.076653"}
{"text": "This is the default CO variant .Given that d is high , a result may not contain the query keywords , if many entities that contain the keywords link to the result .As mentioned above , small d favours focused results that contain the actual query keywords .", "label": "", "metadata": {}, "score": "60.088734"}
{"text": "According to a study by the present inventors on parsing 2,904 documents , only 42 % of keywords can be found in WordNet , which has more than 60,000 words .See G. A. Miller . \" \" Nouns in WordNet : A Lexical Inheritance System \" In International Journal of Lexicography 3 ( 4 ) , 1990 , pages 245 - 264 .", "label": "", "metadata": {}, "score": "60.11547"}
{"text": "( q ) , D.sub.k ) is the number of query sessions in which w.sub.i.sup .( q ) and document D k appear together , f.sup .( q)(w.sub.i.sup .( q ) ) is a number of query sessions that contain term w.sup.i.sup .", "label": "", "metadata": {}, "score": "60.149315"}
{"text": "The search strategy is in part a serial search .It proceeds by first finding the best ( or nearest ) cluster(s ) and then looking within these .The second stage is achieved by doing a serial search of the documents in the selected cluster(s ) .", "label": "", "metadata": {}, "score": "60.158127"}
{"text": "[0052 ] An Exemplary Procedure .[ 0053 ] FIG .5 shows an exemplary procedure 500 for query expansion .The operations of this procedure are described in reference to the program module and data components of FIGS . 1 and 2 .", "label": "", "metadata": {}, "score": "60.227783"}
{"text": "By combining the probabilities of all query terms , the joint probability for every document term is obtained according to the following : . P(w.sub.j.sup .( d ) .PI .( P(w.sub.j.sup .( d ) .vertline.w.sub.i.s- up .", "label": "", "metadata": {}, "score": "60.269238"}
{"text": "References 1 . V. Anh and A. Moffat .Pruned query evaluation using pre - computed impacts .In Proc . 29thACM SIGIR , pp\u02d9372 - 379 , 2006 . A. Apostolico .The myriad virtues of subword trees .In Combinatorial Algorithms on Words , NATO ISI Series , pages 85 - 96 .", "label": "", "metadata": {}, "score": "60.285305"}
{"text": "In contrast , a structured database could have a variety of entity types and relationships [ 12 ] ( e.g. , in the EHR dataset of the cardiovascular division of Miami Children 's Hospital there are relationships like patient - to - hospitalization , hospitalization - to - exam , and so on ) .", "label": "", "metadata": {}, "score": "60.35738"}
{"text": "By also trying the right child each time we have gone to the left , all the distinct successive d values in the interval are discovered .They show that it is possible to get the i - th document in the interval directly in O(logN ) time .", "label": "", "metadata": {}, "score": "60.372948"}
{"text": "Clusters are identified from related phrases that have very high prediction measure between all of the phrases in the cluster .Clusters can be used to organize the results of a search , including selecting which documents to include in the search results and their order , as well as eliminating documents from the search results .", "label": "", "metadata": {}, "score": "60.3898"}
{"text": "Results .Overall , the evidence text was judged as \" perfect \" if it scored \" high \" on both of the criteria , and as \" generally \" when the protein was correct but the GO reference was \" generally \" .", "label": "", "metadata": {}, "score": "60.39939"}
{"text": "Figure 8gives an illustration of the model .Variables au and su represent attractiveness and relevance , respec - tively .Ci is the only observed variable .The variables in the box are repeated frompositions 1 to n. The following equations hold in the model .", "label": "", "metadata": {}, "score": "60.523228"}
{"text": "Let w.sub.j.sup .( d ) and w.sub.i.sup .( q ) be an arbitrary document term and query term respectively , wherein the query term for purposes of equations 4 - 7 are respective ones of the query terms recorded in the query log(s ) 210 ( FIG .", "label": "", "metadata": {}, "score": "60.612286"}
{"text": "Theimportance of pages can be propagated in the web graph where vertices are pagesand edges are hyperlinks .The PageRankscores of web pages can be calculated iteratively .In other words , PageRank is adiscrete - time Markov process on the web graph .", "label": "", "metadata": {}, "score": "60.628807"}
{"text": "Hence , documents are viewed as vectors in a very high dimensional term space and the individual elements in the vector represent the frequency of occurrence of a particular term in a given document .More sophisticated measures based on both global and local weightings can also be used .", "label": "", "metadata": {}, "score": "60.651302"}
{"text": "This information is then recorded in conjunction with each good phrase g j .In one embodiment , the cluster number is determined by a cluster bit vector that also indicates the orthogonality relationships between the phrases .The cluster bit vector is a sequence of bits of length n , the number of good phrases in the good phrase list 208 .", "label": "", "metadata": {}, "score": "60.664104"}
{"text": "The columns g k in each row g j of the co - occurrence matrix 212 are then sorted by the information gain values I(g j , g k ) , so that the related phrase g k with the highest information gain is listed first .", "label": "", "metadata": {}, "score": "60.68848"}
{"text": "Phrase Based Personalization of Search .Another aspect of the search system 120 is the capability to personalize 606 or customize the ranking of the search results in accordance with a model of the user 's particular interests .In this manner , documents that more likely to be relevant to the user 's interests are ranked higher in the search results .", "label": "", "metadata": {}, "score": "60.794838"}
{"text": "Page 9 .Time per document listed as in Fig .2 , with 25th and 75th percentiles ( boxes ) , median ( solid line ) , and outliers ( whiskers ) .Peak memory use during search ( MB ) for the algorithms on wsj and protein .", "label": "", "metadata": {}, "score": "60.802895"}
{"text": "Their algorithm iscompletely content - ignorant in the sense that it makes no use of the actual contentsof the queries and the URLs , but is based on only how they co - occur within theclick - through bipartite .Although the algorithm is simple , it can discover highquality query clusters .", "label": "", "metadata": {}, "score": "60.818085"}
{"text": "First , user clicks can beconsidered as implicit feedback on the relevance of documents .Therefore , they canbe used as external tags of web pages as well .In addition , the browse logs can beleveraged for calculating the importance of web pages .", "label": "", "metadata": {}, "score": "60.85824"}
{"text": "For example , the KANT system ( Mitamura et al . , 1991 ) uses a conceptual form called interlingua to model the linguistic relations among the source terms in a deep semantic representation .The interlingua captures domain actions , objects , properties , and relations in a manner which is language - independent , and is used as an intermediate form during translation .", "label": "", "metadata": {}, "score": "60.859634"}
{"text": "To the degree that we can enhance the query translation by template extraction and deeper semantic analysis , as described later in this section , we should be able to recover the loss in precision .Once the query is expanded / translated into Q T , it is used for retrieval , and the retrieved D T 's can be summarized and/or translated as discussed in following sections .", "label": "", "metadata": {}, "score": "60.86645"}
{"text": "While PageRank applies authority flow ranking on World Wide Web ( WWW ) which is largely unstructured , EHRs are typically semi - structured ( XML format ) or completely structured ( relational format ) .A tiny fraction of the Web uses the semi - structured XML format ( HTML tags are mostly for presentation purposes , and hence do not generally define semantic entities ) .", "label": "", "metadata": {}, "score": "60.870735"}
{"text": "An information retrieval system uses phrases to index , retrieve , organize and describe documents .Phrases are identified that predict the presence of other phrases in documents .Documents are the indexed according to their included phrases .Related phrases and phrase extensions are also identified .", "label": "", "metadata": {}, "score": "60.89492"}
{"text": "The presentation system 130 then stable sorts this set of user related phrases Ur according to the value of the bit vectors themselves , prepending the sorted list to the list of query related phrases Qr , and removes any duplicate phrases .", "label": "", "metadata": {}, "score": "60.898235"}
{"text": "As described above , for any given phrase g j , each document d in the g j 's posting list has an associated related phrase bit vector that identifies which related phrases g k and which secondary related phrases g l are present in document d. The more related phrases and secondary related phrases present in a given document , the more bits that will be set in the document 's related phrase bit vector for the given phrase .", "label": "", "metadata": {}, "score": "60.914528"}
{"text": "The expansion term are identified at least in part on the new terms and probabilistic correlations from information in a query log .The query log information includes one or more query terms and a corresponding set of document identifiers ( IDs ) .", "label": "", "metadata": {}, "score": "60.917423"}
{"text": "The expansion term are identified at least in part on the new terms and probabilistic correlations from information in a query log .The query log information includes one or more query terms and a corresponding set of document identifiers ( IDs ) .", "label": "", "metadata": {}, "score": "60.917423"}
{"text": "Once the user selects a translated summary for further investigation , the selected document is translated by the MEMT system , with KBMT , EBMT , transfer , and possibly other MT engines combining to give the user an initial , fully - automatic rough translation .", "label": "", "metadata": {}, "score": "60.923225"}
{"text": "Statistical properties for the 44,693 randomly generated English word queries from the wsj collection .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .", "label": "", "metadata": {}, "score": "60.92785"}
{"text": "Generalizing the surface form ( through morphological variation , category switch , and synonym match ) can help , but what if we want to retrieve documents from multiple languages ?We can extend the notion of a ' ' thesaurus ' ' for keyword synonyms to include terms from multiple languages , but this becomes difficult to manage as the lexicon of search terms and number of languages grows .", "label": "", "metadata": {}, "score": "60.9307"}
{"text": "Knowledge - Based Methods for Translingual IR .When the translingual information retrieval is within a well - defined domain , we expect that the infusion of knowledge - based techniques from the fields of natural language processing ( NLP ) and machine translation ( MT ) can provide the following benefits : .", "label": "", "metadata": {}, "score": "60.968132"}
{"text": "[ 0012 ]FIG .1 is a block diagram of an exemplary computing environment within which systems and methods for query expansion may be implemented .[ 0013 ] FIG .2 is a block diagram that shows further exemplary aspects of application programs and program data of the exemplary computing device of FIG .", "label": "", "metadata": {}, "score": "60.97884"}
{"text": "Note that we are not using \" cluster \" here in the sense of traditional clustering , e.g. k -means , but rather to indicate a set of nodes that are spatially close based on the structure of the ontology .A brief technical description and toy example of the base GOC 's operation is provided in Appendix A , and see elsewhere [ 3 ] .", "label": "", "metadata": {}, "score": "61.022217"}
{"text": "Ranking retrieved documents : Maximal Marginal Relevance .Searching any very large document data base , including the World Wide Web , quickly leads to the realization that there are not just more documents than anyone could ever assimilate , but also there are more relevant documents than anyone could ever assimilate .", "label": "", "metadata": {}, "score": "61.047626"}
{"text": "Before conducting a user survey , we tested several values of the damping factor in the range [ 1 ] and found that two values - 0.3 and 0.85 - gave reasonable results .Also , we wanted to test a smaller and a higher damping factor for reasons mentioned before .", "label": "", "metadata": {}, "score": "61.08862"}
{"text": "Q .BQ . ) mf . log .Number .Of .Rows .[ .b . ) .] m .n . ) g .h . ) log .Number .Of .Rows .[ .", "label": "", "metadata": {}, "score": "61.146465"}
{"text": "N , April 2013 . \u00b7 17entities with the patterns .Finally , it calculates the context similarities betweenthe mined entities and the seed entities , and ranks the new entities based on theircontext similarity scores .With the patterns , new entities of the class , such as \" viagra \" and \" phentermine \" , can be mined .", "label": "", "metadata": {}, "score": "61.18856"}
{"text": "We demonstrate the functionality of the framework by recomposing succinct solutions for document retrieval .\" We have shown that our structure can use , instead , O(n(log \u03c3 + log D ) ) bits for the tf measure ( and slightly more for others ) , but the constants are still large .", "label": "", "metadata": {}, "score": "61.194546"}
{"text": "The damping factor d determines the portion of ObjectRank that an object transfers to its neighbors as opposed to keeping itself .Changing the damping factor d offers another calibration opportunity .In particular , larger values of d favor nodes pointed by high - authority nodes through single - edge or multi - edge paths , while smaller values of d favor nodes containing the actual keywords -- nodes in the base set -- or their immediate neighbors .", "label": "", "metadata": {}, "score": "61.22359"}
{"text": "FIG .1 shows that words used in HyperText Markup Language ( HTML ) documents related to the words \" car \" and \" dealer \" may vary from one document to another .Languages other than HTML , such as Extensible Markup Language ( XML ) and Standard Generalized Markup Language ( SGML ) , may be used .", "label": "", "metadata": {}, "score": "61.325817"}
{"text": "2002 ; Wen et al . 2001].A click - through bipartite graph in practice can be extremely large .How toACM Transactions on Computational Logic , Vol .V , No .N , April 2013 .The algorithm needsonly one scan of the data and the average case time cost is linear to the numberof instances .", "label": "", "metadata": {}, "score": "61.35005"}
{"text": "IR techniques view each document as an independent entity to discover relevant pages and ignore the link structure of the document collection .Quality of results could be improved by also considering link structure to discover relevant pages [ 6 ] .", "label": "", "metadata": {}, "score": "61.383595"}
{"text": "So far very little has been said about the actual process by which the required information is located .In the case of document retrieval the information is the subset of documents which are deemed to be relevant to the query .", "label": "", "metadata": {}, "score": "61.393024"}
{"text": "A weight cij may be associated with an edge eij indicating thetotal number of times URL uj is clicked with respect to query qi .Click - throughbipartite is probably the most widely used data structure in log mining .Click patterns summarize positions of clicked URLs insearch results of queries .", "label": "", "metadata": {}, "score": "61.40495"}
{"text": "Each such concept will be denoted as C i .The entries of the form S - S will contribute additional concepts and those of the form S - P will contribute proper names .The entries of the form P - S will contribute additional concepts and those of the form P - P will contribute additional proper names .", "label": "", "metadata": {}, "score": "61.41745"}
{"text": "Thus , a phrase g j predicts another phrase g k when the information gain I of g k in the presence of g j exceeds a threshold .And good phrase g j predicts good phrase g k where : .", "label": "", "metadata": {}, "score": "61.42388"}
{"text": "Finally , we would like to explore the interaction between TFIDF weights and the importance of a term in the GO .Preliminary analysis suggests that there are very frequent terms in the GO with relatively high TFIDF scores in the corpus ; this would unfairly value those terms in GOC and exacerbate the overseeding problem .", "label": "", "metadata": {}, "score": "61.455986"}
{"text": "Appendix A covers the related basic concepts .Page 3 .Suffix Arrays and Self - Indexes .The suffix array A[1 .n ] of a text collection T of length n is a permutation of ( 1 ... n ) , so that the suffixes of T , starting at the consecutive positions indicated in A , are lexicographically sorted [ 10 ] : T [ A[i].", "label": "", "metadata": {}, "score": "61.48269"}
{"text": "14 ] applies authority flow ranking over XML document collections .We use ObjectRank [ 12 , 15 ] , which applies keyword query based authority flow ranking techniques on structured relational databases , as our experimental dataset is a relational anonymized EHR database .", "label": "", "metadata": {}, "score": "61.494484"}
{"text": "First , query expansion will be discussed .FIG .6 shows an example of query expansion under a prior query expansion scheme .A query \" retrieve documents containing the words car and dealer \" is rewritten as shown by adding additional words relevant to car and dealer .", "label": "", "metadata": {}, "score": "61.498074"}
{"text": "See W. B. Croft et al . , \" Corpus - Specific Stemming Using Word Form Co - occurrence , \" Proceedings of the Fourth Annual Symposium , 1994 .The above techniques that expand a query term to a set of semantically related terms are called global analysis .", "label": "", "metadata": {}, "score": "61.504044"}
{"text": "ACM Transactions on Computational Logic , Vol .V , No .N , April 2013 . 30 \u00b7 \u017d\u0110\u01b5\u0175\u011e\u0176\u019a\u0190D\u0102\u019a\u0110\u015a\u015d\u0176\u0150\u0128\u037e\u018b \u0355 \u011a\u0355 \u0189 \u037f^\u011e\u0102\u018c\u0110\u015a\u036c\u018c\u017d\u01c1\u0190\u011e\u017d\u0150\u0190\u017d\u0176\u019a\u011e\u01c6\u019aW\u018c\u017d\u0128\u015d\u016f\u011e\u0190\u017d\u0176\u019a\u011e\u01c6\u019aW\u018c\u017d\u0128\u015d\u016f\u011e \u0128\u017d\u018c \u018bK\u0128\u0128\u016f\u015d\u0176\u011eK\u0176\u016f\u015d\u0176\u011e\u0359\u018b\u018b\u017d\u0176\u019a\u011e\u01c6\u019a \u015d\u0176\u0128\u017d\u018c\u0175\u0102\u019a\u015d\u017d\u0176\u018bK\u0189\u019a\u015d\u017d\u0176 \u03eeK\u0189\u019a\u015d\u017d\u0176 \u03edFig .The general framework of a contextualized search system .A contextualized search systemcharacterizes the search context and leverages the context information in search .", "label": "", "metadata": {}, "score": "61.51195"}
{"text": "The algorithm creates and maintains an inverted index about all thenon - zero elements of the instances in the existing clusters .The random walk usually takes several stepsof walk and stops .It is observed that the role of self - transition probability is veryimportant .", "label": "", "metadata": {}, "score": "61.516155"}
{"text": "4 shows exemplary probabilistic correlations between query terms 302 ( newly submitted or logged session terms ) and document terms 310 .The degree of correlation between a query term and a document term is the conditional probability of a document term 's appearance on condition that the query term is used .", "label": "", "metadata": {}, "score": "61.53457"}
{"text": "No .10/900,055 , filed on Jul. 26 , 2004 ; .Phrase - Based Searching in an Information Retrieval System , application Ser .No .10/900,041 , filed on Jul. 26 , 2004 ; .Phrase - Based Personalization of Searches in an Information Retrieval System , application Ser .", "label": "", "metadata": {}, "score": "61.545486"}
{"text": "5 illustrates this process , in which there are the following functional stages for indexing a document : .500 : Post document to the posting lists of good phrases found in the document .502 : Update instance counts and related phrase bit vector for related phases and secondary related phrases .", "label": "", "metadata": {}, "score": "61.55075"}
{"text": "Figure 2 shows a medical record in HL7 CDA format .An example HL7 CDA XML medical document .An example HL7 CDA XML medical document that shows the use of ID / IDREF attributes in XML .Likewise , relational data can also be modelled as a graph where relational entities are viewed as nodes , and primary - foreign key relationships ( e.g. , hospitalization to patient or medication to hospitalization ) between the entities are represented as edges in the graph .", "label": "", "metadata": {}, "score": "61.560112"}
{"text": "The front end server 140 receives queries from a user of a client 170 , and provides those queries to the search system 120 .The search system 120 is responsible for searching for documents relevant to the search query ( search results ) , including identifying any phrases in the search query , and then ranking the documents in the search results using the presence of phrases to influence the ranking order .", "label": "", "metadata": {}, "score": "61.66534"}
{"text": "Likewise , the vector is an approximation in this lower - dimensional space .We write this approximation as .Synonymy is the phenomenon where different words describe the same idea .Thus , a query in a search engine may fail to retrieve a relevant document that does not contain the words which appeared in the query .", "label": "", "metadata": {}, "score": "61.681698"}
{"text": "Moreover , we found that choosing any value of k from 1 to 100 had little effect on the runtime of Greedy and Quantile .This is a result of the low occ and docc for that set of queries , thus requiring less work from the self - index methods .", "label": "", "metadata": {}, "score": "61.706924"}
{"text": "If a phrase Q in the query has a set of phrase extensions Qe ( as further explained below ) , then the search system 120 first forms the union of the posting lists of the phrase extensions , prior to doing the intersection with the posting lists .", "label": "", "metadata": {}, "score": "61.72614"}
{"text": "The bipartiteACM Transactions on Computational Logic , Vol .V , No .N , April 2013 . \u00b7 51012uu3u4u5URLsq23q4u1q3020Queries100100012040qFig .An example of click - through bipartite graph .In a click - through bipartite graph , nodesrepresent queries and URLs , and edges represent click relations between queries and URLs.graph consists of a set of query nodes and a set of URL nodes .", "label": "", "metadata": {}, "score": "61.75766"}
{"text": "For example the phrases \" bolt action rifle \" and \" 22 \" would both have \" gun \" as a related phase .In this case , the search system 120 retrieves the posting lists of both phrases Q 1 and Q 2 and intersects the lists to produce a list of documents that contain both phrases .", "label": "", "metadata": {}, "score": "61.775597"}
{"text": "FIG .12 shows a physical implementation of a system upon which the present invention may be practiced .Such a system includes a database 1206 for storing a collection of documents .The database may include an index 1208 for storing concepts ( e.g. semantical or syntactical concepts ) and their relationships to the documents in the collection .", "label": "", "metadata": {}, "score": "61.817245"}
{"text": "References .Carbonell , J. G. , 1996 . ''Query - Relevant Document Summarization ' ' .CMU Technical Report , Carnegie Mellon University .Carbonell , J. , Yang , Y. , Frederking , R. , Brown , r. , Geng , Y. , Lee , D. , 1997 . ''", "label": "", "metadata": {}, "score": "61.81842"}
{"text": "Singhal A : Modern Information Retrieval : A Brief Overview .Proceedings of IEEE Data Engineering Bulletin 2001 , 24 ( 4 ) : 35 - 43 .Robertson SE , Walker S , Beaulieu M : Okapi at TREC-7 : automatic ad hoc , filtering , VLC and filtering tracks .", "label": "", "metadata": {}, "score": "61.84858"}
{"text": "5 ( c ) .An example is to represent entries ( car , dealer ) , ( automobile , showroom ) , and ( auto , SalesOffice ) as ( Sem 1 , Sem 2 ) .The algorithm for this type of merge is as follows : .", "label": "", "metadata": {}, "score": "61.877068"}
{"text": "If the total number of results ( e.g. in class 0 and class 1 ) is greater than 50 , the query processor can stop without performing further query processing .Note that the query processor can produce the results in slots ( 2,3 ) and ( 3,2 ) successively as well .", "label": "", "metadata": {}, "score": "61.914993"}
{"text": "( q)co - occur in at least one query session ( that is , there is at least one user using the query term M.q ) has selected / clicked on the document ) .[0045 ] P(D.sub.k.vertline.w.sub.i.sup .( q ) ) is the conditional probability of the document D.sub.k being clicked in case that w.sub.i.sup .", "label": "", "metadata": {}, "score": "61.949654"}
{"text": "( 13 ) PubMed View Article .Fontaine JF , Barbosa - Silva A , Schaefer M , Huska MR , Muro EM , Andrade - Navarro MA : MedlineRanker : Flexible Ranking of Biomedical Literature .Journal of Nucleic Acids Research 2009 , 37 : W141 - 6 .", "label": "", "metadata": {}, "score": "62.01376"}
{"text": "Full - text . edu.au 2Department of Computer Science , Univ . of Chile .gnavarro@dcc.uchile.cl Abstract .Text search engines return a set of k documents ranked by similarity to a query .Typically , documents and queries are drawn from natural language text , which can readily be partitioned into words , allow- ing optimizations of data structures and algorithms for ranking .", "label": "", "metadata": {}, "score": "62.023384"}
{"text": "See G. Salton et al . , \" Improving retrieval performance by relevance feedback , \" Journal of the American Society for Information Science , 41(4):288 - 297 , June 1990 .This is called local analysis .A formal study has shown that using global analysis techniques , such as word context and phrase structure , on the local set of documents produces results that are both more effective and more predictable than simple local feedback .", "label": "", "metadata": {}, "score": "62.0282"}
{"text": "The book by Lancaster and Fayen [ 16 ] contains details of many operational on - line systems .Barraclough [ 17 ] has written an interesting survey article about on - line searching .Discussions on search strategies are usually found embedded in more general papers on information retrieval .", "label": "", "metadata": {}, "score": "62.030098"}
{"text": "On a given document URL 0 , the indexing system 110 identifies each outlink to another document URL 1 , in which the anchor text A is a phrase in the good phrase list 208 .FIG .8 a illustrates schematically this relationship , in which anchor text \" A \" in document URL 0 is used in a hyperlink 800 .", "label": "", "metadata": {}, "score": "62.079502"}
{"text": "n ] over an alphabet \u03a3 of size \u03c3 .A wavelet tree computes D[i ] in time O(log\u03c3 ) , as well as rankc(D , i ) , the number of occurrences of symbol c in D[1 .i ] , and selectc(D , j ) , the position in D of the j - th occurrence of symbol c. An example of a wavelet tree is shown in Fig .", "label": "", "metadata": {}, "score": "62.086678"}
{"text": "As implemented in Pangloss , unchosen alternative translations could be selected by the user through a special - purpose interface that interacted with the chart representation ( Frederking et al .93 ) , which greatly increased the usefulness of the transfer - based translations .", "label": "", "metadata": {}, "score": "62.103493"}
{"text": "Time to find word based queries using Zettair and the best of the new methods for 2 and 4 word queries on wsj .Term - based Search .However , these approaches are not directly comparable to com- mon word - based queries at which traditional inverted indexes excel .", "label": "", "metadata": {}, "score": "62.12599"}
{"text": "The result of the intersection is a set of documents that are relevant to the query .In one embodiment , the search system 120 can use an optimized mechanism to identify documents responsive to the query without having to intersect all of the posting lists of the query phrases Q. As a result of the structure of the index 150 , for each phrase g j , the related phrases g k are known and identified in the related phrase bit vector for g k .", "label": "", "metadata": {}, "score": "62.157734"}
{"text": "The categorization methodology uses our novel Gene Ontology Categorizer ( GOC ) technology [ 3 ] to select GO nodes which cover the terms in the input set , based on the structure of the GO .BioCreAtIvE Task 2 had two subtasks for which we received evaluated results : .", "label": "", "metadata": {}, "score": "62.17461"}
{"text": "Referring to now .FIG .2 , the phrase identification process has the following functional stages : .200 : Collect possible and good phrases , along with frequency and co - occurrence statistics of the phrases .202 : Classify possible phrases to either good or bad phrases based on frequency statistics .", "label": "", "metadata": {}, "score": "62.21578"}
{"text": "claim 3 , wherein discarding at least one of the first document or the second document from the set of documents comprises removing the first document or the second document from an index .The method of .claim 1 , wherein comparing the document description of the first document with a document description of the second document further comprises : . for the first document , generating the document description of the first document by selecting sentences of the document , and ordering the selected sentences in the document description as a function of a number of related phrases in the selected sentences ; and .", "label": "", "metadata": {}, "score": "62.23642"}
{"text": "The word feedback is normally used to describe the mechanism by which a system can improve its performance on a task by taking account of past performance .In other words a simple input - output system feeds back the information from the output so that this may be used to improve the performance on the next input .", "label": "", "metadata": {}, "score": "62.264362"}
{"text": "I. System Overview .Referring now to .FIG .1 , there is shown the software architecture of an embodiment of a search system 100 in accordance with one embodiment of present invention .In this embodiment , the system includes a indexing system 110 , a search system 120 , a presentation system 130 , and a front end server 140 .", "label": "", "metadata": {}, "score": "62.281097"}
{"text": "Those of skill in the art of information retrieval will appreciate the flexibility of generality of the phrase information allows for a large variety of uses and applications in indexing , document annotation , searching , ranking , and other areas of document analysis and processing .", "label": "", "metadata": {}, "score": "62.28292"}
{"text": "( q ) ) is the number of the query sessions that contain the term w.sub.i.sup .( q ) .W.sub.jk.sup .( d)is the normalized weight of the term w.sub.j.sup .( d ) in the document D.sup.k , which is divided by the maximum value of term weights in the document D.sup.k .", "label": "", "metadata": {}, "score": "62.321278"}
{"text": "With this representation , the documents can be easily ranked as follows : .The presentation of the ranking graph is carried out by available visualization tools .For example , a visualization method , called Cone Trees , can be modified by adding the depth for 3 dimensional ranking graph presentation .", "label": "", "metadata": {}, "score": "62.3286"}
{"text": "Another hypothesis they considered is the cascade model , which assumes thatusers view search results in a top - down manner .Users make a decision on whetherthey click a webpage before they move to the next webpage .Moreover , a user who clicks never comes back , anda user who skips always continues until she clicks .", "label": "", "metadata": {}, "score": "62.350864"}
{"text": "Examples , both operational and experimental , of systems providing mechanisms of this kind are MEDLINE [ 11 ] and MEDUSA [ 12 ] both based on the MEDLARS system .Another interesting sophisticated experimental system is that described by Oddy [ 13 ] .", "label": "", "metadata": {}, "score": "62.481785"}
{"text": "There is another theoretical way of looking at the construction of cluster representatives and that is through the notion of a maximal predictor for a cluster [ 6 ] .Given that , as before , the documents Di in a cluster are binary vectors then a binary cluster representative for this cluster is a predictor in the sense that each component ( ci ) predicts that the most likely value of that attribute in the member documents .", "label": "", "metadata": {}, "score": "62.52632"}
{"text": "For example , consider a query \" pericardial effusion \" over the clinical dataset shown in Figure 1 .Assume that the ranking function is the product of tf and idf , i.e. , tf\u00b7idf .In most proposed formulas , the two factors are typically combined by product for better results .", "label": "", "metadata": {}, "score": "62.56894"}
{"text": "These problems get worse when dealing with document information collected from the Web since the number of documents is very large and the words used are extremely diverse , inconsistent , and sometimes incorrect ( e.g. , typographical errors ) .A study has shown that most user queries on the Web typically involve two words .", "label": "", "metadata": {}, "score": "62.574066"}
{"text": "In Proc . 13thSPIRE , pp\u02d9122 - 133 , 2006 .R. Raman , V. Raman , and S. Rao .Succinct indexable dictionaries with applica- tions to encoding k - ary trees and multisets .In Proc .SODA , pp\u02d9233 - 242 , 2002 .", "label": "", "metadata": {}, "score": "62.672737"}
{"text": "Cluster - based retrieval has as its foundation the cluster hypothesis , which states that closely associated documents tend to be relevant to the same requests .Clustering picks out closely associated documents and groups them together into one cluster .In Chapter 3 , I discussed many ways of doing this , here I shall ignore the actual mechanism of generating the classification and concentrate on how it may be searched with the aim of retrieving relevant documents .", "label": "", "metadata": {}, "score": "62.68878"}
{"text": "In this example , .These scores indicate the importance and relevance of the entities in the clinical dataset in Figure 1 for query \" pericardial effusion \" .The higher the score , the more relevant and important the entity is for the query .", "label": "", "metadata": {}, "score": "62.69828"}
{"text": "Another array , C[1 .n ] , stores in C[i ] the last occurrence of D[i ] in D[1 .The algorithm first finds A[sp .To retrieve all of the unique values in D[sp .ep ] , it starts with the interval [ s ..", "label": "", "metadata": {}, "score": "62.711834"}
{"text": "Our interpretation of the task was that there were two results : prediction of the GO node and selection of the evidence text .While in some of the runs , our overall results were not strong , our independent investigations show that our overall performance is better when considering annotation ( GO node prediction ) distinctly from evidence text selection .", "label": "", "metadata": {}, "score": "62.745316"}
{"text": "Our architecture proved not to be very successful on the evidence text component of the task , in the configuration used to generate the submitted results .Conclusion .The initial results show promise for both of the methods we explored , and we are planning to integrate the methods more closely to achieve better results overall .", "label": "", "metadata": {}, "score": "62.81992"}
{"text": "Improved recall through linguistic generalization ; .Improved precision by modelling linguistic relations ; .Truly semantic multilingual search through conceptual querying .Query Expansion Translation : When translating a query , it is not possible to do a reliable exact translation , especially because queries tend to include isolated words and phrases out of context , as well as possibly full clauses or sentences .", "label": "", "metadata": {}, "score": "62.83744"}
{"text": "The system according to . claim 47 , wherein within each of the stages , the ones of the documents are retrieved in an order reflecting a level of importance assigned to at least one of the words of the query .", "label": "", "metadata": {}, "score": "62.8844"}
{"text": "Suffix arrays : a new method for on - line string searches .SIAM J. Computing , 22(5):935 - 948 , 1993 .G. Manzini .An analysis of the Burrows - Wheeler transform .J. ACM , 48(3):407- 430 , 2001 .", "label": "", "metadata": {}, "score": "62.938187"}
{"text": "Inverted indexes require the definition of terms in T prior to their construction .In the case of many natural languages , the choice of terms is simply the vocabulary of the language : words .In turn , for the inverted index to operate efficiently , queries must be composed only of terms that are in the index .", "label": "", "metadata": {}, "score": "63.011333"}
{"text": "Translingual Query , Retrieval , and Summarization .Let us first cast the problem of translingual IR ( TIR ) in its simplest terms , and subsequently revisit the surrounding complexity .Assume a query Q S in the the user 's language ( definitionally , the source language , SL ) .", "label": "", "metadata": {}, "score": "63.016365"}
{"text": "At each step , the surfer follows a hyperlink with probability d or concludes that relevance is low and so randomly jumps to another node with probability 1 - d .The PageRank value of v i is the probability r ( v i ) that at a given time , the surfer is at v i .", "label": "", "metadata": {}, "score": "63.04295"}
{"text": "In a first pass ( e.g. , if there are no stored query information for the user ) , the search system 120 operates to simply return the relevant documents in the search result to the user 's query , without further customized ranking .", "label": "", "metadata": {}, "score": "63.05581"}
{"text": "To gain preliminary insights about CO vs. BM25 , we worked with a convenience sample of two primary - care physicians ( MW and PB ) , who were blinded to the automated rankings .Note that the users have been trained before since we also conducted an initial version of the User Survey for the users to get used to the way the survey was built .", "label": "", "metadata": {}, "score": "63.10831"}
{"text": "The method according to . claim 14 , wherein the words failing to meet the predetermined criterion are proper nouns .The method according to . claim 14 , where the syntactically related words are words co - occurring in one of the documents above a threshold level of frequency .", "label": "", "metadata": {}, "score": "63.111633"}
{"text": "Santa Fe Institute Series in the Sciences of Complexity .Oxford University Press 2001 , 305 - 334 .Mordeson JN , Nair PS : Fuzzy Graphs and Fuzzy Hypergraphs Springer - Verlag 2000 .Rocha LM : Automatic Conversation Driven by Uncertainty Reduction and Combination of Evidence for Recommendation Agents .", "label": "", "metadata": {}, "score": "63.11482"}
{"text": "The approach is based on Weakly Supervised Latent Dirichlet Allocation(WS - LDA ) , an extension of conventional LDA .Their method creates a pseudodocument for each labeled named entity .It views the contexts of a named entity insearch log as words of the document with regard to the entity , and the classes of thenamed entity are regarded as possible topics of the document .", "label": "", "metadata": {}, "score": "63.14077"}
{"text": "The importance of a result is determined by its authoritativeness ( should be from a trusted source ) .The specificity of a result is determined by its relevance ( being on the proper subject and satisfying user goals ) and conciseness .", "label": "", "metadata": {}, "score": "63.24829"}
{"text": "To address this , we utilized a method for expanding the set of terms associated with a given GO node .This method is based on the idea that the presence of words that are strongly associated with a GO node label are good indicators of that GO node , in addition to the terms that occur in the node label itself .", "label": "", "metadata": {}, "score": "63.28977"}
{"text": "Davis , M. , and Dunning , T. , 1996 . ''A TREC evaluation of query translation methods for multi - lingual text retrieval ' ' , In Proceedings of the 4th Text Retrieval Conference ( TREC-4 ) .Dumais , S. , Landauer , T. and Littman , M. , 1996 . ''", "label": "", "metadata": {}, "score": "63.309635"}
{"text": "In this configuration , we ignored the protein altogether and focused on the GO node - paragraph relationship .Nonetheless , we received a score of \" high \" on the protein mention measurement for 638 of the 1050 ( 61 % ) answers we submitted .", "label": "", "metadata": {}, "score": "63.33373"}
{"text": "When a document is crawled , the above described document description process is performed to obtain the selected sentences , and then the hash of these sentences .If the hash table is filled , then again the newly crawled document is deemed to be a duplicate of a previous document .", "label": "", "metadata": {}, "score": "63.346542"}
{"text": "With respect to queries , only 153/1076 ( 14 % ) of Task 2.1 queries and 44/435 ( 10 % ) of Task 2.2 queries included proteins for which we had names .This issue had a big impact on our ability to focus in on text within documents that was directly relevant to the protein of interest ( see further discussion of this problem , below ) .", "label": "", "metadata": {}, "score": "63.39482"}
{"text": "[29 ] described a novel technique to explain the results of authority - flow based techniques .For both CO and BM25 methods , we provide an \" adjacent entities \" link that pictorially explains each result .In the case of CO , an explaining graph is displayed using the principles described in [ 29 ] .", "label": "", "metadata": {}, "score": "63.407036"}
{"text": "Identification of Related Phrases and Clusters of Related Phrases .Referring to .FIG .4 , the related phrase identification process includes the following functional operations .400 : Identify related phrases having a high information gain value .402 : Identify clusters of related phrases .", "label": "", "metadata": {}, "score": "63.430042"}
{"text": "Original GOC output in the toy example .For the BioCreAtIvE Task 2 the following changes were made to the base GOC algorithm described above : .Label sets X were allowed to be terms as well as gene products .Since each item of the list \" hits \" a collection of GO nodes with its particular weight , the query as a whole implicates a collection of GO nodes in a complex way .", "label": "", "metadata": {}, "score": "63.43695"}
{"text": "Succinct data structures for flexible text retrieval systems .J. Discrete Algorithms , 5(1):12 - 22 , 2007 .G. Salton , A. Wong , and C. S. Yang .A vector space model for automatic indexing .Comm .ACM , 18(11):613 - 620 , 1975 .", "label": "", "metadata": {}, "score": "63.522865"}
{"text": "R i .The product value here is a score of how topical anchor phrase Q is to document D. This score is here called the \" inbound score component .\" This product effectively weights the current document D 's related bit vector by the related bit vectors of anchor phrases in the referencing document R. If the referencing documents R themselves are related to the query phrase Q ( and thus , have a higher valued related phrase bit vector ) , then this increases the significance of the current document D score .", "label": "", "metadata": {}, "score": "63.52534"}
{"text": "The cascade model as - sumes that a user who clicks never comes back , and a userwho skips always continues .A click on the i - th documentindicates : 1 . the user must have decided to skip the ranksabove ; 2 . the user deem the i - th document relevant .", "label": "", "metadata": {}, "score": "63.532463"}
{"text": "The search starts at the root of the tree , node 0 in the example .It proceeds by evaluating a matching function at the nodes immediately descendant from node 0 , in the example the nodes 1 and 2 .This pattern repeats itself down the tree .", "label": "", "metadata": {}, "score": "63.537476"}
{"text": "To initiate the search in response to a request it is necessary to know in advance one terminal node appropriate for that request .It is not unusual to find that a user will already known of a document relevant to his request and is seeking other documents similar to it .", "label": "", "metadata": {}, "score": "63.687973"}
{"text": "Their approach employs weakly supervised learning by assuming thatthere are a small number labeled instances available , that is , seed entities belongingto a class .It starts the mining process with the seed entities .It matches the seedentities to the query log , discovers context patterns of the entities , and mines newACM Transactions on Computational Logic , Vol .", "label": "", "metadata": {}, "score": "63.730145"}
{"text": "Protein recognition and context term selection .Swiss - Prot and TrEMBL identifiers were provided as input identifiers for the protein , so we needed to establish a set of names by which that protein ( indicated by a Swiss - Prot identifier ) could be referenced in the text .", "label": "", "metadata": {}, "score": "63.74196"}
{"text": "Evidence selection consisting of the paragraph selection algorithm based on GOC results .Run 3 : A configuration using the full system architecture , minus the sentence - based context term selection component , using instead the \" fallback \" scenario of selecting the top TFIDF - ranked terms in the document as a whole as the context terms for the protein .", "label": "", "metadata": {}, "score": "63.785973"}
{"text": "Toronto ; 2004:564 - 575 .Guo L , Shao F , Botev C , Shanmugasundaram J : XRANK :Ranked Keyword Search over XML Documents .In Proceedings of Association for Computing Machinery Special Interest Group in Management of Data ( SIGMOD ) .", "label": "", "metadata": {}, "score": "63.799183"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .The above objects and advantages of the present invention will become more apparent by describing in detail preferred embodiments thereof with reference to the attached drawings in which : .FIG .1 illustrates the problem of word mismatch in the context of information retrieval .", "label": "", "metadata": {}, "score": "63.874596"}
{"text": "This difference between human and CO approaches likely led to the variable sensitivity .We would infer in many such cases that the human gold standard may have actually been faulty in failing to detect certain relevant cases .Indeed , our own reviews and discussions about the findings suggested this .", "label": "", "metadata": {}, "score": "63.959766"}
{"text": "Each occurrence of a word is treated as having the same meaning due to the word being represented as a single point in space .For example , the occurrence of \" chair \" in a document containing \" The Chair of the Board \" and in a separate document containing \" the chair maker \" are considered the same .", "label": "", "metadata": {}, "score": "63.975792"}
{"text": "PageRank was the key novelty behind the first Google Web search engine .Intuitively , a page is important ( high PageRank ) if it is pointed via hyperlinks from other important pages .This recursive definition leads to an iterative formula , as shown in Equation 2 below .", "label": "", "metadata": {}, "score": "63.983036"}
{"text": "However , much of the work has been directed to the study of retrieval measures such as recall and precision .First , index size is extremely large since many words in a document collection ( e.g. the Web ) are distinct proper names and each word has a number of semantically similar and syntactically related words .", "label": "", "metadata": {}, "score": "63.999973"}
{"text": "Since sessionpatterns represent users ' search behaviors in a more precise way , it has been usedextensively .As will be seen later , session patterns have been widely used in taskssuch as query transformation , document ranking , and user satisfaction prediction .", "label": "", "metadata": {}, "score": "64.06397"}
{"text": "claim 29 , wherein the predetermined criterion is whether the words can be found in a lexical dictionary .The system according to . claim 26 , wherein the higher granularity concepts are higher granularity syntactical concepts .The system according to .", "label": "", "metadata": {}, "score": "64.115"}
{"text": "The traditional BM25 system exploits the EHRs ' content without regard to association among entities within .The Clinical ObjectRank ( CO ) system exploits the entities ' associations in EHRs using an authority - flow algorithm to discover the most relevant entities .", "label": "", "metadata": {}, "score": "64.1431"}
{"text": "PI.P(w.su- b.j.sup .( d ) .vertline.w.sub.i.sup .( q))+1 ) ) .wherein Q stands for the new terms ; and selecting the expansion terms from the particular ones as a function of rankings of the joint probabilities .A method as recited in claim 1 , and wherein the method further comprises generating a database of the probabilistic correlations .", "label": "", "metadata": {}, "score": "64.21219"}
{"text": "5 gives pseudocode for our new methods .Page 14 .Algorithms for computing the top - k documents by tf .The algorithm in ( a ) maintains a priority queue h of ( node , range ) pairs , each pair having priority equal to the length of the range component .", "label": "", "metadata": {}, "score": "64.215195"}
{"text": "[ 0046 ] This is because the document D.sub.k separates the query term w.sub.i.sup .( q ) from the document term w.sub.j.sup .( d ) .[ 0047 ] P(D.sub.k.vertline.w.sub.i.sup .( q ) ) can be statistically obtained from the query logs .", "label": "", "metadata": {}, "score": "64.2436"}
{"text": "In one embodiment , the search system 120 calculates a score for each document that is a function ( e.g. , linear combination ) of two scores , a body hit score and an anchor hit score .The weights of 0.30 and 0.70 can be adjusted as desired .", "label": "", "metadata": {}, "score": "64.257744"}
{"text": "\" While this approach may produce search results having documents that are conceptually related at the level of individual words , it does not typically capture topical relationships that inhere between co - occurring phrases .SUMMARY OF THE INVENTION .An information retrieval system and methodology uses phrases to index , search , rank , and describe documents in the document collection .", "label": "", "metadata": {}, "score": "64.32492"}
{"text": "We manually pick edge role names .However , the names of the edge roles are not important in the algorithms execution .Figure 1 presents a subset of our clinical data graph D ( V , E ) .The schema graph G ( V G , E G ) ( Figure 3 ) is a directed graph that describes the structure of a data graph D ( V , E ) .", "label": "", "metadata": {}, "score": "64.347595"}
{"text": "The method according to . claim 1 , wherein in the replacing step , only ones of the words in the preliminary index meeting a predetermined criterion are replaced by the corresponding higher granularity concepts .The method according to .claim 4 , wherein the predetermined criterion is whether the words can be found in a lexical dictionary .", "label": "", "metadata": {}, "score": "64.44862"}
{"text": "In this study , in a limited sample of test cases , CO provided , on average , a 71 % improvement over BM25 .This difference was observed without a compromise in specificity .The CO030 variant performed best , in terms of both sensitivity and specificity .", "label": "", "metadata": {}, "score": "64.47951"}
{"text": "Paice , C. D. , 1990 . ''Constructing Literature Abstracts by Computer : Techniques and Prospects ' ' .Information Processing and Management , Vol .26 , pp .171 - 186 .Salton , G. and McGill , M. J. , 1983 . ''", "label": "", "metadata": {}, "score": "64.512146"}
{"text": "506 : Reorder index entries according to posting list size .These stages are now described in further detail .A set of documents is traversed or crawled , as before ; this may be the same or a different set of documents .", "label": "", "metadata": {}, "score": "64.51537"}
{"text": "At block 510 , the query expansion model compares the joint probabilities to select top - ranked expansion term(s ) 206 for adding to the terms of the newly submitted query .A top - ranked expansion term is a term with a higher calculated joint probability than the joint probability corresponding to another term .", "label": "", "metadata": {}, "score": "64.58632"}
{"text": "Data mining differs from searching , since data mining techniques look for interesting patterns or trends in the data , whereas search algorithms look for relevant discrete pieces of data in a collection , given a query .Since data mining is not the focus of this work , we give some further pointers to readers who might be more interested in this area .", "label": "", "metadata": {}, "score": "64.61982"}
{"text": "c is the correction increment , its value is arbitrary and is therefore usually set to unit .In practice it may be necessary to cycle through the set of documents several times before the correct set of weights are achieved , namely those which will separate A and ' A linearly ( this is always providing a solution exists ) .", "label": "", "metadata": {}, "score": "64.66684"}
{"text": "The following steps are taken by the indexing system 110 for each document that is crawled .Traverse the words of the document with a phrase window length of n , where n is a desired maximum phrase length .The length of the window will typically be at least 2 , and preferably 4 or 5 terms ( words ) .", "label": "", "metadata": {}, "score": "64.711685"}
{"text": "Haveliwala [ 8 ] proposes a topic - sensitive PageRank , where the topic - specific PageRanks for each page are pre - computed and the PageRank value of the most relevant topic is used for each query .Brinkmeier [ 9 ] models pagerank as a power series ( in contrast to the usual Markov Chain modeling ) and presents some results concerning the convergence of the standard iteration used for PageRank .", "label": "", "metadata": {}, "score": "64.74737"}
{"text": "The user isassumed to sequentially scan the list of webpages from the top to the bottom untilshe decides to stop .If the user does not examine the snippet at position i , then she will notexamine the subsequent positions ( Equation 3(g ) ) .", "label": "", "metadata": {}, "score": "64.823524"}
{"text": "Note that due to the list cutoff , recall is bounded above by precision .Thus Figure 6 shows a more detailed analysis for precision only , and furthermore breaks out the family groups by their individual constituents ( e.g. parents and siblings ) .", "label": "", "metadata": {}, "score": "64.86085"}
{"text": "For example , entries ( car , dealer ) , ( automobile , dealer ) , and ( auto , dealer ) are replaced by ( Sem 1 , dealer ) .The algorithm used here is the same as that for S - P and P - S form .", "label": "", "metadata": {}, "score": "64.86249"}
{"text": "D.s- ub.k ) is a function of frequency of occurrence of W ( d ) in a document D.sub.k , as well as the occurrence of the term w.sub.j.sup .( d ) in all documents identified in the user log .", "label": "", "metadata": {}, "score": "64.87341"}
{"text": "The presentation system 130 does this as follows .As in other aspects of the system 100 , the presentation system 130 makes use of the related phrase bit vector for each document d in the search results .More specifically , for each query phrase Q , and for each document d in Q 's posting list , the related phrase bit vector indicates which related phrases Qr are present in the document .", "label": "", "metadata": {}, "score": "64.96415"}
{"text": "We submitted 3 runs for each of tasks 2.1 and 2.2 ( as well as a run for task 2.3 which was not scored ) .The runs consisted of the following configurations of the system : .Task 2.1 .Run 2 : A configuration using the full system architecture including GOC , in which GOC is constrained to search for cluster heads only below the annotation given in the input query .", "label": "", "metadata": {}, "score": "64.99808"}
{"text": "For a document collection of M documents with N distinct terms , the collection is represented as an M \u00d7N matrix .A query is also represented as a vector of terms .The document retrieval is based on similarity computation of the cosine measure of the query vector and each document vector .", "label": "", "metadata": {}, "score": "65.01384"}
{"text": "( Lines interpolated for clarity . )Due to Obs .5 Experiments We evaluated our new algorithms ( Greedy from Section 4.1 and Quantile from Section 4.2 ) with English text and protein collections .We also implemented our improved version of Gagie et al . 's Wavelet Tree document listing method , labelled WT .", "label": "", "metadata": {}, "score": "65.05631"}
{"text": "KV , CJ , and LMR contributed to the writing of the manuscript .Authors ' Affiliations .Los Alamos National Laboratory .School of Informatics , Indiana University .Cognitive Science Program , Indiana University .References .The Gene Ontology Cosortium : Gene Ontology : Tool For the Unification of Biology .", "label": "", "metadata": {}, "score": "65.106804"}
{"text": "4.2 Top - k via Quantile Probing We now exploit the fact that in a sorted array X[1 .In general we have the following : Observation 1 On a sorted array X[1 .ep].However , we can access the elements of D[sp .", "label": "", "metadata": {}, "score": "65.129745"}
{"text": "Let f be the compression factor that is obtained by grouping dictionary words into semantic concepts .Thus , f can be viewed as the average number of words grouped by a concept .The table size in FIG .3 ( a ) is : .", "label": "", "metadata": {}, "score": "65.15073"}
{"text": "( XLS 22 KB ) .Competing interests .The authors declare that they have no competing interests .Authors ' contributions .VH conceived the whole study , participated in its design and coordination and helped to draft the manuscript .", "label": "", "metadata": {}, "score": "65.176"}
{"text": "Automobile , auto , and sedan are words having a similar meaning to the word car .Similarly , Showroom and SalesOffice have meanings similar to the word dealer .The other type of query expansion , shown in Line 2 , is by , for example , syntactical co - occurrence relationships .", "label": "", "metadata": {}, "score": "65.205215"}
{"text": "Thus we end up with two sets of n nodes from the GO - our n annotation predictions and the n correct annotations .Ultimately , this problem becomes that of measuring the amount of overlap between two sets of GO nodes , which is actually a difficult mathematical problem , which we [ 3 , 11 ] and others ( e.g. [ 12 ] ) are addressing .", "label": "", "metadata": {}, "score": "65.21562"}
{"text": "A Framework and Graphical Development Environment for Robust NLP Tools and Applications .Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics ( ACL'02 ) ; Philadelphia 2002 , 168 - 175 .Rocha LM , Bollen J : Biologically Motivated Distributed Designs for Adaptive Knowledge Management .", "label": "", "metadata": {}, "score": "65.25677"}
{"text": "[ 0033 ] FIG .2 is a block diagram that shows further exemplary aspects of application programs 160 and program data 164 of FIG .1 used to expand query terms .System memory 134 is shown to include a number of application programs including , for example , query expansion module 202 and other modules 204 .", "label": "", "metadata": {}, "score": "65.33983"}
{"text": "4 have been introduced for efficient query processing .Initially , the storage estimate for the indices used in a traditional IR system , i.e. , the tables shown in FIG .2 , will be calculated .The index sizes in terms of number of entries ( i.e. , number of rows ) as well as in terms of the total size ( i.e. , number of pointers ) of the table is computed .", "label": "", "metadata": {}, "score": "65.39194"}
{"text": "The mask bit vector is then used to mask the related phrase bit vector for each document in the current set of search results by ANDing the related phrase bit vector with the mask bit vector .This has the effect of adjusting the body score and the anchor hit score by the mask bit vector .", "label": "", "metadata": {}, "score": "65.55582"}
{"text": "( 4 ) Intersection of vector of expanded GO node words ( W GOProx ) with word vectors for each paragraph in the document ( columns of R ) : paragraph with largest intersection is returned .Run 1 submitted for Task 2.1 yielded a comparatively very good result ( see Results presented below ) .", "label": "", "metadata": {}, "score": "65.62627"}
{"text": "Evaluation results on the evidence text selected for Task 2.2 .See legend for Table 1 .In this task , evaluation of the GO node reference was done with respect to the predicted GO annotation provided by the system .Our results for the other runs we submitted for Task 2.1 were less good , achieving a perfect or generally good score for 83/86 ( runs 2/3 , respectively ) of the queries , or about 8 % .", "label": "", "metadata": {}, "score": "65.65161"}
{"text": "The success of authority - flow algorithms depends on the choice of the entities ' definition .In our experiments , we roughly create an entity for each tuple of the relational database , e.g. , patient , hospitalization , and so on .", "label": "", "metadata": {}, "score": "65.71118"}
{"text": "Inverted indexes require the tex- tual units ( words , q - grams , characters ) of the vocabulary to be defined before indexing commences in order to limit the size of the index and vocabulary , and to allow tf\u00d7idf information to be precomputed and stored .", "label": "", "metadata": {}, "score": "65.7372"}
{"text": "It may be new phrase just coming into usage , and thus during subsequent crawls becomes increasingly common .In that case , its respective counts will increases and may ultimately satisfy the thresholds for being a good phrase .The third stage of the indexing operation is to prune 204 the good phrase list 208 using a predictive measure derived from the co - occurrence matrix 212 .", "label": "", "metadata": {}, "score": "65.78955"}
{"text": "VH was partially supported by NSF grants IIS-0811922 and IIS- 0952347 , and DHS grant 2009-ST-062 - 000016 .Electronic supplementary material .1472 - 6947 - 10 - 64-S1 .XLS Additional file 1 : Table s1 - Average Sensitivity and Specificity of Algorithm Variants .", "label": "", "metadata": {}, "score": "65.8685"}
{"text": "( d ) .vertline .D.s- ub.k ) is the conditional probability of occurrence of w.sub.j.sup .( d ) if the document D.sub.k is selected , P(D.sub.k.vertline.w.sub.i.sup .( q ) ) is statistically obtained from the query log , P(w.sub.j.sup .", "label": "", "metadata": {}, "score": "65.94781"}
{"text": "The SVD is typically computed using large matrix methods ( for example , Lanczos methods ) but may also be computed incrementally and with greatly reduced resources via a neural network -like approach , which does not require the large , full - rank matrix to be held in memory .", "label": "", "metadata": {}, "score": "65.949356"}
{"text": "Specifically , we returned the top 5 to 10 additional words with largest average value of WPP to all the words in W GO ( the green nodes in Figure 1 ) .The additional words thus discovered were used to expand W GO .", "label": "", "metadata": {}, "score": "65.9616"}
{"text": "Indeed , the WPP matrix defines a fuzzy graph [ 7 ] where the vertices are words w i , and the edges are probability weights wpp ( w i , w j ) .Such a graph can also be understood as an associative knowledge structure that represents how words co - occur in a given document , and therefore as an associative model of the knowledge stored in each document in terms of its constituent words [ 8 ] .", "label": "", "metadata": {}, "score": "65.97557"}
{"text": "Modern Information Retrieval .IR is the science of searching for relevant information in a collection of documents .An IR process begins with a user submitting a query to the IR system , which compares the query to the documents and returns a ranked list of relevant documents .", "label": "", "metadata": {}, "score": "65.98455"}
{"text": "A document may have one or more pages , partitions , segments or other components , as appropriate to its content and type .Equivalently a document may be referred to as a \" page , \" as commonly used to refer to documents on the Internet .", "label": "", "metadata": {}, "score": "66.01694"}
{"text": "The method according to . claim 14 , wherein ones of the words of original granularity contained in the documents correspond to multiple ones of the higher granularity concepts .The method according to . claim 14 , wherein the step of executing progresses in successive stages until a predetermined number of the ones of the documents associated with the corresponding ones of the higher granularity concepts are retrieved .", "label": "", "metadata": {}, "score": "66.02397"}
{"text": "( 9 ) View Article .Motwani R , Raghavan P : Randomized Algorithms .Cambridge University Press , United Kingdom ; 1995 .Matsunaga T , Yonemori C , Tomita E , Muramatsu M : Clique - based data mining for related genes in a biomedical database .", "label": "", "metadata": {}, "score": "66.02991"}
{"text": "For every extracted term the query expansion module generates selected document terms 216 .Selected document terms represent corresponding ones of the terms selected from the probabilistic correlation database 212 .The joint probabilities are ranked .[ 0040 ] The query expansion model selects one or more expansion terms 206 from the top - ranked selected document terms .", "label": "", "metadata": {}, "score": "66.040474"}
{"text": "The results for the two tasks are shown in Tables 1 and 2 .We were user 7 .On Task 2.1 , run 1 , we achieved a score of either perfect or generally good for 413 of the results ; this corresponds to a good result for 38 % of the 1076 queries .", "label": "", "metadata": {}, "score": "66.085144"}
{"text": "A bit is set if the related phrase g k in R is in the same cluster as phrase g j .More generally , this means that the corresponding bit in the cluster bit vector is set if there is information gain in either direction between g j and g k .", "label": "", "metadata": {}, "score": "66.09135"}
{"text": "Preferably , the presentation system 130 keeps the document that has a higher page rank or other query independent measure of document significance .In addition , the presentation system 130 can modify the index 150 to remove the duplicate document , so that it will not appear in future search results for any query .", "label": "", "metadata": {}, "score": "66.19592"}
{"text": "The model is an analogy to anelectrical network .The probabilities on the edge correspond to conductance , theprobabilities of nodes correspond to voltage and the null node corresponds to theACM Transactions on Computational Logic , Vol .V , No .", "label": "", "metadata": {}, "score": "66.2081"}
{"text": "2004].5.1.2 Term - based Methods .Compared with click - based methods , term - basedpersonalization methods are more robust to sparse data .The BM25ACM Transactions on Computational Logic , Vol .V , No .N , April 2013 .", "label": "", "metadata": {}, "score": "66.24983"}
{"text": "Discussion .There are several important general issues in the evaluation that impacted our performance .Unknown proteins .We discovered that the test data contained many protein IDs that were not yet available in SwissProt , in stark contrast to the training data .", "label": "", "metadata": {}, "score": "66.2554"}
{"text": "One consequence is that measuring the practical impact of new theoretical proposals is a difficult task , since older base- line implementations may not rely on the same basic components , and reimplementing from scratch can be very time - consuming .", "label": "", "metadata": {}, "score": "66.33414"}
{"text": "The method according to . claim 10 , wherein within each of the stages , the ones of the documents are retrieved in an order reflecting a level of importance assigned to at least one of the words of the query .", "label": "", "metadata": {}, "score": "66.4017"}
{"text": "Also , it is necessary to have a stopping rule which terminates the search and forces a retrieval .In Figure 5.3 the decision rule is : expand the node corresponding to the maximum value of the matching function achieved within a filial set .", "label": "", "metadata": {}, "score": "66.46423"}
{"text": "Translate the query -- Convert Q S into Q ' T by manual or machine translation .Then search [ D T ] with Q ' T , and if desired translate the retrieved documents manually or by MT from TL into SL .", "label": "", "metadata": {}, "score": "66.48938"}
{"text": "TL k ) .Let us start with a single target language .Let [ D S ] be a document collection to be searched in the source language , and [ D T ] be another document collection to be searched , but in the target language .", "label": "", "metadata": {}, "score": "66.55759"}
{"text": "SM was responsible for the code development of GOC and the implementation of the extensions in the code .AR worked on BioCreAtIvE Task 2.3 which was not evaluated in the end .LMR participated in the design of the proximity analysis and paragraph selection algorithms .", "label": "", "metadata": {}, "score": "66.56905"}
{"text": "Such massive amounts of search / browselog data , on the one hand , provide great opportunities to mine the wisdom of crowdsand improve web search results .Particu - larly , for researchers planning to start investigations in this direction , the surveycan serve as a short introduction course leading them to the frontier quickly.-Second , we provide general data mining audience an informative survey .", "label": "", "metadata": {}, "score": "66.57552"}
{"text": "( d ) .vertline . D.sub.k ) is the conditional probability of occurrence of w.sub.j.sup .( d ) if the document D.sub.k is selected , P(D.sub.k.vertline.w.sub.i.sup .( q ) ) is statistically obtained from the query log , P(w.sub.j.sup .", "label": "", "metadata": {}, "score": "66.60602"}
{"text": "Latent semantic analysis ( LSA ) is a technique in natural language processing , in particular distributional semantics , of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms .", "label": "", "metadata": {}, "score": "66.65208"}
{"text": "New phrases are always being generated , from sources such technology , arts , world events , and law .Other phrases will decline in usage over time .Some existing information retrieval systems attempt to provide retrieval of concepts by using co - occurrence patterns of individual words .", "label": "", "metadata": {}, "score": "66.67784"}
{"text": "This bit vector is a bi - bit vector as described above .For each related phrase Qr of the query that is also present in the user model , both of the bits for this related phrase are set in the mask bit vector .", "label": "", "metadata": {}, "score": "66.68952"}
{"text": "All relevant surface generalizations ( in the supported target languages ) are compiled into a set of search templates , which contain all the relevant morphologic variations , category switches , etc . ; .The templates are matched against the database , and relevant documents are retrieved for the user .", "label": "", "metadata": {}, "score": "66.697556"}
{"text": "If you are looking to hire a patent attorney , you 've come to the right place .Protect your idea and hire a patent lawyer .Systems and methods for query expansion are described .In one aspect , new terms are extracted from a newly submitted query .", "label": "", "metadata": {}, "score": "66.787384"}
{"text": "Actual Translingual Retrieval .In this stage , we either transform the source language query into a query or set of queries in the target language(s ) , or we avoid the need to translate the query at all .In either event , the result is a set of target language documents believed to match the query to some degree .", "label": "", "metadata": {}, "score": "66.82861"}
{"text": "McDonald CJ , Dexter P , Schadow G , Chueh HC , Abernathy G , Hook J , Blevins L , Overhage JM , Berman JJ : SPIN Query Tools for De - identified Research on a Humongous Database .Proceedings of AMIA Annual Symposium 2005 , 2005 : 515 - 519 .", "label": "", "metadata": {}, "score": "66.88388"}
{"text": "PI .( P- ( w.sub.j.sup .( d ) .vertline.w.sub.i.sup.9q))+1 ) ) , wherein Q stands for the new terms ; and selecting the expansion terms from the particular ones as a function of rankings of the joint probabilities .", "label": "", "metadata": {}, "score": "66.893524"}
{"text": "P(w.sub.j.sup .( d ) .vertline . D.sub.k ) is the conditional probability of occurrence of w.sub.j.sup .( d ) if the document D.sub.k is selected .It is noted that .P(w.sub.j.sup .( d ) .vertline.w.sub.i.sup .", "label": "", "metadata": {}, "score": "67.006134"}
{"text": "( 4 ) the search always terminates and will retrieve at least one document .An immediate generalisation of this search is to allow the search to proceed down more than one branch of the tree so as to allow retrieval of more than one cluster .", "label": "", "metadata": {}, "score": "67.018036"}
{"text": "This description is then stored in association with the document , for example as a string or a hash of the sentences .During indexing , a newly crawled document is processed in the same manner to generate the document description .", "label": "", "metadata": {}, "score": "67.0231"}
{"text": "However , Zet - io pre- orders the inverted lists to maximize efficiency , removing many of the standard calculations performed in Zet and Zet - ph .This makes Zet - io comparable with the computational cost of our new methods .", "label": "", "metadata": {}, "score": "67.102936"}
{"text": "Space precludes a full explication of GOC , which would furthermore be redundant with prior published work [ 3 ] .Therefore a synoptic account is provided here , focusing on the extensions to GOC for this task .For full details about the base GOC , see [ 3 ] .", "label": "", "metadata": {}, "score": "67.10461"}
{"text": "The dataset contains a mix of inpatient and outpatient events and is modeled as a clinical web with entities interconnected with one another based on their relationships .The hospitalization objects are inpatient events .A batch of SQL queries was executed on the source relational database to extract this experimental subset of the EHR dataset with timestamps between June 2005 and December 2005 .", "label": "", "metadata": {}, "score": "67.11966"}
{"text": "R. Baeza - Yates and B. Ribeiro - Neto .Modern Information Retrieval .Addison Wesley , 1999 .M. Bender and M. Farach - Colton .The LCA problem revisited .LATIN , LNCS 1776 , pp\u02d988 - 94 , 2000 .", "label": "", "metadata": {}, "score": "67.15137"}
{"text": "The indexing system 110 then sorts 506 all of the posting lists in the index 150 in declining order according to the number of documents listedphrase number of in each posting list , so that the most frequently occurring phrases are listed first .", "label": "", "metadata": {}, "score": "67.19405"}
{"text": "In particular , the authority flow graph needs to be irreducible ( i.e. , ( V , E ) be strongly connected ) and aperiodic .The former is true due to the damping factor d , while the latter happens in practice .", "label": "", "metadata": {}, "score": "67.19692"}
{"text": "Text retrieval is confined to one language ( Salton 1970 ) .The query and the document collection must be in the same language , typically English .Success metrics are confined to relevance - only measures ( Salton and McGill 1983 ) , i.e. precision and recall , without regard to redundancy or suitability of the documents retrieved .", "label": "", "metadata": {}, "score": "67.202126"}
{"text": "This data model can abstract for both XML and relational data .Health standards organizations like Health Level 7 have been designing XML - based formats to represent EHRs .The Clinical Document Architecture [ 19 ] is such a format .", "label": "", "metadata": {}, "score": "67.20346"}
{"text": "By summarizing common patterns in raw data , the size of data can be greatlyreduced .Moreover , after aggregation , we may prune patterns with low frequenciesto reduce noise .One question is how to summarize raw log data for various log mining tasks .", "label": "", "metadata": {}, "score": "67.21023"}
{"text": "We continue to intersect the candidate list with the remaining gathered lists until either no lists remain , or the size of the candidate list becomes less than a threshold .At this point , for each item ( block number ) in the candidate list , we scan each of the corresponding text block looking for occurrences of q. The intersection phase of the algorithm can be thought of as a filtering step : blocks that can not contain the pattern are eliminated from the later scanning phase .", "label": "", "metadata": {}, "score": "67.224304"}
{"text": "However , it was discovered after the initial evaluation results were returned that there had been a problem with the evaluation of our submissions , as well as the submissions of user 17 .We were allowed to select one run for reevaluation by the EBI annotators ; we selected run 2 .", "label": "", "metadata": {}, "score": "67.26193"}
{"text": "Within this field , the configuration and management of large networks comprise storage devices and computers that are communicatively coupled to dissimilar computers and storage devices over a network , such as the Internet .Finally , it should be noted that the language used in the specification has been principally selected for readability and instructional purposes , and may not have been selected to delineate or circumscribe the inventive subject matter .", "label": "", "metadata": {}, "score": "67.28481"}
{"text": "Frederking , R. , Grannes , D. , Cousseau , P. , and Nirenburg , S. , 1993 .An MAT Tool and Its Effectiveness .In Proceedings of the DARPA Human Language Technology Workshop , Princeton , NJ .Frederking , R. and Nirenburg , S. 1994 . ''", "label": "", "metadata": {}, "score": "67.304794"}
{"text": "\" Our technique is to translate these top-$k$ problems into multidimensional geometric search problems .As an additional bonus , we describe some improvements to those problems .Abstract .Background .As the use of electronic health records ( EHRs ) becomes more widespread , so does the need to search and provide effective information discovery within them .", "label": "", "metadata": {}, "score": "67.3407"}
{"text": "The present invention provides efficient indexing and processing support for query expansion by applying a concept of multi - granularity .During query processing the tuples with information at a higher level of granularity are used to retrieve relevant documents .The original words of the query , at a finer granularity , can then be used to rank the documents in the answer set retrieved during query processing on the basis of exact , semantic , and syntactic similarity matches .", "label": "", "metadata": {}, "score": "67.52484"}
{"text": "Singhal A , Buckley C , Mitra M : Pivoted document length normalization .In Proceedings of Association for Computing Machinery Special Interest Group in Information Retrieval ( SIGIR ) .New York ; 1996:21 - 29 .Savoy J : Bayesian inference networks and spreading activation in hypertext systems .", "label": "", "metadata": {}, "score": "67.5316"}
{"text": "One isbased on content , and the other one based on propagation on the click - through bi - partite graph .Their method is equivalent to increasing the amount of training databy semi - supervised learning with click - through bipartite graph .", "label": "", "metadata": {}, "score": "67.58032"}
{"text": "Thus , ( car , dealer ) , ( auto , dealer ) , ( auto , sales office ) , and ( Ford , showroom ) are used to rank their degrees of relevance .The candidates are ranked based the degrees of relaxation in matching words in the document with words in the query .", "label": "", "metadata": {}, "score": "67.61867"}
{"text": "A processor 1204 may be used to accept queries presented by a user through the user interface 1202 .The processor 1204 then processes the query and performs ranking function .The results of the query and ranking function are presented back to the user through the user interface 1202 .", "label": "", "metadata": {}, "score": "67.67247"}
{"text": "The fundamental difference between the two search methods studied here , BM25 and CO , stems from their different modelling of the collection of EHRs : in BM25 , every document is modelled as a bag of keywords .CO models the corpus as a graph of interconnected entities .", "label": "", "metadata": {}, "score": "67.738144"}
{"text": "5 shows an exemplary procedure for query expansion .DETAILED DESCRIPTION .[0017 ]An Exemplary Operating Environment .[ 0018 ] Turning to the drawings , wherein like reference numerals refer to like elements , the invention is illustrated as being implemented in a suitable computing environment .", "label": "", "metadata": {}, "score": "67.752686"}
{"text": "In our experiments , a simpler technique related to LSI but without its attempt at dimension reduction produced equivalent results at lower processing cost : the Generalized Vector Space Model ( GVSM ) .Integrating Translingual IR into an Analyst 's Workstation .", "label": "", "metadata": {}, "score": "67.763145"}
{"text": "The algorithms and operations presented herein are not inherently related to any particular computer or other apparatus .Various general - purpose systems may also be used with programs in accordance with the teachings herein , or it may prove convenient to construct more specialized apparatus to perform the required method steps .", "label": "", "metadata": {}, "score": "67.908295"}
{"text": "Examples of proper names include Ford , Buick , NBA , and National Football League .As noted above , syntactical co - occurrence relationships are derived from analysis on the frequency of two words co - occurring in the same document .", "label": "", "metadata": {}, "score": "67.93939"}
{"text": "times .f ik ( q ) ( w i ( q ) , D k ) f ( q ) ( w i ( q ) ) ) , wherein w.sub.j.sup .( d ) and w.sub.i.sup .( q ) are an arbitrary document term and query term respectively , and P(w.sub.j.sup .", "label": "", "metadata": {}, "score": "67.94932"}
{"text": "The above strategies may be described as top - down searches .A bottom - up search is one which enters the tree at one of its terminal nodes , and proceeds in an upward direction towards the root of the tree .", "label": "", "metadata": {}, "score": "67.98582"}
{"text": "Compared with a query expanded with the traditional scheme , an expanded query in accordance with the present invention is more compact with fewer conditions to check since the query words are converted to entities at a coarser granularity .As a result , the query processing for the expanded query in accordance with the present invention is less expensive .", "label": "", "metadata": {}, "score": "68.00743"}
{"text": "In practice , the sizeof search and browse log data at a search engine often at the magnitude of tens oftera - bytes each day .Second , log data are quite noisy .For example , queries may beissued by machines for experiments ; user input in URL boxes may be redirected tosearch engines by web browsers ; and clicks on search result pages may be randomlymade by users .", "label": "", "metadata": {}, "score": "68.00816"}
{"text": "( q ) are an arbitrary document term and query term respectively , and P(w.sub.j.sup .( d ) .vertline.w.sub.i.sup .( q ) ) is defined as follows .times . times . times . times . times .( q ) is the conditional probability of the document D.sub.k being selected in case that w.sub.i.sup .", "label": "", "metadata": {}, "score": "68.01707"}
{"text": "The query is processed to identify any phrases that are present in the query , so as to retrieve the associated posting lists for the query phrases , and the related phrase information .In addition , in some instances a user may enter an incomplete phrase in a search query , such as \" President of the \" .", "label": "", "metadata": {}, "score": "68.086334"}
{"text": "Results .The evaluation results indicate that the method for expanding words associated with GO nodes is quite powerful ; we were able to successfully select appropriate evidence text for a given annotation in 38 % of Task 2.1 queries by building on this method .", "label": "", "metadata": {}, "score": "68.099205"}
{"text": "PI .( P- ( w.sub.j.sup .( d ) .vertline.w.sub.i.sup .( q))+1 ) ) wherein Q stands for the new terms ; and selecting the expansion terms from the particular ones as a function of rankings of the joint probabilities .", "label": "", "metadata": {}, "score": "68.14664"}
{"text": "In Proc . 14th SODA , pp\u02d9841 - 850 , 2003 .W.-K. Hon , R. Shah , and J. S. Vitter .Space - efficient framework for top - k string retrieval problems .In Proc .FOCS , pp\u02d9713 - 722 , 2009 . U.", "label": "", "metadata": {}, "score": "68.33632"}
{"text": "Sehgal AK , Srinivasan P : Retrieval with gene queries .BMC Bioinformatics 2006 , 7 : 220 .( 13 ) PubMed View Article .Farf\u00e1n F , Hristidis V , Ranganathan A , Weiner M : XOntoRank : Ontology - Aware Search of Electronic Medical Records .", "label": "", "metadata": {}, "score": "68.42865"}
{"text": "Joslyn C , Mniszewski S , Fulmer A , Heaton G : The Gene Ontology Categorizer .Bioinformatics 2004 , 20 ( Suppl 1 ) : I169-I177 .View Article PubMed .Witten IH , Moffat A , Bell T : Managing Gigabytes : Compressing and Indexing Documents and Images New York : Van Nostrand Reinhold 1994 .", "label": "", "metadata": {}, "score": "68.48011"}
{"text": "N , April 2013 .20 \u00b7 through an iterative process .It is easy to see that the values Skare non - decreasingand have an upper bound of 1 .Thus , the iterative process converges .The similarity propagation can overcome the sparsity in log data .", "label": "", "metadata": {}, "score": "68.55575"}
{"text": "The method according to . claim 1 , wherein the step of executing progresses in successive stages until a predetermined number of the ones of the documents associated with the corresponding ones of the higher granularity concepts are retrieved .The method according to . claim 10 , wherein each of the stages represents a class of expansion .", "label": "", "metadata": {}, "score": "68.57204"}
{"text": "In web search , with large amounts of search and browse log data available , itbecomes possible to conduct deeper query understanding and represent intents ofqueries with richer representations .Web pages are hypertext documentscontaining HTML tags and links .One can create rich document representationsfor web pages and leverage them in web search .", "label": "", "metadata": {}, "score": "68.600945"}
{"text": "Are they all localized together in the structure , or in multiple groups , or spread out over a wide area ?This problem had not actually been well defined or addressed previously , and presents novel problems for computer science ( see Appendix A below ) .", "label": "", "metadata": {}, "score": "68.63877"}
{"text": "We envision the following framework for presenting multilingual search results to the information gatherer : .Based on the quality of the match to the query that was used to retrieve each document , documents are scored and sorted using MMR ; .", "label": "", "metadata": {}, "score": "68.74342"}
{"text": "A phrase window may be terminated by an end of line , a paragraph return , a markup tag , or other indicia of a change in content or format .FIG .3 illustrates a portion of a document 300 during a traversal , showing the phrase window 302 starting at the word \" stock \" and extending 5 words to the right .", "label": "", "metadata": {}, "score": "68.76123"}
{"text": "The document IDs represent each document selected from a list generated by the search engine in response to searching for information relevant to corresponding ones of the query terms .BRIEF DESCRIPTION OF THE DRAWINGS .[ 0011 ] The following detailed description is described with reference to the accompanying figures .", "label": "", "metadata": {}, "score": "68.772705"}
{"text": "Subnetwork of WPP with 34 words for document JBC_1999/bc005868 .The red nodes denote the words retrieved from the given GO annotation ( 0007266 : \" Rho \" , \" protein \" , \" signal \" , \" transduce \" ) : W GO .", "label": "", "metadata": {}, "score": "68.913445"}
{"text": "In a given phrase window 302 , identify all good phrases in the window , starting at position i. Each good phrase is denoted as g i .Thus , g 1 is the first good phrase , g 2 would be the second good phrase , and so forth .", "label": "", "metadata": {}, "score": "68.93348"}
{"text": "vertline .D.s- ub.k ) is the conditional probability of occurrence of w.sub.j.sup .( d ) if the document D.sub.k is selected , P(D.sub.k.vertline.w.sub.i.sup .( q ) ) is statistically obtained from the query log , p(w.sub.j.sup .( d ) .", "label": "", "metadata": {}, "score": "68.93582"}
{"text": "New York , USA .Jing , Y. et al . , \" An Association Thesaurus for Information Retrieval \" , Proceedings of RIAO-94 , 4th International Conference on Intelligent Multimedia Information Retrieval Systems and Management , Oct. 11 , 1994-Oct . 13 , 1994 [ online ] [ Retrieved on Aug. 9 , 2005 ] Retrieved from the Internet : .", "label": "", "metadata": {}, "score": "68.99414"}
{"text": "Similarly , during preparation of the results of a search query , the documents in the search result set can be processed to eliminate duplicates .The present invention has further embodiments in system and software architectures , computer program products and computer implemented methods , and computer generated user interfaces and presentations .", "label": "", "metadata": {}, "score": "69.002235"}
{"text": "Appendix A : The gene ontology categorizer ( GOC ) and its extensions .GOC is an algorithm for categorization in hierarchies represented as partially ordered sets ( posets [ 13 ] ) .Posets are distinguished from networks , which are represented as directed graphs : while every poset is a directed graph , the converse is not true .", "label": "", "metadata": {}, "score": "69.07828"}
{"text": "The method of .claim 1 , wherein comparing the document description of the first document with a document description of the second document further comprises : . retrieving a stored document description of the first document comprising selected sentences of the document , wherein the selected sentences are ordered in the document description as a function of a number of related phrases in the selected sentences ; and . retrieving a stored document description of the second document comprising selected sentences of the document , wherein the selected sentences are ordered in the document description as a function of a number of related phrases in the selected sentences .", "label": "", "metadata": {}, "score": "69.09337"}
{"text": "Two scores are calculated for each page : a hub score and an authorityscore .A page has a high hub score if it links to many pages .A page has a highauthority score if it is pointed by many pages .", "label": "", "metadata": {}, "score": "69.09487"}
{"text": "Therefore , in the ranking phase , the original words in the candidate documents are accessed and are used for ranking .In FIG .8 , four candidate documents are shown with keywords satisfying the condition : .( Sem 1 V Ford V Buick)\u039b(Sem 2 V Ford V Buick ) .", "label": "", "metadata": {}, "score": "69.100525"}
{"text": "5 and parents , children , and siblings from this figure .Some of the results appear impressive , for example approaching 100 % for all ancestors and low specificity .This is misleading , since simply the topmost GO nodes like \" biological process \" and \" gene ontology \" are identified .", "label": "", "metadata": {}, "score": "69.28105"}
{"text": "Their methodlearns the topic model given the labeled data using variational EM algorithm .Inlearning , the supervision information is incorporated into the objective function asconstraints .As a result , the probabilities of words given topics , that is , probabilitiesof contexts given classes are learned from the documents , and they can be utilized aspatterns for entity mining .", "label": "", "metadata": {}, "score": "69.35117"}
{"text": "In our experiments , we use a relational anonymized EHR database provided by the Cardiac Division of Miami Children 's Hospital .As we see in Figure 3 , the schema links through primary - to - foreign keys entities like patients , hospitalizations of patients , employees , medications and associated events .", "label": "", "metadata": {}, "score": "69.351364"}
{"text": "For example , if the search query is \" President of the United , \" the search system 120 can automatically suggest to the user \" President of the United States \" as the search query .After the last stage of the indexing process is completed , the good phrase list 208 will contain a large number of good phrases that have been discovered in the corpus .", "label": "", "metadata": {}, "score": "69.35675"}
{"text": "As noted above , the co - occurrence matrix 212 is an m\u00d7m matrix of storing data associated with the good phrases .Each row j in the matrix represents a good phrase g j and each column k represented a good phrase g k .", "label": "", "metadata": {}, "score": "69.44211"}
{"text": "In this model every XML element is represented as a node , and the parent - child relationships between elements are captured as edges called containment edges .The use of ID / IDREF attributes in XML [ 14 ] creates an additional edge -- the ID / IDREF edge -- between elements that are not directly connected by a parent - child relationship .", "label": "", "metadata": {}, "score": "69.4482"}
{"text": "See G. Golub et al . , \" Matrix Computations , \" Johns - Hopkins , Baltimore , Second Edition , 1989 .Retrieval is then performed using the database of singular values and vectors obtained from the truncated SVD .Preliminary evaluation of LSI indicates that this approach of information retrieval is a more robust measure than that based on individual terms .", "label": "", "metadata": {}, "score": "69.51169"}
{"text": "claim 39 , wherein the words failing to meet the predetermined criterion are proper nouns .The system according to .claim 39 , where the syntactically related words are words co - occurring in one of the documents above a threshold level of frequency .", "label": "", "metadata": {}, "score": "69.56044"}
{"text": "ep ] using quantile(D[sp . ep],r ) in O(logN ) time .In the remainder of this section we refer to D[sp .ep ] as X[1 .m ] with m a power of 2 , and assume we can probe X as if it were sorted ( with each probe requiring O(logN ) time ) .", "label": "", "metadata": {}, "score": "69.56974"}
{"text": "We also show the containment statistics for these query terms .Evaluation Measures .To evaluate the results of each approach , we computed the sensitivity and specificity of each method , for each query .The physician users defined the truth or gold standard .", "label": "", "metadata": {}, "score": "69.57976"}
{"text": "then to satisfy the ( K 1 AND K 2 ) part we intersect the K 1 and K 2 lists , to satisfy the ( K 3 AND ( NOT K 4 ) ) part we subtract the K 4 list from the K 3 list .", "label": "", "metadata": {}, "score": "69.69284"}
{"text": "It has been popularised by Norbert Wiener in his book Cybernetics .In information retrieval it has been used with considerable effect .Consider now a retrieval strategy that has been implemented by means of a matching function M .Furthermore , let us suppose that both the query Q and document representatives D are t -dimensional vectors with real components where t is the number of index terms .", "label": "", "metadata": {}, "score": "69.7072"}
{"text": "Neither should computing environment 120 be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in computing environment 120 .[ 0020 ] The methods and systems described herein are operational with numerous other general purpose or special purpose computing system environments or configurations .", "label": "", "metadata": {}, "score": "69.71385"}
{"text": "1 Introduction Text search is a vital enabling technology in the information age .Web search engines such as Google allow users to find relevant information quickly and easily in a large corpus of text , T .Typically , a user provides a query as a list of words , and the information retrieval ( IR ) system returns a list of relevant documents from T , ranked by similarity .", "label": "", "metadata": {}, "score": "69.73488"}
{"text": "The method according to . claim 22 , wherein each of the stages represents a slot within a class of expansion .The method according to . claim 22 , wherein within each of the stages , the ones of the documents are retrieved in an order reflecting a level of importance assigned to at least one of the words of the query .", "label": "", "metadata": {}, "score": "69.742905"}
{"text": "Program modules generally include routines , programs , objects , components , data structures , etc . , that perform particular tasks or implement particular abstract data types .[ 0019 ]FIG .1 illustrates an example of a suitable computing environment 120 on which the subsequently described systems , apparatuses and methods to expand queries may be implemented .", "label": "", "metadata": {}, "score": "69.82196"}
{"text": "The method according to . claim 14 , wherein the higher granularity semantic concepts each contain synonyms .The method according to . claim 14 , wherein the higher granularity concepts are higher granularity syntactical concepts .The method according to .", "label": "", "metadata": {}, "score": "69.879196"}
{"text": "Appendix A also includes technical information on these extensions .Input terms are mapped to GO nodes via one of three mechanisms : .Direct : The term occurs in the node label of GO node .Definitional : The term occurs in the definition text associated with GO node .", "label": "", "metadata": {}, "score": "69.8934"}
{"text": "Honolulu , Hawaii ; 2002:517 - 526 .Brinkmeier M : PageRank revisited .ACM Transactions on InternetTechnology 2006 , 6 ( 3 ) : 282 - 301 .( 8) View Article .Lin J : PageRank without Hyperlinks : Reranking with Related Document .", "label": "", "metadata": {}, "score": "69.99362"}
{"text": "Each edge is labelled with a role , which may be omitted .For instance , the associated_events -to- employee edge in Figure 3 has role \" created_by \" .Schema of the EHR dataset .The schema graph of the EHR dataset is a directed graph that describes the structure of the EHR dataset in Figure 1 .", "label": "", "metadata": {}, "score": "70.0067"}
{"text": "In Proceedings of IEEE International Conference on Data Engineering ( ICDE ) .San Jose ; 2002:5 - 16 .Hristidis V , Papakonstantinou Y : DISCOVER : Keyword Search in Relational Databases .In Proceedings of Very Large Databases ( VLDB ) .", "label": "", "metadata": {}, "score": "70.02724"}
{"text": "A user 's behavior in a web browser can be categorized into two states : the search stateand browse state.results.Browse logs are usually collected by client - side browser plug - ins or proxies ofInternet Service Providers .They record all URLs visited by users , no matter fromsearch engines themselves or other web servers .", "label": "", "metadata": {}, "score": "70.14363"}
{"text": "W .V . ) m .n . ) g .h . ) log .V .V .VW .W .W .Similarly , the lookup cost of executing Q under multi - granularity expansion will be : . LookupCost .", "label": "", "metadata": {}, "score": "70.29379"}
{"text": "vertline.w.sub.i.sup .( q ) ) is defined as follows .times . times . times . times . times .( q ) ) is the conditional probability of the document D.sub.k being selected in case that w.sub.i.sup .( q ) appears in the user query , P(w.sub.j.sup .", "label": "", "metadata": {}, "score": "70.30985"}
{"text": "These findings are referred to as the Semantic Proximity Effect .[ 6 ] .When participants made mistakes in recalling studied items , these mistakes tended to be items that were more semantically related to the desired item and found in a previously studied list .", "label": "", "metadata": {}, "score": "70.38562"}
{"text": "'smethod are based on typical substitutions web searchers make .The aforementioned methods can automat - ically mine similar queries from click - through data and session data .These methodsusually work very well for head queries , but not for tail queries .", "label": "", "metadata": {}, "score": "70.429794"}
{"text": "After the user clicks on a webpage in the result list , she may click onanother webpage .What may such a click tell us ?Possibly , the webpage clickedpreviously does not completely satisfy the user 's information need .Therefore , theuser is looking for more information .", "label": "", "metadata": {}, "score": "70.62575"}
{"text": "( d ) is a normalized weight of the term w.sub.j.sup .( d ) in document D.sub.k , which is divided by a maximum value of term weights in a document D.sub.k .A method as recited in claim 3 , wherein identifying expansion terms further comprises : calculating joint probabilities for each of the particular ones according to : P(w.sub.j.sup .", "label": "", "metadata": {}, "score": "70.63545"}
{"text": "Run 3 : Same configuration as above for annotation portion .Evidence selection used the paragraph selection algorithm based on GOC results .Task 2.2 .Run 1 : A configuration using the full system architecture .Evidence selection consisting of the simple sentence selection algorithm .", "label": "", "metadata": {}, "score": "70.73078"}
{"text": "12 \u00b7 ground .At the beginning the labeled nodes have a unit of voltage , and after someiterations the voltages of all the nodes become stable .Li et al .[2008 ] proposed a method of classifying queries into a class ( topic ) usingclick - through bipartite and some labeled queries .", "label": "", "metadata": {}, "score": "70.73952"}
{"text": "Deng M , Tu Z , Sun F , Chen R : Mapping Gene Ontology to Proteins Based on Protein - Protein Interaction Data .Bioinformatics 2004 , 20 ( 6 ) : 895 - 902 .View Article PubMed .Schroder , Bernd SW : Ordered Sets , Birkhauser , Boston 2003 .", "label": "", "metadata": {}, "score": "70.80919"}
{"text": "Precision for different values of Specificity , s .Log of precision as a function of s , broken out by the distinct ( non - cumulative ) family relations .By constrast , the precision results for \" nuclear family \" in Fig .", "label": "", "metadata": {}, "score": "70.82681"}
{"text": "Description .TECHNICAL FIELD .[ 0001 ] The invention pertains to information retrieval .BACKGROUND .[0002 ] People increasingly rely on the World Wide Web ( \" Web \" ) to satisfy diverse information needs .To meet these needs , existing search engine technology allows users to input a query consisting of one or more keywords for a search for Web documents containing the keywords .", "label": "", "metadata": {}, "score": "70.834404"}
{"text": "Space - efficient algorithms for document retrieval .In B. Ma and K. Zhang , editors , Proc . 18thCPM , LNCS 4580 , pp\u02d9205 - 215 , 2007 .I. Witten , A. Moffat , and T. Bell .Managing Gigabytes .", "label": "", "metadata": {}, "score": "70.90076"}
{"text": "The matrix product contains all these dot products .Element ( which is equal to element ) contains the dot product ( ) .Likewise , the matrix contains the dot products between all the document vectors , giving their correlation over the terms : .", "label": "", "metadata": {}, "score": "70.9761"}
{"text": "Tothat extent , browse logs provide a more comprehensive picture of user behaviorsthan search logs do .In addition , browse logs also contain URLs and timestampsof web pages browsed by the users .Browse logs , however , usually do not containsearch results returned from search engines .", "label": "", "metadata": {}, "score": "71.05882"}
{"text": "claim 1 , wherein selecting a first document and a second document from a set of documents further comprises : . selecting the first document and second document during indexing of the first document .The method of .claim 1 , further comprising storing a document description in association with the document to which the document description corresponds .", "label": "", "metadata": {}, "score": "71.15688"}
{"text": "The presentation system 130 is responsible for modifying the search results including removing near duplicate documents , and generating topical descriptions of documents , and providing the modified search results back to the front end server 140 , which provides the results to the client 170 .", "label": "", "metadata": {}, "score": "71.301254"}
{"text": "[ 0051 ] Q stands for the terms extracted from the newly submitted query 214 .Thus , for every query , we get a list of candidate expansion terms as well as the conditional probabilities between each term and the query .", "label": "", "metadata": {}, "score": "71.36525"}
{"text": "The documents can then be shown to the user , grouped accordingly under the appropriate cluster names as headings .For example , assume a search query of \" blue merle agility training \" , for which the search system 120 retrieves 100 documents .", "label": "", "metadata": {}, "score": "71.385376"}
{"text": "Joslyn C , Mniszewski S , Fulmer A , Heaton G : Structural Classification in the Gene Ontology .Proceedings of the Sixth Annual Bio - Ontologies Meeting ( Bio - Ontologies 2003 ) , Brisbane , Australia 2003 .Joslyn C : Poset Ontologies and Concept Lattices as Semantic Hierarchies .", "label": "", "metadata": {}, "score": "71.39587"}
{"text": "Salton , G. , 1970 . ''Automatic Processing of Foreign Language Documents ' ' , Journal of American Society for Information Sciences , Vol .21 , pp .187 - 194 .DOI : 10.1007/978 - 3 - 642 - 15781 - 3_17 In book : Algorithms - ESA 2010 , pp.194 - 205 .", "label": "", "metadata": {}, "score": "71.435326"}
{"text": "Figure 4 shows a sample user survey page for query \" respiratory distress \" .Figure 5 shows a sample \" Full Description \" page of a hospitalization object for query \" respiratory distress \" .Sample User Survey Page for query \" respiratory distress \" .", "label": "", "metadata": {}, "score": "71.48012"}
{"text": "vertline . D.sub.k ) is a function of frequency of occurrence of w.sup.j.sup .( d ) in a document D.sub.k , as well as the occurrence of the term w.sub.j.sup .( d ) in all documents identified in the user log .", "label": "", "metadata": {}, "score": "71.48466"}
{"text": "For each collection , a total of 200 queries of character lengths ranging from 3 to 20 which appear at least 5 times in the collection were randomly generated , for a total of 3,600 sample queries .Each query was run 10 times .", "label": "", "metadata": {}, "score": "71.50159"}
{"text": "Anessential idea is that the linguistic knowledge learned from heads can be appliedto tails .An operation can be insertion , deletion , and substitutionof letters in a word , splitting of a word into multiple words , merging of multiplewords into a single word , word stemming , or some others .", "label": "", "metadata": {}, "score": "71.51442"}
{"text": "After identifying the set of nodes which are annotated to that set , GOC traverses the structure of the GO , percolating hits upwards , and calculating scores for each GO node .GOC then returns a rank - ordered list of GO nodes representing cluster heads .", "label": "", "metadata": {}, "score": "71.55028"}
{"text": "] m . log .W .f .V . ) m .n . ) g .f .h . ) log .V .V .V .W .f .W .W .f .", "label": "", "metadata": {}, "score": "71.60567"}
{"text": "D Query Data Table 2 summarizes attributes of the queries used .Note the unusually low aver- age occ and docc values for the queries of length 5 for the protein data set .Page 16 .query lengthprotein queries avg total avg doc avg total avg doc occ 3 10,458 12,510 4 972 5 304 6 723 7 979 8 764 9 682 10 + 535 Table 2 .", "label": "", "metadata": {}, "score": "71.68817"}
{"text": "Referring to the example of .FIG .3 , assume that the \" stock dogs \" is on the good phrase list 208 , as well as the phrases \" Australian Shepherd \" and \" Australian Shepard Club of America \" .", "label": "", "metadata": {}, "score": "71.70572"}
{"text": "Jacobs , P. , Krupka , G. , Rau , L. , Mauldin , M. and Kaufmann , T. , 1992 . ''Description of the TIPSTER / SHOGUN System as used for MUC-4 ' ' , Proceedings of the Fourth Message Understanding Conference , McLean , Virginia .", "label": "", "metadata": {}, "score": "71.73166"}
{"text": "3 .An example of a query under the multi - granularity query expansion scheme of the present invention is shown in FIG .7 .Multi - granularity query expansion transforms the words car and dealer into the concepts Sem 1 and Sem 2 by using the table in FIG .", "label": "", "metadata": {}, "score": "71.74032"}
{"text": "Rather , such a system is likely to also retrieve and highly rank documents that are about Australia ( and have nothing to do with dogs ) , and documents about \" shepherds \" generally .The problem here is that conventional systems index documents based on individual terms , than on concepts .", "label": "", "metadata": {}, "score": "71.8617"}
{"text": "( remember n is the number of documents in the cluster ) by the following procedure .So , finally we obtain as a cluster representative a binary vector C .In both cases the intuition is that keywords occurring only once in the cluster should be ignored .", "label": "", "metadata": {}, "score": "71.88939"}
{"text": "Query expansion has been suggested as a technique for dealing with this problem .When query expansion is used , the \" car dealer \" query is expanded as follows to include terms with similar meanings : .Line 1 . [", "label": "", "metadata": {}, "score": "72.0388"}
{"text": "Then , features of GO nodes are cast as a set of labels X , and can be , for example , the gene products annotated to GO nodes , or in our case are the terms making up the labels of each GO node .", "label": "", "metadata": {}, "score": "72.08188"}
{"text": "trec queries occoccocc 17,204 10,446 6,071 4,086 2,312 2,000 1,523 2,177 114,379 48,123 23,660 9,355 4,320 6,365 2,035 3,390 919 230 664 879 761 649 523 Table 3 shows the statistical properties of the new phrase queries of varying word length , from 2 to 15 .", "label": "", "metadata": {}, "score": "72.10632"}
{"text": "\" The search system 100 operates over a large corpus of documents , such as the Internet and World Wide Web , but can likewise be used in more limited collections , such as for the document collections of a library or private enterprises .", "label": "", "metadata": {}, "score": "72.19101"}
{"text": "Journal of Inform Prim Care 2007 , 15 ( 2 ) : 121 - 7 .Podowski RM , Cleary JG , Goncharoff NT : Suregene , a scalable system for automated term disambiguation of gene and protein names .Journal of Bioinformatics and Computational Biology ( JCB ) 2005 , 3 ( 3 ) : 743 - 70 .", "label": "", "metadata": {}, "score": "72.21565"}
{"text": "Health standards organizations like Health Level 7 have been designing XML - based formats to represent EHRs .Such XML formats have been adopted by pioneering health institutes like Regenstrief [ 13 ] , and variations of these formats are expected to be adopted by many more institutes in the near future .", "label": "", "metadata": {}, "score": "72.34586"}
{"text": "vertline .D.s- ub.k ) is a function of frequency of occurrence of w.sub.j.sup .( d ) in a document D.sub.k , as well as the occurrence of the term w.sub.j.sup .( d ) in all documents identified in the user log .", "label": "", "metadata": {}, "score": "72.35332"}
{"text": "Both products have the same non - zero eigenvalues , given by the non - zero entries of , or equally , by the non - zero entries of .Now the decomposition looks like this : .The values are called the singular values , and and the left and right singular vectors .", "label": "", "metadata": {}, "score": "72.40498"}
{"text": "( d ) is a normalized weight of the term w.sub.j.sup .( d ) in document D.sub.k , which is divided by a maximum value of term weights in a document D.sub.k .A computing device as recited in claim 16 , wherein the computer - program instructions for identifying expansion terms further comprise instructions for : calculating joint probabilities for each of the particular ones according to : P(w.sub.j.sup .", "label": "", "metadata": {}, "score": "72.49268"}
{"text": "Retrieved texts are presented verbatim to the user , possibly with keywords highlighted , rather than summarized , gisted , grouped , or otherwise processed .Classification of documents into index categories , such as those in library catalogs is a purely manual process , and as such it is laborious , expensive , time - consuming , and lacking in consistency .", "label": "", "metadata": {}, "score": "72.515854"}
{"text": "Experimental Evaluation .The experimental dataset is a subset of the relational anonymized EHR database of the Cardiac Division of Miami Children 's Hospital , which contains clinical entities like hospitalization , patient , employee , medication , diagnosis , diagnostics , cardiac , events , and labs .", "label": "", "metadata": {}, "score": "72.53364"}
{"text": "Users ' behavior in a webbrowser can be categorized into two states , namely , the search state and the browsestate ( see Figure 1 ) .In the search state , a user raises a query to a search engine and selectively clickson the search results returned by the search engine .", "label": "", "metadata": {}, "score": "72.63461"}
{"text": "4 ( c ) is computed : . Number .Of .Rows .[ .b . ) . ]V .V .V .W .f .W .W .f .TotalSize . [ .b . ) . ] q . )", "label": "", "metadata": {}, "score": "72.64967"}
{"text": "In that case , the second phrase has significant information gain with respect to the first phrase .Semantically , related phrases will be those that are commonly used to discuss or describe a given topic or concept , such as \" President of the United States \" and \" White House .", "label": "", "metadata": {}, "score": "72.66304"}
{"text": "FIG .3 , the secondary window 304 is 30 words .The co - occurrence matrix 212 thus maintains : .R(j , k ) : Raw Co - occurrence count .The number of times that phrase g j appears in a secondary window 304 with phrase g k ; .", "label": "", "metadata": {}, "score": "72.68224"}
{"text": "We participated in the BioCreAtIvE evaluation ( Critical Assessment of Information Extraction in Biology ) .We approached the task utilizing various combinations of two distinct methods .The first method is an unsupervised algorithm for expanding words associated with GO nodes .", "label": "", "metadata": {}, "score": "72.708824"}
{"text": "Precision and recall as a function of specificity s across these different categories are shown in Figure 5 .Results are especially poor for direct hits and very high specificity .For moderate levels of specificity at the level of nuclear and extended families , our results approach 50 % precision .", "label": "", "metadata": {}, "score": "72.73066"}
{"text": "That is , paragraphs containing the largest number of words also found in W GOProx are selected .The Gene ontology categorizer .For Task 2.2 , we were required to predict the appropriate GO node(s ) associated with a protein based on the information in a given document .", "label": "", "metadata": {}, "score": "72.90947"}
{"text": "The corresponding document lists are also merged .A similar procedure is followed for the entries in the P - S form .As shown in FIGS .4 ( c ) , entries ( Ford , car ) and ( Ford , auto ) are replaced by ( Ford , Sem 1 ) .", "label": "", "metadata": {}, "score": "72.910416"}
{"text": "NATO Science Series ( Edited by : Melo - Pinto P , Teodorescu HN , Fukuda T ) .IOS Press 2003 , 249 - 265 .Shatkay , et al .: Genes , Themes and Microarrays Using Information Retrieval for Large - Scale Gene Analysis .", "label": "", "metadata": {}, "score": "72.96525"}
{"text": "Via customization , various CO profiles can be created to suit the diverse information needs of various kinds of users , such as researchers , pharmacists , physicians , and nurses .For example , for a pharmacist , the medications are typically most important ; for a researcher , the patient and employee information may not be as relevant as other information .", "label": "", "metadata": {}, "score": "72.96715"}
{"text": "For example , a given news article produced by a news bureau such as the Associated Press , may be replicated in a dozen or more websites of individual newspapers .Including all of these duplicate documents in response to a search query only burdens the user with redundant information , and does not usefully respond to the query .", "label": "", "metadata": {}, "score": "73.01886"}
{"text": "Acknowledgements .This work was sponsored by the Department of Energy , and by a cooperative research agreement with the Procter & Gamble Company , who also supplied us with the list of protein synonyms .We would like to thank Andy Fulmer and Jun Xu , and the LANL Protein Function Inference Group for their contributions to this work .", "label": "", "metadata": {}, "score": "73.029884"}
{"text": "Tan et al .[2006 ] built personalized language models .Suppose that query qi issubmitted by user u. For each query qj , the method constructs a languagemodel \u03b8j from both the clicked and unclicked search results of qj .", "label": "", "metadata": {}, "score": "73.06653"}
{"text": "The next step is to determine 402 which related phrases together form a cluster of related phrases .A cluster is a set of related phrases in which each phrase has high information gain with respect to at least one other phrase .", "label": "", "metadata": {}, "score": "73.090965"}
{"text": "Improving the quality and safety of care often requires identification of medical records that meet specified criteria .Although the availability of electronic administrative and clinical data has facilitated many types of automated searches , the searching often requires technical expertise , slow batch processes , and tolerance for low sensitivity of results .", "label": "", "metadata": {}, "score": "73.111755"}
{"text": "Gedeon , T.D. et al . , \" Hierarchical Co - Occurrence Relations \" , Systems , Man , and Cybernetics , IEEE International Conference in San Diego , CA , Oct. 11 , 1998-Oct .14 , 1998 , pp .", "label": "", "metadata": {}, "score": "73.23996"}
{"text": "Conclusion .There is still significant room for improvement on this task .However , the initial results show promise for both of the methods we explored , and further analysis has helped us to better understand the impact of the various parameters of the system .", "label": "", "metadata": {}, "score": "73.32181"}
{"text": "A toy example of a labeled poset .GO nodes are modeled by nodes with capital letters , with gene labels annotated to them in lower case .Note that the structure is neither a tree nor a lattice , but technically , the Hasse diagram of a poset P .", "label": "", "metadata": {}, "score": "73.43109"}
{"text": "vertline.w.sub.i.sup .( q ) ) is defined as follows .times . times . times . times . times .- sup .( q ) ) is the conditional probability of the document D.sub.k being selected in case that w.sub.i.sup .", "label": "", "metadata": {}, "score": "73.43787"}
{"text": "The present invention provides a solution to the problem of word mismatch and resulting inefficient query processing via a method and apparatus for efficient query expansion using reduced size indices and for progressive query processing .More specifically , queries are expanded conceptually , rather than physically , using semantically similar and syntactically related words to those specified by the user in the query to reduce the chances of missing relevant documents .", "label": "", "metadata": {}, "score": "73.500854"}
{"text": "That is , their probabilities of being in the class are all set to one .The learning process of themodel then becomes prorogation of the class labels to the rest of nodes on the graphthrough random walk .The algorithm keeps updating the probabilitieson the nodes and is guaranteed to be converged .", "label": "", "metadata": {}, "score": "73.65738"}
{"text": "Without loss of generality then , the documents generally , regardless of format or location ( e.g. , which website or database ) will be collectively referred to as a corpus or document collection .Each document has an associated identifier that uniquely identifies the document ; the identifier is preferably a URL , but other types of identifiers ( e.g. , document numbers ) may be used as well .", "label": "", "metadata": {}, "score": "73.66269"}
{"text": "An incomplete phrase is a phrase that only predicts its phrase extensions , and which starts at the left most side of the phrase ( i.e. , the beginning of the phrase ) .The \" phrase extension \" of phrase p is a super - sequence that begins with phrase p. For example , the phrase \" President of \" predicts \" President of the United States \" , \" President of Mexico \" , \" President of AT&T \" , etc .", "label": "", "metadata": {}, "score": "73.8823"}
{"text": "A preferred embodiment of a method and apparatus for efficient query expansion is described below in detail with reference to the accompanying drawings .It is to be noted that while the following discussion is presented in the context of the NEC PERCIO Object Oriented Database Management System ( OODBMS ) , the present invention is not so limited .", "label": "", "metadata": {}, "score": "73.95933"}
{"text": "We startwith an introduction to search and browse log data and an overview of frequently - used datasummarizations in log mining .INTRODUCTIONHuge amounts of search log data have been accumulated in various search engines .Currently , a commercial search engine receives billions of queries and collects tera - bytes of log data on every single day .", "label": "", "metadata": {}, "score": "74.03334"}
{"text": "V , No .N , April 2013 , Pages 1 - 42 . 2 \u00b7 data mining .We try to bridge theresearch frontier and the industrial practice .Since raw log data is usually noisy and of extremely large size , pre - processing is often conducted before mining algorithms are applied .", "label": "", "metadata": {}, "score": "74.11686"}
{"text": "PB and MW participated in the user survey , analyzed results , contributed to conclusions and discussions and helped to draft and revise the manuscript .All authors read and approved the final manuscript .Authors ' Affiliations .School of Computing and Information Sciences , Florida International University .", "label": "", "metadata": {}, "score": "74.152954"}
{"text": "The expected value E is the percentage of documents in the collection expected to contain g j .This is computed , for example , as the ratio of the number of documents containing g j to the total number T of documents in the collection that have been crawled : P(j)/T. .", "label": "", "metadata": {}, "score": "74.219055"}
{"text": "In addition , the present invention is not described with reference to any particular programming language .It is appreciated that a variety of programming languages may be used to implement the teachings of the present invention as described herein , and any references to specific languages are provided for disclosure of enablement and best mode of the present invention .", "label": "", "metadata": {}, "score": "74.35455"}
{"text": "For example then , \" President of the United \" is an incomplete phrase because the only other phrase that it predicts is \" President of the United States \" which is an extension of the phrase .The incomplete phrase list 216 itself is very useful during actual searching .", "label": "", "metadata": {}, "score": "74.3707"}
{"text": "V , No .N , April 2013 .Their method builds a TF - IDF vector V ( ck ) for each nodeck using its associated documents .Finally , the user'spreference on topic ck is derived by aggregating the probabilities Pd(c ) over all thevisited documents .", "label": "", "metadata": {}, "score": "74.44594"}
{"text": "[ 0034 ] The query expansion module identifies one or more query expansion terms 206 from analysis of query session(s ) 208 stored in query log(s ) 210 .A query session is represented , for example , as follows : . [", "label": "", "metadata": {}, "score": "74.46634"}
{"text": "claim 39 , wherein the order of relevance is an exact match , a semantic match , a syntactical match and no match between the words of the query and words in the retrieved ones of the documents .The system according to .", "label": "", "metadata": {}, "score": "74.59778"}
{"text": "Further , there has been recent work on the use of medical ontologies to improve the search quality , where the ontology is generally used to perform query expansion [ 26 - 28 ] .Clinical ObjectRank ( CO ) Variants .", "label": "", "metadata": {}, "score": "74.60983"}
{"text": "claim 39 , wherein the higher granularity semantic concepts each contain synonyms .The system according to .claim 39 , the higher granularity concepts are higher granularity syntactical concepts .The system according to .claim 41 , wherein the higher granularity syntactical concepts each contain words co - occurring in ones of the documents above a threshold level of frequency .", "label": "", "metadata": {}, "score": "74.615654"}
{"text": "During an initial version of the User Survey that we conducted , we found that the raters are mostly interested in Hospitalization entities as they provide very specific details of an inpatient event .The rest of the entity types ( the non - hospitalization ones ) - patient , employee , medication , diagnosis , diagnostics , cardiac , events , and labs , assist in the ranking of the hospitalization entities .", "label": "", "metadata": {}, "score": "74.72784"}
{"text": "KV managed the project , developed the text pre - processing and NLP tools , built the integrated infrastructure of the complete system , and identified the GOC extensions necessary for our solution .JC provided database support , specifically for protein name management .", "label": "", "metadata": {}, "score": "74.89528"}
{"text": "Conclusions .Authority - flow techniques can greatly improve the detection of relevant information in EHRs and hence deserve further study .Electronic supplementary material .The online version of this article ( doi : 10 .1186/\u200b1472 - 6947 - 10 - 64 ) contains supplementary material , which is available to authorized users .", "label": "", "metadata": {}, "score": "75.121445"}
{"text": "Shanghai ; 2009:820 - 831 .Lieberman MI , Ricciardi TN , Masarie FE , Spackman KA : The Use of SNOMED \u00a9 CT Simplifies Querying of a Clinical Data Warehouse .Proceedings of AMIA Annual Symposium 2003 , 910 .Moskovitch R , Shahara Y , Vaidurya : A Multiple - ontology , Concept - based , Context - sensitive Clinical - guideline Search Engine .", "label": "", "metadata": {}, "score": "75.15397"}
{"text": "To make the most of linguistic generalization , it is necessary to improve precision through the use of linguistic relations .The real cause of impreciseness in multiple keyword search is that all information about the relationships between the words is lost .", "label": "", "metadata": {}, "score": "75.24211"}
{"text": "Methods .Corpus pre - processing .Some pre - processing was performed on the document corpus .Morphological normalization .We morphologically normalized the documents using a tool we developed , called BioMorpher .BioMorpher is a morphological analysis tool built on the Morph tool originally developed at the University of Sheffield by Kevin Humphreys and Hamish Cunningham for general English .", "label": "", "metadata": {}, "score": "75.32742"}
{"text": "12 is not intended to limit the present invention .Indeed , those skilled in the art will recognize that other alternative hardware environments may be used without departing from the scope of the invention .Other modifications and variations to the invention will be apparent to those skilled in the art from the foregoing disclosure and teachings .", "label": "", "metadata": {}, "score": "75.32895"}
{"text": "Each node in the Gene Ontology ( GO ) is associated with a textual label , in addition to its numeric identifier .This label is intended to capture the meaning of the node , i.e. to reflect the underlying concept that the node represents .", "label": "", "metadata": {}, "score": "75.371124"}
{"text": "The present invention has been described in particular detail with respect to one possible embodiment .Those of skill in the art will appreciate that the invention may be practiced in other embodiments .Further , the system may be implemented via a combination of hardware and software , as described , or entirely in hardware elements .", "label": "", "metadata": {}, "score": "75.44783"}
{"text": "For example , the co - occurring words with Ford could be dealer , body shop , Mustang , Escort , etc . .To support query expansion , indices of words related by lexical semantics and syntactical relationships , such as co - occurrence , need to be maintained .", "label": "", "metadata": {}, "score": "75.68234"}
{"text": "Multi - Engine Machine Translation ( MEMT )( Frederking and Nirenburg 94 ) is designed for general purpose , human - aided MT .The MEMT architecture is well - suited to the task of selective assimilation of retrieved documents .", "label": "", "metadata": {}, "score": "75.84398"}
{"text": "For example the query \" cheap bolt action rifle \" has two phrases \" cheap \" and \" bolt action rifle \" .In this case , the search system 120 does the regular intersection of the posting lists of Q 1 and Q 2 to obtain the documents for scoring .", "label": "", "metadata": {}, "score": "75.93276"}
{"text": "Polysemy is the phenomenon where the same word has multiple meanings .So a search may retrieve irrelevant documents containing the desired words in the wrong meaning .For example , a botanist and a computer scientist looking for the word \" tree \" probably desire different sets of documents .", "label": "", "metadata": {}, "score": "75.97384"}
{"text": "We review several click models calledsequential click models here .To learn sequential click models , one critical problem is to cope with positionbias .Thus , the probability of a webpage being clicked ina sequential click model also depends on the position .", "label": "", "metadata": {}, "score": "76.04095"}
{"text": "( d ) is a normalized weight of the term w.sub.j.sup .( d ) in document D.sub.k , which is divided by a maximum value of term weights in a document D.sub.k .A computer - readable medium as recited in claim 11 , wherein the computer - program instructions for identifying expansion terms further comprise instructions for : calculating joint probabilities for each of the particular ones according to : P(w.sub.j.sup .", "label": "", "metadata": {}, "score": "76.047134"}
{"text": "Then store bitvector Broot[1 .At the leaves , where all the symbols of the corresponding Dleaf are equal , nothing is stored .Page 4 .The top row of each node shows D , the second row the bitvector Bv , and numbers in circles are node numbers for reference in the text .", "label": "", "metadata": {}, "score": "76.05403"}
{"text": "The key focus of information retrieval ( IR ) is determining how to rank the documents of a collection according to their \" goodness \" with respect to a query .EHRs are typically complex structured documents containing several associated clinical entities ( e.g. , physicians , medications , patients , and events ) .", "label": "", "metadata": {}, "score": "76.10456"}
{"text": "As such , we employed Zettair in three modes .Zettair was modified to ensure that all efficiency mea- surements were done in ram , just as the self - indexing methods require .Time to load posting lists into memory is not counted in the measurements .", "label": "", "metadata": {}, "score": "76.296005"}
{"text": "( d ) .vertline.w.sub.i.sup .( q ) ) .times .f ik ( q ) ( w i ( q ) , D k ) f ( q ) ( w i ( q ) ) ) ( 7 ) .", "label": "", "metadata": {}, "score": "76.30754"}
{"text": "In contrast , although \" declaration \" frequently co - occurs with the locationname \" Independence \" , a city in Missouri , in the queries \" declaration of indepen - dence \" , it is not a location sensitive query .", "label": "", "metadata": {}, "score": "76.35721"}
{"text": "BACKGROUND OF THE INVENTION .Field of the Invention .This invention relates generally to field of indices and queries applied to a collection of documents in a database .More specifically , this invention relates to efficient expansion and processing of the queries , to reducing the size of indices used to perform the query expansion and to progressive query processing .", "label": "", "metadata": {}, "score": "76.37312"}
{"text": "Certain aspects of the present invention include process steps and instructions described herein in the form of an algorithm .It should be noted that the process steps and instructions of the present invention could be embodied in software , firmware or hardware , and when embodied in software , could be downloaded to reside on and be operated from different platforms used by real time network operating systems .", "label": "", "metadata": {}, "score": "76.387695"}
{"text": "In the case where the terms comprising documents and queries are fixed as words in the English language , Greedy is capable of processing 4600 queries per second , com- pared to the best inverted indexing method , Zet - io , which processes only 1400 on average .", "label": "", "metadata": {}, "score": "76.49995"}
{"text": "MGQ . ) m . log .Number .Of .Rows .[ .b . ) .] m .n . ) g .f .h . ) log .Number .Of .Rows .[ .", "label": "", "metadata": {}, "score": "76.538086"}
{"text": "The figures depict a preferred embodiment of the present invention for purposes of illustration only .One skilled in the art will readily recognize from the following discussion that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles of the invention described herein .", "label": "", "metadata": {}, "score": "76.650314"}
{"text": "The number of documents crawled per pass can vary , and is preferably about 1,000,000 per partition .It is preferred that only previously uncrawled documents are processed in each partition , until all documents have been processed , or some other termination criteria is met .", "label": "", "metadata": {}, "score": "76.847"}
{"text": "Negoita [ 24 ] gives a theoretical discussion of a bottom - up search strategy in the context of cluster - based retrieval .Much of the early work on relevance feedback done on the SMART project has now been reprinted in Salton [ 25 ] .", "label": "", "metadata": {}, "score": "76.89177"}
{"text": "However , the phrase \" Australian Shepherd Club of America \" appears as anchor text for a hyperlink ( indicated by the underline ) to website .The process of traversing each document with both the sequence window 302 and the secondary window 304 , is repeated for each document in the partition .", "label": "", "metadata": {}, "score": "77.03559"}
{"text": "Line 2 .( \" Ford \" OR \" Buick \" ) ] AND .Line 3 .( \" Dealer \" OR \" Showroom \" OR \" SalesOffice \" ) .There are two types of query expansion involved in this example .", "label": "", "metadata": {}, "score": "77.17351"}
{"text": "391 - 398 , IEEE Computational Intelligence Society , Chicago , IL , USA .Translingual Information Access .Abstract .We present an attempt at a coherent vision of an end - to - end translingual information retrieval system .We begin by presenting a sample of the broad range of possibilities .", "label": "", "metadata": {}, "score": "77.54734"}
{"text": "CRC - Taylor & Francis ; 2009 .( 4,11 )View Article .Robertson SE , Walker S , Jones S , et al .: Okapi at TREC-3 .In Proceedings of the Text Retrieval Conference ( TREC ) .", "label": "", "metadata": {}, "score": "77.56512"}
{"text": "These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art .These operations , while described functionally or logically , are understood to be implemented by computer programs .", "label": "", "metadata": {}, "score": "77.845985"}
{"text": "Let this row vector be called .Likewise , the only part of that contributes to is the column , .These are not the eigenvectors , but depend on all the eigenvectors .It turns out that when you select the largest singular values , and their corresponding singular vectors from and , you get the rank approximation to with the smallest error ( Frobenius norm ) .", "label": "", "metadata": {}, "score": "78.04104"}
{"text": "The interesting thing is that starting with any Q we can adjust it iteratively using feedback information so that it will converge to Q 0 .There is a theorem ( Nilsson [ 14 ] , page 81 ) which states that providing Q 0 exists there is an iterative procedure which will ensure that Q will converge to Q 0 in a finite number of steps .", "label": "", "metadata": {}, "score": "78.05638"}
{"text": "Each of these stages will now be described in further detail .The first stage 200 is a process by which the indexing system 110 crawls a set of documents in the document collection , making repeated partitions of the document collection over time .", "label": "", "metadata": {}, "score": "78.27519"}
{"text": "The method of .claim 1 , wherein the document description of the first document matches the document description of the second document when a hash value of the first document description equals a hash value of the second document description .", "label": "", "metadata": {}, "score": "78.48368"}
{"text": "According to the Bayesian theorem , the conditional probability P(w.sub.j.sup .( d ) .vertline.w.sub.i.s- up .( q ) ) is defined as follows .times . times . times . times . times .[0044 ] S is a set of documents .", "label": "", "metadata": {}, "score": "78.70699"}
{"text": "Let us now look at other ways of representing clusters .We seek a method of representation which in some way ' averages ' the descriptions of the members of the clusters .The method that immediately springs to mind is one in which one calculates the centroid ( or centre of gravity ) of the cluster .", "label": "", "metadata": {}, "score": "78.82521"}
{"text": "Given our assumption above , we can say that if a given GO node is about a specific concept or theme , then we expect the words in its label to co - occur with other words in any given document which also refer to this concept .", "label": "", "metadata": {}, "score": "79.115364"}
{"text": "The MEMT architecture makes it possible to exploit the differences between MT technologies .Differences in translation quality and domain size can be exploited by merging the best results from different engines .In the earlier Pangloss unrestricted translation system , when Knowledge - Based MT ( KBMT ) could produce high - quality , in - domain translations , its results were used ; when Example - Based MT ( EBMT ) found a high - quality match , its results were used .", "label": "", "metadata": {}, "score": "79.23419"}
{"text": "( GO:0006412 : protein biosynthesis , 0.8 ) , .( GO:0006412 : protein biosynthesis , 0.8 ) , .( GO:0042158 : lipoprotein biosynthesis , 0.8 ) , .Note the duplicate items in the bag , in particular the node GO:0006412 is present twice with weight 0.8 , receiving one contribution from the query term ( \" protein biosynthesis \" , 0.8 ) and another from the query term ( \" biosynthesis \" , 0.8 ) .", "label": "", "metadata": {}, "score": "79.24303"}
{"text": "Obviously , search and browselog data are useful for evaluation of a search system .In themeantime , various models can be applied to predict user satisfaction from searchand browse log data .The applications of log data for monitoring and predictinguser satisfaction will be discussed in Section 6 .", "label": "", "metadata": {}, "score": "79.39139"}
{"text": "This cluster test is repeated for each pair ( g l , g m ) in R. .For example , assume the good phrase \" Bill Clinton \" is related to the phrases \" President \" , \" Monica Lewinsky \" , because the information gain of each of these phrases with respect to \" Bill Clinton \" exceeds the Related Phrase threshold .", "label": "", "metadata": {}, "score": "79.67833"}
{"text": "Limitations .This study has limitations .The performance was evaluated with only two end users .This was done by design so that we could gain preliminary insights into performance and discuss possible explanations about differences between the methods .A larger sample would clearly be needed to make more definitive conclusions .", "label": "", "metadata": {}, "score": "80.100784"}
{"text": "[ 0025 ] The drives and associated computer - readable media provide nonvolatile storage of computer readable instructions , data structures , program modules , and other data for computer 130 .[ 0027 ] A user may provide commands and information into computer 130 through input devices such as keyboard 166 and pointing device 168 ( such as a \" mouse \" ) .", "label": "", "metadata": {}, "score": "80.17224"}
{"text": "The present invention relates to an information retrieval system for indexing , searching , and classifying documents in a large scale corpus , such as the Internet .BACKGROUND OF THE INVENTION .Information retrieval systems , generally called search engines , are now an essential tool for finding information in large scale , diverse , and growing corpuses such as the Internet .", "label": "", "metadata": {}, "score": "80.5997"}
{"text": "[ 0029 ] Computer 130 may operate in a networked environment using logical connections to one or more remote computers , such as a remote computer 182 .Remote computer 182 may include many or all of the elements and features described herein relative to computer 130 .", "label": "", "metadata": {}, "score": "80.83644"}
{"text": "But the term frequency in general is per term frequency , which , in this case , is the same for both terms \" pericardial \" and \" effusion \" .A subset of Electronic Health Record Dataset .A subset of the relational - anonymized experimental EHR dataset of the Cardiac Division of Miami Children 's Hospital , which contains clinical entities like hospitalization , patient , employee , medication , diagnosis , diagnostics , cardiac , events , and labs .", "label": "", "metadata": {}, "score": "81.076744"}
{"text": "Next we set out to identify words associated with GO nodes .Using the GO nodes in the provided triples we retrieved the words from the GO node label .Let us refer to this set of words as W GO ( the red nodes in Figure 1 , for GO node 0007266 ) .", "label": "", "metadata": {}, "score": "81.37461"}
{"text": "The method according to .claim 35 , wherein each of the stages represents a class of expansion .The method according to .claim 35 , wherein each of the stages represents a slot within a class of expansion .The system according to .", "label": "", "metadata": {}, "score": "81.436195"}
{"text": "Thus DNA ligation is a specific kind of DNA repair .A portion of the Molecular Function branch of the Gene Ontology .Reprinted with permission from Nature from [ 1].In order to take the structure of the GO into consideration in this analysis , we employed a technology called the Gene Ontology Categorizer ( GOC , [ 3 , 10 ] ) .", "label": "", "metadata": {}, "score": "81.71936"}
{"text": "Conventional retrieval systems , by which documents may be retrieved through the application of queries , are based on a common set of principles and methodologies of categorizing documents .Documents are normally indexed manually by subject experts or librarians using pre - specified and controlled vocabularies .", "label": "", "metadata": {}, "score": "81.88771"}
{"text": "Each node v has a role \u03bb ( v ) .For instance , node v3 in Figure 1 has role \" Medication \" .Each edge e from u to v is labelled with its role \u03bb ( e ) and represents a relationship between u and v .", "label": "", "metadata": {}, "score": "82.89699"}
{"text": "Declarations .Acknowledgements .We thank Dr. Redmond Burke from Miami Children 's Hospital and Jeffrey White for providing an anonymized dataset of health records .We thank Dr. Helga Van Herle for assisting in prioritizing clinical edge types and identifying schema weights .", "label": "", "metadata": {}, "score": "83.10564"}
{"text": "claim 1 , further comprising : . receiving a query comprising at least one phrase ; . retrieving a plurality of documents responsive to the query to form the set of documents as a search result set including the first document and the second document ; and .", "label": "", "metadata": {}, "score": "83.12926"}
{"text": "Affiliated with .Affiliated with .Affiliated with .Abstract .Background .We participated in the BioCreAtIvE Task 2 , which addressed the annotation of proteins into the Gene Ontology ( GO ) based on the text of a given document and the selection of evidence text from the document justifying that annotation .", "label": "", "metadata": {}, "score": "83.44148"}
{"text": "The second case described above is where anchor phrase A does not appear in URL 1 .Here , this shows that the URL 1 does not contain the anchor phrase \" Australian Shepard \" , but does contain the related phrases \" blue merle \" , \" red merle \" , and \" tricolor \" .", "label": "", "metadata": {}, "score": "84.27969"}
{"text": "This apparatus may be specially constructed for the required purposes , or it may comprise a general - purpose computer selectively activated or reconfigured by a computer program stored on a computer readable medium that can be accessed by the computer .", "label": "", "metadata": {}, "score": "84.469955"}
{"text": "For example , assume that the phrase \" weave poles \" appears in 75 of the 100 documents , \" teeter \" appears in 60 documents , \" red merle \" appears in 50 documents .Then the first cluster is named \" weave poles \" and a selected number of documents from that cluster are presented ; the second cluster is named \" teeter , \" and selected number are presented as well , and so forth .", "label": "", "metadata": {}, "score": "85.79271"}
{"text": "These phrases then form the set R. To determine the clusters , the indexing system 110 evaluates the information gain of each of these phrases to the others by determining their corresponding information gains .Thus , the indexing system 110 determines the information gain I(\"President \" , \" Monica Lewinsky \" ) , I(\"President \" , \" purse designer \" ) , and so forth , for all pairs in R. This is because while \" Bill Clinton \" does not predict \" purse designer \" with sufficient information gain , \" Monica Lewinsky \" does predict both of these phrases .", "label": "", "metadata": {}, "score": "85.90239"}
{"text": "The related phrases of these query phrases as : . \" blue merle \" : : \" Australian Shepherd , \" \" red merle , \" \" tricolor , \" \" aussie \" ; . \" agility training \" : : \" weave poles , \" \" teeter , \" \" tunnel , \" \" obstacle , \" \" border collie \" .", "label": "", "metadata": {}, "score": "87.43022"}
{"text": "[ 0022 ] Bus 136 represents one or more of any of several types of bus structures , including a memory bus or memory controller , a peripheral bus , an accelerated graphics port , and a processor or local bus using any of a variety of bus architectures .", "label": "", "metadata": {}, "score": "88.08729"}
{"text": "[ 0032 ] In a networked environment , program modules depicted relative to computer 130 , or portions thereof , may be stored in a remote memory storage device .Thus , e.g. , as depicted in FIG .1 , remote application programs 189 may reside on a memory device of remote computer 182 .", "label": "", "metadata": {}, "score": "88.751526"}
{"text": "claim 1 , wherein comparing the document description of the first document with a document description of the second document further comprises : . generating for the first document a document description by selecting sentences of the first document , and ordering in the document description as a function of a number of related phrases in each sentence ; and . retrieving for the second document a stored document description comprising selected sentences of the second document , wherein the selected sentences are ordered in the document description as a function of a number of related phrases in each sentence .", "label": "", "metadata": {}, "score": "88.83719"}
{"text": "\u00a9 Verspoor et al 2005 .This article is published under license to BioMed Central Ltd.Currently , apopular web search engine may every day receive billions of queries and collect tera - bytes ofrecords about user search behavior .Beside search log data , huge amounts of browse log datahave also been collected through client - side browser plug - ins .", "label": "", "metadata": {}, "score": "89.66855"}
{"text": "The search system 120 would identify the following candidate phrases , \" Hillary Rodham Clinton Bill on , \" \" Hillary Rodham Clinton Bill , \" and \" Hillary Rodham Clinton \" .The first two are discarded , and the last one is kept as a valid query phrase .", "label": "", "metadata": {}, "score": "89.9669"}
{"text": "Modem 178 , which may be internal or external , may be connected to system bus 136 via the user input interface 170 or other appropriate mechanism .[0031 ] Depicted in FIG .1 , is a specific implementation of a WAN via the Internet .", "label": "", "metadata": {}, "score": "90.03784"}
{"text": "Of the five related phrases of \" Australian Shepard \" , only one , \" Aussie \" appears in URL 0 .Intuitively then , URL 0 is only weakly about Australian Shepherds .URL 1 , by comparison , not only has the phrase \" Australian Shepherd \" present in the body of the document , but also has many of the related phrases present as well , \" blue merle , \" \" red merle , \" and \" tricolor . \"", "label": "", "metadata": {}, "score": "91.71135"}
{"text": "\" GREEDY is also dependent on size of the [ sp . ep ] range , requiring two orders of magnitudes more time on ENWIKI - BIG than on ENWIKI - SML , matching the difference in their sizes .This is due to the faster extraction of inverse SA values and the use of a \u03a8 - based CSA instead of a WT based one .", "label": "", "metadata": {}, "score": "92.70323"}
{"text": "1 are a local area network ( LAN ) 177 and a general wide area network ( WAN ) 179 .Such networking environments are commonplace in offices , enterprise - wide computer networks , intranets , and the Internet .[ 0030 ] When used in a LAN networking environment , computer 130 is connected to LAN 177 via network interface or adapter 186 .", "label": "", "metadata": {}, "score": "92.83422"}
{"text": "In a distributed computing environment , program modules may be located in both local and remote memory storage devices .[ 0021 ] As shown in FIG .1 , computing environment 120 includes a general - purpose computing device in the form of a computer 130 .", "label": "", "metadata": {}, "score": "93.52697"}
{"text": "Such media may be any available media that is accessible by computer 130 , and it includes both volatile and non - volatile media , removable and non - removable media .In FIG .1 , system memory 134 includes computer readable media in the form of volatile memory , such as random access memory ( RAM ) 140 , and/or non - volatile memory , such as read only memory ( ROM ) 138 .", "label": "", "metadata": {}, "score": "94.31121"}
{"text": "RAM 140 typically contains data and/or program modules that are immediately accessible to and/or presently being operated on by processor 132 .[ 0024 ] Computer 130 may further include other removable / non - removable , volatile / non - volatile computer storage media .", "label": "", "metadata": {}, "score": "97.560165"}
{"text": "Nuclear family : a direct hit , or p is a child , parent , or sibling of q .Extended family : a nuclear family hit , or p is grandparent , grandchild , cousin ( grandchild of a grandparent or grandparent of a grandchild ) , aunt / uncle ( child of a grandparent ) , or a niece / nephew ( grandchild of a parent ) , of q .", "label": "", "metadata": {}, "score": "99.60001"}
{"text": "For example , the phrase \" President of the United States \" is a phrase that predicts other phrases such as \" George Bush \" and \" Bill Clinton . \"However , other phrases are not predictive , such as \" fell down the stairs \" or \" top of the morning , \" \" out of the blue , \" since idioms and colloquisms like these tend to appear with many other different and unrelated phrases .", "label": "", "metadata": {}, "score": "100.01973"}
{"text": "Pre - publication history .Copyright .\u00a9 Hristidis et al .2010 .This article is published under license to BioMed Central Ltd. Easy To Use Patents Search & Patent Lawyer Directory .At Patents you can conduct a Patent Search , File a Patent Application , find a Patent Attorney , or search available technology through our Patent Exchange .", "label": "", "metadata": {}, "score": "103.245865"}
{"text": "S - P or P - S forms such as ( Buick , car ) , ( Buick , dealer ) , ( car , Ford ) , ( Ford , auto ) , and ( Ford , dealer ) .S - S form such as ( car , garage ) and ( auto , garage ) .", "label": "", "metadata": {}, "score": "106.69743"}
{"text": "Regenstrief Institute , Inc. .Indiana University School of Medicine .Indiana University Center for Health Services and Outcomes Research .VA HSR&D Center of Excellence on Implementing Evidence - Based Practice , Richard L. Roudebush VA Medical Center .References .", "label": "", "metadata": {}, "score": "113.14366"}
