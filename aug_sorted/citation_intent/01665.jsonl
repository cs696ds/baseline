{"text": "An example of an auditory model is described in U.S. Pat .No .4,980,918 to Bahl et al entitled \" Speech Recognition System with Efficient Storage and Rapid Assembly of Phonological Graphs \" .Preferably , according to the present invention , for each frequency band i of the adapted feature vector signal X'(t ) at time t , the auditory model 42 calculates a new parameter E i ( t ) according to Equations 20 and 21 : . where .", "label": "", "metadata": {}, "score": "48.471207"}
{"text": "This information is buffered so that the utterance recognition step can operate asynchronously with the input speech .The utterance recognition subtask uses either the windowed Dynamic Programming Algorithm ( DPA ) isolated word recognizer or a full DPA connected digit recognizer or both as needed .", "label": "", "metadata": {}, "score": "49.38638"}
{"text": "No .730,714 , filed on Jul. 16 , 1991 , entitled \" Past Algorithm for Deriving Acoustic Prototypes for Automatic Speech Recognition .\"Alternatively , all acoustic feature vectors generated by the utterance of a training text and which correspond to a given elementary model may be clustered by K - means Euclidean clustering or K - means Gaussian clustering , or both .", "label": "", "metadata": {}, "score": "49.61553"}
{"text": "No .4,980,918 to Bahl et al entitled \" Speech Recognition System with Efficient Storage and Rapid Assembly of Phonological Graphs \" .Preferably , according to the present invention , for each frequency band i of the adapted feature vector signal X'(t ) at time t , the auditory model 62 calculates a new parameter E.sub.i ( t ) according to Equations 23 and 24 : . where . and where K.sub.1 , K.sub.2 , and K.sub.3 are fixed parameters of the auditory model .", "label": "", "metadata": {}, "score": "50.084213"}
{"text": "Essentially , that system employs a method that detects the occurrence of keywords in continuously spoken speech and evaluates both the keyword hypothesis and the alternative hypothesis that the observed speech is not a keyword .A general language model is used to evaluate the latter hypothesis .", "label": "", "metadata": {}, "score": "50.345825"}
{"text": "A speech recognition method as claimed in claim 19 , further comprising the steps of : . storing a source vocabulary of words in the source language ; . comparing each word in the source text with each word in the source vocabulary to identify each word in the source text which is not in the source vocabulary ; and .", "label": "", "metadata": {}, "score": "50.844604"}
{"text": "Next , we proposed the use of an adaptive filter using a sub - word unit .Previously , we constructed the speech support system that used a transfer function for sub - word to create a clear speech from body - conducted speech ( Ishimitsu et al . , 2007 ) .", "label": "", "metadata": {}, "score": "51.191162"}
{"text": "No .730,714 , filed on Jul. 16 , 1991 , entitled \" Fast Algorithm for Deriving Acoustic Prototypes for Automatic Speech Recognition .\"Alternatively , all acoustic feature vectors generated by the utterance of a training text and which correspond to a given elementary model may be clustered by K - means euclidean clustering or K - means Gaussian clustering , or both .", "label": "", "metadata": {}, "score": "51.494434"}
{"text": "The estimated area A r is computed as the area under the similarity curve for the target 's phoneme label , between the projected locations of the target 's left and right frames .The word congruence score is computed as the weighted sum of congruence scores for all the targets , divided by the sum of their weights .", "label": "", "metadata": {}, "score": "51.57267"}
{"text": "A speech recognition system as claimed in claim 1 , further comprising : . means for storing a source vocabulary of words in the source language ; . means for comparing each word in the source text with each word in the source vocabulary to identify each word in the source text which is not in the source vocabulary ; and .", "label": "", "metadata": {}, "score": "51.653534"}
{"text": "Current automatic speech recognition ( ASR ) systems are divided basically into two general functional categories .The first category is designated as connected speech recognition ( CSR ) systems and the second category is word spotting systems .The function of a CSR system is to determine which of a closed set of valid phrases has been spoken , assuming that the input speech is one of these phrases .", "label": "", "metadata": {}, "score": "52.454144"}
{"text": "A typical alignment path 806 is shown .The path that has the minimum score is selected to be extended to D subject to the local path constraint : every horizontal or vertical step must be followed by a diagonal step .", "label": "", "metadata": {}, "score": "52.69635"}
{"text": "According to a further specific embodiment , the spoken sequence of words is unknown , and a computerized speech recognition system is operated to determine the spoken sequence of words .According to a further specific embodiment , the posterior - based score is further mapped to a grade as would be assigned by human grader , and the grade is presented to the student speaker .", "label": "", "metadata": {}, "score": "53.068375"}
{"text": "A speech recognition method as claimed in claim 16 , further comprising the step of outputting an unrecognizable - sound indication signal if the best match score for the current sound is worse than the recognition threshold score for the current sound .", "label": "", "metadata": {}, "score": "53.3409"}
{"text": "In general , a frame of acoustic features is produced at each time - step along this path .( However , some state transitions such as the \" skip \" transition take no time and produce no output . )The path identifies the sequence of states traversed .", "label": "", "metadata": {}, "score": "53.491783"}
{"text": "This distance is doubled before adding if a diagonal step was chosen to aid in path score normalization .The movement of the DPA function is along the template axis for each utterance frame .Rather than process every cell in the matrix , only a window of four cells are processed for a template for each utterance frame .", "label": "", "metadata": {}, "score": "53.582092"}
{"text": "No .4,748,670 by Lalit R. Bahl et al entitled \" Apparatus And Method For Determining A Likely Word Sequence From Labels Generated By An Acoustic Processor . \"FIG .2 is a block diagram of a portion of one example of a speech recognition system according to the invention .", "label": "", "metadata": {}, "score": "53.8695"}
{"text": "So , this method can be used to estimate a clear speech using only body - conducted speech .Thereafter , we combined the proposed method and conventional signal retrieval methods to make a clear signal .Combined methods using an adaptive filter for a word , its effectiveness is shown the results in the difference of spectrograms between each signal and speech .", "label": "", "metadata": {}, "score": "54.593094"}
{"text": "The second stage represents each word by a prototype that consists of a series of phoneme targets and global statistics , namely the average word duration and average match rate .These represent the degree of fit of the word prototype to its training data .", "label": "", "metadata": {}, "score": "54.92154"}
{"text": "By combining these quasi - independent sources of information produced at each step , a significant gain in accuracy is obtained .According to one aspect of the invention , a word recognizer for processing an input speech utterance is provided for a speech recognition system .", "label": "", "metadata": {}, "score": "55.187073"}
{"text": "BRIEF DESCRIPTION OF THE FIGURES .FIG .1 is a block diagram of a key word scoring method and apparatus according to the prior art .FIG .2 is a block diagram of a connected speech recognition method and apparatus according to the prior art .", "label": "", "metadata": {}, "score": "55.27666"}
{"text": "The algorithm next checks the scores of the best partial sentence options ( BEAMS ) 732 to see if the poor scoring ones should be eliminated .The surviving options are transferred to storage indexed by the current utterance number ( TRANSP ) 734 , 736 .", "label": "", "metadata": {}, "score": "55.287354"}
{"text": "This defines a normalized score S RC for each word .Normalized scores range from 0 to 1 and are dimensionless , making it possible to combine scores resulting from different scoring methods .The target congruence stage is then applied on each word candidate selected by the RC stage .", "label": "", "metadata": {}, "score": "55.322903"}
{"text": "Dynamic programming time alignment and matching ( DPA for short ) , .Connected digit phrase score and update , .Utterance frame penalty computation , .Best digit phrase retrieval , .Partial sentence scoring and updating .Again the last function is part of the syntax control subtask and will be discussed later .", "label": "", "metadata": {}, "score": "55.342617"}
{"text": ", 2004 ) .However , since a retrieval signal using differential acceleration is clear , the estimation of clearest signal can be expected by using the retrieval signal and adaptive filter ( Haykin , 1996 ) .The updated filter method is shown in the following equation and in Figure 7 . where , . w .", "label": "", "metadata": {}, "score": "55.41337"}
{"text": "In the speech recognition system and method according to the present invention , information about the source sentence being translated is used to estimate the probability that each speech hypothesis would be uttered .This probability is estimated with the aid of a translation model .", "label": "", "metadata": {}, "score": "55.80078"}
{"text": "By combining the quasi - independent sources of information produced at each stage , a significant gain in accuracy is obtained .The system 's architecture features three distinct components that are applied in sequence on the incoming speech to compute the best word candidate .", "label": "", "metadata": {}, "score": "55.948143"}
{"text": "However , even with developments in speech recognition technology , high recognition performance can be compromised due to noisy environments .To achieve a high recognition performance , background noise should be minimal , and normal speech should be clear , because the system estimates recognition using a feature vector from its signal .", "label": "", "metadata": {}, "score": "55.95526"}
{"text": "A multistage word hypothesizer is used prior to frame - by - frame alignment in order to reduce the search space and thereby improve real time performance .The number of stages in the hypothesizer , as well as the computational complexity of each stage , and the number of word candidates preserved at each stage can be adjusted to achieve desired goals of speed , memory size and recognition accuracy for a particular application .", "label": "", "metadata": {}, "score": "56.11311"}
{"text": "The Viterbi algorithm is also discussed in numerous other references , such as G. D. Forney , Jr. , \" The Viterbi algorithm , \" Proc .IEEE , vol.61 , pp.268 - 278 , 1973 .In the specific embodiment , the sequence of spoken words from the speaker 105 may or may not be known in advance by the pronunciation evaluation system 101 .", "label": "", "metadata": {}, "score": "56.29602"}
{"text": "Top 1 recognition rates under two training speech conditions and 5 test speech conditions are shown in FIG .7 .For more information on the McNemar test see \" Some Statistical Issues in the Comparison of Speech Recognition Algorithms , \" by L. Gillick and S. J. Cox , Proc .", "label": "", "metadata": {}, "score": "56.416824"}
{"text": "A speech recognition apparatus as claimed in claim 1 , characterized in that the acoustic processor is adapted to measure the value of at least one feature of each of a sequence of at least three sounds , wherein the first prior sound is contiguous with the current sound .", "label": "", "metadata": {}, "score": "56.48974"}
{"text": "Therefore , to perform an objective experiment with statistical analysis , the recognition rate of isolated word recognition was evaluated using an acoustic model for unspecified speakers built with a speech .Generally , a subjective listening experiment is often used to evaluate the sound quality however it needs many people and much data as a admitting result .", "label": "", "metadata": {}, "score": "56.54484"}
{"text": "The setting of the end - of - sentence frame threshold depends on whether or not the syntax control algorithm \" thinks \" that the speaker has spoken a complete sentence .Do all estimates of what the speaker said form a complete path in the finite state description of all sentences ?", "label": "", "metadata": {}, "score": "56.575096"}
{"text": "A speech recognition apparatus as claimed in claim 6 , characterized in that the output means displays an unrecognizable - sound indicator if the best match score for the current sound is worse than the recognition threshold score for the current sound .", "label": "", "metadata": {}, "score": "56.650383"}
{"text": "After the segmentation step a single observation feature vector is computed for each segment .Point oriented methods avoid actually generating all possible segmentations by simultaneous scoring of all hypotheses and immediate pruning of poorly scored partial hypotheses .Consequently , all possible segmentations and identifications of the input pattern are considered in an efficient manner .", "label": "", "metadata": {}, "score": "56.801716"}
{"text": "Noise at the end of the sentence is ignored as long as it does not look like the beginning of an utterance .As the utterance begin detector becomes more sophisticated , the end - of - sentence detector improves .Two details indicated on the flowchart must be added to the above end point algorithm description .", "label": "", "metadata": {}, "score": "56.94897"}
{"text": "BACKGROUND OF THE INVENTION .The invention relates to computer speech recognition , particularly to the recognition of spoken computer commands .When a spoken command is recognized , the computer performs one or more functions associated with the command .In general , a speech recognition apparatus consists of an acoustic processor and a stores set of acoustic models .", "label": "", "metadata": {}, "score": "57.014236"}
{"text": "A speech recognition method is claimed in claim 25 , characterized in that : . each word in the source text bas a spelling comprising one or more letters , each letter being upper case or being lower case ; . the method further comprises the step of identifying each word in the source text which has an upper case first letter ; and .", "label": "", "metadata": {}, "score": "57.294106"}
{"text": "In yet another embodiment of the invention , the mapping analyzer 707 uses a decision tree or , alternatively , a class probability tree .The machine scores to be combined are the input to a tree that implements the mapping between the machine scores 703 and the corresponding human scores 705 .", "label": "", "metadata": {}, "score": "57.317856"}
{"text": "As indicated , the accuracy of the KS method is improved by a technique called bias removal which makes the threshold value a function of the keyword and the speaker .Referring to FIG .2 , there is shown a simple block diagram of a continuous or connected speech recognition ( CSR ) system .", "label": "", "metadata": {}, "score": "57.378487"}
{"text": "The twenty dimension adapted feature vector signal X'(t ) from the adaptive labeler 60 is preferably provided to an auditory model 62 .Auditory model 62 may , for example , provide a model of how the human auditory system perceives sound signals .", "label": "", "metadata": {}, "score": "57.46376"}
{"text": "A discrete set of human targets are defined as classes used by the decision or class probability tree into which classify the input machine scores .VI .Language Instruction in a Client - Server Environment .FIG .8 is a block diagram of a distributed system 801 for language instruction that evaluates pronunciation quality .", "label": "", "metadata": {}, "score": "57.470406"}
{"text": "1 depicts a typical grammar node as found in an evolutional grammar network , with preceding arcs p(g ) and succeeding arcs s(g ) .FIG .2 shows an algorithm written in pseudo code , of a resampling procedure for computing the normalized instance vector of a fixed length for any segment of arbitrary length .", "label": "", "metadata": {}, "score": "57.719345"}
{"text": "Using this method , keywords and keyword pieces share parameters , and score normalization deals with distances in the same space .Equation 2 does not apply uniquely to the wordspotting application .It applies to the general problem of testing a given interval of speech to determine whether it contains an utterance of interest .", "label": "", "metadata": {}, "score": "57.732136"}
{"text": "4 through 13 .Throughout this application the word \" utterance \" will be used to indicate either a spoken isolated word or a spoken sequence of connected digits .Thus , the overall tasl of utterance recognition is the task of recognizing either an isolated word or a sequence of connected digits ( or connected words if desired ) .", "label": "", "metadata": {}, "score": "57.734062"}
{"text": "This counter will then be incremented each frame until either a new utterance is found , or the counter exceeds a threshold indicating that the end of the sentence has occurred .Using a non - speech counter as described rather than a straight silence - counter for end - of - sentence detection has a major advantage .", "label": "", "metadata": {}, "score": "57.881527"}
{"text": "No . 439,018filed on Nov. 3 , 1982 for G. Vensko et al 2 - 1 - 1 - 1 is entitled \" A Data Processing Apparatus and Method for Use in Speaker Recognition \" .That application describes a processing system for particularly operating with incoming speech and for processing the speech and comparing the same by the use of templates .", "label": "", "metadata": {}, "score": "57.892586"}
{"text": ", m n ) for each utterance , plus a bias term , to approximate the corresponding human score h : .The linear coefficients \u03bb j and bias term \u03bb 0 are optimized to minimize the mean square between the predicted and the actual human scores over the utterances of the development set .", "label": "", "metadata": {}, "score": "57.97886"}
{"text": "Thus , the node - extension vector at one utterance shows what nodes will be active while processing the next utterance in the sentence .The utterance initialization procedure in the recognition algorithms uses the node - extension vector and the template - node membership information to determine what templates should be marked active .", "label": "", "metadata": {}, "score": "58.03846"}
{"text": "A speech recognition system which interprets speech queries such as help queries and presents a list of relevant proposed commands sorted in order based upon relevance of the commands .Speech command input recognition system for interactive computer display with term weighting means used in interpreting potential commands from relevant speech terms US 6192343 B1 .", "label": "", "metadata": {}, "score": "58.14052"}
{"text": "FIG .6 is a block diagram of an example of the acoustic processor of FIG .1 .DESCRIPTION OF THE PREFERRED EMBODIMENTS .Referring to FIG .1 , the speech recognition apparatus according to the invention comprises an acoustic processor 10 for measuring the value of at least one feature of each of a sequence of at least two sounds .", "label": "", "metadata": {}, "score": "58.2078"}
{"text": "From the recognition experiments , the differential acceleration signals exhibited the most improvement , and the proposed algorithms improved when compared with base - line body - conducted speech signals .Furthermore , the system does not depend on the environments and speakers because the system chose the highest likelihood from the signals .", "label": "", "metadata": {}, "score": "58.326378"}
{"text": "In that case a window advance of one template frame will be made 1037 .See FIG .9e .The third function of path boundary control designated generally 1040 in FIG .10b also effects window movement .The effect of these controls keeps the window and thus the selection of the best path within the diagonal lines 812 and 814 drawn from the top right corner 816 of the DPA matrix 800 of FIG . 8 .", "label": "", "metadata": {}, "score": "58.36387"}
{"text": "Score : A value generated by a machine according to a scoring function or algorithm as applied to a speech utterance .A Frame of Acoustic Features : A characterization of speech sounds within a short time - frame produced by a feature extractor for subsequent processing and analysis .", "label": "", "metadata": {}, "score": "58.377037"}
{"text": "A speech recognition system as claimed in claim 7 , characterized in that : . each word in the source text has a spelling comprising one or more letters , each letter being upper case or being lower case ; .the system further comprises means for identifying each word in the source text which has an upper case first letter ; and .", "label": "", "metadata": {}, "score": "58.422565"}
{"text": "In effect , the hypothesizer stages select the most probable word candidates and thereby reducing the search space for the fine match procedure .To further improve recognition reliability the probability scores obtained at each stage of the word hypothesizer are combined with the scores of the fine match procedure in order to produce a final word decision .", "label": "", "metadata": {}, "score": "58.69849"}
{"text": "Algorithmically , summing probabilities is achieved with only slightly greater complexity than the standard CSR matcher .Summing the probabilities uses all the top scores for an input frame to compute the summation term in Equation 2 , which serves as the bottom score for the next input frame .", "label": "", "metadata": {}, "score": "58.75022"}
{"text": "This function is the utterance frame penalty computation 1106 ( SAVPEN ) .In the last few frames of the utterance ( determined by CD - end - range ) the best scoring digit phrase ending in those frames is selected as the connected digit phrase sequence .", "label": "", "metadata": {}, "score": "58.8472"}
{"text": "This number will be the total number of template frames in the partial phrase plus the number of frames in the utterance .Therefore the normalized path score is an average frame - to - frame distance over the entire path .", "label": "", "metadata": {}, "score": "58.913902"}
{"text": "( See , for example , Lalit R. Bahl et al , \" Apparatus and Method of Grouping Utterances of a Phoneme into Context - Dependent Categories Based on Sound - Similarity for Automatic Speech Recognition . \" U.S. Pat .No .", "label": "", "metadata": {}, "score": "58.91781"}
{"text": "The input signal can be a long sample using following equation .where .x is the length of long sample ; .i is the number of each sub - word sample , and .N is the number of connection .", "label": "", "metadata": {}, "score": "58.94188"}
{"text": "This causes the ASR system to wait for an interval of silence before scoring the phrase .In the wordspotting application , the termination criterion requires no additional processing , as indicated by the dotted line .The combined task syntax and termination criterion is therefore equivalent to a self - looping node in this case .", "label": "", "metadata": {}, "score": "59.00307"}
{"text": "We found that this system exhibited an average recognition rate of greater than 95 % .However , the recognition for body - conducted speech needs the suitable acoustic model to achieve a high recognition performance .Here , we aimed to extract a clear signal using body - conducted speech and to evaluate its efficacy by signal frequency characteristics and recognition performance .", "label": "", "metadata": {}, "score": "59.277363"}
{"text": "67 - 72 , February 1975 , to find the best time alignment path or match between a given template and the spoken word .Isolated word recognizers such as those outlined above require the user to artificially pause between every input word or phrase .", "label": "", "metadata": {}, "score": "59.33086"}
{"text": "Preferably , the prior sound occurs immediately prior to the current sound .A speech recognition apparatus according to the invention may further comprise means for storing at least one acoustic silence model representing one or more series of acoustic feature values representing the absence of a spoken utterance .", "label": "", "metadata": {}, "score": "59.388027"}
{"text": "In any event , the CSR method briefly described above takes a step towards alleviating this problem by using filler templates , which are intended to model all speech sounds .For a keyword to appear in the best matching template string as to enable it to be detected and reported , incoming speech must be closer to the keyword template than to any concatenation of filler templates .", "label": "", "metadata": {}, "score": "59.45194"}
{"text": "Given an active lexicon of N words , the region count stage is first applied to produce a short list of word candidates with normalized scores .A weighted Euclidean distance is used to measure the degree of fit of a test word X to a reference word P ( in RC format as supplied by the RC word prototype database ) .", "label": "", "metadata": {}, "score": "59.506325"}
{"text": "As indicated , both system have problems associated therewith .In any event , while the block diagrams of FIGS . 1 and 2 are relatively simple , it is also indicated that the technique for performing template matching as well as for keyword templates or filler templates and for deriving the same are well known in the prior art .", "label": "", "metadata": {}, "score": "59.50757"}
{"text": "The present system uses a multistage word hypothesizer that is applied prior to a frame - by - frame alignment , in order to reduce the search space and to achieve real time performance improvements .The word hypothesizer and fine match procedure share the initial representation of speech as a sequence of multiple phoneme similarity values .", "label": "", "metadata": {}, "score": "59.545677"}
{"text": "The fundamental speech recognition is described as follows briefly ( Rabiner , 1993 ) .Speech were recorded with a microphone and sampled at 16 kHz and 16 bits .As part of the recognition parameters , speech data were converted to the feature vectors as cepstrum coefficients .", "label": "", "metadata": {}, "score": "59.66171"}
{"text": "the step of generating speech hypotheses generates one or more speech hypotheses solely from words in the set of candidate words .A speech recognition method as claimed in claim 19 , characterized in that the acoustic match score comprises an estimate of the probability of occurrence of the sequence of coded representations of the utterance given the occurrence of the speech hypothesis .", "label": "", "metadata": {}, "score": "59.671646"}
{"text": "The processing stages of the word hypothesizer are applied in sequence to reduce the search space for a more computationally expensive fine match word recognition system .Speech representation by phoneme similarities has been applied in speaker - independent , template - based word recognition systems for their relative insensitivity to speaker variations .", "label": "", "metadata": {}, "score": "59.73579"}
{"text": "x .i . ) consists of the speech signal .s .i . ) and the noise signal .n .i . )An estimated spectrum .S . can be obtained using the spectral subtraction method from Equation ( 2 ) .", "label": "", "metadata": {}, "score": "59.834095"}
{"text": "Figure 6 .Figure 7 .Figure 8 .Figure 9 .Adaptive filter for sub - word unit .Adaptive filter method for word unit .In previous research ( Ishimitsu et al ., 2004 ) , the adaptive filter method ( Haykin , 1996 ) was not enough to recover a sufficient frequency characteristic when body - conducted speech was used as a reference signal .", "label": "", "metadata": {}, "score": "59.892097"}
{"text": "A set of one or more speech hypotheses , each comprising one or more words from the target language , are produced .Each speech hypothesis is modeled with an acoustic model .An acoustic match score for each speech hypothesis comprises an estimate of the closeness of a match between the acoustic model of the speech hypothesis and the sequence of coded representations of the utterance .", "label": "", "metadata": {}, "score": "59.898796"}
{"text": "The goal of the function is to center the window around the locally best path so that , hopefully , the overall best path will be found through the matrix with a minimum of effort .The location of the cell with the minimum path score is saved during the DPA function so that the window movement can be adjusted optimally .", "label": "", "metadata": {}, "score": "59.949966"}
{"text": "If there are further utterances to be processed , the utterance loop is repeated 737 and 738 .The second function of computing the best partial sentence descriptions at the end of each utterance appears as a subroutine ( SNTCSR ) 1300 of the recognition algorithms shown in more detail in FIG .", "label": "", "metadata": {}, "score": "59.973133"}
{"text": "In a third alternate acoustic - scoring embodiment , the acoustic scorer 503 generates the frame - based posterior probabilities p(q i . linevert split.y t ) directly by using a multi - layer perceptron ( MLP ) .The multi - layer perceptron is trained using forced ( i.e. , known - script - constrained ) alignments on exemplary training data .", "label": "", "metadata": {}, "score": "59.97397"}
{"text": "Human - generated scores 705 are also collected for the utterances in the development set .The development set is assembled so as to include speech from speakers of varying proficiency levels .A mapping analyzer 707 processes the machine scores 703 and the corresponding human grades 705 to generate a scores - to - grade mapping 603 .", "label": "", "metadata": {}, "score": "60.00925"}
{"text": "These flags remain on until the end of the sentence ( SPCHBG ) or current utterance ( UTTBG ) have been found .The setting of the SPCHBG flag permits the recognition algorithms to start .The same type of algorithm is used to detect the beginning of utterances ( other than the first utterance ) .", "label": "", "metadata": {}, "score": "60.067947"}
{"text": "Thus , for example , prototype vector signals P5 , P1 , P2 , P4 , and P3 could have been assigned rank scores of \" 1 \" , \" 2 \" , \" 3 \" , \" 3 \" and \" 3 \" , respectively .", "label": "", "metadata": {}, "score": "60.09031"}
{"text": "Then , we focused on the recognition system that calculates the likelihood between signal and model in recognition parameter .The algorithm chooses the clearest signal because it is appeared a highest likelihood from the recognition decoder .So we apply this idea to the decoding algorithm for differential acceleration .", "label": "", "metadata": {}, "score": "60.23964"}
{"text": "Through a resampling procedure , discussed more fully below , such a representation can be computed for a segment of arbitrary length .In other words , any sample segment can be mapped to a vector in R 2n .Based on this representation , the distance between two sample segments is defined as : . u b ) .", "label": "", "metadata": {}, "score": "60.264038"}
{"text": "The other top scores are discarded .All templates starting at the next input frame use the same bottom score .A \" global mininum \" score is obtained at each input frame that is the minimum accumulated distance between the input speech up to and including the current frame and the best concatenation of templates ending at any template frame .", "label": "", "metadata": {}, "score": "60.28129"}
{"text": "7 is a block diagram of a system for creating FIG .6 's mapping function between one or more types of machine scores into a pronunciation grade as would be produced by a human grader .FIG .8 is a block diagram of a distributed language instruction system that evaluates pronunciation quality .", "label": "", "metadata": {}, "score": "60.282433"}
{"text": "A full DPA is used in the connected digit recognizer in contrast to the windowed DPA used in the isolated word recognizer .The reason for this is that in a connected digit utterance a particular template might begin or end anywhere in the utterance .", "label": "", "metadata": {}, "score": "60.31098"}
{"text": "To avoid decreasing of the recognition performance , the decoder algorithm was improved for signal retrieval using differential acceleration .The proposed algorithm using differential acceleration is shown in Figure 22 and represents three input signals .First , the speaker uttered a word , and its signal was then extracted with the accelerator .", "label": "", "metadata": {}, "score": "60.34066"}
{"text": "The source text comprises one or more words in a source language .An acoustic processor generates a sequence of coded representations of an utterance to be recognized .The utterance comprising a series of one or more words in a target language different from the source language .", "label": "", "metadata": {}, "score": "60.34964"}
{"text": "First is that individual frames of the input speech are statistically independent of one another .As a consequence , the likelihood functions in Equation 1 can be computed as products of likelihoods of the individual frames that make up the segment of the input signal being tested .", "label": "", "metadata": {}, "score": "60.438164"}
{"text": "e . is expressed as a transfer function that converts a noisy signal to a clear signal .To estimate .H .E . s .t .i . m . a .t .e . , autocorrelation functions and linear prediction coefficients by the Levinson Durbin algorithm are required ( Durbin , 1960 ) .", "label": "", "metadata": {}, "score": "60.49102"}
{"text": "e . , the following equation was used .Figure 6 shows the retrieval signal using a transfer function in a word estimated by the cross spectrum method .Sufficient recovery of the frequency characteristic was not observed when processed by the cross spectrum method .", "label": "", "metadata": {}, "score": "60.51526"}
{"text": "This is true because the many of the context - dependent score 's components already exist from operation of the HMM recognizer 203 used for segmentation .The score for a phone and a sentence are computed similarly as in the specific embodiment , except that in Equation ( 10 ) , the context - dependent posterior produced by Equation ( 12 ) should be substituted for the context - independent posterior produced by Equation ( 9 ) .", "label": "", "metadata": {}, "score": "60.549557"}
{"text": "H .S . p .e .e .c . h . and .H .N .o .i . s .e . , the number of the linear prediction coefficients and autocorrelation function used the same number because this setting allows us to solve the problem simply and easily .", "label": "", "metadata": {}, "score": "60.566925"}
{"text": "In one preferred embodiment , the input sequence is resampled during preprocessing , so calculating the actual distance can be avoided in the resampling procedure performed for segmental matching .Since a sample segment does not necessarily contain the same number of points as the model segment that it is being compared to a resampling procedure is needed .", "label": "", "metadata": {}, "score": "60.677418"}
{"text": "Although certain preferred embodiments have been shown and described , it will be understood that many changes and modifications may be made therein without departing from the scope and intent of the appended claims .The multistage word recognizer uses a word reference representation based on reliably detected peaks of phoneme similarity values .", "label": "", "metadata": {}, "score": "60.68956"}
{"text": "( See , for example , F. Jelinek . \"Continuous Speech Recognition By Statistical Methods .\" Proceedings of the IEEE , Vol . 64 , No . 4 , April 1976 , pages 532 - 556 . )Preferably , each acoustic command model represents a command spoken in isolation ( that is , independent of the context of prior and subsequent utterances ) .", "label": "", "metadata": {}, "score": "60.748337"}
{"text": "At this point the set up process continues on to FIG .9 via branch \" A \" .Also provided is a routine to handle situations where an actual command shows up as part of the spoken query seeking relevant commands .", "label": "", "metadata": {}, "score": "60.89564"}
{"text": "Such an environment demands the very natural mode of continuous speech input .However , problems of identifying word boundaries in continuous speech recognition , along with larger vocabulary demands and the requirement of syntax control processing to identify only predefined meaningful phrases and sentences , requires added and more complex processing .", "label": "", "metadata": {}, "score": "61.039948"}
{"text": "The stored acoustic models may be , for example , Markov models or other dynamic programming type models .The parameters of the acoustic Markov models may be estimated from a known uttered training text by , for example , the Forward - Backward Algorithm .", "label": "", "metadata": {}, "score": "61.084198"}
{"text": "More sophisticated language models based on probabilistic decision trees , stochastic context - free grammars , and automatically discovered classes of words have also been used .While statistical language models which use no knowledge or information about the actual utterance to be recognized are useful in scoring speech hypotheses in a speech recognition system , the best scoring speech hypotheses do not always correctly identify the corresponding utterances to be recognized .", "label": "", "metadata": {}, "score": "61.18775"}
{"text": "This application also shows detailed programming as well as apparatus for providing the above - noted procedures .It is indicated that such apparatus can be employed in conjunction with this invention .U.S. Pat .No .4,241,329 issued on Dec. 23 , 1980 to L. G. Bahler et al and entitled \" Continuous Speech Recognition Method for Improving False Alarm Rates \" also describes a system which is pertinent in enabling one to appreciate prior art speech recognition techniques .", "label": "", "metadata": {}, "score": "61.20023"}
{"text": "e .n . ) is calculated from the difference between the input signal and the output signal .By using an error signal , the system can be used to estimate a new filter part using Equation 5 .Figure 8 shows the retrieval signal using an adaptive filter when the convergence coefficient was set to 0.01 , and the filter length of taps was 16,384 .", "label": "", "metadata": {}, "score": "61.298332"}
{"text": "A speech recognition apparatus as claimed in claim 2 , characterized in that : . the apparatus further comprises means for storing at least one acoustic silence model representing one or more series of acoustic feature values representing the absence of a spoken utterance ; .", "label": "", "metadata": {}, "score": "61.33411"}
{"text": "A speech recognition method as claimed in claim 25 , characterized in that the step of generating an acoustic model comprises : . storing a plurality of acoustic letter models ; and .generating an acoustic model of a word by replacing each letter in the spelling of the word with an acoustic letter model corresponding to the letter .", "label": "", "metadata": {}, "score": "61.515728"}
{"text": "A speech recognition system as claimed in claim 7 , characterized in that the means for generating an acoustic model comprises : . means for storing a plurality of acoustic letter models ; and .means for generating an acoustic model of a word by replacing each letter in the spelling of the word with an acoustic letter model corresponding to the letter .", "label": "", "metadata": {}, "score": "61.552135"}
{"text": "This achieves region - to - region alignment .For each training utterance the number of occurrences ( or probability ) of a particular region is then obtained .At that time , regions with probabilities less than a pre - established Reliability Threshold ( typically 0.25 ) are found unreliable and are eliminated .", "label": "", "metadata": {}, "score": "61.571167"}
{"text": "Still referring to FIG .1 , the speech recognition system further comprises a translation match score generator 26 for generating a translation match score for each speech hypothesis .Each translation match score comprises an estimate of the probability of occurrence of the speech hypothesis given the occurrence of the source text .", "label": "", "metadata": {}, "score": "61.59611"}
{"text": "730,714 Filed on Jul. 16 , 1991 .Bahl , L. R. , et al . \"A Maximum Likelihood Approach to Continuous Speech Recognition . \"IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .PAMI-5 , No . 2 , pp .", "label": "", "metadata": {}, "score": "61.667732"}
{"text": "The prior - art approach is further limited in that it can generate only certain types of evaluation scores , such as a spectral likelihood score .While the prior - art approach achieves a rudimentary level of performance using its evaluation scores , the level of performance is rather limited , as compared to that achieved by human listeners .", "label": "", "metadata": {}, "score": "61.74095"}
{"text": "In accordance with the present invention , there is provided an improved segment oriented method , or interleaved segmental method , in a handwriting recognition system , that ameliorates the tradeoff between efficiency and accuracy .Point oriented methods are used to obtain partial segmentation hypotheses .", "label": "", "metadata": {}, "score": "61.823074"}
{"text": "25 - 42 , which is herein incorporated by reference .The score for a phone and a sentence are computed similarly as in the specific embodiment , except that in Equation ( 10 ) , the MLP - based posterior is used instead of the HMM - derived posterior .", "label": "", "metadata": {}, "score": "61.84152"}
{"text": "7 is a block diagram of a system 701 for creating FIG .6 's mapping function 603 between one or more types of machine scores into a pronunciation grade as would be produced by a human listener .In FIG .", "label": "", "metadata": {}, "score": "61.8626"}
{"text": "4 is a block diagram of the presently preferred word recognizer system ; .FIG .5 is a block diagram illustrating the target congruence word prototype training procedure ; .FIG .6 is a bar graph comparing recognition results for clean test speech for the two hypothesizer stages ( RC , TC ) and the fine match stage ( MSM ) , the word hypothesizer ( RC+TC ) and the recognition system as a whole ( RC+TC+MSM ) .", "label": "", "metadata": {}, "score": "61.872154"}
{"text": "190 194 , Jun. 21 23 , 1988 .A speech recognizer that selects a command model for a current sound if the best match score for the current sound exceeds its corresponding threshold score .The threshold score is assigned a confidence score based on the best match score and recognition threshold of a prior sound .", "label": "", "metadata": {}, "score": "61.916115"}
{"text": "Thus , the system 801 according to the present invention permits a virtually inexhaustible , immediately - usable supply of unique word sequences for pronunciation evaluation .In another embodiment , the display 807 is replaced or supplemented by a speaker 809 that provides audio prompts , such as scripts and questions .", "label": "", "metadata": {}, "score": "61.982586"}
{"text": "A speech recognition system which interprets speech queries such as help queries and presents a list of relevant proposed commands sorted in order based upon relevance of the commands .When such a sorted command is selected , the system has means responsive to a speech command for carrying out the system action corresponding to the command .", "label": "", "metadata": {}, "score": "61.98894"}
{"text": "First , step 80 , a set of recognizable spoken commands , which will drive the system being used , is set up and stored .Then , there are set up appropriate processes to carry out the actions called for by each recognized speech command , step 81 .", "label": "", "metadata": {}, "score": "62.02247"}
{"text": "736,278 , Filed on Jul. 25 , 1991 .Lucassen , J. M. et al . \"An Information Theoretic Approach To The Automatic Determination Of Phonemic Baseforms . \" Proceedings of the 1984 IEEE Inter - Conference on Acoustics , Speech , and Signal Processing , vol .", "label": "", "metadata": {}, "score": "62.02722"}
{"text": "Phoneme models were trained on the TIMIT database SX sentences , downsampled to 8 kHz sampling rate .For training nominal clean phoneme models , each sentence was used twice : once as clean speech and once with artificially added stationary pink Gaussian noise at 20 dB SNR .", "label": "", "metadata": {}, "score": "62.028606"}
{"text": "Protect your idea and hire a patent lawyer .A speech recognition system displays a source text of one or more words in a source language .The system has an acoustic processor for generating a sequence of coded representations of an utterance to be recognized .", "label": "", "metadata": {}, "score": "62.057438"}
{"text": "This prior - art approach is referred to as text - dependent evaluation because it relies on statistics related to specific words , phrases , or sentences .What is needed are methods and systems for automatic assessment of pronunciation quality capable of grading even arbitrary utterances -- i.e . , utterances made up of word sequences for which there may be no training data or incomplete training data .", "label": "", "metadata": {}, "score": "62.06237"}
{"text": "The utterance of speech may be an arbitrary utterance made up of a sequence of words which had not been encountered before .Pronunciation scores are converted into grades as would be assigned by human graders .Pronunciation quality may be evaluated in a client - server language instruction environment .", "label": "", "metadata": {}, "score": "62.06257"}
{"text": "Once the word prototype has been obtained in this fashion , the average match rate and average word duration are computed and stored as part of the word prototype data .The number of parameters needed to represent a word depends on the average duration of the word and on the level of phonetic detail that is desired .", "label": "", "metadata": {}, "score": "62.13302"}
{"text": "For each new sample data point , taken in chronological sequence , the HMM hypotheses scores are discretely integrated and propagated through the HMM network .Alternatively , stochastic pattern recognizers can be segment oriented .A segmental feature is a measurement of some characteristic of a contiguous collection of sample points as for example by a sliding window measurement , or as further described below by applying segmental features selected through point based features .", "label": "", "metadata": {}, "score": "62.200024"}
{"text": "The acoustic processor measures the value of the feature of each sound during each of a series of successive time intervals to produce a series of feature signals representing the feature values of the sound .Means are also provided for storing a set of acoustic command models .", "label": "", "metadata": {}, "score": "62.261417"}
{"text": "Similar behavior is observed in the phoneme plausibility time series of the VINICS system , as described in \" Plausibility Functions in Continuous Speech Recognition : The VINICS System , \" by Y. Gong and J. P. Haton , Speech Communication , Vol . 13 , Oct. 1993 , pp .", "label": "", "metadata": {}, "score": "62.262703"}
{"text": "1 is a preferred embodiment block diagram of the Isolated Word / Connected Digit apparatus of the present invention .FIG .2 is a more detailed block diagram of the bandpass filter portion of the invention of FIG .1 .", "label": "", "metadata": {}, "score": "62.31192"}
{"text": "A speech recognition method as claimed in claim 12 , characterized in that the prior sound is contiguous with the current sound .A speech recognition method as claimed in claim 13 , further comprising the steps of : . storing at least one acoustic silence model representing one or more series of acoustic feature values representing the absence of a spoken utterance ; . generating a match score for each sound and the acoustic silence model , each match score comprising an estimate of the closeness of a match between the acoustic silence model and a series of feature signals corresponding to the sound ; and .", "label": "", "metadata": {}, "score": "62.33603"}
{"text": "Using an adaptation technique to estimate the new parameter in an acoustic model , the recognition performance increased to greater than 95 % .Here , we focused on the investigation of the signal retrieval , so the feature vectors in the acoustic models did not need new parameters in this experiment .", "label": "", "metadata": {}, "score": "62.354523"}
{"text": "The technique uses a method for reducing the complexity by computing the summation term in Equation 2 recursively using table lookups .Each step of the recursion uses the following equation : . where SUM i is the distance equivalent to the sum of probabilities including i terms .", "label": "", "metadata": {}, "score": "62.41731"}
{"text": "Preferably , in this embodiment , the speech hypothesis generator 16 generates one or more speech hypotheses solely from words in the set of candidate words from candidate word generator 20 .Returning to FIG .1 , the speech recognition system further comprises an acoustic model generator 18 for generating an acoustic model for each speech hypothesis generated by the speech hypothesis generator 16 .", "label": "", "metadata": {}, "score": "62.49106"}
{"text": "The system also provides means for adding terms to previous speech terms wherein the probability determining means will redetermine probability to include such added terms .In such a situation , the probability determining means will redetermine the weights to include the additional weights of such added terms .", "label": "", "metadata": {}, "score": "62.51719"}
{"text": "3 is a block diagram showing a speech segmenter of FIG .2 that is a hidden Markov model ( HMM ) speech recognizer according to an embodiment of the present invention .FIG .4 is a diagram illustrating a portion of a maximum likelihood path for sample input speech .", "label": "", "metadata": {}, "score": "62.52145"}
{"text": "The system relies on two fixed data structures storing the finite state description of the grammar to compute what templates should be matched next in the sentence .The first structure is a node - to - node connection matrix ( NODCO ) .", "label": "", "metadata": {}, "score": "62.540268"}
{"text": "At the end of that process a target rate constraint ( i.e. desired number of targets per second ) is then applied to obtain a uniform word description level for all the words in the lexicon .The desired number of targets per second can be selected to meet system design constraints such as the ability of a given processor to handle data at a given rate .", "label": "", "metadata": {}, "score": "62.58167"}
{"text": "( See , for example , \" Vector Quantization Procedure For Speech Recognition Systems Using Discrete Parameter Phoneme - Based Markov Word Models \" by L. R. Bahl , et al , IBM Technical Disclosure Bulletin , Volume 32 , No . 7 , December 1989 , pages 320 and 321 . )", "label": "", "metadata": {}, "score": "62.601326"}
{"text": "In a more sophisticated implementation , initial model segments can be computed from isolated letter samples before the iterative training procedure starts , and then applied and updated at each iteration during training .FIGS . 3 and 4 illustrate the effect of applying letter matching scores in the HMM system by comparing the different letter level segmentations obtained with and without letter matching scores .", "label": "", "metadata": {}, "score": "62.637978"}
{"text": "For example , the output means may display an unrecognizable - sound indicator if the best match score for the current sound is worse than the recognition threshold score for the current sound .The unrecognizable - sound indicator may comprise , for example , one or more question marks .", "label": "", "metadata": {}, "score": "62.739876"}
{"text": "The following equation describes the Wiener filtering method .The estimated signal spectrum , .H .E . s .t .i . m . a .t .e . , is calculated from the noisy speech , .", "label": "", "metadata": {}, "score": "62.769173"}
{"text": "During training , a current frame -- and optionally its surrounding acoustic context frames -- is presented to the inputs of the MLP along with the desired output .The desired output for any frame is 1-of - N targets ( target 1 is set to the output corresponding to the correct phone type and targets 0 are used for the other outputs ) .", "label": "", "metadata": {}, "score": "62.77357"}
{"text": "Despite these potential advantages of speech recognition computer interfaces , this technology has been relatively slow in gaining extensive user acceptance .That aspect of the technology is now expected to have accelerated development until it will have a substantial niche in the word processing market .", "label": "", "metadata": {}, "score": "62.77735"}
{"text": ", 2004 ) .The signals were recorded at 16 kHz and 16 bits .Table 1 shows the recording environments used in this research .Speech generally provides a clear signal ; however , body - conducted speech is not always clear because it lacks a high frequency component ( 2 kHz or more ) .", "label": "", "metadata": {}, "score": "62.78144"}
{"text": "A first alternate acoustic - scoring embodiment computes a context - dependent posterior probability according to a variation of Equation ( 9 ) .Equation ( 12 ) differs from Equation ( 9 ) in that the term p(y t .linevert split.q i , ctx i ) in the numerator is computed from an output distribution of an HMM state to which the frame y t is aligned in a context - dependent ( i.e. , tri - phone ) HMM phone model .", "label": "", "metadata": {}, "score": "62.80469"}
{"text": "The rate of speech of each exemplary speaker is calculated from the training speech .The rate of speech of the student speaker 105 is calculated from available data for the speaker , including the acoustic segmentation 205 itself .The following equations summarize use of speaker - normalized phone durations in the preferred embodiment : # # EQU2 # # II.B. Syllabic Duration .", "label": "", "metadata": {}, "score": "62.82232"}
{"text": "A neural network ( NN ) is also used in speech recognition previously .However ANN is applied to other application ( Rivara et al . , 2009 ) , speech recognition systems uses only HMM recently .Usually , the HMM 's state transitions are in a left - to - right model , and the initial and final states are limited .", "label": "", "metadata": {}, "score": "62.829918"}
{"text": "The method according to claim 21 wherein said student speech sample comprises an acoustic features sequence , the method further comprising the steps of : . computing a path through a set of trained hidden Markov models ( HMMs ) from among said trained speech models , said path being an allowable path through the HMMs that has maximum likelihood of generating said acoustic features sequence ; and . identifying transitions between phones within said path , thereby defining phones .", "label": "", "metadata": {}, "score": "62.86792"}
{"text": "Referring to FIG .3 , the interesting regions of high phoneme similarity value are represented as high similarity regions .By representing the speech as features at a lower data rate in the initial stages of recognition , the complexity of the matching procedure is greatly reduced .", "label": "", "metadata": {}, "score": "62.87504"}
{"text": "Consequently , we experimented whether supervised speech recognition could be achieved by this system .The proposed system would be able to estimate the boundary of a sub - word or a word using the recognition decoder .The continuous sub - word unit recognition decoder is made by Julian that is the Large vocabulary continuous speech recognition system ( Kawahara et al . , 1999 ; Lee et al . , 2001 ) .", "label": "", "metadata": {}, "score": "62.880775"}
{"text": "Bahl , L. R. , et al .\" Speaker - Independent Label Coding Apparatus \" .U.S. patent application Ser .No .673,189 , filed Mar. 22 , 1991 .Bahl , L. R. , et al . \"Vector Quantization Procedure For Speech Recognition Systems Using Discrete Parameter Phoneme - Based Markov Word Models . \"", "label": "", "metadata": {}, "score": "62.895485"}
{"text": "The parameters of these distributions are estimated according to standard statistical estimation methods using the durations of each type of phone as found in training speech from exemplary speakers .In other , preferred embodiments , each phone type 's duration probability distribution is represented as a ( nonparametric ) probability mass function .", "label": "", "metadata": {}, "score": "62.939186"}
{"text": "To evaluate the performance of signal retrieval using differential acceleration , the Julian ( Kawahara et al . , 1999 ; Lee et al . , 2001 ) , the Japanese speech recognition system that consists of grammar and an acoustic model , was used as the recognition decoder .", "label": "", "metadata": {}, "score": "63.00843"}
{"text": "AT9 - 98 - 344 ) is directed to the modeless or transparent transitions between the spoken query state when the user presents queries to search for desired commands and the command mode when the user controls the system by speaking the located actual commands .", "label": "", "metadata": {}, "score": "63.02034"}
{"text": "Equation ( 7 ) was applied for speech recognition with signals of differential acceleration .The recognition decoders give the recognition results that are the candidates of words .w .w .w .N .The parameters of the frame lengths and acoustic scores differ in scale for each signal because Wiener filtering causes a problem in sample length .", "label": "", "metadata": {}, "score": "63.06353"}
{"text": "Each ending path for a template represents the completion of a partial digit phrase ending in the digit represented by the template and matching the utterance from its beginning up to the current utterance frame .The purpose of the connected digit phrase score and update function ( DIGSEQ ) 1104 is to compute a normalized path score for each of these partial phrases and save the best one .", "label": "", "metadata": {}, "score": "63.168076"}
{"text": "After processing each template frame against the current utterance frame , the best template window score is determined 1050 , and a determination is made as to whether the current template frame is within an end range of the template and if the template has an ending path 1052 .", "label": "", "metadata": {}, "score": "63.206688"}
{"text": "In other embodiments , the pronunciation evaluator ( of FIG .1 ) is not implemented on the server processor 811 .Instead , the evaluator is implemented on either the client processor 803 or elsewhere .Therefore , pronunciation evaluation is controlled by the client process without need for sending speech samples to the server process .", "label": "", "metadata": {}, "score": "63.227592"}
{"text": "Since the normalized path score is basically the average frame - to - frame distance for the match , partial sentence descriptions ending in isolated templates or connected digit template sequences compete on equal footing .The final step in the IWCD algorithm after the last utterance in the sentence has been matched is to search back through the syntax sentence description tables to retrieve the word sequence associated with the best scoring sentence description 740 .", "label": "", "metadata": {}, "score": "63.392517"}
{"text": "A convergence coefficient of 0.3 and number of connection of 6 times were used .It was possible to recover the high frequency components and the formant frequencies .Additionally , since an impulsive noise was mixed at the boundary of each sub - word , the calculated results always include the errors .", "label": "", "metadata": {}, "score": "63.401237"}
{"text": "Improvement using a combination between the proposed method and conventional method .We attempted to extract a clear signal using a combination of differential acceleration and the Wiener filtering method .We next evaluated the combination of the proposed method with various conventional methods including the cross spectrum method and the adaptive filter method .", "label": "", "metadata": {}, "score": "63.422638"}
{"text": "The running of the process will now be described with respect to FIG .9 .First , step 105 , a determination is made as to whether there has been a speech input .If No , then the input is returned to step 105 where a spoken input is awaited .", "label": "", "metadata": {}, "score": "63.443012"}
{"text": "Find which keyword template has the lowest top score .Trace back to determine when the match to that keyword template started ( frame M ) .As with other detection / rejection methods , thresholds are determined empirically to achieve the desired operating point .", "label": "", "metadata": {}, "score": "63.552155"}
{"text": "Through this mechanism , segmental letter matching scores computed on dynamically allocated , temporary , segments directly affects the decision making at each point during the Viterbi search , so that the system is biased towards sequences with better matches at the letter level .", "label": "", "metadata": {}, "score": "63.591934"}
{"text": "H .N .o .i . s .e . , is then estimated by autocorrelation functions and is used as a noise signal in differential acceleration .Figure 5 shows the result of each signal when the coefficient of both linear prediction coefficients and autocorrelation functions were equal to 1 , frame width was 764 sample , and repetition was three times .", "label": "", "metadata": {}, "score": "63.71133"}
{"text": "7 is a more detailed block diagram of the recognition and syntax control portions of the IW / CD algorithm of FIG .4 . FIG .8 is a graph summarizing the time alignment and matching , windowing , and boundary constraint operations of the Isolated Word recognition portion of the IW / CD algorithm of FIG .", "label": "", "metadata": {}, "score": "63.73745"}
{"text": "I. Automatic Pronunciation Evaluation .FIG .1 is a block diagram of a system 101 for evaluating pronunciation quality according to embodiments of the present invention .In FIG .1 , a speech input device 103 converts a sequence of spoken words from a speaker 105 into machine - readable input speech 107 .", "label": "", "metadata": {}, "score": "63.747433"}
{"text": "The principle of this method was developed and described in 1973 by J. F. Bridle in an article entitled An Efficient Elastic - Template Method for Detecting Given Words in Running Speech published by the British Accoustical Society in the spring meeting , pages 1 - 4 , April 1973 .", "label": "", "metadata": {}, "score": "63.82817"}
{"text": "The auto - recognition of dice system ( ARDS ) software is written using image processing techniques and MUGCA in Visual Basic 6.0 with MIL 8.0 library , as shown in Figure 6 .The optimal clustering weighting , the distinguishing coefficient , and the score of dice can be obtained by ARDS computing .", "label": "", "metadata": {}, "score": "63.834248"}
{"text": "An apparatus and method for recognition of sentences comprised of utterances separated by short pauses , the utterances representative of both isolated words and connected words .Speech to be recognized is converted into frames of digital signals .Selected ones of the frames of digital signals are compared with isolated word and connected word templates stored in a template memory .", "label": "", "metadata": {}, "score": "63.835594"}
{"text": "Note the high top 10 % accuracy for the RC stage is graphically depicted in FIG .6 .The region count prototype is constructed as follows .A first utterance of a training word or phrase is represented as time - dependent phoneme similarity data .", "label": "", "metadata": {}, "score": "63.84773"}
{"text": "The technique finds the concatenation or string of templates that most closely matches the incoming speech without making any distinction between \" keyword templates \" and \" filler templates \" .The system then serves to report the occurrence of a keyword whenever the template for that keyword appears in the best matching template string .", "label": "", "metadata": {}, "score": "63.964306"}
{"text": "ICASSP , Vol .I , pp .469 - 472 , 1992 ; \" Speaker Independent Speech Recognition Method Using Phoneme Similarity Vector , \" by M. Hoshimi et al . , Proc .ICSLP , Vol . 3 , pp .", "label": "", "metadata": {}, "score": "63.982426"}
{"text": "Abstract .A speech recognizer that selects a command model for a current sound if the best match score for the current sound exceeds its corresponding threshold score .The threshold score is assigned a confidence score based on the best match score and recognition threshold of a prior sound .", "label": "", "metadata": {}, "score": "64.15222"}
{"text": "In any event , the apparatus for performing keyword template or filler template matching are known in the prior art and such techniques are evident by structure and apparatus described in the above - noted references .Referring to FIG .3 , there is shown a block diagram of the method employed according to this invention .", "label": "", "metadata": {}, "score": "64.22454"}
{"text": "The word hypothesizer and fine match stages of the invention share the initial representation of speech as a sequence of multiple phoneme similarity values .The word hypothesizer stages further refine this speech representation , to preserve only the interesting regions of high phoneme similarity , or features .", "label": "", "metadata": {}, "score": "64.266716"}
{"text": "To each solid line transition , there corresponds an output probability distribution over either feature vector signals or label signals produced by the acoustic processor 10 .For each state of the model , there corresponds a probability distribution over the transitions out of that state .", "label": "", "metadata": {}, "score": "64.270035"}
{"text": "3 is a table giving the filter characteristics of the bandpass filter portion of FIG .2 . FIG .4 is a preferred embodiment block diagram of the operation of the IW / CD algorithm portion of the present invention .", "label": "", "metadata": {}, "score": "64.394745"}
{"text": "Speech recognition systems which match each input utterance to reference templates composed of phoneme similarity vectors , as in the model speech method of Hoshimi et al . , cited above , have achieved high accuracies for small vocabulary tasks .Their reference speech representation is frame - based and requires a high data rate ( typically 8 to 12 parameters every 10 to 20 milliseconds ) .", "label": "", "metadata": {}, "score": "64.40833"}
{"text": "9a - e and FIG .10b summarizes the window movements .The center of the window is defined to be the second cell up 902 in FIG .9a .If the window minimum is at the center 1031 , a movement control variable is set so that the window will be advanced up one template frame for the next utterance frame 1032 .", "label": "", "metadata": {}, "score": "64.46793"}
{"text": "the speech hypothesis generator generates one or more speech hypotheses solely from words in the set of candidate words .A speech recognition system as claimed in claim 1 , characterized in that the acoustic match score comprises an estimate of the probability of occurrence of the sequence of coded representations of the utterance given the occurrence of the speech hypothesis .", "label": "", "metadata": {}, "score": "64.52849"}
{"text": "In word processing , such visual feedback is inherent in this process since the purpose of the process is to translate from the spoken to the visual .That may be one of the reasons that the word processing applications of speech recognition has progressed at a faster pace .", "label": "", "metadata": {}, "score": "64.53145"}
{"text": "However , there was a marginal difference of spectrograms in all frequencies of Figure 14 .Therefore , the adaptive filter for a word was confirmed as the most suitable retrieval method when it was combined with retrieval signal of differential acceleration .", "label": "", "metadata": {}, "score": "64.58294"}
{"text": "The signal characteristic of body - conducted speech in a noisy environment is not affected by noise ; however , the basic frequency of the signal rises by the Lombard effect .Generally , since the decoder only uses spectral envelopes as recognition parameters , the problem is a matter of no importance .", "label": "", "metadata": {}, "score": "64.59835"}
{"text": "4 , an overview of the presently preferred system will be presented .The first component of the present system is a phoneme similarity front end 10 that converts speech signals into phoneme similarity time series .Speech is digitized at 8 kilohertz and processed by 8th order linear predictive coding ( LPC ) analysis to produce 8 cepstral coefficients every 100th of a second .", "label": "", "metadata": {}, "score": "64.60625"}
{"text": "Keyword and filler templates are matched simultaneously .The reason for showing the termination criterion in the upper part of the syntax is that the algorithm keeps track of the instants of time at which the task syntax is entered and exited .", "label": "", "metadata": {}, "score": "64.65568"}
{"text": "Automatic Determination of Pronunciation of Words From Their Spellings . \"IBM Technical Disclosure Bulletin , vol .32 , No .10B Mar. 1990 , pp .19 . gtoreq.23 .Bahl , L. R. et al .\" Fast Algorithm for Deriving Acoustic Prototypes for Automatic Speech Recognition . \" U.S. patent application Ser .", "label": "", "metadata": {}, "score": "64.65794"}
{"text": "A word spotter detects the occurrence of these keywords .The recognition methods currently employed in CSR and word spotting systems frequently cause word or phrase utterances to be reported when they are not actually spoken .In the prior art there essentially are two main methods of word spotting .", "label": "", "metadata": {}, "score": "64.65856"}
{"text": "Next the list of reliable regions , together with the associated probabilities of detecting those regions is passed to the target building module 32 .This module builds targets by unifying the region series to produce a list of phoneme targets associated with each word in the database .", "label": "", "metadata": {}, "score": "64.71222"}
{"text": "Table 9 .Table 10 .Recognition results of all speakers in noisy environment .Conclusions and future work .Here , we investigated a signal retrieval from body - conducted speech using differential acceleration combined with conventional noise reduction methods .", "label": "", "metadata": {}, "score": "64.73497"}
{"text": "An automatic speech recognition system employs parallel syntaxes with a first syntax operative to compare keyword templates with incoming speech over a given time interval and with a second syntax in parallel with the first and operative to compare filler templates with incoming speech over the same interval .", "label": "", "metadata": {}, "score": "64.76294"}
{"text": "Table 1 .Figure 1 .Figure 2 .Body - conducted speech .Differential acceleration .Because body conducted speech does not exhibit a high frequency component , conventional retrieval techniques may also be needed to extract clear speech .However , speech is not well measured with a microphone in noisy environments .", "label": "", "metadata": {}, "score": "64.76843"}
{"text": "determining from said path at least one boundary or duration of one acoustic unit .The method according to claim 9 wherein : . said spoken sequence of words is spoken according to a known script ; and .the path computing step comprises using said script in defining allowability of any path through the HMMs .", "label": "", "metadata": {}, "score": "64.80097"}
{"text": "The candidates for recognition in this experiment included each of the following signals : .The body - conducted speech was compared with the retrieval signal from the recognition experiment .It was expected that the recognition performance would improve if the signal approximated natural speech from the body - conducted speech .", "label": "", "metadata": {}, "score": "64.80774"}
{"text": "The congruence score of a matched target CG match , that is , the alignment found between target t of the prototype and region r of the test word , is defined as . where A t and A r respectively represent the target 's area and the aligned region 's area in the time similarity plane .", "label": "", "metadata": {}, "score": "64.91463"}
{"text": "X .x .x .x .n are feature vectors .P .X .w . ) is likelihood from the acoustic model .Generally , the acoustic model represents the sub - word or word unit .The system determines the estimated candidate by the likelihood from each HMM .", "label": "", "metadata": {}, "score": "64.95355"}
{"text": "Then every frame of the input utterance is processed by the algorithm via frame loop 706 .For each frame the isolated word recognition algorithm ( RCLOOP ) 720 and the connected digit recognition algorithm ( DRLOOP ) 722 are called in turn to process all active templates relative to their respective tasks .", "label": "", "metadata": {}, "score": "64.97311"}
{"text": "Given the boundary points of a curve segment , many different metrics can be used to measure how well the curve segment matches a certain known pattern .Metrics can be based on various moment features , or other global features , for example , total angle change and presence of a loop .", "label": "", "metadata": {}, "score": "64.989105"}
{"text": "A pointer to the last frame of the previous matched template , .The total path score of the best partial digit phrase ending this frame .The total number of template frames in the partial digit phrase , .The normalized path score for the partial digit phrase .", "label": "", "metadata": {}, "score": "65.07895"}
{"text": "To improve the sound quality , we focused on a high frequency component of 2 kHz or more , however this signal has little gain and includes an effective frequency .Subsequently , we developed for a novel signal retrieval method using differential acceleration calculated from the difference of body - conducted speech in each sample .", "label": "", "metadata": {}, "score": "65.084885"}
{"text": "13 ) .Referring to FIG .7 , after each utterance is processed 726 , the algorithm tests the last template of each partial sentence description ending at the utterance to see if all templates are a member of a final node in the grammer 728 .", "label": "", "metadata": {}, "score": "65.08495"}
{"text": "Window movement control , .Path boundary control , .Path score normalization , .Partial sentence scoring and updating .The last function is really part of the syntax control 410 and serves to tie the results of each template match into the overall goal of recognizing the sentence .", "label": "", "metadata": {}, "score": "65.098724"}
{"text": "Alignment time , memory size and error rate under clean or mild noise conditions are in fact superior to the fine match procedures .The robustness of the word hypothesizer 's top 1 recognition performance under various other adverse conditions is under current investigation .", "label": "", "metadata": {}, "score": "65.169075"}
{"text": "The invention computes the likelihood score of Equation 2 for every hypothesized utterance .In the case of wordspotting , a keyword is hypothesized to have ended at every frame of input speech .The likelihood computation then proceeds as follows : .", "label": "", "metadata": {}, "score": "65.19527"}
{"text": "187 - 196 .Conventional speech recognition systems match each input utterance to reference templates , such as templates composed on phoneme similarity vectors , as in the model speech method ( MSM ) of Hoshimi et al .In these conventional systems the reference speech representation is frame - based and requires a high data rate , typically 8 to 12 parameters every 10 to 20 milliseconds .", "label": "", "metadata": {}, "score": "65.19616"}
{"text": "As each isolated word template ( or sequence of digit templates ) is matched against an utterance , the algorithm checks each partial sentence description ending at the previous utterance to see if the template ( or digit templates ) can legally extend the description 718 .", "label": "", "metadata": {}, "score": "65.21985"}
{"text": "National Academy of the Sciences , 1966 . )In one approach to speech recognition , speech hypotheses are scored using two probability models .One model is a language model which estimates the probability that the speech hypothesis would be uttered , but which uses no knowledge or information about the actual utterance to be recognized .", "label": "", "metadata": {}, "score": "65.22999"}
{"text": "6 , multiple pronunciation scores 115 are computed for acoustic features 111 of a single utterance .These scores include a phone duration score 115 , a syllabic duration score , 115 , and an acoustic - posterior - probability - based score 115 , which have been described , separately .", "label": "", "metadata": {}, "score": "65.3035"}
{"text": "The acoustic scorer 503 computes for each phone a normalized log - likelihood l ' i : . wherein l i is the log - likelihood corresponding to phone i and d i is its duration in number of frames .The normalization by the phone 's duration is to give short - duration phones a boost in their effect on the log likelihood score , which would be dominated by longer phones , otherwise .", "label": "", "metadata": {}, "score": "65.32613"}
{"text": "Here , to obtain a high recognition performance , the acoustic model needed to re - estimate the parameter using body - conducted speech .Because it is possible to estimate a speech from body - conducted speech , it expects that the retrieval signal can be directory used to speech recognition .", "label": "", "metadata": {}, "score": "65.39492"}
{"text": "Computation is done on all segments except segments in context with silence , which arc excluded by element 208 ( FIG .2 ) before acoustic unit duration is extracted .In a preferred embodiment , the acoustic unit duration model 213 includes probability distributions P d ' ( d ' .", "label": "", "metadata": {}, "score": "65.4091"}
{"text": "The word hypothesizer stages , depicted in FIG .4 generally at 14 , comprise the second major component of the system .A peak driven procedure is first applied on the phoneme similarity time series supplied by front end 10 .", "label": "", "metadata": {}, "score": "65.472824"}
{"text": "The acoustic scorer 503 computes an acoustic log - likelihood , log p(Y i . linevert split.q ) , of the speech Y i for each alignment to a phone type q 's HMM using the standard HMM backtracing technique known in the art of speech recognition .", "label": "", "metadata": {}, "score": "65.53842"}
{"text": "S . p .e .e .c . h .B .C .S .To estimate the retrieval signal , .H .B .C .S .E . s .t .i . m . a .", "label": "", "metadata": {}, "score": "65.56383"}
{"text": "The acoustic silence model may be , for example , a Markov model or other dynamic programming model .The parameters of the acoustic silence model may be estimated from a known uttered training text by , for example , smoothing parameters obtained by the forward - backward algorithm , in the same manner as for the acoustic command models .", "label": "", "metadata": {}, "score": "65.59825"}
{"text": "This is done by the fourth function , path score normalization ( TALLY ) .See 1064 in FIG .10a .When all the template frames of all the templates being processed are finished for the current frame , the next frame is processed 1066 .", "label": "", "metadata": {}, "score": "65.59841"}
{"text": "And Table 6 shows the average of all speakers .There was an improvement of 3 - 9 % in Speakers B and C but little improvement in Speaker A. About 5 % of the improvement was obtained through average of the recognition rate .", "label": "", "metadata": {}, "score": "65.625565"}
{"text": "Pronunciation quality is automatically evaluated for an utterance of speech based on one or more pronunciation scores .One type of pronunciation score is based on duration of acoustic units .Examples of acoustic units include phones and syllables .Another type of pronunciation score is based on a posterior probability that a piece of input speech corresponds to a certain model , such as a hidden Markov model , given the piece of input speech .", "label": "", "metadata": {}, "score": "65.66998"}
{"text": "67 - 72 , February 1975 . on Acoustics , Speech and Signal Processing , Vol . ASSP-26 , No . 6 , pp .575 - 582 , Dec. 1978 .The IWR algorithm can be broken down into five functions that take part in the recognition of every active isolated word template : .", "label": "", "metadata": {}, "score": "65.692856"}
{"text": "A method according to claim 1 wherein said handwriting recognition system is a Hidden Markov Model based handwriting recognition system .A method according to claim 1 wherein one of said segmental feature signals is based on an inter - segmental distance measure correlation metric .", "label": "", "metadata": {}, "score": "65.79117"}
{"text": "Equation ( 6 ) shows the fundamental formulation of this isolated word / sub - word recognition .In equation ( 6 ) , . w .^ is an estimated candidate , .W is set of all candidates , w represents each candidate in .", "label": "", "metadata": {}, "score": "65.842804"}
{"text": "For example , the output 16 may display an unrecognizable - sound indicator if the best match score for the current sound is worse than the recognition threshold score for the current sound .The unrecognizable - sound indicator may comprise one or more displayed question marks .", "label": "", "metadata": {}, "score": "65.90639"}
{"text": "The accuracy of the KS method is improved by a technique called \" bias removal \" which makes the threshold value a function of the keyword and the speaker .The second technique can generally be defined as the CSR method because it is implemented using a modified CSR algorithm .", "label": "", "metadata": {}, "score": "65.97272"}
{"text": "The mapping analyzer trains the neural network using the standard backpropagation technique , using cross - validation on about 15 percent of the training data .The training is stopped when performance degrades on the cross - validation set .In another embodiment of the present invention , the mapping analyzer 707 computes a mapping 603 that defines the predicted human score h ' as the conditional expected value of the actual human score h given the measured machine scores m 1 , . . .", "label": "", "metadata": {}, "score": "65.97388"}
{"text": "No .4,759,068 entitled \" Constructing Markov Models of Words From Multiple Utterances \" , or by any other known method of generating context - independent models .Alternatively , context - dependent models may be produced from context - independent models by grouping utterances of a command into context - dependent categories .", "label": "", "metadata": {}, "score": "66.00068"}
{"text": "Conventional retrieval methods for body - conducted speech include Modulation Transfer Function ( MTF ) , Linear Predictive Coefficients ( LPC ) , direct filtering and the use of a throat microphone .However , these methods need the direct input of speech ( Tamiya and Shimamura , 2006 ; Vu et al . , 2006 ; Liu et al .", "label": "", "metadata": {}, "score": "66.017494"}
{"text": "The word recognition processor of claim 1 wherein said region count stage produces a first score corresponding to the degree of fit between the input utterance and each of the first list of word candidates ; . wherein said target congruence stage produces a second score corresponding to the degree of fit between the input utterance and each of the second list of word candidates ; and . wherein said recognizer combines the first and second scores and selects at least the word with the best score as a final word candidate .", "label": "", "metadata": {}, "score": "66.05133"}
{"text": "The set of candidate words consists solely of words in the target language which are partial or full translations of words in the source text .One or more speech hypotheses are generated solely from words in the set of candidate words .", "label": "", "metadata": {}, "score": "66.05569"}
{"text": "Other rules in such a system specify the dropping of accents from letters , or the modification of verbal endings .The comparator 34 may also identify words in the source text that begin with an uppercase letter , but do not appear in the source language vocabulary , and place them into the target language vocabulary .", "label": "", "metadata": {}, "score": "66.13649"}
{"text": "Briefly , keyword templates are \" dragged across \" the input speech producing match scores at every input frame .Each match score measures the distance or dissimiliarity between the keyword template and the input speech ending at that frame .The keyword with the lowest match score is hypothesized as having been spoken .", "label": "", "metadata": {}, "score": "66.14943"}
{"text": "First , it uses a syntax structure that divides the templates into two groups - filler templates and templates associated with the task vocabulary .Second , the template matching procedure for matching the filler templates to incoming speech is modified to perform summing of probabilities .", "label": "", "metadata": {}, "score": "66.20842"}
{"text": "From the highest likelihood , the system can determine the candidate word / sub - word HMM .Generally , likelihood of acoustic models is computed with Viterbi algorithms .This recognition system includes dictionary and acoustic models , however no language models .", "label": "", "metadata": {}, "score": "66.258575"}
{"text": "2 , input speech is compared with keyword matches and filler matches over exactly the same intervals of the input speech .This matching occurs in given speech frames for both the keyword templates 20 and filler templates 21 .As indicated above , the prior art structure is completely amenable to performing such operation on keyword and filler templates .", "label": "", "metadata": {}, "score": "66.32656"}
{"text": "In one possible implementation , segment matching scores are not applied during training .The model segment for each letter pattern class is computed once using the segmentations obtained at the end of the training procedure .To be more specific , during the final iteration of the segmental iterative training at the whole word level , all training word samples are segmented and labeled according to the final HMM parameters .", "label": "", "metadata": {}, "score": "66.331535"}
{"text": "This biases against template paths that follow poor scoring partial digit phrases .At the beginning part of the utterance , where it is impossible for any partial phrase to have ended ( due to local path constraints ) , the penalty is set equal to the utterance frame number times a constant .", "label": "", "metadata": {}, "score": "66.33786"}
{"text": "The best results were obtained using the conditions shown in Figure 5 .We confirmed the recovery of frequency components at 2 kHz or more when using the Wiener filtering method , and musical noise was not found .Next , we compared the signal difference using spectrograms .", "label": "", "metadata": {}, "score": "66.36539"}
{"text": "The speech recognition apparatus according to the present invention may be used with any existing speech recognizer , such as the IBM Speech Server Series ( trademark ) product .The match score processor 14 and the recognition threshold comparator and output 16 may be , for example , suitably programmed special purpose or general purpose digital processors .", "label": "", "metadata": {}, "score": "66.399345"}
{"text": "No . 673,810 , filed on Mar. 22 , 1991 entitled \" Speaker - Independent Label Coding Apparatus \" .An apparatus and method for recognition of sentences comprised of utterances separated by short pauses , the utterances representative of both isolated words and connected words .", "label": "", "metadata": {}, "score": "66.414024"}
{"text": "We expect that these recognition rates can be greatly improved by fine - tuning parameters for each speaker using an adaptation technique .Table 5 .Table 6 .Recognition results of all speakers .Investigation of body - conducted speech in a noisy environment .", "label": "", "metadata": {}, "score": "66.431564"}
{"text": "If desired , the feature vector signals may be quantized by replacing each feature vector signal with a prototype vector signal , from a set of prototype vector signals , which is best matched to the feature vector signal .Each prototype vector signal has a label identifier , and so in this case the acoustic processor produces a series of label signals representing the feature values of the sound .", "label": "", "metadata": {}, "score": "66.45982"}
{"text": "Further reference is made to U.S. patent application Ser .No .473,422 filed on Mar. 9 , 1983 for G. Vensko et al 3 - 2 - 2 - 2 and entitled \" Apparatus and Method for Automatic Speech Recognition \" and assigned to the assignee herein .", "label": "", "metadata": {}, "score": "66.504654"}
{"text": "In other embodiments , various approximations are made to simplify the computation of this sum .One such approximation is # # EQU2 # # Here T.cndot .sup.k denotes the set of target sequences that begin with T and contain k additional words , n is a parameter specifying the maximum allowed number of additional words , and . alpha . is a special generic target word .", "label": "", "metadata": {}, "score": "66.52717"}
{"text": "In a typical Hidden Markov Model ( HMM ) based recognition system , an input pattern such as a handwritten word , is represented as a time - ordered sequence of observations , usually in the form of feature vectors .Observation probabilities derived from these feature vectors are presented to a network of HMM states .", "label": "", "metadata": {}, "score": "66.54705"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a block diagram of a system for evaluating pronunciation quality .FIG .2 is a block diagram of a pronunciation scorer of FIG .1 that produces a pronunciation score based on duration of acoustic units according to an embodiment of the present invention .", "label": "", "metadata": {}, "score": "66.55087"}
{"text": "In this process , low peaks and local peaks of phoneme similarity values are discarded , as illustrated in FIG .3 .In the preferred embodiment regions are characterized by 4 parameters : phoneme symbol , height at the peak location and time locations of the left and right frames .", "label": "", "metadata": {}, "score": "66.5535"}
{"text": "Sentence begin detection , utterance begin detection , utterance end detection , and sentence end detection .( Remember that an utterance is either an isolated word in the sentence or a sequence of connected digits , both of which have beginnings and ends tha must be detected ) .", "label": "", "metadata": {}, "score": "66.660126"}
{"text": "Each figure was compared with its original signal obtained with Wiener filtering .In the lower range of 1.5 kHz , there is a large difference in spectrograms between speech and retrieval signal with cross spectrum method .The difference was similarly extended in Figure 15 .", "label": "", "metadata": {}, "score": "66.704544"}
{"text": "An improved method for performing handwriting recognition of a handwriting sample represented by a signal sequence , utilizing one or more point oriented feature signals to hypothesize a segment of said handwriting sample giving rise to a point oriented hypotheses score wherein the improvement comprises the steps of : . generating one or more segmental feature signals of said segment of said handwriting sample giving rise to a segmental hypothesis score ; . augmenting said point oriented hypothesis score with a segmental matching score computed using said segmental hypothesis score ; and .", "label": "", "metadata": {}, "score": "66.71154"}
{"text": "The final score output by the word hypothesizer is a combination of the information obtained at each hypothesizer stage .In the presently preferred embodiment the final score output of the hypothesizer is : .In the presently preferred embodiment the five words having the highest combined scores are selected as word candidates for the final stage fine match process .", "label": "", "metadata": {}, "score": "66.73479"}
{"text": "In doing so , the program developer has the option , among others , of displaying all recognized commands or only recognized commands which are not clearly recognized so that the user will have the opportunity of confirming the command .AT9 - 98 - 343 ) .", "label": "", "metadata": {}, "score": "66.74097"}
{"text": "An inductive or iterative process is then performed for each of the successive utterances of the training word or phrase .Specifically , each successive utterance is represented as a vector like that of the first utterance .The two vectors are then combined to generate the vector sum and the vector sum of the squares .", "label": "", "metadata": {}, "score": "66.742096"}
{"text": "In some embodiments of the invention , the server processor 811 contains the final stages of the pronunciation evaluator which generate the evaluation grade for student pronunciation .In one such embodiment , the microphone 805 is coupled 817 to convey speech to the client processor 803 .", "label": "", "metadata": {}, "score": "66.76789"}
{"text": "In contrast , body - conducted speech is a solid propagated signal and is less influenced by noise .Figures 1 and 2 demonstrate the word , \" Asahi \" , obtained from the database of JEIDA which contains 100 local place words ( Itahashi , 1991 ) .", "label": "", "metadata": {}, "score": "66.84805"}
{"text": "One method for obtaining shape information in a point oriented system is to extract features from a window of fixed or variable size around each sample point .This method , however , does not adapt to the varying characteristics of pattern shapes , sizes , and segmentation boundaries .", "label": "", "metadata": {}, "score": "66.86229"}
{"text": "3 schematically shows an example of an acoustic silence model .The model starts in the initial state S4 and terminates in the final state S10 .The dashed null transitions correspond to no acoustic feature signal output .To each solid line transition there corresponds an output probability distribution over the feature signals ( for example , feature vector signals or label signals ) produced by the acoustic processor 10 .", "label": "", "metadata": {}, "score": "66.86452"}
{"text": ", 2004 ) .Additionally , a conventional microphone does not extract speech in a noisy environment .Thus , we proposed retrieval methods with only body - conducted speech .Body - conducted speech .Characteristics of body - conducted speech .", "label": "", "metadata": {}, "score": "66.86983"}
{"text": "The utterances are representative of both isolated words and connected words .Speech to be recognized is converted into frames of digital signals .Selected ones of the frames of digital signals are compared with isolated word and connected word templates stored in the template memory .", "label": "", "metadata": {}, "score": "66.90703"}
{"text": "However , it is possible to improve sound quality using a transfer function for sub - word , because sub - word is a minimum unit of uttered speech ( Ishimitsu et al . , 2007 ) .Figure 3 .Figure 4 .", "label": "", "metadata": {}, "score": "66.97951"}
{"text": "The regulated acoustic score was calculated by the acoustic score and flame length .With equation ( 8) , each score was compared and then the decoder determined the final candidate using the regulated acoustic scores .Experimental setup .Finally , we evaluated the signal retrieval from body - conducted speech in a noisy environment with conventional decoding and the decoding algorithm for differential acceleration .", "label": "", "metadata": {}, "score": "66.98019"}
{"text": "For training multistyle phoneme models , the additive noise was replaced by data show noise at 10 dB SNR .Word level training and testing was done on one repetition of speech data from 64 talkers .Word prototypes were trained and tested on nonoverlapping gender - balanced sets of 32 talkers each .", "label": "", "metadata": {}, "score": "67.024055"}
{"text": "Context - independent acoustic Markov models may be produced , for example , by the method described in U.S. Pat .No .4,759,068 entitled \" Constructing Markov Models of Words From Multiple Utterances , \" or by any other known method of generating acoustic word models .", "label": "", "metadata": {}, "score": "67.11636"}
{"text": "Noise reduction for differential acceleration .Spectral subtraction method .The spectral subtraction method subtracts the spectrum of the noise sections from the average of spectrum of the noisy signal ( Gong , 1995 ) .Equations ( 1 ) and ( 2 ) describe this method .", "label": "", "metadata": {}, "score": "67.12637"}
{"text": "Bahl , L. R. et al . \" Apparatus and Method For Grouping Utterances of a Phoneme Into Context - Dependent Categories Based on Sound - Similarity For Automatic Speech Recognition . \" U.S. patent application Ser .No .468,546 , filed Jan. 23 , 1990 .", "label": "", "metadata": {}, "score": "67.17029"}
{"text": "The states S1 through S10 and the allowable transitions between the states for the combined acoustic model of FIG .4 at each of a number of times t are schematically shown in FIG .5 .From Equation 11 , above , normalized state output scores W(S4 , t ) and Q(S10 , t ) can be obtained for states S4 and S10 of the combined model of FIG .", "label": "", "metadata": {}, "score": "67.17029"}
{"text": "In one embodiment , this combined score is computed as a sum over all complete sentence T ' in T.cndot .: # # EQU1 # # .The probability P(T ' ) is obtained from the language match score generator , and the probability P(S.vertline .", "label": "", "metadata": {}, "score": "67.17799"}
{"text": "It describes a line with a slope of 2 by being advanced by two every utterance frame .If the first cell of the window is equal to the bottom constraint 814 variable , the window is forced to advance by two cells 1042 .", "label": "", "metadata": {}, "score": "67.21704"}
{"text": "A Maximum Likelihood Approach to Continuous Speech Recognition . \"IEEE Transactions on Pattern Analysis and Machine Intelligence , Volume PAMI-5 , No . 2 , pages 179 - 190 , March 1983 . )The models may be context - independent or context - dependent .", "label": "", "metadata": {}, "score": "67.232544"}
{"text": "The proposed algorithms are substituted for manual recognition .From the experimental results , it is found that this system is excellent due to its good capabilities which include flexibility , high speed , and high accuracy .Keywords : .Machine vision ; Grey relational analysis ; Grey clustering ; Dice ; Auto - recognition .", "label": "", "metadata": {}, "score": "67.249756"}
{"text": "Stochastic pattern recognizers , such as Hidden Markov Model ( HMM ) based recognizers are typically point oriented in that the observations are often localized in nature .For example , observations for sampled on - line handwriting might include point positions , interpoint vector orientation such as stroke tangents and curvature .", "label": "", "metadata": {}, "score": "67.31066"}
{"text": "The system allows for automatic detection of the occurrence of keywords in unrestricted natural speech .The systemm can be trained by a particular speaker or can function independently of the speaker .In regard to the above - described techniques the primary disadvantage of the KS method is that it only uses templates for the keywords .", "label": "", "metadata": {}, "score": "67.379395"}
{"text": "Each silence match score comprises an estimate of the closeness of a match between the acoustic silence model and a series of feature signals corresponding to the sound .The recognition signal may be , for example , a command signal for calling a program associated with the command .", "label": "", "metadata": {}, "score": "67.39537"}
{"text": "Referring to FIGS . 8 , 9 , 10a and 10b , operation of the IWR algorithm is described .In FIG .10a , the start of the IWR algorithm begins every new speech frame but acts only on active isolated word templates .", "label": "", "metadata": {}, "score": "67.44266"}
{"text": "Recognition results .Retrieval signals with Wiener filtering exhibited marginal improvement with a decrease in recognition because the algorithm rejects a stationary noise and consonant frequency .This problem is described in Section 8.1 .We speculated that the noise reduction made improved the recognition performance when the stationary noise level was louder .", "label": "", "metadata": {}, "score": "67.48865"}
{"text": "The method of claim 16 further comprising : . comparing the input speech utterance with each prototype to provide a recognition score .Description .BACKGROUND AND SUMMARY OF THE INVENTION .The present invention relates generally to speech recognition .More particularly , the invention relates to a word recognizer having multistage word candidate hypothesizer .", "label": "", "metadata": {}, "score": "67.4991"}
{"text": "The method according to claim 9 wherein : . said sample acoustic units are syllables ; and .the step of determining at least one acoustic unit boundary or duration comprises the steps of : . extracting boundaries or durations of at least two phones from said path ; and .", "label": "", "metadata": {}, "score": "67.575005"}
{"text": "One method of automatically selecting context is described in U.S. patent application Ser .No .468,546 , filed Jan. 23 , 1990 , entitled \" Apparatus and Method For Grouping Utterances of a Phoneme Into Context - Dependent Categories Based on Sound - Similarity For Automatic Speech Recognition . \"", "label": "", "metadata": {}, "score": "67.67178"}
{"text": "This part of the algorithm is executed after every utterance to determine what templates should be activated for matching against the next utterance in the sentence .This will be explained later .The algorithm then sets a flag ( MOVEIT ) to tell the parameter extraction subtask that the system is waiting for speech 716 .", "label": "", "metadata": {}, "score": "67.71077"}
{"text": "When an utterance is detected , a count of the number of utterances in the sentence is incremented ( UTTIN ) and a non - speech frame counter ( NSPCNT ) is set ot zero 612 .This counter remains zero until the end of the utterance is found and is used to keep track of the number of frames in the pause between utterances or to indicate that the end of the sentence has occurred .", "label": "", "metadata": {}, "score": "67.721436"}
{"text": "the output means displays one or more words corresponding to the command model having the best match score for a current sound if the best match score for the current sound is better than the recognition threshold score for the current sound .", "label": "", "metadata": {}, "score": "67.750786"}
{"text": "A gap feature signal can be used to indicate whether a gap is present .In one preferred embodiment , the gap feature signal is a binary variable g(t ) , which can be computed during preprocessing for each point in the time ordered sequence .", "label": "", "metadata": {}, "score": "67.76007"}
{"text": "AT9 - 98 - 344 ) .This copending application involves seamless transitions between speech command modes of operation where speech commands are given to the system and the query mode of operation where spoken queries are given to the system from which the system may search for appropriate commands to be given to the system .", "label": "", "metadata": {}, "score": "67.81497"}
{"text": "If No from step 100 , a further determination is made , step 101 , as to whether the user has spoken any terms to be added to the last query .If No , the process is returned to decision step 93 via branch \" B \" , and a determination is made as to whether the session is at an end as previously described .", "label": "", "metadata": {}, "score": "67.832184"}
{"text": "\u03bc is the convergence coefficient , and .n is time index , respectively .Output signal .y .n . ) is provided by input signal .x .n . ) and current filter .w .n . )", "label": "", "metadata": {}, "score": "67.88413"}
{"text": "X .X .X .N were performed for speech recognitions as input signals .The signals of Figure 22 represent original body - conducted speech , differential acceleration and retrieval signals using Wiener filtering .This experiment focused on the body - conducted speech recognition in a noisy environment , so the speech signal is removed in this experiment .", "label": "", "metadata": {}, "score": "67.8946"}
{"text": "This invention was made with Government support under Contract Number N00014 - 91-C-0135 awarded by the office of Naval Research .The Government has certain rights in this invention .Claims .We claim : .A speech recognition system comprising : . means for displaying a source text comprising one or more words in a source language ; . an acoustic processor : for generating a sequence of coded representations of an utterance to be recognized , said utterance comprising one or more words in a target language different from the source language ; . means for generating a set of one or more speech hypotheses , each speech hypothesis comprising one or more words from the target language ; . means for generating an acoustic model of each speech hypothesis ; . means for generating an acoustic match score for each speech hypothesis , each acoustic match score comprising an estimate of the closeness of a match between the acoustic model of the speech hypothesis and the sequence of coded representations of the utterance ; . means for generating a translation match score for each speech hypothesis , each translation match score comprising an estimate of the probability of occurrence of the speech hypothesis given the occurrence , of the source text ; . means for generating a hypothesis score for each hypothesis , each hypothesis score comprising a combination of the acoustic match score and the translation match score for the hypothesis ; . means for storing a subset of one or more speech hypotheses , from the set of speech hypotheses , having the best hypothesis scores ; and . means for outputting at least one word of one or more of the speech hypotheses in the subset of speech hypotheses having the best hypothesis scores .", "label": "", "metadata": {}, "score": "68.0323"}
{"text": "Unlike point oriented systems where each point is analyzed independently , many alternate segments in a segment oriented system can be modelled for a given set of sample points .To generate all segmentations and compute all possible hypothesis scores is an intractable task , thus , impractical .", "label": "", "metadata": {}, "score": "68.09761"}
{"text": "Next , with respect to FIG .8 , step 88 , a routine is set up for displaying the relevant commands of step 86 sorted based upon the weighting of step 87 .A process is then set up for adding recognized noncommand terms , i.e. query terms , to the already displayed prior query terms and for looking up such relevant terms in the table of relevant terms , step 89 .", "label": "", "metadata": {}, "score": "68.191635"}
{"text": "Alternatively , a single correlation based metric can be used .In one preferred embodiment , the present invention is implemented with an inter - segmental distance measure correlation metric adapted from a similar metric used for isolated symbol recognition , which is disclosed in \" Method of Recognizing Handwritten Symbols , \" U.S. Pat .", "label": "", "metadata": {}, "score": "68.19261"}
{"text": "FIG .7 is a bar graph that compares the recognition rates under five test speech conditions : clean , data show 20 dB , car 20 dB , data show 10 dB , and car 10 dB SNR .Word prototypes were trained on clean speech ( left ) or on both clean and noisy ( data show noise at 10 dB SNR ) speech ( right ) ; and .", "label": "", "metadata": {}, "score": "68.19646"}
{"text": "The method of extracting normal speech under these complex conditions because environment always changes .Several methods have been investigated to extract clear speech under these conditions , such as a noise reduction method , the use of a microphone array or a body - conducted signal .", "label": "", "metadata": {}, "score": "68.29262"}
{"text": "A process for displaying all spoken inputs other than recognized commands , i.e. speech queries , is then set up , step 84 .A process for looking up all spoken inputs other than recognized commands , i.e. speech queries , on this relevance table to then determine relevant commands is set up , step 85 .", "label": "", "metadata": {}, "score": "68.40316"}
{"text": "To describe the invention , some terminology must be defined .A CSR system uses a syntax to specify which sequences of templates can be matched to the input speech .A syntax can be thought of as a network containing nodes and directional connections between nodes .", "label": "", "metadata": {}, "score": "68.62297"}
{"text": "Each speech hypothesis comprises one or more words from the target language .An acoustic model generator produces an acoustic model of each speech hypothesis .An acoustic match score generator produces an acoustic match score for each speech hypothesis .Each acoustic match score comprises an estimate of the closeness of a match between the acoustic model of the speech hypothesis and the sequence of coded representations of the utterance produced by the acoustic processor .", "label": "", "metadata": {}, "score": "68.648155"}
{"text": "Consequently , the query was displayed in window 71 .Then the speech term is interpreted using the relevance table of FIG .2 and the process and the algorithm to be described .The algorithm includes the following rules among others : a firm recognition of a speech term is accorded twice the weight of an infirm recognition .", "label": "", "metadata": {}, "score": "68.650116"}
{"text": "V. Combination of Scores and Mapping to a Human Grade .FIG .6 is a block diagram of a system that combines different types of pronunciation scores according to an embodiment of the invention .By combining scores , an improvement in evaluation performance is achieved , overall , as compared to using each score by itself .", "label": "", "metadata": {}, "score": "68.78262"}
{"text": "Otherwise , the template is deactivated 1060 .The isolated word recognition algorithm 720 permits the last several frames of the input utterance to be skipped .This is achieved by moving the top path boundary constraint back a few frames from the end of the utterance .", "label": "", "metadata": {}, "score": "68.81241"}
{"text": "The first fifty eigenvectors of the resulting matrix form the rotation matrix .( See , for example , \" Vector Quantization Procedure For Speech Recognition Systems Using Discrete Parameter Phoneme - Based Markov Word Models \" by L. R. Bahl , et al , IBM Technical Disclosure Bulletin , Volume 32 , No . 7 , December 1989 , pages 320 and 321 . )", "label": "", "metadata": {}, "score": "68.89867"}
{"text": "Word prototypes , for the multistyle training condition , used multistyle phoneme models and two training passes over the speech data : once clean and once with 10 dB SNR additive data show noise .Each recognition data point resulted from 3200 trials .", "label": "", "metadata": {}, "score": "68.91331"}
{"text": "A valid template sequence is obtained by following connections through the network and picking one ( any ) template each time a node is entered .A \" top score \" is obtained at each input frame for each template that is the accumulated distance between the input speech up to and including the current frame and the best concatenation of templates ending at the last frame of that template .", "label": "", "metadata": {}, "score": "68.94777"}
{"text": "Each probability mass function is smoothed , and a probability floor is introduced , in order to maintain robustness of the model , given that only finite quantities of training speech are available .Phone durations of the training speech are determined during training in the same manner as are phone durations 209 of input speech 107 determined during testing .", "label": "", "metadata": {}, "score": "68.948975"}
{"text": "No .655,958 , filed on Sept. 28 , 1984 and entitled \" Keyword Recognition System and Method Using Template - Concatenation Model \" filed for A. L. Higgins et al 1 - 1 - 1 and assigned to the assignee herein .", "label": "", "metadata": {}, "score": "68.98947"}
{"text": "Tables 7 - 9 are shown the recognition results of each speaker .And Table 10 is the result of average of all speakers .The meaning of each data is described in Section 5 .In all speakers , the recognition performances are improved on ' Diff .", "label": "", "metadata": {}, "score": "68.989685"}
{"text": "A phoneme similarity module , receptive of the input speech utterance , accesses the phone model database and produces phone similarity data indicative of the correlation between the input speech utterance and the phone model speech data corresponding to successive intervals of time .", "label": "", "metadata": {}, "score": "69.01022"}
{"text": "In actual implementation , the three separate scorers 113 would likely share many common components , such as an acoustic segmenter 203 ( of FIGS . 2 and 5 ) .A scores - to - grade mapper 119 accepts the different scores 115 and applies a mapping function 603 to the scores 115 to derive a single grade 121 .", "label": "", "metadata": {}, "score": "69.01996"}
{"text": "To incorporate segmental shape information into the search , where the letter is the segment , the incoming scores are augmented with segmental letter matching scores , computed using global letter shape models .More specifically , let \u03b1 i ( t 1 , t 2 ) be the likelihood score of the segment from sample point t 1 to t 2 on the observation sequence being matched to letter pattern class l , the augmented incoming scores are defined as : .", "label": "", "metadata": {}, "score": "69.03991"}
{"text": "T is the number of filler templates , and K is a constant that de - weights distances to account for intra - frame correlation of parameters .Equation 2 expresses the log likelihood ratio in terms of distances or template match scores .", "label": "", "metadata": {}, "score": "69.05971"}
{"text": "This variable keeps track of the number of utterance frames spanned by the DPA path for the template and is used as an index to link the current template to the one preceding it in the utterance .In order to keep track of what templates match where in the utterance and to be able to later link them together for obtaining the best matching connected digit phrase , several types of information must be saved for every utterance frame : .", "label": "", "metadata": {}, "score": "69.110466"}
{"text": "During operation of the pronunciation evaluation system 101 , the various data , including the input speech 107 , the acoustic features 111 , the pronunciation score(s ) 115 , and the pronunciation grade 121 may be stored in storage devices for later use .", "label": "", "metadata": {}, "score": "69.14728"}
{"text": "The noise cancellation processor 32 adapts to changing noise levels by periodically updating the noise vector N(t ) whenever the prior feature vector F(t-1 ) is identified as noise or silence .After noise cancellation , the feature vector F'(t ) is normalized to adjust for variations in the loudness of the input speech by short term mean normalization processor 38 .", "label": "", "metadata": {}, "score": "69.150566"}
{"text": "An acoustic model of a word is then produced by replacing each letter in the spelling of the word with an acoustic letter model corresponding to the letter .BRIEF DESCRIPTION OF THE DRAWING .FIG .1 is a block diagram of an example of a speech recognition system according to the invention .", "label": "", "metadata": {}, "score": "69.2009"}
{"text": "The invention of claim 1 , wherein said comprarison of said selected partial phrase connected word templates and said frames of digital signals is done in accordance with a full dynamic programming algorithm ( DPA ) .Description .BACKGROUND OF THE INVENTION .", "label": "", "metadata": {}, "score": "69.23105"}
{"text": "A speech recognition apparatus as claimed in claim 3 , characterized in that the recognition signal comprises a command signal for calling a program associated with the command .A speech recognition apparatus as claimed in claim 4 , characterized in that : .", "label": "", "metadata": {}, "score": "69.27891"}
{"text": "The matrix currently in use is made up of a family of 5 \" mel - cosine \" vectors that transform the bandpass filter data into an approximation of \" mel - cepstral \" coefficients .These 5 coefficients together with the amplitude measure are placed in the input sentence buffer 522 for use by the end point detection and recognition algorithms 404 and 406 .", "label": "", "metadata": {}, "score": "69.33098"}
{"text": "The Isolated Word Recognition ( IWR ) 720 and Connected Digit Recognition 722 algorithms are based on the well - known dynamic programming algorithm ( DPA ) which is described in an article by F. Itakura entitled \" Miminimum Prediction Residual Principle Applied to Speech Recognition \" , IEEE Trans .", "label": "", "metadata": {}, "score": "69.36455"}
{"text": "The model parameters were able to approximate a natural speech when the recognition rate compared with body - conducted speech to each retrieval signal .Additionally , because HMM is an acoustic model that evaluates each feature vector using the output of a multi - dimensional normal distribution , it can be evaluated statistically .", "label": "", "metadata": {}, "score": "69.368385"}
{"text": "No .5,182,773 entitled \" Speaker - Independent Label Coding Apparatus \" .Bahl , L. R .. , et al .Vector Quantization Procedure For Speech Recognition Systems Using Discrete Parameter Phoneme Based Markov Word Models .IBM Technical Disclosure Bulletin , vol .", "label": "", "metadata": {}, "score": "69.46936"}
{"text": "5 and 6 , and the query addition is compared to the relevance table , step 103 .Decision step 99 , a determination is made as to whether the user has spoken one of the relevant commands from which point , the process proceeds as described above .", "label": "", "metadata": {}, "score": "69.51265"}
{"text": "MFCCs were used in 12 dimensions computed every 10 ms .The differences in coefficients ( \u0394MFCC ) and power ( \u0394LogPow ) were also incorporated into the feature vectors .The recognition system then uses these parameters to discriminate sub - word or word unit candidates .", "label": "", "metadata": {}, "score": "69.52412"}
{"text": "The invention applies this principle to the detection or rejection of speech utterances .The invention uses the scores or distances provided by a modified CSR template matcher to approximate these likelikhoods .The numerator likelihood is evaluated using whole - word templates for the task vocabulary words , while the denominator likelihood is evaluated using filler templates .", "label": "", "metadata": {}, "score": "69.54383"}
{"text": "DESCRIPTION OF THE PREFERRED EMBODIMENT .The present invention employs a unique compact speech representation based on regions of high phoneme similarity values .As shown in FIG .1 , there is an overall consistency in the shape of the phoneme similarity time series for a given word .", "label": "", "metadata": {}, "score": "69.63079"}
{"text": "r .r .e . c .t .r . a .t .e .A . [ . % . ]Equation ( 9 ) is a word correct rate , which calculates a result whether the word is recognized or not .", "label": "", "metadata": {}, "score": "69.65756"}
{"text": "This diminishes the statistical power and therefore the performance of the method .The second shortcoming is that the method does not allow the operating point or tradeoff between false acceptance and false rejection errors to be controlled separately for each keyword .", "label": "", "metadata": {}, "score": "69.73337"}
{"text": "5 is a more detailed block diagram of the parameter extraction portion of the IW / CD algorithm of FIG .4 .FIG .6 is a more detailed block diagram of the sentence and utterance endpoint detection portion of the IW / CD algorithm of FIG .", "label": "", "metadata": {}, "score": "69.74115"}
{"text": "In general , all speech utterances for a given language may be represented by phones from a set of distinct phone types for the language , the number of distinct phone types being on the order of 40 .Acoustic Units : Time - segments of speech whose durations are used to generate a score that is indicative of pronunciation quality .", "label": "", "metadata": {}, "score": "69.80054"}
{"text": "This probability distribution is established by tabulating durations of all syllables found in training speech from exemplary speakers .Syllable durations of the training speech are determined during training in the same manner as are syllable durations 209 of input speech 107 determined during testing .", "label": "", "metadata": {}, "score": "69.80145"}
{"text": "Because the approach is computationally costly , it is not well suited to consumer product applications that , for cost reasons , can not use large , powerful processors .The present invention represents a significant departure from current frame - based techniques .", "label": "", "metadata": {}, "score": "69.83092"}
{"text": "Figure 11 .Figure 12 .Figure 13 .Figure 14 .Figure 15 .Difference of Adaptive 2 .Recognition experiment .Next , we evaluated the performance of the proposed method with an isolated word recognition experiment .In previous research , we constructed the body - conducted speech recognition system , which could perform in noisy environments , specifically in the engine room of a training ship ( Ishimitsu et al .", "label": "", "metadata": {}, "score": "69.90155"}
{"text": "A speech recognition system as claimed in claim 17 , characterized in that the means for measuring the value of at least one feature of an utterance comprises a microphone .A speech recognition method comprising : . displaying a source text comprising one or more words in a source language ; . generating a sequence of coded representations of an utterance to be recognized , said utterance comprising one or more words in a target language different from the source language ; . generating a set of one or more speech hypotheses , each speech hypothesis comprising one or more words from the target language ; . generating an acoustic model of each speech hypothesis ; . generating an acoustic match score for each speech hypothesis , each acoustic match score comprising an estimate of the closeness of a match between the acoustic model of the speech hypothesis and the sequence of coded representations of the utterance ; . generating a translation match score for each speech hypothesis , each translation match score comprising an estimate of the probability of occurrence of the speech hypothesis given the occurrence of the source text ; . generating a hypothesis score for each hypothesis , each hypothesis score comprising a combination of the acoustic match score and the translation match score for the hypothesis ; . storing a subset of one or more speech hypotheses , from the set of speech hypotheses , having the best hypothesis scores ; and . outputting at least one word of one or more of the speech hypotheses in the subset of speech hypotheses having the best hypothesis scores .", "label": "", "metadata": {}, "score": "69.90634"}
{"text": "Each word or command output by the speech recognition apparatus has an associated match score .By comparing the command words in the known training script with the recognized words output by the speech recognition apparatus , correctly recognized words and misrecognized words can be identified .", "label": "", "metadata": {}, "score": "69.97368"}
{"text": "The noise cancellation processor 52 adapts to changing noise levels by periodically updating the noise vector N(t ) whenever the prior feature vector F(t-1 ) is identified as noise or silence .The noise vector N(t ) is updated according to the formula .", "label": "", "metadata": {}, "score": "69.99169"}
{"text": "The recognition experiment using the differential acceleration followed by the Wiener filtering method , demonstrated the efficacy of differential acceleration that the recognition performance improved 3 - 5 % in isolated word recognition .These results suggest that the retrieval signal approximated natural speech .", "label": "", "metadata": {}, "score": "70.019516"}
{"text": "The method of claim 27 further comprising the step of computing the recognition score for a given instance of a spoken word or phrase with respect to a given region count prototype .The method of claim 29 wherein said recognition score is a weighted Euclidean distance .", "label": "", "metadata": {}, "score": "70.060265"}
{"text": "sbsb.1 t .sbsb.2 ) , where a l is the model segment for letter pattern l , a t1t2 is the segment from sample point t 1 to t 2 , on the input sample sequence and w.sub.\u03b1 is a weight factor .", "label": "", "metadata": {}, "score": "70.150024"}
{"text": "Each state in a speech HMM has an associated probability distribution of the acoustic features which are produced while in the state .( These output distributions are alternatively but equivalently described in the literature as being associated with the transition branches . )", "label": "", "metadata": {}, "score": "70.394424"}
{"text": "Briefly , this procedure works as follows .The probability of the aligned sentence pairs is a computable function of the parameter values .The goal of the procedure it to find parameter values which locally maximize this function .This is accomplished iteratively .", "label": "", "metadata": {}, "score": "70.41075"}
{"text": "By adopting the confidence scores according to the invention , a speech recognition apparatus and method has a high likelihood of rejecting acoustic matches to inadvertent sounds or words spoken but not intended for the speech recognizer .BRIEF DESCRIPTION OF THE DRAWING .", "label": "", "metadata": {}, "score": "70.42287"}
{"text": "All transition probabilities out of any given state , including any self transition probabilities , sum to one .The output and transition probability distributions for all states in a speech HMM are established from training speech data using standard HMM training algorithms and techniques , including the forward - backward ( Baum - Welch ) algorithm .", "label": "", "metadata": {}, "score": "70.42557"}
{"text": "Acoust . , Speech , Signal Proc . , Vol .ASSP-28 , pp .357 - 366 .End point detection 404 is the next step after the linear transformation .Thus , the end point 404 detection algorithms are activated every time the variable frame rate encoding algorithm 510 passes on a new frame of data to buffer 514 and the system is actively listening to speech ( i.e. MOVEIT flag is on ) .", "label": "", "metadata": {}, "score": "70.45237"}
{"text": "word translation probabilities p.sub.5 ( s.vertline.t ) for source words s and target words t satisfying # # EQU7 # # . alignment probabilities P.sub.6 ( i.vertline.j , l ) satisfying # # EQU8 # # .Values for these parameters can be determined from a large quantity of aligned source - target sentence pairs ( S.sup.l , T.sup.l ) . . .", "label": "", "metadata": {}, "score": "70.46492"}
{"text": "S . p .e .e .c . h . , and noise spectrum , .H .N .o .i . s .e .H .E . s .t .i . m . a .", "label": "", "metadata": {}, "score": "70.51201"}
{"text": "FIG .4 shows the segmentation of the same sample when letter matching scores are applied and the sample is correctly recognized .The hypothesis shown in FIG .3 is no longer selected because the segment corresponding to letter \" a \" does not match the corresponding model segment well and therefore yields a poor letter matching score .", "label": "", "metadata": {}, "score": "70.526024"}
{"text": "The acoustic scorer 503 of the specific embodiment computes the acoustic score 115 \u03c1 for an entire utterance as the average of the phone posterior scores \u03c1 i of each phone i : # # EQU6 # # wherein the sum runs over the number N of phones in the utterance .", "label": "", "metadata": {}, "score": "70.584595"}
{"text": "Table 2 shows the experimental environments for isolated word recognition .The recognition decoder , Julius ( Kawahara et al . , 1999 ; Lee et al . , 2001 ) , was used in this experiment .Because Julius is a decoder for large vocabulary continuous speech recognition , it can be changed into isolated word recognition .", "label": "", "metadata": {}, "score": "70.60889"}
{"text": "A method of improving the reliability of keyword identification by a speech recognition system for continuously spoken speech in a given language comprising the steps of : . providing a set of keyword templates each of which represents a respective keyword for recognition by said system ; . providing a set of filler templates each of which is representative of an arbitrary sound or utterance that is a component of spoken speech including words in said given language ; . generating a set of signals indicative of said spoken speech in a given time interval ; . providing parallel operations of : . comparing the keyword match score to the filler concatenation match score to determine , according to a pre - established threshold , whether said keyword match score is sufficiently better than said filler concatenation match score to confirm keyword identification .", "label": "", "metadata": {}, "score": "70.66112"}
{"text": "4 is a block diagram of an example of an acoustic processor for a speech recognition system according to the invention .FIG .5 is a block diagram of an example of an acoustic feature value measure for an acoustic processor for a speech recognition system according to the invention .", "label": "", "metadata": {}, "score": "70.685715"}
{"text": "Pronunciation quality is automatically evaluated for an utterance of speech based on one or more pronunciation scores .One type of pronunciation score is based on duration of acoustic units .Examples of acoustic units include phones and syllables .Method and apparatus for automatic text - independent grading of pronunciation for language instruction US 6055498 A .", "label": "", "metadata": {}, "score": "70.70476"}
{"text": "The acoustic model generator 18 generates an acoustic model of at least one word in the source text which is not in the source vocabulary .In one embodiment of the invention , this comparator may operate according to a set of rules that describe the manner in which letters in the source language should be rewritten when translated into the target language .", "label": "", "metadata": {}, "score": "70.71537"}
{"text": "This technique worked effectively because the predictive coefficients provided suitable parameters in each retrieval phase .Therefore , we concluded that the most suitable noise reduction method was Wiener filtering combined with differential acceleration .Figures 13 , 14 and 15 demonstrate the differences between speech and each retrieval signal that was used in combination with a conventional method .", "label": "", "metadata": {}, "score": "70.777695"}
{"text": "Section 4 contains conclusions about the proposed system .Materials and Methods .Image acquisition .In order to obtain online images for auto - recognition , a machine vision system was being developed .This system includes a CCD ( coupled - charge device ) monochrome camera ( WAT-902B , Watec Inc ) with a zoom lens , a frame grabber ( Meteor , Matrox Inc ) , and a personal computer ( Intel Pentium 4 processor 2.4 GHz ) .", "label": "", "metadata": {}, "score": "70.77823"}
{"text": "X ., is represented by . arg .X .Figure 4 shows the results from the spectral subtraction method when the filtering was repeated seven times with a setting frame width of 128 samples .The stationary noise is not removed completely .", "label": "", "metadata": {}, "score": "70.836914"}
{"text": "The termination criterion adds a single self - looping node containing a silence template of about 250 ms duration .Whenever the global minimum is found in this silence template , the best matching path is traced back to find the beginning and ending of the matched phrase .", "label": "", "metadata": {}, "score": "70.86304"}
{"text": "The separate channel 819 in another of these embodiments is a virtual channel that appears to the server process to be a separate channel , even though it is implemented using physical lines also shared by the client - to - server connection .", "label": "", "metadata": {}, "score": "70.866486"}
{"text": "The block of analysis frames is then shifted by one frame at a time to produce a vector of phoneme similarity values each centisecond ( each 100th of a second ) .As illustrated in FIG .4 , the phoneme similarity front end works in conjunction with a phone model database 12 that supplies the phoneme reference templates .", "label": "", "metadata": {}, "score": "70.93553"}
{"text": "The process proceeds inductively or iteratively in this fashion , each new utterance being combined with the previous ones such that the sum and sum of squares vectors ultimately represent the accumulated data from all of the utterances .Once all training utterances have been processed in this fashion the vector mean and vector variance are calculated .", "label": "", "metadata": {}, "score": "70.95447"}
{"text": "Figure 10 shows the difference between speech and body - conducted speech using a time - frequency representation .Figure 11 shows the difference between speech and the signal retrieves by the spectral subtraction method , and Figure 12 represents the difference between speech and the signal retrieves using Wiener filtering .", "label": "", "metadata": {}, "score": "70.96794"}
{"text": "Additionally , this method is little cost in calculation .Although the differential acceleration of body - conducted speech became a retrieval signal when stationary noise was present .Thus , it was possible to remove noise effectively using conventional noise reduction methods i.e. spectral subtraction or Wiener filtering .", "label": "", "metadata": {}, "score": "71.04126"}
{"text": "In general , a frame of acoustic features is a vector .Acoustic Segments : Time - segments of speech whose boundaries ( or durations ) are determined by a speech segmenter based on acoustic properties of the speech .In an embodiment of the invention , each acoustic segment produced by the speech segmenter is a \" phone .", "label": "", "metadata": {}, "score": "71.13449"}
{"text": "The acoustic scorer 503 computes the acoustic score 115 \u03c1 for an entire utterance as the average of the phone posterior score \u03c1 i of each phone i in the utterance , according to Equation ( 11 ) .IV.B. Phone Log - Likelihood Scores .", "label": "", "metadata": {}, "score": "71.15183"}
{"text": "A new method is also provided to improve handwriting recognition by proper segmentation of a handwriting sample .A gap feature is defined to distinguish a spatial distance between successive strokes greater than a threshold value , from a spatial distance between successive strokes less than the threshold value .", "label": "", "metadata": {}, "score": "71.15495"}
{"text": "The fast match estimates the closeness of a match between an acoustic fast match model of a word and a portion of the sequence of coded representations of the utterance .The \" detailed \" match examines only those words which the \" fast \" match determines to be good possibilities for extending the candidate word strings .", "label": "", "metadata": {}, "score": "71.15713"}
{"text": "It is a further object to provide a system and method which compares keyword matches with filler matches over exactly the same intervals of the input speech thus eliminating the above - noted problems associated with prior art devices .It is a further object of the present invention to provide separate parametric control of the operating point for each keyword thus providing greater accuracy and control of an automatic speech recognition system .", "label": "", "metadata": {}, "score": "71.18396"}
{"text": "A method according to claim 5 wherein said handwriting recognition system is a Hidden Markov Model based handwriting recognition system .An apparatus for performing handwriting recognition of a handwriting sample represented by a signal sequence , utilizing point oriented feature signals to hypothesize a segment of said handwriting sample giving rise to a point oriented hypothesis score , the improvement comprising : . means for generating one or more segmental feature signals of said segment of said handwriting sample giving rise to a segmental hypothesis score ; . means for augmenting said point oriented hypothesis score with a segmental matching score computed using said segmental hypothesis score ; and .", "label": "", "metadata": {}, "score": "71.20572"}
{"text": "SUMMARY OF THE INVENTION .An apparatus and method for speech recognition of sentences in accordance with a predetermined syntax is disclosed .The sentences of speech comprise utterances separated by short pauses where the utterances are either isolated words or connected words .", "label": "", "metadata": {}, "score": "71.243355"}
{"text": "This stage extracts a short list of word candidates that are then supplied to the next stage of the word hypothesizer 14 , the Target Congruence stage or TC stage 20 .The RC stage 18 has an RC word prototype database 22 that supplies compact word representations based on the novel compact speech representation ( regions of high phoneme similarity values ) of the invention .", "label": "", "metadata": {}, "score": "71.26163"}
{"text": "It has been found that acoustic unit duration scores are particularly important indicators of pronunciation quality when the student speaker 105 's speech is received through a channel that adds a large amount of noise or distortion , such as speech transmitted through a telephone connection .", "label": "", "metadata": {}, "score": "71.28951"}
{"text": "It operates to find the concatenation of a string of templates that most closely matches the incoming speech without making any distinction between keyword templates and filler templates .It then operates to report the occurrence of a keyword whenever the template for that keyword appears in the best matching template string .", "label": "", "metadata": {}, "score": "71.32756"}
{"text": "532 - 535 .Use of the word hypothesizer improved recognition performance ( compared to exhaustive search by the fine match alone ) for every test condition under multistyle training .The error reduction due to the hypothesizer was insignificant ( 2 % ) for 10 dB car noise , but was 25 % or more for each of the 4 other test conditions .", "label": "", "metadata": {}, "score": "71.4225"}
{"text": "1 , the speech recognition apparatus further comprises a match score processor 14 for generating a match score for each sound and each of one or more acoustic command models from the set of acoustic command models in acoustic command models store 12 .", "label": "", "metadata": {}, "score": "71.49396"}
{"text": "Accordingly , the acoustic unit duration scorer 211 computes the acoustic unit duration score 115 for an entire utterance as the average of the log - probability of each phone i 's speaker - normalized duration d ' i .A speaker - normalized phone duration is the phone duration multiplied by the rate of speech ( computed in element 206 ) for the speaker in question .", "label": "", "metadata": {}, "score": "71.49485"}
{"text": "The boundary constraints are applied when the recognition process is within boundary - range frames ( BRANGE ) from the end of the utterance .The constraints keep the window movement from wandering into regions in which a path can not be extended to the upper - right corner of the matrix .", "label": "", "metadata": {}, "score": "71.49909"}
{"text": "One explanation of why syllabic duration is a good indicator of pronunciation quality , even after normalization for rate of speech ( as will be described ) , is that language learners tend to impose the rhythm of their native language on the language they are learning .", "label": "", "metadata": {}, "score": "71.52078"}
{"text": "The first confidence score and the second confidence score for the recognition treshold are tuning parameters which may be adjusted by the user .The first and second confidence scores may be generated , for example , as follows .A training script comprising in - vocabulary command words represented by stored acoustic command models , and also comprising out - of - vocabulary words which are not represented by stored acoustic command models is uttered by one or more speakers .", "label": "", "metadata": {}, "score": "71.55071"}
{"text": "The invention of claim 1 , wherein said means for recognizing said connected words comprises recognition of connected digits .The invention of claim 1 , wherein said comparison of said selected isolated word templates and said frames of digital signals is done in accordance with a windowed dynamic programming algorithm ( DPA ) .", "label": "", "metadata": {}, "score": "71.56457"}
{"text": "In addition , it allows separate parametric control of the operating point for each keyword .Thus this method is a significant improvement over the prior art CSR techniques as for example shown in the above - noted references .Referring to FIG .", "label": "", "metadata": {}, "score": "71.635124"}
{"text": "If they do not , then the threshold is set to a value of 50 frames 630 ( which currently is fixed , but need not be ) .If the system \" thinks \" the speaker has more to say , it waits up to one second for the speaker to continue .", "label": "", "metadata": {}, "score": "71.65358"}
{"text": "Each keyword is represented by a keyword template which represents one or more target patterns and each target pattern comprises statistics of at least one spectrum selected from plural short term spectra generated according to a predetermined system for processing of the incoming audio .", "label": "", "metadata": {}, "score": "71.66452"}
{"text": "In another embodiment , acoustic units are \" syllables \" whose durations are determined based on the boundaries ( or durations ) of the acoustic segments produced by the speech segmenter .SUMMARY OF THE INVENTION .According to the invention , methods and systems are provided for assessing pronunciation quality of an arbitrary speech utterance based on one or more metrics on the utterance , including acoustic unit duration and a posterior - probability - based evaluation .", "label": "", "metadata": {}, "score": "71.77457"}
{"text": "1 , during computer operations .Further , the program instructions may be stored in the memory of another computer prior to use in the system of the present invention and transmitted over a LAN or a WAN , such as the Internet , when required by the user of the present invention .", "label": "", "metadata": {}, "score": "71.82587"}
{"text": "The word hypothesizer produced large reductions of computational complexity .On a 100 word task , alignment complexity was reduced by 93 % , with significant error rate reduction for clean and noisy test conditions .all Addendum Article Book Review Case Report Comment Commentary Communication Concept Paper Conference Report Correction Creative Data Descriptor Discussion Editorial Erratum Essay Interesting Images Letter New Book Received Obituary Opinion Project Report Reply Retraction Review Short Note Technical Note .", "label": "", "metadata": {}, "score": "71.866516"}
{"text": "Each acoustic command model represents one or more series of acoustic feature values representing an utterance of a command associated with the acoustic command model .The stored acoustic command models may be , for example , Markov models or other dynamic programming models .", "label": "", "metadata": {}, "score": "71.87861"}
{"text": "5,634,086 , entitled METHOD AND APPARATUS FOR VOICE - INTERACTIVE LANGUAGE INSTRUCTION ; and U.S. Pat .No .5,581,655 , entitled METHOD FOR RECOGNIZING SPEECH USING LINGUISTICALLY - MOTIVATED HIDDEN MARKOV MODELS ; which applications and patents ( including any and all attachments and appendices ) are incorporated herein by reference in their entirety for all purposes .", "label": "", "metadata": {}, "score": "71.88728"}
{"text": "Lapanja et al .[ 1 ] provided a complete overview of a reliability control module for an electro - mechanical dice gambling machine based on a machine vision technique .The chroma - key principle and the smoothing vectors were used to estimate the location of each die , and a template matching technique was proposed for fine - tuning and detecting the number of spots .", "label": "", "metadata": {}, "score": "71.89242"}
{"text": "8 .The times reported here were for nonoptimized software .For a 100 word lexicon the whole system requires only 7.3 % of the alignment time used by the fine match alone .For larger lexicons the alignment time reduction is yet larger , as shown in the right side of FIG .", "label": "", "metadata": {}, "score": "71.919266"}
{"text": "Also p.sub.9 ( k.vertline.T ) is the probability of the set of all complete sentences which begin with T and contain k additional words .In one embodiment this probability is estimated as # # EQU4 # # where q is an estimate of the unigram probability of the end - of - sentence marker .", "label": "", "metadata": {}, "score": "72.00464"}
{"text": "A speech recognition method as claimed in claim 18 , characterized in that unrecognizable - sound indicator comprises one or more question marks .A speech recognition method as claimed in claim 12 , characterized in that : . each sound comprises a vocal sound ; and each command model comprises at least one word .", "label": "", "metadata": {}, "score": "72.04474"}
{"text": "Each command associated with an acoustic command model preferably comprises at least one word .At the beginning of a speech recognition session , the recognition threshold may be initialized at either the first confidence score or the second confidence score .", "label": "", "metadata": {}, "score": "72.108536"}
{"text": "A method for performing handwriting recognition of a handwriting sample comprising a string of interconnected symbols represented by a signal sequence , comprising the steps of : . utilizing one or more point oriented feature signals to hypothesize one or more segmentations of said string of interconnected symbols , each of said hypothesized segmentations having associated therewith a point oriented hypothesis score ; . generating one or more segmental feature signals of each of said hypothesized segmentations giving rise to a segmental hypothesis score for each of said hypothesized segmentations ; . respectively adding to said point oriented hypothesis score of each of said hypothesized segmentations a segmental matching score computed using said segmental hypothesis score of each of said hypothesized segmentations , resulting in an augmented hypothesis score for each of said hypothesized segments ; and .", "label": "", "metadata": {}, "score": "72.18555"}
{"text": "Each acoustic match score comprises an estimate of the closeness of a match between the acoustic model of the speech hypothesis and the sequence of coded representations of the utterance .When the acoustic models are Markov models , acoustic match scores may be obtained , for example , by the forward pass of the Forward - Backward Algorithm .", "label": "", "metadata": {}, "score": "72.18628"}
{"text": "1 , the speech recognition system comprises a hypothesis score generator 28 for generating a hypothesis score for each hypothesis .Each hypothesis score comprises a combination of the acoustic match score and the translation match score for the hypothesis .The speech recognition system further comprises a storage device 30 for storing a subset of one or more speech hypotheses , from the set of speech hypotheses , having the best hypothesis scores .", "label": "", "metadata": {}, "score": "72.21805"}
{"text": "The duration probability distribution is represented as a probability mass function .The probability mass function is smoothed , and a probability floor is introduced , in order to maintain robustness of the model , given that only finite quantities of training speech are available .", "label": "", "metadata": {}, "score": "72.221436"}
{"text": "In a user interactive computer controlled display system with speech command input recognition comprising , a method for interpreting speech queries to locate commands comprising : . predetermining a plurality of speech commands each associated with a corresponding plurality of system actions , . responsive to a speech command , carrying out the system action corresponding to the command , . storing for each of said plurality of commands , an associated set of speech terms , each term having relevance to its associated command , . responsive to a speech query , determining the probability of speech terms from said set in said query by applying a weight factor for a firm recognition of a speech term at least twice the weight of an infirm recognition of the term , and . responsive to said probability determination , prompting the user with a displayed sequence of commands sorted based upon said probability of speech terms associated with said commands .", "label": "", "metadata": {}, "score": "72.225174"}
{"text": "Variable frame rate encoding is used to limit the number of frames to be compared and in the preferred embodiment the connected word recognition comprises connected digit recognition .BRIEF DESCRIPTION OF THE DRAWINGS .Objects , features and advantages of the present invention will become more fully apparent from the following detailed description of the preferred embodiment , the appended claims and the accompanying drawings , in which : .", "label": "", "metadata": {}, "score": "72.251434"}
{"text": "presenting said grade to said student speaker .The method according to claim 24 wherein said step of mapping said posterior - based evaluation score to a grade comprises : . collecting a set of training speech samples from a plurality of language students of various proficiency levels ; . collecting a set of human evaluation grades for each of said training samples from human expert listeners listening to said samples ; and .", "label": "", "metadata": {}, "score": "72.261734"}
{"text": "The target rate constraint ( the desired number of targets per second ) may be set to a level that achieves the desired target rate .After adjusting the target rate a statistical analyzer module 36 estimates the global statistics ( the average match rate and the average word duration ) and these statistics along with the list of targets at the selected rate are then stored as the TC word prototype database 24 .", "label": "", "metadata": {}, "score": "72.26956"}
{"text": "The global score of each word in the short list is then defined as : .Evaluation Task .Recognition word accuracy was evaluated in isolated word speaker - independent mode on a speech database of 100 English proper names .Testing was performed in several noise conditions : clean test speech and speech with additive noise at 20 dB or 10 dB signal - to - noise ratio .", "label": "", "metadata": {}, "score": "72.32631"}
{"text": "The method according to claim 6 wherein said mapping function is obtained by non - linear regression implemented with a neural net which allows arbitrary mappings from machine scores to human expert grades .The method according to claim 4 wherein the step of mapping comprises using a decision tree or class probability tree whose parameters were established using training duration scores .", "label": "", "metadata": {}, "score": "72.343094"}
{"text": "The channel filters are implemented in a conventional manner using Reticon Model Numbers R5604 and R5606 switched - capacitor devices .FIG .3 gives the clock input frequency , center frequency and 3 db bandwidth of the 19 channels of the BPF circuits 208 and 210 .", "label": "", "metadata": {}, "score": "72.40392"}
{"text": "In that case the window will be advanced only one cell 1035 .See FIG .9c .If the window minimum is below the center ( first cell 910 in FIG .9d ) , generally it is desirable to leave the window at the same level , i.e. , do n't advance 912 and 1036 .", "label": "", "metadata": {}, "score": "72.40428"}
{"text": "Diff .Acc . 'becomes a clear signal in this experiment because it does not produce a stationary noise from differential acceleration .And ' Max ' is worked on the recognition experiment correctly , so it is proven by Table 10 that the effectiveness of the combination method using retrieval method of signal and its decoding algorithm .", "label": "", "metadata": {}, "score": "72.470604"}
{"text": "Similarly template \" 5 \" uses the information indexed by frame i'-1 .The scores of all partial phrases ending at frame k re compared and the set of five values listed above will be saved ( indexed by k ) for the lowest scoring partial digit phrase .", "label": "", "metadata": {}, "score": "72.47199"}
{"text": "The top constraint variable 812 ( TOPLIM ) is incremented one frame every other utterance frame and describes a line with a slope of one - half .If the top of the window touches this constraint 1044 its movement alternates between \" do n't advance \" and \" advance by one \" 1046 .", "label": "", "metadata": {}, "score": "72.49642"}
{"text": "A word recognition processor for processing an input speech utterance in a speech recognition system , comprising : . a phoneme similarity module receptive of said input speech utterance for producing phone similarity data indicative of the correlation between said input speech utterance and predetermined phone model speech data ; . a high similarity module coupled to said phoneme similarity module for identifying those regions of the phone similarity data that exceed a predetermined threshold ; . a region count stage having a first word prototype database for storing similarity region count data for a plurality of predetermined words ; . said region count stage coupled to said high similarity module and generating a first list of word candidates selected from said first word prototype database based on similarity regions ; . a target congruence stage having a second word prototype database for storing word prototype data corresponding to a said plurality of predetermined words ; . said target congruence stage being receptive of said first list of word candidates and being coupled to said high similarity module for generating a second list of at least one word candidate , selected from said first list based on similarity regions .", "label": "", "metadata": {}, "score": "72.53525"}
{"text": "FIG .3 is a block diagram of a portion of an example of a speech recognition system according to the invention .In this embodiment of the invention , the system comprises a source vocabulary store 33 for storing the source language vocabulary .", "label": "", "metadata": {}, "score": "72.62587"}
{"text": "The second confidence score may be , for example , the worst match score which is better than the match scores of , for example , 99 to 100 % of the misrecognized words in the training script .The recognition signal which is output by the recognition threshold comparator and output 16 may comprise a command signal for calling a program associated with the command .", "label": "", "metadata": {}, "score": "72.63983"}
{"text": "The delay variable controls how many frames the recognition algorithm is delayed behind the input .Since the recognition algorithm takes special steps near the end of an utterance , it must be held back until the end is known .While processing an utterance ( non - speech frame count equals zero ) , a sequence of silence frames may occur because the end has come .", "label": "", "metadata": {}, "score": "72.69597"}
{"text": "One example of the acoustic processor 10 of FIG .3 is shown in FIG .6 .The acoustic processor comprises a microphone 24 for generating an analog electrical signal corresponding to the utterance .The analog electrical signal from microphone 24 is converted to a digital electrical signal by analog to digital converter 26 .", "label": "", "metadata": {}, "score": "72.702866"}
{"text": "The task of the conditional translation match score generator is to compute a conditional translation score P(S.vertline .T ) of a sequence S of source given a sequence T of target words .In one embodiment of a conditional translation match score generator , the probability of S given T is computed as # # EQU5 # # .", "label": "", "metadata": {}, "score": "72.8886"}
{"text": "The details of the actual weighting process and algorithm will be subsequently described in greater detail .FIG .4 shows a display screen with visual feedback display panel 70 .Window 72 may also include commands which were an exact match for terms in the speech query .", "label": "", "metadata": {}, "score": "72.93801"}
{"text": "32 , No . 7 , Dec. 1989 , pp .320 - 321 .Brown , P. F. et al . \"Method and Apparatus For Translating A Series of Words From One Language to Another \" .U.S. patent application Ser .", "label": "", "metadata": {}, "score": "73.00531"}
{"text": "3 that as set forth hereinabove , the spoken query ( which is not the case in FIG .3 ) may include terms or words which are an exact match for on the listed commands .In such a case , in the sorting of displayed commands , any exact match of a speech query term with any command doubles the weight accorded to that command in the sorting and if the command were not previously displayed , it will now be displayed .", "label": "", "metadata": {}, "score": "73.0117"}
{"text": "Referring to FIG .1 , the speech recognition system comprises a display 10 for displaying a source text .The source text comprises one or more words in a source language , such as French .The source text may be provided to the display by , for example , a source text input device 12 such as a computer system .", "label": "", "metadata": {}, "score": "73.01535"}
{"text": "The following equations summarize use of speaker - normalized syllabic durations in the preferred syllabic - duration - scoring embodiment : # # EQU3 # # II.C. Syllabic Duration Using Specific Syllables .In other embodiments of the present invention , syllabic duration of specific syllables are used for scoring in a manner analogous to that described above for all syllables .", "label": "", "metadata": {}, "score": "73.01653"}
{"text": "The target congruence hypothesizer stage is coupled to the high similarity module for generating a second list of at least one word candidate that is selected from the first list based on similarity regions .A word recognizer stage , having a word template database for storing word template data corresponding to a plurality of predetermined words , receives the second list of word candidates from the target congruence hypothesizer stage .", "label": "", "metadata": {}, "score": "73.028625"}
{"text": "In post decision processing , concatenatio techniques based on a likelihood ratio for rejecting false alarms are also disclosed .Post decision processing can include also a prosodic test to enhance the effectiveness of the recognition apparatus .Thus the prior art as indicated is replate with many systems for utilizing both keyword templates and filler templates in automatic speech recognition systems .", "label": "", "metadata": {}, "score": "73.05941"}
{"text": "Figure 3 shows the differential acceleration signal estimated from Figure 2 .Figure 3 becomes a emphasized signal however the stationary noise was included .For this reason , differential acceleration involving a retrieval signal introduces conventional noise reduction ( Gong , 1995 ) .", "label": "", "metadata": {}, "score": "73.09601"}
{"text": "6 for the different stages and combinations in the system .The output of the hypothesizer ( list of top 5 word candidates ) shows no critical deterioration ( 99.6 % accuracy ) even when compared to original fine match alone ( 99.3 % accuracy for top 5 candidates ) .", "label": "", "metadata": {}, "score": "73.12916"}
{"text": "Automatic Determination of Pronunciation of Words From Their Spellings . \"IBM Technical Disclosure Bulletin , Volume 32 , No .10B , March 1990 , pages 19 - 23 ; and J. M. Lucassen , et al . \"An Information Theoretic Approach To The Automatic Determination of Phonemic Baseforms . \" Proceedings of the 1984 IEEE International Conference on Acoustic and Signal Processing , Vol . 3 , pages 42.5.1 - 42.5.4 , March 1984 . )", "label": "", "metadata": {}, "score": "73.150215"}
{"text": "Target Congruence Modeling .In the presently preferred embodiment targets are generalized HS regions described by 5 parameters : . phoneme symbol ; . target weight ( percentage occurrence in training data ) ; . average peak height ( phoneme similarity value ) ; . average left frame location ; . average right frame location .", "label": "", "metadata": {}, "score": "73.19441"}
{"text": "An apparatus for recognizing sentences of speech , said sentences comprised of utterances separated by pauses and including both isolated words and connected words taken from a predefined finite size vocabulary , said apparatus comprising : . means including a bandpass filter bank for forming frames of digital signals representative of said sentences of speech ; and . microprocessor means for recognizing said sentences from said frames of digital signals in accordance with a predefined syntax ; wherein said means for recognizing said sentences further comprises ; . memory means for storing said predefined vocabulary as isolated word templates and partial phrase connected word templates ; . means for detecting the endpoints of said utterances and for generating an output representative of such endpoint detection ; . isolated word recognizing means responsive to the output of said endpoint detection means for recognizing said isolated words by comparing selected ones of said isolated word templates with said frames of digital signals ; . connected word recognizing means responsive to the output of said endpoint detection means for recognizing said connected words by comparing selected ones of said partial phrase connected word templates with said frames of digital signals ; and .", "label": "", "metadata": {}, "score": "73.226585"}
{"text": "-Edit ( 1,2 ) .Score : Same as \" undo \" for the same reasons .Now with reference to FIGS . 7 , 8 and 9 , we will describe a process implemented by the present invention in conjunction with the flowcharts of these figures in which the weighting algorithms described above may be applied .", "label": "", "metadata": {}, "score": "73.23784"}
{"text": "The Viterbi algorithm optimizes modelling of the observed state sequence by calculating the maximum probability of being in a particular state at any point in time and calculating the maximum probability of a transition between preceding and succeeding states .However , since the accumulated score computed by the method of the present invention incorporates not only the transition probability from the preceding to succeeding states , but also information reflected in the letter duration regarding how the previous state was reached , the optimality is no longer guaranteed .", "label": "", "metadata": {}, "score": "73.397125"}
{"text": "Where the spatial distance is less than the threshold value , the alternative hypothesis scores are biased towards two discontinuous strokes , by adding a penalty to those alternative hypothesis scores indicating that the two successive strokes are continuous .BRIEF DESCRIPTION OF THE DRAWINGS .", "label": "", "metadata": {}, "score": "73.45503"}
{"text": "This study develops an iterative calculation that is suitable for dice identification , and is organized as follows : an image acquisition system , an image processing method , the proposed modified unsupervised grey clustering algorithm , and an auto - recognition system for dice are presented in Section 2 .", "label": "", "metadata": {}, "score": "73.48016"}
{"text": "The twenty - first dimension of the feature vector F'(t ) , representing the total amplitude or total power , is discarded .Each component i of the normalized feature vector X(t ) at time t may , for example , be given by the equation .", "label": "", "metadata": {}, "score": "73.50151"}
{"text": "8 helps to illustrate the algorithm .A template is placed on the y - axis 802 and the input utterance is placed on the x - axis 804 to form a DPA matrix 800 .Every cell in the matrix corresponds to a one - to - one mapping of a template frame with an utterance frame .", "label": "", "metadata": {}, "score": "73.52498"}
{"text": "The value of the silence end threshold is a tuning parameter which can be adjusted by the user .A value of 10 -25 has been found to provide good results .The silence is considered to have ended at the first time t end at which the ratio of Equation 14 is less than the associated tuning parameter .", "label": "", "metadata": {}, "score": "73.5508"}
{"text": "The method of claim 6 further including the step of enabling the user to speak a command in said sorted sequence of commands to thereby initiate the system action associated with the command .The method of claim 6 further including the step of adding terms to previous speech terms wherein said probability determination will redetermine the probability to include such added terms .", "label": "", "metadata": {}, "score": "73.55529"}
{"text": "As a next step of the proposed method , we applied the noise reduction methods to body - conducted speech in a noisy environment .From the experimental results , the Wiener filtering method proved to be a suitable noise reduction method for differential acceleration as evidenced by comparing spectrograms with normal speech and each retrieval signal in a noisy environment .", "label": "", "metadata": {}, "score": "73.626396"}
{"text": "Referring now to FIG .6 , if the beginning of the sentence has not yet been found ( SPCHBG 602 still false ) , the last ten amplitude measures from 522 are summed and compared with a speech threshold ( SPTHRS ) 604 .", "label": "", "metadata": {}, "score": "73.65909"}
{"text": "9 is a flowchart of the steps involved in a typical run of the program set up in FIGS . 8 and 9 .DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT .A central processing unit ( CPU ) 10 , such as any PC microprocessor in a PC available from IBM or Dell Corp. , is provided and interconnected to various other components by system bus 12 .", "label": "", "metadata": {}, "score": "73.69997"}
{"text": "And , the signal retrieval using differential acceleration is applied to body - conducted speech in noisy environments .Furthermore , we will also construct the microphone using body - conducted speech and differential acceleration for noise environment .References . 7 - Z. Liu , Z. Zhang , A. Acero , J. Droppo , X. Huang , 2004 Direct Filtering for Air- and Bone - Conductive Microphones , in proc .", "label": "", "metadata": {}, "score": "73.747375"}
{"text": "Put in another way , the path describes an \" alignment \" of the sequence of frames 111 with a corresponding sequence of states of the HMMs .In FIG .3 , the HMM speech recognizer 203 is operated not merely for its ordinary purpose of speech recognition , but also for time - segmenting speech into component phones .", "label": "", "metadata": {}, "score": "73.80299"}
{"text": "3 illustrates the misrecognition of a sample word \" line \" by a precursor handwriting recognition system that does not incorporate the present invention .FIG .4 illustrates the results of a handwriting recognition system according to the present invention of the same sample word shown in FIG .", "label": "", "metadata": {}, "score": "73.83623"}
{"text": "8 is a series of graphs illustrating alignment time by stage ( left ) and alignment time ratio versus lexicon size ( right ) .Alignment time is given for one test word aligned to 100 reference words .Corresponding alignment time for the fine match is 3.4 seconds .", "label": "", "metadata": {}, "score": "73.83797"}
{"text": "The method according to claim 26 wherein said spoken sequence of words is unknown , and the path computing step is performed using a computerized speech recognition system that determines said spoken sequence of words .The method according to claim 21 wherein segments in context with silence are excluded from said student speech sample and from training data used to train said speech models .", "label": "", "metadata": {}, "score": "73.883606"}
{"text": "After each utterance frame , the best path scores for the isolated word templates are compared ( PRUNE ) , and those templates with a path score greater than the overall best path score by a fixed amount ( TPRUNE ) are marked inactive 724 .", "label": "", "metadata": {}, "score": "73.88434"}
{"text": "During an utterance the counter will generally have a zero value 618 , but at the end of an utterance its value will build up until it exceeds the end of the utterance frame count threshold ( ENDUTT ) 620 .When this happens the utterance flag is turned off ( UTTBG ) , the length of the utterance is recorded , and the non - speech frame counter ( NSPCNT ) is initialized to the utterance frame count threshold ( ENDUTT ) 622 .", "label": "", "metadata": {}, "score": "73.95667"}
{"text": "1 is a block diagram of an example of a speech recognition apparatus according to the invention .FIG .2 schematically shows an example of an acoustic command model .FIG .3 schematically shows an example of an acoustic silence model .", "label": "", "metadata": {}, "score": "74.03993"}
{"text": "A hypothesis score for each hypothesis comprises a combination of the acoustic match score and the translation match score .At least one word of one or more speech hypot This invention was made with Government support under Contract Number N00014 - 91-C-0135 awarded by the office of Naval Research .", "label": "", "metadata": {}, "score": "74.04086"}
{"text": "5 , a speech segmenter 203 accepts the sequence of acoustic features 111 and produces from them a time - segmentation 205 specifying acoustic segments .An acoustic scorer 503 accepts the acoustic segmentation 205 and also the sequence of acoustic features 111 .", "label": "", "metadata": {}, "score": "74.05553"}
{"text": "The method of claim 22 wherein said parameters include a representation of the phone similarity peak location , peak height and the left and right frame locations .The method of claim 16 further comprising the step of : . representing an instance of a given spoken word or phrase by the number of high phoneme similarity regions found for each of a plurality of phoneme identifiers .", "label": "", "metadata": {}, "score": "74.1118"}
{"text": "The normalization constants . lambda . sub.5 and . lambda . sub.6 are chosen so that the updated quantities are conditional probabilities .( See , U.S. patent application Ser .No .736,278 , filed on Jul. 25 , 1991 , by Peter F. Brown et al entitled \" Method and System For Natural Language Translation . \" )", "label": "", "metadata": {}, "score": "74.11597"}
{"text": "2 is a diagram showing the integration of multiple stages of word hypothesization with a fine match procedure ; .FIG .3 is a series of graphs showing the output of the region picking procedure whereby similarity values are converted into high similarity regions ; .", "label": "", "metadata": {}, "score": "74.17412"}
{"text": "For this purpose , the command associated with the acoustic model having the best match score may be selected as the recognition result .A serious problem with such systems , however , is that inadvertent sounds such as coughs , sighs , or spoken words not intended for recognition can be misrecognized as valid commands .", "label": "", "metadata": {}, "score": "74.23273"}
{"text": "On the other hand , the optimal clustering weighting is larger while the dice are closer together in a bowl .Thus , the clustering weighting value is the evaluated parameter of the recognition accuracy for determining the location and the score of dice .", "label": "", "metadata": {}, "score": "74.2881"}
{"text": "Above referenced copending application , \" SPEECH COMMAND INPUT RECOGNITION SYSTEM FOR INTERACTIVE COMPUTER DISPLAY WITH MEANS FOR CONCURRENT AND MODELESS DISTINGUISHING BETWEEN SPEECH COMMANDS AND SPEECH QUERIES FOR LOCATING COMMANDS \" , Scott A. Morgan et al .( Attorney Docket No .", "label": "", "metadata": {}, "score": "74.30578"}
{"text": "This mechanism can be easily modified to incorporate segmental matching scores at the stroke level as well .However , since individual strokes have mostly very simple shape characteristics , little shape information is obtained by augmenting the scores at this level .", "label": "", "metadata": {}, "score": "74.39914"}
{"text": "According to the present invention , the training speech are not required to include the sequence of spoken words found in the input speech 107 .These training speech are not even required to include individual words from the sequence of spoken words found in the input speech 107 .", "label": "", "metadata": {}, "score": "74.40527"}
{"text": "The human being on the other hand correctly classifies highly distorted or atypical speech , evidently using models of other speech sounds to tell whether an unknown that is far from the target sound is actually moved closer to other sounds .", "label": "", "metadata": {}, "score": "74.412766"}
{"text": "in the logarithmic domain , where F ' .The normalized twenty dimension feature vector X(t ) may be further processed by an adaptive labeler 60 to adapt to variations in pronunciation of speech sounds .An adapted twenty dimension feature vector X'(t ) is generated by subtracting a twenty dimension adaptation vector A(t ) from the twenty dimension feature vector X(t ) provided to the input of the adaptive labeler 60 .", "label": "", "metadata": {}, "score": "74.43005"}
{"text": "Scoring Pronunciation Using Acoustic Unit Durations .FIG .2 is a block diagram of a pronunciation scorer 113 of FIG .1 according to embodiments of the present invention that produce a pronunciation score 115 based on duration of acoustic units .", "label": "", "metadata": {}, "score": "74.4722"}
{"text": "A computer program having program code included on a computer readable medium for interpreting speech queries to locate commands in an interactive computer controlled display system with speech command input comprising : . means for predetermining a plurality of speech commands each associated with a corresponding plurality of system actions , . means responsive to a speech command for carrying out the system action corresponding to the command , . means for storing for each of said plurality of commands , an associated set of speech terms , each term having relevance to its associated command , . means responsive to a speech query for determining the probability of speech terms from said set in said query by applying a weight factor for a firm recognition of a speech term at least twice the weight of an infirm recognition of the term , and . means responsive to said probability determining means for prompting the user with a displayed sequence of commands sorted based upon said probability of speech terms associated with said commands .", "label": "", "metadata": {}, "score": "74.53145"}
{"text": "IV .Scoring Pronunciation Using Acoustic Features .FIG .5 is a block diagram of a system 113 for computing an acoustic score 115 based directly on the acoustic features 111 themselves , rather than on acoustic unit durations , according to embodiments of the present invention .", "label": "", "metadata": {}, "score": "74.62492"}
{"text": "The method of claim 16 further comprising performing a fine match upon said second list of word candidates to select a single recognized word from said second list .The method of claim 16 wherein said region count procedure produces a first score corresponding to the degree of fit between the input utterance and each of the first list of word candidates .", "label": "", "metadata": {}, "score": "74.82617"}
{"text": "Syntax control includes selecting the isolated word and connected word templates to be compared after each utterance and includes combining the recognized isolated words and connected words into sentences in accordance with predefined syntax after the end of the sentence has been detected .", "label": "", "metadata": {}, "score": "74.94527"}
{"text": "4 .It is divided into two parts , called a task syntax 30 and a rejection syntax 31 .These correpond to the upper and lower halves of the template - matcher shown in FIG .3 .Separate top scores , bottom scores , and global minimum scores are maintained for the two syntaxes .", "label": "", "metadata": {}, "score": "74.94691"}
{"text": "FIG .13 is a more detailed block diagram of the sentence scoring function of the syntax control portion of the IW / CD algorithm of FIG .4 . FIG .14 is a block diagram of a preferred embodiment Voice Phone embodying the IW / CD apparatus of the present invention .", "label": "", "metadata": {}, "score": "74.950455"}
{"text": "The average of iteration number is 21 after testing by ARDS software .Table 2 presents the classification results of three samples .Even for low contrast images , acceptable results can still be obtained ( Figure 11 ) .PI represents the sum of average distances between clustering data and the clustering center .", "label": "", "metadata": {}, "score": "74.96503"}
{"text": "At this point or if the decision from step 94 was No , i.e. , no recognizable command , then , the speech is displayed as a speech query , step 95 .Up to this point , the process is substantially the same as that covered in the above referenced copending patent applications , ( Attorney Reference Nos .", "label": "", "metadata": {}, "score": "75.02373"}
{"text": "The acoustic scorer 503 computes , for each frame y t within a phone i of phone type q i , a frame - based posterior probability P(q i . linevert split.y t ) of phone i 's type given the observed acoustic feature frame y t : # # EQU4 # # wherein p(y t .", "label": "", "metadata": {}, "score": "75.033905"}
{"text": "MLP 's are well known in the art , and are described for example in Nelson Morgan and Herve Bourlard , \" Continuous Speech Recognition : An introduction to the Hybrid HMM - Connectionist Approach , \" IEEE Signal Processing Magazine , Vol .", "label": "", "metadata": {}, "score": "75.0923"}
{"text": "Cross spectrum method .The cross spectrum method ( Morise et al . , 2007 ) was introduced using the auto spectrum of body - conducted speech , .H .B .C .S . , and the cross spectrum between normal speech and body - conducted speech , .", "label": "", "metadata": {}, "score": "75.12273"}
{"text": "Keyword match scores are provided by a standard CSR template matcher .The summation term on the right - hand side of Equation 2 is computed using a modified CSR template - matching algorithm that performs a computation called \" summing of probabilities \" .", "label": "", "metadata": {}, "score": "75.12872"}
{"text": "First , HS regions are extracted from the phoneme similarity time series for a number of training speakers .The training data may be generated based on speech from a plurality of different speakers or it may be based on multiple utterances of the same training words by a single speaker .", "label": "", "metadata": {}, "score": "75.189705"}
{"text": "Alternatively , the acoustic match score may be combined with other match scores , such as additional acoustic match scores and language model match scores .The word or words associated with the acoustic model or models having the best combined match score may be selected as the recognition result .", "label": "", "metadata": {}, "score": "75.19616"}
{"text": "Then , all relevant commands are displayed in an order sorted by weighting as previously described , step 98 to give the user the opportunity to select one of the relevant commands .Decision step 99 , a determination is made as to whether the user has spoken one of the relevant commands .", "label": "", "metadata": {}, "score": "75.23725"}
{"text": "a combined score generator which uses the language match score and the conditional translation match score to produce an estimate of a joint probability P(S , T.cndot . )The combined match score generator will now be described .In the prior art , language match scores and conditional translation match scores are combined only when the words of S are generated from the words T and no other words .", "label": "", "metadata": {}, "score": "75.27634"}
{"text": "In the specific embodiment , the output distribution of each state of within each phone type q 's HMM is a weighted mixture of Gaussian distributions .Good results have been achieved using approximately 100 Gaussian distributions with diagonal covariances ( i.e. , off - diagonal entries constrained to zero in the covariance matrix ) .", "label": "", "metadata": {}, "score": "75.33171"}
{"text": "A Study on the Recognition of the Korean Monothongs Using Artificial Neural Models .Proceedings of the 5th Jerusalem Conference on Information Technology , pp .364 371 , Oct. 22 25 , 1990 .Lines , B.M. A Model for Assessing the Ability of an Office Local Area Network , Employing the Technical Office Protocol ( TOP ) to Carry Interactive Speech While Heavily Loaded with Data Traffic .", "label": "", "metadata": {}, "score": "75.37784"}
{"text": "In traditional methods , manual detection with human eyes is used to recognize dice , thus we propose a methodology which can estimate the score of dice in dice games accurately and effectively .Our system has performed at 100 % detection capability .", "label": "", "metadata": {}, "score": "75.512405"}
{"text": "A method of handwriting recognition is provided that combines the efficiency of a point oriented system and the shape information of a segment oriented system in an HMM based handwriting recognition system .The partial segmentation hypotheses obtained using the point oriented features in a conventional Viterbi search are augmented with scores based on segmental shape measurements made on the hypothesized segments .", "label": "", "metadata": {}, "score": "75.52261"}
{"text": "2 .Then , there is set up a process for displaying relevant commands so that the user may choose a relevant command by speaking to set off the command action , step 86 .This has been previously described with respect to FIG .", "label": "", "metadata": {}, "score": "75.52629"}
{"text": "8 , a remote client processor 803 runs a client process .The client process executes software instructions that presents a prompt to a student 105 .In response , the student 105 speaks into a microphone 805 .As will be further discussed , the system 801 contains a pronunciation evaluator ( 101 , as shown in FIG .", "label": "", "metadata": {}, "score": "75.55043"}
{"text": "5 , the HS region computation module 16 is used to convert the similarity time series from the speech database into a list of HS regions .The alignment module 30 operates on this list of HS regions to eliminate unreliable regions by alignment across speakers .", "label": "", "metadata": {}, "score": "75.55722"}
{"text": "No .5,671,328 , U.S. Pat .No .5,133,111 , U.S. Pat .No .5,222,146 , U.S. Pat .No .5,664,061 , U.S. Pat .No .5,553,121 and U.S. Pat .No . 5,157,384 .The speech input to the system could be actual commands , which the system will recognize , and/or speech terminology , which the user addresses to the computer in a query so that the computer may propose appropriate relevant commands through feedback .", "label": "", "metadata": {}, "score": "75.57121"}
{"text": "The word recognition processor of claim 1 wherein said phoneme similarity module includes a phone model database for storing phone model speech data corresponding to a plurality of phonemes that comprise said predetermined phone model speech data .The word recognition processor of claim 1 wherein said region count stage produces a first score corresponding to the degree of fit between the input utterance and each of the first list of word candidates .", "label": "", "metadata": {}, "score": "75.60942"}
{"text": "FIG .6 is the display screen view of FIG .5 after even more additional terms have been added to the speech query ; .FIGS . 7 and 8 combine into a flowchart of the basic elements of the system and program in a computer controlled display system for prompting with a weighted list of relevant commands in response to speech query input in accordance with the present invention ; and .", "label": "", "metadata": {}, "score": "75.63025"}
{"text": "4 through 6 , we will provide an illustrative example of how the present invention may be used to provide for the searching and weighting of relevant commands in accordance with the present invention .When the screen image panels are described , it will be understood that these may be rendered by storing image and text creation programs , such as those in any conventional window operating system in the RAM 14 of the system of FIG .", "label": "", "metadata": {}, "score": "75.63659"}
{"text": "A speech recognition method as claimed in claim 35 , characterized in that the means for measuring the value of at least one feature of in utterance comprises a microphone .Description .BACKGROUND OF THE INVENTION .The invention relates to automatic speech recognition .", "label": "", "metadata": {}, "score": "75.65825"}
{"text": "2 is a block diagram of a portion of another example of a speech recognition system according to the invention .FIG .3 is a block diagram of a portion of another example of a speech recognition system according to the invention .", "label": "", "metadata": {}, "score": "75.66307"}
{"text": "FIG .2 is a block diagram of a portion of the system of FIG .1 showing a generalized expanded view of the system components involved in the implementation ; .FIG .3 is a generalized view of a portion of a relevance table showing the commands relevant to the speech terms in an illustrative example described in the specification ; .", "label": "", "metadata": {}, "score": "75.6724"}
{"text": "However , the ARDS can easily separate abreast dice as illustrated in Figure 8 .Furthermore , the recognizing ability of ARDS is independent of the image size of the dice .The locations of dice in Figure 9(a ) and 9(b ) are the same , but the acquired images are different in the size of distances between the dices for the different position of the CCD camera .", "label": "", "metadata": {}, "score": "75.692566"}
{"text": "To compute the expectation the conditional probability P(h.linevert split .M 1 , . . ., M n ) is needed .The number of bins to use in the quantization is determined by the amount of available training data .", "label": "", "metadata": {}, "score": "75.69394"}
{"text": "The method according to claim 1 wherein said exemplary acoustic unit duration model is established using duration - training speech data from at least one exemplary speaker , said duration - training data not necessarily including said sequence of spoken words .", "label": "", "metadata": {}, "score": "75.71126"}
{"text": "The second data structure ( TEMNOD ) contains template - node membership information .For each template , t , a bit vector records in what nodes template t has membership .The algorithm ( NEXTND ) 736 uses the node - to - node membership matrix to compute for each utterance in the sentence a node - extension vector .", "label": "", "metadata": {}, "score": "75.72123"}
{"text": "Syntax control includes selecting the isolated word and connected word templates to be compared after each utterance and includes combining the recognized isolated words and connected words into sentences in accordance with the predefined syntax after the end of the sentence has been detected .", "label": "", "metadata": {}, "score": "75.76276"}
{"text": "Essentially , as indicated , this method is fully described in U.S. patent application entitled \" Keyword Recognition System and Method Using Template Concatenation Model \" filed on Sept. 28 , 1984 as Ser .No .655,958 , as indicated above .", "label": "", "metadata": {}, "score": "75.76883"}
{"text": "This gives added weight to those commands that are in the list because one or more of the exact words in the command were in the query as well .As more context becomes known through user additions to the query , the context of the query matches becomes higher and , hence , the list ( of relevant commands ) may dynamically change to reflect this confidence level .", "label": "", "metadata": {}, "score": "75.814255"}
{"text": "Alternatively , the command signal may be an application program interface call .The recognition threshold comparator and output 16 may comprise a display , such as a cathode ray tube , a liquid crystal display , or a printer .The recognition threshold comparator and output 16 may display one or more words corresponding to the command model having the best match score for a current sound if the best match score for the current sound is better than the recognition threshold score for the current sound .", "label": "", "metadata": {}, "score": "75.82"}
{"text": "The utterance comprises , for example , a series of one or more words in a target language , such as English , different from the source language .A speech hypothesis generator 16 generates a set of one or more speech hypotheses .", "label": "", "metadata": {}, "score": "75.83353"}
{"text": "GLOSSARY .In this art , the same terms are often used in different contexts with very different meanings .For purposes of clarity , in this specification , the following definitions will apply unless the context demands otherwise : .Grade : An assessment of the pronunciation quality of a speaker or a speech utterance on a grade scale such as used by human expert listeners .", "label": "", "metadata": {}, "score": "75.87918"}
{"text": "The system according to claim 37 wherein said server process receives said speech sample over a speech channel that is separate from a communication channel through which said server process and said client process communicate .The system according to claim 37 wherein said client process and said server process are located on two separate computer processors and communicate via a network .", "label": "", "metadata": {}, "score": "75.89197"}
{"text": "A speech recognition apparatus as claimed in claim 1 , characterized in that the acoustic processor comprises a microphone .A speech recognition apparatus as claimed in claim 1 , characterized in that : . each sound comprises a vocal sound ; and .", "label": "", "metadata": {}, "score": "75.922134"}
{"text": "a duration scorer configured to compare said sample acoustic unit durations to said model of exemplary acoustic unit duration and compute a duration score indicative of similarity between said sample acoustic unit durations and acoustic unit durations in exemplary speech .In an automatic speech processing system , a method for grading the pronunciation of a student speech sample , the method comprising : . accepting said student speech sample which comprises a sequence of words spoken by a student speaker ; . computing an evaluation score , herein referred to as the posterior - based evaluation score , of pronunciation quality for said student speech sample from said posterior probabilities .", "label": "", "metadata": {}, "score": "75.93976"}
{"text": "The frames of digitized speech signals from bandpass filter bank 108 are converted to five \" Mel - cepstral \" coefficients ( to be discussed later ) and one energy measure on the average of every 20 ms by the parameter extraction subtask 402 .", "label": "", "metadata": {}, "score": "75.969055"}
{"text": "Another system [ 2 ] which automated the tasks of detection and classification of the dice scores on the playing tables in casinos was based on the online analysis of images captured by a monochrome CCD camera and the spots of dice were extracted .", "label": "", "metadata": {}, "score": "75.976654"}
{"text": "The method according to claim 1 further comprising : . mapping said duration score to a grade ; and .presenting said grade to a student .The method according to claim 4 wherein the step of mapping said duration score to a grade comprises : . collecting a set of training speech samples from a plurality of language students of various proficiency levels ; . computing training duration scores for each of said training speech samples ; . collecting at least one human evaluation grade from a human grader for each of said training speech samples ; and .", "label": "", "metadata": {}, "score": "76.03334"}
{"text": "The method of claim 16 wherein said region count procedure produces a first score corresponding to the degree of fit between the input utterance and each of the first list of word candidates ; . wherein said target congruence procedure produces a second score corresponding to the degree of fit between the input utterance and each of the second list of word candidates ; and .", "label": "", "metadata": {}, "score": "76.09926"}
{"text": "The role of the translation match score generator is to compute a translation match score Score(S , T.cndot . ) that a finite sequence S of source words is the translation of a sequence of target words beginning with the finite sequence T. Here and in the following , T.cndot . will denote the set of all complete target sentences that begin with the sequence of target words T. A complete sentence is a sequence that ends in a special end - of - sentence marker .", "label": "", "metadata": {}, "score": "76.16794"}
{"text": "The sum over q runs over all phone types .P(q i ) represents the prior probability of the phone type q i .The acoustic scorer 503 of the specific embodiment computes a phone posterior score \u03c1 i for each phone i defined by the acoustic segmentation 205 .", "label": "", "metadata": {}, "score": "76.20968"}
{"text": "Each word in the source text has a spelling comprising one or more letters .Each letter is either upper case or lower case .The acoustic model generator produces an acoustic model of each word in the source text which is not in the source vocabulary , and which has an upper case first letter .", "label": "", "metadata": {}, "score": "76.21649"}
{"text": "The recognition threshold for the current sound comprises a first confidence score from confidence scores store 18 if the best match score for a prior sound was better than a recognition threshold for that prior sound .The recognition threshold for the current sound comprises a second confidence score from confidence scores store 18 , better than the first confidence score , if the best match score for a prior sound was worse than the recognition threshold for that prior sound .", "label": "", "metadata": {}, "score": "76.32801"}
{"text": "Returning to FIG .1 , the match score processor 14 generates a match score for each sound and the acoustic silence model in acoustic silence model store 20 .Each match score with the acoustic silence model comprises an estimate of the closeness of a match between the acoustic silence model and a series of feature signals corresponding to the sound .", "label": "", "metadata": {}, "score": "76.35559"}
{"text": "In this way , the acoustic scorer 503 obtains acoustic feature frames which correspond to each acoustic segment .The acoustic scorer 503 compares the acoustic feature frames of the acoustic segments to a model 505 of exemplary acoustic feature frames .", "label": "", "metadata": {}, "score": "76.43624"}
{"text": "Multistage word recognizer based on reliably detected phoneme similarity regions US 5822728 A .Abstract .The multistage word recognizer uses a word reference representation based on reliably detected peaks of phoneme similarity values .The word reference representation captures the basic features of the words by targets that describe the location and shape of stable peaks of phoneme similarity values .", "label": "", "metadata": {}, "score": "76.45397"}
{"text": "SUMMARY OF THE INVENTION .It is an object of the invention to provide a speech recognition apparatus and method which has a high likelihood of rejecting acoustic matches to inadvertent sounds or words spoken but not intended for the speech recognizer .", "label": "", "metadata": {}, "score": "76.49694"}
{"text": "FIG .2 schematically shows an example of a hypothetical acoustic command model .In this example , the acoustic command model comprises four states S1 , S2 , S3 , and S4 illustrated in FIG .2 as dots .The model starts at the initial state S1 and terminates at the final state S4 .", "label": "", "metadata": {}, "score": "76.51222"}
{"text": "The machine scores 703 to be combined are the input to a neural network 603 that implements the mapping between the multiple machine scores 703 and the corresponding human scores 705 .The mapping analyzer establishes the parameters within the neural network 603 using the actual human scores 705 as targets .", "label": "", "metadata": {}, "score": "76.57826"}
{"text": "For example , the invention may be used to recognize an utterance in English of a translation of a sentence in French .In one study , it was found that the efficiency of a human translator who dictates a translation in one language corresponding to source text in another language , is greater than the efficiency of a human translator who writes or types a translation .", "label": "", "metadata": {}, "score": "76.642044"}
{"text": "Description .CROSS - REFERENCE TO RELATED COPENDING PATENT APPLICATIONS . A. Morgan et al . , Ser .No .09/213,858 ; \" SPEECH COMMAND INPUT RECOGNITION SYSTEM FOR INTERACTIVE COMPUTER DISPLAY WITH SPEECH CONTROLLED DISPLAY OF RECOGNIZED COMMANDS \" , Scott A. Morgan , Ser .", "label": "", "metadata": {}, "score": "76.67239"}
{"text": "If the sum is greater than the speech threshold , the first frame of the ten with an amplitude greater than a \" silence \" threshold ( SILENZ ) becomes the first frame of the sentence and obviously the first frame of the first utterance .", "label": "", "metadata": {}, "score": "76.74015"}
{"text": "The method of claim 25 further comprising the step of : . building a region count prototype corresponding to a spoken word or phrase that consists of statistics based on the number of high phoneme similarity regions found for each phoneme identifier in each of a plurality of time intervals in the phoneme similarity data .", "label": "", "metadata": {}, "score": "76.85776"}
{"text": "If an actual command is clearly identified , actual command 55 , that command may actually be carried out and then displayed via display adapter 36 to display 38 or the actual command may be displayed first and subsequently carried out .", "label": "", "metadata": {}, "score": "76.876175"}
{"text": "In some embodiments of the invention , the lexicon 307 also includes any assigned transition probabilities from phone type to phone type within each word .A grammar 309 describes allowed word - to - word transitions in a language .The grammar 309 of the specific embodiment is a \" bi - gram \" that specifies context - free word - to - word transition probabilities between every pair of words .", "label": "", "metadata": {}, "score": "76.87709"}
{"text": "5,333,209 , Jul. 26 , 1994 , the teachings of which are incorporated as if fully set forth herein .This metric is chosen for its simplicity in both concept and computation , and its relative completeness in representing the shape of the whole segment .", "label": "", "metadata": {}, "score": "76.884186"}
{"text": "The TC stage provides a more selective short list of word candidates , essentially a further refinement of the list produced by the RC stage 18 .The fine match word recognition stage 26 , the final major component of the present system , is preferably a fine match word recognizer that performs frame - by - frame alignment to select the recognized word from the short list supplied by TC stage 20 .", "label": "", "metadata": {}, "score": "76.91824"}
{"text": "3 and the principles set forth above , we will run through an example of dynamic weighting as the user adds terms .In the example , underlined words will be considered to be firm , non - underlined words are not yet firm .", "label": "", "metadata": {}, "score": "76.97534"}
{"text": "( Note that in general segment boundaries define durations , and a sequence of durations defines segment boundaries given a single boundary within the sequence .Therefore , a system component that is described as using boundaries can in general be alternatively but equivalent described as using durations , or durations plus a boundary . )", "label": "", "metadata": {}, "score": "76.992935"}
{"text": "A speech recognition system as claimed in claim 1 , characterized in that the output means comprises a loudspeaker .A speech recognition system as claimed in claim 1 , characterized in that the output means comprises a speech synthesizer .A speech recognition system as claimed in claim 1 , characterized in that the means for storing speech hypotheses comprises readable computer memory .", "label": "", "metadata": {}, "score": "77.06096"}
{"text": "Investigation of characteristics difference .To evaluate the efficacy of the retrieval signals , the following signals were compared with speech : .Retrieval signal with Wiener filtering and the cross spectrum method ( Cross ) .Retrieval signal with Wiener filtering and the adaptive filter for word ( Adaptive 1 ) .", "label": "", "metadata": {}, "score": "77.08981"}
{"text": "( Attorney Docket No .AT9 - 98 - 343 ) .It should be noted that while this referenced application is the preferred method of locating commands applicable to the speech query , this invention is operable with any other process for searching for commands in response to spoken queries , such as \" Help \" queries .", "label": "", "metadata": {}, "score": "77.0977"}
{"text": "The main shortcoming of the CSR method is that it does not treat keyword templates separately from filler templates in the matching process .In terms of hypothesis testing , it does not explicitly separate the keyword hypothesis from the null hypothesis .", "label": "", "metadata": {}, "score": "77.10774"}
{"text": "In such a situation , the probability determining means will redetermine the weights to include the additional weights of such added terms .In a user interactive computer controlled display system with speech command input recognition comprising , apparatus for interpreting speech queries to locate commands comprising : . means for predetermining a plurality of speech commands each associated with a corresponding plurality of system actions , . means responsive to a speech command for carrying out the system action corresponding to the command , . means for storing for each of said plurality of commands , an associated set of speech terms , each term having relevance to its associated command , . means responsive to a speech query for determining the probability of speech terms from said set in said query by applying a weight factor for a firm recognition of a speech term at least twice the weight of an infirm recognition of the term , and . means responsive to said probability determining means for prompting the user with a displayed sequence of commands sorted based upon said probability of speech terms associated with said commands .", "label": "", "metadata": {}, "score": "77.13627"}
{"text": "S ) , while in another embodiment the translation match score is an estimate of a joint probability P(S , T.cndot . )In the latter embodiment , the translation match score generator includes three components : . a language match score generator which computes an estimate P(T ) of the prior probability of a target word sequence T ; . a conditional translation match score generator which computes an estimate P(S.vertline .", "label": "", "metadata": {}, "score": "77.25816"}
{"text": "The creation of the relevance table is described in detail in the above - mentioned copending application ( Attorney Docket No .AT9 - 98 - 343 ) which is hereby incorporated by reference .Initially , an active vocabulary is determined .", "label": "", "metadata": {}, "score": "77.307785"}
{"text": "Automatic speech recognition systems provide a means for man to interface with communication equipment , computers and other machines in a human 's most natural and convenient mode of communication .Also , machines using normal voice input require much less user training than do systems relying on complex keyboards , switches , push buttons and other similar devices .", "label": "", "metadata": {}, "score": "77.542206"}
{"text": "Figure 18 shows the differential acceleration estimated from Figure 17 .Body - conducted speech was extracted with an accelerator from the noisy environment .The signal level in each frequency is low compares to signal in quiet environment .Therefore , differential acceleration in the noisy environment exhibited a clearer signal compared with that extracted in the quiet environment .", "label": "", "metadata": {}, "score": "77.61857"}
{"text": "A region count hypothesizer stage , which includes a first word prototype database for storing similarity region count data for a plurality of words , is coupled to the high similarity module .The region count hypothesizer generates a first list of word candidates selected from the first word prototype database , based on similarity regions .", "label": "", "metadata": {}, "score": "77.67439"}
{"text": "In a similar fashion the weighting factor ( reciprocal of the variance ) is converted into a scaler number by adding all of the vector elements .The final score is then computed by dividing the scaler distance by the scaler weight .", "label": "", "metadata": {}, "score": "77.76175"}
{"text": "The audio receiver process runs on the server processor 811 .In other such embodiments , the microphone 805 is coupled to relay student speech samples to the server process across a separate channel 819 which is not under the direct control of the client process .", "label": "", "metadata": {}, "score": "77.829636"}
{"text": "SUMMARY OF THE PRESENT INVENTION .When such a sorted command is selected , the system has means responsive to a speech command for carrying out the system action corresponding to the command .Preferably , means for determining probability of speech terms weight said probability upon the firmness of recognition of the speech terms .", "label": "", "metadata": {}, "score": "78.011566"}
{"text": "The match score for each sound and an acoustic command model corresponding to states S1 through S4 of FIGS . 2 and 4 may be obtained as follows .Alternatively , the match score for each sound and the acoustic command model may be given by the sum of the normalized state output scores Q[S10,t ) for state S10 over time intervals t ' end through t end .", "label": "", "metadata": {}, "score": "78.018265"}
{"text": "In addition , there may be circumstances where the user in speaking a run of speech words and terms to seek out commands appropriate to his needs may use phrases which include actual commands .These spoken commands may be inadvertent and not the best commands for the user 's purpose or they may be very pertinent .", "label": "", "metadata": {}, "score": "78.03249"}
{"text": "No . 439,018 filed Nov. 3 , 1982 of Vensko , et al , and Ser .No .473,422 filed Nov. 9 , 1983 of Vensko , et al both described above .Hereafter , this system is referred to as the \" standard CSR system \" .", "label": "", "metadata": {}, "score": "78.05761"}
{"text": "detecting each of said pen - up instances within said handwriting sample ; . calculating said spatial distance associated with each of said pen - up instances , respectively ; . associating with each of said pen - up instances a predetermined gap feature signal indicative of whether said spatial distances are at least equal to , or less than , a predetermined gap threshold spatial distance value ; . recognizing said handwriting sample based on said adjusted alternative hypothesis scores .", "label": "", "metadata": {}, "score": "78.20813"}
{"text": "FIGS .9A-9E summarize the window movement control function of the Isolated Word Recognition portion of the IW / CD algorithm of FIG .4 .FIGS .10A and 10B are a more detailed block diagram of the Isolated Word recognition portion of the IW / CD algorithm of FIG .", "label": "", "metadata": {}, "score": "78.22587"}
{"text": "An apparatus for performing handwriting recognition of a handwriting sample comprising a string of interconnected symbols represented by a signal sequence , comprising : . means for hypothesizing one or more segmentations of said string of interconnected symbols utilizing one or more point oriented feature signals and generating a point oriented hypothesis score for each of said hypothesized segmentations ; . means for generating one or more segmental feature signals of each of said hypothesized segmentations giving rise to a segmental hypothesis score for each of said hypothesized segments ; . means for respectively adding to said point oriented hypothesis score for each of said hypothesized segmentations a segmental matching score computed using said segmental hypothesis score for each of said hypothesized segmentations resulting in an augmented hypothesis score for each of said hypothesized segmentations ; and .", "label": "", "metadata": {}, "score": "78.22606"}
{"text": "The microphone array is typically combined with noise reduction .Body - conducted speech is a robust signal extraction method that differs from the other techniques , because it provides a solid signal that propagates through skin and bone .Previously , we built a body - conducted speech recognition system to recognize speech in a noisy environment ( 98 dB SPL ) , specifically in the engine room of Oshima - maru , a training ship in Oshima National College of Maritime Technology ( Ishimitsu et al .", "label": "", "metadata": {}, "score": "78.27748"}
{"text": "5 is a block diagram of a system for computing an acoustic score based directly on the acoustic features 111 themselves according to embodiments of the present invention .FIG .6 is a block diagram of a system that combines different pronunciation scores according to an embodiment of the invention .", "label": "", "metadata": {}, "score": "78.30059"}
{"text": "The computer program of claim 11 further including means for enabling the user to speak a command in said sorted sequence of commands to thereby initiate the system action associated with the command .The computer program of claim 11 further including means for adding terms to previous speech terms wherein the probability determining means will redetermine probability to include such added terms .", "label": "", "metadata": {}, "score": "78.32967"}
{"text": "For the purpose of deciding whether the recognition threshold should be the first confidence score or the second confidence score , the silence duration threshold stored in silence match and duration thresholds store 22 is a tuning parameter which is adjustable by the user .", "label": "", "metadata": {}, "score": "78.364136"}
{"text": "The method according to claim 1 wherein the step of operating said segmentation system excludes acoustic units in context with silence from analysis .The method according to claim 1 wherein the step of operating said segmentation system comprises operating a speech recognition system as said acoustic segmentation system .", "label": "", "metadata": {}, "score": "78.38255"}
{"text": "FIG .11 is a more detailed block diagram of the Connected Digit recognition portion of the IW / CD algorithm of FIG .4 .FIG .12 is a graph illustrating the operation of totaling the path score of the best partial digit phrase portion of the Connected Digit recognition algorithm of FIG .", "label": "", "metadata": {}, "score": "78.41184"}
{"text": "To compute the above segment matching score , each letter pattern class must have a corresponding single model segment .Let u 1 , u 2 , . . ., u N be the normalized instance vectors of a set of prototypes for the letter pattern class l. Since a sample segment and a given model segment do not necessarily contain the same number of points , a resampling procedure is needed to compute the normalized instance vector of a fixed length for any segment of arbitrary length .", "label": "", "metadata": {}, "score": "78.635025"}
{"text": "In the numerator of Equation ( 9 ) , p(y t .linevert split.q i ) is computed by evaluating the output distribution of the HMM state to which the frame y t is aligned in phone type q i 's HMM .", "label": "", "metadata": {}, "score": "78.657974"}
{"text": "Digalakis , Vassilios et al .Genones : Generalized Mixture Tying in Continuous Hidden Markov Model Based Speech Recognizers .SRI International , Menlo Park , CA .IEEE Trans .Speech & Audio Processing Journal , Jun. 1994 .pp .", "label": "", "metadata": {}, "score": "78.69055"}
{"text": "A gap occurs if there is a pen - up and the distance between the pen - lift point , the beginning of the pen - up and the following pen - down point , the end of the pen - up , is equal to or greater than a gap threshold value .", "label": "", "metadata": {}, "score": "78.728455"}
{"text": "The vector variance is the mean of the squares minus the square of the means .The mean and variance vectors are then stored as the region count prototype for the given word or phrase .The same procedure is followed to similarly produce a mean and variance vector for each of the remaining words or phrases in the lexicon .", "label": "", "metadata": {}, "score": "78.85118"}
{"text": "At this point we will describe some of the general principles involved in carrying out the weighting according to the present invention .The entire spoken input string is considered as a single entity , i.e. we are not parsing the firm words and then separately parsing the infirm words .", "label": "", "metadata": {}, "score": "78.96172"}
{"text": "However , rather than generating frame - based posterior probabilities according to Equation ( 9 ) , the acoustic scorer 503 generates phone - based posterior probabilities directly .In this embodiment , the acoustic scorer 503 includes an HMM engine .", "label": "", "metadata": {}, "score": "79.04397"}
{"text": "It is an object of the invention the provide a speech recognition system which has an improved language model for increasing the accuracy of speech recognition .It is another object of the invention the provide a speech recognition system which estimates the probability of occurrence of each speech hypothesis using additional knowledge or information about the actual utterance to be recognized .", "label": "", "metadata": {}, "score": "79.083565"}
{"text": "In computing the pronunciation scores 115 , the pronunciation scorer 113 relies upon speech models 117 which characterize various aspects of desirable , i.e. exemplary , speech pronunciation .The speech models 117 are established using training speech from exemplary speakers .", "label": "", "metadata": {}, "score": "79.09108"}
{"text": "The prototype vector signal P1 has the second best prototype match score with the feature vector signal at time t1 , and therefore is associated with the second - rank score of \" 2 \" .Similarly , for the feature vector signal at time t1 , prototype vector signals P2 , P4 , and P3 are ranked \" 3 \" , \" 4 \" and \" 5 \" respectively .", "label": "", "metadata": {}, "score": "79.165726"}
{"text": "The parameters of the model are : . conditional frequency distributions f.sub.3 ( t.sub.3 .vertline.t.sub.1 t.sub.2 ) , f.sub.2 ( t.sub.3 . vertline.t.sub.2 ) , f.sub.1 ( t.sub.3 ) , for target words t.sub.1,t.sub.2,t.sub.3 ; . a bucketing scheme c which assigns word pairs t.sub.1 t.sub.2 small number of classes ; . non - negative interpolation functions . lambda .", "label": "", "metadata": {}, "score": "79.17964"}
{"text": "The RC stage 18 of word hypothesizer 14 represents each reference word with statistical information on the number of HS regions over a predefined number of time intervals .These parameters are easily estimated from training data .Each word requires exactly 330 parameters , which corresponds to 2 statistics , each over 3 intervals each comprising 55 phoneme units ( 2 statistics\u00d73 intervals\u00d755 phoneme units ) .", "label": "", "metadata": {}, "score": "79.20975"}
{"text": "wherein : . said trained speech models comprise a set of phone models ; . said student speech sample comprises phones ; and .the sum over q runs over all phone types ; and .P(qi ) represents the prior probability of the phone type qi .", "label": "", "metadata": {}, "score": "79.21959"}
{"text": "For each centisecond time interval , the output of the auditory model 42 is a modified twenty dimension feature vector signal .This feature vector is augmented by a twenty - first dimension having a value equal to the square root of the sum of the squares of the values of the other twenty dimensions .", "label": "", "metadata": {}, "score": "79.2236"}
{"text": "Our proposed system is an unsupervised system and its operation does not require a matching template .The classification process is independence of the size of dice images and is applicable to different styles of dice .In addition , the system is workable even for low contrast images .", "label": "", "metadata": {}, "score": "79.28703"}
{"text": "COST278 and ISCA Tutorial and Research Workshop ( ITRW ) on Robustness Issues in Conversational Interaction , paper31 .12 - K. Yamashita , S. Ogata , T. Shimamura , 2005 Improved Spectral Subtraction Utilizing Iterative Processing , in Trans . of IEICE on Inst . of Electronics , Information and Communication Engineers , J88-A 11 1246 1257 .", "label": "", "metadata": {}, "score": "79.293"}
{"text": "The presently preferred word recognizer may be implemented according to the techniques described in \" A Study of English Model Speech Method , \" by Y. Ohno et al . , Proc .Acoustical Society of Japan , Spring 1995 ( in Japanese ) .", "label": "", "metadata": {}, "score": "79.30354"}
{"text": "A speech recognition method as claimed in claim 19 , characterized in that the output means comprises a loudspeaker .A speech recognition method as claimed in claim 19 , characterized in that the output means comprises a speech synthesizer .A speech recognition method as claimed in claim 19 , characterized in that the means for storing speech hypotheses comprises readable computer memory .", "label": "", "metadata": {}, "score": "79.31778"}
{"text": "Figures 16 and 17 demonstrate the word \" Ageo \" that was obtained from the database of JEIDA .Figures 16 and 17 exhibit speech and body - conducted speech signals from the engine room of the Oshima - maru .Because body - conducted speech is a structure bone sound , it is less influenced by noise than normal speech .", "label": "", "metadata": {}, "score": "79.332275"}
{"text": "The maximum likelihood path 313 includes the sequence of states traversed 314 and the duration of time 315 spent in each state .The maximum likelihood path 313 defines an acoustic segmentation 205 of the acoustic features into a sequence of phones .", "label": "", "metadata": {}, "score": "79.43709"}
{"text": "An adapted twenty dimension feature vector X'(t ) is generated by subtracting a twenty dimension adaptation vector A(t ) from the twenty dimension feature vector X(t ) provided to the input of the adaptive labeler 40 .The twenty dimension adapted feature vector signal X'(t ) from the adaptive labeler 40 is preferably provided to an auditory model 42 .", "label": "", "metadata": {}, "score": "79.546295"}
{"text": "Missegmentation or misclassification could occur when these facts are not considered .Furthermore , when segmental matching scores are used , the mistakes on segmentation during training directly affect the reliability of the resulting model segments for the letter patterns , which could in turn cause more recognition errors .", "label": "", "metadata": {}, "score": "79.562485"}
{"text": "If Yes , then the command is displayed , step 96 so that the user now has an opportunity to confirm the command by repeating it more precisely .By a possible command , we mean that a term which matches a command is recognized in the spoken input but within that context , it appears that the user has not intended it to be a definite command .", "label": "", "metadata": {}, "score": "79.63344"}
{"text": "The signals of 100 words , from the database of JEIDA were read three times in each environment by three males aged 20 , 20 and 37 years old .For body - conducted speech extraction , measurements were taken from the upper lip .", "label": "", "metadata": {}, "score": "79.64978"}
{"text": "In this paper , a novel machine vision system is used to identify the score of dice in games .Firstly , we obtain an image of dice using an auto - acquisition method with machine vision .Secondly , the locations of spots on the dice are estimated by the image processing techniques .", "label": "", "metadata": {}, "score": "79.65408"}
{"text": "FIG .1 is a block diagram of an isolated word / connected digit recognizer apparatus designated generally 100 .It comprises a microphone 104 such as Shure Brothers , Inc. Model No .SM10 ; a preamplifier circuit 106 , such as a Bogen Company Model No .", "label": "", "metadata": {}, "score": "79.67053"}
{"text": "No . 09/213,856 and \" METHOD AND APPARATUS FOR PRESENTING PROXIMAL FEEDBACK IN VOICE COMMAND SYSTEMS \" , Alan R. Tannenbaum , Ser .No .09/213,857 .TECHNICAL FIELD .The present invention relates to interactive computer controlled display systems with speech command input and more particularly to such systems which present display feedback to query inputs from the interactive users .", "label": "", "metadata": {}, "score": "79.73523"}
{"text": "The Mora unit is constructed of a vowel or consonant and a vowel .There is a problem in length of sample because the length of an adaptive filter for a sub - word is very short .So adaptive filter for sub - word unit could not be estimated by conventional methods .", "label": "", "metadata": {}, "score": "79.755806"}
{"text": "Notes : The word \" paste \" in the input is found in two commands .It is not yet firm .Results : . -Paste ( 1,4 ) .Hit : \" paste \" .Score : One for the single word hit , then doubled to two because it is an exact match for the command , plus two more for the second pass finding the hit \" paste \" to be a subphrase of the command found .", "label": "", "metadata": {}, "score": "79.756256"}
{"text": "The result of recognition will be incorrect if the obtained cluster number is not equal to the expected cluster number ( i.e. , the number of dice ) .Results and Discussion .In this paper , the modified unsupervised grey clustering software ( MUGCS ) is designed with Matlab 7.0 , and the interface of MUGCS is shown in Figure 4 .", "label": "", "metadata": {}, "score": "79.88048"}
{"text": "The system should be able to distinguish the straightforward command mode of operation from the context of the spoken term .For example , if the spoken term is the singular command with no terminology surrounding it , the system may be set up to display and then conventionally carry out the command without going into the weighting process of the present invention .", "label": "", "metadata": {}, "score": "79.90442"}
{"text": "In the hypothetical example , the feature vector signals and the prototype vector signal are shown as having one dimension only , with only one parameter value for that dimension .In practice , however , the feature vector signals and prototype vector signals may have , for example , fifty dimensions , where each dimension has two parameter values .", "label": "", "metadata": {}, "score": "79.912254"}
{"text": "There is a need to make computer directed activities accessible to people who , up to a few years ago , were computer illiterate or , at best , computer indifferent .Thus , there is continuing demand for interfaces to computers and networks which improve the ease of use for the interactive user to access functions and data from the computer .", "label": "", "metadata": {}, "score": "79.95726"}
{"text": "Prototype stores 34 and 36 may be electronic computer memory of the types discussed above .The prototype vectors in prototype store 24 may be obtained , for example , by clustering feature vector signals from a training set into a plurality of clusters , and then calculating the mean and standard deviation for each cluster to form the parameter values of the prototype vector .", "label": "", "metadata": {}, "score": "80.06351"}
{"text": "Paste ( 1,6 ) .Score : Same as in [ 3 ] above .[5 ] Next spoken input : \" How do I paste special text using the clipboard \" .Notes : Two speech terms from the relevancy table portion shown in FIG .", "label": "", "metadata": {}, "score": "80.071335"}
{"text": "Thus , a clear signal was produced using an adaptive filter .Moreover , the formant was not observed in the retrieval signal with the cross spectrum method .And it was also confirmed in the spectrogram .Adaptive filter method for sub - word unit .", "label": "", "metadata": {}, "score": "80.079155"}
{"text": "4 is a diagrammatic view of a display screen on which an interactive dialog panel interface used for visual feedback when an initial speech command and/or speech query input has been made ; .FIG .5 is the display screen view of FIG .", "label": "", "metadata": {}, "score": "80.10565"}
{"text": "BACKGROUND OF THE INVENTION .The present invention relates to automatic evaluation of speech pronunciation quality .One application is in computer - aided language instruction and assessment .Techniques related to embodiments of the present invention are discussed in co - assigned U.S. application Ser .", "label": "", "metadata": {}, "score": "80.1653"}
{"text": "Each acoustic model represents the acoustic features of an utterance of one or more words associated with the model .The sound features of the utterance are compared to each acoustic model to produce a match score .The match score for an utterance and an acoustic model is an estimate of the closeness of the sound features of the utterance to the acoustic model .", "label": "", "metadata": {}, "score": "80.22818"}
{"text": "For a more complete understanding of the invention , its objects and advantages , reference may be had to the following specification and to the accompanying drawings .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a phoneme similarity time series for the word \" hill \" spoken by two speakers ; .", "label": "", "metadata": {}, "score": "80.312744"}
{"text": "One example of an acoustic feature value measure is shown in FIG .5 .The measuring means includes a microphone 44 for generating an analog electrical signal corresponding to the utterance .The analog electrical signal from microphone 44 is converted to a digital electrical signal by analog to digital converter 46 .", "label": "", "metadata": {}, "score": "80.326294"}
{"text": "The display screens of FIGS .3 through 7 are presented to the viewer on display monitor 38 of FIG .1 .In accordance with conventional techniques , the user may control the screen interactively through a conventional I / O device such as mouse 26 , FIG .", "label": "", "metadata": {}, "score": "80.344795"}
{"text": "The client process exceeds previous pronunciation evaluation systems in that it can ( and does ) use scripts containing words for which there may be no training data or incomplete training data , as described above .These scripts include scripts generated dynamically during execution by the system 801 .", "label": "", "metadata": {}, "score": "80.370224"}
{"text": "The signals exhibited frequency characteristics of 2 kHz and more .The estimated signal rejected stationary noise from the differential acceleration completely .The effect of repetitions was also clearly observable .We found that three repetitions allowed stationary noise to be completely reduced .", "label": "", "metadata": {}, "score": "80.43088"}
{"text": "If Yes , then the command is carried out , step 92 , and then a determination is made as to whether the session is at an end , step 93 .If Yes , the session is exited .If No , the flow is returned to step 105 where a further spoken input is awaited .", "label": "", "metadata": {}, "score": "80.492294"}
{"text": "linevert split.q i , . . . ) is a context - dependent likelihood p(y t .linevert split.q i , ctx i ) , wherein ctx i represents context .The method according to claim 30 wherein the model corresponding to each phone type is a Gaussian mixture phone model .", "label": "", "metadata": {}, "score": "80.5701"}
{"text": "42.5.1 - 42.5.4 , Mar. 1984 .\" Language and Machines - Computers in Translation and Linguistics \" .National Academy of the Sciences , Washington , D.C. , Publication 1416 , 1966 .Primary Examiner : Fleming ; Michael R. Assistant Examiner : Hofiz ; Tarif R. Attorney , Agent or Firm : .", "label": "", "metadata": {}, "score": "80.61476"}
{"text": "An existing CSR system such as those referenced above is used in place of the \" Keyword Template Matcher \" shown in FIG .3 .The task vocabulary replaces the \" Keyword Templates \" .The given task syntax is inserted in the \" Task Syntax \" block in FIG .", "label": "", "metadata": {}, "score": "80.631874"}
{"text": "A match score processor generates a match score for each sound and each of one or more acoustic command models from the set of acoustic command models .Each match score comprises an estimate of the closeness of a match between the acoustic command model and a series of feature signals corresponding to the sound .", "label": "", "metadata": {}, "score": "80.71135"}
{"text": "Speech was measured 30 cm from the mouth using a microphone , and body - conducted speech was extracted from the upper lip with an accelerator .This microphone position is commonly used for a speech input of the car navigation system .", "label": "", "metadata": {}, "score": "80.721924"}
{"text": "5 illustrates the word prototype training procedure by which the TC word prototype database 24 is constructed .The RC word prototype database 22 is constructed by similar , but far simpler process , in that only the presence or absence of an HS region occurring with each of the 3 equal time intervals must be detected .", "label": "", "metadata": {}, "score": "80.72195"}
{"text": "Referring now to FIG .2 , a more detailed block diagram of the bandpass filter bank circuit 108 is shown .The output from preamp 106 on lead 112 from FIG .1 is transmitted to an input amplifier stage 200 which has a 3 db bandwidth of 10 kHZ .", "label": "", "metadata": {}, "score": "80.77658"}
{"text": "From Figure 21 , we expect that performance of speech recognition can also be improved .Decoding algorithm for differential acceleration .Problem of recognition for differential acceleration .The differential acceleration exhibited a distorted signal when a consonant was present .", "label": "", "metadata": {}, "score": "80.78702"}
{"text": "When the cluster number is equivalent to the number of dice and PI achieves an optimal value , the location of each die and the score can be exactly determined .The clustering weight value and the distinguishing coefficient keep changing until the dice are exactly identified .", "label": "", "metadata": {}, "score": "80.865715"}
{"text": "A prior - art approach to automatic pronunciation evaluation is discussed in previous work owned by the assignee of the present invention .See Bernstein et al . , \" Automatic Evaluation and Training in English Pronunciation \" , Internat .Conf . on Spoken Language Processing , 1990 , Kobe , Japan .", "label": "", "metadata": {}, "score": "80.8686"}
{"text": "One hundred sample sets including 3 , 4 , 5 , and 6 dice were randomly sampled from acquired image in order to test ARDS software .After all , an accuracy rate 100 % can be achieved when threshold value setting is between 100 and 150 in binary process under a controllable environment .", "label": "", "metadata": {}, "score": "80.88927"}
{"text": "As machine vision was not provided during the recognition process , the suspicion of cheating can not be eliminated .Because of the above - mentioned issues , a novel auto - recognition system is proposed to estimate the location of each die and the score of dice accurately and effectively in the games using machine vision techniques .", "label": "", "metadata": {}, "score": "80.90584"}
{"text": "Prototype stores 54 and 56 may be electronic computer memory of the types discussed above .The prototype vectors in prototype store 38 may be obtained , for example , by clustering feature vector signals from a training set into a plurality of clusters , and then calculating the mean and standard deviation for each cluster to form the parameter values of the prototype vector .", "label": "", "metadata": {}, "score": "80.93382"}
{"text": "While the present invention has been disclosed in connection with the preferred embodiment thereof , it should be understood that there may be other embodiments which fall within the spirit and scope of the invention as defined and by the following claims .", "label": "", "metadata": {}, "score": "80.98013"}
{"text": "Delayed strokes are considered special one - stroke letters .Each letter typically requires more than one letter model representing different letter pattern classes as a result of different writing styles .Referring to FIG .1 , g is a typical grammar node with a number of incoming arcs p(g ) , representing the preceding letter pattern classes and a number of outgoing arcs s(g ) , representing the succeeding letter pattern classes .", "label": "", "metadata": {}, "score": "81.076584"}
{"text": "An acoustic feature value measure 36 is provided for measuring the value of at least one feature of an utterance over each of a series of successive time intervals to produce a series of feature vector signals representing the feature values .", "label": "", "metadata": {}, "score": "81.07686"}
{"text": "08/375,908 , now U.S. Pat .No .5,864,810 , entitled METHOD AND APPARATUS FOR SPEECH RECOGNITION ADAPTED TO AN INDIVIDUAL SPEAKER ; U.S. application Ser .No .08/276,742 , now U.S. Pat .No .5,825,978 , entitled METHOD AND APPARATUS FOR SPEECH RECOGNITION USING OPTIMIZED PARTIAL MIXTURE TYING OF HMM STATE FUNCTIONS ; U.S. Pat .", "label": "", "metadata": {}, "score": "81.089966"}
{"text": "Digalakis , Vassilios et al .Genones : Optimizing the Degree of Mixture Tying in a Large Vocabulary Hidden Markov Model Based Speech Recognizer .SRI International , Menlo Park , CA .ICASSP 1994 .pp .I 537 I 540 .", "label": "", "metadata": {}, "score": "81.15593"}
{"text": "9b ) it is desirable to advance the window by two template frames for the next utterance frame .This is achieved by shifting the window up one cell in the current utterance frame 908 and setting the control variable to advance the window one template frame for the next utterance frame 1034 .", "label": "", "metadata": {}, "score": "81.36264"}
{"text": "Those skilled in the art will be able to devise various modifications , which although not explicitly described or shown herein , embody the principles of the invention and are thus within its spirit and scope .Free format text : TERMINATION AND RELEASE OF SECURITY INTEREST IN PATENT RIGHTS;ASSIGNOR : JPMORGAN CHASE BANK , N.A. ( FORMERLY KNOWN AS THE CHASE MANHATTAN BANK ) , AS ADMINISTRATIVE AGENT;REEL / FRAME:018590/0047 Method and apparatus of rejecting false hypotheses in automatic speech recognizer systems US 4896358 A .", "label": "", "metadata": {}, "score": "81.41529"}
{"text": "The word recognition processor of claim 13 wherein said region count prototype consists of statistics based on the number of high phoneme similarity regions found for each phoneme identifier in each of a plurality of time intervals .The word recognition processor of claim 14 wherein said statistics comprise the mean and inverse variance of the number of said high phoneme similarity regions found for each phoneme identifier in each of said plurality of time intervals .", "label": "", "metadata": {}, "score": "81.44963"}
{"text": "In this manner , the feature extractor 109 produces a sequence of acoustic feature frames 111 .The input speech 107 and the sequence of acoustic feature frames 111 are both representations of the speaker 105 's speech and may therefore each be referred to as a \" student speech sample . \"", "label": "", "metadata": {}, "score": "81.46605"}
{"text": "See 512 .If the distance is small ( large similarity ) and not more than two frames of data have been skipped , the current frame is also passed over , otherwise it is stored for future comparisons in buffer 511 and passed on to the next step to buffer 514 .", "label": "", "metadata": {}, "score": "81.51094"}
{"text": "The initial state of the model is denoted by h(l ) and the final state is denoted by f(l ) .For any state i , q i ( t ) denotes the state sequence ( hypothesis ) selected by a Viterbi algorithm leading to i at sample point t , and \u03b4 i ( t ) denotes the accumulated likelihood score of that hypothesis .", "label": "", "metadata": {}, "score": "81.51707"}
{"text": "3 is based on principles derived from detection theory .As will be explained , the theory is based on the fact that the optimal detector of an event is one that computes the likelihood ratio of the event and performs an accept / reject decision by comparing the likelihood ratio with a threshold .", "label": "", "metadata": {}, "score": "81.517494"}
{"text": "Each match score measures the distance or dissimilarity between the keyword template and the input speech ending at a particular frame .Thus the keyword with the lowest match score is hypothesized as having been the spoken word .This hypothesis is accepted or rejected by comparing the match score with a given threshold value as evidenced by module 12 of FIG .", "label": "", "metadata": {}, "score": "81.54883"}
{"text": "The table in FIG .3 shows the relevant commands which these two speech terms are associated with .Results : . - Paste special ( 4,19 ) .Score : Same as in [ 4 ] above except that \" clipboard \" is an associated speech term for this command and , thus , a fourth hit .", "label": "", "metadata": {}, "score": "81.645294"}
{"text": "So we concluded that it was difficult to recover frequency characteristics with this method .Wiener filtering method .The Wiener filtering method is a technique which estimates a speech spectrum envelope from noisy speech ( Li and O'Shaughnessy , 2003 ) .", "label": "", "metadata": {}, "score": "81.70769"}
{"text": "The invention has now been explained with reference to specific embodiments .Other embodiments will be apparent to those of ordinary skill in the art in view of the foregoing description .For example , preselected scripts may be delivered to a user via off - line means such as a written guidebook , as a newspaper advertisement or in other visual or auditory forms .", "label": "", "metadata": {}, "score": "81.76257"}
{"text": "In many query applications , there may be a substantial latency between when a word is spoken and when it is decoded or declared firm .The processing of firm and infirm words is used and described in greater detail in the document , \" SMAPI Developer 's Guide for IBM ViaVoice for Windows , Version 1.01 \" available from IBM Corp. in connection with the IBM ViaVoice SDK product .", "label": "", "metadata": {}, "score": "81.777885"}
{"text": "The duration scorer compares these durations to a model 213 of syllabic duration in exemplary speech to compute a syllabic duration score 115 .The syllabic duration model 213 includes a probability distribution of duration for a subset of the syllables in the language .", "label": "", "metadata": {}, "score": "81.80294"}
{"text": "The microphone 805 forms at least a part of the pronunciation evaluator 's speech input device ( 103 , as shown in FIG .1 only ) .In one embodiment of FIG .8 , the client process uses a computer display 807 to provide the prompts .", "label": "", "metadata": {}, "score": "81.88768"}
{"text": "Normalization processor 58 normalizes the twenty - one dimension feature vector F'(t ) to produce a twenty dimension normalized feature vector X(t ) .The twenty - first dimension of the feature vector F'(t ) , representing the total amplitude or total power , is discarded .", "label": "", "metadata": {}, "score": "81.91318"}
{"text": "4 schematically shows an example of the acoustic silence model of FIG .3 concatenated onto the end of the acoustic command model of FIG .2 . FIG .5 schematically shows the states and possible transitions between states for the combined acoustic model of FIG .", "label": "", "metadata": {}, "score": "81.93562"}
{"text": "3 shows the segmentation of a sample of word \" line \" when the basic HMM system was used and the sample was falsely recognized as \" arc \" .It shows how such an error is probable when global letter shape information is missing from the system .", "label": "", "metadata": {}, "score": "82.13002"}
{"text": "Certain embodiments of the present invention compute duration scores 115 based on phone duration .The speech segmenter 203 segments the acoustic features 111 into acoustic segments which are phones .The acoustic unit duration extractor 207 defines acoustic units as , simply , the phones themselves .", "label": "", "metadata": {}, "score": "82.331314"}
{"text": "The spot images are extracted by using the global thresholding , hole - filling , closing , and opening operators [ 4 ] , respectively , as illustrated in Figure 1 .The location of each die can be obtained according to the images of spots .", "label": "", "metadata": {}, "score": "82.37477"}
{"text": "The method according to claim 30 wherein the model corresponding to each phone type is a hidden markov model .A system for pronunciation training in a client / server environment wherein there exists a client process for presenting prompts to a student and for accepting student speech elicited by said prompts , the system comprising : . a server process for sending control information to said client process to specify a prompt to be presented to said student and for receiving a speech sample derived from said student speech elicited by said presented prompt ; and .", "label": "", "metadata": {}, "score": "82.40504"}
{"text": "The method according to claim 1 wherein : . said exemplary acoustic unit duration distribution model is a model of speaker - normalized acoustic unit durations , and the duration measuring step comprises the steps of : . analyzing said student speech sample to determine a student speaker normalization factor ; and . employing said student speaker normalization factor to measure speaker - normalized durations as said measured sample acoustic unit durations , whereby the comparing step compares said speaker - normalized sample acoustic unit durations to said exemplary speaker - normalized acoustic unit duration distribution model .", "label": "", "metadata": {}, "score": "82.41066"}
{"text": "The vocabulary capability of the preferred embodiment recognizer is 100 words , any ten of which can be spoken in connected fashion with a \" real - time \" recognition ( less than 200 milliseconds response time ) .The Exatron Stringy / Floppy mass storage device 114 is an endless tape loop with a storage capacity of approximately 8K - bits per foot .", "label": "", "metadata": {}, "score": "82.41792"}
{"text": "The apparatus of claim 1 further including means for enabling the user to speak a command in said sorted sequence of commands to thereby initiate the system action associated with the command .The apparatus of claim 1 further including means for adding terms to previous speech terms wherein the probability determining means will redetermine probability to include such added terms .", "label": "", "metadata": {}, "score": "82.535385"}
{"text": "JEIDA 100 local place words were used as candidates for word recognition ( Itahashi , 1991 ) .The words consisted of a database of Japanese place names after consideration of phoneme balance .The acoustic model was the context - dependent type tri - phone model in a word for unspecified speakers .", "label": "", "metadata": {}, "score": "82.55791"}
{"text": "In other embodiments of the present invention , word duration is used for scoring in a manner analogous to that described above for syllables .In these embodiments , the acoustic unit duration extractor 207 recovers word durations from the acoustic segmentation 205 .", "label": "", "metadata": {}, "score": "82.67644"}
{"text": "The present invention will be better understood and its numerous objects and advantages will become more apparent to those skilled in the art by reference to the following drawings , in conjunction with the accompanying specification , in which : .FIG .", "label": "", "metadata": {}, "score": "82.71431"}
{"text": "Paste ( 1,6 ) .Score : Same as in [ 2 ] above since the additional word has no contribution to this command .Note that the order of the results has changed here since the command \" paste special \" now has a higher weight than \" paste \" .", "label": "", "metadata": {}, "score": "82.71744"}
{"text": "2 , a speech segmenter 203 accepts the sequence of acoustic features 111 and produces from them a time - segmentation 205 specifying acoustic segments .The acoustic segmentation 205 is a representation of acoustic segments from which their durations may be determined .", "label": "", "metadata": {}, "score": "82.75481"}
{"text": "3 is a block diagram of the method and apparatus according to this invention .FIG .4 is a simplified block diagram of a syntax format according to this invention .DETAILED DESCRIPTION OF THE FIGURES .Referring to FIG .", "label": "", "metadata": {}, "score": "82.767075"}
{"text": "It is difficult to auto - recognize the score of dice in the acquired images because dice are scattered anywhere in a bowl .A brief summary of the grey relational analysis theorem [ 5 - 10 ] is given before introducing the grey clustering algorithm [ 8 , 9 ] .", "label": "", "metadata": {}, "score": "82.80844"}
{"text": "The task of the language match score generator is to compute a score P(T ) for a finite sequence T of target words .The probability P(T ) of occurrence of the target word sequence may be approximated by the product of n - gram probabilities for all n - grams in each string .", "label": "", "metadata": {}, "score": "83.02858"}
{"text": "The acoustic match score may comprise , for example , an estimate of the probability of occurrence of the sequence of coded representations of the utterance given the occurrence of the speech hypothesis .The hypothesis score may then comprise the product of the acoustic match score multiplied by the translation match score .", "label": "", "metadata": {}, "score": "83.04543"}
{"text": "2 .Display adapter 36 includes a frame buffer 39 , which is a storage device that holds a representation of each pixel on the display screen 38 .By using the aforementioned I / O devices , a user is capable of inputting visual information to the system through the keyboard 24 or mouse 26 in addition to speech input through microphone 27 and receiving output information from the system via display 38 or speaker 28 .", "label": "", "metadata": {}, "score": "83.052475"}
{"text": "FIG .2 shows a preferred resampling algorithm written in pseudo code .A pen - up refers to the situation when the pen is lifted from a pad during writing .Although a pen - up by itself is not a reliable criterion for segmentation since its occurrence within a handwritten word is highly writer dependent , there are some general rules regarding pen - up 's that could be used to assist segmentation and recognition .", "label": "", "metadata": {}, "score": "83.15857"}
{"text": "Lapanja , I. ; Mraz , M. ; Zimic , N. Computer vision based reliability control for electromechanical dice gambling machine .Industrial Technology , Proc .IEEE Int .Conf .[ Google Scholar ] .Correia , B.A.B. ; Silva , J.A. ; Carvalho , F.D. ; Guilherme , R. ; Rodrigues , F.C. ; Ferreira , A.M.S. Automated detection and classification of dice .", "label": "", "metadata": {}, "score": "83.22183"}
{"text": "The acoustic - posterior - probability - based score 115 \u03c1 is designed to be potentially less affected by changes in spectral match due to particular speaker characteristics or acoustic channel variations .Changes in acoustic match are likely to affect both numerator and denominator similarly in Equation ( 9 ) , thereby making the acoustic score 115 more invariant to those changes and more focused on phonetic quality .", "label": "", "metadata": {}, "score": "83.52104"}
{"text": "2 , input speech is again applied to a template matcher 14 .The template matcher 14 operates in conjunction with keyword and filler templates designated as module 15 .An output is provided when the keyword appears in the best matching template string as evidenced by module 16 of FIG .", "label": "", "metadata": {}, "score": "83.673546"}
{"text": "Comparing Figures 2 and 17 , there was little difference of frequency characteristic between quiet and noisy environment , so it expects that the proposed method for signal retrieval can apply to the signal in noisy environment .Figure 16 .Figure 17 .", "label": "", "metadata": {}, "score": "83.67524"}
{"text": "Each translation match score comprises an estimate of the probability of occurrence of the speech hypothesis given the occurrence of the source text .A hypothesis score generator produces a hypothesis score for each hypothesis .Each hypothesis score comprises a combination of the acoustic match score and the translation match score for the hypothesis .", "label": "", "metadata": {}, "score": "83.67857"}
{"text": "Preferably , the rank score processor 42 associates a rank score with all prototype vector signals for each feature vector signal .Each rank score represents the estimated closeness of the associated prototype vector signal to the feature vector signal relative to the estimated closeness of all other prototype vector signals to the feature vector signal .", "label": "", "metadata": {}, "score": "83.729485"}
{"text": "No .5,559,897 , issued on Sep. 24 , 1996 , entitled , \" Methods and Systems for Performing Handwriting Recognition , \" which is itself a continuation in part of U.S. patent application Ser .No . 08/184,811 , filed Jan. 21 , 1994 , entitled , \" Large Vocabulary Connected Speech Recognition System and Method of Language Representation Using Evolutional Grammar to Represent Context Free Grammars , \" now U.S. Pat .", "label": "", "metadata": {}, "score": "83.74046"}
{"text": "Finally , a process is set up for a recognized spoken cancel or clear command which cancels the prior spoken query along with any relevant displayed commands , step 91 , whereby the user may speak an entirely new query .This has been previously described with respect to FIG .", "label": "", "metadata": {}, "score": "83.8731"}
{"text": "Using the duration information from the acoustic segmentation 205 , the present invention evaluates pronunciation quality , as was described above in connection with FIGS . 1 and 2 .The HMM search engine 311 computes the maximum likelihood path through its speech HMMs according to a standard pruning HMM search algorithm that uses the well - known Viterbi search method .", "label": "", "metadata": {}, "score": "83.8869"}
{"text": "The word recognition processor of claim 1 wherein said region count stage represents an instance of a given spoken word or phrase by the number of high similarity regions found corresponding to each of a plurality of phoneme identifiers .The word recognition processor of claim 11 further comprising means for breaking said phone similarity data into a plurality of time intervals and wherein said instance of a given spoken word or phrase is represented by the number of high similarity regions in each of said time intervals .", "label": "", "metadata": {}, "score": "83.89545"}
{"text": "For a sentence of , for example , 10 words out of a target language vocabulary of 20,000 words , there are 20,000 . times.10 .sup.43 possible hypotheses .With such a large number of hypotheses , it is not feasible to generate all possible hypotheses .", "label": "", "metadata": {}, "score": "83.9384"}
{"text": "For example , it takes less than a few seconds for ARDS to identify six dice which are scattered in a bowl , as shown in Figure 6 .In general , the dices are undistinguishable when they are abreast in a bowl .", "label": "", "metadata": {}, "score": "83.948875"}
{"text": "The output device 32 may be , for example , a display , such as a cathode ray tube or liquid crystal display , a printer , a loudspeaker , or a speech synthesizer .FIG .4 is a block diagram of an example of an acoustic processor 14 ( FIG .", "label": "", "metadata": {}, "score": "84.01444"}
{"text": "The method of claim 20 wherein said combining step is performed by averaging said first and second normalized scores .The method of claim 16 further comprising representing said high similarity regions as a parameter representing the high similarity regions of the phone similarity data .", "label": "", "metadata": {}, "score": "84.026245"}
{"text": "The 1990 's decade has been marked by a technological revolution driven by the convergence of the data processing industry with the consumer electronics industry .This advance has been even further accelerated by the extensive consumer and business involvement in the Internet over the past few years .", "label": "", "metadata": {}, "score": "84.043335"}
{"text": "An HMM based handwriting recognition system , which uses only local features , is composed of stroke models embedded in an evolutional grammar network representing a vocabulary .Each arc in the grammar network corresponds to a letter model representing a unique letter pattern class .", "label": "", "metadata": {}, "score": "84.07011"}
{"text": "SPEECH COMMAND INPUT RECOGNITION SYSTEM FOR INTERACTIVE COMPUTER DISPLAY WITH INTERPRETATION OF ANCILLARY RELEVANT SPEECH QUERY TERMS INTO COMMANDS \" , Scott A. Morgan et al .( Attorney Docket No . \"SPEECH COMMAND INPUT RECOGNITION SYSTEM FOR INTERACTIVE COMPUTER DISPLAY WITH MEANS FOR CONCURRENT AND MODELESS DISTINGUISHING BETWEEN SPEECH COMMANDS AND SPEECH QUERIES FOR LOCATING COMMANDS \" , Scott A. Morgan et al .", "label": "", "metadata": {}, "score": "84.08985"}
{"text": "Statistical language models exploit the fact that not all word sequences occur naturally with equal probability .One simple model is the trigram model of English , in which it is assumed that the probability that a word will be spoken depends only on the previous two words that have been spoken .", "label": "", "metadata": {}, "score": "84.17987"}
{"text": "The word recognition processor of claim 1 wherein said high similarity module produces a parameterized representation of high similarity regions of the phone similarity data .The word recognition processor of claim 8 wherein said parameterized representation includes a representation of the phone similarity peak location and peak height .", "label": "", "metadata": {}, "score": "84.30573"}
{"text": "Many proper names are missing from even large vocabularies and yet are often translated directly from one language to another with no change in spelling .In one embodiment of the invention , the acoustic model generator 18 generates an acoustic model of a word by replacing each letter in the spelling of the word with an acoustic letter model , from an acoustic letter model store 35 , corresponding to the letter .", "label": "", "metadata": {}, "score": "84.30976"}
{"text": "Description .The government has rights in this invention pursuant to contract No . MDA-904 - 83-C-0475 awarded by the Maryland Procurement Office .This invention relates to a method of rejecting false hypotheses in an automatic speech recognizer system and more particularly to a method and apparatus for performing utterance rejection in such systems employing a likelihood scoring technique .", "label": "", "metadata": {}, "score": "84.31276"}
{"text": "Each sound may be , for example , a vocal sound , and each command may comprise at least one word .Thus , according to the invention , acoustic match scores generally fall into three categories .When the best match score is better than a \" good \" confidence score , the word or words corresponding to the acoustic model having the best match score almost always correspond to the measured sounds .", "label": "", "metadata": {}, "score": "84.329926"}
{"text": "Parametric template and results data are transferred by direct memory access in response to control of the DMA circuits by the master processor .As one can ascertain from this application , the processing techniques for operating on templates are well known in the prior art and these techniques as well as the apparatus can be employed in implementing this invention .", "label": "", "metadata": {}, "score": "84.45346"}
{"text": "The conditional probabilities may be determined empirically by examining large bodies of text .For example , the conditional probability f(W.sub.z . vertline . W.sub.x W.sub.y ) of word W.sub.z given the occurrence of the string W.sub.x W.sub.y may be estimated from the equation # # EQU10 # # .", "label": "", "metadata": {}, "score": "84.68346"}
{"text": "For example , in an embodiment of the present invention , the acoustic features 111 include 12th order mel - cepstra features computed every 10 ms within a shifting 20 ms window , and the features ' approximate derivatives .In an embodiment of the present invention , the speech input device 103 is a telephone , and the speech input 107 is conveyed across a telephone network to the feature extractor 109 .", "label": "", "metadata": {}, "score": "84.7132"}
{"text": "However , the signal levels of vowels are high because of the formant frequencies .Thus , vowels were kept intact .The stationary noise level changed according to the environment of .Figure 18 .Figure 19 .Figure 20 .", "label": "", "metadata": {}, "score": "84.85426"}
{"text": "The spectrum analyzer 50 may be , for example , a fast Fourier transform processor .Alternatively , it may be a bank of twenty band pass filters .The twenty - one dimension vector signals produced by spectrum analyzer 50 may be adapted to remove background noise by an adaptive noise cancellation processor 52 .", "label": "", "metadata": {}, "score": "84.868"}
{"text": "A window generator 28 obtains , for example , a twenty millisecond duration sample of the digital signal from analog to digital converter 26 every ten milliseconds ( one centisecond ) .Each twenty millisecond sample of the digital signal is analyzed by spectrum analyzer 30 in order to obtain the amplitude of the digital signal sample in each of , for example , twenty frequency bands .", "label": "", "metadata": {}, "score": "85.04254"}
{"text": "r .x .i . k . ) x .j .k . ) max .i .j .k . ) max .min . ) max . max .i .j .I . max . k .", "label": "", "metadata": {}, "score": "85.165405"}
{"text": "The grey clustering algorithm was primarily based on the grey theory [ 5 - 10 ] .The aims of grey theory are to provide relational analysis , predication , decision , control , and clustering data for the grey system .", "label": "", "metadata": {}, "score": "85.18767"}
{"text": "European Conference on Speech Communication and Technology ( EUROSPEECH ) , 1691 1694 .20 - K. Itou , M. Yamamoto , K. Takeda , T. Takezawa , T. Matsuoka , T. Kobayashi , K. Shikano , S. Itahashi , 1999 JNAS : Japanese speech corpus for large vocabulary continuous speech recognition research , in Journal of ASJ , 20 3 199 206 .", "label": "", "metadata": {}, "score": "85.21016"}
{"text": "A window generator 48 obtains , for example , a twenty millisecond duration sample of the digital signal from analog to digital converter 46 every ten milliseconds ( one centisecond ) .Each twenty millisecond sample of the digital signal is analyzed by spectrum analyzer 50 in order to obtain the amplitude of the digital signal sample in each of , for example , twenty frequency bands .", "label": "", "metadata": {}, "score": "85.21137"}
{"text": "The method according to claim 12 wherein the step of combining portions of at least two phones comprises measuring the time difference between centers of vowel phones from among said phones to obtain a duration of a syllable acoustic unit .The method according to claim 1 wherein said sample acoustic units are phones .", "label": "", "metadata": {}, "score": "85.36426"}
{"text": "The 100 word vocabulary storage requirement is approximately 144,000 bits which can readily be stored on the 50-foot cartridge .The Digitalker is controlled through programmed I / O by the microprocessor 110 .The synthesizer 116 interrupts the processor when it can accept additional outputs , after the initial word input .", "label": "", "metadata": {}, "score": "85.39322"}
{"text": "For example , the recognized word sequence 317 may be used by an interactive language instruction system included in the specific embodiment .This language instruction system might determine the meaning of the recognized word sequence 317 and whether the recognized word sequence 317 is a correct and appropriate utterance in relation to a current lesson being conducted .", "label": "", "metadata": {}, "score": "85.450264"}
{"text": "The word duration model 213 includes a probability distribution of duration for a subset of the words in the language .These words are the ones for which sufficient training speech data existed from which duration distributions could be estimated .The duration scorer compares words from the student speech sample with the word duration model 213 to derive word duration pronunciation scores , based on those words of the student speech sample whose durations are modelled within the word duration model 213 .", "label": "", "metadata": {}, "score": "85.45701"}
{"text": "See 506 .The resulting 16 coefficients plus the amplitude measure characterize one 10 ms frame of the speech signal stored in buffer 508 .The frame of data from buffer 508 is passed to the variable rate frame encoding step 510 .", "label": "", "metadata": {}, "score": "85.50214"}
{"text": "Score : Same as \" undo \" for the same reasons .This is the state shown in FIG .6 .[ 6 ] Next spoken input : \" How do I paste special using the clipboard \" .Notes : Finally , the whole phrase is firm .", "label": "", "metadata": {}, "score": "85.57526"}
{"text": "The data transfer means includes a shared data bus for transferring data from the shared memory to the remote bus and for transferring data from the shared memory to the local processor for local processing .The data transfer further includes a plurality of circuits connected to the shared data bus for effecting the data transfer across the shared data bus .", "label": "", "metadata": {}, "score": "85.70707"}
{"text": "Based on this comparison , the acoustic scorer 503 computes the acoustic score 115 as the pronunciation score 115 of FIG .1 .The acoustic model 505 forms a part of the speech models 117 of FIG .1 .In certain acoustic - scoring embodiments of the invention , the speech segmenter 203 is an HMM recognizer 203 that produces an acoustic segmentation 205 of the sequence of acoustic features 111 into phones , as was described in connection with FIG .", "label": "", "metadata": {}, "score": "85.80376"}
{"text": "3 utilizes filler templates 21 to normalize keyword match scores .The technique therefore eliminates the disadvantages of the above - described KS method .According to this technique , the method maintains the distinction between keyword templates and filler templates in both the matching and decision procedures .", "label": "", "metadata": {}, "score": "85.82063"}
{"text": "Each prototype vector signal has at least one parameter value and has a unique identification value .Table 2 shows a hypothetical example of five prototype vectors signals having one parameter value each , and having identification values P1 , P2 , P3 , P4 , and P5 , respectively .", "label": "", "metadata": {}, "score": "85.8309"}
{"text": "In one embodiment , the server process controls the lesson by dynamically sending control information that contains or specifies individual prompts , such as scripts and questions , shortly before the prompts are to be provided to the student 105 .In another embodiment , the server process controls the lesson more loosely by downloading control information which includes software ( e.g. , JAVA - language software ) for individual lessons to the client processor 803 's local storage 815 , which includes RAM , or hard disk , etc .", "label": "", "metadata": {}, "score": "85.965866"}
{"text": "The Euclidean distance between the test utterance and the prototype is computed by subtracting the test utterance RC data vector from the prototype mean vector and this difference is then squared .The Euclidean distance is then multiplied by a weighting factor , preferably the reciprocal of the prototype variance .", "label": "", "metadata": {}, "score": "86.13504"}
{"text": "Description .CROSS REFERENCE TO RELATED APPLICATIONS .This application is a continuation of application Ser .No .08/543,568 , filed Oct. 16 , 1995 , now abandoned , which is is a continuation in part of application Ser .No .", "label": "", "metadata": {}, "score": "86.273094"}
{"text": "In general firm terms are understood in the art to be terms which the voice recognition \" engine \" doing the decoding has completed such decoding and recognized as definite or firm words .Infirm words are those which the engine is still decoding .", "label": "", "metadata": {}, "score": "86.57631"}
{"text": "Acoustical Society of Japan , Spring 1995 ( in Japanese ) .Phoneme similarity values are typically computed as the normalized Mahalanobis distance between a segment consisting of consecutive linear predictive coding ( LPC ) analysis frames and a standard phoneme template .", "label": "", "metadata": {}, "score": "86.597855"}
{"text": "When the noise level is low , sound quality becomes clear .However , when the noise level is high , the speech is buried in the noise , causing a change in the speaker 's utterance style , termed the Lombard effect .", "label": "", "metadata": {}, "score": "86.67006"}
{"text": "In FIG .4 the high similarity region extraction module 16 performs the peak driven procedure .The output of the HS region extraction module is supplied to 2 different word hypothesizer stages that operate using different hypothesizer techniques to provide a short list of word candidates for the fine match final recognizer stage 26 .", "label": "", "metadata": {}, "score": "86.67164"}
{"text": "The spectrum analyzer 30 may be , for example , a fast Fourier transform processor .Alternatively , it may be a bank of twenty band pass filters .The twenty - one dimension vector signals produced by spectrum analyzer 30 may be adapted to remove background noise by an adaptive noise cancellation processor 32 .", "label": "", "metadata": {}, "score": "86.697"}
{"text": "In the case of wordspotting , the task syntax 30 is a single node containing all the keyword templates , as shown by the dotted lines .The box 32 to the right of the task syntax is called the termination criterion .", "label": "", "metadata": {}, "score": "86.84378"}
{"text": "A speech recognition method as claimed in claim 28 , characterized in that the display comprises a cathode ray tube .A speech recognition method as claimed in claim 28 , characterized in that the display comprises a liquid crystal display , .", "label": "", "metadata": {}, "score": "86.867584"}
{"text": "4 , July , 1996 , which is incorporated herein by reference .Computer - aided language instruction systems exist that exercise the listening and reading comprehension skills of language students .While such systems have utility , it would be desirable to add capabilities to computer - based language instruction systems that allow students ' language production skills also to be exercised .", "label": "", "metadata": {}, "score": "87.02721"}
{"text": "The grey clustering method assembles the data into clustering according to the correlation between those .In this study , the modified unsupervised grey clustering algorithm ( MUGCA ) is used to classify the dices and is described as follows ( Figure 2 ) .", "label": "", "metadata": {}, "score": "87.04921"}
{"text": "Differential acceleration in a noisy environment .The signals can be a clear with same setting of signal retrieval in quiet room with proposed method .Difference in signals characteristics between speech and body - conducted speech are little because that reason is shown a difference of Figures 2 and 17 .", "label": "", "metadata": {}, "score": "87.154144"}
{"text": "[ Google Scholar ] .Bergant , U. ; Zimic , N. ; Lapanja , I. Design considerations of an electromechanical dice gambling machine .Industrial Technology , Proc .IEEE Int .Conf .[ Google Scholar ] .Gonzalez , R.C. ; Woods , R.E. Digital image processing , 2nd ed . ; Prentice Hall : Englewood Cliff , NJ , 2002 .", "label": "", "metadata": {}, "score": "87.267426"}
{"text": "This embodiment reduces the amount of data which need be conveyed across the network because acoustic features 111 typically are a more compact representation of speech than are the input speech 107 itself in this embodiment .This embodiment also reduces the amount of computation required of the local computing system .", "label": "", "metadata": {}, "score": "87.26992"}
{"text": "A Markov model ( MM ) is a network of states connected by directed transition branches .The HMM speech recognizer 203 uses a Markov model to model the production of speech sounds .The HMM recognizer 203 represents each type of phone in a language by a phone model made up of a handful of connected states .", "label": "", "metadata": {}, "score": "87.309746"}
{"text": "A speech recognition system as claimed in claim 10 , characterized in that the display comprises a cathode ray tube .A speech recognition system as claimed in claim 10 , characterized in that the display comprises a liquid crystal display .", "label": "", "metadata": {}, "score": "87.34779"}
{"text": "A comparison processor 40 compares the closeness of the feature value of each feature vector signal to the parameter values of the prototype vector signals to obtain prototype match scores for each feature vector signal and each prototype vector signal .Table 3 illustrates a hypothetical example of prototype match scores for the feature vector signals of Table 1 , and the prototype vector signals of Table 2 .", "label": "", "metadata": {}, "score": "87.39061"}
{"text": "In this way , the server processor 811 becomes capable of controlling a greater number of lessons simultaneously in a multi - tasking manner .As described , the client process and the server process run on separate processors 803 and 811 which are coupled via a network 813 .", "label": "", "metadata": {}, "score": "87.49861"}
{"text": "The method according to claim 21 wherein : . said particular known model is a context - dependent model ; and . individual models are context - dependent or context - independent models .The method according to claim 21 wherein said particular portion of said speech sample is a phone .", "label": "", "metadata": {}, "score": "87.52806"}
{"text": "Hit : \" paste \" .Score : One for the single word hit , plus two more for the second pass finding the hit \" paste \" to be a subphrase of the command found .This is the state shown in FIG .", "label": "", "metadata": {}, "score": "87.60581"}
{"text": "An HMM Speech Recognizer for Acoustic Segmentation .FIG .3 is a block diagram showing a speech segmenter 203 of FIG .2 that is an HMM speech recognizer 203 , according to a specific embodiment of the present invention .", "label": "", "metadata": {}, "score": "87.655396"}
{"text": "LF398 ) in sampling circuitry 214 .The 19 channel samples are then multiplexed through multiplexers 216 and 218 ( Siliconix Model No . DG506 ) and converted from analog to digital signals in log A / D converter 220 , a Siliconix device , Model No . DF331 .", "label": "", "metadata": {}, "score": "87.78749"}
{"text": "Essentially , input speech is applied to the input of a template matcher 10 .The template matcher has another input which is coupled to a plurality of keyword templates 11 .The template matcher 10 operates to match the incoming speech with each of the keyword templates 11 and to produce an output when the keyword match score is below a given threshold as determined for example by the circuitry associated with the template matcher and indicated by module 12 .", "label": "", "metadata": {}, "score": "88.37572"}
{"text": "1 .A read only memory ( ROM ) 16 is connected to CPU 10 via bus 12 and includes the basic input / output system ( BIOS ) that controls the basic computer functions .Random access memory ( RAM ) 14 , I / O adapter 18 and communications adapter 34 are also interconnected to system bus 12 .", "label": "", "metadata": {}, "score": "88.54529"}
{"text": "From the acoustic segmentation 205 , the acoustic unit duration extractor 207 recovers or computes durations 209 of the acoustic units .An acoustic unit duration scorer 211 accepts the acoustic unit durations 209 and compares them to a model 213 of exemplary acoustic unit duration which has been established using training speech from exemplary speakers .", "label": "", "metadata": {}, "score": "88.6117"}
{"text": "1 .The acoustic unit duration model 213 forms a part of the speech models 117 of FIG .1 .In embodiments of the invention , the acoustic unit duration model 213 may be a parametric model or a non - parametric model .", "label": "", "metadata": {}, "score": "88.77803"}
{"text": "This algorithm searches back through the data structures built up while processing the utterance .The Syntax Control Subtask 410 comprises two functions .The first is to determine what templates should be active for matching against each utterance in the sentence ( see 410 FIG .", "label": "", "metadata": {}, "score": "88.99484"}
{"text": "The HMM recognizer 203 of the specific embodiment uses output distributions which are weighted tied mixtures of Gaussian distributions .Weighted tied mixtures are known in the art of speech recognition .A standard HMM speech recognizer which can be configured to implement the HMM recognizer 203 of the specific embodiment is the DECIPHER system from SRI International of Menlo Park , California .", "label": "", "metadata": {}, "score": "89.09607"}
{"text": "5,699,456 , the disclosures of which are incorporated herein by reference as if fully set forth herein .FIELD OF THE INVENTION .The present invention relates generally to methods for handwriting recognition and to selecting and implementing one or more appropriate features to represent a handwritten sample upon which to operate .", "label": "", "metadata": {}, "score": "89.141235"}
{"text": "Mel - cosine linear transformations are discussed in ( 1 ) Davis , S. B. and Mermelstein , P. \" Evaluation of Acoustic Parameters for Monosyllable Word Identification \" , Journal Acoust .Soc .Am . , Vol . 64 , Suppl . 1 , pp .", "label": "", "metadata": {}, "score": "89.1653"}
{"text": "The acoustic unit duration scorer 211 in certain phone - duration - scoring embodiments computes a log - probability \u03c1 i of the duration d i of each phone i : . wherein q i is the phone type of phone i. .", "label": "", "metadata": {}, "score": "89.286865"}
{"text": "Acoustics , Speech Signal Proc . , ASSP-28 , 4 357 366 .24 - N. Rivara , P. B. Dickinson , A. T. Shenton , 2009 Constrained variance control of peak - pressure position by spark - ionisation feedback for multi - cylinder control ' , International Journal of Advanced Mechatronic Systems ( IJAMechS ) , 1 4 242 250 .", "label": "", "metadata": {}, "score": "89.54572"}
{"text": "5 .[ 4 ] Next spoken input : \" How do I paste special text using the \" .Notes : The entire phrase \" paste special \" is now firm .Results : . - Paste special ( 3,18 ) .", "label": "", "metadata": {}, "score": "89.58998"}
{"text": "For example , the word \" copy \" is an exact match for a valid clipboard command .Assuming it was firm , it would get a weight of four in the list ( two for being firm and counted twice since the trigger word \" copy \" was an exact match for the command ) .", "label": "", "metadata": {}, "score": "89.65711"}
{"text": "Four bits are used by each circuit while one bit is used to select which circuit .It therefore takes 10 milliseconds to A / D convert 19 sampled channels plus a ground reference sample .These 20 digital signals are called a frame of data and they are transmitted over bus 114 at appropriate times to microprocessor 110 .", "label": "", "metadata": {}, "score": "89.710495"}
{"text": "These spoken commands may be inadvertent and not the best commands for the user 's purpose or they may be very pertinent .Such commands are presented and sorted as will be subsequently described so that the user may choose them if there are pertinent .", "label": "", "metadata": {}, "score": "89.80464"}
{"text": "This signal serves to sync the filter circuit 108 timing to the processor 110 input .Timing generator circuit 226 further provides a 2 kHz data ready strobe via lead 230 to processor 110 .This provides 20 interrupt signals per frame to processor 110 .", "label": "", "metadata": {}, "score": "90.17117"}
{"text": "This known word sequence 319 represents additional information that forms a part of the grammar network 310 .The sequence of spoken words may be known in advance for example because a language instruction system has requested that the speaker 105 read from a known script .", "label": "", "metadata": {}, "score": "90.318405"}
{"text": "2 , voice or speech input 50 is applied through microphone 51 which represents a speech input device .Since the art of speech terminology and speech command recognition is an old and well developed one , we will not go into the hardware and system details of a typical system which may be used to implement the present invention .", "label": "", "metadata": {}, "score": "90.39717"}
{"text": "e . l . a .t .i .v .e .I . m .p .r .o .v .e . m .e . n .t .C .o .r .", "label": "", "metadata": {}, "score": "90.50453"}
{"text": "The grey clustering algorithm is an essential topic in grey system theory .Hsu et al .[11 ] proposed a system to predict variations of stock market using the grey clustering method .Yang et al .[ 12 ] applied a grey prediction model to predict the recovery rate of vegetation according to the satellite images of landslide caused by an earthquake .", "label": "", "metadata": {}, "score": "90.56265"}
{"text": "Retrieval signal with Wiener 3 . the recording signal , so the number of the suitable repetitions should be selected appropriately for recognition with the proposed retrieval method and noise environment .The recognition performance decreases if the repetitions are not sufficient when the stationary noise level is changed .", "label": "", "metadata": {}, "score": "90.59383"}
{"text": "The denominator still uses the sum over the context - independent phones as in the specific embodiment .The context - dependent model used to compute the numerator of Equation ( 12 ) is a more precise model than the context - independent one as it captures the realization of the given phone type in the specific phonetic context of the surrounding phones as they occur in the test sentence .", "label": "", "metadata": {}, "score": "90.6567"}
{"text": "In an embodiment of the present invention , the speech input device 103 is a digitizing microphone system , such as a microphone connected to a remote , \" client \" computing system that contains hardware and software for audio digitization .", "label": "", "metadata": {}, "score": "90.68039"}
{"text": "The count n.sub.xy is the number of occurrence ; of the bigram W.sub.x W.sub.y in the training text .The values of the coefficients . lambda .sub.1 , . lambda . sub.2 , . lambda . sub.3 , and . lambda . sub.4 in equations [ 10 ] and [ 15 ] may be estimated by the deleted interpolation method .", "label": "", "metadata": {}, "score": "90.77327"}
{"text": "Essentially , the keyword template matcher is associated with only keyword templates as 20 while the filler template matcher , also contained within module 22 , is associated with filler templates 21 .An output is provided when a likelihood score is below a given threshold value as is evidenced by module 23 and as will be further explained .", "label": "", "metadata": {}, "score": "90.93028"}
{"text": "This subtask is closely integrated with the subtask of syntax control 410 as shown in FIG .7 .The first column designated generally 406 of FIG .7 starting with \" Recognition Command \" 704 , together with the loop labeled \" Frame Loop \" designated generally 706 is a description of the utterance recognition subtasks 410 .", "label": "", "metadata": {}, "score": "91.64693"}
{"text": "Score : One extra point for \" clipboard \" now being a firm word .-Paste ( 3,14 ) .Score : Two extra points since \" clipboard \" is firm and since \" clipboard \" is used in two separate associated terms for this command , the word by itself and in the phrase \" using the clipboard \" .", "label": "", "metadata": {}, "score": "91.85102"}
{"text": "1 phoneme similarity time series for the word \" hill \" spoken by two speakers are compared .Although the precise wave shapes differ between the two speakers , the phoneme similarity data nevertheless exhibit regions of similarity between the speakers .", "label": "", "metadata": {}, "score": "91.88129"}
{"text": "The CCD camera was employed for image acquisition with a light intensity of 4150 lx and F4.0 opening ( iris diaphragm ) .The images are stored in the hard drive as tagged image file format ( TIF ) .Image processing and modified grey clustering algorithm .", "label": "", "metadata": {}, "score": "91.911316"}
{"text": "Referring now to FIG .5 , as discussed before every 500 microseconds the microprocessor 110 is interrupted by the circuit 108 via lead 230 .The software which handles that interrupt is the parameter extraction subtask 402 .Usually the software merely stores the new filter value from bus 114 into a buffer such as any one of the buffers 502 , 504 , etc . , and returns , but every 10 ms ( the 20 interrupt ) a new frame signal is sent via line 228 .", "label": "", "metadata": {}, "score": "92.002106"}
{"text": "In these syllabic - duration - scoring embodiments , the acoustic unit duration extractor 207 determines durations of acoustic units that are \" syllables \" based on the durations of phones as specified by the speech segmenter 203 .In particular , the acoustic unit duration extractor 207 determines syllabic durations as the duration between the centers of vowel phones within speech .", "label": "", "metadata": {}, "score": "92.03075"}
{"text": "Easy To Use Patents Search & Patent Lawyer Directory .At Patents you can conduct a Patent Search , File a Patent Application , find a Patent Attorney , or search available technology through our Patent Exchange .Patents are available using simple keyword or date criteria .", "label": "", "metadata": {}, "score": "92.16124"}
{"text": "e . c .t .r . a .t .e . B .C .o .r .r .e . c .t .r . a .t .e .A .C .", "label": "", "metadata": {}, "score": "92.19873"}
{"text": "If the entire phrase is an exact match for a command , then the weight for the phrase is doubled .For each match in the command string of a subphrase from the search query , an additional weight equivalent to one firm word is added to the weight for that command .", "label": "", "metadata": {}, "score": "92.39158"}
{"text": "The duration scorer compares syllables from the student speech sample with the syllable duration model 213 to derive syllabic duration pronunciation scores , based on those syllables of the student speech sample whose durations are modelled within the syllabic duration model 213 .", "label": "", "metadata": {}, "score": "92.44055"}
{"text": "The outputs of filters 204 and 206 are provided to bandpass filter circuits ( BPF ) 208 and BPF 210 , respectively .BPF 208 includes channels 1 - 9 while BPF 210 includes channels 10 - 19 .Each of channels 1 - 18 contains a 1/3 octave filter .", "label": "", "metadata": {}, "score": "92.716705"}
{"text": "Two relevant commands were found : \" paste \" and \" paste special \" .These commands are shown in window 72 with their respective weights shown in parenthesis and the commands ordered or sorted so that the most significant command at this point , \" paste \" , 75 , is shown first and highlighted .", "label": "", "metadata": {}, "score": "92.85501"}
{"text": "This is conventional practice to provide more gain at the higher frequencies than at the lower frequencies since the higher frequencies are generally lower in amplitude in speech data .At the output of amplifier 202 the signal splits and is provided to the inputs of anti - aliasing filters 204 ( with a cutoff frequency of 1.4 kHz ) and 206 ( with a cutoff frequency of 10.5 kHz ) .", "label": "", "metadata": {}, "score": "93.073044"}
{"text": "Presently each utterance is divided into 3 time intervals , with each time interval being represented by data corresponding to the 55 phonemes .Thus the presently preferred implementation represents each utterance as a 3\u00d755 vector .In representing the utterance as a 3\u00d755 vector , each vector element in a given interval stores the number of similarity regions that are detected for each given phoneme .", "label": "", "metadata": {}, "score": "93.13432"}
{"text": "A 2 MHz clock 224 generates various timing signals for the circuitry 214 , multiplexers 216 and 218 and for A / D converter 220 .A sample and hold command is sent to circuitry 214 once every 10 milliseconds over lead 215 .", "label": "", "metadata": {}, "score": "93.24144"}
{"text": "Nakayama Masashi 1 , 3 , Ishimitsu Shunsuke 2 and Nakagawa Seiji 3 .[ 3 ] National Institute of Advanced Industrial Science and Technology , Japan .Introduction .During recent years , applications using speech recognition have been developed to aid dictation during lectures and to advance voice - prompted car navigation systems .", "label": "", "metadata": {}, "score": "93.373505"}
{"text": "The candidate word generator 20 receives the source text from source text input device 12 , and receives translations of each word in the source text from a source - text translation store 22 .From the source text and from the translations , candidate word generator 20 generates a set of candidate words consisting solely of words in the target language which are partial or full translations of words in the source text .", "label": "", "metadata": {}, "score": "93.76126"}
{"text": "A block diagram description of a Voice Phone 1400 is shown in FIG .14 .Implementation of an interface box 1406 is considered conventional and obvious to one skilled in the art .As an example of how the Voice Phone operates , consider the following : To call another extension in the same building , for example , say , \" INSIDE . . .", "label": "", "metadata": {}, "score": "93.78983"}
{"text": "12 shows two templates \" 4 \" and \" 5 \" ending at the same utterance frame k. The path 1202 of template \" 4 \" starts at frame i and the path 1204 of template \" 5 \" starts at frame i ' .", "label": "", "metadata": {}, "score": "93.890564"}
{"text": "I / O adapter 18 may be a small computer system interface ( SCSI ) adapter that communicates with the disk storage device 20 , i.e. a hard drive .Communications adapter 34 interconnects bus 12 with an outside network enabling the data processing system to communicate with other such systems over a local area network ( LAN ) or wide area network ( WAN ) , which includes , of course , the Internet .", "label": "", "metadata": {}, "score": "93.906006"}
{"text": "Wen , K.L. Grey systems modeling and prediction . ; Yang 's Scientific Research Institute : Tucson , AZ , USA , 2004 .[ Google Scholar ] .Wong , C.C. ; Chen , C.C. ; Lai , H.R. Fundamental method and applications of grey system . ; Gau - Lih : Taiwan , 2001 ; in Traditional Chinese .", "label": "", "metadata": {}, "score": "93.9132"}
{"text": "The value of PI varies while the cluster number is changing .Then , the optimal value of PI can be obtained .Thus , MUGCS can classify a data set to several clusters .Finally , MUGCA is executed to recognize the location and the spot number of each die ( cluster ) in this study .", "label": "", "metadata": {}, "score": "94.07057"}
{"text": "-Paste ( 3,12 ) .- Copy 2,6 ) .Score : Two hits , the same as the command \" paste \" received , for the associated terms : \" using the clipboard \" and \" clipboard \" for the same six points . -", "label": "", "metadata": {}, "score": "94.15272"}
{"text": "Joint Conf .AI Fuzzy Syst .Grey Syst .[ Google Scholar ] .Yang , C.M. ; Chen , J.C. ; Peng , L.L. ; Yang , J.S. ; Chou , C.H. Chi - Chi Earthquake - caused Landslide : grey prediction model for pioneer vegetation recovery monitored by satellite images .", "label": "", "metadata": {}, "score": "94.17268"}
{"text": "Another example , . \" OUTSIDE . . .278 . . .1234 \" .Response , \" 278 - 1234 CALLED \" .Most , if not all , one can do now by dialing a present phone can be done by talking to the Voice Phone of FIG .", "label": "", "metadata": {}, "score": "94.31957"}
{"text": "The HMM recognizer 203 also provides additional , context - dependent phone models , including \" tri - phone \" models , that represent each phone type when it is preceded and/or followed by particular other phone types .The HMM recognizer 203 also includes a pause phone which models pauses that occur during speech between words .", "label": "", "metadata": {}, "score": "94.38086"}
{"text": "Department of Mechatronic Engineering , Huafan University , Taipei , Taiwan .Received : 17 November 2007 / Accepted : 14 February 2008 / Published : 21 February 2008 .Abstract .:In this paper , a novel identification method based on a machine vision system is proposed to recognize the score of dice .", "label": "", "metadata": {}, "score": "94.39165"}
{"text": "In addition , the distinguishing coefficient \u03be is an adjustable parameter in MUGCA instead of a constant in UGCA .In this paper , we use MUGCA to identify several scattered dices in a bowl .The number of dice is assumed to be the expected cluster number ( EN ) .", "label": "", "metadata": {}, "score": "94.70741"}
{"text": "Fine match word recognition is performed in stage 26 .Unlike the word hypothesizer 14 , the word recognizer stage 26 uses the phoneme similarity time series directly in a frame - by - frame , dynamic programming match on the list of 5 word candidates given by the hypothesizer .", "label": "", "metadata": {}, "score": "95.01715"}
{"text": "In casinos the score of dice is generally obtained by visual inspection because of suspicions about the potential for cheating with electronic devices .Here , we propose an automated detection system with machine vision to execute such inspection .Machine vision is a powerful tool and is widely employed in automatic monitoring and detecting processes .", "label": "", "metadata": {}, "score": "95.405075"}
{"text": "TABLE I _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Alignment Memory System Error Rate Time Ratio Size Clean 20 dB 10 dB______________________________________Fine Match 100 % 600 5.8 7.2 11.2Hypothesizer 2.3 % 457 5.1 5.7 12.2Whole System 7.3 % 1057 4.0 4.4 7.9 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "95.678856"}
{"text": "[ 2 ] Next spoken input : \" How do I paste \" .Notes : The word \" paste \" in the input has now become firm .-Paste ( 1,6 ) .- Paste special ( 1,4 ) .", "label": "", "metadata": {}, "score": "95.76705"}
{"text": "j .k . ) min .min .i .j .I . min . k .K . i .j .k . )Indeed , \u03be is an adjustable parameter according to different demands and L is a constant .", "label": "", "metadata": {}, "score": "96.32509"}
{"text": "The acoustic model 505 in certain of these embodiments includes separate models of acoustic feature frames for each phone type .In a preferred embodiment , these models are HMM models from the HMM recognizer 203 used for segmentation .IV.A. Phone Log - Posterior Probability Scores .", "label": "", "metadata": {}, "score": "96.34262"}
{"text": "These operate through user interface 22 to call upon programs in RAM 14 cooperating with the operating system 41 to create the images in frame buffer 39 of display adapter 36 to control the display panels on monitor 38 .FIGS .", "label": "", "metadata": {}, "score": "96.731125"}
{"text": "TABLE 1 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ time t1 t2 t3 t4 t5 Feature Value 0.18 0.52 0.96 0.61 0.84 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "96.795044"}
{"text": "A remote controller controls transfer of data across the remote bus .The shared controller includes synchronization circuitry for synchronizing shared data bus requests with the timing of the local processor and priority circuitry to insure that the local processor always has access to the shared memory through the shared data bus without waiting .", "label": "", "metadata": {}, "score": "96.89817"}
{"text": "This invention was made in whole or in part with the use of Government funds from the Central Intelligence Agency under Contract 94-F130400 - 00 .The Government has certain rights in the invention .STATEMENT OF RELATED APPLICATIONS .", "label": "", "metadata": {}, "score": "97.26121"}
{"text": "The experimental parameters of \u03c9 and \u03be ca n't be adjusted in UGCA process automatically .Moreover , EN value is a convergence index and denotes the score of dice , but UGCA process is short of EN value .Therefore , the score of dice ca n't be found using UGCA correctly and flexibly .", "label": "", "metadata": {}, "score": "97.68541"}
{"text": "1234 \" .The response from the IW / CD is \" 1234 dialed \" .This lets you know that the correct number was dialed .Note , there is a pause between INSIDE and 1234 indicated by the . . .", "label": "", "metadata": {}, "score": "97.721634"}
{"text": "In embodiments of the present invention , the speech segmenter 203 segments the acoustic features 111 into acoustic segments which are phones .The speech segmenter 203 also identifies the type of each phone .The acoustic segmentation 205 includes segment information in the form of , for example , phone boundaries expressed as indices into the sequence of acoustic features 111 and phone type labels for each phone .", "label": "", "metadata": {}, "score": "98.72473"}
{"text": "The rotation matrix used in rotator 66 may be obtained , for example , by classifying into M classes a set of 189 dimension spliced vectors obtained during a training session .The inverse of the covariance matrix for all of the spliced vectors in the training set is multiplied by the within - sample covariance matrix for all of the spliced vectors in all M classes .", "label": "", "metadata": {}, "score": "98.868454"}
{"text": "State S4 is the last state of the command model and is the first state of the silence model .State S10 is the last state of the silence model .The silence match threshold is a tuning parameter which may be adjusted by the user .", "label": "", "metadata": {}, "score": "98.88079"}
{"text": "The acoustic match score generator 24 preferably generates two types of acoustic match scores : ( 1 ) a relatively fast , relatively less accurate acoustic match score , and ( 2 ) a relatively slow , relatively more accurate \" detailed \" acoustic : match score .", "label": "", "metadata": {}, "score": "99.25107"}
{"text": "FIG .4 is a diagram illustrating a portion of a maximum likelihood path 313 for sample input speech 107 in accordance with the invention .The input speech 107 is composed of its constituent words 403 , which are in turn broken down into constituent phones 205 , which are themselves broken down into constituent states 405 .", "label": "", "metadata": {}, "score": "99.35184"}
{"text": "Wong , C.C. ; Chen , C.C. Data clustering by grey relational analysis .J. Grey Syst .[ Google Scholar ] .Wong , C.C. ; Lai , H.R. A new grey relational measurement .J. Grey Syst .[ Google Scholar ] .", "label": "", "metadata": {}, "score": "99.97763"}
{"text": "This feature vector is augmented by a twenty - first dimension having a value equal to the square root of the sum of the squares of the values of the other twenty dimensions .For each centisecond time interval , a concatenator 64 preferably concatenates nine twenty - one dimension feature vectors representing the one current centisecond time interval , the four preceding centisecond time intervals , and the four following centisecond time intervals to form a single spliced vector of 189 dimensions .", "label": "", "metadata": {}, "score": "100.4232"}
{"text": "Deng , J.L. Control problems of grey systems .Syst .Control Lett .[ Google Scholar ] .Deng , J.L. Introduction to grey system theory .The Journal of Grey System 1989 , 1 ( 1 ) , 1 - 24 .", "label": "", "metadata": {}, "score": "100.62276"}
{"text": "[ 3 ] Next spoken input : \" How do I paste special \" .Notes : The phrase \" paste special \" is split with only \" paste \" being firm but \" special \" currently not yet firm .Results : . - Paste special ( 3,15 ) .", "label": "", "metadata": {}, "score": "100.75265"}
{"text": "The grammar 309 allows the pause phone to be skipped .The grammar 309 implements a skip as a transition arc which does not correspond to any outputted acoustic features .Grammars 309 and lexicons 307 together form a grammar network 310 that specifies allowable links between phones and , hence , allowable words and sentences .", "label": "", "metadata": {}, "score": "100.8287"}
{"text": "Copy ( 2,8 ) .Score : Two extra points for the same reason as the \" paste \" command . -Cut ( 2,8 ) .Score : Same as \" copy \" for the same reasons .-Undo ( 1,2 ) .", "label": "", "metadata": {}, "score": "100.9603"}
{"text": "3 , The HMM recognizer 203 accepts the acoustic features 111 .The HMM recognizer 203 includes hidden Markov models ( HMMs ) specified by the phone acoustic models 305 , the lexicon 307 , and the grammar 309 .An HMM search engine 311 within the HMM recognizer 203 computes a maximum likelihood path 313 .", "label": "", "metadata": {}, "score": "101.344666"}
{"text": "However , body - conducted speech had no formant frequencies which are characteristic of the Japanese vowels .Comparing Figures 11 and 12 , there was little difference in the frequency component .Particularly , as shown in Figure 12 , the difference of formant frequencies was minimal .", "label": "", "metadata": {}, "score": "101.350296"}
{"text": "An example of such a string might be \" using the clipboard \" , which has relationship with many clipboard functions .Firm words are given double the weight of infirm words .When searching through a relevant command table , exact matches for commands are counted twice .", "label": "", "metadata": {}, "score": "102.021545"}
{"text": "Keyboard 24 and mouse 26 are all interconnected to bus 12 through user interface adapter 22 .Audio output is provided by speaker 28 , and the speech input which is made through input device 27 which is diagrammatically depicted as a microphone that accesses the system through an appropriate interface adapter 22 .", "label": "", "metadata": {}, "score": "102.29576"}
{"text": "The grammar network 310 and the phone acoustic models 305 form a part of the speech models 117 ( of FIG .1 ) .All phone models 305 plus the lexicon 307 and the grammar 309 may be considered to be a vast virtual network called \" the HMMs \" or \" the recognition HMM .", "label": "", "metadata": {}, "score": "103.53783"}
{"text": "4 , of all proposed relevant commands and input text .Pressing button 74 or saying the command \" never mind \" causes the whole application to go away .The state of the panel in FIG .4 is the state after the spoken query \" How do I paste \" .", "label": "", "metadata": {}, "score": "103.9593"}
{"text": "TABLE 4 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Prototype Vector Rank Scores _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ time t1 t2 t3 t4 t5 Prototype Vector Identification Value P1 2 1 4 3 4 P2 3 1 3 1 3 P3 5 5 1 4 2 P4 4 3 2 2 1 P5 1 4 5 5 5 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "104.6066"}
{"text": "However , the grey relational coefficient r is always between 0 and 1 for any value of \u03be .The unsupervised grey clustering algorithm ( UGCA ) [ 7 ] is based on the grey relational analysis .The relational level is obtained according to the grey relation of data .", "label": "", "metadata": {}, "score": "105.15956"}
{"text": "Bull .Acad .Sin .[ Google Scholar ] .Figure 9 .Figure 9 .", "label": "", "metadata": {}, "score": "105.208496"}
{"text": "This patent application claims priority from U.S. Provisional Application Ser .No .60/027,638 , filed Oct. 2 , 1996 .The content of the provisional application is incorporated herein by reference .COPYRIGHT NOTICE .A portion of the disclosure of this patent document contains material which is subject to copyright protection .", "label": "", "metadata": {}, "score": "106.57018"}
{"text": "In order to acquire , a noisy environment , we used the engine room of the ' Oshima - maru ' training ship from the Oshima National College of Technology , Japan .Noise within the engine room , under the two conditions of anchorage and cruising , were 93 and 98 dB SPL , respectively , and the SNR measurements from microphone .", "label": "", "metadata": {}, "score": "110.016495"}
{"text": "Wiener 1 : differential acceleration using Wiener filtering that is repeated one time .Wiener 2 : differential acceleration using Wiener filtering that is repeated two times .Wiener 3 : differential acceleration using Wiener filtering that is repeated three times .", "label": "", "metadata": {}, "score": "110.431175"}
{"text": "In particular , in embodiments whose phone segmentation 205 expressly include phone durations , the acoustic unit duration extractor 207 simply uses the existing phone durations as the acoustic unit durations 209 .In embodiments whose phone segmentation 205 represents phone segmentation with only phone boundaries , the acoustic unit duration extractor 207 is an arithmetic subtractor that computes acoustic unit durations from the phone boundaries .", "label": "", "metadata": {}, "score": "114.37479"}
{"text": "Each 189 dimension spliced vector is preferably multiplied in a rotator 46 by a rotation matrix to rotate the spliced vector and to reduce the spliced vector to fifty dimensions .The rotation matrix used in rotator 46 may be obtained , for example , by classifying into M classes a set of 189 dimension spliced vectors obtained during a training session .", "label": "", "metadata": {}, "score": "115.83481"}
