{"text": "For clarity , the differences and their contributions among different evaluations are emphasized ( in Bold , compared with the left configuration ) .It shows that the POS tagger trained on the refined version of the BioCreative - POS corpus works better ( +0.40 ) than the POS tagger trained on the GENIA corpus V3.02p ( closed-2 vs. closed-1 ) .", "label": "", "metadata": {}, "score": "35.82607"}
{"text": "Web - scale experiments show that the DMV , perhaps because it is unlexicalized , does not benefit from orders of magnitude more annotated but noisier data .Our model , trained on a single blog , generalizes to 53.3 % accuracy out - of - domain , against the Brown corpus - nearly 10 % higher than the previous published best .", "label": "", "metadata": {}, "score": "36.98147"}
{"text": "We observe that the lists of extracted collocations on these two corpora differ markedly ( collocations were extracted with a threshold of 0.001 and 0.01 for TMI and PMI respectively ) .The PMI algorithm identified 15,814 collocations in the All Informative Notes corpus , and 2,527 in the Last Informative Notes corpus .", "label": "", "metadata": {}, "score": "39.10798"}
{"text": "Conventional wisdom is that larger corpora yield better results in text mining .But how does the observed EHR redundancy affect text mining ?Does such redundancy introduce a bias that distorts learned models ?Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?", "label": "", "metadata": {}, "score": "41.83341"}
{"text": "We therefore did not include FD modelling in the 1998 evaluation system .The soft - clustering technique developed at JHU [ 9 ] had shown worthwhile reductions in word error rate on the Switchboard corpus and we performed a preliminary evaluation on Broadcast News data .", "label": "", "metadata": {}, "score": "41.849472"}
{"text": "Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?( iii )How can one mitigate the impact of redundancy on text mining ?Before presenting results of our experiments and methods , we first review previous work in assessing redundancy in the EHR , two standard text - mining techniques of interest for data - driven disease modeling , and current work in how to mitigate presence of information redundancy .", "label": "", "metadata": {}, "score": "41.90355"}
{"text": "Our use of domain - specific dictionaries was less effective , giving an increase of only 0.5 in F - measure to 80.9(open division ) compared to the post - processing without dictionaries approach .Our conclusion is that either much more sophisticated algorithms that make use of dictionaries need to be employed , or the dictionaries themselves are not sufficient .", "label": "", "metadata": {}, "score": "42.498375"}
{"text": "One may ask , however , whether the fact that the sentences are repeated in EHR corpora reflects on their semantic importance from a clinical standpoint , and therefore , whether the collocations extracted from the full EHR corpus contain more clinically relevant collocations .", "label": "", "metadata": {}, "score": "42.84836"}
{"text": "However there is still much interest in reducing the error rate of such systems further which will increase the potential for further applications as well as establishing techniques for the accurate transcription of general audio material .The HTK Broadcast News Transcription System used in the 1997 DARPA / NIST Hub4 evaluation had an overall word error rate of 15.8 % .", "label": "", "metadata": {}, "score": "44.28424"}
{"text": "The first submission , the highest ranked constituency parsing system , uses a combination of PCFG - LA product grammar parsing and self - training .In the second submission , also a constituency parsing ... \" .The DCU - Paris13 team submitted three systems to the SANCL 2012 shared task on parsing English web text .", "label": "", "metadata": {}, "score": "44.509415"}
{"text": "The word error rate on BNeval97 of 14.3 % ( including FV and SAT ) represents a 13 % reduction relative to the same stage of the 1997 evaluation system [ 16 ] .We have recently experimented with discriminative training of large vocabulary systems and using the frame discrimination ( FD ) technique [ 13 ] .", "label": "", "metadata": {}, "score": "44.63481"}
{"text": "How can one mitigate the impact of redundancy on text mining ?Results .We analyze a large - scale EHR corpus and quantify redundancy both in terms of word and semantic concept repetition .We observe redundancy levels of about 30 % and non - standard distribution of both words and concepts .", "label": "", "metadata": {}, "score": "45.321117"}
{"text": "Most of the above papers reporting on the use of ML for WSD follow a similar pattern .A set of ambiguous words is selected , a corpus for each word is collected , and the different senses within the corpus are annotated ( automatically or manually ) .", "label": "", "metadata": {}, "score": "45.45752"}
{"text": "We compare the performance of standard algorithms for collocation identification and topic modeling inference on a variety of corpora with different redundancy levels .We introduce synthetic corpora where we can control the level of redundancy .These synthetic corpora are derived from the Wall Street Journal ( WSJ ) standard corpus .", "label": "", "metadata": {}, "score": "45.798386"}
{"text": "The results of high redundancy in patient notes are consistent with Wrenn et al .[14 ] observations on a similar EHR dataset .The contrast between same - patient and across - patient redundancy , however , is surprising given that the whole corpus is sampled from a population with at least one shared chronic condition .", "label": "", "metadata": {}, "score": "45.95028"}
{"text": "The fact that redundancy never occurs across patients , but within same - patient notes only , seems to create unintended biases in the extracted collocations .The results on the WSJ and its synthetic variants confirm our results on the EHR corpora : collocations extracted on a redundant corpus differ significantly from those extracted on a corpus of similar size without redundancy .", "label": "", "metadata": {}, "score": "45.965626"}
{"text": "The system takes the 1997 system and includes the additional acoustic training data in BNtrain98 ; cluster - based normalisation and VTLN ; the revised language modelling data and build procedure and full variance adaptation with SAT training .The word N - grams were trained by interpolating ( and merging ) component LMs trained on the acoustic transcriptions , the broadcast news texts and the newspaper texts .", "label": "", "metadata": {}, "score": "45.967865"}
{"text": "The redundant corpus , though 6.9 times larger , produces the same fit as the non - redundant corpus ( Last Informative Note ) .When applied to the synthetic WSJ corpora , we get a finer picture of the behavior of LDA under various corpora sizes and redundancy levels ( Figure 4 ) .", "label": "", "metadata": {}, "score": "46.196777"}
{"text": "In this scenario , we control for vocabulary : only word types that appear in the smaller corpus ( Last Informative Note ) are considered for collocations .To measure the impact of redundancy on the extracted collocations , for each collocation , we count the number of patients whose notes contain this collocation .", "label": "", "metadata": {}, "score": "46.441944"}
{"text": "This poorer performance was also reflected in the number of frames assigned to multiple speaker segments : 1.6 % for BNeval97 but 4.3 % for BNeval98 .This paper has described the development and performance of the 1998 HTK broadcast news transcription system .", "label": "", "metadata": {}, "score": "46.649822"}
{"text": "A similar pattern is observed at the bi - gram level ( a Zipfian distribution for the non - redundant corpus and a non - Zipfian distribution for the redundant corpus ) .Impact of redundancy on text mining .We have observed that redundant corpora exhibit different statistical profiles than non - redundant ones , according to their word occurrence distributions .", "label": "", "metadata": {}, "score": "46.94345"}
{"text": "WSJ data ( Petrov and Klein , 2007 ; Foster , 2010 ) .The parser uses the English signature list described in Attia et al ( 2010 ) to assign partof - speech tags to unknown words . \" ...Domain adaptation is an important task in order for NLP systems to work well in real applications .", "label": "", "metadata": {}, "score": "47.025238"}
{"text": "The results obtained when clustering the Yahoo !News corpus , both by our system and also by the baseline system , are significantly better when compared to the results obtained when clustering the Reuters - RCV1 corpus .There are no more instances of full recall and minimal precision as before , and the F - measure values show a definite increase .", "label": "", "metadata": {}, "score": "47.276207"}
{"text": "We subsequently based our assessment of performance on error rates and associated standard errors .Our method also differs from related work because the sample size for each sense is always fixed , whereas in related work the sample size for the entire corpus is generally fixed but not the sample sizes of the senses .", "label": "", "metadata": {}, "score": "47.51703"}
{"text": "Additional error analysis could be done on the output of the other systems .It may also be useful to combine the outputs of multiple taggers as well .The second aspect has to do with the use of dictionaries .Our system used a simple algorithm to exploit a single data resource from the NCBI .", "label": "", "metadata": {}, "score": "47.825947"}
{"text": ".. our corpus .The second question is how one can estimate NLP systems ' performance when gold standard on the test data does not exist .Our experiments show that the predicted scores are close to the real scores when tested on the CTB data .", "label": "", "metadata": {}, "score": "48.04917"}
{"text": "The use of the MSU Swb1 training transcriptions for language modelling purposes raised certain issues .First , the average sentence length was 11.3 words compared to 9.5 words on the LDC transcripts that we previously used .This has the effect that LMs trained on the MSU transcripts have a higher test - set perplexity which is mainly due to the reduced probability of the sentence - end symbol .", "label": "", "metadata": {}, "score": "48.101723"}
{"text": "Even more striking , when examining the behavior of WSJs5 ( with 3,300 documents sampled from 1,300 distinct documents ) up to 100 topics , we observe it reaches the same fit as WSJ-600 .We have seen that for the naturally occurring WSJ corpus training on more data produces better fit to held out data ( see Figure 4 a ) .", "label": "", "metadata": {}, "score": "48.13054"}
{"text": "Using all of the knowledge sources , the SVM method achieved the highest accuracy rate of 65.4 % .Another type of WSD approach uses established knowledge from curated terminology systems [ 23 , 24 ] .In the biomedical domain , Schijvenaars [ 13 ] developed a simple thesaurus - based algorithm to disambiguate human gene symbols using training data from PubMed abstracts and annotations from the Online Mendelian Inheritance in Man(OMIM )", "label": "", "metadata": {}, "score": "48.313004"}
{"text": "Note that the WSJs5 corpus has roughly 2.5 times the size of WSJ-1300 .The process was repeated 10 times to eliminate bias from the choice of documents repeated .Synthetic corpora with various levels of redundancy , for WSJs5 we report averages and standard deviation based on 10 replications .", "label": "", "metadata": {}, "score": "48.399387"}
{"text": "This is expected based on the definition of PMI , and we confirm this prediction on WSJx2 and WSJx3 which produce exactly the same list of collocations as WSJ-1300 ( WSJx2 is a corpus constructed by doubling every document in WSJ-1300 ) .", "label": "", "metadata": {}, "score": "48.588646"}
{"text": "We see that the significantly smaller Last Informative Note performs as well as All Informative Notes ( 8,557 notes vs. 1,247 ) while Reduced Redundancy Informative Notes ( 3,970 notes ) outperforms both .As we showed in Figure 4 a , we would expect a larger corpus to yield a better fit on the model : All Informative Notes is more than 7 times larger than Last Informative , still it yields the same fit on held out data .", "label": "", "metadata": {}, "score": "48.74613"}
{"text": "All Informative , input corpus , the corpus obtained by the redundancy reduction baseline ( Last Informative Note ) , and the corpora produced by the fingerprinting redundancy reduction strategy at different level .Computation time for constructing a redundancy - reduced corpus at a given similarity threshold using the selective fingerprinting is 6 minutes ( with an Intel Xeon CPU X5570 2.93 GHz ) .", "label": "", "metadata": {}, "score": "49.089714"}
{"text": "The results of this study raised four questions that we believe should be addressed in the near future - two general to the entire effort , and two specific to our system .First , it would have been useful to have an estimate of the upper bound on accuracy for any entity identification system trained on the BioCreAtIvE corpus , which is a function of how consistent and correct that data is .", "label": "", "metadata": {}, "score": "49.36358"}
{"text": "The WSJx2 corpus is constructed from WSJ-1300 to simulate redundancy , where each document of WSJ-1300 appears twice in the corpus .The WSJx3 corpus is similar to the WSJx2 corpus , except it contains three copies of each document in the WSJ-1300 corpus .", "label": "", "metadata": {}, "score": "50.007122"}
{"text": "We made a number of changes to these manual corrections and also automatically removed more than 30 hours of silence data at segment boundaries .An important feature of the MSU transcripts is the full - word transcription of false starts and mispronunciations .", "label": "", "metadata": {}, "score": "50.041245"}
{"text": "If words were not seen in the training data a uniform distribution over all pronunciation variants is assumed .However , this straight - forward implementation only brought moderate improvements in WER .The dictionaries in the HTK system explicitly contain silence models as part of a pronunciation .", "label": "", "metadata": {}, "score": "50.05181"}
{"text": "56 ] .The log - likelihood graphs were computed on withheld datasets .A non - redundant withheld dataset of 233 Informative notes was created for EHR corpus ( all the notes from the same patients were removed from the redundant corpora to prevent contamination between corpora and the withheld dataset ) .", "label": "", "metadata": {}, "score": "50.121487"}
{"text": "It can be seen that the new training corpus reduces the WER by a 0.7 % absolute and a further 0.5 % absolute reduction was obtained by using a merged interpolated language model .The merged interpolated models gave most improvement on the spontaneous speech portions of the data .", "label": "", "metadata": {}, "score": "50.393772"}
{"text": "We compare the results of these methods on synthetic data with controlled levels of redundancy and observe significant performance variation .Finally , we compare two mitigation strategies to avoid redundancy - induced bias : ( i ) a baseline strategy , keeping only the last note for each patient in the corpus ; ( ii ) removing redundant notes with an efficient fingerprinting - based algorithm .", "label": "", "metadata": {}, "score": "50.416218"}
{"text": "Model fit as function of number of topics on the WSJ corpora .In ( a ) we compare the effect of size on LDA , bigger corpora yield better fit .In ( b ) we examine the effect of redundancy : the doubled / trebled corpora reduce fit slightly while the noisier WSJs5 performs almost as badly as training on the smaller WSJ-600 corpus .", "label": "", "metadata": {}, "score": "50.473686"}
{"text": "View Article .Engelson SP , Dagan I : Minimizing manual annotation cost in supervised training from corpora .34th Annual Meeting of Association for Computational Linguistics 319 - 326 .Pustejovsky J , Castano J , Cochran B , Kotecki M , Morrell M : Automatic extraction of acronym - meaning pairs from MEDLINE databases .", "label": "", "metadata": {}, "score": "50.55816"}
{"text": "When we calculated the similarity of the documents in the Reuters - RCV1 corpus to their respective clusters , we found that these range from approximately 0.02 to near 0.55 with an average of less than 0.1 .Due to this overlap between these \" similarities \" and \" dis - similarities \" , one can not establish a clear similarity threshold that would warrant membership in the respective cluster .", "label": "", "metadata": {}, "score": "50.64965"}
{"text": "Furthermore , it is important to enhance the discrimination of the acoustic models without overly relying on the language model to resolve difficulties .Therefore as suggested in [ 15 ] a unigram language model was used during MMIE training which also improves generalisation performance [ 19 ] .", "label": "", "metadata": {}, "score": "50.924805"}
{"text": "We expect that the lower the similarity threshold , the lower the actual redundancy level of the resulting corpus ( in other words , we verify that our fingerprinting redundancy reduction algorithm effectively reduces redundancy ) .Descriptive statistics of reduced corpora .", "label": "", "metadata": {}, "score": "50.95359"}
{"text": "There is a growing need for techniques to handle this increasing flood of incoming data and avoid delay in its distribution [ 6 , 9 ] .The presence of online sources of data continuously streaming out new documents , such as news sites and blogs , necessitates the use of incremental document clustering systems [ 13 , 14 ] .", "label": "", "metadata": {}, "score": "51.010044"}
{"text": "This phenomenon also hampers the use of machine learning methods by preventing a good division of the data to non - overlapping test and train sets .Results and discussion .Quantifying redundancy in a large - scale EHR corpus .Word sequence redundancy at the patient level .", "label": "", "metadata": {}, "score": "51.210266"}
{"text": "News corpus .There were many cases where both the recall and precision scores are 1 .This means that in these cases , the produced clusters were identical to the reference clusters .There are very few cases where the recall or precision are low .", "label": "", "metadata": {}, "score": "51.24197"}
{"text": "The level of overall redundancy is significant and spread over many documents ( over a third ) .Concept redundancy at the corpus level .Since free - text notes exhibit high level of variability in their language , the redundancy measures may be different when we examine terms normalized against a standard terminology .", "label": "", "metadata": {}, "score": "51.50657"}
{"text": "The reduced bandwidth models are used for data classified as narrow band .The system uses the LIMSI 1993 WSJ pronunciation dictionary augmented by pronunciations from a TTS system and hand generated corrections for a 65k word vocabulary .The 1997 system used N - gram language models trained on 132 million words of broadcast news texts , the LDC - distributed 1995 newswire texts , and the transcriptions from BNtrain97 ( LMtrain97 ) .", "label": "", "metadata": {}, "score": "51.527817"}
{"text": "The reason behind this is that apart from exceptional cases , the similarity between a cluster and a non - member document never exceeds the minimum similarity between a cluster and its member documents .When clustering the Google News corpus , our Document Clustering component achieves an average recall of 0.7737 and average precision of 0.9120 .", "label": "", "metadata": {}, "score": "51.614586"}
{"text": "The shapes of the distributions of concepts differ depending on the presence of redundancy in the corpus .The difference in shapes of distributions confirms in a qualitative fashion our hypothesis about the three corpora and their varying levels of redundancy .", "label": "", "metadata": {}, "score": "51.665665"}
{"text": "In order to make it more convenient for users with an operating system earlier than Windows 2000 and without a language support pack to use our data , we have produced a Pinyin version of the LCMC corpus in addition to the standard version containing characters .", "label": "", "metadata": {}, "score": "51.767952"}
{"text": "Therefore , this type of method may not be applicable and ML approaches may be useful .Recently , Humphrey [ 26 ] proposed another type of statistical - based method to resolve the ambiguity problem within the UMLS Metathesaurus .They used a Journal Descriptor Indexing ( JDI ) method , which is ultimately based on statistical associations between words in a training set of MEDLNE citations and a small set of journal descriptors assumed to be inherited by the citations .", "label": "", "metadata": {}, "score": "52.01803"}
{"text": "The most successful scheme used three separate dictionary entries for each real pronunciation which differed by the word - end silence type : a no silence version ; adding a short pause preserving cross - word context ; and a general silence model altering context .", "label": "", "metadata": {}, "score": "52.184044"}
{"text": "This section gives an overview of the complete system as used in the March 2000 evaluation .The system operates in multiple passes through the data : initial passes are used to generate word lattices and then these lattices are rescored using four different sets of adapted acoustic models .", "label": "", "metadata": {}, "score": "52.309273"}
{"text": "On this synthetic corpus , we obtain a different list of collocations when using the PMI algorithm : 17,015(\u00b1950 ) instead of 2,737 .The growth in number of extracted collocations is expected since WSJs5 is 2.5 times larger than WSJ-1300 , but this growth is less than expected when comparing the trend ( WSJ-400 , WSJ-600 , WSJ-1300 ) with a growth of ( 565 , 1,000 and 2,737 ) extracted collocations .", "label": "", "metadata": {}, "score": "52.40935"}
{"text": "News corpus , and 0.0230 for the Reuters - RCV1 corpus ) .As expected , the results obtained by our modified system , where each document is clustered with the most similar category , are slightly better than the ones obtained by the original system .", "label": "", "metadata": {}, "score": "52.53838"}
{"text": "Baldridge J , Morton T , Bierner G : The opennlp maximum entropy package .[ Technical report , SourceForge ] .Teufel S , Elhadad N : Collection and Linguistic Processing of a Large - scale Corpus of Medical Articles .", "label": "", "metadata": {}, "score": "52.667786"}
{"text": "The baseline acoustic corpus available in 1997 used recorded audio from various US broadcast news shows ( television and radio ) .This amounted to a total of 72 hours of usable data ( BNtrain97 ) .This data was annotated to ensure that each segment was acoustically homogeneous ( same speaker , background noise condition and channel ) .", "label": "", "metadata": {}, "score": "52.67437"}
{"text": "The input , Full EHR corpus , is the largest .As expected , the Last Informative Note corpus obtained through our metadata - based baseline is the smallest corpus .While redundancy is reduced , its size is also drastically decreased from the original corpus .", "label": "", "metadata": {}, "score": "52.695087"}
{"text": "In this paper , we ask three research questions : ( i ) how can redundancy be quantified in large - scale text corpora ?( ii )Conventional wisdom is that larger corpora yield better results in text mining .But how does the observed text redundancy in EHR affect text mining ?", "label": "", "metadata": {}, "score": "52.74731"}
{"text": "This modified system was then used to cluster the Google News corpus .The comparison results are also found in Section 4.2 .Results .Table 1 shows a summary of the results obtained by our system and the baseline system when clustering the Reuters - RCV1 Corpus .", "label": "", "metadata": {}, "score": "52.780632"}
{"text": "The All EHR corpus , which contains all notes of all types , fits between these two extremes , since we expect less redundancy across note types , even for a single patient .One standard way of characterizing large corpora is to plot the histogram of terms and their raw frequencies in the corpus .", "label": "", "metadata": {}, "score": "52.812492"}
{"text": "Some of these were included in 1998 HTK Hub4 evaluation system .Other experiments which did n't lead to overall word error rate reductions include discriminative training using the frame discrimination method and use of the soft - clustering technique .The paper is arranged as follows .", "label": "", "metadata": {}, "score": "53.143864"}
{"text": "All of these features made a significant contribution to the word error rate improvements of the complete system .In addition , several minor changes have been made and these include the use of additional training data and revised transcriptions ; acoustic data weighting ; and an increased vocabulary size .", "label": "", "metadata": {}, "score": "53.289772"}
{"text": "Our study suggests that this would be helpful for improving recall at least modestly .Conclusion .The POS - tagging - based approach that we took from the ABGene system worked reasonably well .Post - processing rules , which included pattern - based rules , rules that used abbreviation recognition heuristics , and lexicon - based rules , worked well to increase both precision and recall .", "label": "", "metadata": {}, "score": "53.414864"}
{"text": "This paper identifies a characteristic of EHR text corpora : their inherent high level of redundancy , caused by the process of cut and paste involved in the creation and editing of patient notes by health providers .We empirically measure this level of redundancy on a large patient note corpus , and verify that such redundancy introduces unwanted bias when applying standard text mining algorithms .", "label": "", "metadata": {}, "score": "53.49394"}
{"text": "However as discussed in [ 16 ] this can be approximated by using a word lattice which is generated once to constrain the number of word sequences considered .This lattice - based framework can be used to generate the necessary statistics to apply the Extended - Baum Welch ( EBW ) algorithm [ 5 , 13 , 16 ] to iteratively update the model parameters .", "label": "", "metadata": {}, "score": "53.51435"}
{"text": "WSJx2 , WSJx3 , and WSJs5 are all larger in size than WSJ-1300 .We therefore would expect them to reach higher log - likelihood , but this does not occur .Instead , their log - likelihood graphs keep increasing as the number of topics increases , all the while remaining consistently inferior to the WSJ-1300 corpus , from which they are derived .", "label": "", "metadata": {}, "score": "53.558586"}
{"text": "Table 2 shows the number of clustered speech states and the number of Gaussians per state for each of these systems as well as word error rates on eval97sub .An initial 3.5-fold increase in the amount of training data results in a 4.6 % absolute reduction in word error rate ( WER ) .", "label": "", "metadata": {}, "score": "53.768684"}
{"text": "The performance improvements achieved by these two methods are significant for two reasons .First , it suggests that the phonologi- cal feature systems used here are not simply functionally equivalent representations leading to the same decoded phone sequences .In fact , based on the performance improvements obtained here , they in- deed appear to be complementary in the information that they repre- sent .", "label": "", "metadata": {}, "score": "53.874123"}
{"text": "Here , as others have done previously ( e.g. [ 15 ] ) , we experimented with building separate language models for each of the 3 data sources and then interpolating the language models .For efficiency and ease of use in decoding , a model merging process was employed using tools supplied by Entropic Ltd. , that gives a similar effect to explicit model interplotation but saves run - time computation and storage .", "label": "", "metadata": {}, "score": "53.961742"}
{"text": "Examination of how instances of word types are tagged in the training and devtest corpora 's lexicon revealed effective post - processing rules .For the lexicon - based post - processing steps , tag set 2 , which has detailed boundary information , is used .", "label": "", "metadata": {}, "score": "54.10849"}
{"text": "While this architecture results in a complex overall system , this section also reports the results of each of the stages .This allows the performance of many system variants at different levels of complexity to be assessed .The VTLN acoustic models used in the system were either triphones ( 6165 speech states/16 Gaussians per state ) or quinphones ( 9640 states/16 Gaussians per state ) trained on h5train00 .", "label": "", "metadata": {}, "score": "54.117054"}
{"text": "The second question is how one can estimate NLP systems ' performance when gold standard on the test data does not exist .To answer the question , we extend the parsing prediction model in ( Ravi et al . , 2008 ) to provide prediction for word segmentation and POS tagging as well .", "label": "", "metadata": {}, "score": "54.12481"}
{"text": "The LCMC corpus has been constructed using written Mandarin Chinese texts published in Mainland China to ensure some degree of textual homogeneity .It should be noted that plain written texts alone have been transcribed , with tables , illustrations , pictures , formulae and special symbols omitted and replaced with a gap element marked by the wording ' omission ' .", "label": "", "metadata": {}, "score": "54.130325"}
{"text": "We utilised three different corpora for our evaluation .The first corpus is the Reuters - RCV1 collection - this collection has been used in [ 13 , 25 ] and is the successor of the Reuters-21578 collection that was used in [ 3 , 4 , 7 , 17 ] .", "label": "", "metadata": {}, "score": "54.13591"}
{"text": "Bodenreider O : The unified medical language system ( UMLS ) : integrating biomedical terminology .Nucleic Acids Res 2004 , 32 : D267 .PubMed View Article .Gildea D : Corpus variation and parser performance .Citeseer ; 2001:167 - 202 .", "label": "", "metadata": {}, "score": "54.154892"}
{"text": "Since we do not require hierarchies , we did not consider the use of Hierarchical Clustering approaches since they have been reported to be slower than Partitional Clustering approaches [ 23 ] .Our clustering component is derived from the k - means Clustering algorithm , which is also used in [ 7 , 12 , 15 , 16 , 26 ] , but adapted to work in an incremental environment .", "label": "", "metadata": {}, "score": "54.28235"}
{"text": "Such differences among SVM , DHMM1 and DHMM2 mean that they complement each other , and show the potential for significant performance improvement via an ensemble .In addition , we also incorporate three post - processing modules : an abbreviation resolution module , a protein / gene name refinement module and a simple dictionary matching module , into the system to further improve the performance .", "label": "", "metadata": {}, "score": "54.315285"}
{"text": "Proc EMNLP 2002 , 41 - 48 .Mohammad S , Pedersen T : Combining lexical and syntactic features for supervised word sense disambiguation .Proc of the CoNLL .Wilks Y , Fass D , Guo C , MacDonald J , Plate T , Slator B : Providing Machine Tractable Dictionary Tools Cambridge , MA : MIT Press 1990 .", "label": "", "metadata": {}, "score": "54.318916"}
{"text": "News corpus , it obtains results that are comparable ( albeit poorer ) to the ones obtained by the baseline system .The difference in the results when processing these three corpora is due to the difference in the \" entropy \" of the data corpora .", "label": "", "metadata": {}, "score": "54.33393"}
{"text": "View Article PubMed .Maglott D , Ostell J , Pruitt KD , Tatusova T : Entrez Gene : Gene - centered information at NCBI .Nucleic Acids Res 2005 , 3 : D54-D58 .Yngve VH : Syntax and the problem of multiple meaning .", "label": "", "metadata": {}, "score": "54.35646"}
{"text": "Our method can produce corpora with different redundancy amounts quickly , without alignment of documents and without any prior knowledge of the documents .We confirmed that the parameter of our Selective Fingerprinting method is a good predictor of document alignment and can be used as the sole method for removing redundancy .", "label": "", "metadata": {}, "score": "54.400764"}
{"text": "In Section 6 , the performance of these combined models are summarized and compared to the first - level HMMs defined in Sec- tion 3.3 .The optimum phone sequences and lattices decoded by these new combined models are also used as another set of inputs to the system combination paradigm described in Section 5 . \" SYSTEM COMBINATION System combination techniques have been widely used in LVCSR for combining output word strings or word lattices obtained from multiple ASR systems [ 4].", "label": "", "metadata": {}, "score": "54.40246"}
{"text": "In this paper , we also demonstrated that ambiguity of biomedical entities is a significant problem , which has a substantial impact on text mining and retrieval tasks in the biomedical domain .ML methods are still needed for WSD , which is critical for increasing the accuracy of biomedical natural language , text mining , and information retrieval systems .", "label": "", "metadata": {}, "score": "54.413353"}
{"text": "This gave a new word list with 54,537 words where most of the pronunciations were already available in our broadcast news ( Hub4 ) dictionary .The 54k wordlist reduced the out - of - vocabulary ( OOV ) rate on eval98 from 0.94 % to 0.38 % .", "label": "", "metadata": {}, "score": "54.459007"}
{"text": "Table 8 provides descriptive statistics of the different WSJ - based corpora with which we experiment : .The WSJ-1300 corpus contains a random sample of 1,300 documents from the Wall Street Journal corpus , .The WSJ-400 corpus is a subset of WSJ-1300 of 400 documents , .", "label": "", "metadata": {}, "score": "54.554012"}
{"text": "Many studies have indeed shown that cross - domain learned corpora yield poor language models [ 35 ] .The field of domain adaptation attempts to compensate for the poor quality of cross - domain data , by adding carefully picked text from other domains [ 36 , 37 ] or other statistical mitigation techniques .", "label": "", "metadata": {}, "score": "54.557877"}
{"text": "ABSTRACT .This paper presents the development of the HTK broadcast news transcription system for the November 1998 Hub4 evaluation .Overall these changes to the system reduced the error rate by 13 % on the 1997 evaluation data and the final system had an overall word error rate of 13.8 % for the 1998 evaluation data sets .", "label": "", "metadata": {}, "score": "54.583145"}
{"text": "To understand this discrepancy , we examine the topics obtained on the redundant corpora qualitatively .Topics are generated by LDA as ranked lists of words .Once a topic model is applied on a document , we can compute the topic assignment for each word in the document .", "label": "", "metadata": {}, "score": "54.681335"}
{"text": "The main variations are usually in the selection of features and choice of machine - learning algorithms .Experiments are usually performed on a fixed amount of documents ( i.e. 1,000 abstracts ) per an ambiguous word , where the entire set consists of all the senses , and the sense distribution is generally uneven .", "label": "", "metadata": {}, "score": "54.778225"}
{"text": "The LCMC corpus was built in response to the general lack of publicly available balanced corpora of Chinese .While there are some corpus resources , most of them , for example , the PH Corpus and the PFR People 's Daily Corpus released by the Institute of Computational Linguistics , Peking University , are composed exclusively of newswire texts and are thus not balanced .", "label": "", "metadata": {}, "score": "54.935593"}
{"text": "Finally , we decided to use a different ( though similarly sized ) portion of newspaper texts covering 1995 to February 1998 ( about 70MW in total ) .All these sources excluded data from the designated test epochs .This corpus was denoted LMtrain98 .", "label": "", "metadata": {}, "score": "54.97355"}
{"text": "Considering the availability of texts of some categories , we decided to modify the FLOB sampling period slightly by also including some samples in \u00b12 years of 1991 when there were not enough samples readily available for 1991 .As a result , of the 500 samples included in the LCMC corpus , around two thirds were produced in 1991 while the other one third produced within two years of 1991 .", "label": "", "metadata": {}, "score": "55.038063"}
{"text": "81 , pp .92 - 93 , 1987 .[ 12 ] H. Hermansky , D. Ellis , and S. Sharma , \" Tandem connection- ist feature stream extraction for conventional HMM systems , \" Proc .Int .Conf . on Acoust . , Speech , and Sig .", "label": "", "metadata": {}, "score": "55.087116"}
{"text": "We study this problem as a new task - multiple source parser adaptation .Our system trains on corpora from many different domains .It learns not only statistics of those domains but quantitative measures of domain differences and how those differences affect parsing accuracy .", "label": "", "metadata": {}, "score": "55.098335"}
{"text": "Such lexicon compilation requires highly reliable predicate - argument structures to practically contribute to Natural Language Processing ( NLP ) applications , such as paraphrasing , text entailment , and machine translation .We first apply chunking to raw corpora and then extract reliable chunks to ensure that high - quality predicate - argument structures are obtained from the chunks .", "label": "", "metadata": {}, "score": "55.162422"}
{"text": "We present a method for acquiring reliable predicate - argument structures from raw corpora for automatic compilation of case frames .Such lexicon compilation requires highly reliable predicate - argument structures to practically contribute to Natural Language Processing ( NLP ) applications , such as par ... \" .", "label": "", "metadata": {}, "score": "55.256348"}
{"text": "[ Google Scholar ] .Surdeanu , M. ; Turmo , J. ; Ageno , A. A Hybrid Unsupervised Approach for Document Clustering .In KDD ' 05 : Proceedings of the Eleventh ACM SIGKDD International Conference On Knowledge Discovery in Data Mining , Chicago , IL , USA , 21 - 24 August 2005 ; ACM : New York , NY , USA , 2005 ; pp .", "label": "", "metadata": {}, "score": "55.2692"}
{"text": "Figure 1 further details the full histogram of redundancy for pairs of same - patient informative notes .The redundancy ( percentage of aligned tokens ) was computed for the notes of a random sample of 100 patients .For instance , it indicates that 7.6 % of the same patient note pairs in the corpus have between 20 % and 30 % identity .", "label": "", "metadata": {}, "score": "55.301125"}
{"text": "Liu H , Johnson SB , Friedman C : Automatic resolution of ambiguous terms based on machine learning and conceptual relations in the UMLS .J Am Med Inform Assoc 2002 , 9 : 621 - 636 .View Article PubMed .", "label": "", "metadata": {}, "score": "55.53324"}
{"text": "The premise of this paper is that it may be possible to exploit com- plementary aspects of different phonological feature systems for de- coding a sequence of phone labels from speech .Phonological feature based phone recognition was performed in [ 1 ] using an HMM based phoneme recognizer whose distribu- tions were defined over estimates of the posterior probabilities of phonological distinctive features .", "label": "", "metadata": {}, "score": "55.53759"}
{"text": "Comparison of extracted collocations on synthetic redundant corpora and non - redundant corpora ( WSJ - X words / Y distinct words ) .Collocations were extracted using using True Mutual Information and Pointwise Mutual Information ( with cutoffs of 0.001 and 0.01 respectively ) .", "label": "", "metadata": {}, "score": "55.594765"}
{"text": "X. Luo of JHU supplied code to help with the soft - clustering experiments .Fiscus , J.G. ( 1997 )A Post - Processing System to Yield Reduced Word Error Rates : Recogniser Output Voting Error Reduction ( ROVER ) .", "label": "", "metadata": {}, "score": "55.734158"}
{"text": "This lack of consistency explains the confusion and consequently low performance achieved by LDA on redundant corpora .Mitigation strategies for handling redundancy .Given a corpus with inherent redundancy , like the EHR corpus , the basic goal of redundancy mitigation is to choose the largest possible subset of the corpus with an upper bound on the amount of redundancy in that subset .", "label": "", "metadata": {}, "score": "55.747772"}
{"text": "View Article .Pedersen T , Bruce R : Distinguishing word senses in untagged text .Second Conference on Empirical Methods in Natural Language Processing .Hsu G , Lin C : A comparison of methods for multi - class support vector machines .", "label": "", "metadata": {}, "score": "55.778107"}
{"text": "The three phonological feature based ASR systems were trained using the estimates of the posterior probabilities obtained from the feature based TDNNs described in Section 3.1 transformed as described in Section 3.2 .The phone accuracy obtained for feature based and MFCC based systems is summarized in Section 6 .", "label": "", "metadata": {}, "score": "55.818325"}
{"text": "The main steps performed by our clustering system are shown in Figure 1 .Our clustering system obtains its source news reports via the RSS feeds .The RSS feeds from the selected sources are downloaded periodically and parsed .The relevant news reports are then downloaded , if they had not already been downloaded previously , and cleaned from the surrounding text and HTML code in such a way that only the news report content remains as simple text .", "label": "", "metadata": {}, "score": "55.823997"}
{"text": "Based on a pilot study of the ratio of words to characters , we decided to adopt a ratio of 1:1.6 , which means that we needed a 3,200-character running text for a 2,000-word sample .When a text was less than the required length , texts of similar quality were combined into one sample .", "label": "", "metadata": {}, "score": "55.846367"}
{"text": "We developed a fast implementation technique to make FD training on large HMM sets practical and on the WSJ / NAB task FD gives similar reductions in word error rate ( about 5 % relative ) to lattice - based MMIE with a much smaller computational cost .", "label": "", "metadata": {}, "score": "55.863857"}
{"text": "More recently , Perotte et al .leveraged topic models in a supervised framework for the task of assigning ICD-9 codes to discharge summaries [ 29 ] .There , the input consisted of the words in the discharge summaries and the hierarchy of ICD-9 codes .", "label": "", "metadata": {}, "score": "55.87581"}
{"text": "We show that this algorithm does not require the slower alignment stage of BLAST and that it accurately identifies instances of copy - paste operations .Text mining techniques .We review two established text - mining techniques : collocation identification and topic modeling .", "label": "", "metadata": {}, "score": "55.913017"}
{"text": "News corpus , our clustering system can achieve significantly better results than when clustering the Reuters - RCV1 corpus .However , the results obtained are still lower than the baseline , and therefore , one may conclude that our clustering component is not optimal for the clustering of documents into general categories .", "label": "", "metadata": {}, "score": "55.979225"}
{"text": "There are several observations that can be made from Table 3 and from comparing the performance of the systems shown in Ta- bles 2 and 3 .It is clear from rows two through four of Table 3 that feature integration of a single PDF with MFCC based ASR results in substantial improvement in PAC with respect to the MFCC base- line system .", "label": "", "metadata": {}, "score": "55.99645"}
{"text": "Similar methods are also applied in [ 14 , 20 ] .Luo [ 14 ] further adapts the k - means clustering algorithm to First Story Detection in a resource - adaptive manner for large - scale processing scenarios .Less important documents are dropped from the main document queue and placed in a lower priority queue whenever the system becomes overloaded .", "label": "", "metadata": {}, "score": "56.070866"}
{"text": "It was shown that reasonable frame level speaker independent phone classification accuracy could be obtained for each of these feature representations by using neural network ( NN ) based feature detectors .These detec- tors were trained from canonical feature labels obtained from phone- mically labeled speech utterances [ 10].", "label": "", "metadata": {}, "score": "56.128716"}
{"text": "809 - 814 .[ Google Scholar ] .Azzopardi , J. ; Staff , C. Automatic Adaptation and Recommendation of News Reports using Surface - Based Methods .In PAAMS ' 12 ( Special Sessions ) : Proceedings of the 10th International Conference on Practical Applications of Agents and Multi - Agent Systems , Salamanca , Spain , 28 - 30 March 2012 ; Springer - Velag : Berlin / Heidelberg , Germany , 2012 ; pp .", "label": "", "metadata": {}, "score": "56.1941"}
{"text": "All CNC system combination experiments were per- formed with the help of the SRI LM Toolkit[16].REFERENCES [ 1 ] Simon King and Paul Taylor , \" Detection of phonological fea- tures in continuous speech using neural networks , \" Computer Speech and Language , vol .", "label": "", "metadata": {}, "score": "56.227524"}
{"text": "News corpus .In this corpus , there is still a significant overlap for similarities between clusters and their constituent documents , and between clusters and non - member documents .However , since this overlap is less than in the case of the Reuters - RCV1 corpus , a similarity threshold can be selected that can be reasonably effective .", "label": "", "metadata": {}, "score": "56.31028"}
{"text": "We focus on copy - and - paste redundancy : clinicians typically copy and paste information from previous notes when documenting a current patient encounter .Thus , within a longitudinal patient record , one expects to observe heavy redundancy .In this paper , we ask three research questions : ( i ) How can redundancy be quantified in large - scale text corpora ?", "label": "", "metadata": {}, "score": "56.366207"}
{"text": "Int .Conf . on \" Incorporating voice onset time Acoust . , Speech , and Sig .Processing , vol .1 , pp .13 - 16 , March 1998 .[ 8 ] K. Kirchhoff , G. Fink , and G. Sagerer , \" Conversational speech recognition using acoustic and articulatory input , \" Proc .", "label": "", "metadata": {}, "score": "56.36863"}
{"text": "Earlier studies have investigated a number of the issues discussed here in the context of constructing better classifiers .A discussion of some of the issues involved can be found in [ 43 ] .Here , we examined these issues in the context of word sense disambiguation .", "label": "", "metadata": {}, "score": "56.386826"}
{"text": "[ Google Scholar ] .Steinbach , M. ; Karypis , G. ; Kumar , V. A Comparison of Document Clustering Techniques .In Proceedings of the KDD Workshop on Text Mining , Boston , MA , USA , 20 - 23 August 2000 .", "label": "", "metadata": {}, "score": "56.450848"}
{"text": "ICASSP'98 , pp .177 - 180 , Seattle .S.J. Young , J.J. Odell & P.C. Woodland ( 1994 ) .Tree - Based State Tying for High Accuracy Acoustic Modelling .[ ps ] [ pdf ] Proc .1994 ARPA Human Language Technology Workshop , pp .", "label": "", "metadata": {}, "score": "56.61073"}
{"text": "[ Google Scholar ] .Borko , H. ; Bernick , M. Automatic document classification .J. ACM 1963 , 10 , 151 - 162 .[ Google Scholar ] [ CrossRef ] .Larsen , B. ; Aone , C. Fast and Effective Text Mining Using Linear - Time Document Clustering .", "label": "", "metadata": {}, "score": "56.657417"}
{"text": "The Last Informative Note corpus is a subset of All Informative Notes , and contains only the most recent note for each patient .Synthetic WSJ redundant corpora .We construct synthetic corpora with a controllable level of redundancy to compare the behavior of the text mining methods on various levels of redundancy .", "label": "", "metadata": {}, "score": "56.832092"}
{"text": "In our opinion , an index built from 70 news reports provides ample indication of which terms are important , and which terms are common throughout the entire collection .The clustering of these 70 documents proceeds normally with the sole exception that the global index is not re - updated whilst the clustering of these 70 documents is being performed .", "label": "", "metadata": {}, "score": "57.00181"}
{"text": "As one can note , there is a significant difference between these two results .The results obtained show that our clustering system is very effective in clustering news reports into event - centric clusters .However , its use for the classification of documents or news reports into more general clusters is not recommended .", "label": "", "metadata": {}, "score": "57.09581"}
{"text": "In this paper , we focused on intrinsic , quantitative evaluations to assess the impact of redundancy on two text - mining techniques .Qualitative analysis as well as task - based evaluations are needed to get a full understanding of the role of redundancy in clinical notes on text - mining methods .", "label": "", "metadata": {}, "score": "57.142456"}
{"text": "Second , Section 6.2 presents the performance obtained by combining these feature based phone recognizers with a \" traditional \" MFCC based phonerecognizerusingthesystemcombinationtechniquesfromSec- tion 5 .Finally , the performance of the lattice re - scoring approach is described in Section 6.3 where discriminative model combination ( DMC ) is used to estimate the weights of the log linear model for feature integration described in Section 4 .", "label": "", "metadata": {}, "score": "57.171814"}
{"text": "We focus on the All Informative Notes corpus .The metadata - based baseline produces the Last Informative Note corpus .The content - based mitigation strategy , which relies on fingerprinting , can produce corpora with varying levels of redundancy .", "label": "", "metadata": {}, "score": "57.172874"}
{"text": "Since the stream of news reports never terminates , cluster reorganisation is not feasible unlike the \" standard \" k - means algorithm .On the other hand , in cases where the requested output clusters are more generic - e.g . , clustering all news reports about sports , our system obtains worse results than the baseline system ( the standard k - means system ) .", "label": "", "metadata": {}, "score": "57.22975"}
{"text": "Previously , using an implementation from JHU , the technique was investigated using various training set sizes and levels of model complexity [ 7 ] .It was found that while consistent improvements were obtained , the improvement in WER was reduced when features such as VTLN and MLLR adaptation were included in the system .", "label": "", "metadata": {}, "score": "57.277122"}
{"text": "We investigate whether a redundant corpus exhibits a different distribution of concepts than a less redundant one .We expect that different subsets of the EHR corpus exhibit different levels of redundancy .The All Informative Notes corpus , which contains several notes per patient , but only the ones of types : \" primary - provider \" , \" clinical - note \" and \" follow - up - note \" , is assumed to be highly redundant , since it is homogeneous in style and clinical content .", "label": "", "metadata": {}, "score": "57.42447"}
{"text": "The primary focus for research and development of such systems for US English has been the Switchboard / Call Home English corpora along with the regular NIST ' ' Hub5 ' ' evaluations .The Cambridge University HTK ( CU - HTK ) Hub5 system has been developed over several years .", "label": "", "metadata": {}, "score": "57.495308"}
{"text": "These lattices were expanded expanded to contain language model probabilities generated by the interpolation of the word 4-gram and the class trigram .Subsequent passes rescored these lattices and operated in two branches : a branch using GI MMIE trained models ( branch ' ' a ' ' ) and a branch using GD , soft - tied , MLE models ( branch ' ' b ' ' ) .", "label": "", "metadata": {}, "score": "57.60341"}
{"text": "Stage P2 used MMIE GI triphones to generate the transcriptions for unsupervised test - set MLLR adaptation [ 8 , 3 ] with a 4-gram LM .A global transform ( A ' ' global transform ' ' denotes one transform for speech and a separate transform for silence . ) for the means ( block - diagonal ) and variances ( diagonal ) was computed for each side .", "label": "", "metadata": {}, "score": "57.619225"}
{"text": "Full - text .Three different feature systems , differing in their structure and in the acoustic phonetic features they represent , are considered .A two stage process involving a mechanism for frame level phono- logical feature detection and a mechanism for decoding phoneme sequences from features is implemented for each phonological fea- ture system .", "label": "", "metadata": {}, "score": "57.62139"}
{"text": "In addition , papers should also characterize the difficulty of the WSD task , the WSD situations addressed and not addressed , as well as the ML methods and features used .This should lead to an improved understanding of the generalizablility and the limitations of the methodology .", "label": "", "metadata": {}, "score": "57.63772"}
{"text": "See Table 2 .The second type of error , loss of signal can also be observed .Another method for selecting the significant collocations is using a top - N cutoff instead of a PMI cutoff .Comparing the top 1,000 collocations with TMI for All Informative Notes and Last Informative Notes , we find a marked difference of 196 collocations .", "label": "", "metadata": {}, "score": "57.697193"}
{"text": "Therefore , this system can not employ complex linguistic models or use multi - pass clustering approaches , as these will result in higher processing times that are not feasible in our operational environment .Also , cluster re - organisation is not possible , since it will result in an interruption of the operational system .", "label": "", "metadata": {}, "score": "57.770393"}
{"text": "We artificially introduce redundancy by randomly sampling documents and repeating them until a controlled level of redundancy is achieved .Collocation identification .We expect that in a redundant corpus , the word sequences ( n - grams ) which are copied often will be over - represented .", "label": "", "metadata": {}, "score": "57.819984"}
{"text": "The reason that DHMM1 performs differently to DHMM2 may be due to that the refined BioCreative - POS corpus restricts much more on the NNP POS and has much less NNP POS - tagged words than the unrefined BioCreative - POS corpus .", "label": "", "metadata": {}, "score": "57.8362"}
{"text": "In the highly - redundant All Informative Notes corpus , the peak is the most pronounced , with more concepts occurring four to eight times in the corpus than once .Concept - distribution .Distribution of UMLS concept occurrences in corpora with different levels of redundancy .", "label": "", "metadata": {}, "score": "57.854477"}
{"text": "Figure 2 shows the distribution of UMLS concepts ( CUI ) frequencies in the three corpora with expected decreasing levels of redundancy : the All Informative Notes corpus , the All Notes corpus , and the Last Informative Note Corpus .We observe that the profile in the non - redundant Last Informative Note corpus differs markedly from the ones of the redundant corpora ( All Notes and All Informative Notes ) .", "label": "", "metadata": {}, "score": "57.860474"}
{"text": "To compensate for these issues , logarthmic amplitude compression and feature space rotation is ap- plied to these vectors .To reduce the dynamic range of the phonological feature values , a logarithmic compression was applied to the posterior values at the output of TDNNs .", "label": "", "metadata": {}, "score": "57.889122"}
{"text": "They reported an F - measure of over 0.7 for genes with sufficient number of known document references .Liu [ 29 ] investigated the effect of window size and claimed that biomedical ambiguous words needed a larger window size than general English ambiguous words .", "label": "", "metadata": {}, "score": "57.951427"}
{"text": "For example , it can be applied successfully to the clustering of social media feeds to produce clusters according to the item being discussed by the different people .References .Azzopardi , J. ; Staff , C. Fusion of News Reports Using Surface - Based Methods .", "label": "", "metadata": {}, "score": "57.984615"}
{"text": "Moreover , it shows that our system benefits very much from the post - processing modules , such as abbreviation resolution and name refinement .Finally , it shows that the dictionary matching module using a very big open dictionary decreases the performance .", "label": "", "metadata": {}, "score": "58.14042"}
{"text": "This is also of assistance to users who can read Romanised Chinese but not Chinese characters .Both versions of the corpus come in fifteen files .The corpus is XML conformant .Each file has two parts : a corpus header and text .", "label": "", "metadata": {}, "score": "58.21891"}
{"text": "Fingerprinting algorithm .Detecting redundancy within the notes of a single patient is feasible using standard alignment methods borrowed from bioinformatics such as : Smith - Waterman [ 52 ] , FastA [ 41 ] or Blast2seq [ 40 ] .However , some available EHR corpora are de - identified to protect patient privacy [ 57 ] and notes are not grouped by patients .", "label": "", "metadata": {}, "score": "58.233402"}
{"text": "Furthermore while the overall performance of the system is significantly enhanced by the use of MMIE models , the complete pure MLE system achieves a 36.8 % WER on eval98 .This paper has discussed the substantial improvements in system performance that have been made to our Hub5 transcription system since the 1998 evaluation .", "label": "", "metadata": {}, "score": "58.2686"}
{"text": "Here , the ensemble is constructed using a simple majority voting strategy .Among the three classifiers , the only difference between the two DHMMs comes from the part - of - speech ( POS ) features , which are trained on different corpora .", "label": "", "metadata": {}, "score": "58.276474"}
{"text": "In addition to monolingual studies of the Chinese language , LCMC , in combination with FLOB , is also a sound basis for contrastive studies of Chinese and English , whether one wishes to compare the two languages as a whole or compare them by text type .", "label": "", "metadata": {}, "score": "58.40787"}
{"text": "Computational linguistics 2003 , 29 ( 3 ) : 333 - 347 .View Article .Atterer M , Sch tze H : The effect of corpus size in combining supervised and unsupervised training for disambiguation .Association for Computational Linguistics ; 2006:25 - 32 .", "label": "", "metadata": {}, "score": "58.440056"}
{"text": "Conclusion .Several different independent aspects affect performance when using ML techniques for WSD .We found that combining them into one single result obscures understanding of the underlying methods .Although we studied only four abbreviations , we utilized a well - established statistical method that guarantees the results are likely to be generalizable for abbreviations with similar characteristics .", "label": "", "metadata": {}, "score": "58.72035"}
{"text": "However , although there are several phonological feature sets based on different linguistic theories , it is not clear whether any of them could be considered as the best design for the detection - based ASR task [ 6].Therefore , instead of building a detection - based ASR system by randomly selecting one of the phonological feature sets , it would be better to consider each of them before constructing a detection - based ASR system .", "label": "", "metadata": {}, "score": "58.75183"}
{"text": "However , the inclusion of the MLE system outputs gives a 0.2 % WER absolute improvement .The final error rate from the system ( 25.4 % ) was lowest in the evaluation by a statistically significant margin .A further run on eval98 was performed to investigate the effect of using a combined MMIE / MLE system .", "label": "", "metadata": {}, "score": "58.755127"}
{"text": "16 - 22 .[ Google Scholar ] .Stavrianou , A. ; Andritsos , P. ; Nicoloyannis , N. Overview and semantic issues of text mining .SIGMOD Rec .[ Google Scholar ] [ CrossRef ] .Viles , C.L. ; French , J.C. On the Update of Term Weights in Dynamic Information Retrieval Systems .", "label": "", "metadata": {}, "score": "58.83084"}
{"text": "It can serve as an intermediate step to perform other tasks [ 8 ] .The main justification behind the need for automatic document clustering systems is the information overload problem [ 4 , 6 , 7 , 9 , 10 , 11 , 12 , 13 ] .", "label": "", "metadata": {}, "score": "58.841404"}
{"text": "Redundancy across two documents may be measured in different manners : shared words , shared concepts or overlapping word sequences .The most stringent method examines word sequences , and allows for some variation in the sequences ( missing or changed words ) .", "label": "", "metadata": {}, "score": "58.946793"}
{"text": "Conf . on Acoust . , Speech , and Sig .Processing , pp .1435 - 1438 , June 2000 .[ 9 ] J. Morris and E. Fosler - Lussier , \" Further experiments with detector - based conditional random fields in phonetic recog- nition , \" in Proceedings of the International Conference on Acoustic , Speech , and Signal Processing , Honolulu , Hawaii , 2007 .", "label": "", "metadata": {}, "score": "58.957214"}
{"text": "The advantage of this approach is that one does not need to have the entire document collection at hand to weight the documents ' index terms .Wang [ 19 ] utilises an incremental version of the TF.IDF , whereby the term frequency of a word is determined based on the number of times the word appears until a particular time , and the number of times this same term appears in the newly appearing stories .", "label": "", "metadata": {}, "score": "59.113686"}
{"text": "It can be seen that there is a rather different distribution data type between the two sets : particularly for F0 , F2 , F4 and FX .The HTK Broadcast News system runs in a number of stages .This is followed by generating a lattice for each segment using the adapted triphone models with a bigram LM , expanding these lattices using a word 4-gram interpolated with a category trigram LM , and performing iterative lattice rescoring and MLLR adaptation with a set of quinphone HMMs .", "label": "", "metadata": {}, "score": "59.16533"}
{"text": "The HMMs were trained on 180 hours of Hub5 training data .The system used a 27k vocabulary that covered all words in the acoustic training data .The core of the pronunciation dictionary was based on the 1993 LIMSI WSJ lexicon , but used a large number of additions along with various changes .", "label": "", "metadata": {}, "score": "59.300713"}
{"text": "Our study is different because it quantified the effect of similarity of senses , and studied the relation between \" similarity of senses \" and other issues such as \" sample size \" and \" sense distribution \" .Podowski 's [ 28 ] work covered task types 2 and 3 , while Hatzivassiloglou 's [ 10 ] work addressed task type 4 .", "label": "", "metadata": {}, "score": "59.35946"}
{"text": "We present a number of semi - supervised parsing experiments on the Irish language carried out using a small seed set of manually parsed trees and a larger , yet still relatively small , set of unlabelled sentences .We take two popular dependency parsers - one graph - based and one transition - based - and ... \" .", "label": "", "metadata": {}, "score": "59.37214"}
{"text": "Furthermore the 1998 4-gram language model gave a constant 15 % improvement ( over all test sets ) in perplexity over the equivalent model used in the 1997 evaluation .The overall decoding process proceeds as for the 1997 system , but with a couple of additional stages .", "label": "", "metadata": {}, "score": "59.38482"}
{"text": "The filtered corpus ( where the reports belonging to more than one category have been removed ) contains 26,310 news reports classified into 78 categories .The second corpus is the Yahoo !News collection - a collection of news reports downloaded via the RSS feeds provided by the Yahoo !", "label": "", "metadata": {}, "score": "59.509544"}
{"text": "The third corpus is the Google News collection - this is a collection of news reports download via the RSS feeds provided by Google News .These news reports are clustered according to the event that they describe .Therefore , the clustering in this dataset is much finer than the categories in the other datasets .", "label": "", "metadata": {}, "score": "59.541576"}
{"text": "The final system is trained on the combined official training and dry - run data ( 10000 sentences ) .All the open and closed evaluations are done on the official test data ( 5000 sentences ) using the precision / recall / F - measure .", "label": "", "metadata": {}, "score": "59.67104"}
{"text": "We utilised three different datasets of clustered news reports , and we compared how close the clusters produced by our system are to the clusters in these datasets .We then repeated the evaluation using a baseline system .The metrics generally used for clustering evaluation are the recall , precision and F - measure - metrics that have been adapted from Information Retrieval .", "label": "", "metadata": {}, "score": "59.678303"}
{"text": "More recently , supervised machine learning ( ML ) technologies have received considerable attention and have shown promising results [ 16 - 18 ] .Bruce [ 19 ] applied a Bayesian algorithm and chose features based on their \" informative \" nature .", "label": "", "metadata": {}, "score": "59.694145"}
{"text": "Table 3 shows word error rates using triphone HMMs trained on h5train00 .These experiments required the generation of numerator and denominator lattices for each of the 267,611 training segments .It was found that two iterations of MMIE re - estimation gave the best test - set performance [ 19 ] .", "label": "", "metadata": {}, "score": "59.71363"}
{"text": "EHR corpora , however , exhibit specific characteristics when compared with corpora in the biomedical literature domain or the general English domain .This paper is concerned with the inherent characteristics of corpora composed of longitudinal records in particular and their impact on text - mining techniques .", "label": "", "metadata": {}, "score": "59.720955"}
{"text": "Based on careful error analysis , we implemented a set of post - processing rules to correct both false positives and false negatives .We participated in both the open and the closed divisions ; for the open division , we made use of data from NCBI .", "label": "", "metadata": {}, "score": "59.745575"}
{"text": "In the second submission , also a constituency parsing system , the n - best lists of various parsing models are combined using an approximate sentence - level product model .The third system , the highest ranked system in the dependency parsing track , uses voting over dependency arcs to combine the output of three constituency parsing systems which have been converted to dependency trees .", "label": "", "metadata": {}, "score": "59.749626"}
{"text": "The average amount of redundancy in removed note pairs is sampled as well .Redundancy is computed in the same way as in Section 2.1.1 .We randomly sampled 2,000 same - patient pairs of notes and aligned them using Smith - Waterman alignment .", "label": "", "metadata": {}, "score": "59.749977"}
{"text": "This improvement only occurs when the log is per- formed with amplitude compression implemented to constrain the allowable range of feature detector output values to 10 dB.Second , while the GP based system obtains the best PAC at 68.1 % , all three of the feature based phone recognizers obtain relatively similar per- formance .", "label": "", "metadata": {}, "score": "59.81348"}
{"text": "Each electronic text file was proofread and corrected independently by two native speakers of Mandarin Chinese so as to keep the transcribed raw texts as accurate as possible .While the digital library has a very large collection of books , it does not provide newspapers .", "label": "", "metadata": {}, "score": "59.832912"}
{"text": "Initially we used bandwidth independent , gender independent triphones to evaluate the technique and under these conditions it gave a 1 % absolute reduction in WER .However , when bandwidth dependent , gender dependent models with variance normalisation and MLLR adaptation were used , there was no WER advantage and hence soft clustering was not used in the 1998 evaluation system .", "label": "", "metadata": {}, "score": "59.84169"}
{"text": "Rather than comparing documents ( news reports ) with each other , our system compares documents with the centroid vectors representing each cluster .This same approach was followed in [ 4 , 7 , 17 , 23 ] .The cluster centroid is represented by an index of the stemmed versions of all the terms ( excluding stop - words ) that appear in those documents which are members of that cluster .", "label": "", "metadata": {}, "score": "59.869194"}
{"text": "In Topic Detection and Tracking ( TDT ) systems , the incoming stream / s of news reports are clustered in real - time as soon as each report is received [ 15 ] .The major issue encountered when performing Document Clustering is to perform effective clustering in an efficient manner [ 14 ] .", "label": "", "metadata": {}, "score": "59.884308"}
{"text": "No additional knowledge about the target domain is included .A more realistic approach assumes that only raw text from the target domain is available .This assumption lends itself well to semi - supervised learning methods since these utilize both labeled and unlabeled examples .", "label": "", "metadata": {}, "score": "59.923195"}
{"text": "Meanwhile , we also recorded the percentage of ambiguous words that were removed from the ambiguous word - list for different thresholds .We removed words with frequencies higher than 10 % , 1 % , 0.1 % and 0.05 % from the two lists of the mouse organism .", "label": "", "metadata": {}, "score": "60.027596"}
{"text": "Viles [ 9 ] found that strict adherence to a term weighting scheme is not required to maintain effectiveness in most situations .Incremental clustering systems also introduce scalability issues .As new documents keep arriving , the system will eventually run out of memory space to store all these documents .", "label": "", "metadata": {}, "score": "60.03923"}
{"text": "In this research , we have implemented a clustering system that uses a modified k - means clustering algorithm adapted for incremental clustering to cluster news reports into event - centric clusters .News reports are downloaded continuously through RSS , and these are clustered \" on the fly \" , resulting in the creation of new clusters or the updating of previously existing clusters .", "label": "", "metadata": {}, "score": "60.039864"}
{"text": "This suggests that the lexicon contained in the training data is very important for being able to successfully apply our post - processing steps .We believe that a larger training set covering a larger lexicon would help improve the performance of our system .", "label": "", "metadata": {}, "score": "60.094"}
{"text": "ZGD carried out the studies in DHMMs and the majority voting strategy , took in - charge of the whole system and drafted the manuscript .SD implemented the SVM , the abbreviation resolution and dictionary matching module .ZJ implemented the SVM , the abbreviation resolution and name refinement modules .", "label": "", "metadata": {}, "score": "60.209915"}
{"text": "The basic adaptation approach in our system remains MLLR for both means and variances [ 2 ] .In addition , for the quinphone stage of iterative unsupervised adaptation , the effect of a single full variance ( FV ) transform [ 3 ] was investigated .", "label": "", "metadata": {}, "score": "60.358223"}
{"text": "On the March 2000 Hub5 evaluation set the CU - HTK system gave an overall word error rate of 25.4 % , which was the best performance by a statistically significant margin .This paper describes the new system features and gives the results of each processing stage for both the 1998 and 2000 evaluation sets .", "label": "", "metadata": {}, "score": "60.408897"}
{"text": "Using a clustering procedure and a set of smoothing rules the final segments to be processed by the decoder are generated .For recognition , each frame of input speech is represented by a 39 dimensional feature vector that consists of 13 ( including ) MF - PLP cepstral parameters and their first and second differentials .", "label": "", "metadata": {}, "score": "60.41057"}
{"text": "The system then uses quinphone models ( VTLN / SAT trained ) and MLLR with an additional FV transform to process the data ( P4 ) .This stage is repeated twice more while increasing the number of MLLR transforms ( P5/P6 ) .", "label": "", "metadata": {}, "score": "60.435024"}
{"text": "Among the various speech knowledge sources , phonological features are used most frequently by detectionbased ASR research groups [2][3][4][5].However , although there are several phonological feature sets based on different linguistic theories , it is not clear whether any of them could be considered as the best design for the detection - based ASR task [ 6].", "label": "", "metadata": {}, "score": "60.43993"}
{"text": "We call notes of these 3 types \" Informative Notes \" .In our experiments , we rely on different variants of the EHR corpus ( see Table 7 ): .The All Notes corpus is our full EHR corpus , .", "label": "", "metadata": {}, "score": "60.505714"}
{"text": "First , many phono- logical feature systems have been defined in the linguistics commu- nity where the feature definitions themselves are based on different theories of speech production and acoustic phonetics [ 1 , 5 , 6].Third , techniques have been proposed for combin- ing information from phonological feature detectors for recognizing phonestringsinASR[9,2].", "label": "", "metadata": {}, "score": "60.5078"}
{"text": "proposed an ensemble method ( Reichart and Rappoport , 2007 ) .They regarded parses as being of high quality if 20 different parsers agreed .They used an SVM regression approach on the basis of text - based and parse - based features .", "label": "", "metadata": {}, "score": "60.52552"}
{"text": "In Readings in Information Retrieval ; Morgan Kaufmann Publishers Inc. : San Francisco , CA , USA , 1997 ; pp .313 - 316 .[ Google Scholar ] .Deng , S. ; Peng , H. Document Classification Based on Support Vector Machine Using a Concept Vector Model .", "label": "", "metadata": {}, "score": "60.577114"}
{"text": "Topic modeling .The algorithm for topic modeling that we analyze , LDA , is a complex inference process which captures patterns of word co - occurrences within documents .To investigate the behavior of LDA on corpora with varying levels of redundancy , we rely on two standard evaluation criteria : log - likelihood fit on withheld data and the number of topics required in order to obtain the best fit on the withheld data .", "label": "", "metadata": {}, "score": "60.599087"}
{"text": "This paper revisits an assump - tion that genre variation is continuous along multiple dimensions , and an early use of principal component analysis to find these dimensions .Results on a very heterogeneous corpus of post-1990s American English reveal four major dimensions , three of which echo those found in prior work and the fourth depending on features not used in the earlier study .", "label": "", "metadata": {}, "score": "60.681168"}
{"text": "However , the dictionary - based approach increased our F - measure by only 0.5 % .Baseline , and normalizing for the difficulty of the task .As a baseline for understanding the difficulty of the task , we measured the performance achieved by simply assigning each word the most frequent tag seen with that word in the training set .", "label": "", "metadata": {}, "score": "60.695305"}
{"text": "For a given model set a single Gaussian per state version was created .For each speech state in the single Gaussian system , the nearest two other states were found using a log - overlap distance metric [ 14 ] , which calculates the distance between two Gaussians as the area of overlap of the two probability density functions .", "label": "", "metadata": {}, "score": "60.703033"}
{"text": "Such a technique , called named entity recognition , has been well developed in the Information Extraction literature [ 5 , 6 ] .In MUC , the task of named entity recognition is to recognize the names of persons , locations , organizations , etc . in the newswire domain .", "label": "", "metadata": {}, "score": "60.744812"}
{"text": "The fact that the results obtained on the Google News clusters are very good may imply that our algorithm is similar to the one used by Google News for clustering .Unfortunately , we could not confirm this since we could not find information about the inner workings of Google News .", "label": "", "metadata": {}, "score": "60.76673"}
{"text": "In our evaluation , the F - measure metric gave equal weight to recall and precision .For the evaluation of single - label text clustering , where a document may be a member of only one cluster , Ji [ 3 ] modifies the Reuters-21578 collection by discarding documents with multiple category labels , and removing clusters with less than 40 documents .", "label": "", "metadata": {}, "score": "60.78322"}
{"text": "The full - form in the title or abstract of the article was then replaced with the ambiguous abbreviation , and the appropriate sense was noted separately .Table 1 shows the number of articles that were obtained for the different abbreviations and senses .", "label": "", "metadata": {}, "score": "60.86831"}
{"text": "We observe that the log - likelihood graphs for them have the same shape , with the larger corpora achieving higher log - likelihood , and the best fits obtained with topic numbers between 100 and 200 ( Figure 4 a ) .", "label": "", "metadata": {}, "score": "60.86861"}
{"text": "In the baseline , the documents were represented using the Bag - of - Words representation - the set of all the terms in each document were considered to be representative of that document .Each set of document terms was filtered from stop - words and had their suffix removed using the Porter 's stemming routine [ 24 ] .", "label": "", "metadata": {}, "score": "60.919983"}
{"text": "It is also clear from rows five and six in Table 3 that feature combination performed through succes- sive lattice re - scoring results in performance improvements that are similar to those obtained through CNC based system combination .All of these results suggest that these feature based systems convey complementary information which can significantly reduce that am- biguity associated with MFCC based ASR .", "label": "", "metadata": {}, "score": "60.9568"}
{"text": "System details can be found in [ 16 ] .The data segmentation [ 4 ] aims to generate acoustically homogeneous speech segments and discard non - speech portions such as pure music .It uses a set of Gaussian mixture models to classify the data as to type ( wideband speech , narrow - band speech , pure music , speech and music ) , and then any pure music is discarded .", "label": "", "metadata": {}, "score": "60.957207"}
{"text": "In Proceedings of the 1st international workshop on Text mining in bioinformatics : 2006 .ACM ; 2006:7 - 14 .McInnes BT , Pedersen T , Pakhomov SV : Determining the syntactic structure of medical terms in clinical notes .In Proceedings of the Workshop on BioNLP 2007 : Biological , Translational , and Clinical Language Processing : 2007 .", "label": "", "metadata": {}, "score": "60.990395"}
{"text": "Comparison of the oracle phone recognition results and the real phone recognition results indicates that investigation of high - accuracy front - end detectors is a key issue in improving the performance of detection - based ASR . \"Among the various speech knowledge sources , phonological features are used most frequently by detectionbased ASR research groups [", "label": "", "metadata": {}, "score": "60.992546"}
{"text": "Rep. , Cambridge University Engineer- ing Department , Speech Group , Cambridge , 1993 .[ 16 ] Andreas Stolcke , \" SRILM - an extensible language modeling toolkit , \" in Proceedings of the International Conference on Spoken Language Processing , 2002 , pp .", "label": "", "metadata": {}, "score": "61.036118"}
{"text": "This was similarly transcribed at the speaker turn level but did n't distinguish between background conditions which meant that marked training segments were no longer necessarily homogeneous .The combined set of 1997 and 1998 data is denoted BNtrain98 .System development mainly used the 1997 Hub4 evaluation data , BNeval97 .", "label": "", "metadata": {}, "score": "61.2362"}
{"text": "Such delays may render the clustering system not feasible especially if it is just a small of part of a larger and considerably more complex operational cycle .Evaluation .Evaluation Methodology .According to Sahoo [ 13 ] , the clusters produced by a document clustering system can be evaluated in two ways , namely by using qualitative evaluation where the actual clusters are evaluated and quantitative evaluation by demonstrating the benefit of clustering for a particular retrieval task .", "label": "", "metadata": {}, "score": "61.255646"}
{"text": "Haug P , Koehler S , Lau L , Wang P , Rocha R , Huff S : A natural language understanding system combining syntactic and semantic techniques .Proc Annu Symp Comput Appl Med Care 1994 , 247 - 251 .", "label": "", "metadata": {}, "score": "61.285954"}
{"text": "For each abbreviation , we measured error rates of the SVM classifier under different combinations of sample size , sense distribution , cross validation scheme ( 5-fold vs. 10-fold ) , and multi - class SVM algorithms ( for BPD only , which has 3 different senses ) .", "label": "", "metadata": {}, "score": "61.28817"}
{"text": "[ 4 ] L. Mangu , E. Brill , and A. Stolcke , \" Finding consensus in speech recognition : Word error minimization and other appli- cations of confusion networks , \" Computer , Speech and Lan- guage , vol .14 , no .", "label": "", "metadata": {}, "score": "61.362324"}
{"text": "Page 6 . decoder through a lattice re - scoring approach .The system inte- gration was based on weighted log linear combination of feature based and MFCC based likelihoods where the weights were esti- mated automatically using a discriminative model combination ap- proach .", "label": "", "metadata": {}, "score": "61.374023"}
{"text": "This figure shows the plots of ' ' error rate ' ' versus ' ' sample size ' ' with different sense distributions of PCA data set ( case where the 2 ambiguous senses are very similar ) using 5-fold cross validation .", "label": "", "metadata": {}, "score": "61.37654"}
{"text": "In addition , we used an SVM classifier for all the experiments .Since the goals of our study did not include the comparison of different algorithms , we do not present related results here .Other studies showed that different ML algorithms had similar performance for WSD tasks [ 29 , 30 ] .", "label": "", "metadata": {}, "score": "61.426632"}
{"text": "Cepstral mean subtraction and variance normalisation are performed for each conversation side .Vocal tract length normalisation ( VTLN ) was applied in both training and test .The acoustic modelling used cross - word triphone and quinphone hidden Markov models ( HMMs ) trained using conventional maximum likelihood estimation .", "label": "", "metadata": {}, "score": "61.432224"}
{"text": ", 2009 ; Biber & Gray , 2010 ) , but the most interesting usages apply the divergence to a machine learning system .Despite the fact that authors have shown that a divergence ( Van Asch & Daelemans , 2010 ; Plank , 2011 ) or a linear combination of divergences ( McClosky , 2010 ) can be successfully used to link the sim ... . \" ...", "label": "", "metadata": {}, "score": "61.439003"}
{"text": "This is probably because while MLE training gives equal weight to all training utterances , MMIE training effectively gives greater weight to those training set utterances with low sentence posterior probabilities for the correct utterance .MMIE was also used to train quinphone HMMs .", "label": "", "metadata": {}, "score": "61.44948"}
{"text": "Merkel M , Andersson M : Combination of contextual features for word sense disambiguation .SENSEVAL-2 Workshop 123 - 127 .Bruce R , Wiebe J : Word sense disambiguation using decomposable models .Proceedings of the Thirty - second Annual Meeting of the Association of Computational Linguistics 139 - 146 .", "label": "", "metadata": {}, "score": "61.470497"}
{"text": "The differences we observe in this experiment are caused by the fact that some sentences only are copied , in a variable number of times ( some sentences occur once , some twice , and others 5 times ) .Thus , PMI ( which does not simply reflect word frequencies in a corpus , but takes into account global patterns of co - occurrences , since it relies on the probability of seeing terms jointly and terms independently ) does not behave similarly when fed with our different corpora .", "label": "", "metadata": {}, "score": "61.501793"}
{"text": "English and German .We were impressed by its availability on a variety of platforms , its intuitive interface , and the stability of its distribution , which installed easily and never crashed .For the official test we trained TnT on both the training corpus and devtest corpus and then tested it on the official test set .", "label": "", "metadata": {}, "score": "61.601517"}
{"text": "[ Google Scholar ] .Sahoo , N. ; Callan , J. ; Krishnan , R. ; Duncan , G. ; Padman , R. Incremental Hierarchical Clustering of Text Documents .In CIKM ' 06 : Proceedings of the 15th ACM International Conference on Information and Knowledge Management , Arlington , VA , USA , 5 - 11 November 2006 ; ACM : New York , NY , USA , 2006 ; pp .", "label": "", "metadata": {}, "score": "61.657803"}
{"text": "[ Before ROVER combination an alignment pass was run to get exact word timings .Due to the effects of automatic segmentation this process reduces the WER by about 0.1 % absolute .] Table 6 : Word error rates for each stage of the 1998 HTK broadcast news evaluation system ( also P4 FV contrast ) .", "label": "", "metadata": {}, "score": "61.662575"}
{"text": "These details are useful .Presently Xara version 1.0 is aware of XML markup .With this tool , users can either search the whole corpus or define a subcorpus containing a certain text type or a specific file .The POS tags allow users to search for a certain class of words , and in combination with tokens , to extract a specific word that belongs to a certain class .", "label": "", "metadata": {}, "score": "61.672325"}
{"text": "TSH gave feed - back on biomedical name boundaries and tokenization .All authors have read and approved the final manuscript .MUC6 Proceedings of the Sixth Message Understanding Conference ( MUC-6 ) Columbia , Maryland .Morgan Kaufmann Publishers , Inc 1995 .", "label": "", "metadata": {}, "score": "61.80479"}
{"text": "To test the null hypothesis of no differences in the error rates among the different sample sizes ( and overall probability distribution ) for the BSA and PCA abbreviations , we used Friedman 's test .Then we performed sub - analysis using the sign - test ( see Methods section for details ) .", "label": "", "metadata": {}, "score": "61.88057"}
{"text": "Document - cluster similarities were found by calculating the cosine similarity between the document and the centroid vector of the relevant cluster ( as described in Section 3 ) .The number of clusters to produce was given beforehand to the k - means system , thus giving this system an advantage over our system .", "label": "", "metadata": {}, "score": "61.96888"}
{"text": "This work was in part supported by GCHQ .Gunnar Evermann has studentships from the EPSRC and the Cambridge European Trust , and Dan Povey holds a studentship from the Schiff Foundation .The authors are grateful to Thomas Niesler and Ed Whittaker for their help in building the class - based language models .", "label": "", "metadata": {}, "score": "62.083252"}
{"text": "Therefore it is important that we understand the different elements affecting their performance .Methods .After manually reviewing a set of WSD papers in the biomedical domain , different issues associated with performance were enumerated .For an initial study , we conducted experiments to evaluate the effect of three confounding issues : \" sample size \" , \" sense distribution \" and \" degree of difficulty \" , and we used an automatically generated data set .", "label": "", "metadata": {}, "score": "62.14377"}
{"text": "Generally , there are two patterns \" full form ( abbreviation ) \" and \" abbreviation ( full form ) \" .Our algorithm is based on the fact that it is much harder to classify an abbreviation than its full form .", "label": "", "metadata": {}, "score": "62.153057"}
{"text": "Other confounding issues of WSD .Other issues in addition to sample size , distribution of senses , and difficulty of the task also affect the performance and subsequent assessment of WSD classifiers , as noted below : .As often discussed in various papers , different features were evaluated to see their contribution to classifier performance [ 10 , 20 , 29 ] .", "label": "", "metadata": {}, "score": "62.195633"}
{"text": "The set of words in each of the news reports are filtered using stop - words lists , and Porter 's suffix stemming routine [ 24 ] is applied to reduce words to their stems .The reasons for the selection of the Bag - of - Words approach is that it is simple and efficient and does not require any supervision or any other intervention .", "label": "", "metadata": {}, "score": "62.229675"}
{"text": "Proceedings of the 19th International Conference on Computational Linguistics ( COLING 2002 ) 765 - 771 .Schwartz AS , Hearst MA : A Simple Algorithm For Identifying Abbreviation Definitions in Biomedical Text .Proceedings of the Pacific Symposium on Biocomputing 2003 , 8 : 451 - 462 .", "label": "", "metadata": {}, "score": "62.287163"}
{"text": "Along with the advent of EHR comes the ability to copy and paste from one note to another .While this functionality has definite benefits for clinicians , among them more efficient documentation , it has been noted that it might impact the quality of documentation as well as introduce errors in the documentation process [ 9 - 13 ] .", "label": "", "metadata": {}, "score": "62.319855"}
{"text": "The goal of BioCreAtIvE Task1A is to assess the ability of an automated system to identify mentions of genes in text from biomedical literature .The corpus used for Task1A consists of sentences drawn from Medline abstracts and is divided into three sets : training , devtest , and official test .", "label": "", "metadata": {}, "score": "62.37648"}
{"text": "This is proven by the ensemble of these three classifiers via a simple majority voting strategy , which improved the F - measure by about 3.7 ( over SVM ) .It also shows that the abbreviation resolution and name refinement modules further improve the F - measure by 3.7 and 2.4 respectively .", "label": "", "metadata": {}, "score": "62.38548"}
{"text": "Like Tanabe and Wilbur [ 1 , 2 ] , we approached the molecular biology entity identification problem as a part - of - speech ( POS ) tagging task , adding to the standard POS tag set one or more gene tags for genes and gene products .", "label": "", "metadata": {}, "score": "62.39537"}
{"text": "Both methods rely on a two stage process involving a mechanism for framelevelfeaturedetectionandamechanismfordecodingphoneme sequencesfromdetectedphonologicalfeaturesforeachfeaturestream .The components of this process are described in Section 3 .The first method , described in Section 4 , involves integrating phone strings derivedfromphonologicaldistinctivefeatureswiththesolutionspace of a conventional mel frequency cepstrum coefficient ( MFCC ) based HMM speech recognizer .", "label": "", "metadata": {}, "score": "62.441795"}
{"text": "The second feature setconsistsofonlyeight featureswhereeach fea- ture can assume anywhere from two to ten values .This is referred to as the multi - valued ( MV ) system .It defines phones in terms of well known linguistic terminology , such as manner and place , ar- ranged into a hierarchy .", "label": "", "metadata": {}, "score": "62.46601"}
{"text": "View Article .Banko M , Brill E : Mitigating the paucity - of - data problem : Exploring the effect of training corpus size on classifier performance for natural language processing .Association for Computational Linguistics ; 2001:1 - 5 .", "label": "", "metadata": {}, "score": "62.534103"}
{"text": "We take two popular dependency parsers - one graph - based and one transition - based - and compare results for both .Results show that using semisupervised learning in the form of self - training and co - training yields only very modest improvements in parsing accuracy .", "label": "", "metadata": {}, "score": "62.559265"}
{"text": "This method is used as an alternative to empirical estimation of these weights as was previously done in [ 2].Feature Integration Inpreviouswork , astrategyforintegratingphonologicalfeaturebased models with traditional MFCC based ASR was investigated .A sim- ple model for decoding an optimum phone string from multiple in- dependent phonological feature vectors was presented in [ 2].", "label": "", "metadata": {}, "score": "62.56667"}
{"text": "Self - training creates semi - supervised learners from existing supervised learners with minimal effort .We first show results on self - training for constituency parsing within a single domain .While self - training has failed here in the past , we present a simple modification which allows it to succeed , producing state - of - the - art results for English constituency parsing .", "label": "", "metadata": {}, "score": "62.592518"}
{"text": "14 ] K.-F. Lee and H.-W. Hon , \" Speaker - independent phone recog- nition using hidden Markov models , \" IEEE Transaction on Acoustics , Speech , and Signal Processing , vol .37 , pp .1641- 1648 , 1989 .", "label": "", "metadata": {}, "score": "62.59413"}
{"text": "Bioinformatics 2004 , 20 : 2597 - 2604 .View Article PubMed .Schijvenaars BJ , Mons B , Weeber M , Schuemie MJ , van Mulligen EM , Wain HM , et al .: Thesaurus - based disambiguation of gene symbols .", "label": "", "metadata": {}, "score": "62.693516"}
{"text": "The balanced Chinese corpus built in China , as reported in Zhou & Yu ( 1997 ) , is not publicly available .Since the corpus approach has increasingly been recognized a useful tool for the linguistic investigation , the research community has felt an increasing need for appropriate corpus resources for this major world language .", "label": "", "metadata": {}, "score": "62.84081"}
{"text": "[ 13 ] P Beyerlein , \" Discriminative model combination , \" in Proceed- ings of the International Conference on Acoustics , Speech , and Signal Processing .ICASSP , May 1998 , vol .I , pp .481 - 484 .", "label": "", "metadata": {}, "score": "62.856308"}
{"text": "473 - 476 .[ Google Scholar ] .Hearst , M.A. ; Pedersen , J.O. Reexamining the Cluster Hypothesis : Scatter / gather on Retrieval Results .In SIGIR ' 96 : Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , Zurich , Switzerland , 18 - 22 August 1996 ; ACM Press : New York , NY , USA , 1996 ; pp .", "label": "", "metadata": {}, "score": "62.858803"}
{"text": "Conclusions .Before applying text - mining techniques , one must pay careful attention to the structure of the analyzed corpora .While the importance of data cleaning has been known for low - level text characteristics ( e.g. , encoding and spelling ) , high - level and difficult - to - quantify corpus characteristics , such as naturally occurring redundancy , can also hurt text mining .", "label": "", "metadata": {}, "score": "62.950592"}
{"text": "In this approach , each incoming document is compared to existing clusters , and if the cluster - document similarity is above a pre - defined threshold ( in our setup , this is set to 0.4 ) , the document is placed within that cluster .", "label": "", "metadata": {}, "score": "63.085114"}
{"text": "Our EHR corpus can be organized by patient identifier .We can , therefore , quantify the amount of redundancy within a patient record .On average , our corpus contains 14 notes per patient , with standard deviation of 16 , minimum of 1 and 167 maximum notes per patient .", "label": "", "metadata": {}, "score": "63.09005"}
{"text": "This criterion can be optimized with respect to the log linear model co- efficients , \u039b , using training samples .The first summa- tion in the above equation is over all M utterances in the training set .The second summation is over the K most likely phone ystrings produced by the MFCC based ASR system .", "label": "", "metadata": {}, "score": "63.09235"}
{"text": "This means that our approach in choosing the faster system is justified .Conclusions .In this paper , we have described the design and evaluation of our clustering system .Our clustering system reads incoming news reports from RSS streams , and clusters them \" on the fly \" according to the event they are describing .", "label": "", "metadata": {}, "score": "63.10298"}
{"text": "It measures the decrease in precision / recall / F - measure by leaving one feature out at a time .It shows that the orthographic feature , POS and surface word are critical and contributes about 96 % of all the features while the remaining morphological feature and trigger word only contribute about 4 % .", "label": "", "metadata": {}, "score": "63.212196"}
{"text": "In their study , rare senses ( senses appearing in less than 40 documents ) were excluded from the testing set .This makes the disambiguation task easier because it reduces the problem of sparse senses .In addition , the training set was created based on long - form and short - form pairs , where ambiguous words not having long - forms were not tested .", "label": "", "metadata": {}, "score": "63.236847"}
{"text": "Downey D , Etzioni O , Soderland S : Analysis of a probabilistic model of redundancy in unsupervised information extraction .Artif Intell 2010 , 174 ( 11 ) : 726 - 748 .View Article .Altschul SF , Madden TL , Sch\u00e4ffer AA , Zhang J , Zhang Z , Miller W , Lipman DJ : Gapped BLAST and PSI - BLAST : a new generation of protein database search programs .", "label": "", "metadata": {}, "score": "63.23974"}
{"text": "View Article .Weston J , Watkins C : Multiclass support vector machines .Proceedings of ESANN99 .Copyright .\u00a9 Xu et al .2006 .This article is published under license to BioMed Central Ltd.Abstract : .This paper describes the Cambridge University HTK ( CU - HTK ) system developed for the NIST March 2000 evaluation of English conversational telephone speech transcription ( Hub5E ) .", "label": "", "metadata": {}, "score": "63.24813"}
{"text": "The Document Clustering process typically consists of [ 7 ] : the extraction of features from the documents ; the mapping of the documents to high - dimensional space ; and the clustering of the points within the high - dimensional space .", "label": "", "metadata": {}, "score": "63.259136"}
{"text": "They confirm that in outpatient notes , like for inpatient notes , there is a large amount of redundancy .Different metrics for quantifying redundancy exist for text .Sequence alignment methods such as the one proposed by Zhang et al .", "label": "", "metadata": {}, "score": "63.261723"}
{"text": "This could also be due to the existence of other confounding factors in the datasets that were used .In our study , we controlled for this factor by using \" bag - of - word \" features in all experiments , but it would be interesting to see if the performance improves when different feature vectors are used .", "label": "", "metadata": {}, "score": "63.30441"}
{"text": "The category - trigram used 1000 automatically derived word classes and was trained using LMtrain98 .Category bigrams and trigrams were added only if the leave - one training set likelihood improved and the final category model contained 0.85 million bigrams and 9.4 million trigrams .", "label": "", "metadata": {}, "score": "63.320747"}
{"text": "It was again found that there is a fairly consistent 1 % absolute reduction in WER from confusion networks .A contrast ( not shown in the table ) showed that on P2 the use of MMIE models had given a 2.1 % absolute reduction in WER over the corresponding MLE models .", "label": "", "metadata": {}, "score": "63.370117"}
{"text": "View Article PubMed .Gaudan S , Krisch H , Rebholz - Schuhmann D : Resolving abbreviations to their senses in Medline .Bioinformatics 2005 , 21 : 3658 - 3664 .View Article PubMed .Schuemie MJ , Kors JA , Mons B : Word sense disambiguation in the biomedical domain : an overview .", "label": "", "metadata": {}, "score": "63.421555"}
{"text": "This agrees with work by Rifkin and Klatau [ 34 ] .A description of the different multi - class algorithms is provided in the Methods section .Table 5 .Results for BPD data set .Annotation of the table : Dist : Distribution of senses ; S. Size : sample size ; Err .", "label": "", "metadata": {}, "score": "63.431976"}
{"text": "Finally , we use the dictionary to match the test data and correct the output of the ensemble .Results and discussion .In the BioCreative competition , we only participated in the protein / gene name recognition task ( Task 1A ) , focusing on the closed evaluation .", "label": "", "metadata": {}, "score": "63.442425"}
{"text": "The results obtained by our system show a high recall and a very low precision .The clustering component produced some very large clusters containing a huge number of documents , and the remaining documents were scattered in very small clusters .", "label": "", "metadata": {}, "score": "63.445705"}
{"text": "The resulting average precision and recall with post - processing was 82.0 and 81.1 , respectively .The averaged results of the cross - validation runs are shown in Figure 1A .The results for official test are shown in Figure 1B .", "label": "", "metadata": {}, "score": "63.464863"}
{"text": "These papers are important in that they report on useful methods and provide insights and overall results .However , a deeper and more systematic analysis is needed in order to obtain a better understanding of the different factors affecting the performance of ML methods for WSD .", "label": "", "metadata": {}, "score": "63.46487"}
{"text": "MM and CF conceived of the study , and participated in its design and coordination and helped to draft the manuscript .MM also performed statistical analysis and interpreted the results .HL advised in the design of study .All authors read and approved the final manuscript .", "label": "", "metadata": {}, "score": "63.477512"}
{"text": "A user can identify any RSS feed as a source of news he / she would like to receive and our clustering system can cluster reports received from the separate RSS feeds as they arrive without knowing the number of clusters in advance .", "label": "", "metadata": {}, "score": "63.53898"}
{"text": "When the texts were segmented and it was possible to count exact word numbers , they were automatically cut to around 2000 words while keeping the final sentence complete .However , while the ratio that we decided on worked on most texts , a small number of texts finally yielded slightly less than 2,000 words .", "label": "", "metadata": {}, "score": "63.543953"}
{"text": "Table 7 : OOV rate and perplexities of the 1998 evaluation LMs .Perplexities shown for trigram ( tg ) , 4-gram ( fg ) and word 4-gram interpolated with category trigram ( fgintcat ) .The out - of - vocabulary ( OOV ) rate and perplexity of these language models on BNeval97 and the two halves of the BNeval98 set is shown in Table 7 .", "label": "", "metadata": {}, "score": "63.547325"}
{"text": "IEEE Workshop on Automatic Speech Recognition and Understanding , pp .347 - 354 , Santa Barbara .Affiliated with .Abstract .Background .Automated techniques have been developed that address the WSD problem for a number of text processing situations , but the problem is still a challenging one .", "label": "", "metadata": {}, "score": "63.610416"}
{"text": "The phonological distinctive feature ( PDF ) based phone recog- nizers described in Section 3 consist of TDNN based feature detec- tors , log / PCA based transformation of feature detector outputs , and HMM based feature - to - phone mapping .", "label": "", "metadata": {}, "score": "63.6251"}
{"text": "This healthy behavior strongly indicates that Reduced Redundancy Informative Notes indeed behaved as a non - redundant corpus with respect to the LDA algorithm .Model fit as function of number of topics .Patient notes corpora , including the \" Reduced Informative \" corpus .", "label": "", "metadata": {}, "score": "63.65443"}
{"text": "Rule - based post - processing .We applied a number of simple , pattern - based rules to fix cases where the BioCreAtIvE task definition specified that a different boundary for the gene name than the one returned by the raw tagger output .", "label": "", "metadata": {}, "score": "63.705513"}
{"text": "[ Google Scholar ] .Stokes , N. ; Carthy , J. First Story Detection Using a Composite Document Representation .In HLT ' 01 : Proceedings of the First International Conference on Human Language Technology Research , San Diego , CA , USA , 18 - 21 March 2001 ; Association for Computational Linguistics : Morristown , NJ , USA , 2001 ; pp . 1 - 8 .", "label": "", "metadata": {}, "score": "63.77282"}
{"text": "P1 to P3 use triphones and P4-P6 quinphones .The results ( over the complete 1998 evaluation set ) for each of these stages , together with additional contrasts , is shown in Table 6 .There is a 12 % reduction in error by using gender dependent models and VTLN ( P1 to P2 ) and a further 7 % from using MLLR .", "label": "", "metadata": {}, "score": "63.785942"}
{"text": "Our experience suggests that the Brill tagger is susceptible to specific kinds of performance problems that we hoped to avoid .However , we did not rigorously compare the performance of the two taggers .The main difference between the two systems is our focus on tailoring the post - processing steps for the BioCreAtIvE task .", "label": "", "metadata": {}, "score": "63.79664"}
{"text": "[ Google Scholar ] .Ji , X. ; Xu , W. Document Clustering with Prior Knowledge .In SIGIR ' 06 : Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , Seattle , WA , USA , 6 - 11 August 2006 ; ACM : New York , NY , USA , 2006 ; pp .", "label": "", "metadata": {}, "score": "63.83"}
{"text": "PHONOLOGICAL FEATURE SYSTEMS Three different definitions of PDFs are investigated here and corre- spond to feature sets used in a previous study of frame level feature detection [ 1].These feature sets are briefly introduced in this section in order to contrast the differing motivations that lead to their devel- opment , the differences in structure , and the differences in the level of articulatory and acoustic information that is characterized by each one .", "label": "", "metadata": {}, "score": "63.842346"}
{"text": "Authors ' Affiliations .Department of Computer Science , Ben - Gurion University in the Negev .Department of Biomedical Informatics , Columbia University .References .Friedman : A general natural - language text processor for clinical radiology .Jamia - Journal of the American Medical Informatics Association 1994 , 1 ( 2 ) : 161 .", "label": "", "metadata": {}, "score": "63.903255"}
{"text": "View Article .Zhou G , Zhao J , Liu K , Cai L : Exploiting web - derived selectional preference to improve statistical dependency parsing .Proceedings of ACL : 2011 , 2011 : 1556 - 1565 .Chen HB , Huang HH , Tan CT , Tjiu J , Chen HH : A statistical medical summary translation system .", "label": "", "metadata": {}, "score": "63.99782"}
{"text": "It is made up of two parts .First , the lattice re - scoring strategy , as originally introduced in [ 2 ] , is described as a general method for integration of multiple independent features with tradi- tional MFCC based ASR .", "label": "", "metadata": {}, "score": "64.00331"}
{"text": "Experiments with no adaptation ( or cluster - based normalisation ) showed that the word error rate ( WER ) was reduced by up to 0.9 % absolute .However when MLLR adaptation and VTLN were applied ( see below ) the WER gain was reduced to 0.4 % absolute .", "label": "", "metadata": {}, "score": "64.06502"}
{"text": "Three phonological feature sets derived from different underlying phonological theories are investigated .Our experiments , were , conducted , on the , TIMIT database .By comparing , the oracle phone , recognition results achieved , by assuming , that all the phonological features are correctly detected based on each feature set , we show that selecting an appropriate phonological , feature set is crucial , to the , performance , of detection - based ASR .", "label": "", "metadata": {}, "score": "64.07405"}
{"text": "Several papers [ 29 , 30 ] realized this issue and reported results for the baseline .More specifically , they excluded samples with a majority sense larger than a threshold because they realized the contribution of the classifier would not be much for those cases .", "label": "", "metadata": {}, "score": "64.10065"}
{"text": "An alternative route to text mining in the presence of high levels of redundancy consists of keeping all the existing redundant data , but designing redundancy immune statistical learning algorithms .This is a promising route of future research .Methods .", "label": "", "metadata": {}, "score": "64.123215"}
{"text": "The frame accuracy was between 87 % and 98 % for the GP feature set .Phonological Feature Transformations The estimates of posterior probabilities generated at the output of the TDNN feature classifiers for the three different feature systems are transformed and applied as input to the phonological feature based phoneme recognizers described in Section 3.3 .", "label": "", "metadata": {}, "score": "64.223404"}
{"text": "PubMed .Manning CD , Schutze H : Foundations of statistical natural language processing .MIT Press , Cambridge MA ; 1999:151 - 190 .Joshi M , Pakhomov S , Pedersen T , Chute CG : A comparative study of supervised learning as applied to acronym expansion in clinical reports .", "label": "", "metadata": {}, "score": "64.22526"}
{"text": "According to Salton [ 16 ] , the similarity between 2 vectors can be calculated more precisely than by just a simple count of overlapping index terms .Stavrianou [ 8 ] defines two types of similarity measures , namely : Statistical Similarity - based on term and co - occurrence frequencies ( e.g. , using Cosine Similarity ) ; and Semantic Similarity - using distance between terms meanings ( e.g. , using WordNet ) .", "label": "", "metadata": {}, "score": "64.248405"}
{"text": "Aronson AR : Effective mapping of biomedical text to the UMLS Metathesaurus : the MetaMap program .Proc AMIA Symp 2001 , 17 - 21 : 17 - 21 .Weeber M , Klein H , Aronson AR , Mork JG , de Jong - van den Berg LT , Vos R : Text - based discovery in biomedicine : the architecture of the DAD - system .", "label": "", "metadata": {}, "score": "64.25375"}
{"text": "The original data set for PCA contained 6 different senses , but we only used the two that were very similar for our experiments .We used a simple \" full - form substitution \" method to automatically generate a data set for the experiments described in this paper , and this dataset was partitioned into training and testing sets .", "label": "", "metadata": {}, "score": "64.275185"}
{"text": "1471 - 2105 - 7 - 334-S1.doc Additional File 1 : Supplementary material for gene ambiguity for mining MEDLINE ( DOC 925 KB ) .Authors ' contributions .HX carried out data collection , programming , experiments using SVM and drafted the manuscript .", "label": "", "metadata": {}, "score": "64.27908"}
{"text": "Furthermore , in line with the triphone figures , the overall gain for 1998 trained MLLR adapted quinphone models was 0.4 % absolute due to VTLN .For the 1998 system , the additional transcriptions from the 1998 acoustic training were available .", "label": "", "metadata": {}, "score": "64.2862"}
{"text": "Table 3 presents a summary of the evaluation results obtained when the Google News corpus was clustered by three systems : our system ; a modification of our system where each document is placed within the most similar cluster ; and the baseline system .", "label": "", "metadata": {}, "score": "64.29949"}
{"text": "According to Salton [ 16 ] , cluster reorganisation would eventually be needed in such incremental environments .In our system , the news reports are clustered into event clusters .Since events are usually quite distinct from each other , the clusters should be quite distinct from each other , and cluster reorganisation would not be necessary .", "label": "", "metadata": {}, "score": "64.32687"}
{"text": "Each token in the task1A corpus is labeled with a POS tag or a gene tag .Because the default tagging seemed overly simplistic , we hypothesized that expanding the gene tag set to incorporate boundary information would improve performance .We tested the following gene tag sets : .", "label": "", "metadata": {}, "score": "64.34796"}
{"text": "A further approximately 3-fold increase in the amount of training data only brings a further 1.6 % absolute reduction in WER .The model parameters in HMM based speech recognition systems are normally estimated using Maximum Likelihood Estimation ( MLE ) .", "label": "", "metadata": {}, "score": "64.35993"}
{"text": "It also shows that our closed system performs only slightly worse ( 0.6 ) than the best open system and better than other open systems .It is surprising because we had expected that the best open system should outperform the best closed system by at least 2 - 4 in the F - measure .", "label": "", "metadata": {}, "score": "64.37653"}
{"text": "For plagiarism detection , HaCohen - Kerner et al .[42 ] compare two fingerprinting methods : ( i ) Full fingerprinting - all substrings of length n of a string are used as fingerprints .This means that for a string of length m , m - n+1 fingerprints will be used ; and ( ii ) Selective Fingerprinting - non - overlapping substrings are chosen .", "label": "", "metadata": {}, "score": "64.40359"}
{"text": "373 - 400 , 2000 .[5 ] Noam Chomsky and Morris Halle , The sound pattern of En- glish , Studies in language ( New York , N.Y. ) .Harper & Row , New York , 1968 .[ 6 ] John Harris , English sound structure , Blackwell , Oxford , UK ; Cambridge , Mass. , 1994 .", "label": "", "metadata": {}, "score": "64.4316"}
{"text": "When all three feature based systems were sequentially applied in a sequential lattice re - scoring scenario , a 4.7 % increase in PAC was obtained .The second method proposed for integrat- ing multiple phonological feature based systems with MFCC based phone recognition was based on a ROVER and CNC system combi- nationparadigms .", "label": "", "metadata": {}, "score": "64.4678"}
{"text": "Systems are combined in the order shown .System Integration using Lattice Re - scoring Table 3 displays the phone accuracy for systems implemented using thelatticere - scoringscenariooriginallyintroducedin[2]tooptimize the weighted log - linear combination criterion given in Equation 2 .Rows two through four in Table 3 display the phone accuracies ob- tained by integrating the MFCC based phone recognizer with each of the three phonological distinctive feature based systems .", "label": "", "metadata": {}, "score": "64.567505"}
{"text": "Therefore , generally , each document has a relatively low similarity with unrelated clusters .We also performed some tests to compare the results between our categorisation system and a system where the document is clustered with the most similar threshold , and have found that the difference in results is negligible .", "label": "", "metadata": {}, "score": "64.57645"}
{"text": "Effects of \" sense distribution \" have been addressed in other papers [ 30 , 37 ] because it is believed that the performance of a WSD classifier may change if the distribution of the different senses is unbalanced .For example , when there is a majority sense for an ambiguous word , the improvement of a WSD classifier is believed to be very small .", "label": "", "metadata": {}, "score": "64.625275"}
{"text": "Less stringent metrics include : amount of shared words , amount of shared concepts or amount of overlapping bi - grams [ 16 ] .While these methods have been shown to identify semantic similarity of texts , they do not specifically capture instances of copy - paste operations , which reproduce whole paragraphs .", "label": "", "metadata": {}, "score": "64.63123"}
{"text": "View Article PubMed .Humphrey SM , Rogers WJ , Kilicoglu H , Demner - Fushman D , Rindflesch TC : Word sense disambiguation by selecting the best semantic type based on Journal Descriptor Indexing : Preliminary experiment .Journal of the American Society for Information Science and Technology 2006 , 57 : 96 - 113 .", "label": "", "metadata": {}, "score": "64.63165"}
{"text": "The output of the respective branches served as the adaptation supervision to stage P5a / P5b .These were as P4a / P4b but were based on quinphone acoustic models .Finally for the MMIE branch only , a pass with two MLLR transforms was run ( P6a ) .", "label": "", "metadata": {}, "score": "64.63301"}
{"text": "In our opinion it is worth having a faster system for the cost of 4 % lower effectiveness .The baseline results also contain cases where the produced clusters were identical to the reference clusters .However , on the whole the baseline results are significantly worse than the results obtained by our clustering system .", "label": "", "metadata": {}, "score": "64.64566"}
{"text": "Conclusion .Our results show that a part - of - speech tagger can be augmented with post - processing rules resulting in an entity identification system that competes well with other approaches .Background .This paper describes the methods we used to accomplish entity identification ( also known as named entity recognition ) in the molecular biology domain .", "label": "", "metadata": {}, "score": "64.66592"}
{"text": "However there is a concern that a very limited set of words may have accounted for the vast majority of ambiguity .Therefore , for each ambiguous word , we calculated its frequency , which is defined as the ratio between the number of abstracts containing the word and the total number of abstracts in the pool .", "label": "", "metadata": {}, "score": "64.67572"}
{"text": "Another reason may be somewhat corpus specific .For example , one system - component that seems to help our score quite a bit ( as shown in Table 3 ) is the name refinement module , which is built in part to adjust decisions to conform more to what is marked in this corpus .", "label": "", "metadata": {}, "score": "64.74875"}
{"text": "The HMM based component of all three systems includes context dependent tri - phone three state HMM phone models with continuous diagonal covarianceGaussianmixtureobservationdensitiescontaining5mix- tures per state .HMM models in all three systems were trained using a maximum likelihood ( ML ) criterion .", "label": "", "metadata": {}, "score": "64.75941"}
{"text": "However , most ... \" .It is well known that parsing accuracy suffers when a model is applied to out - of - domain data .It is also known that the most beneficial data to parse a given domain is data that matches the domain ( Sekine , 1997 ; Gildea , 2001 ) .", "label": "", "metadata": {}, "score": "64.77109"}
{"text": "Here , the Viterbi algorithm [ 17 ] is implemented to find the most likely tag sequence .Abbreviation resolution .In the competition , we present an effective and efficient algorithm to resolve abbreviations accurately by mapping them to their full forms .", "label": "", "metadata": {}, "score": "64.79767"}
{"text": "The particular issue investigated in this paper is whether complementary informa- tion that may be represented by ASR systems defined over multiple phonological feature systems can be exploited using system integra- tion methodologies .The methodologies explored here include lat- tice re - scoring based methods like those reported in [ 2 ] and system combination methods like those described in [ 3 , 4].", "label": "", "metadata": {}, "score": "64.91123"}
{"text": "These collections , however , represent newswire texts from more than eighty newspapers and television or broadcasting stations .The samples from these sources account for around two thirds of texts for the press categories ( A - C ) .The other one third are sampled from newswire texts from Xinhua News Agency ( excerpted from the PH Corpus ) .", "label": "", "metadata": {}, "score": "64.92433"}
{"text": "The same study , which was also performaned for the Fly organism , showed similar results , but with slightly higher ambiguity rates .For a more complete description of this study and the results , please [ see additional file 1 ] .", "label": "", "metadata": {}, "score": "64.97174"}
{"text": "Mooney RJ : Comparative experiments on disambiguating word senses : An illustration of the role of bias in machine learning .Proc 1996 Conf on Empirical Methods in Natural Language Processing 82 - 91 .Ng HT , Lee HB : Integrating multiple knowledge sources to disambiguate word sense : An examplar - based approach .", "label": "", "metadata": {}, "score": "65.00264"}
{"text": "In the second row , the parameters were empirically estimated from the development set and in the third row , the parameters were estimated using DMC .It is clear from the ta- ble that the phone accuracy obtained using DMC based estimation of the log linear weights is not significantly different from the phone accuracy obtained by empirical estimation of these weights .", "label": "", "metadata": {}, "score": "65.0216"}
{"text": "The algorithm works as follows Given a sentence with parentheses , we use a similar algorithm as in Schwartz et al [ 18 ] to determine whether it is an abbreviation with parentheses .This is done by starting from the end of both the abbreviation and the expanded form , moving from right to left and trying to find the shortest expanded form that matches the abbreviation .", "label": "", "metadata": {}, "score": "65.047066"}
{"text": "A similar process is applied to the right edge of the multi - word gene mention using the list of words known not to be tagged as GENE_END .The following lines show the POS counts in the training corpus for the words binding and regulator .", "label": "", "metadata": {}, "score": "65.084335"}
{"text": "Borko [ 6 ] advocates the use of pre - selected terms to represent each document .In contrast , [ 7 , 9 , 14 , 16 , 18 , 20 , 23 ] extract all the terms from the documents to act as content - representatives - albeit using some filtering sometimes , such as using only the highest - weighted n terms [ 7 ] .", "label": "", "metadata": {}, "score": "65.09367"}
{"text": "Evaluation shows that our system achieves the best performance from among 10 systems with a balanced F - measure of 82.58 on the closed evaluation of the BioCreative protein / gene name recognitiontask ( Task 1A ) .Background .With an overwhelming amount of textual information in biomedicine , there is a need for effective and efficient literature mining and knowledge discovery that can help biologists to gather and make use of the knowledge encoded in text documents .", "label": "", "metadata": {}, "score": "65.15736"}
{"text": "Mitigation strategies for handling redundancy .Metadata - based baseline .The metadata - based mitigation strategy leverages the note creation date , the note type and the patient identifier information and selects the last available note per patient in the corpus .", "label": "", "metadata": {}, "score": "65.16293"}
{"text": "SPE , GP and MV , respectively .These observation vectors are input to the HMM - based feature - to - phone mapping in Section 3.3 .HMM Based Feature - to - Phone Mapping Continuous diagonal mixture Gaussian observation density HMM models were used to map from frame level phonological feature based observations derived from the discriminative networks described in Section 3.1 to phone sequences .", "label": "", "metadata": {}, "score": "65.17229"}
{"text": "As such , the LDA topics group words that tend to co - occur .From the viewpoint of disease modeling , LDA topics are an attractive data modeling and corpus exploration tool .As illustrative examples , we show the top-20 tokens corresponding to three topics acquired from a corpus of patient notes in Table 1 .", "label": "", "metadata": {}, "score": "65.22003"}
{"text": "Methods for identifying redundancy in large string - based databases exist in both bioinformatics and plagiarism detection [ 40 - 42 ] .A similar problem has been addressed in the creation of sequence databases for bioinformatics : Holm and Sander [ 43 ] advocated the creation of non - redundant protein sequence databases and suggested that databases limit the level of redundancy .", "label": "", "metadata": {}, "score": "65.26551"}
{"text": "xi m(1 ) , ... , ?Discriminative Model Combination One approach pursued in automatic speech recognition for optimum integration of multiple acoustic and language models is discrimi- native model combination ( DMC ) .This approach has been applied in situations where the cost or likelihood of a system incorporating multiple models can be represented as one general log - linear poste- rior probability distribution [ 13].", "label": "", "metadata": {}, "score": "65.2798"}
{"text": "Initial passes were used for test - data warp factor selection , gender determination and finding an initial word string for unsupervised mean and variance maximum likelihood linear regression ( MLLR ) adaptation [ 8 , 3 ] .Word - level lattices were then created using adapted triphone HMMs and a bigram model which were expanded to included the full 4-gram and class model probabilities .", "label": "", "metadata": {}, "score": "65.293076"}
{"text": "Also shown is the distribution of the lengths ( in words ) of the gene mentions .Task1A has two divisions : open and closed .The open division permits systems to use external data resources such as online dictionaries or databases while the closed division does not .", "label": "", "metadata": {}, "score": "65.315025"}
{"text": "This is similar to the approach used by Arnold et al .( 2010 ) [ 28 ] and is accepted as a method for comparing LDA performance [ 54 ] .The topic models were learned using the Collapsed Gibbs Sampler provided in Mallet [ 55 ] with the recommended parameters and with hyper - parameter optimization as described in Wallach et al .", "label": "", "metadata": {}, "score": "65.3689"}
{"text": "However the observed decrease in error rate was more dramatic in the cases where the different senses were well separated .For example , in BSA , the error rate dropped to approximately 5 % when the sample size was 80 and the sense distributions were almost balanced , and it was approximately 8 % for other distributions with the same size .", "label": "", "metadata": {}, "score": "65.381874"}
{"text": "PubMed View Article .Li W : Random texts exhibit Zipf's - law - like word frequency distribution .Information Theory , IEEE Transactions on 1992 , 38 ( 6 ) : 1842 - 1845 .View Article .Yoshimasa Tsuruoka YT , Jin - Dong K , Tomoko O , Sophia A , Jun'ichi T : Developing a Robust Part - of - Speech Tagger for Biomedical Text .", "label": "", "metadata": {}, "score": "65.46993"}
{"text": "Our base system without post - processing achieved a precision and recall of 68.0 % and 77.2 % , respectively , giving an F - measure of 72.3 % .The full system with post - processing achieved a precision and recall of 80.3 % and 80.5 % giving an F - measure of 80.4 % .", "label": "", "metadata": {}, "score": "65.54446"}
{"text": "The subsequent sections give the details of a number of experiments that we performed in system development .This is followed by a description of , and the results from , the 1998 Hub4 evaluation system .The full recognition results from the various stages of operation are included .", "label": "", "metadata": {}, "score": "65.64115"}
{"text": "In the clinical domain , Arnold et al .[28 ] used LDA for comparing patient notes based on topics .A topic model was learned for different cohorts , with the number of topics derived experimentally based on log - likelihood fit of the created model to a test set .", "label": "", "metadata": {}, "score": "65.65558"}
{"text": "On other test sets improvements greater than 1 % absolute have also been obtained and size of the gains is found to be fairly independent of the complexity of the underlying system .A side - dependent block - full variance ( FV ) transformation [ 4 ] , , of the form was investigated .", "label": "", "metadata": {}, "score": "65.658875"}
{"text": "Intelligent Systems , IEEE 2009 , 24 ( 2 ) : 8 - 12 .View Article .Dredze M , Blitzer J , Talukdar PP , Ganchev K , Graca J , Pereira F : Frustratingly hard domain adaptation for dependency parsing .", "label": "", "metadata": {}, "score": "65.67445"}
{"text": "Although we have applied a name refinement module to filter such errors , it is always difficult to cover special cases .Conclusion .In this paper , we first propose an ensemble of classifiers for biomedical name recognition via a simple majority voting strategy to effectively integrate various domain - specific features and then present several ad - hoc post - processing modules to further improve the performance .", "label": "", "metadata": {}, "score": "65.68843"}
{"text": "In this study , we used 4 abbreviations from Liu 's abbreviation list .However , we used a different method to collect the datasets because we wanted to control the sample sizes of the senses for our experiments .Leroy [ 30 ] tried to reduce the training sample size by supplying external knowledge from the UMLS for supervised machine learning algorithms , but the results were not promising .", "label": "", "metadata": {}, "score": "65.739784"}
{"text": "The following sub - section presents the results obtained on each of the three corpora .In Section 3 , we described how in our system , a document is clustered with the first category it encounters with which it has a similarity higher than the threshold .", "label": "", "metadata": {}, "score": "65.78164"}
{"text": "The three feature sets , SPE , MV , and GP , differ both in the level of hierarchy that are embedded in the representations and also in the balance between acoustic and phonological features that are repre- sented .It is natural to expect that using these different feature sys- tems in phone recognition could potentially result in decoded phone strings whose errors are complementary .", "label": "", "metadata": {}, "score": "65.82023"}
{"text": "The use of quinphone models instead of triphone models gives a further gain of 0.9 % for both branches .Whereas the second adaptation stage with two speech transforms for the quinphone MMIE models brings 0.5 % , after obtaining CN output the difference is only 0.2 % .", "label": "", "metadata": {}, "score": "65.86459"}
{"text": "These were constructed by training separate models for transcriptions of the Hub5 acoustic training data and for Broadcast News data and then merging the resultant language models to effectively interpolate the component N - grams .The word - level 4-grams used were smoothed with a class - based trigram model using automatically derived classes [ 12 ] .", "label": "", "metadata": {}, "score": "65.87453"}
{"text": "First , phonological fea- ture and MFCC based systems are combined in a lattice re - scoring paradigm .Second , confusion network based system combination ( CNC ) is used to combine phone networks derived from phonologi- cal distinctive feature ( PDF ) and MFCC based systems .", "label": "", "metadata": {}, "score": "65.88135"}
{"text": "Banerjee S , Pedersen T : The design , implementation , and use of the ngram statistics package .[Computational Linguistics and Intelligent Text Processing ] .Wallach HM , Murray I , Salakhutdinov R , Mimno D : Evaluation methods for topic models .", "label": "", "metadata": {}, "score": "65.91188"}
{"text": "This FV transform was used with , for the wideband data , HMMs estimated with a single iteration of speaker adaptive training ( SAT ) [ 14 ] to update the mean parameters .The effect of these changes is shown in Table 5 .", "label": "", "metadata": {}, "score": "65.92342"}
{"text": "High redundancy and copy - and - paste operations in the notes create a biased sample of the \" patient note \" genre .From a practical perspective , redundant data in a corpus lead to waste of CPU time in corpus analysis and waste of I / O and storage space especially in long pipelines , where each stage of data processing yields an enriched set of the data .", "label": "", "metadata": {}, "score": "65.94808"}
{"text": "While a small number of samples , if they were conformant with our sampling frame , were collected from the Internet , most samples were provided by the SSReader Digital Library in China .As each page of electronic books in the library comes in PDG format , these pages were transferred into text files using an OCR program provided by the digital library .", "label": "", "metadata": {}, "score": "65.96764"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of BPD data set ( where there are 3 ambiguous senses that are different ) using 5-fold cross validation and \" one - vs - rest \" algorithm .", "label": "", "metadata": {}, "score": "65.98981"}
{"text": "The information in notes can be found in the form of narrative and semi - structured format through lists or templates with free - text fields .As such , much research has been devoted to parsing and information extraction of clinical notes [ 1 - 3 ] with the goal of improving both health care and clinical research .", "label": "", "metadata": {}, "score": "66.022064"}
{"text": "Perotte A , Bartlett N , Elhadad N , Wood F : Hierarchically Supervised Latent Dirichlet Allocation .[ NIPS :2011 ] .Bisgin H , Liu Z , Fang H , Xu X , Tong W : Mining FDA drug labels using an unsupervised learning technique - topic modeling .", "label": "", "metadata": {}, "score": "66.03577"}
{"text": "Table 6 lists the evaluation system performance on the March 2000 evaluation set .The performance on eval00 gives a similar per stage improvement to that obtained for eval98 .However the absolute WER levels are reduced by about 10 % absolute .", "label": "", "metadata": {}, "score": "66.06342"}
{"text": "Liu H , Teller V , Friedman C : A multi - aspect comparison study of supervised word sense disambiguation .J Am Med Inform Assoc 2004 , 11 : 320 - 331 .View Article PubMed .Leroy G , Rindflesch TC : Effects of information and machine learning algorithms on word sense disambiguation with small datasets .", "label": "", "metadata": {}, "score": "66.21884"}
{"text": "If each ambiguous gene symbol in an article were accompanied by its corresponding long form , the disambiguation task would be much easier .Schijvenaars [ 13 ] showed that 33 % of the human genes in their thesaurus were affected by homonymy .", "label": "", "metadata": {}, "score": "66.25715"}
{"text": "When analysing the results obtained from the evaluation of our clustering system , one can notice that our system attains very poor results when clustering the Reuters - RCV1 corpus .On the other hand , it achieves very good results when clustering the Google News corpus .", "label": "", "metadata": {}, "score": "66.32589"}
{"text": "Page 2 . based system combination can result in significant improvement in phone accuracy .An experimental study is described in Section 6 that evaluates the effects of the above techniques on phone recognition accuracy ( PAC ) .Performance obtained using different strategies for combin-", "label": "", "metadata": {}, "score": "66.34675"}
{"text": "PubMed View Article .Hirschtick R : A piece of my mind .Copy - and - paste .JAMA 2006 , 295 ( 20 ) : 2335 - 2336 .PubMed View Article .Yackel TR , Embi PJ : Copy - and - paste - and - paste .", "label": "", "metadata": {}, "score": "66.3512"}
{"text": "The estimates of the word posterior probabilities encoded in the confusion networks can be used directly as confidence scores ( which are essentially word - level posteriors ) , but they tend to be over - estimates of the true posteriors .", "label": "", "metadata": {}, "score": "66.35652"}
{"text": "Table 4 shows the individual post - processing effects in our cross - validation testing .It shows that removing rule - based post - processing or removing the lexicon - based post - processing from the post - processing steps has nearly the same effect .", "label": "", "metadata": {}, "score": "66.36405"}
{"text": "Stokes [ 15 ] adapts the k - means clustering algorithm for First Story Detection such that clustering is performed on incoming documents read from a stream .In this algorithm , each document is compared to existing clusters and is placed into a cluster if the cluster - document similarity exceeds a pre - defined threshold .", "label": "", "metadata": {}, "score": "66.36947"}
{"text": "The NSP package we use in our experiments is widely used for collocation and n - gram extraction in the clinical domain [ 19 - 22 ] .Collocations in a corpus of clinical notes are prime candidates to be mapped to meaningful phenotypes [ 19 - 21 ] .", "label": "", "metadata": {}, "score": "66.41124"}
{"text": "325 - 328 .[ 3 ] J. Fiscus , \" A post - processing system to yield reduced word error rates : Recogniser output voting error reduction ( ROVER ) , \" Proceedings 1997 IEEE Workshop on Automatic Speech Recognition and Understanding , pp .", "label": "", "metadata": {}, "score": "66.412"}
{"text": "Documents are added one by one to the new corpus , a document sharing a proportion of fingerprints larger than the cutoff value with a document already in the corpus is not added .See Figure 6 for pseudo code of this algorithm .", "label": "", "metadata": {}, "score": "66.42374"}
{"text": "That both sets of results show the same trends shows that our system did not over - train on the devtest corpus and that it performs consistently .Precision and Recall .Figure 1A shows the precision and recall for the cross validation data .", "label": "", "metadata": {}, "score": "66.428314"}
{"text": "Once the news reports have been converted to their corresponding representation , the similarities between the different news reports are calculated as necessary .Each similarity is measured using the distance function that is most widely used within the reviewed document clustering systems - the Cosine Similarity measure .", "label": "", "metadata": {}, "score": "66.50869"}
{"text": "In our implementation , the full variance transform was computed after standard mean and variance maximum likelihood linear regression ( MLLR ) .Typically a WER reduction of 0.5 % to 0.8 % was obtained .However as a side effect , we found that there were reduced benefits from multiple iterations of MLLR when used with a full variance transform .", "label": "", "metadata": {}, "score": "66.53137"}
{"text": "But some reported that certain classification algorithms were better than others .It is still an unclear issue , probably due to the interaction of different combinations of issues .The comparison between different classifiers should be a carefully controlled experiment .", "label": "", "metadata": {}, "score": "66.56815"}
{"text": "In contrast to MLE , discriminative training schemes , such as Maximum Mutual Information Estimation ( MMIE ) take account of possible competing word hypotheses and try to reduce the probability of incorrect hypotheses .The objective function to maximise in MMIE is the posterior probability of the true word transcriptions given the training data .", "label": "", "metadata": {}, "score": "66.58082"}
{"text": "In this section a short overview of its features is given ( see [ 6 ] for details ) .The system uses perceptual linear prediction cepstral coefficients derived from a mel - scale filterbank ( MF - PLP ) [ 18 ] covering the frequency range from 125Hz to 3.8kHz .", "label": "", "metadata": {}, "score": "66.65065"}
{"text": "333 - 353 , 2000 .[ 2 ] R.C. Rose and P. Momayyez , \" Integration of multiple feature sets for reducing ambiguity in ASR , \" in Proceedings of the In- ternational Conference on Acoustics , Speech , and Signal Pro- cessing , Hawaii , April 2007 , vol .", "label": "", "metadata": {}, "score": "66.67205"}
{"text": "Blei DM , Ng AY , Jordan MI : Latent dirichlet allocation .J Mach Learn Res 2003 , 3 : 993 - 1022 .Arnold CW , El - Saden SM , Bui AAT , Taira R : Clinical Case - based Retrieval Using Latent Topic Analysis .", "label": "", "metadata": {}, "score": "66.67331"}
{"text": "We empirically measure the damage caused by redundancy on the tasks of collocation extraction and topic modeling through a series of controlled experiments .Preliminary qualitative inspection of the results suggests that idiosyncrasies of each patient ( where the redundancy occurs ) explain the observed bias .", "label": "", "metadata": {}, "score": "66.67718"}
{"text": "In contrast , Cardoso - Cachopo [ 17 ] describes a method to calculate the vector centroid based on the Rocchio algorithm .In this method , the centroid vector of a particular cluster is taken to be the sum of all the document vectors for positive training examples for that cluster subtracted by the sum of all the document vectors for negative training examples for that cluster .", "label": "", "metadata": {}, "score": "66.72361"}
{"text": "Given a corpus , a histogram of term frequencies is computed to examine whether the corpus follows Zipf 's law .According to Zipf 's law , terms frequencies have a long tail in their distribution : that is , very few terms occur frequently ( typically function words and prominent domain words ) while most terms occur only once or twice in the corpus overall .", "label": "", "metadata": {}, "score": "66.728836"}
{"text": "Results .Overall .We did five rounds of cross - validation , training on four subsets of the data and testing on a fifth using a combined corpus consisting of the training and devtest data .We evaluated our results using the scoring software provided with the BioCreAtIvE data .", "label": "", "metadata": {}, "score": "66.76176"}
{"text": "It should be emphasised that the MMIE models were all gender independent while the MLE VTLN models were all gender dependent using soft - tying .All the acoustic models used Call Home weighting .9.2 Word List & Language Models .", "label": "", "metadata": {}, "score": "66.76904"}
{"text": "\" Sample size ' , \" sense distribution \" and \" degree of difficulty \" were three of multiple confounding issues that affect the performance of a WSD classifier .Results from our experiments demonstrated that these three factors were intrinsically connected .", "label": "", "metadata": {}, "score": "66.80542"}
{"text": "In this paper , we address two issues that are related to domain adaptation .The first question is how much genre variation will affect NLP systems ' performance .We investigate the effect of genre variation on the performance of three NLP tools , namely , word segmenter , POS tagger , and parser .", "label": "", "metadata": {}, "score": "66.899155"}
{"text": "The subject is of interest to biologists because it is a necessary first step in many kinds of applications that are of interest to them , including information extraction , information retrieval , and bibliometrics .It is of interest to linguists and computer scientists because it seems to be more difficult than entity identification in \" general English \" domains [ 1 ] .", "label": "", "metadata": {}, "score": "66.90133"}
{"text": "For official test the score achieved precision of 41.3 and recall of 43.4 .These results are considerably worse than even our without - post - processing results .Per - token precision and recall .We then determined the results on a per - word basis .", "label": "", "metadata": {}, "score": "66.933624"}
{"text": "The results presented here agree with general results presented in the literature on the performance of classifiers [ 43 - 45 ] .Future work .To further analyze the effects of \" sample size \" , \" sense distribution \" and \" degree of difficulty \" on the error rate , an error decomposition model will be explored .", "label": "", "metadata": {}, "score": "66.93739"}
{"text": "Post - processing is effective on all gene mentions of any length .However , it seems that improvement in performance is greater for longer gene mentions .This is probably due to lexicon - based post - processing that corrects boundaries .", "label": "", "metadata": {}, "score": "66.95328"}
{"text": "For the case where the system has just started processing its first documents , a special procedure is performed for the weighting of those documents ' terms .Before starting the categorisation process , the system waits for the first 70 documents to be available for processing , and initialises a global index with the occurrence frequencies of these documents ' terms within this initial collection of 70 documents .", "label": "", "metadata": {}, "score": "67.0009"}
{"text": "Therefore the recall is lower and the precision is higher .The most probable reason for better results is that the baseline system knows the number of clusters to produce beforehand , and also performs cluster reorganisation .The results obtained by our system and the baseline system when clustering the Yahoo !", "label": "", "metadata": {}, "score": "67.020706"}
{"text": "Mutual information and topic modeling .Collocation identification was carried out on the different corpora using the Ngram Statistics Package [ 53 ] , which provides an implementation for collocation detection using True Mutual Information ( TMI ) and Pointwise Mutual Information ( PMI ) .", "label": "", "metadata": {}, "score": "67.02528"}
{"text": "The F - measure , which in our case is the average between the recall and precision , is very low as a result of the very low precision values .The baseline clustering system produces better results albeit still with very low F - measure values .", "label": "", "metadata": {}, "score": "67.02583"}
{"text": "It uses a second - order Markov model with tags as states and words as outputs .Smoothing is done with linear interpolation of unigrams , bigrams , and trigrams , with \u03bb estimated by deleted interpolation .Unknown words are handled by learning tag probabilities for word endings .", "label": "", "metadata": {}, "score": "67.10244"}
{"text": "In the competition , 53 TW1 and 51 TW2 trigger words are used .Support Vector Machine .Support Vector Machine ( SVM ) is a powerful machine learning method , which has been applied successfully in biomedical name recognition [ 7 , 8 ] .", "label": "", "metadata": {}, "score": "67.141556"}
{"text": "In this way , we can correct the boundary error of the full form which defines an abbreviation .In addition , we can classify the abbreviation according to the prediction of its full form , since we assume it is more accurate to classify the full form than the abbreviation .", "label": "", "metadata": {}, "score": "67.166"}
{"text": "Arora , R. ; Bangalore , P. Text Mining : Classification & Clustering of Articles Related to Sports .In ACM - SE 43 : Proceedings of the 43rd Annual Southeast Regional Conference , Kennesaw , GA , USA , 18 - 20 March 2005 ; ACM : New York , NY , USA , 2005 ; pp .", "label": "", "metadata": {}, "score": "67.17134"}
{"text": "The first system was motivated by the distinctive features originally defined in Chomsky and Halle 's , The sound pattern of English ( SPE ) [ 5].The first feature set , referred to as SPE , consists of a set of thirteen binary features .", "label": "", "metadata": {}, "score": "67.17203"}
{"text": "The number of topics is a free parameter of LDA - given two LDA models with the same log - likelihood on withheld data , the one with the lower number of topics has better explanatory power ( fewer latent variables or topics are needed to explain the data ) .", "label": "", "metadata": {}, "score": "67.218796"}
{"text": "Affiliated with .Affiliated with .Abstract .Background .Our approach to Task 1A was inspired by Tanabe and Wilbur 's ABGene system [ 1 , 2 ] .Like Tanabe and Wilbur , we approached the problem as one of part - of - speech tagging , adding a GENE tag to the standard tag set .", "label": "", "metadata": {}, "score": "67.23357"}
{"text": "When the senses are well separated , any increase in the sample size results in a statistically significant decrease of the error rate .This holds for all sense distributions and it is in agreement with the finding that for BSA there was no significant effect of the sense distributions on the error rates for the different sample sizes used .", "label": "", "metadata": {}, "score": "67.239365"}
{"text": "It is well known that parsing accuracy suffers when a model is applied to out - of - domain data .It is also known that the most beneficial data to parse a given domain is data that matches the domain ( Sekine , 1997 ; Gildea , 2001 ) .", "label": "", "metadata": {}, "score": "67.24635"}
{"text": "Conventional wisdom is that larger corpora yield better results in text mining .In fact , it is well established empirically that larger datasets yield more accurate models of text processing ( see for example , [ 31 - 34 ] ) .", "label": "", "metadata": {}, "score": "67.345764"}
{"text": "Page 4 . system WER when the average individual system error rates are sim- ilarbutthe nature ofthe errorsfromthe individual systemsarediffer- ent .TheexperimentalstudyinSection6investigatestheeffectofap- plying this same class of system combination techniques as a means for integrating the multiple phonological feature based phone recog- nition systems described in Section 3 .", "label": "", "metadata": {}, "score": "67.38464"}
{"text": "The main effect of rule - based and lexicon - based post - processing is an increase in precision .In cross - validation for full gene names , average precision increased from 68.0 to 82.0 , and average recall increased from 76.6 to 81.1 .", "label": "", "metadata": {}, "score": "67.43828"}
{"text": "The pure MLE system ( MLE models in P2/P3 and MLE lattices ) performs 2.1 % absolute poorer than the MMIE system on P2 .Comparing the performance of MLE models in P4b , they are 0.7 % poorer than in the eval setup ( MLE models with MMIE lattices and adaptation supervision ) without confusion networks but only 0.3 % poorer with confusion networks .", "label": "", "metadata": {}, "score": "67.56331"}
{"text": "As shown in [ 19 ] the gains from MLLR adaptation are as great for MMIE models as for MLE trained models .Hence the primary acoustic models used in the March 2000 CU - HTK evaluation system used gender - independent MMIE trained HMMs .", "label": "", "metadata": {}, "score": "67.56699"}
{"text": "[ Google Scholar ] .Toda , H. ; Kataoka , R. A Clustering Method for News Articles Retrieval System .In WWW ' 05 : Special Interest Tracks and Posters of the 14th International Conference on World Wide Web , Chiba , Japan , 10 - 14 May 2005 ; ACM Press : New York , NY , USA , 2005 ; pp .", "label": "", "metadata": {}, "score": "67.64299"}
{"text": "This dataset contains 1561 news reports downloaded in January 2011 that are covering 205 different news events .Borko [ 6 ] , Larsen [ 7 ] and Toda [ 11 ] evaluate their clustering methods by comparing their automatic clustering results with manual clustering results .", "label": "", "metadata": {}, "score": "67.66258"}
{"text": "Similarly , using quinphone models with MLLR a gain of 0.5 % in WER was achieved with increased training data .We also did some experiments that used automatic segmentation of the extended training data to try and ensure that the segments used in training were acoustically homogeneous but this provided no additional improvements .", "label": "", "metadata": {}, "score": "67.691635"}
{"text": "First P1 ( GI non - VTLN MLE triphones , trigram LM , 27k dictionary ) , generated an initial transcription .This P1 pass is identical to the 1998 P1 setup [ 6 ] .The P1 output was used solely for VTLN warp - factor generation and assignment of a gender label for each test conversation side .", "label": "", "metadata": {}, "score": "67.74713"}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT :In this paper we undertake the extraction of phonological fea - tures applied to Spanish language .Also propose a method to integrate these features into an HMM based speech recogni - tion system using an architecture that uses independent feature streams .", "label": "", "metadata": {}, "score": "67.77882"}
{"text": "McClosky et al .( 2010 ) coined the term multiple source domain adaptation .Similar to us , McClosky et al .( 2010 ) regard a target domain as mixture of source domains , b .. by Joseph Le Roux , Jennifer Foster , Joachim Wagner , Rasul Samad , Zadeh Kaljahi , Anton Bryl . \" ...", "label": "", "metadata": {}, "score": "67.77905"}
{"text": "EHR corpora .We collected a corpus of patient notes from the clinical data warehouse of the New York - Presbyterian Hospital .The study was approved by the Institutional Review Board ( IRB - AAAD9071 ) and follows HIPAA ( Health Insurance Portability and Accountability Act ) privacy guidelines .", "label": "", "metadata": {}, "score": "67.79393"}
{"text": "Conversely , precision is the fraction of the retrieved documents that are relevant to the query .The F - measure metric is calculated as a weighted average of recall and precision .The use of these metrics in Document Clustering is discussed in [ 7 , 10 , 13 , 17 , 19 ] .", "label": "", "metadata": {}, "score": "67.8014"}
{"text": "By comparing the oracle phone recognition results achieved by assuming that all the phonological features are correctly detected based on each feature set , we show that selecting an appropriate phonological feature set is crucial to the performance of detection - based ASR .", "label": "", "metadata": {}, "score": "67.82515"}
{"text": "Contributions of various features in our best closed system ( closed-3 ) : decrease in precision / recall / F - measure by leaving one feature at a time .Finally , in order to further evaluate our system , we have implemented an error analysis .", "label": "", "metadata": {}, "score": "67.82614"}
{"text": "Supervised ML methods have also been applied to WSD in the biomedical domain .Hatzivassiloglou [ 10 ] developed a disambiguation system to determine the class of a known biomedical named entity by choosing one of three pre - defined senses : gene , RNA , protein .", "label": "", "metadata": {}, "score": "67.82976"}
{"text": "Therefore , computation of the above model consists of two parts .The first is to compute the state transition model : .Here , the traditional ngram modeling ( e.g. trigram ) is used .The second is to estimate the output model : .", "label": "", "metadata": {}, "score": "67.86093"}
{"text": "PubMed View Article .Wrenn JO , Stein DM , Bakken S , Stetson PD : Quantifying clinical narrative redundancy in an electronic health record .J Am Med Inform Assoc 2010 , 17 ( 1 ) : 49 .PubMed View Article .", "label": "", "metadata": {}, "score": "67.911255"}
{"text": "A Post - Processing System to Yield Reduced Word Error Rates : Recogniser Output Voting Error Reduction ( ROVER ) .Proc .IEEE Workshop on Automatic Speech Recognition and Understanding , pp .347 - 354 , Santa Barbara .P.S. Gopalakrishnan , D. Kanevsky , A. Nadas & D. Nahamoo ( 1991 ) .", "label": "", "metadata": {}, "score": "67.931526"}
{"text": "Without DMC , it would be nearly impossible to obtain em- pirical estimates of these weights by exhaustively tuning them on a development set for each different experimental scenario .In order to demonstrate that there is no significant performance degradation as- sociated with using DMC in estimating \u039b , the performance of PDF feature integration for both DMC and empirical estimation of \u039b is shown in Table 4 .", "label": "", "metadata": {}, "score": "67.935684"}
{"text": "The system achieved an accuracy rate of 92.7 % on an automatically generated testing set .Schijvenaars 's study described an effective method for gene disambiguation , but the evaluation results were limited to certain conditions .The automatically generated testing set contained human genes symbols that appeared as long - form and short - form pairs ( e.g. prostate specific antigen ( PSA ) ) in articles , where at least 6 articles were determined to be associated with each gene sense .", "label": "", "metadata": {}, "score": "67.94348"}
{"text": "For collocations detection , in Reduced Redundancy Informative Notes , 6,034 collocations were extracted , on average each collocation is supported by 37 distinct patients and collocations supported by 3 patients or less make 6 % of the extracted collocation .We see a significant reduction in the number of collocations based on very few patients from 36 % to 6 % ( Table 3 ) .", "label": "", "metadata": {}, "score": "67.970276"}
{"text": "Proc of the 40th Annual Meeting of the Association for Computational Linguistics ( ACL ) 2002 , 473 - 480 .Salton G , Buckley C : Improving retrieval performance by relevance feedback .Journal of American Society for Information Systems 1990 , 41 : 288 - 297 .", "label": "", "metadata": {}, "score": "68.03389"}
{"text": "These works aim to predict the parser performance on a given target sentence .Ravi et al .( 2008 ) frame this as a regression problem .Kawahara and Uchimoto ( 2008 ) treat ... . \" ...Genre classification has been found to improve performance in many applications of statistical NLP , including language modeling for spoken language , domain adaptation of statistical parsers , and machine translation .", "label": "", "metadata": {}, "score": "68.046936"}
{"text": "An additional issue is that this study limited the disambiguation of gene symbols to gene senses and one other category called \" non - gene sense \" , but the actual sense in this category was not resolved .This could be critical for NLP systems accessing phenotypic or disease - related information .", "label": "", "metadata": {}, "score": "68.14845"}
{"text": "In evaluating our system , we found that our system is very good in performing fine - grained clustering , but performs rather poorly when performing coarser - grained clustering .Keywords : . clustering ; news ; eventdetection ; incrementalclustering .", "label": "", "metadata": {}, "score": "68.148994"}
{"text": "One more important problem associated with all three sets of phonological feature vectors is the potential high corre- lation among individual outputs from the neural networks .Principal components analysis ( PCA ) was applied to estimating linear trans- formations that result in a transformed feature space where feature vectors are approximately uncorrelated .", "label": "", "metadata": {}, "score": "68.15799"}
{"text": "Proceedings of the ACL'2003 Workshop on Natural Language Processing in Biomedicine , Sapporo , Japan 2003 , 33 - 40 .Shen Dan , Zhang Jie , Zhou GuoDong , Su Jian , Tan Chew Lim : Effective Adaptation of a Hidden Markov Model - based Named Entity Recognizer for Biomedical Domain , .", "label": "", "metadata": {}, "score": "68.18669"}
{"text": "To understand the effects of increased sample size on the error rate , we stratified by the sense distribution and then tested the null hypothesis of no difference between the error rates obtained under the different sample sizes using the sign test .", "label": "", "metadata": {}, "score": "68.19797"}
{"text": "The POS tagger .Past experience with the ABGene system in our lab suggested that the POS - tagging - based approach to entity identification is workable in the molecular biology domain .Previous experiments with the TnT Trigrams ' n ' Tags POS tagger , using the GENIA corpus for cross - validation , showed good results with no post - processing of the output .", "label": "", "metadata": {}, "score": "68.27386"}
{"text": "To be able to identify whether there are significant differences in the error rates due to different sample sizes and sense distributions while controlling for the abbreviation used , we used Friedman 's procedure .Notice that if we stratify by the abbreviation , the mean error rates form a two - way table where the columns correspond to different sample sizes and the rows correspond to different sense distributions .", "label": "", "metadata": {}, "score": "68.274124"}
{"text": "However , such models may be too complex to be feasible to be applied to automatic document analysis .The issue of efficiency is felt more deeply in real time systems .According to Luo [ 14 ] , new event detection systems always assume that there are enough resources available to perform the necessary computation , and thus they only focus on accuracy and do not give efficiency its proper attention .", "label": "", "metadata": {}, "score": "68.322845"}
{"text": "Metric for assessing redundancy at the patient level .Given two notes , we computed redundancy for the pair by aligning the two notes .We applied the Smith - Waterman text alignment algorithm , a commonly used string alignment algorithm in bioinformatics [ 52 ] .", "label": "", "metadata": {}, "score": "68.33696"}
{"text": "Markatou M , Tian H , Biswas S , Hripcsak G : Analysis of variance of cross - validation estimators of the generalization error .Journal of Machine Learning Research 2005 , 6 : 1127 - 1168 .Resnik P , Yarowsky D : Distinguishing systems and distinguishing senses : New evaluation tools for words sense disambiguation .", "label": "", "metadata": {}, "score": "68.35648"}
{"text": "[ 39 ] suggested a model for unsupervised information extraction which takes redundancy into account when extracting information from the web .They showed that the popular information extraction method , Pointwise Mutual Information ( PMI ) , is less accurate by an order of magnitude compared to a method with redundancy handling .", "label": "", "metadata": {}, "score": "68.48235"}
{"text": "Endnotes .Declarations .Acknowledgements .This work was supported by a National Library of Medicine grant R01 LM010027 ( NE ) .Any opinions , findings , or conclusions are those of the authors , and do not necessarily reflect the views of the funding organization .", "label": "", "metadata": {}, "score": "68.82739"}
{"text": "It increases the recall by 1.5 % but decreases the precision by 0.4 % .While the abbreviation resolution is very general , the name refinement and the dictionary matching are fine - tuned based on the error analysis of the development set and may be very much dependent on the development set .", "label": "", "metadata": {}, "score": "68.83788"}
{"text": "With the same sample size change , the error rate for PCA dropped from 43.00 % to only 28.53 % .Results for BPD are shown in Table 5 , which contains the results from three different multi - class SVM algorithms .", "label": "", "metadata": {}, "score": "69.00714"}
{"text": "The third phonological feature system is based on multiple prop- ertiesofthespeechspectrumreferredtoas\"primes\"andismotivated by the theory Government Phonology ( GP ) [ 6].This will be referred toastheGPphonologicalfeaturesystem .TheGPfeaturesystemdif- fers from SPE and MV feature systems primarily in that it is defined with respect to acoustic classes rather than the speech production classes of the SPE and MV .", "label": "", "metadata": {}, "score": "69.0279"}
{"text": "The Reduced Redundancy Informative Notes corpus contains 3,970 patient notes , 3.18 as many notes as the Last Informative Notes corpus while having same - patient redundancy of only 9.8 % compared to 29 % in the All Informative Notes Corpus .", "label": "", "metadata": {}, "score": "69.09557"}
{"text": "Advances in informatics 2005 , LNCS 3746 : 382 - 392 .View Article .Smith TF , Waterman MS , Fitch WM : Comparative biosequence metrics .J Mol Evol 1981 , 18 ( 1 ) : 38 - 46 .", "label": "", "metadata": {}, "score": "69.12842"}
{"text": "[ Google Scholar ] .Kang , B.H. ; Kim , Y.S. ; Choi , Y.J. Does Multi - User Document Classification Really Help Knowledge Management ?In AI ' 07 : Proceedings of the 20th Australian Joint Conference on Advances in Artificial Intelligence , Gold Coast , Australia , 2 - 6 December 2007 ; Springer - Verlag : Berlin / Heidelberg , Germany , 2007 ; pp .", "label": "", "metadata": {}, "score": "69.21742"}
{"text": "This rule applies only to the open division .If one of the previous rules did not tag the long form and the abbreviation with GENE , then apply the following .If the abbreviation was more than three characters long and was tagged as GENE , then we double - checked it against data from NCBI ( see Section Dictionary - based post - processing below ) .", "label": "", "metadata": {}, "score": "69.22389"}
{"text": "[ Google Scholar ] .Braun , R.K. ; Kaneshiro , R. Exploiting Topic Pragmatics for New Event Detection in tdt-2004 , Proc . of Topic Detection and Tracking Workshop ; ACM Press : New York , NY , USA , 2004 .", "label": "", "metadata": {}, "score": "69.23626"}
{"text": "Bigram , trigram and 4-gram LMs were trained on each data set ( LDC Hub5 , MSU Hub5 , BN ) and merged to form an effective 3-way interpolation .Furthermore , as described in [ 6 ] a class - based trigram model using 400 automatically generated word classes [ 12 , 9 ] was built to smooth the merged 4-gram language model by a further interpolation step to form the language model used in lattice rescoring .", "label": "", "metadata": {}, "score": "69.26652"}
{"text": "Collocation discovery can help identify lexical variants of medical concepts that are specific to the genre of clinical notes and are not covered by existing terminologies .Topic modeling , another text - mining technique , can help cluster terms often mentioned in the same documents across many patients .", "label": "", "metadata": {}, "score": "69.290054"}
{"text": "HMM acoustic models and TDNN based phonological feature detectors were trained from 3572 utterances taken from the TIMIT training set with a small 124 utterance de- velopment set held out for empirical estimation of the log linear weights , \u039b , given in Section 4.1 .", "label": "", "metadata": {}, "score": "69.30022"}
{"text": "In the competition , only three features are used in the DHMM : the orthographic feature , the POS feature and the surface word as described above .All the three features are combined and become an observation of DHMM while each tag is structural and consists of three parts [ 13 ] : .", "label": "", "metadata": {}, "score": "69.31739"}
{"text": "First , a set of neural network based classifiers that are used to extract the values for phonological distinctive features are presented .Sec- ond , the de - correlating and amplitude compression transformations applied to the neural network outputs are described .", "label": "", "metadata": {}, "score": "69.34326"}
{"text": "When post - processing was applied , average precision and recall were 82.0 and 81.1 .Post - processing improved both the precision and the recall , having a much larger effect on precision than on recall .This tendency is reasonable because our algorithms focus on repairing or removing gene mentions found by the base system and concentrate less on finding new gene mentions that were mistakenly tagged with POS tags such as NN or NNS .", "label": "", "metadata": {}, "score": "69.41234"}
{"text": "Some are template based , such as radiology or lab reports , and others are less structured and contain mostly free text .We identified that note types : \" primary - provider \" , \" clinical - note \" and \" follow - up - note \" contain more information than other note types .", "label": "", "metadata": {}, "score": "69.494095"}
{"text": "167 - 174 .[ Google Scholar ] .Aslam , J. ; Pelekhov , K. ; Rus , D. A Practical Clustering Algorithm for Static and Dynamic Information Organization .In SODA ' 99 : Proceedings of the Tenth Annual ACM - SIAM Symposium on Discrete Algorithms , Baltimore , MD , USA , 17 - 19 January 1999 ; Society for Industrial and Applied Mathematics : Philadelphia , PA , USA , 1999 ; pp .", "label": "", "metadata": {}, "score": "69.543945"}
{"text": "In order to better characterize the effect of unknown words on the performance of our system , we analyzed false positives that are one word in length .The percentage of false positives that are one word long is 40 % and 43 % for our system without post - processing and with post - processing , respectively .", "label": "", "metadata": {}, "score": "69.56127"}
{"text": "Cardoso - Cachopo , A. ; Oliveira , A.L. Semi - Supervised Single - Label Text Categorization Using Centroid - Based Classifiers .In SAC ' 07 : Proceedings of the 2007 ACM Symposium on Applied Computing , Seoul , Korea , 11 - 15 March 2007 ; ACM : New York , NY , USA , 2007 ; pp .", "label": "", "metadata": {}, "score": "69.57036"}
{"text": "Proceedings of the Sixth Applied Natural Language Processing Conference ( ANLP-2000 ) .Fukuda K , Tsunoda T , Tamura A , Takagi T : Toward information extraction : identifying protein names from biological papers .Pacific Symposium for Biocomputing 1998 , 3 : 705 - 716 .", "label": "", "metadata": {}, "score": "69.584885"}
{"text": "Agglomerative - whereby we start with each point being in a separate cluster , and at each step , the most similar pair of clusters are merged together ( examples of a agglomerative hierarchical clustering algorithms may be found in [ 4 , 19 ] ) , and .", "label": "", "metadata": {}, "score": "69.70819"}
{"text": "[ Google Scholar ] .Wang , C. ; Zhang , M. ; Ma , S. ; Ru , L. Automatic Online News Issue Construction in Web Environment .In WWW ' 08 : Proceeding of the 17th International Conference on World Wide Web , Beijing , China , 21 - 25 April 2008 ; ACM : New York , NY , USA , 2008 ; pp .", "label": "", "metadata": {}, "score": "69.74079"}
{"text": "Finally , this combined network is used for obtaining the highest scoring string using a modified vot- ing procedure .This involves adding the posterior probabilities or , if available , confidence scores on the labels at each alignment point .EXPERIMENTAL STUDY An experimental study is presented which evaluates the performance of the two different strategies described in Sections 4 and 5 for inte- gratingphonologicalfeaturebasedrepresentationswithMFCCbased ASR .", "label": "", "metadata": {}, "score": "69.8043"}
{"text": "If yes , we remove the abbreviation and the parentheses from the sentence .After the sentence is processed , we restore the abbreviation with parentheses to its original position in the sentence .Then , the abbreviation is classified as the same class of the full form , if the full form is recognized as an entity name .", "label": "", "metadata": {}, "score": "69.86146"}
{"text": "The adaptation of clustering algorithms for incremental scenarios presents various problems .Salton [ 16 ] mentions that inverted indices used to represent documents are not easily updated .As new documents are added to the clusters with the highest similarity , cluster reorganisation will eventually be needed [ 16 ] .", "label": "", "metadata": {}, "score": "69.89653"}
{"text": "Term - level scores ( i.e. , for performance on full gene names , analogous to the strict metric of Olsson et al .[5 ] ) were obtained using the BioCreAtIvE scoring software .We evaluated performance both with and without post - processing .", "label": "", "metadata": {}, "score": "69.94441"}
{"text": "This means that the amount of clusters is constantly growing .When a news report describing a new event is received , it is compared with the existing clusters , and when no \" similar \" cluster is found , it is clustered on its own in a new clusters .", "label": "", "metadata": {}, "score": "69.968346"}
{"text": "At its ... \" .Genre classification has been found to improve performance in many applications of statistical NLP , including language modeling for spoken language , domain adaptation of statistical parsers , and machine translation .It has also been found to benefit retrieval of spoken or written docu - ments .", "label": "", "metadata": {}, "score": "69.99429"}
{"text": "The same study , which was also performed for the Fly organism , showed similar results , but with slightly higher ambiguity rates .This study shows that the ambiguity among gene symbols , English words and other biomedical terms is extensive and the distribution of ambiguity is very sparse .", "label": "", "metadata": {}, "score": "70.100075"}
{"text": "Table 5 gives results for each processing stage for the 1998 evaluation set .The large difference ( 6.8 % absolute in WER ) between the P1 and P2 results is due to the combined effects of VTLN , MMIE models on the new training set , the larger vocabulary and a 4-gram LM .", "label": "", "metadata": {}, "score": "70.14941"}
{"text": "It was shown in [ 2 ] that this phonological distinctive feature based HMM system could significantly improve phone recognition performance when used as a mechanism for integrating phonological distinctive features with \" traditional\"MFCCbasedASRthroughalatticere - scoringparadigm .This paper extends the work in [ 1 ] and [ 2 ] by investigating whe- ther multiple definitions of phonological distinctive features can be shown to be complementary in their effect on ASR performance .", "label": "", "metadata": {}, "score": "70.152145"}
{"text": "The index terms are weighted using the TF.IDF measure .Since the collection of news reports is incremental , the document frequency of each term refers to the number of times that term has appeared in the news report collection until the time that the processing is being done .", "label": "", "metadata": {}, "score": "70.15552"}
{"text": "Morgan Kaufmann Publishers , Inc 1998 .Kazama J , Makino T , Ohta Y , Tsujii J : Tuning Support Vector Machines for Biomedical Named Entity Recognition .Proceedings of the Workshop on Natural Language Processing in the Biomedical Domain ( at ACL'2002 ) 2002 , 1 - 8 .", "label": "", "metadata": {}, "score": "70.211784"}
{"text": "Confusion networks were shown to consistently improve word error rates and yield improved confidence scores .On the 1998 evaluation set a relative reduction in word error rate of 11 % was obtained .The system presented here gave the lowest word error rate in the March 2000 Hub5E evaluation .", "label": "", "metadata": {}, "score": "70.237335"}
{"text": "It was presented to show the degree of difficulty among different abbreviations .Results from 5-fold cross - validation showed no statistical difference with results from 10-fold cross - validation , which indicated 5-fold cross - validation might be used in evaluation in order to save computational power ( for a discussion of the relative merits of 5-fold cross - validation vs. 10-fold cross - validation , see [ 35 ] ) .", "label": "", "metadata": {}, "score": "70.24042"}
{"text": "Only the first 13 principle components were retained after PCA analysis for this fea- turesystem .NodimensionalityreductionwasperformedfortheSPE or GP based observation vectors .Each of the resulting transformed vectors was then concatenated with first and second difference vec- tors to obtain 42 , 33 , and 39 components observation vectors for 48 .", "label": "", "metadata": {}, "score": "70.24159"}
{"text": "This transcription is used for both gender selection as well as VTLN warp selection for each segment cluster .Gender dependent VTLN models are then used ( P2 ) to provide a revised transcription which is used to estimate global mean and variance MLLR transforms for each cluster .", "label": "", "metadata": {}, "score": "70.247986"}
{"text": "The implementation we have used is rather different to the one in [ 16 ] and does a full forward - backward pass constrained by ( a margin around ) the phone boundary times that make up each lattice arc .Furthermore the smoothing constant in the EBW equations is computed on a per - Gaussian basis for fast convergence and a novel weight update formulation used .", "label": "", "metadata": {}, "score": "70.331604"}
{"text": "In recent years , many explorations have been done to port existing named entity recognition systems into the biomedical domain [ 7 - 10 ] .On all accounts , we can say that the entity names in the biomedical domain are much more complex than those in the newswire domain .", "label": "", "metadata": {}, "score": "70.344505"}
{"text": "Table 5 : % WER and normalised cross entropy ( NCE ) values on eval98 for all stages of the evaluation system .The final system output is a combination of P4a , P4b , P6a and P5b . ''no FV ' ' denotes system output without full variance transform . ''", "label": "", "metadata": {}, "score": "70.347984"}
{"text": "Tables 2 , 3 and 4 display the results for BSA , PCA and RSV , each of which has two senses .The distribution shown with bold font in column 1 is the estimated distribution of the senses , which is calculated based on the number of retrieved articles for each sense and the number of retrieved articles for all the senses .", "label": "", "metadata": {}, "score": "70.38985"}
{"text": "In 2000 , the UMLS Metathesaurus [ 6 ] , a comprehensive resource that specifies and categorizes biomedical concepts , contained 9,416 ambiguous terms , and in 2004 , the number increased to 21,295 , an increase of 126 % within 4 years [ 7 ] .", "label": "", "metadata": {}, "score": "70.4025"}
{"text": "So far , soft - tying has only been used with MLE training , although the technique could also be applied to MMIE trained models .The pronunciation dictionary used in this task contains on average 1.1 to 1.2 pronunciations per word .", "label": "", "metadata": {}, "score": "70.41286"}
{"text": "Proc AMIA : 2011 , 2011 : 1612 - 1620 .Lin CY : Rouge :A package for automatic evaluation of summaries .[Text Summarization Branches Out : Proceedings of the ACL-04 Workshop : 2004 ] .Altschul SF , Gish W , Miller W , Myers EW , Lipman DJ : Basic local alignment search tool .", "label": "", "metadata": {}, "score": "70.448105"}
{"text": "For this work , two methods were investigated : the use of acoustic scaling and a weakened language model .Normally the language model probability and the acoustic model likelihoods are combined by scaling the language model log probabilities .This situation leads to a very large dynamic range in the combined likelihoods and a very sharp posterior distribution in the denominator of ( 1 ) .", "label": "", "metadata": {}, "score": "70.49985"}
{"text": "The 1998 evaluation data , BNeval98 , consisted of two 1.5 hour data sets : the first drawn from a similar epoch as the 1997 data and the second drawn from June 1998 .The evaluation results are presented for each of the NIST ' ' focus ' ' conditions which are shown in Table 1 .", "label": "", "metadata": {}, "score": "70.536736"}
{"text": "As shown in Figure 5 , PCA , which has two very close senses , had much higher error rates than BSA , which has two unrelated senses .Therefore , when comparing the performance of different WSD systems , data sets with the same degree of difficulty should be used .", "label": "", "metadata": {}, "score": "70.54201"}
{"text": "5 \" and \" E . coli RNase H \" .This rule is quite corpus specific .It deals with the special tokenization scheme used in the BioCreative annotation .Removing stop words , e.g. \" by \" and \" or \" , from the recognized names , which have been wrongly recognized as a part of the names .", "label": "", "metadata": {}, "score": "70.57055"}
{"text": "We expect redundancy to be high across notes of the same patient and low across notes of distinct patients .Furthermore , within a single patient record , we expect heavy redundancy across notes from the same note types .We report redundancy on same patient / similar note type ( we focus on the most informative note types : primary provider , follow up and clinical notes ; in this analysis we ignore the template - based note types which are redundant by construction ) .", "label": "", "metadata": {}, "score": "70.60058"}
{"text": "PubMed View Article .Pearson WR : [ 5 ] Rapid and sensitive sequence comparison with FASTP and FASTA .Academic Press ; 1990:63 - 98 .[Methods in Enzymology .vol .Volume 183 ] .HaCohen - Kerner Y , Tayeb A , Ben - Dror N : Detection of simple plagiarism in computer science papers .", "label": "", "metadata": {}, "score": "70.66771"}
{"text": "[ Proceedings of the 2nd ACM SIGHIT symposium on International health informatics : 2012 ] .Zeng QT , Crowell J : Semantic classification of consumer health content .MEDNET Retrieved May 2008 , 2006 : 19 .Jiang Y : A computational semantics system for detecting drug reactions and patient outcomes in personal health messages .", "label": "", "metadata": {}, "score": "70.81506"}
{"text": "Table 3 shows the detailed performance of various components in our best closed evaluation ( closed-3 ) .It shows that individual SVM , DHMM1 and DHMM2 achieve the precision / recall / F - measure of 75.1%/70.2%/72.7 , 71.6%/71.9%/71.8 and 70.1%/74.3%s/72.1 respectively on the official test data .", "label": "", "metadata": {}, "score": "70.83557"}
{"text": "SIGIR'04 Workshop on Search and Discovery in BioInformatics .Hatzivassiloglou V , Duboue PA , Rzhetsky A : Disambiguating proteins , genes , and RNA in text : a machine learning approach .Bioinformatics 2001 , 17 ( Suppl 1 ) : S97 - 106 .", "label": "", "metadata": {}, "score": "70.848694"}
{"text": "While some individual samples contain fewer words , and some more words , than 2,000 , the total number of words for each text type is roughly conformant to our sampling frame .Encoding and markup conventions .Unlike single - byte western languages like English , Chinese uses 2 bytes of ASCII codes for each character .", "label": "", "metadata": {}, "score": "70.86178"}
{"text": "According to the literature reviewed in this research , the most common clustering method used is the k - means Clustering , or a variation of it .In k - means Clustering , we start with k points as the initial cluster centroids , and assign all the points to the nearest centroid .", "label": "", "metadata": {}, "score": "70.93516"}
{"text": "Int J Med Inform 2002 , 67 ( 1/3 ) : 63 - 74 .PubMed View Article .Kullo IJ , Fan J , Pathak J , Savova GK , Ali Z , Chute CG : Leveraging informatics for genetic studies : use of the electronic medical record to enable a genome - wide association study of peripheral arterial disease .", "label": "", "metadata": {}, "score": "70.96532"}
{"text": "Current statistical parsers tend to perform well only on their training domain and nearby genres .While strong performance on a few related domains is sufficient for many situations , it is advantageous for parsers to be able to generalize to a wide variety of domains .", "label": "", "metadata": {}, "score": "71.10092"}
{"text": "Current statistical parsers tend to perform well only on their training domain and nearby genres .While strong performance on a few related domains is sufficient for many situations , it is advantageous for parsers to be able to generalize to a wide variety of domains .", "label": "", "metadata": {}, "score": "71.10092"}
{"text": "The expression \" w/o post - p \" is used as \" without post - processing \" .Table 2 .The term - level score comparison between the cross - validation and official test .This table shows the term - level scores about the cross - validation data and official test .", "label": "", "metadata": {}, "score": "71.105064"}
{"text": "Apart from aiding the system efficiency , \" cluster freezing \" is also preventing new news reports to be clustered with obsolete events .The identification of \" frozen \" clusters is performed by the system , which traverses the list of active ( unfrozen ) clusters periodically .", "label": "", "metadata": {}, "score": "71.137726"}
{"text": "For each sense , we recorded all the retrieved PMIDs , randomly selected 250 , and then obtained the corresponding abstracts to form a data pool , from which all the experiments were drawn .Feature vector and machine - learning algorithm .", "label": "", "metadata": {}, "score": "71.273"}
{"text": "Finally all dictionary probabilities are renormalised so that the pronunciation for each word which has the highest probability is set to one .During recognition the ( log ) pronunciation probabilities are scaled by the same factor as used for the language model .", "label": "", "metadata": {}, "score": "71.28543"}
{"text": "On the level of individual token ( including unknown words ) , post - processing had a much smaller , and not always positive , effect .The main effect of dictionary - based post - processing is an increase in recall .", "label": "", "metadata": {}, "score": "71.31401"}
{"text": "This suggests that exploring public resources still remains a big problem and much more research should be made in this direction in the near future .Table 3 .Detailed performance of various components in our best closed system ( closed-3 ) .", "label": "", "metadata": {}, "score": "71.329605"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of RSV data set ( case where the 2 ambiguous senses both refer to viruses but the viruses are different types of viruses ) using 5-fold cross validation .", "label": "", "metadata": {}, "score": "71.35313"}
{"text": "There is a 6 % gain from employing the category trigram and 4-gram over the trigram alone , and a 7 % gain moving from adapted triphones to adapted quinphones : most of which ( 5 % ) was due to the full variance adaptation .", "label": "", "metadata": {}, "score": "71.46451"}
{"text": "PubMed View Article .O'Donnell HC , Kaushal R , Barr\u00f3n Y , Callahan MA , Adelman RD , Siegler EL : Physicians ' Attitudes Towards Copy and Pasting in Electronic Note Writing .J Gen Intern Med 2009 , 24 ( 1 ) : 63 - 68 .", "label": "", "metadata": {}, "score": "71.490555"}
{"text": "Detecting Drug Interactions From Adverse - Event Reports : Interaction Between Paroxetine and Pravastatin Increases Blood Glucose Levels .Clin Pharmacol Ther 2011 , 90 ( 1 ) : 133 - 142 .PubMed View Article .Wang X , Hripcsak G , Markatou M , Friedman C : Active Computerized Pharmacovigilance Using Natural Language Processing , Statistics , and Electronic Health Records : A Feasibility Study .", "label": "", "metadata": {}, "score": "71.54761"}
{"text": "We found an overall improvement in WER with cluster - based variance normalisation of 0.3 % absolute and a further 0.6 % absolute by applying VTLN in both training and testing without adaptation .However with mean and variance MLLR adaptation the separate beneficial effect of variance normalisation and VTLN is much reduced .", "label": "", "metadata": {}, "score": "71.61517"}
{"text": "If Entrez returned any items , then we tagged the word as GENE .Declarations .Acknowledgements .We would like to thank Thorsten Brants who made TnT available for this research .We also wish to acknowledge NIH / NIAAA grant 5U01 AA13524 - 02 ( Hunter , PI ) which supported this research , and Fujitsu , Inc. , which funded a year - long internship for SK in the Hunter laboratory .", "label": "", "metadata": {}, "score": "71.65167"}
{"text": "The latter only contain either newswire texts or official documents .The only balanced corpus of Mandarin Chinese is the Sinica Corpus , which was produced by Academia Sinica , Taiwan .As Taiwan has been separated from Mainland China for decades , the language used in Taiwan is not exactly the same as that used on the mainland .", "label": "", "metadata": {}, "score": "71.66122"}
{"text": "For the MV feature set , the output activations for each of the eight feature based TDNNs , 28 values in all , correspond to the bi- nary values defined in the MV set .The frame classification accuracy of these TDNNs ranges between 73 % for the 10 element \" place \" feature and 92 % for the 2 element \" phonation \" feature .", "label": "", "metadata": {}, "score": "71.70465"}
{"text": "Normally , a window of a target word w represents the local context of w and is used to make a decision on w .In this competition , we set the window size to 7 , which includes the previous 3 words and the next 3 words of the target word w including the target word w itself .", "label": "", "metadata": {}, "score": "71.74666"}
{"text": "Table 4 : % WER on BNeval97 for different trigram LMs with VTLN unadapted triphone HMMs with either pooled data or ( merged ) interpolated LMs .The effect of using three different LMs on BNeval97 with VTLN data and 1998 unadapted triphone HMMs is shown in Table 4 .", "label": "", "metadata": {}, "score": "71.832886"}
{"text": "If no cluster is found to have a similarity with the document that exceeds the similarity threshold , a new cluster is created with that document as its first member .This is different from the usual approach found in literature where a document is clustered with the cluster with which it has the highest similarity .", "label": "", "metadata": {}, "score": "71.869675"}
{"text": "Our goal was to improve recall without a decrease in precision .Our approach was to examine previously unseen words that were tagged as nouns and were four or more characters in length .If such a word matched a LocusLink symbol , then we tagged it as GENE .", "label": "", "metadata": {}, "score": "71.94154"}
{"text": "In the competition , an ensemble of classifiers is proposed to recognize the protein / gene names , in which three classifiers , one Support Vector Machine ( SVM ) and two discriminative Hidden Markov Models ( DHMMs ) , are effectively combined .", "label": "", "metadata": {}, "score": "71.95781"}
{"text": "Error rates for each combination of sense distribution and sample size were averaged using 30 runs .Statistical methodology .To quantify the effects of sample size , sense distribution and difficulty of the task on the error rate , appropriate statistical methods were used .", "label": "", "metadata": {}, "score": "72.02273"}
{"text": "Index Terms- Speech Recognition , Acoustic Modeling , Pho- nological Features 1 .INTRODUCTION There has been a great deal of research on the use of phonological distinctive feature systems arising from multiple phonological the- ories in automatic speech recognition ( ASR ) .", "label": "", "metadata": {}, "score": "72.0325"}
{"text": "View Article PubMed .Tanabe L , Wilbur WJ : Tagging gene and protein names in full text articles .Proceedings of the workshop on biomedical natural language processing in the biomedical domain Association for Computational Linguistics 2002 , 9 - 13 .", "label": "", "metadata": {}, "score": "72.05603"}
{"text": "McKeown , K.R. ; Barzilay , R. ; Evans , D. ; Hatzivassiloglou , V. ; Klavans , J.L. ; Nenkova , A. ; Sable , C. ; Schiffman , B. ; Sigelman , S. Tracking and Summarizing News on a Daily Basis with Columbia 's Newsblaster .", "label": "", "metadata": {}, "score": "72.11698"}
{"text": "For each link in a particular word lattice ( from standard decoding ) a posterior probability is estimated using the forward - backward algorithm .The lattice with these posteriors is then transformed into a linear graph , or confusion network ( CN ) , using a link clustering procedure [ 11 ] .", "label": "", "metadata": {}, "score": "72.150734"}
{"text": "Data set for experiments .Four abbreviations were used in the experiments .Table 1 lists the detailed information about the abbreviations and their senses .These abbreviations were originally specified in the ABBR data set [ 8 ] .We chose them by considering the different levels of semantic similarity among their senses .", "label": "", "metadata": {}, "score": "72.16076"}
{"text": "This similarity in performance for the MV , GP , SPE , and MFCC based systems is important when combining these systems using the techniques described in Section 6.2 .Feature Based Phone Recognition Accuracy Feature Trans .MV PCA64.1 % log+PCA66.9 % GPSPE 64.2 % 66.5 % 66.1 % 68.1 % Table 1 .", "label": "", "metadata": {}, "score": "72.22013"}
{"text": "One solution to this is to use document retirement [ 16 ] .The decision to retire a document can be based on a number of factors such as : the number of citations to that document , the age of the document and/or the usage of the document [ 16 ] .", "label": "", "metadata": {}, "score": "72.32402"}
{"text": "First an overview of the 1998 HTK system is given .This is followed by a description of the data sets used in the experiments and then by sections that discuss each of the major new features of the system .Finally the complete March 2000 evaluation system is described and the results of each stage of processing presented .", "label": "", "metadata": {}, "score": "72.34529"}
{"text": "For the multi - valued ( MV ) feature system , a separate TDNN was used for each of the eight features [ 1].All the networks have a single hidden layer with varying number of hidden units .The input to each network is a vector of twelve MFCCs along with their first and second differences .", "label": "", "metadata": {}, "score": "72.43851"}
{"text": "Both the weight estimation in lattice re - scoring and confusion network construction and combination in CNC are entirely data driven .ACKNOWLEDGMENTS The authors would like to thank Simon King of the Center for Tech- nology Research at the University of Edinburgh for his helpful ad- vice in building phonological feature classifiers .", "label": "", "metadata": {}, "score": "72.46909"}
{"text": "Finally , separate HMM models defined over spectral energy ( MFCC ) based observations and multi- ple phonological feature based observations are trained and used for decoding phone sequences and generating phone lattices .Neural Network Based Feature Detection Following the work in [ 1 ] , time delay neural networks ( TDNNs ) were used for phonological feature detection .", "label": "", "metadata": {}, "score": "72.64372"}
{"text": "Ginter [ 27 ] introduced a new family of classifiers , which were based on an ordering and weighing of the feature vectors obtained from word counts and word co - occurrence in the text .This method was used to determine whether a term was a gene versus a protein and achieved 86 % accuracy .", "label": "", "metadata": {}, "score": "72.67915"}
{"text": "In the LCMC corpus , the FLOB sampling frame is followed strictly except for two minor variations .The first variation relates to the sampling frame - we replaced western and adventure fiction ( category N ) with martial arts fiction .", "label": "", "metadata": {}, "score": "72.68332"}
{"text": "Our system maintains a global index that stores the occurrence of each stemmed term within the entire news report collection .This global index is updated incrementally as the incoming news reports are being processed .A separate index is also created for each news report being processed storing the occurrence frequencies of the different terms in the corresponding news report .", "label": "", "metadata": {}, "score": "72.694275"}
{"text": "Two ambiguous gene symbol lists were formed as a result of the comparisons : a gene - English list ( containing gene symbols ambiguous with general English words ) and a gene - UMLS list ( containing gene symbols ambiguous with biomedical terms ) .", "label": "", "metadata": {}, "score": "72.748985"}
{"text": "Thus the complete soft - tied system has the same number of Gaussians as the original system and three times as many mixture weights per state .After this revised structure has been created all system parameters are re - estimated .", "label": "", "metadata": {}, "score": "72.79018"}
{"text": "The results show that an unsupervised technique based on topic models is effective - it outperforms random data selection on both languages examined , English and Dutch .Moreover , the technique works better than manually assigned labels gathered from meta - data that is available for English . ...", "label": "", "metadata": {}, "score": "72.818985"}
{"text": "We use a maximum likelihood technique to select the best data warp factor via a parabolic search .It is important when comparing the warped data likelihoods to properly take into account the effect of the transformation .We have done this implicitly by performing variance normalisation on the data .", "label": "", "metadata": {}, "score": "72.86174"}
{"text": "Siegler EL , Adelman R : Copy and Paste : A Remediable Hazard of Electronic Health Records .Am J Med 2009 , 122 ( 6 ) : 495 - 496 .PubMed View Article .Markel A : Copy and Paste of Electronic Health Records : A Modern Medical Illness .", "label": "", "metadata": {}, "score": "72.91115"}
{"text": "Dictionary - based post - processing in the open division .We employed a dictonary - based post - processing step that uses NCBI LocusLink symbols database for the open division .LocusLink database used for this research has 279,007 symbols that include official symbols or other aliases that are used to refer to a given gene .", "label": "", "metadata": {}, "score": "72.95909"}
{"text": "Each of them contains entries ranging from thousands to millions and multiplies rapidly .Normally , all of these resources are annotated manually by human experts .However , such manual handling is much throughput - limited , extremely time - consuming and enormously expensive .", "label": "", "metadata": {}, "score": "72.96921"}
{"text": "For example , Hearst [ 26 ] compares ranked documents in a best cluster to an equivalent cutoff in the original ranked retrieval results .On the other hand , Stokes [ 15 ] compares the presented results with a basic First Story Detection system that uses the traditional vector space model to compute syntactic similarity between documents and clusters .", "label": "", "metadata": {}, "score": "72.97009"}
{"text": "PACs measured for systems integrating MFCC based and MV phonological feature based with empirical and DMC estimation of log - linear weights ( No logarithmic amplitude compression was applied to MV feature values ) 7 .SUMMARY AND CONCLUSION Two methods for integrating multiple phonological feature based phonerecognizerswithmore\"traditional\"MFCCbasedphonerecog- nition have been investigated .", "label": "", "metadata": {}, "score": "72.97279"}
{"text": "For all other sense distributions , an increase in the sample size did not produce a significant reduction in the error rate - that is , there are no statistically significant differences between the error rates .We would like to stress here a limitation of the current study .", "label": "", "metadata": {}, "score": "73.05234"}
{"text": "There are different types of WSD and some are more difficult than others .For example , if two senses are syntactically different , a reliable part of speech tagging method could be effective in resolving the ambiguity .For senses that correspond to the same syntactic category , the similarity of their semantic categories will affect the difficulty of the task ( i.e. the bovine serum albumin sense of BSA is substantially different from the body surface area sense ) .", "label": "", "metadata": {}, "score": "73.07747"}
{"text": "Approximation techniques to make this problem tractable were developed in bioinformatics to search sequence databases and for plagiarism detection .In both fields , fingerprinting schemes are applied .In BLAST , short substrings are used as fingerprints , whose length is defined by biological significance .", "label": "", "metadata": {}, "score": "73.0872"}
{"text": "While the system produces good results it is computationally expensive : a companion paper [ 12 ] discusses a version of the system that runs in less than ten times real - time on commodity hardware .This work is in part supported by an EPSRC grant on ' ' Multimedia Document Retrieval ' ' reference GR / L49611 and by a grant from DARPA .", "label": "", "metadata": {}, "score": "73.09881"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" for BSA , RSV and PCA data sets with fixed distribution of \" ( 0.5 , 0.5 ) \" using 5-fold cross validation .Discussion .", "label": "", "metadata": {}, "score": "73.22952"}
{"text": "The cross - validation average precision was 81.3 and average recall was 75.9 without post - processing .Average precision was 82.3 and average recall was 77.6 with post - processing .Post - processing yielded little improvement in performance for unknown words .", "label": "", "metadata": {}, "score": "73.26749"}
{"text": "This suggests that in unseen sentences that it will not likely appear as the last word of a gene mention .The following examples demonstrate how the boundary correction post - processing step would change two gene mentions that mistakenly include the word binding .", "label": "", "metadata": {}, "score": "73.391884"}
{"text": "The online version of this article ( doi : 10 .1186/\u200b1471 - 2105 - 7 - 334 ) contains supplementary material , which is available to authorized users .Background .During the last few years , there has been a surge of interest in information extraction and text mining of the biomedical literature [ 1 , 2 ] .", "label": "", "metadata": {}, "score": "73.464874"}
{"text": "IEEE Trans .Information Theory , Vol .37 , pp .107 - 113 .T.R. Niesler , E.W.D. Whittaker & P.C. Woodland ( 1998 ) .Comparison of Part - Of - Speech and Automatically Derived Category - Based Language Models for Speech Recognition .", "label": "", "metadata": {}, "score": "73.51608"}
{"text": "When comparing the performance of WSD classifiers , those metrics are critical because they indicate whether or not an improvement is statistically significant ; if there is a large deviation , there may not actually be an improvement even though one error rate is smaller than the other .", "label": "", "metadata": {}, "score": "73.544945"}
{"text": "Comparison , of the , oracle phone , recognition results and , the real phone , recognition , results indicates that investigation of high - accuracyfront - end detectors is a key issue in improving the performance , of detection - based ASR .", "label": "", "metadata": {}, "score": "73.66812"}
{"text": "Although the IO representation can not differentiate consecutive names , it simplifies the problem a lot since we can avoid the SVM multi - class problem .Discriminative Hidden Markov Model .Here , we use the discriminative Hidden Markov Model ( DHMM ) which was first proposed in Zhou et al [ 13 ] and then applied in Shen et al [ 9 ] and Zhou et al [ 10 ] .", "label": "", "metadata": {}, "score": "73.72503"}
{"text": "Hand DJ : Construction and assessment of classification rules Chichester , England : John Wiley & Sons 1997 .Hand DJ : Assessing Classification Rules .Journal of Applied Statistics 1994 , 21 : 3 - 16 .View Article .Fukunaga K , Hayes RR : Effect of sample size in classifier design .", "label": "", "metadata": {}, "score": "73.77896"}
{"text": "While MMIE is very effective at reducing training set error a key issue is generalisation to test data .It is very important that the confusable data generated during training ( as found from the posterior distribution of state occupancy for the recognition lattice ) is representative to ensure good generalisation .", "label": "", "metadata": {}, "score": "73.875946"}
{"text": "Assessing redundancy through alignment is a more appropriate and more stringent method than counting simple token overlap as in a bag - of - word model .High percentage of alignment between two notes indicates not only that tokens are similar across the two notes , but that the sequences of tokens in the notes are also similar .", "label": "", "metadata": {}, "score": "73.89162"}
{"text": "Unrefined BioCreative - POS tagger , which is trained on the original BioCreative - POS corpus with the NEWGENE ( indicating a protein / gene name ) tag replaced by the NNP tag ( indicating a proper noun ) .Refined - BioCreative - POS tagger , which is trained on a refined version of the BioCreative - POS corpus .", "label": "", "metadata": {}, "score": "73.92601"}
{"text": "No assumptions are made about the original distribution ( e.g. normal vs. other ) of the documents .Analysis of variance models are versatile statistical tools for studying the relation between error rates and sense distribution , sample size , and degree of difficulty of a task .", "label": "", "metadata": {}, "score": "73.933014"}
{"text": "For example , if a word occurs in the vocabulary ( collected from the training data ) , one dimension in the feature vector of the SVM ( corresponding to the position of the word in the vocabulary ) is set to 1 .", "label": "", "metadata": {}, "score": "73.93962"}
{"text": "Conversion procedures fall out of our ... \" .We show how web mark - up can be used to improve unsupervised dependency parsing .Starting from raw bracketings of four common HTML tags ( anchors , bold , italics and underlines ) , we refine approximate partial phrase boundaries to yield accurate parsing constraints .", "label": "", "metadata": {}, "score": "73.99266"}
{"text": "However , most previous work on domain adaptation relied on the implicit assumption that domains are somehow given .As more and more data becomes available , automatic ways to select data that is beneficial for a new ( unknown ) target domain are becoming attractive .", "label": "", "metadata": {}, "score": "74.051285"}
{"text": "Previously the ROVER technique introduced in [ 2 ] had been used to combine the 1-best output of multiple systems .Confusion network combination ( CNC ) can be seen as a generalisation of ROVER to confusion networks , i.e. it uses the competing word hypotheses and their posteriors encoded in the confusion sets instead of only considering the most likely word hypothesised by each system .", "label": "", "metadata": {}, "score": "74.076126"}
{"text": "AAAI Fall Symp 93 98 - 107 .Hamosh A , Scott AF , Amberger J , Bocchini C , Valle D , McKusick VA : Online Mendelian Inheritance in Man ( OMIM ) , a knowledgebase of human genes and genetic disorders .", "label": "", "metadata": {}, "score": "74.120544"}
{"text": "Joachims T : Making large - Scale SVM Learning Practical .Advances in Kernel Methods - Support Vector Learning ( Edited by : Schukopf B , Burges C , Smola A ) .MIT - Press 1999 .Shannon CE : Prediction and Entropy of Printed English .", "label": "", "metadata": {}, "score": "74.195816"}
{"text": "In such cases , public resources , e.g. a protein / gene name dictionary , may bridge the gap .In our closed evaluations , the dictionary is constructed by extracting all protein / gene names from the training data .Then , the dictionary is filtered out using some criteria to reduce possible side - effects since all the public resources are vulnerable to noise and ambiguity .", "label": "", "metadata": {}, "score": "74.25807"}
{"text": "In our system , all the five features as described above are applied for each of the 7 words in the window .When a word contains dash(es ) , one additional overlapping orthographic feature is generated for each segment separated by dashes .", "label": "", "metadata": {}, "score": "74.25876"}
{"text": "The final hypothesis combination uses word - level confidence scores based on an N - best homogeneity measure .These are used with the NIST ROVER program [ 1 ] to produce the final output .We first compared the effect of using the additional training data in the BNtrain98 set .", "label": "", "metadata": {}, "score": "74.26558"}
{"text": "One should note that in cases where the vector space model with TF.IDF weighting is used , the cost of the update of the inverted index would be proportional to the current size of the inverted index and not on the size of the update [ 9 ] .", "label": "", "metadata": {}, "score": "74.433586"}
{"text": "Viterbi AJ : Error bounds for convolutional codes and an asymptotically optimum decoding algorithm .IEEE Transactions on Information Theory 1967 , IT ( 13 ) : 260 - 269 .View Article .Schwartz AS , Hearst MA : A simple algorithm for identifying abbreviation definitions in biomedical text .", "label": "", "metadata": {}, "score": "74.4711"}
{"text": "For each tag set we modified the training corpus to comply with the tag set and then trained TnT. We tested the four models on the devtest set .The result of this experiment is shown in Table 5 .The differences in performance between the four tag sets are very small .", "label": "", "metadata": {}, "score": "74.566986"}
{"text": "The triphone HMMs were estimated using BNtrain97 and contained 6684 decision - tree clustered states [ 17 ] , each with 12 Gaussians per state while the quinphone models used 8180 states and 16 Gaussians per state .The HMMs were initially trained on all the wide - band analysed training data .", "label": "", "metadata": {}, "score": "74.63878"}
{"text": "The two rows in the table correspond to the case where PCA transformation alone is applied to the feature detector outputs and both log and PCA based transformations are used .There are several observations that can be made from Table 1 .", "label": "", "metadata": {}, "score": "74.707344"}
{"text": "Joshi M , Pedersen T , Maclin R : A comparative study of support vector machines applied to the supervised word sense disambiguation problem in the medical domain .[ Proceedings of the 2nd Indian International Conference on Artificial Intelligence ( IICAI'05 ) : 2005 ] .", "label": "", "metadata": {}, "score": "74.768936"}
{"text": "This may be because larger tag sets are sometimes harder to learn because there are fewer examples for each tag .We speculate that tag sets two and three could possibly outperform the others if we had more training data .However , because the simplest tagging scheme performed the best , we used this scheme for all subsequent experiments described below .", "label": "", "metadata": {}, "score": "74.78738"}
{"text": "With these goals in mind , one might want to identify concepts that are associated by looking for frequently co - occurring pairs of concepts or phrases in patient notes , or cluster concepts across patients to identify latent variables corresponding to clinical models .", "label": "", "metadata": {}, "score": "74.89159"}
{"text": "The methodology is easy to apply , it provides a principled way of studying the effects of the different factors on the error rate , and since it is based on a strong theoretical foundation , it guarantees that the results to apply to all abbreviations with similar characteristics .", "label": "", "metadata": {}, "score": "75.03133"}
{"text": "There is a wide variation in the number of notes per patient , either because of their health status , or because some patients go to different health providers while others have all their visits in the same institution .Furthermore , clinicians typically copy and paste information from previous notes when documenting a current patient encounter .", "label": "", "metadata": {}, "score": "75.03508"}
{"text": "This is an 11 % reduction in WER relative to the CU - HTK evaluation result obtained on the same data set in 1998 ( 39.5 % ) .Note that confusion network output consistently improves performance by about 1 % absolute and that combination of the 4 outputs using confusion network combination ( CNC ) is 0.4 % absolute better than using the ROVER approach .", "label": "", "metadata": {}, "score": "75.03695"}
{"text": "For BPD , which has three different senses , three different multi - class SVM methods [ 47 ] : \" mc - svm \" , \" one - vs - rest \" , \" one - vs - one \" , were used . \" Mc - svm \" implements the algorithm with a decision function which considers all classes at once , while \" one - vs - rest \" and \" one - ve - one \" are constructed by combining several binary SVM classifiers .", "label": "", "metadata": {}, "score": "75.05665"}
{"text": "[14 ] examined 1,670 patient notes of four types ( resident sign - out note , progress note , admission note and discharge note ) and assessed the amount of redundancy in these notes through time .Redundancy was defined through alignment of information in notes at the line level , using the Levenshtein edit distance .", "label": "", "metadata": {}, "score": "75.11522"}
{"text": "Affiliated with .Affiliated with .Affiliated with .Abstract .This paper proposes an ensemble of classifiers for biomedical name recognition in which three classifiers , one Support Vector Machine and two discriminative Hidden Markov Models , are combined effectively using a simple majority voting strategy .", "label": "", "metadata": {}, "score": "75.117065"}
{"text": "PHONOLOGICAL DISTINCTIVE FEATURE BASED PHONE RECOGNITION This section extends the work described in [ 2 ] where phonologi- cal distinctive feature ( PDF ) based phoneme recognition systems were developed as part of a larger formalism for integrating PDFs with MFCC based ASR .", "label": "", "metadata": {}, "score": "75.118484"}
{"text": "Results for BSA data set .Annotation of the table : Dist : Distribution of senses ; S. Size : sample size ; Err .Rate : Error Rate ; SE : Standard Error of error rates ; CV : cross - validation ; .", "label": "", "metadata": {}, "score": "75.1306"}
{"text": "More specifically : . where w t , c refers to the weight of term t within cluster c , D c refers to the collection of documents in cluster c , and w t , d refers to the weight of term t within document d .", "label": "", "metadata": {}, "score": "75.14198"}
{"text": "To enable the calculation of similarity between a document and a cluster , the cluster is usually represented using a centroid vector .The centroid vector is the weighted average of the documents within that cluster [ 4 , 7 , 17 , 23 ] .", "label": "", "metadata": {}, "score": "75.21294"}
{"text": "Our document clustering system was implemented to be the initial part of a larger system that performs news report fusion and issues personalised recommendations - refer to [ 1 , 2 ] for more details .Our system downloads RSS feeds from 9 different news sources ( including Maltese local sources and international sources such as Reuters ) .", "label": "", "metadata": {}, "score": "75.227905"}
{"text": "17 ] was then applied using quinphone models and confidence scores estimated using an N - best homogeneity measure for both the triphone and quinphone output .The final stage combined these two transcriptions using the ROVER program [ 2 ] .", "label": "", "metadata": {}, "score": "75.336075"}
{"text": "Mixture Gaussian distributions for each tied state were then trained using sentence - level Baum - Welch estimation and iterative mixture splitting [ 20 ] .After gender independent ( GI ) models had been trained , a final training iteration using gender - specific training data and updating only the means and mixture weights was performed to estimate gender dependent ( GD ) model sets .", "label": "", "metadata": {}, "score": "75.36748"}
{"text": "All the words in the title and abstract of the articles were used as features for machine learning and an SVM algorithm was used to generate a classifier .We used a package called \" Spider \" [ 46 ] to perform all the SVM training and testing .", "label": "", "metadata": {}, "score": "75.47156"}
{"text": "These methods require labeled examples of syntactic structures to learn statistical patterns governing these structures .Labeled data typically requires expert annotators which makes it both time consuming and costly to produce .Furthermo ... \" .Current efforts in syntactic parsing are largely data - driven .", "label": "", "metadata": {}, "score": "75.479004"}
{"text": "CNC is an extension of ROVER where , instead of aligning the strings produced by the individual ASR systems in the first stage , confusion networks are aligned [ 4].Confusion networks are a com- pact representation oflattices which are in turngraph representations of the search space of the recognizer containing the most likely word hypotheses .", "label": "", "metadata": {}, "score": "75.54686"}
{"text": "State of the art articles ( as cited above ) and libraries ( such as the NSP package ) do not include any form of redundancy control or noise reduction .Redundancy mitigation is currently not a standard practice within the field of collocation extraction .", "label": "", "metadata": {}, "score": "75.60681"}
{"text": "Notes contain the following metadata : unique patient identifier , date , and note type ( e.g. , Primary - Provider ) .HealthTermFinder identifies named - entities mentions and maps them against semantic concepts in UMLS [49 ] .As such , it is possible to map lexical variants ( e.g. , \" myocardial infarction , \" \" myocardial infarct , \" \" MI , \" and \" heart attack \" ) of the same semantic concept to a UMLS CUI ( concept unique identifier ) .", "label": "", "metadata": {}, "score": "75.72317"}
{"text": "Our guess is that an F - measure of 80 is probably within seven points of the upper limit .Another important question that arises from this effort is to determine the effect of training corpus size on performance .This could be achieved by training on successively bigger percentages of the training corpus .", "label": "", "metadata": {}, "score": "75.80196"}
{"text": "[ Google Scholar ] .Gulli , A. The Anatomy of a News Search Engine .In WWW ' 05 : Proceedings of the Special Interest Tracks and Posters of the 14th International Conference on World Wide Web , Chiba , Japan , 10 - 14 May 2005 ; ACM Press : New York , NY , USA , 2005 ; pp .", "label": "", "metadata": {}, "score": "75.81485"}
{"text": "PubMed View Article .Kho A , Pacheco J , Peissig P , Rasmussen L , Newton K , Weston N , Crane P , Pathak J , Chute C , Bielinski S : Electronic Medical Records for Genetic Research : Results of the eMERGE Consortium .", "label": "", "metadata": {}, "score": "75.84037"}
{"text": "It also shows that the protein / gene name refinement module increases the F - measure by 2.35 ( closed-3 vs. closed-2 ) .However , the open evaluation shows that extra protein / gene names from public resources decrease the performance by 2.57 in F - measure from 80.63 to 78.06 ( closed-2 vs. open-1 ) .", "label": "", "metadata": {}, "score": "76.06643"}
{"text": "Results .Support Vector Machine ( SVM ) classifiers were applied to an automatically generated data set containing four ambiguous biomedical abbreviations : BPD , BSA , PCA , and RSV , which were chosen because of varying degrees of differences in their respective senses .", "label": "", "metadata": {}, "score": "76.07128"}
{"text": "Conclusion .In this paper , we aimed to further an understanding of the different factors affecting the performance of ML techniques for WSD by systematically simulating a variety of situations where different sample size , sense distribution , degree of difficulty , and cross validation methods were used .", "label": "", "metadata": {}, "score": "76.11737"}
{"text": "Tested across six domains , our system outperforms all non - oracle baselines including the best domain - independent parsing model .Thus , we are able to demonstrate the value of customizing parsing models to specific domains . ... train models in many different domains but sidestep the problem of domain detection .", "label": "", "metadata": {}, "score": "76.23359"}
{"text": "CNC involves three steps .First , the lattices generated by the indi- vidual ASR systems are converted to confusion networks .Second , these networks are aligned in sequential order , using the confusion network of one of ASR systems as a reference .", "label": "", "metadata": {}, "score": "76.24831"}
{"text": "Two methods are investigated for integrating these features with MFCC based ASR systems .First , phonological feature and MFCC based systems are combined in a lattice re - scoring paradigm .Second , confusion network based system combination ( CNC ) is used to combine phone networks derived from phonological distinctive feature ( PDF ) and MFCC based systems .", "label": "", "metadata": {}, "score": "76.26678"}
{"text": "It applies these N(N-1)/2 SVM classifiers and the class assignment is determined by a voting strategy ( e.g. the class chose by the maximum number of SVM classifiers wins ) .The performance was measured using both a 5-fold and a 10-fold cross - validation method .", "label": "", "metadata": {}, "score": "76.31726"}
{"text": "In our study , we proposed a simple \" full - term substitution \" method , which is described in more detail in the Methods section , to automatically generate training data , but this is only applicable for abbreviations .In this study , we used a \" full - form substitution \" method to automatically generate the data set for the experiments , which is an artificial training set .", "label": "", "metadata": {}, "score": "76.35855"}
{"text": "The number of clusters to produce is not known beforehand , and new events are detected automatically .As we mentioned in Section 1 , the clustering process described here is very fast - every news report is clustered in less than 1 second on average .", "label": "", "metadata": {}, "score": "76.388885"}
{"text": "Cormode G , Hadjieleftheriou M : Finding frequent items in data streams .Proceedings of the VLDB Endowment 2008 , 1 ( 2 ) : 1530 - 1541 .Copyright .\u00a9 Cohen et al . ; licensee BioMed Central Ltd. 2013 .", "label": "", "metadata": {}, "score": "76.41623"}
{"text": "One should keep in mind that the similarity threshold has a crucial importance in our clustering system since it determines when new clusters should be created .On the other hand , the baseline system has the number of clusters provided beforehand and so does not has the problem of creating too many clusters .", "label": "", "metadata": {}, "score": "76.63601"}
{"text": "Therefore , a system where the number of clusters is continuously growing is not scalable .To resolve this issue , the concept of \" freezing \" old clusters .This means that clusters that have not had new members for some time are \" frozen \" , and incoming documents are not compared to them at all .", "label": "", "metadata": {}, "score": "76.673706"}
{"text": "Table 4 .The effect of the post - processing procedures on overall system performance .This table shows the effects of each post - processing procedures in comparison with the all post - processing results .For example , No rule column shows the results without rule - based post - processing , that shows 4.5 % lower score than All Post - processing in F - measure .", "label": "", "metadata": {}, "score": "76.733444"}
{"text": "Latent Dirichlet Allocation ( LDA ) , introduced by Blei et al .[ 27 ] , is an unsupervised generative probabilistic graphical model for topic modeling .Documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over words .", "label": "", "metadata": {}, "score": "76.78815"}
{"text": "In these cases the produced cluster that is closest to the reference cluster is a very large cluster that encompasses the entire or most of the reference cluster .Since all ( or most ) of the reference cluster 's documents are in that large produced cluster , the recall is 1 ( or nearly 1 ) .", "label": "", "metadata": {}, "score": "76.87349"}
{"text": "[ 30 ] applied LDA topic modeling to FDA drug side effects labels , their results demonstrated that the acquired topics properly clustered drugs by safety concerns and therapeutic uses .As observed for the field of collocation extraction , redundancy mitigation is not mentioned as standard practice in the case of topic modeling .", "label": "", "metadata": {}, "score": "76.92212"}
{"text": "To demonstrate the extent of the ambiguity problem in MEDLINE we searched MEDLINE abstracts to determine how many abstracts contained gene symbols that were ambiguous with general English words or biomedical terms .We repeated the same procedure for the fly and yeast organisms as well .", "label": "", "metadata": {}, "score": "77.055084"}
{"text": "Dietterich TG : Approximate statistical tests for comparing supervised classification learning algorithms .Neural Computation 1998 , 10 : 1895 - 1924 .View Article PubMed .Salzberg SL : On comparing classifiers : Pitfalls to avoid and a recommended approach .", "label": "", "metadata": {}, "score": "77.067764"}
{"text": "[ Google Scholar ] .Luo , G. ; Tang , C. ; Yu , P.S. Resource - Adaptive Real - Time New Event Detection .In SIGMOD ' 07 : Proceedings of the 2007 ACM SIGMOD International Conference on Management of Data , Beijing , China , 11 - 14 June 2007 ; ACM : New York , NY , USA , 2007 ; pp .", "label": "", "metadata": {}, "score": "77.08504"}
{"text": "View Article .Kohane IS : Using electronic health records to drive discovery in disease genomics .Nat Rev Genet 2011 , 12 ( 6 ) : 417 - 428 .PubMed View Article .Tatonetti N , Denny J , Murphy S , Fernald G , Krishnan G , Castro V , Yue P , Tsau P , Kohane I , Roden D , et al .", "label": "", "metadata": {}, "score": "77.35542"}
{"text": "Since there are 28 total components corresponding to the output values for the MV feature set , the overall observation vector dimensionality would be 84 when these 28 components are concatenated with first and second order difference vectors .The observation vectors associated with the SPE and GP feature systems have dimension 14 and 11 respectively .", "label": "", "metadata": {}, "score": "77.4037"}
{"text": "The i th binary SVM classifier is trained by considering all instances associated with the i th class as positive examples and the others as negative instances .It applies the N classifiers and chooses the one with the highest confidence .", "label": "", "metadata": {}, "score": "77.40836"}
{"text": "While they contain the most - likely paths , a significant part of the ' ' tail ' ' of the overall posterior distribution is missing .To compensate for this a decision tree was trained to map the estimates to confidence scores .", "label": "", "metadata": {}, "score": "77.42763"}
{"text": "Therefore , POS may provide useful evidence about the boundaries of biomedical names .In this competition , a DHMM [ 13 ] -based POS tagger is trained to assign the POS feature .Throughout the competition , three different POS taggers are trained on different corpora : .", "label": "", "metadata": {}, "score": "77.490166"}
{"text": "Figures 1 , 2 and 3 show the error rate versus the sample size for each distribution of the BSA , PCA and RSV data sets with 5-fold cross - validation .As the figures indicate , the reduction of the error rate as a function of the sample size is more dramatic for BSA than for PCA .", "label": "", "metadata": {}, "score": "77.51794"}
{"text": "Admission notes showed a redundancy of 30 % compared to the progress , discharge and sign - out notes of the same patient .More recently , Zhang et al .[ 15 ] experimented with different metrics to assess redundancy in outpatient notes .", "label": "", "metadata": {}, "score": "77.87523"}
{"text": "Three different training sets were used during the course of development : the 18 hour Minitrain set defined by BBN which gives a fast turnaround ; the full 265 hour training set ( h5train00 ) for the the March 2000 system and a subset of h5train00 denoted h5train00sub .", "label": "", "metadata": {}, "score": "77.97365"}
{"text": "Holm L , Sander C : Removing near - neighbour redundancy from large protein sequence collections .Bioinformatics 1998 , 14 ( 5 ) : 423 .PubMed View Article .Bateman A , Birney E , Durbin R , Eddy SR , Howe KL , Sonnhammer ELL : The Pfam protein families database .", "label": "", "metadata": {}, "score": "78.075325"}
{"text": "Within some time of an event happening in the real world , numerous news reports will appear on news sites on the World Wide Web that describe that event .Moreover , as time passes , new reports will appear that give information on how that event developed and what its effects were .", "label": "", "metadata": {}, "score": "78.08653"}
{"text": "The h5train00sub set was chosen to include all the speakers from Swb1 in h5train00 as well as a subset of the available CHE sides .Furthermore results are given for the March 2000 evaluation data set , eval00 , which has 40 sides of Swb1 and 40 CHE sides .", "label": "", "metadata": {}, "score": "78.2206"}
{"text": "The range of sample size per sense ranges from 10 - 40 , with increments of 10 per sense .Average error rates ( Err .Rate ) and average standard errors ( SE ) were reported for each combination of distribution and sample size ( see Methods section ) .", "label": "", "metadata": {}, "score": "78.41459"}
{"text": "Recall actually degraded somewhat .These data are consistent with our findings that many of our post - processing steps correct the boundaries of gene mentions at the term level .Per - token performance on unknown words .We use the phrase unknown word to describe a word that was not previously seen in the training corpora .", "label": "", "metadata": {}, "score": "78.47119"}
{"text": "If a words length has less than two characters and contains digits , Greek letters or roman numerals , then it is tagged NN . ...If the word mutation is followed by a word tagged GENE , then the word is tagged NN .", "label": "", "metadata": {}, "score": "78.57414"}
{"text": "The results of using soft - tied ( ST ) triphone and quinphone systems on eval98 is shown in Table 4 when data weighting is used .We have found that the use of acoustic data weighting reduces the beneficial effect of soft - tying .", "label": "", "metadata": {}, "score": "78.574814"}
{"text": "Multiple comparisons , adjusted for multiple testing , indicated that when the overall significance level is 0.1 , the sense distributions ( 0.5 , 0.5 ) and ( 0.6 , 0.4 ) impact the error rate .These results show that almost balanced sense distributions and rather large training sample sizes reduce the error rate to approximately half of our best guess , which is using the majority sense .", "label": "", "metadata": {}, "score": "79.01382"}
{"text": "As the Friedman 's test indicated , the effect of the sense distribution on the error rate is significant .When the sense distribution is ( 0.5 , 0.5 ) there are statistically significant differences between the pairs of error rates produced under sample size ( 20 and 120 ) , the sample sizes ( 40 and 120 ) and the sample sizes ( 80 and 120 ) .", "label": "", "metadata": {}, "score": "79.296364"}
{"text": "Pfam [ 44 ] is a non - redundant protein sequence database manually built using representatives from each protein family .This database is used for construction of Hidden - Markov - Model classifiers widely used in Bioinformatics .When constructing a corpus of patient notes for statistical purposes , we encounter patients with many records .", "label": "", "metadata": {}, "score": "79.31247"}
{"text": "Rows five and six in Table 3 display the phone accuracies obtained by combining multiple MFCC and feature based systems by sequential lattice re - scoring .At each stage of this se- quential process , a phone lattice is produced and this phone lattice is then re - scored by the following feature based HMM system .", "label": "", "metadata": {}, "score": "79.40266"}
{"text": "The detailed distribution supports the distinction into 2 groups of notes : those with heavy repetition ( about 37 % of the pairs - with similarity between 40 % and 100 % ) and those with no repetition ( about 63 % of the notes ) .", "label": "", "metadata": {}, "score": "79.412384"}
{"text": "McCallum AK : Mallet : A machine learning for language toolkit .Wallach H , Mimno D , McCallum A : Rethinking LDA : Why priors matter .Advances in Neural Information Processing Systems 2009 , 22 : 1973 - 1981 .", "label": "", "metadata": {}, "score": "79.41641"}
{"text": "Words are ranked by their significance in the topic ( i.e. , in the first topic the most important word is \" renal \" ) .The first topic includes words pertaining to renal disease , the second to hypertension and the third to symptoms and treatments related to the pulmonary system .", "label": "", "metadata": {}, "score": "79.47801"}
{"text": "System Combination Performance GiventhesimilarityofthephoneaccuraciesobtainedfromtheMFCC andfeaturebasedphonerecognizersshowninTable1 , itislikelythat performance could be further improved through some combination of these systems .This is true , of course , only if the errors produced by these different systems are complementary in some way .By ob- serving the level of improvements obtained using the ROVER and CNC based system combination techniques described in Section 5 , it is possible to get an indication of the degree to which the different feature representations convey complementary information .", "label": "", "metadata": {}, "score": "79.59019"}
{"text": "Center for Computational Pharmacology , University of Colorado School of Medicine .Fujitsu Ltd , BioChemical Information Project .Dept . of Computer Science , University of Colorado at Boulder .References .Tanabe L , Wilbur WJ : Tagging gene and protein names in biomedical text .", "label": "", "metadata": {}, "score": "79.6584"}
{"text": "Table 1 shows a complete list for this feature in the descending order of priority .Part - of - speech ( POS ) : Since many of the words in biomedical names are in lowercase , capitalization information in the biomedical domain is not as evidential as that in the newswire domain .", "label": "", "metadata": {}, "score": "79.768555"}
{"text": "van Rijsbergen CJ : Information Retrieval .2 Edition Butterworth 1979 .Copyright .\u00a9 Zhou et al 2005 .This article is published under license to BioMed Central Ltd. \" ...We show how web mark - up can be used to improve unsupervised dependency parsing .", "label": "", "metadata": {}, "score": "79.88758"}
{"text": "Labeled data typically requires expert annotators which makes it both time consuming and costly to produce .Furthermore , once training data has been created for one textual domain , portability to similar domains is limited .This domain - dependence has inspired a large body of work since syntactic parsing aims to capture syntactic patterns across an entire language rather than just a specific domain .", "label": "", "metadata": {}, "score": "80.038666"}
{"text": "Error Rate versus Sample Size with different sense distributions of BSA data set .This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of BSA data set ( case where the 2 ambiguous senses are very different ) using 5-fold cross - validation .", "label": "", "metadata": {}, "score": "80.04534"}
{"text": "Since there is only one name class ( NEWGENE ) in the BioCreative protein / gene name recognition task , we simplify the traditional BIO representation and employ IO tags to represent the regional information of protein / gene names .In this IO representation , I means that current word is a part of a protein / gene name , which corresponds to the SVM output 1 ; O means that current word is not a part of a protein / gene name , which corresponds to the SVM output -1 .", "label": "", "metadata": {}, "score": "80.25455"}
{"text": "For example , when the total sample size is 20 and 5-fold cross validation is used the size of the training set is 16 , while if the sample size is 80 the size of the training set is 64 .", "label": "", "metadata": {}, "score": "80.25554"}
{"text": "Breiman L : Bagging Predictors .Machine Learning 1996 , 24 : 123 - 140 .Schapire RE , Singer Y : Improved Boosting Algorithms using Confidence - rated Predictions .Proceedings of the 11th Annual ACM Conference on Computational Learning Theory 1998 , 80 - 91 .", "label": "", "metadata": {}, "score": "80.42181"}
{"text": "Background .The increasing availability of Electronic Health Record ( EHR ) data and specifically free - text patient notes presents opportunities for phenotype extraction .Text - mining methods in particular can help disease modeling by mapping named - entities mentions to terminologies and clustering semantically related terms .", "label": "", "metadata": {}, "score": "80.44632"}
{"text": "For the details of the ambiguity study , please refer to the sub - section \" Gene Ambiguity for mining MEDLINE \" in the Methods section .Research in automated WSD can be traced back to the 1950s [ 15 ] .", "label": "", "metadata": {}, "score": "80.490135"}
{"text": "Training and improvement of NLP tools for Medical - Informatics tasks on public available data will continue growing as more EHRs are incorporated into health care givers worldwide .The nature of epidemiological research demands looking at cohorts of patients , such as our kidney patient notes .", "label": "", "metadata": {}, "score": "80.60878"}
{"text": "However , if the performance has not yet flattened off ( or worsened ) , then there is hope that our system can be improved simply by training on more data .There are two aspects specific to our system that we would like to explore .", "label": "", "metadata": {}, "score": "80.685776"}
{"text": "The estimate of the standard error was then obtained by averaging the above values over the 30 runs .Gene ambiguity for mining MEDLINE .To determine the extent of the gene ambiguity problem in MEDLINE , we searched MEDLINE abstracts to determine how many abstracts contained gene symbols that were ambiguous with general English words or biomedical terms .", "label": "", "metadata": {}, "score": "80.69716"}
{"text": "The Hub5 acoustic training data is from two corpora : Switchboard-1 ( Swb1 ) and Call Home English ( CHE ) .The 180 hour training set used for training the 1998 HTK system used various sources of Swbd1 transcriptions and turn - level segmentations .", "label": "", "metadata": {}, "score": "80.84509"}
{"text": "Four ambiguous abbreviations : BPD , BSA , PCA , and RSV , were used in this study .They were chosen because they were associated with varying degrees of differences between their respective senses .For example , two of the senses of PCA studied are very similar whereas two senses of BSA are very different .", "label": "", "metadata": {}, "score": "80.91103"}
{"text": "For example , a sample testing set with size 20 and sense distribution ( 0.5 , 0.5 ) means 10 samples in the set are with one sense and the other 10 samples are with the other sense .The estimated sense distribution is listed in the last column of Table 1 , which is calculated based on the number of retrieved articles for each sense and the number of retrieved articles for all the senses .", "label": "", "metadata": {}, "score": "80.91768"}
{"text": "In this analysis a true positive is a single word that is tagged as GENE both in the gold standard and by our system .As would be expected , performance on single words is better than the term - level results , with an average precision of 88.3 and average recall of 78.7 without post - processing , and an average precision of 92.5 and average recall of 77.8 with post - processing .", "label": "", "metadata": {}, "score": "81.08519"}
{"text": "Background .Document Clustering refers to the process whereby a collection of documents is clustered in an unsupervised manner into clusters such that documents within the same cluster are more similar to each other than to documents in other clusters [ 3 , 4 ] .", "label": "", "metadata": {}, "score": "81.11694"}
{"text": "The parameter n is the granularity of the method , and its choice determines how stringent the comparison is .In order to compare two notes A and B , we compute the number of fingerprints shared by A and B. The level of similarity of B to A is defined as the ratio ( number of shared fingerprints ) / ( number of fingerprints in A ) .", "label": "", "metadata": {}, "score": "81.12711"}
{"text": "Abbreviations .There are many instances in the corpora in which a full gene name is immediately followed by an appositive parenthesized symbol or abbreviation .In many cases , the tagger would recognize either the full gene name or the symbol / abbreviation , but not both .", "label": "", "metadata": {}, "score": "81.32443"}
{"text": "In particular , we notice that when the sense distribution ( P1 , P2 ) was very unbalanced ( i.e. 0.9 , 0.1 ) , then the error rate was almost equal to the minority sense proportion .All these findings indicate that the effectiveness of an increase in the sample size is very dependent on the degree of difficulty .", "label": "", "metadata": {}, "score": "81.37721"}
{"text": "Table 3 shows the effectiveness of post - processing on one - word false positives with respect to the number of times the words corresponding to the false positives were seen in the training data .This table shows that 12.3 % of one - word false positives that correspond to unknown words were corrected while 85.2 % of one - word false positives that correspond to a word that had been seen twice or more in the training data were corrected .", "label": "", "metadata": {}, "score": "81.711685"}
{"text": "Figure 4 shows plots of the error rate versus sample size for each distribution of the BPD data set based on the 5-fold cross validation using the \" one - vs - rest \" algorithm .The plots for the four different sense distributions are very similar and actually agree with results obtained indicating that the effect of the different distributions on the error rate is insignificant .", "label": "", "metadata": {}, "score": "81.77286"}
{"text": "A head - to - head competition between the TnT tagger , the Brill tagger , and perhaps others would help determine whether or not the choice of tagger is an important decision .We would look at both the raw performance of each tagger as well as the performance of post - processing rules applied to the results of each tagger .", "label": "", "metadata": {}, "score": "81.8376"}
{"text": "Chen L , Liu H , Friedman C : Gene name ambiguity of eukaryotic nomenclatures .Bioinformatics 2005 , 21 : 248 - 256 .View Article PubMed .Schuemie MJ , Weeber M , Schijvenaars BJA , van Mulligen EM , van der Eijk CC , Jelier R , et al .", "label": "", "metadata": {}, "score": "82.08098"}
{"text": "Smaller increases in the sample size had an insignificant effect .We performed further sub - analysis using non - parametric multiple comparisons to identify the pairs of sample sizes that differ when the abbreviations BSA and RSV were analyzed .This analysis revealed that in the case of BSA the improvements in terms of error rate were statistically significant across distributions as the sample size increased from 20 to 40 .", "label": "", "metadata": {}, "score": "82.11038"}
{"text": "\" [ Show abstract ] [ Hide abstract ] ABSTRACT :In this paper , we study the effect of using different phonological feature sets for detection - based automatic speech recognition in phone recognition tasks .Three phonological feature sets derived from different underlying phonological theories are investigated .", "label": "", "metadata": {}, "score": "82.12237"}
{"text": "Shatkay H , Feldman R : Mining the biomedical literature in the genomic era : an overview .J Comput Biol 2003 , 10 : 821 - 855 .View Article PubMed .Fukuda K , Tamura A , Tsunoda T , Takagi T : Toward information extraction : identifying protein names from biological papers .", "label": "", "metadata": {}, "score": "82.14401"}
{"text": "Feature representation .The features described here are used in all the evaluations .In the competition , various features , including the surface word itself , are applied to capture the special characteristics of protein / gene names : .Orthographic feature : The purpose of this feature is to capture capitalization , digitalization and other word formation information .", "label": "", "metadata": {}, "score": "82.507126"}
{"text": "We computed the standard deviation of the error rate as follows .Recall that for each abbreviation , each sense distribution and each sample size we run the experiment 30 times .The error rate was computed using both a 5-fold and a 10-fold cross - validation scheme .", "label": "", "metadata": {}, "score": "82.56241"}
{"text": "Unlike western languages such as English , in which words are typically separated with white spaces and can thus be relatively easily be counted in terms of word number , Chinese contains running characters .Consequently , while it is easy to count the character number , it is not possible to count word number with raw texts .", "label": "", "metadata": {}, "score": "82.75546"}
{"text": "INTRODUCTION Currently , detection - based automatic speech recognition ( ASR ) isa , popular research topic in fields , related to ASR .Because human , beings often understand speech , by integrating , multiple knowledge sources from the bottom up , detection - based ASR systems , attempt , to reduce , the gap , between , human , speech .", "label": "", "metadata": {}, "score": "82.79353"}
{"text": "We used the training and devtest data to find ambiguous types that have zero or low probability ( less than 3 % ) of having the GENE_BEGIN or GENE_END tag in a multi - word gene name .For all multi - word gene mentions output by the tagger , we check the first word to see if it is on a list of words known not to be tagged GENE_BEGIN .", "label": "", "metadata": {}, "score": "82.901474"}
{"text": "This may be also due to the high ambiguity in the open dictionary of protein / gene names .This suggests that proper handling of public knowledge resources is important for the performance improvement in biomedical name recognition .Table 2 .", "label": "", "metadata": {}, "score": "82.917564"}
{"text": "If a word contains hyphen and the characters preceding the hyphen are capitalized letters or digits and the material following the hyphen is a gene keyword such as mutan t , then it is tagged GENE , e.g. SH2-mutant , and ANP - receptor .", "label": "", "metadata": {}, "score": "82.93902"}
{"text": "For instance , the phrase \" hip rplc \" is a common phrase used to refer to the hip replacement procedure , which does not match any concept on its own in the UMLS .When gathering counts or co - occurrence patterns for association studies with the goal of high - level applications , like detection of adverse drug events or disease modeling , augmenting existing terminologies with such collocations can be beneficial .", "label": "", "metadata": {}, "score": "83.29783"}
{"text": "Finally , the effect of the automatic segmentation procedure on the BNeval98 set was investigated .On BNeval97 we had found that automatic segmentation had produced very similar overall accuracy to manually defined segments .However on BNeval98 the automatic segmenter faired more poorly .", "label": "", "metadata": {}, "score": "83.322914"}
{"text": "View Article PubMed .Friedman M : The use of ranks to avoid the assumption of normality implicit in the analysis of variance .Journal of the American Statistical Association 1937 , 32 : 675 - 701 .View Article .Rifkin R , Klatau A : In defense of one - vs - all classification .", "label": "", "metadata": {}, "score": "83.4755"}
{"text": "It is useful for testing whether one random variable in a pair tends to have larger ( smaller or simply different ) values than the other random variable in the pair .In our case , the random variables in the pair are the error rates obtained under the different sample sizes used .", "label": "", "metadata": {}, "score": "83.515625"}
{"text": "For the ROVER based system combination , a single phone string was produced by each 50 .Page 5 . system and the phone strings were successively aligned in the or- der shown in the table with the phone string produced by the MFCC system used as the reference string in the alignment process .", "label": "", "metadata": {}, "score": "83.54622"}
{"text": "A produced cluster with a precision of 1 means that it does not contain any \" wrong \" documents in it .However , the fact that recall is lower than 1 means that the produced cluster does not contain all the documents in the corresponding reference cluster .", "label": "", "metadata": {}, "score": "83.62591"}
{"text": "Figure 2A shows the effect of term length for the cross validation data .Figure 2B shows the effect of term length for the official test data .Recall and precision tend to be better for shorter gene mentions .However precision tends to degrade slightly for gene mentions that are only one word long .", "label": "", "metadata": {}, "score": "83.65405"}
{"text": "Most stories of this type , even though they were published recently , are under the influence of vernacular Chinese , i.e. modern Chinese styled to appear like classical Chinese .While the inclusion of this text type has made the tasks of POS tagging and post - editing more difficult , it may also make it possible to compare representations of vernacular Chinese and modern Chinese .", "label": "", "metadata": {}, "score": "83.849335"}
{"text": "Acknowledgements .This work was supported by part by Grants R01 LM7659 , R01 LM8635 from the National Library of Medicine , and Grants NSF - DMS-0504957 , NSF- IIS-0430743 from the National Science Foundation .We would like to thank Lyudmila Shagina for providing technical support .", "label": "", "metadata": {}, "score": "83.895355"}
{"text": "It suggests that we need to model the ends of biomedical names .Removing generic adjective words , e.g. \" new \" and \" novel \" in the beginning of recognized protein / gene names .This rule can compensate the failure of IO representation in the SVM to model the beginnings of biomedical names , compared with the BIO representation , even though the IO representation simplifies the problems and makes the data denser .", "label": "", "metadata": {}, "score": "83.92639"}
{"text": "A path through the graph is found by choosing one of the alternatives from each confusion set .By picking the word with the highest posterior from each set the sentence hypothesis with the lowest overall expected word error rate can be found .", "label": "", "metadata": {}, "score": "84.03435"}
{"text": "Background .The Electronic Health Record ( EHR ) contains valuable information entered by clinicians .Besides its immediate clinical use at the point of care , the EHR , when treated as a repository of medical information across many patients , provides rich data waiting to be analyzed and mined for clinical discovery .", "label": "", "metadata": {}, "score": "84.5554"}
{"text": "In future work , we will explore more classifiers and more effective approaches to integrate them in an ensemble .Moreover , we will explore proper approaches for handling the large open dictionary and even more knowledge resources .Finally , we will further improve the performance by investigating more on conjunctive and disjunctive construction , the synonym phenomenon and the name alias phenomenon .", "label": "", "metadata": {}, "score": "84.56858"}
{"text": "Technology license is available with a bilateral agreement .Please contact Dr. Su Jian ( the 4 th author SJ : sujian@i2r.\u200ba - star.\u200bedu.\u200bsg ) for details .Declarations .Acknowledgements .We would like to thank Associate Professor Ng See Kiong and Ms. Zhang Zhuo from the Institute of Infocomm Research , Singapore for providing the large open biomedical name list , although this time we did n't have enough time to make good use ofsuch a rich resource .", "label": "", "metadata": {}, "score": "84.602234"}
{"text": ": When an event occurs in the real world , numerous news reports describing this event start to appear on different news sites within a few minutes of the event occurrence .This may result in a huge amount of information for users , and automated processes may be required to help manage this information .", "label": "", "metadata": {}, "score": "84.728134"}
{"text": "The default gene tag set contains two gene tags : ' NEWGENE ' and ' NEWGENE1 ' .The latter tag is used when two gene mentions are immediately next to each other in the text .Approximately 1.1 % of the gene mentions in the training and devtest sets are tagged with the ' NEWGENE1 ' tag .", "label": "", "metadata": {}, "score": "84.746735"}
{"text": "17 ] , the most popular sequence similarity algorithm in bioinformatics , is based on hashing of short sub - strings within the genetic sequence and then using the slower optimized dynamic programming alignment for sequences found to share enough sub - sequences .", "label": "", "metadata": {}, "score": "84.8771"}
{"text": "\u00a9 Kinoshita et al 2005 .This article is published under license to BioMed Central Ltd.This paper presents techniques for exploiting complementary information contained in multiple definitions of phonological feature systems .Three different feature systems , differing in their structure and in the acoustic phonetic features they represent , are considered .", "label": "", "metadata": {}, "score": "84.961685"}
{"text": "For PCA , the estimated distribution was ( 0.67 , 0.33 ) .Four different sample sizes were used ( 20 , 40 , 80 and 120 ) , and for each , a proportional sample for each sense was obtained based on the particular distribution .", "label": "", "metadata": {}, "score": "84.97297"}
{"text": "Trigger word : The head noun of a noun phrase often describes the function or the property of the noun phrase .In this paper , we automatically extract unigram and bigram head nouns from the context of protein / gene names in the training data as trigger words .", "label": "", "metadata": {}, "score": "85.483955"}
{"text": "ROVER , as originally introduced by Fiscus [ 3 ] , is performed in two stages .In the first stage , the decoded output strings produced by the individual speech recognition systems are aligned using dynamic programming .This is a sequential procedure that is initiated by first picking a reference string .", "label": "", "metadata": {}, "score": "85.49134"}
{"text": "Ginter F , Boberg J , Salakoski T , Salakoski T : New Techniques for Disambiguation in Natural Language and Their Application to Biological Text .Journal of Machine Learning Research 2004 , 5 : 605 - 621 .Podowski RM , Cleary JG , Goncharoff NT , Amoutzias G , Hayes WS : AZuRE , a scalable system for automated term disambiguation of gene and protein names .", "label": "", "metadata": {}, "score": "85.634766"}
{"text": "Statistical tests [ 39 , 40 ] can be used to compare different classifiers .It is very important that the baseline of a classification task is reported because it shows how much of an improvement there is using a classifier as compared to the baseline .", "label": "", "metadata": {}, "score": "85.68067"}
{"text": "However , combining a single feature based system with the MFCC system using CNC re- sults in a far greater improvement , with the MFCC+GP combination resulting in a 3.9 % absolute improvement .Finally , the last two rows of Table 2 show that significant additional improvements in PAC are obtained as the additional feature based systems are combined using both ROVER and CNC .", "label": "", "metadata": {}, "score": "85.706436"}
{"text": "11 July 2003 .Zhou GuoDong , Zhang Jie , Su Jian , Shen Dan , Tan ChewLim : Recognizing Names in Biomedical Texts : a Machine Learning Approach .Bioinformatics 2004 , 20 ( 7 ) : 1178 - 1190 .", "label": "", "metadata": {}, "score": "85.888695"}
{"text": "Department of Biomedical Informatics , Columbia University .Department of Biostatistics , Bioinformatics and Biomathematics , Georgetown University Medical Center .References .Krallinger M , Valencia A : Text - mining and information - retrieval services for molecular biology .Genome Biol 2005 , 6 : 224 .", "label": "", "metadata": {}, "score": "85.929504"}
{"text": "where is the composite model corresponding to the word sequence and is the probability of this sequence as determined by the language model .The summation in the denominator of ( 1 ) is taken over all possible word sequences allowed in the task and it can be replaced by .", "label": "", "metadata": {}, "score": "86.171074"}
{"text": "In order to further improve the performance , we also develop a name refinement module .This module applies some heuristic rules to refine the recognized protein / gene names according to the Task1A guidelines and recover the errors caused by the inconsistency and the improper tokenization in the training data , e.g. .", "label": "", "metadata": {}, "score": "86.25075"}
{"text": "Two implications of noise are possible .The first is false positive identification , i.e. , extracting collocations which are the result of mere chance .The second implication is loss of significant collocations due to noise ( or because important collocations are out - ranked by less important ones ) .", "label": "", "metadata": {}, "score": "86.679855"}
{"text": "In this paper , we address two issues that are related to domain adaptation .The first question is how much genre variation will affect NLP systems ' per ... \" .Domain adaptation is an important task in order for NLP systems to work well in real applications .", "label": "", "metadata": {}, "score": "86.73303"}
{"text": "For each combination of error rates we have a sample of 30 observations .To exemplify , assume the pair consisted of the error rates obtained under sample size 20 and 40 .Then the set of observations was comprised of those error rates obtained from the 30 simulation runs .", "label": "", "metadata": {}, "score": "86.79706"}
{"text": "Left boundary errors ( 37 ) : It includes the errors with correct right boundary detection and only wrong left boundary detection .We find that most of such errors come from the long and descriptive naming convention in the biomedical names .", "label": "", "metadata": {}, "score": "86.82216"}
{"text": "The best phone label at each alignment point was chosen by summing the posterior probabilities for arcs containing a given phone label .The ROVER performance in the first row of Table 2 displays the baseline MFCC PAC .The performance displayed for CNC in the first row of the table represents the PAC obtained using a modified word error rate optimization criterion [ 4].", "label": "", "metadata": {}, "score": "86.940254"}
{"text": "All arcs leaving a node , or alignment point , in this WTN have the same destination node .There is no opti- mum ordering of strings in this alignment process that is guaranteed to give the best results .The second stage consists of selecting the best scoring label at each alignment point through a voting process .", "label": "", "metadata": {}, "score": "86.95037"}
{"text": "If the last word of the long form was tagged as a gene , then we changed any non - gene tags in the long form and abbreviation to GENE .For example , if a long form / abbreviation pair contained the tag sequence JJ NN NN GENE ( NNP ) , then we changed the tags to GENE GENE GENE GENE ( GENE ) .", "label": "", "metadata": {}, "score": "87.010635"}
{"text": "Rule 2 .Rule 3 .If the last word was one of a small list of gene keywords such as protein and factor derived from the BioCreAtIvE specification , then all tags in the long form ( and the abbreviation ) were changed to GENE .", "label": "", "metadata": {}, "score": "87.561356"}
{"text": "A term is tagged NN if it contains the word virus and matches one of the following patterns : .The last or second - to - last word of the term contains virus , e.g. type I herpes simplex virus , adenovirus , reovirus RNAs , and rotavirus genome .", "label": "", "metadata": {}, "score": "88.52366"}
{"text": "Example : the / DT dnHLH / NEWGENE protein / NEWGENE Id1/ NEWGENE1 inhibits / VBZ .Tag set 2 : Detailed boundary information .This tag set contains four gene tags : ' GENE_BEGIN ' , ' GENE_INSIDE ' , ' GENE_END ' , and ' GENE_ONEWORD ' .", "label": "", "metadata": {}, "score": "88.61644"}
{"text": "Mach Learn 2010 , 79 ( 1 ) : 123 - 149 .View Article .Blitzer J , Dredze M , Pereira F : Biographies , bollywood , boom - boxes and blenders : Domain adaptation for sentiment classification .Moore RC , Lewis W : Intelligent selection of language model training data .", "label": "", "metadata": {}, "score": "88.72239"}
{"text": "A number of natural language processing systems in the biomedical domain reported decreased precision due to the ambiguity problem [ 3 , 4 ] .Weeber [ 5 ] found that in order to replicate Swanson 's literature - based discovery of the involvement of magnesium deficiency in migraine , it was important to resolve the ambiguity of an abbreviation mg , which can denote either magnesium or milligram .", "label": "", "metadata": {}, "score": "89.45345"}
{"text": "The table also shows the effect of giving a factor of three weighting to the CHE training data ( The test set is balanced across Switchboard and Call Home data but the training set is n't and so data weighting attempts to partially correct this imbalance ) .", "label": "", "metadata": {}, "score": "89.66575"}
{"text": "Right boundary errors ( 9 ) : It includes the errors with correct left boundary detection and only wrong right boundary detection .It usually occurs when the head words of the protein / gene names seldom occur in the training data and the system fails to model these less - frequently occurring head words .", "label": "", "metadata": {}, "score": "90.04448"}
{"text": "They both rely on patterns of co - occurrence of words .Collocations are word sequences that co - occur more often than expected by chance .Collocations , such as \" heart attack \" and \" mineral water , \" carry more information than the individual words comprising them .", "label": "", "metadata": {}, "score": "90.66409"}
{"text": "The tasks of such automated systems may be rendered simpler by having a mechanism that clusters news stories together by specific events ( e.g. , news reports on the murders in Norway by Anders Breivik ) .Although existing news aggregators ( e.g. , Google News ) provide this functionality , the user would be limited to the news stories that the aggregator tracks .", "label": "", "metadata": {}, "score": "90.767395"}
{"text": "Boundary Correction : IgG / NEWGNE binding / NN .Output : regulator / NEWGENE virF / NEWGNE .Boundary Correction : regulator / NN viF / NEWGENE .Single - word false positive correction .We applied a similar process to detect single - word false positives output by the POS tagger using a list of ambiguous types that were observed in the training and devtest data to have a zero or very low probability ( less than 5 % ) of being tagged GENE_ONEWORD .", "label": "", "metadata": {}, "score": "92.52902"}
{"text": "TW1 , such as receptor , enhancer and mutant , is collected based on the Task 1A Guideline .TW2 , such as activation , transcription and stimulation , is extracted automatically from the training data using the tf - idf weighing scheme [ 14 ] to measure how specific a given trigger word is to protein / gene names .", "label": "", "metadata": {}, "score": "92.75155"}
{"text": "For example , If only \" p53 \" in \" p53 mutant \" is recognized as a protein / gene name , we will add \" mutant \" into the name since \" mutant \" is a positive trailer word .Similarly , we also shorten the recognized names by removing negative trailer words .", "label": "", "metadata": {}, "score": "93.73033"}
{"text": "If a word is tagged GENE and is followed by a number , Roman numeral , or Greek letter , then the number / numeral / letter is tagged GENE .If a word is tagged GENE and it is followed by parenthesized material that is five characters or longer , then the parenthesized material is tagged with GENE .", "label": "", "metadata": {}, "score": "94.18044"}
{"text": "A word is tagged GENE if it matches one of the following patterns : .The word starts with the character p and is followed by two or more digits , e.g. p53 , and p69/71 .The word starts with pp or gp and is followed by two or more digits , e.g. pp43 , pp85 , gp27 , and gp120 \u00d7 41 .", "label": "", "metadata": {}, "score": "94.47881"}
{"text": "Removing generic terms ( all the words used in the name are too common ) , e.g. \" protein kinase \" .Removing odd names , such as individual digits and Greek letters .Dictionary matching .Finally , we also evaluate the effectiveness of a protein / gene name dictionary using a simple dictionary matching algorithm .", "label": "", "metadata": {}, "score": "94.57859"}
{"text": "The authors declare that they have no competing interests .Authors ' contributions .RC participated in the study design , carried out the statistical analyses and wrote the paper .ME participated in study design and wrote the paper .NE participated in study design and wrote the paper .", "label": "", "metadata": {}, "score": "94.72406"}
{"text": "Yahoo !News provides RSS feeds for a number of categories that are not so general .Examples of such categories are \" Apple Macintosh \" , \" India \" and \" Democratic Party \" .This corpus contains 7342 news reports classified into 68 categories .", "label": "", "metadata": {}, "score": "95.04372"}
{"text": "For BSA , RSV and BPD , we found that the effect of the sense distribution on the error rate was insignificant .For PCA this effect was significant .The effect of different sample sizes on the error rate was significant for BSA , RSV , and BPD .", "label": "", "metadata": {}, "score": "96.55355"}
{"text": "Tag set 4 : Simplest tag set .This tag set is a simplified version of tag set 1 .Tokens that were tagged ' NEWGENE ' or ' NEWGENE1 ' are all tagged ' GENE ' .Thus , there is only one gene tag in this set : ' GENE ' .", "label": "", "metadata": {}, "score": "97.60762"}
{"text": "Entity category , which indicates whether the word locates inside or outside a protein / gene name .Word feature , which is added to represent the state transition model more accurately .The idea behind the model is that we try to assign each word an appropriate tag , which contains boundary and class information .", "label": "", "metadata": {}, "score": "97.733025"}
{"text": "The word pathway never occurs in the corpora tagged as GENE_ONEWORD while the word estrogen is tagged GENE_ONEWORD in one ( or 4.5 % ) of 22 occurrences .The following lines show the POS counts in the training corpus for the words pathway and estrogen .", "label": "", "metadata": {}, "score": "98.79437"}
{"text": "It often occurs when the system has little information about them and context clues are insufficient .False positive ( 22 ) : It includes the errors by wrongly identifying protein / gene names .It usually occurs when a noun phrase is a description of a protein / gene name or includes symbols or is mixed with digits and capitalized letters .", "label": "", "metadata": {}, "score": "99.598145"}
{"text": "Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .Publisher conditions are provided by RoMEO .", "label": "", "metadata": {}, "score": "100.17799"}
{"text": "Author to whom correspondence should be addressed ; Email : Tel . : +356 - 2340 - 2844 ; Fax . : +356 - 2144 - 0972 .Received : 29 June 2012 ; in revised form : 13 August 2012 / Accepted : 15 August 2012 / Published : 24 August 2012 .", "label": "", "metadata": {}, "score": "101.23757"}
{"text": "Example : androgen / GENE_BEGIN receptor / GENE_END ( AR / GENE_ONEWORD ) .Example : Syn / GENE_BEGIN 5/GENE_INSIDE locus / GENE_END .Tag set 3 : Simplified boundary information .This tag set is a simplified version of tag set 2 .", "label": "", "metadata": {}, "score": "104.13945"}
{"text": "For example , tokens of the ambiguous type binding are tagged as JJ , NN , and GENE_INSIDE .Correctly tagging tokens of ambiguous types is a difficult task .Boundary correction .The POS tagger 's output sometimes contains boundary errors such as the following : .", "label": "", "metadata": {}, "score": "109.97945"}
{"text": "In this example , the long form is Insulin - like growth factor 1 and the abbreviation is IGF-1 .We developed a number of rules that we applied to long form / abbreviation pairs found by the Schwartz and Hearst algorithm : .", "label": "", "metadata": {}, "score": "110.81926"}
{"text": "[ Google Scholar ] .\u00a9 2012 by the authors ; licensee MDPI , Basel , Switzerland .", "label": "", "metadata": {}, "score": "113.97479"}
{"text": "Gold Standard : IgG / GENE_ONEWORD binding / NONGENE .Problem : Right boundary is wrong .Output : regulator / GENE_BEGINvirF / GENE_END .Gold Standard : regulator / NONGENE virF / GENE_ONEWORD .Problem : Left boundary is wrong .", "label": "", "metadata": {}, "score": "119.40628"}
{"text": "Tokens that were tagged ' GENE_END ' are now tagged ' GENE_INSIDE ' and tokens that were tagged ' GENE_ONEWORD ' are now tagged ' GENE_BEGIN ' .Example : androgen / GENE_BEGIN receptor / GENE_INSIDE ( AR / GENE_BEGIN ) .", "label": "", "metadata": {}, "score": "122.492966"}
