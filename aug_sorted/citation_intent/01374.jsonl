{"text": "The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet Agirre , E. and Rigau , G. ( 1996 ) .", "label": "", "metadata": {}, "score": "40.89411"}
{"text": "This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .", "label": "", "metadata": {}, "score": "42.013992"}
{"text": "This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .", "label": "", "metadata": {}, "score": "42.013992"}
{"text": "It was expected to be more useful in this study , because a wide variation of phrases was anticipated between the corpora , as the corpora originated from different institutions and used different annotation guidelines .Performance measures of precision , recall and F1 score were computed for the experiments ( Figure 1 ) .", "label": "", "metadata": {}, "score": "42.818542"}
{"text": "so from where to get tagged words , that are Correctly tagged by nltk 's brill .I think you 'll have to collect the stats manually .You could write a function like accuracy that takes in a \" gold standard \" of tagged sentences .", "label": "", "metadata": {}, "score": "42.923088"}
{"text": "Many studies have indeed shown that cross - domain learned corpora yield poor language models [ 35].The field of domain adaptation attempts to compensate for the poor quality of cross - domain data , by adding carefully picked text from other domains [ 36,37 ] or other statistical mitigation techniques .", "label": "", "metadata": {}, "score": "43.45416"}
{"text": "Specifically , we removed articles and possessive pronouns from i2b2 annotations .Fifteen percent of the i2b2 annotated phrases were modified .When this partially rectified corpus was used to supplement training data for the MCR corpus , there was lesser degradation of the performance measures .", "label": "", "metadata": {}, "score": "43.60565"}
{"text": "This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .", "label": "", "metadata": {}, "score": "44.214996"}
{"text": "This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .", "label": "", "metadata": {}, "score": "44.214996"}
{"text": "This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .", "label": "", "metadata": {}, "score": "44.214996"}
{"text": "The second question is how one can estimate NLP systems ' performance when gold standard on the test data does not exist .To answer the question , we extend the parsing prediction model in ( Ravi et al . , 2008 ) to provide prediction for word segmentation and POS tagging as well .", "label": "", "metadata": {}, "score": "44.66172"}
{"text": "Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .", "label": "", "metadata": {}, "score": "44.81703"}
{"text": "Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .", "label": "", "metadata": {}, "score": "44.81703"}
{"text": "To appear in Journal of Natural Language Engineering , 4(3 ) .use large lexicons ( generally machine readable dictionaries ) and the information associated with the senses ( such as part - of - speech tags , topical guides and selectional preferences ) to indicate the correct sense .", "label": "", "metadata": {}, "score": "45.39411"}
{"text": "This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 13 ] .", "label": "", "metadata": {}, "score": "45.402245"}
{"text": "This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 13 ] .", "label": "", "metadata": {}, "score": "45.402245"}
{"text": ".. our corpus .The second question is how one can estimate NLP systems ' performance when gold standard on the test data does not exist .Our experiments show that the predicted scores are close to the real scores when tested on the CTB data .", "label": "", "metadata": {}, "score": "45.445236"}
{"text": "We divided the available WSJ data into a train and test set , trained a parser on the train set and compared errors on the test set and BIO .Accuracy dropped from 90 % on WSJ to 84 % on BIO .", "label": "", "metadata": {}, "score": "45.473747"}
{"text": "These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .", "label": "", "metadata": {}, "score": "45.584118"}
{"text": "These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .", "label": "", "metadata": {}, "score": "45.584118"}
{"text": "These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .", "label": "", "metadata": {}, "score": "45.584118"}
{"text": "Self - training creates semi - supervised learners from existing supervised learners with minimal effort .We first show results on self - training for constituency parsing within a single domain .While self - training has failed here in the past , we present a simple modification which allows it to succeed , producing state - of - the - art results for English constituency parsing .", "label": "", "metadata": {}, "score": "45.813194"}
{"text": "Results .We found that pooling was effective when the size of the local corpus was small and after some of the guideline differences were reconciled .The benefits of pooling , however , diminished as more locally annotated documents were included in the training data .", "label": "", "metadata": {}, "score": "45.93554"}
{"text": "( 1996 ) which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .A similarity matrix is thus formed which is subject to cluster analysis to determine groups of semantically related instances of terms .", "label": "", "metadata": {}, "score": "46.239357"}
{"text": "No additional knowledge about the target domain is included .A more realistic approach assumes that only raw text from the target domain is available .This assumption lends itself well to semi - supervised learning methods since these utilize both labeled and unlabeled examples .", "label": "", "metadata": {}, "score": "46.355026"}
{"text": "We present a method for acquiring reliable predicate - argument structures from raw corpora for automatic compilation of case frames .Such lexicon compilation requires highly reliable predicate - argument structures to practically contribute to Natural Language Processing ( NLP ) applications , such as paraphrasing , text entailment , and machine translation .", "label": "", "metadata": {}, "score": "46.41941"}
{"text": "In summary , simple pooling of corpora was overall found to reduce the tagger performance .We examined the annotation guidelines for the corpora to delineate several inconsistencies that include concept definition , articles , possessive pronouns , unrelated concepts , prepositional phrases and conjunctions .", "label": "", "metadata": {}, "score": "46.43132"}
{"text": "We observe redundancy levels of about 30 % and non - standard distribution of both words and concepts .We measure the impact of redundancy on two standard text - mining applications : collocation identification and topic modeling .We compare the results of these methods on synthetic data with controlled levels of redundancy and observe significant performance variation .", "label": "", "metadata": {}, "score": "46.557228"}
{"text": "However , machine learning methods are sensitive to the distribution of data , such as the distribution of words in the vocabulary and grammar styles , which could significantly affect the portability of a trained machine learning system across institutions and , thus the value of annotated corpora .", "label": "", "metadata": {}, "score": "46.602486"}
{"text": "References .Demner - Fushman D , Chapman WW , McDonald CJ : What can natural language processing do for clinical decision support ?J Biomed Inform 2009 , 42 ( 5 ) : 760 - 772 .View Article .Meystre SM , Savova GK , Kipper - Schuler KC , Hurdle JF : Extracting information from textual documents in the electronic health record : a review of recent research .", "label": "", "metadata": {}, "score": "46.707504"}
{"text": "decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .This experiment involved the following steps : . # deriving a lexicon from the WordNet data files which contains all possible semantic tags for each noun , adjective , adverb and verb .", "label": "", "metadata": {}, "score": "46.8245"}
{"text": "This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .", "label": "", "metadata": {}, "score": "47.245403"}
{"text": "Instead , we scaled each feature 's value by a factor proportional to its frequency in the target do- main and trained the parser on these scaled feature values .We obtained small improvements on small amounts of training data .Target Focused Learning 4 Future Directions Given our pessimistic analysis and the long list of failed methods , one may wonder if parser adapta- tion is possible at all .", "label": "", "metadata": {}, "score": "47.458916"}
{"text": "In what follows , we provide an er- ror analysis that attributes domain loss for this task to a difference in annotation guidelines between do- mains .We then overview our attempts to improve adaptation .While we were able to show limited adaptation on reduced training data or with first- order features , no modifications improved parsing with all the training data and second - order features .", "label": "", "metadata": {}, "score": "47.538612"}
{"text": "I believe it was trained with most or all of the available corpora , which would definitely make it more accurate .However , it 'll only have high accuracy for text that 's similar to the corpora it was trained on .", "label": "", "metadata": {}, "score": "47.979294"}
{"text": "I think you 'll have to collect the stats manually .You could write a function like accuracy that takes in a \" gold standard \" of tagged sentences .Untag each sentence and run your tagger over it and compare it to the gold sentence .", "label": "", "metadata": {}, "score": "47.993523"}
{"text": "Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 5 ] and LDOCE [ 6 ] .", "label": "", "metadata": {}, "score": "48.022102"}
{"text": "Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 5 ] and LDOCE [ 6 ] .", "label": "", "metadata": {}, "score": "48.022102"}
{"text": "The fact that web mark - up strongly correlates with syntactic structure may have broad applicability in NLP . \" ...We present a method for acquiring reliable predicate - argument structures from raw corpora for automatic compilation of case frames .", "label": "", "metadata": {}, "score": "48.027504"}
{"text": "We present a number of semi - supervised parsing experiments on the Irish language carried out using a small seed set of manually parsed trees and a larger , yet still relatively small , set of unlabelled sentences .We take two popular dependency parsers - one graph - based and one transition - based - and ... \" .", "label": "", "metadata": {}, "score": "48.038986"}
{"text": "The first submission , the highest ranked constituency parsing system , uses a combination of PCFG - LA product grammar parsing and self - training .In the second submission , also a constituency parsing ... \" .The DCU - Paris13 team submitted three systems to the SANCL 2012 shared task on parsing English web text .", "label": "", "metadata": {}, "score": "48.058693"}
{"text": "Performance measures of the taggers trained on the curated i2b2 corpus and tested on MCR corpus .The plots A , B and C show the F1-score , precision and recall respectively .There are two lines in each plot that correspond to the two evaluation methods : Exact ( E ) with solid lines and Overlap ( O ) with dashed lines .", "label": "", "metadata": {}, "score": "48.14292"}
{"text": "We study this problem as a new task - multiple source parser adaptation .Our system trains on corpora from many different domains .It learns not only statistics of those domains but quantitative measures of domain differences and how those differences affect parsing accuracy .", "label": "", "metadata": {}, "score": "48.150085"}
{"text": "However , our results were obtained without adap- tation .Given our position in the ranking , this sug- gests that no team was able to significantly improve performance on either test domain beyond that of a state - of - the - art parser .", "label": "", "metadata": {}, "score": "48.39309"}
{"text": "This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .", "label": "", "metadata": {}, "score": "48.659294"}
{"text": "These fine grained tags provide more information than coarse tags ; experiments that removed fine grained tags 1052 .Page 3 . hurt WSJ performance but did not affect BIO .Finally , we examined the effect of unknown words .Not surprisingly , the most significant dif- ferences in error rates concerned dependencies be- tween words of which one or both were unknown to the parser .", "label": "", "metadata": {}, "score": "48.67698"}
{"text": "Conversion procedures fall out of our linguistic analysis of a newly available million - word hyper - text corpus .Web - scale experiments show that the DMV , perhaps because it is unlexicalized , does not benefit from orders of magnitude more annotated but noisier data .", "label": "", "metadata": {}, "score": "48.932243"}
{"text": "A method for acquiring reliable predicate - argument structures We acquire reliable predicate - argument str ... . \" ...It is well known that parsing accuracy suffers when a model is applied to out - of - domain data .It is also known that the most beneficial data to parse a given domain is data that matches the domain ( Sekine , 1997 ; Gildea , 2001 ) .", "label": "", "metadata": {}, "score": "49.20618"}
{"text": "The corpus has been annotated with various levels of linguistic and semantic information , such as sentence splitting , tokenization , part - of - speech tagging , chunking annotation , and term - event information .For chunker training , we selected a subset of 500 abstracts that constituted a previous version of the GENIA corpus [ 12 ] .", "label": "", "metadata": {}, "score": "49.31704"}
{"text": "Both words were unknown only 5 % of the time in BIO , while one of the words being un- known was more common , reflecting 27 % of deci- sions .Upon further investigation , the majority of unknown words were nouns , which indicates that unknown word errors were caused by the problems discussed above .", "label": "", "metadata": {}, "score": "49.449024"}
{"text": "However , it 'll only have high accuracy for text that 's similar to the corpora it was trained on .If you 're tagging text that has a lot of specialty / unique words and phrases , you 'll need to create your own training data for the training process in order to get accurate results .", "label": "", "metadata": {}, "score": "49.55372"}
{"text": "Two types of arrows point to the test sets : a ) Solid lines representing a direct evaluation on the test set , b )The dotted lines represent 5 fold cross - validation in which the fraction of the corpus being tested is excluded from the training set .", "label": "", "metadata": {}, "score": "49.753418"}
{"text": "But how does the observed EHR redundancy affect text mining ?Does such redundancy introduce a bias that distorts learned models ?Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?( iii )How can one mitigate the impact of redundancy on text mining ?", "label": "", "metadata": {}, "score": "49.880707"}
{"text": "WSJ data ( Petrov and Klein , 2007 ; Foster , 2010 ) .The parser uses the English signature list described in Attia et al ( 2010 ) to assign partof - speech tags to unknown words . \" ...Domain adaptation is an important task in order for NLP systems to work well in real applications .", "label": "", "metadata": {}, "score": "49.90007"}
{"text": "I2b2 annotators used UMLS definitions to guide the annotation , which allowed them greater flexibility to annotate and even include phrases that were not covered in the UMLS .Hence , to facilitate reuse of the annotations for developing machine learning models for concept recognition , we suggest the following two - step approach for annotation .", "label": "", "metadata": {}, "score": "50.058388"}
{"text": "French .French TreeBank ( FTB , Abeill\u00e9 et al ; 2003 )Le Monde , December 2007 version , 28-tag tagset ( CC tagset , Crabb\u00e9 and Candito , 2008 ) .Classical data split ( 10 - 10 - 80 ) : . Brants ( 2000 ) reports 96.7 % token accuracy and 85.5 % unknown word accuracy on a 10-fold cross - validation of the Penn WSJ corpus .", "label": "", "metadata": {}, "score": "50.097313"}
{"text": "As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .With the rise of statistical methods in CL in the 1990s , WSD became one of the main focus ' of supervised learning techniques .", "label": "", "metadata": {}, "score": "50.120724"}
{"text": "The horizontal axis indicates the training sets : MCR , i2b2 and combined ( MCR + i2b2 ) .Intra - corpus testing .Taggers performed the best when the training and test sets were from the same corpus .F1-scores for MCR and i2b2 cross - validations were 0.58 and 0.79 for ' exact span ' evaluation , respectively .", "label": "", "metadata": {}, "score": "50.19023"}
{"text": "To confirm that nouns were problem- atic , we modified a first - order parser ( no second or- der features ) by adding a feature indicating correct noun - noun edges , forcing the parser to predict these edges correctly .", "label": "", "metadata": {}, "score": "50.21309"}
{"text": "However , most ... \" .It is well known that parsing accuracy suffers when a model is applied to out - of - domain data .It is also known that the most beneficial data to parse a given domain is data that matches the domain ( Sekine , 1997 ; Gildea , 2001 ) .", "label": "", "metadata": {}, "score": "50.263298"}
{"text": "We take two popular dependency parsers - one graph - based and one transition - based - and compare results for both .Results show that using semisupervised learning in the form of self - training and co - training yields only very modest improvements in parsing accuracy .", "label": "", "metadata": {}, "score": "50.294533"}
{"text": "The greater degradation for MCR is likely due to small size of the corpus as compared to the i2b2 corpus , i.e. the proportion of data supplemented to MCR training set was much larger than that for i2b2 .The pattern was similar for precision and recall , and for the ' overlap span ' evaluation .", "label": "", "metadata": {}, "score": "50.518272"}
{"text": "Most work from 2002 on adopts the following data splits , introduced by Collins ( 2002 ) : . Brants ( 2000 ) reports 96.7 % token accuracy and 85.5 % unknown word accuracy on a 10-fold cross - validation of the Penn WSJ corpus .", "label": "", "metadata": {}, "score": "50.702766"}
{"text": "In Proceedings of the 14th International Conference on Computational Linguistics ( COLING-92 ) , pages 454 - 460 , Nantes , France , 1992 .This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .", "label": "", "metadata": {}, "score": "50.91323"}
{"text": "Integrated annotation for biomedical information ex- traction .In Proc . of the Human Language Technol- ogy Conference and the Annual Meeting of the North American Chapter of the Association for Computa- tional Linguistics ( HLT / NAACL ) .B. MacWhinney .", "label": "", "metadata": {}, "score": "50.97242"}
{"text": "These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 12 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .", "label": "", "metadata": {}, "score": "51.34266"}
{"text": "These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 12 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .", "label": "", "metadata": {}, "score": "51.34266"}
{"text": "[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .", "label": "", "metadata": {}, "score": "51.345795"}
{"text": "[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .", "label": "", "metadata": {}, "score": "51.345795"}
{"text": "The distributed GENiA tagger is trained on a mixed training corpus and gets 96.94 % on WSJ , and 98.26 % on GENiA biomedical English .Proceedings of the 4th International Conference on Language Resources and Evaluation ( LREC'04 ) ' ' .", "label": "", "metadata": {}, "score": "51.53224"}
{"text": "[ 1 ] The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .", "label": "", "metadata": {}, "score": "51.53587"}
{"text": "[ 1 ] The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .", "label": "", "metadata": {}, "score": "51.53587"}
{"text": "The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .", "label": "", "metadata": {}, "score": "51.856438"}
{"text": "The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .", "label": "", "metadata": {}, "score": "51.856438"}
{"text": "We tried a number of criteria to weigh sentences without suc- cess , including sentence length and number of verbs .Next , we trained a discriminative model on the pro- vided unlabeled data to predict the domain of each sentence based on POS n - grams in the sentence .", "label": "", "metadata": {}, "score": "51.886497"}
{"text": "For example , our clus- tering algorithm grouped first names in one group and measurements in another .We then added the cluster membership as a lexical feature to the parser .None of the resulting features helped adaptation .3.2Diversity Training diversity may be an effective source for adaptation .", "label": "", "metadata": {}, "score": "51.941124"}
{"text": "Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .", "label": "", "metadata": {}, "score": "52.043224"}
{"text": "Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .", "label": "", "metadata": {}, "score": "52.043224"}
{"text": "Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .", "label": "", "metadata": {}, "score": "52.043224"}
{"text": "First , we trained the tagger on i2b2 corpus and tested it on MCR corpus and vice versa .We then performed 5-fold cross validation experiments on MCR , i2b2 and the combined ( i2b2 + MCR ) corpora .", "label": "", "metadata": {}, "score": "52.173965"}
{"text": "Our experiments confirmed that we succeeded in acquiring highly reliable predicate - argument structures on a large scale .proposed an ensemble method ( Reichart and Rappoport , 2007 ) .They regarded parses as being of high quality if 20 different parsers agreed .", "label": "", "metadata": {}, "score": "52.289406"}
{"text": "with high levels of accuracy . E. Brill .Transformation - based error - driven learning . and .natural language processing : A case study in part of speech tagging .Computational Linguistics , 21(4):543 - 566 , December 1995 .", "label": "", "metadata": {}, "score": "52.327034"}
{"text": "The MCR annotations were restricted strictly to the UMLS .Consequently , these annotations can be expected to inherit the limitations of UMLS which includes lack of concept coverage .This would possibly be the reason why the taggers trained on MCR corpus and tested on i2b2 corpus showed greater degradation in performance than vice - versa .", "label": "", "metadata": {}, "score": "52.367226"}
{"text": "Brants ( 2000 ) reports 96.7 % token accuracy and 85.5 % unknown word accuracy on a 10-fold cross - validation of the Penn WSJ corpus .The distributed GENiA tagger is trained on a mixed training corpus and gets 96.94 % on WSJ , and 98.26 % on GENiA biomedical English .", "label": "", "metadata": {}, "score": "52.412903"}
{"text": "Haug P , Koehler S , Lau LM , Wang P , Rocha R , Huff S : A natural language understanding system combining syntactic and semantic techniques .Proc Annu Symp Comput Appl Med Care 1994 , 247 - 251 .", "label": "", "metadata": {}, "score": "52.632717"}
{"text": "When the MCR subset size crosses a threshold , the improvement in recall can not surpass the degradation in precision , which lowers the F1-score .This result leads to a hypothesis that pooling with a compatible corpus from another institution may be beneficial and an economically favorable alternative to extending the in - house annotated corpus , only when the in - house corpus is below a critical size .", "label": "", "metadata": {}, "score": "52.67747"}
{"text": "The tagger performance with the curated i2b2 corpus was greater than with the original corpus for all subsets of MCR corpus .The simple approach of automated annotation , described earlier increased the threshold of the MCR subset size where the F1-score dips on pooling .", "label": "", "metadata": {}, "score": "52.70597"}
{"text": "Ohta T , Kim J - D , Pyysalo S , Wang Y , Tsujii J : Incorporating GENETAG - style annotation to GENIA corpus .In Workshop on current trends in biomedical natural language processing .Stroudsburg , PA , USA : Association for Computational Linguistics ; 2009:106 - 107 .", "label": "", "metadata": {}, "score": "52.84705"}
{"text": "When normalization is not possible to any ontology node , the phrase should be marked as a ' novel ' concept .For developing machine learning applications it is critical that all the phrases that map to the concept of interest are annotated , by ensuring that even those which are not covered in the reference ontology are marked up .", "label": "", "metadata": {}, "score": "53.02588"}
{"text": "Yarowsky reports that the system correctly classifies senses 96 % of the time .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .", "label": "", "metadata": {}, "score": "53.20037"}
{"text": "Conclusion .There 's certainly more you can do for part - of - speech tagging with nltk & python , but the brill tagger based b raubt_tagger should be good enough for many purposes .The most important component of part - of - speech tagging is using the correct training data .", "label": "", "metadata": {}, "score": "53.251602"}
{"text": "Addition of more reports to MCR corpus might lead to improved performance for MCR .For the ' overlap spans ' , the F1-scores were 0.82 for MCR and 0.89 for i2b2 .The performance patterns were similar for recall and precision for the exact and overlap span evaluations .", "label": "", "metadata": {}, "score": "53.32733"}
{"text": "This paper outlines our participation in the 2007 CoNLL Shared Task on Domain Adaptation ( Nivre et al . , 2007 ) .The goal was to adapt a parser trained on a single source domain to a new target domain us- ing only unlabeled data .", "label": "", "metadata": {}, "score": "53.36319"}
{"text": "I 'm working on a class project and this article series saved me a lot of time and trouble .It 's much more accessible than the NLTK documentation , which I now only had to use to understand some specific details .", "label": "", "metadata": {}, "score": "53.75979"}
{"text": "Supervised machine learning taggers that achieve an accuracy of more than 80 % have been developed [ 8 , 9 ] , given their great success for general English text [ 10 ] and biomedical literature [ 11 - 13 ] .", "label": "", "metadata": {}, "score": "53.78528"}
{"text": "We hope that our study will be a useful guide for facilitating reuse of annotated corpora across institutions .Pooling Biomedical Corpora .There have been similar efforts to pool corpora in the biomedical domain .Johnson et al .[ 18 ] semi - automatically changed the format of the Protein Design Group corpus into two new formats ( WordFreak and embedded XML ) , without altering the semantics , to increase the usage of the corpus .", "label": "", "metadata": {}, "score": "53.945312"}
{"text": "Our suspicions are supported by the observation that no team was able to im- prove target domain performance substan- tially over a state of the art baseline . 1 Introduction Dependency parsing , an important NLP task , can be done with high levels of accuracy .", "label": "", "metadata": {}, "score": "54.07539"}
{"text": "Results suggest that the corpora are incompatible for simple pooling .In an earlier study we had reported performance gain for machine learning taggers by pooling corpora across institutions and report types [ 17 ] .The corpora used in that study were subsets of the i2b2 corpus and were annotated with the same guideline .", "label": "", "metadata": {}, "score": "54.181984"}
{"text": "When trained on GENIA GSC and tested on PennBioIE GSC , the F - score of the combined system dropped to 82.1 % for noun phrases and 91.9 % for verb phrases .Since this performance is considerably lower than that of the combined system based on all chunkers , we did not further pursue the use of an SSC based on the three trainable chunkers only .", "label": "", "metadata": {}, "score": "54.270935"}
{"text": "Our results suggest that the time and effort spent in creating a GSC of sufficient size may be much reduced .Whether the approach is applicable to other systems in a natural - language processing pipeline has to be further investigated .", "label": "", "metadata": {}, "score": "54.480484"}
{"text": "Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Computer Recognition of English Word Senses , Amsterdam : North - Holland .Word sense disambiguation using conceptual density .", "label": "", "metadata": {}, "score": "54.49724"}
{"text": "Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Computer Recognition of English Word Senses , Amsterdam : North - Holland .Word sense disambiguation using conceptual density .", "label": "", "metadata": {}, "score": "54.49724"}
{"text": "Clearly , the improvement is largest for small sizes of the GSC , leveling off with increasing size .The performance obtained with a small set of GSC abstracts combined with an SSC is comparable to a larger GSC set without SSC .", "label": "", "metadata": {}, "score": "54.52495"}
{"text": "To address conflicting annota-1053 .Page 4 . tions , we added slack variables to the MIRA learn- ing algorithm ( Crammer et al . , 2006 ) used to train the parsers , without success .We measured diversity by comparing the parses of each model .", "label": "", "metadata": {}, "score": "54.68501"}
{"text": "[20 ] pooled these corpora ( and a third known as AIMED ) [ 21 ] hoping to achieve better performance using the large corpus .However , the performance dropped by 12 % .Subsequently they analyzed incompatibilities among the corpora .", "label": "", "metadata": {}, "score": "54.69069"}
{"text": "The distributed GENiA tagger is trained on a mixed training corpus and gets 96.94 % on WSJ , and 98.26 % on GENiA biomedical English .Manning , Christopher D. 2011 .Part - of - Speech Tagging from 97 % to 100 % : Is It Time for Some Linguistics ?", "label": "", "metadata": {}, "score": "54.737503"}
{"text": "The distributed GENiA tagger is trained on a mixed training corpus and gets 96.94 % on WSJ , and 98.26 % on GENiA biomedical English .Manning , Christopher D. 2011 .Part - of - Speech Tagging from 97 % to 100 % : Is It Time for Some Linguistics ?", "label": "", "metadata": {}, "score": "54.737503"}
{"text": "The above experiment was repeated 10 times , each time starting with a different randomly selected subset of 10 abstracts .The reported results are the averaged F - scores of the 10 experiments .Performance evaluation .The chunker and silver standard annotations were compared with the gold standard annotations by exact matching , similar to the procedure followed in CoNLL-2000 [ 15 ] .", "label": "", "metadata": {}, "score": "54.942986"}
{"text": "While we believe this is not enough diversity , it was not feasible to repeat our experiment with a large number of parsers . 3.3Another approach to adaptation is to favor training examples that are similar to the target .We first mod- ified the weight given by the parser to each training sentence based on the similarity of the sentence to target domain sentences .", "label": "", "metadata": {}, "score": "54.96566"}
{"text": "In Proceedings of COLING'96 and LDOCE J. Guthrie , L. Guthrie , Y. Wilks and H. Aidinejad , Subject - Dependent Co - Occurrence and Word Sense Disambiguation , ACL-91 , pp .146 - 152 .The information in these resources has been used in several ways , for example Wilks and Stevenson Y. Wilks and M. Stevenson .", "label": "", "metadata": {}, "score": "54.968185"}
{"text": "Thus , within a longitudinal patient record , one expects to observe heavy redundancy .In this paper , we ask three research questions : ( i ) How can redundancy be quantified in large - scale text corpora ?( ii )", "label": "", "metadata": {}, "score": "55.04938"}
{"text": "The results show that an unsupervised technique based on topic models is effective - it outperforms random data selection on both languages examined , English and Dutch .Moreover , the technique works better than manually assigned labels gathered from meta - data that is available for English . ...", "label": "", "metadata": {}, "score": "55.205414"}
{"text": "English .Penn Treebank Wall Street Journal ( WSJ ) release 3 ( LDC99T42 ) .The splits of data for this task were not standardized early on ( unlike for parsing ) and early work uses various data splits defined by counts of tokens or by sections .", "label": "", "metadata": {}, "score": "55.36703"}
{"text": "The availability of annotated corpora has facilitated the application of machine learning algorithms to concept extraction from clinical notes .However , high expenditure and labor are required for creating the annotations .A potential alternative is to reuse existing corpora from other institutions by pooling with local corpora , for training machine taggers .", "label": "", "metadata": {}, "score": "55.36773"}
{"text": "A phrase annotated by the gold standard was counted as false negative if the system did not render it exactly ; a phrase annotated by a system was counted as false positive if it did not exactly match the gold standard .", "label": "", "metadata": {}, "score": "55.385025"}
{"text": "So make sure you choose your training data carefully .If you 'd like to try to push NLTK part of speech tagging accuracy even higher , see part 4 , where I compare the brill tagger to classifier based pos taggers , and nltk.tag.pos_tag .", "label": "", "metadata": {}, "score": "55.48964"}
{"text": "Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 9 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .", "label": "", "metadata": {}, "score": "55.522644"}
{"text": "Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 9 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .", "label": "", "metadata": {}, "score": "55.522644"}
{"text": "This design was repeated for the i2b2 corpus by using MCR corpus to supplement the training .The cross - validation experiments were repeated three times to average the performance scores , i.e. 3 times 5-fold cross - validation was performed .", "label": "", "metadata": {}, "score": "55.72979"}
{"text": "What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 10 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .", "label": "", "metadata": {}, "score": "55.861153"}
{"text": "What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 10 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .", "label": "", "metadata": {}, "score": "55.861153"}
{"text": "To reduce the effect of insignificant differences between chunks , words from the stopwords list in PubMed [ 16 ] and punctuation remarks were removed before matching if they appeared at the start or the end of a phrase .Results .", "label": "", "metadata": {}, "score": "55.93781"}
{"text": "first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .The resolution of a word 's syntactic ambiguity has largely been solved . in .language processing by part - of - speech taggers which predict .", "label": "", "metadata": {}, "score": "56.161762"}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "56.28943"}
{"text": "In the second submission , also a constituency parsing system , the n - best lists of various parsing models are combined using an approximate sentence - level product model .The third system , the highest ranked system in the dependency parsing track , uses voting over dependency arcs to combine the output of three constituency parsing systems which have been converted to dependency trees .", "label": "", "metadata": {}, "score": "56.38577"}
{"text": "A group of human annotators then independently follow the guideline to carry out the annotation exercise .Researchers developing a machine learning tagger at an institute have the option of training the tagger on i ) the in - house set of reports that have been manually annotated , ii ) reports annotated at another institution or iii ) a pooled set constructed by combining i and ii .", "label": "", "metadata": {}, "score": "56.4588"}
{"text": "Also the corpora sizes are different from the ones examined in the earlier study .Hence we investigated the effect of differences in the annotation guidelines , distributions of report types and corpora sizes , on the performance of taggers trained on pooled corpora , as described in the following sub - sections .", "label": "", "metadata": {}, "score": "56.67806"}
{"text": "In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .This takes a small number of seed definitions of the senses of some word ( the seeds could be WordNet synsets or definitions from some lexicon ) and uses these to classify the \" obvious \" cases in a corpus .", "label": "", "metadata": {}, "score": "56.755924"}
{"text": "First , there may be room for adaptation with our domains if a common annotation scheme is used .Second , we have stressed that typical adaptation , modifying a model trained on the source domain , will fail but there may be unsupervised parsing techniques that improve performance after adaptation , such as a rule based NP parser for BIO based on knowledge of the annotations .", "label": "", "metadata": {}, "score": "56.78849"}
{"text": "The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .To appear in Journal of Natural Language Engineering , 4(3 ) .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .", "label": "", "metadata": {}, "score": "56.8396"}
{"text": "The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .To appear in Journal of Natural Language Engineering , 4(3 ) .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .", "label": "", "metadata": {}, "score": "56.8396"}
{"text": "Ohta et al .[19 ] extended the annotation of their GENIA corpus to integrate the annotation style of the GENTAG corpus , which is the other prominent and widely used biomedical corpus , so that their corpus can been pooled with others following the same format .", "label": "", "metadata": {}, "score": "56.896946"}
{"text": "The performance of taggers trained and tested on MCR corpus increases in F1-score and recall as the corpus size increases .The increase is rapid at first with increment in the corpus size , but later forms a plateau .", "label": "", "metadata": {}, "score": "57.001343"}
{"text": "Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .", "label": "", "metadata": {}, "score": "57.086777"}
{"text": "Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .", "label": "", "metadata": {}, "score": "57.086777"}
{"text": "The annotation groups involved in clinical research should come together to develop a standard annotation guideline that facilitates reuse of annotation efforts .We also suggest a two - pass annotation method that focuses first on concept recognition , followed by normalization to existing ontologies , to facilitate the pooling of corpora .", "label": "", "metadata": {}, "score": "57.1744"}
{"text": "Further experiments showed that any decrease in training data hurt parser perfor- mance .It would seem that the parser has no dif- ficulty learning important training sentences in the presence of unimportant training examples .A related idea focused on words , weighing highly tokens that appeared frequently in the target domain .", "label": "", "metadata": {}, "score": "57.25123"}
{"text": "These methods require labeled examples of syntactic structures to learn statistical patterns governing these structures .Labeled data typically requires expert annotators which makes it both time consuming and costly to produce .Furthermo ... \" .Current efforts in syntactic parsing are largely data - driven .", "label": "", "metadata": {}, "score": "57.33405"}
{"text": "PubMed View Article .Banko M , Brill E : Mitigating the paucity - of - data problem : exploring the effect of training corpus size on classifier performance for natural language processing .Proceedings of the First International Conference on Human Language Technology Research ; San Diego 2001 , 1 - 5 .", "label": "", "metadata": {}, "score": "57.45172"}
{"text": "Pooling with the i2b2 corpus nearly always increases the recall .However as the precision always degrades on pooling , the F1-score first increases with pooling and then degrades .A possible explanation is that the smaller subsets of MCR corpus are deficient in all the annotation patterns , and when these are supplemented by the i2b2 curated corpus , there is an improvement in recall .", "label": "", "metadata": {}, "score": "57.596664"}
{"text": "aFor text mining , preprocessing the EHR corpus with fingerprinting yields significantly better results .Conclusions Before applying text - mining techniques , one must pay careful attention to the structure of the analyzed corpora .While the importance of data cleaning has been known for low - level text characteristics ( e.g. , encoding and spelling ) , high - level and difficult - to - quantify corpus characteristics , such as naturally occurring redundancy , can also hurt text mining .", "label": "", "metadata": {}, "score": "57.61887"}
{"text": "The second pass of ' normalization ' will facilitate the filtering / sub - classing of annotations for developing machine learning taggers for a particular sub - class .This two - pass annotation method will facilitate the pooling of corpus with other similar corpora .", "label": "", "metadata": {}, "score": "57.786"}
{"text": "Sentence splitting , tokenization , and part - of - speech tagging were included in our chunking pipeline , either as integral part of the chunkers ( Yamcha , Lingpipe ) or as separate components ( OpenNLP ) .We used the gold - standard sentence , token , and part - of - speech annotations for training , but did not use this information in creating the SSC or evaluating the trained models : the input of the annotation pipeline consisted of plain abstracts , the output were chunking annotations .", "label": "", "metadata": {}, "score": "57.80755"}
{"text": "In Conference on Natural Language Learning ( CoNLL ) .J. Nivre , J. Hall , S. K\u00a8 ubler , R. McDonald , J. Nils- son , S. Riedel , and D. Yuret .2007 shared task on dependency parsing . of the CoNLL 2007 Shared Task .", "label": "", "metadata": {}, "score": "57.82148"}
{"text": "Performance of the taggers was poor when they were trained exclusively on reports from the other corpora .For tagger trained on i2b2 and tested on MCR , the F1 score was 0.38 for exact spans .Similarly for tagger trained on MCR and tested on i2b2 , the scores was 0.40 .", "label": "", "metadata": {}, "score": "57.89016"}
{"text": "Our error analysis for this task suggests that a primary source of error is differences in annotation guidelines between treebanks .Our suspicions are supported by the observation that no team was able to improve target domain performance substantially over a state of the art baseline .", "label": "", "metadata": {}, "score": "57.8993"}
{"text": "For the most common 1While only 8 teams participated in the closed track with us , our score beat all of the teams in the open track .Page 2 .The parser was trained on the provided WSJ data .Digits are less than 4 % of the tokens in BIO .", "label": "", "metadata": {}, "score": "58.02478"}
{"text": "For instance the history and examination reports will have a high density of patient symptoms as compared to the progress notes that will mainly refer to the symptoms addressed by the current treatment .Also the progress notes will perhaps contain more medical terminology instead of ordinary English words reported by the patient in the history and examination reports .", "label": "", "metadata": {}, "score": "58.10968"}
{"text": "These days WordNet is the usual dictionary in question .WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .", "label": "", "metadata": {}, "score": "58.16734"}
{"text": "Practically useful machine taggers can be possibly developed by annotating a small local corpus , and pooling it with a large similar corpus , available for reuse from another institution .The benefits of pooling diminish as more local annotations are created .", "label": "", "metadata": {}, "score": "58.662975"}
{"text": "It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .", "label": "", "metadata": {}, "score": "58.682915"}
{"text": "It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .", "label": "", "metadata": {}, "score": "58.682915"}
{"text": "Performance ( F - score ) of chunkers and their combination trained on subsets of different size of the GENIA GSC and on the GSC subset supplemented with an SSC , for noun - phrase and verb - phrase recognition .Discussion .", "label": "", "metadata": {}, "score": "58.69048"}
{"text": "One way of leveraging existing efforts is to pool annotated corpora across institutions .Pooling of the annotations to train machine learning taggers may increase performance of the taggers [ 17 ] .However there has been little research on associated issues .", "label": "", "metadata": {}, "score": "59.00619"}
{"text": "We investigated whether pooling of corpora from two different sources , can improve performance and portability of resultant machine learning taggers .The effect of pooling local and foreign corpora , is dependent on several factors that include compatibility of annotation guidelines , distribution of report types and corpus size .", "label": "", "metadata": {}, "score": "59.01142"}
{"text": "1975 . . .Computer Recognition of English Word Senses , Amsterdam : North - Holland . published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .", "label": "", "metadata": {}, "score": "59.071316"}
{"text": "In each plot the colors of the horizontal lines correspond to the corpus used in the cross - validation experiment , viz .MCR , MCR + i2b2 ( MCR with training fraction supplemented by i2b2 ) and MCR + i2b2C ( MCR with training fraction supplemented by curated i2b2 ) .", "label": "", "metadata": {}, "score": "59.208084"}
{"text": "In all our experiments , we used a voting threshold of three out of five chunkers for noun phrases , and a threshold of two out of four for verb phrases ( GATE only generates noun phrases ) .These thresholds gave uniformly the best results in terms of F - score when the silver standard annotations of the training data were evaluated against the gold standard .", "label": "", "metadata": {}, "score": "59.21826"}
{"text": "Current statistical parsers tend to perform well only on their training domain and nearby genres .While strong performance on a few related domains is sufficient for many situations , it is advantageous for parsers to be able to generalize to a wide variety of domains .", "label": "", "metadata": {}, "score": "59.22474"}
{"text": "Current statistical parsers tend to perform well only on their training domain and nearby genres .While strong performance on a few related domains is sufficient for many situations , it is advantageous for parsers to be able to generalize to a wide variety of domains .", "label": "", "metadata": {}, "score": "59.22474"}
{"text": "Lawrence Erlbaum .M. Marcus , B. Santorini , and M. Marcinkiewicz .Building a large annotated corpus of English : the Penn Treebank .Computational Linguistics , 19(2):313 - 330 .Ryan McDonald , Kevin Lerman , and Fernando Pereira .", "label": "", "metadata": {}, "score": "59.320446"}
{"text": "By removing stopwords before matching we tried to remove \" uninformative \" words that should not play a role in determining whether phrases are the same , similar to other studies ( e.g. , [ 19 , 20 ] ) .Stopword removal can be seen as a relaxation of the strict matching requirement .", "label": "", "metadata": {}, "score": "59.381165"}
{"text": "This paper revisits an assump - tion that genre variation is continuous along multiple dimensions , and an early use of principal component analysis to find these dimensions .Results on a very heterogeneous corpus of post-1990s American English reveal four major dimensions , three of which echo those found in prior work and the fourth depending on features not used in the earlier study .", "label": "", "metadata": {}, "score": "59.526943"}
{"text": "Performance ( F - score ) of chunkers and their combination when trained for noun - phrase and verb - phrase recognition on different training sets .Silver standard as supplement of gold standard .Table 2 shows the performances of chunkers and the combined system when trained on GSCs of varying sizes and on the GSCs supplemented with an SSC .", "label": "", "metadata": {}, "score": "59.588764"}
{"text": "Performance measure : per token accuracy .( The convention is for this to be measured on all tokens , including punctuation tokens and other unambiguous tokens . )English .Penn Treebank Wall Street Journal ( WSJ ) release 3 ( LDC99T42 ) .", "label": "", "metadata": {}, "score": "59.600132"}
{"text": "Performance measure : per token accuracy .( The convention is for this to be measured on all tokens , including punctuation tokens and other unambiguous tokens . )English .Penn Treebank Wall Street Journal ( WSJ ) release 3 ( LDC99T42 ) .", "label": "", "metadata": {}, "score": "59.600132"}
{"text": "However the reports in either corpus did not have meta - data about the type of report .Hence , the authors could not investigate the ' report - type ' factor further .Corpus size .To examine the effect of size , we measured the tagger performance on subsets of MCR corpus of various sizes , by performing 5 fold cross - validation experiments .", "label": "", "metadata": {}, "score": "59.6352"}
{"text": "After the i2b2 corpus was curated to partially rectify the annotation differences , there was an improvement in the overlap of the corpora , as shown in Table 2 .Each cell in the table gives the percentage of annotations that matched with the other corpus before and after automated curation of the i2b2 corpus to partially rectify the annotation differences .", "label": "", "metadata": {}, "score": "59.650833"}
{"text": "For example , training the chunkers on a GSC consisting of only 10 abstracts but supplemented with an SSC yielded similar performance as training them on a GSC of 100 - 250 abstracts .The combined system even performed better than any of the individual chunkers trained on a GSC of 500 abstracts .", "label": "", "metadata": {}, "score": "59.81838"}
{"text": "In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .", "label": "", "metadata": {}, "score": "60.2671"}
{"text": "In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .", "label": "", "metadata": {}, "score": "60.2671"}
{"text": "Human Language Technology conference / North American Chapter of the Association for Computational Linguistics Annual Meeting ; Boston 2004 , 61 - 68 .Ferrucci D , Lally A : UIMA : an architectural approach to unstructured information processing in the corporate research environment .", "label": "", "metadata": {}, "score": "60.27828"}
{"text": "We conclude that an SSC can be a viable alternative for or a supplement to a GSC when training chunkers in a biomedical domain .A combined system only shows improvement if the SSC is used to supplement a GSC .Whether the approach is applicable to other systems in a natural - language processing pipeline has to be further investigated .", "label": "", "metadata": {}, "score": "60.32789"}
{"text": "Since annotation diversity is generally considered a key factor for the improvement seen by ensemble systems ( 4 ) , it may be expected that the combined chunker system shows a smaller increase of performance when based on the SSC than on the GSCs .", "label": "", "metadata": {}, "score": "60.353127"}
{"text": "Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .", "label": "", "metadata": {}, "score": "60.474785"}
{"text": "In this study we investigate an alternative , automatic approach to create an annotated corpus .We have shown before that a system combining the outputs of various chunkers performs better than each of the individual chunkers .Here we postulate that the annotations of such a combined system on a given corpus can be taken as a reference standard , establishing a \" silver standard corpus \" ( SSC ) .", "label": "", "metadata": {}, "score": "60.548725"}
{"text": "These works aim to predict the parser performance on a given target sentence .Ravi et al .( 2008 ) frame this as a regression problem .Kawahara and Uchimoto ( 2008 ) treat ... . \" ...Genre classification has been found to improve performance in many applications of statistical NLP , including language modeling for spoken language , domain adaptation of statistical parsers , and machine translation .", "label": "", "metadata": {}, "score": "60.593697"}
{"text": "Report type .In addition to the differences in the annotation guidelines , the performance of the taggers could be affected by the distribution of report types in the corpora .i2b2 corpus included discharge summaries and progress notes , while MCR corpus had a wider variety , since the reports were randomly selected from the EMR system for annotation .", "label": "", "metadata": {}, "score": "60.719887"}
{"text": "NLTK Brill Tagger Accuracy .So now we have a braubt_tagger .You can tweak the max_rules and min_score params , but be careful , as increasing the values will exponentially increase the training time without significantly increasing accuracy .In fact , I found that increasing the min_score tended to decrease the accuracy by a percent or 2 .", "label": "", "metadata": {}, "score": "60.740944"}
{"text": "We began with the first ap- proach and removed a large number of features that we believed transfered poorly , such as most features for noun - noun edges .We obtained a small improve- ment in BIO performance on limited data only .", "label": "", "metadata": {}, "score": "60.916985"}
{"text": "We used the UMLS MetaThesaurus [29 ] and a collection of words used in a clinical vocabulary viewer [ 30 ] as the domain dictionary .The input text and dictionary were normalized to facilitate flexible matching .The dictionary lookup tagged all phrase occurrences , including overlapping phrases .", "label": "", "metadata": {}, "score": "61.029907"}
{"text": "We selected with replacement 2000 training examples from the training data and trained three parsers .Each parser then tagged the remain- ing 13 K sentences , yielding 39 K parsed sentences .We then shuffled these sentences and trained a final parser .", "label": "", "metadata": {}, "score": "61.250862"}
{"text": "Electronic supplementary material .The online version of this article ( doi : 10 .1186/\u200b2041 - 1480 - 4 - 3 ) contains supplementary material , which is available to authorized users .Background .Development of Natural Language Processing ( NLP ) tools generally requires a set of annotated documents in the application domain [ 1 ] .", "label": "", "metadata": {}, "score": "61.294563"}
{"text": "The increase in F - scores varies between 1.7 and 3.1 percentage points for noun phrases and between 1.0 and 3.3 percentage points for verb phrases .Although performance further increases when training on PennBioIE GSC instead of PennBioIE SSC , differences are not large : 0.2 to 0.8 percentage point for noun phrases , 0.3 to 1.7 percentage point for verb phrases .", "label": "", "metadata": {}, "score": "61.307217"}
{"text": "Another example is the work of Pedersen [ 11 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .", "label": "", "metadata": {}, "score": "61.31021"}
{"text": "Another example is the work of Pedersen [ 11 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .", "label": "", "metadata": {}, "score": "61.31021"}
{"text": "Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , Segond , F. , Schiller , A. , Grefenstette , G. , and Chanod , J. ( 1997 ) .An experiment in semantic tagging using hidden markov model tagging .", "label": "", "metadata": {}, "score": "61.36711"}
{"text": "A good example of this is Luk 's system A. Luk .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .", "label": "", "metadata": {}, "score": "61.62786"}
{"text": "Yarowsky D , Florian R : Evaluating sense disambiguation across diverse parameter spaces .Nat Lang Eng 2002 , 8 : 293 - 310 .View Article .Surdeanu M , Turmo J , Comelles E : Named entity recognition from spontaneous open - domain speech .", "label": "", "metadata": {}, "score": "61.735294"}
{"text": "Kang N , van Mulligen EM , Kors JA : Comparing and combining chunkers of biomedical text .J Biomed Inform 2011 , 44 : 354 - 360 .PubMed View Article .Rebholz - Schuhmann D , Yepes AJ , van Mulligen EM , Kang N , Kors J , Milward D , Corbett P , Hahn U : The CALBC silver standard corpus - harmonizing multiple semantic annotations in a large biomedical corpus .", "label": "", "metadata": {}, "score": "61.902946"}
{"text": "However , most previous work on domain adaptation relied on the implicit assumption that domains are somehow given .As more and more data becomes available , automatic ways to select data that is beneficial for a new ( unknown ) target domain are becoming attractive .", "label": "", "metadata": {}, "score": "62.03382"}
{"text": "We suggest that future initiatives for clinical annotations should consider guideline factors delineated in this paper for development of the annotation guidelines , so that their annotation effort can be utilized by others .Moreover the guidelines should also include instructions to annotate metadata about the reports , so that reports of the same type from different corpora can be readily pooled for enhancing machine learning based taggers .", "label": "", "metadata": {}, "score": "62.24444"}
{"text": "View Article .Sang E , Buchholz S : Introduction to the CoNLL-2000 shared task : chunking .Proceedings of CoNLL-2000 and LLL-2000 ; Lisbon 2000 , 127 - 132 .Littlestone N , Warmuth MK : The weighted majority algorithm .", "label": "", "metadata": {}, "score": "62.650944"}
{"text": "Friedman C , Liu H , Shagina L : A vocabulary development and visualization tool based on natural language processing and the mining of textual patient reports .J Biomed Inform 2003 , 36 ( 3 ) : 189 - 201 .", "label": "", "metadata": {}, "score": "62.690216"}
{"text": "The effect of distribution of report types could not be studied as the corpora were not annotated for report type .The effect of pooling was found to depend on the corpus size , as pooling was found to improve tagger performance for smaller subsets of the MCR corpus .", "label": "", "metadata": {}, "score": "62.701256"}
{"text": "Recently , Huang et al .[ 23 ] have reported significant performance improvement of machine learning based part - of - speech ( POS ) taggers , by training them on pooled dataset .Our current effort can potentially benefit research on development of clinical taggers at healthcare institutions , by facilitating use of annotated corpora from other institutions .", "label": "", "metadata": {}, "score": "62.83921"}
{"text": "Labeled data typically requires expert annotators which makes it both time consuming and costly to produce .Furthermore , once training data has been created for one textual domain , portability to similar domains is limited .This domain - dependence has inspired a large body of work since syntactic parsing aims to capture syntactic patterns across an entire language rather than just a specific domain .", "label": "", "metadata": {}, "score": "62.85974"}
{"text": "Adaptation techniques focus on the former since it is impossible to determine the lat- ter without knowledge of the labeling function .In parsing adaptation , the former corresponds to a dif- ference between the features seen in each domain , such as new words in the target domain .", "label": "", "metadata": {}, "score": "62.965687"}
{"text": "Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .", "label": "", "metadata": {}, "score": "62.985542"}
{"text": "The i2b2 guidelines specify that one prepositional phrase following a concept can be included in the annotation if it does not contain a markable concept and / either indicates an organ / body part .Also a preposition can be included in a concept phrase if words therein can be rearranged to express the same concept without the preposition .", "label": "", "metadata": {}, "score": "63.069294"}
{"text": "It should be noted that unsupervised disambiguation can not actually label specific terms as a referring to a specific concept : that would require more information than is available .What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .", "label": "", "metadata": {}, "score": "63.080894"}
{"text": "Text - mining methods in particular can help disease modeling by mapping named - entities mentions to terminologies and clustering semantically related terms .EHR corpora , however , exhibit specific statistical and linguistic characteristics when compared with corpora in the biomedical literature domain .", "label": "", "metadata": {}, "score": "63.21969"}
{"text": "( 2006 ) , which achieved top results in the 2006 We were given around CoNLL - X shared task .Preliminary experiments in- dicated that the edge labeler was fairly robust to do- main adaptation , lowering accuracy by 3 % in the de- velopment domain as opposed to 2 % in the source , so we focused on unlabeled dependency parsing .", "label": "", "metadata": {}, "score": "63.385216"}
{"text": "Table 1 shows the performance of the three trainable chunkers and the combined system on the PennBioIE GSC when trained on three different corpora : GENIA GSC , PennBioIE SSC , or PennBioIE GSC .GATE and MetaMap could not be trained and when tested on the PennBioIE GSC had F - scores of 78.2 % ( MetaMap ) and 72.8 % ( GATE ) for noun phrases , and 77.7 % ( MetaMap ) for verb phrases .", "label": "", "metadata": {}, "score": "63.390205"}
{"text": "Count all the correct tags along with the total tags , then when it 's finished you can calculate precision . bullaggan .hi jacob , how we can find precision , recall and f , measure by using brill tagger , as brill 's only displaying accuracy.and if we look at precision , its formula is : . of words tagged by taggers .", "label": "", "metadata": {}, "score": "63.523434"}
{"text": "These were annotated for signs / symptoms , disorders , medications and procedures .The annotation class ' problem ' from the first corpus was equivalent to the combination of classes -- signs / symptoms and disorders in the second corpus and we carried out experiments with reference to this class . MedTagger .", "label": "", "metadata": {}, "score": "63.57322"}
{"text": "A possible explanation for this phenomenon is that the SSC incorporates results from the chunkers that are subsequently trained on it .As a consequence , the diversity of the chunkers trained on the SSC may be less than those trained on the GSCs .", "label": "", "metadata": {}, "score": "63.60988"}
{"text": "In ' exact span ' matching , the annotations were counted as matches if begin and end spans matched .In case of ' overlap span ' evaluation the annotations were counted as matches , if there was any overlap in the span ranges .", "label": "", "metadata": {}, "score": "63.723682"}
{"text": "Chowdhury MFM , Lavelli A : Assessing the practical usability of an automatically annotated corpus .Proceedings of the Fifth Linguistic Annotation Workshop ; Portland 2011 , 101 - 109 .Cunningham H : GATE , a general architecture for text engineering .", "label": "", "metadata": {}, "score": "63.742714"}
{"text": "Table 2 shows the overlap in the annotated phrases in the two corpora .Before rectification of the annotation differences , 42.9 % of MCR annotations exactly matched i2b2 annotations , i.e. from the 2,076 concept annotations in MCR , there were 890 annotations that exactly matched with an i2b2 annotation .", "label": "", "metadata": {}, "score": "63.7501"}
{"text": "The additional runs were required to compensate for the increase in variation , so as to provide adequate confidence of the accuracy measurements .The results are summarized in Figure 4 and tabulated in the Additional file 1 .The plots A , B and C show the F1-score , precision and recall of the taggers respectively .", "label": "", "metadata": {}, "score": "63.751663"}
{"text": "Results .Figure 1 summarizes the results of the experiments .Detailed results are tabulated in the Additional file 1 .Performance measures of the taggers .The plots A , B and C show the F1-score , precision and recall respectively .", "label": "", "metadata": {}, "score": "63.869324"}
{"text": "WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .", "label": "", "metadata": {}, "score": "63.940613"}
{"text": "However , in the clinical domain , annotated corpora are often difficult to develop due to high cost of manual annotation involving domain experts and medical practitioners , and also due to concerns for patient confidentiality [ 2 ] .Due to high demand , such corpora have been recently created with pioneering effort of some research groups and made available to the scientific community to support studies in clinical NLP [ 3 - 5 ] .", "label": "", "metadata": {}, "score": "63.966408"}
{"text": "Our er- ror analysis suggests that the primary cause of loss from adaptation is from differences in the annotation guidelines themselves .Therefore , significant im- provements can not be made without specific knowl- edgeofthetargetdomain'sannotationstandards .No amount of source training data can help if no rele- vant structure exists in the data .", "label": "", "metadata": {}, "score": "64.04378"}
{"text": "Decision lists [ 14 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .", "label": "", "metadata": {}, "score": "64.0865"}
{"text": "Decision lists [ 14 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .", "label": "", "metadata": {}, "score": "64.0865"}
{"text": "Creation of the silver standard .We used a simple voting scheme to generate silver standard annotations from the annotations produced by the different chunkers .For each phrase identified by a chunker , the number of chunkers that gave exactly matching annotations was counted .", "label": "", "metadata": {}, "score": "64.24213"}
{"text": "WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .These days [ [ WordNet ] ] is the usual dictionary in question .", "label": "", "metadata": {}, "score": "64.318985"}
{"text": "Most work from 2002 on adopts the following data splits , introduced by Collins ( 2002 ) : .French .French TreeBank ( FTB , Abeill\u00e9 et al ; 2003 )Le Monde , December 2007 version , 28-tag tagset ( CC tagset , Crabb\u00e9 and Candito , 2008 ) .", "label": "", "metadata": {}, "score": "64.65805"}
{"text": "Most work from 2002 on adopts the following data splits , introduced by Collins ( 2002 ) : .French .French TreeBank ( FTB , Abeill\u00e9 et al ; 2003 )Le Monde , December 2007 version , 28-tag tagset ( CC tagset , Crabb\u00e9 and Candito , 2008 ) .", "label": "", "metadata": {}, "score": "64.65805"}
{"text": "View Article .Wagholikar K , Torii M , Jonnalagadda S , Liu H : Feasibility of pooling annotated corpora for clinical concept extraction .In AMIA summit on clinical research informatics .San Francisco , CA : American Medical Informatics Summits on Translational Science Proceedings ; 2012:63 - 70 .", "label": "", "metadata": {}, "score": "64.66144"}
{"text": "EMNLP 2002 ' ' .\" TALN'11 \" . \"PACLIC 2009 \" .Proceedings of the 4th International Conference on Language Resources and Evaluation ( LREC'04 ) ' ' .Lisbon , Portugal .Part - of - Speech Tagging from 97 % to 100 % : Is It Time for Some Linguistics ?", "label": "", "metadata": {}, "score": "64.688126"}
{"text": "One is that the SSC that we used for training the chunkers was evaluated against the GSC of the same subdomain , whereas in the other study the domains from which the CALBC SSC and the BioCreative GSC are taken , are more divergent .", "label": "", "metadata": {}, "score": "64.82884"}
{"text": "The development data was 200 sentences of labeled biomedical oncology text ( BIO , the ONCO portion of the Penn Biomedical Treebank ) , as well as 200 K unlabeled sentences ( Kulick et al ., 2004 ) .The two test domains were a collection of medline chem- istry abstracts ( pchem , the CYP portion of the Penn Biomedical Treebank ) and the Child Language Data Exchange System corpus ( CHILDES ) ( MacWhin- ney , 2000 ; Brown , 1973 ) .", "label": "", "metadata": {}, "score": "64.937904"}
{"text": "View Article .Fan JW , Prasad R , Yabut RM , Loomis RM , Zisook DS , Mattison JE , Huang Y : Part - of - speech tagging for clinical text : wall or bridge between institutions ?AMIA Annu Symp Proc 2011 , 2011 : 382 - 391 .", "label": "", "metadata": {}, "score": "64.947014"}
{"text": "Our results on the practical value of an SSC are different from those that were recently reported by Chowdhury and Lavelli [ 6 ] .They found a considerable drop in performance of a gene recognition system trained on the CALBC SSC as compared to the system trained on the BioCreative GSC , and also noticed that the system trained on a combination of SSC and GSC performed worse than on the GSC only .", "label": "", "metadata": {}, "score": "65.190186"}
{"text": "References Shai Ben - David , John Blitzer , Koby Crammer , and Fer- nando Pereira .Analysis of representations for domain adaptation .In NIPS .Leo Breiman .Learning , 24(2):123 - 140 .Bagging predictors .Machine R. Brown .", "label": "", "metadata": {}, "score": "65.272705"}
{"text": "At its ... \" .Genre classification has been found to improve performance in many applications of statistical NLP , including language modeling for spoken language , domain adaptation of statistical parsers , and machine translation .It has also been found to benefit retrieval of spoken or written docu - ments .", "label": "", "metadata": {}, "score": "65.317184"}
{"text": "J Am Med Inform Assoc 2009 , 16 ( 2 ) : 247 - 255 .View Article .Tjong Kim Sang EF , De Meulder F : Introduction to the CoNLL-2003 shared task .In Seventh conference on natural language learning .", "label": "", "metadata": {}, "score": "65.32617"}
{"text": "Manning , Christopher D. 2011 .Part - of - Speech Tagging from 97 % to 100 % : Is It Time for Some Linguistics ?In Alexander Gelbukh ( ed . ) , Computational Linguistics and Intelligent Text Processing , 12th International Conference , CICLing 2011 , Proceedings , Part I. Lecture Notes in Computer Science 6608 , pp .", "label": "", "metadata": {}, "score": "65.35599"}
{"text": "Aronson AR , Lang FM : An overview of MetaMap : historical perspective and recent advances .J Am Med Inform Assoc 2010 , 17 ( 3 ) : 229 - 236 .Bakken S , Hyun S , Friedman C , Johnson S : A comparison of semantic categories of the ISO reference terminology models for nursing and the MedLEE natural language processing system .", "label": "", "metadata": {}, "score": "65.48361"}
{"text": "We used GENIA tagger for labeling parts of speech to all input tokens .GENIA tagger [ 31 ] is based on maximum entropy models trained on biomedical text as well as generic English text .Machine learning .Using the dictionary lookup and POS tagging results , we derived a set of features for each token .", "label": "", "metadata": {}, "score": "65.59007"}
{"text": "An experiment in semantic tagging using hidden markov model tagging .In Vossen , P. , Adriaens , G. , Calzolari , N. , Sanfilippo , A. , and Wilks , Y. , editors , Proceedings of the ACL / EACL'97 Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources .", "label": "", "metadata": {}, "score": "65.591545"}
{"text": "An experiment in semantic tagging using hidden markov model tagging .In Vossen , P. , Adriaens , G. , Calzolari , N. , Sanfilippo , A. , and Wilks , Y. , editors , Proceedings of the ACL / EACL'97 Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources .", "label": "", "metadata": {}, "score": "65.591545"}
{"text": "Multiple classifier systems have been applied in many domains , including biomedical text mining and information extraction .For instance , Smith et al .[ 2 ] combined the results of 19 systems for gene mention recognition , and found that the combined system outperformed the best individual system by 3.5 percentage points in terms of F - score .", "label": "", "metadata": {}, "score": "65.64376"}
{"text": "We added features indicating when an edge was predicted by another parser and if an edge crossed a predicted edge , as well as conjunctions with edge types .This failed to improve BIO accuracy since these features were less reliable at test time .", "label": "", "metadata": {}, "score": "65.66116"}
{"text": "This decision effectively removes NNP from the BIO domain and renders all features that depend on the NNP tag ineffective .In our above BIO NP example , all nouns are labeled NN , whereas the WSJ example contains NNP tags .", "label": "", "metadata": {}, "score": "65.72279"}
{"text": "The notion that a combination of systems can be used to create a \" silver standard \" corpus has been explored in the CALBC ( Collaborative Annotation of a Large Biomedical Corpus ) project [ 5 ] .Through CALBC , the natural - language processing community has been invited to annotate a very large biomedical corpus with a variety of named - entity recognition systems .", "label": "", "metadata": {}, "score": "65.748695"}
{"text": "171 - -189 .Springer .Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics ( ACL 2007 ) ' ' , pages 760 - 767 .Semi - supervised condensed nearest neighbor for part - of - speech tagging .", "label": "", "metadata": {}, "score": "65.859146"}
{"text": "171 - -189 .Springer .Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics ( ACL 2007 ) ' ' , pages 760 - 767 .Semi - supervised condensed nearest neighbor for part - of - speech tagging .", "label": "", "metadata": {}, "score": "65.859146"}
{"text": "Nouns are far more The annota- 2We measured these drops on several other dependency parsers and found similar results .ery token is headed by \" Department \" .In contrast , a similar BIO phrase has a very different structure , pursuant to the BIO guidelines .", "label": "", "metadata": {}, "score": "65.86975"}
{"text": "Corpora .Two annotated corpora were used in this study ( Table 3 ) .The corpora differed in their sources as well their annotation guidelines , but contained annotations for the same concept type , i.e. ' medical problems ' .", "label": "", "metadata": {}, "score": "65.98686"}
{"text": "# constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .# computing a HMM model based on the training corpus , runnig the tagger on the test corpus and comparing the results with the original tags in the test corpus .", "label": "", "metadata": {}, "score": "66.21539"}
{"text": "The corpora were annotated for medical problems , but with different guidelines .The taggers were constructed using an existing tagging system MedTagger that consisted of dictionary lookup , part of speech ( POS ) tagging and machine learning for named entity prediction and concept extraction .", "label": "", "metadata": {}, "score": "66.26523"}
{"text": "Remarkably , the performance difference between the combined systems based on GENIA GSC and PennBioIE SSC is only small ( 0.2 percentage point ) .To test the consistency of this result , we redid the experiment with interchanged corpora , i.e. , GENIA GSC was used for training the chunkers and generating the SSC , and PennBioIE GSC was used for testing .", "label": "", "metadata": {}, "score": "66.33473"}
{"text": "Future directions .Studies on different corpora are needed to elucidate the relationship between the above mentioned factors and performance of taggers trained on pooled corpora .We plan to investigate whether weighting of features for the machine learning tagger and filtering of the annotations using a dictionary lookup , can improve the tagger performance on pooling the corpora .", "label": "", "metadata": {}, "score": "66.491035"}
{"text": "Buyko E , Wermter J , Poprat M , Hahn U : Automatically adapting an NLP core engine to the biology domain .Proceedings of the Joint BioLINK - Bio - Ontologies Meeting ; Fortaleza 2006 , 65 - 68 .Kudo T , Matsumoto Y : Chunking with support vector machines .", "label": "", "metadata": {}, "score": "66.547806"}
{"text": "In the first scenario , a chunker has to be trained for a biomedical subdomain for which a GSC is not available .Rather than creating a new GSC , we generate an SSC for the new domain and train the chunker on the SSC .", "label": "", "metadata": {}, "score": "66.548965"}
{"text": "[ 3 ] combined eight systems for event extraction and showed that the performance of the combined system increased by 4 percentage points as compared to the best individual system .We previously combined six publicly available text chunkers using a simple voting approach [ 4 ] .", "label": "", "metadata": {}, "score": "66.67588"}
{"text": "This is an adaptation of the BioTagger - GM system that was originally developed to identify gene / protein names in biomedical literature [ 9 ] .The pipeline of this system consisted of dictionary lookup , part of speech ( POS ) tagging and machine learning for named entity prediction and concept extraction .", "label": "", "metadata": {}, "score": "66.69145"}
{"text": "MCR guidelines did not explicitly address this issue .Reconciliation of annotations differences .To investigate the effect of annotation differences due to the differing guidelines , we considered curation of the annotations .Rectification of the differences in all guideline factors would require considerable manual effort .", "label": "", "metadata": {}, "score": "66.7038"}
{"text": ", 2009 ; Biber & Gray , 2010 ) , but the most interesting usages apply the divergence to a machine learning system .Despite the fact that authors have shown that a divergence ( Van Asch & Daelemans , 2010 ; Plank , 2011 ) or a linear combination of divergences ( McClosky , 2010 ) can be successfully used to link the sim ... . \" ...", "label": "", "metadata": {}, "score": "66.71213"}
{"text": "We found certain scaling techniques obtained tiny improvements on the target domain that , while significant compared to competition results , are not statistically significant .We also attempted a sim- ilar approach on the feature level .A very predic- tive source domain feature is not useful if it does not appear in the target domain .", "label": "", "metadata": {}, "score": "66.74222"}
{"text": "Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable .\" One of the main challenges in natural language processing ( NLP ) is to correct for biases in the manually annotated data available to system engineers .", "label": "", "metadata": {}, "score": "66.79878"}
{"text": "Our experiments indicated that a GSC consisting of only 10 or 25 abstracts but expanded with an SSC yields similar performances as a GSC of 100 or 250 abstracts .Practically , these results suggest that the time and effort spent in creating a GSC of sufficient size may be much reduced .", "label": "", "metadata": {}, "score": "67.094475"}
{"text": "Lingpipe , OpenNLP , and Yamcha were trained on the gold standard annotations of each subset and the total set , and tested on the 1,499 GENIA abstracts that were not used for training .The GSC and corresponding SSC ( together always totaling 500 abstracts ) were then used to train the chunkers .", "label": "", "metadata": {}, "score": "67.5208"}
{"text": "3 Adaptation Approaches We survey the main approaches we explored for this task .While some of these approaches provided a modest performance boost to a simple parser ( lim- ited data and first - order features ) , no method added any performance to our best parser ( all data and second - order features ) .", "label": "", "metadata": {}, "score": "67.724884"}
{"text": "Further studies on different corpora are needed to elucidate the relationship between the above mentioned factors and performance of taggers trained on pooled corpora .The investigation of these relationships would be a useful guide for researchers to develop machine learning taggers for clinical text .", "label": "", "metadata": {}, "score": "67.98731"}
{"text": "\" TALN'11 \" . \"PACLIC 2009 \" .Proceedings of the 4th International Conference on Language Resources and Evaluation ( LREC'04 ) ' ' .Lisbon , Portugal .Part - of - Speech Tagging from 97 % to 100 % : Is It Time for Some Linguistics ?", "label": "", "metadata": {}, "score": "68.156296"}
{"text": "Annotation of clinical text .Machine learning based taggers for detecting phrases that convey particular concepts , requires the availability of reports that have been manually marked ( annotated ) for the phrases .For instance , in the sentence \" The patient denies any abdominal pain \" , the phrase denoting a medical problem has been marked by the underline .", "label": "", "metadata": {}, "score": "68.40086"}
{"text": "This shows that chunkers may considerably differ with the gold standard with respect to the annotation of stopwords .Since the creation of an SSC is automatic , its size can be very large .For different text - processing applications , increasing amounts of data for training classifiers have been shown to improve classifier performance [ 21 - 23 ] .", "label": "", "metadata": {}, "score": "68.46474"}
{"text": "Tateisi Y , Yakushiji A , Ohta T , Tsujii J : Syntax Annotation for the GENIA corpus .Proceedings of the Second International Joint Conference on Natural Language Processing ; Jeju Island , South Korea 2005 , 222 - 227 .", "label": "", "metadata": {}, "score": "68.60805"}
{"text": "For ex- ample , trained on in - domain data , nouns that occur more often tend to be heads .However , none of these features transfered between domains .A final type of feature we added was based on the behavior of nouns , adjectives and verbs in each domain .", "label": "", "metadata": {}, "score": "68.64577"}
{"text": "Acknowledgements .This study was supported by the European Commission FP7 Program ( FP7/2007 - 2013 ) under grant no .231727 ( the CALBC Project ) .Authors ' contributions .NK co - developed the methodology , built the software infrastructure , carried out the experiments , and drafted the manuscript .", "label": "", "metadata": {}, "score": "68.68506"}
{"text": "The chunkers then annotated the PennBioIE corpus and the annotations of all chunkers were combined to yield the silver standard .Subsequently , Lingpipe , OpenNLP , and Yamcha were trained on the PennBioIE SSC and on the PennBioIE GSC , using 10-fold cross - validation .", "label": "", "metadata": {}, "score": "68.76518"}
{"text": "Part - of - Speech Tagging from 97 % to 100 % : Is It Time for Some Linguistics ?In Alexander Gelbukh ( ed . ) , Computational Linguistics and Intelligent Text Processing , 12th International Conference , CICLing 2011 , Proceedings , Part I. Lecture Notes in Computer Science 6608 , pp .", "label": "", "metadata": {}, "score": "68.86636"}
{"text": "View Article .Van Erp M , Schomaker L : Variants of the borda count method for combining ranked classifier hypotheses .Proceedings of the Seventh International Workshop on Frontiers in Handwriting Recognition ; Amsterdam 2000 , 443 - 452 .Seki K , Mostafa J : An application of text categorization methods to gene ontology annotation .", "label": "", "metadata": {}, "score": "68.87548"}
{"text": "171 - -189 .Springer .S\u00f8gaard , Anders .Semi - supervised condensed nearest neighbor for part - of - speech tagging .The 49th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies ( ACL - HLT ) .", "label": "", "metadata": {}, "score": "68.955154"}
{"text": "171 - -189 .Springer .S\u00f8gaard , Anders .Semi - supervised condensed nearest neighbor for part - of - speech tagging .The 49th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies ( ACL - HLT ) .", "label": "", "metadata": {}, "score": "68.955154"}
{"text": "We examined the annotation guidelines to identify factors that contributed to the performance degradation of taggers trained on pooled corpora .Concept definition .Annotation guidelines for the two corpora differed slightly in definition of concepts .i2b2 annotation guideline extends definition of medical problem beyond the semantic type of signs / symptoms and disease / syndrome ( disorder ) , to include pathologic functions , mental dysfunction , molecular dysfunction , congenital abnormality , acquired abnormality , neoplastic process , and virus / bacterium .", "label": "", "metadata": {}, "score": "68.98405"}
{"text": "Competing interests .The authors declare that they have no competing interest .Authors ' contribution .KW carried out the experiments , led the study design and analysis and drafted the manuscript .MT helped with the experiments , participated in the study analysis and manuscript drafting .", "label": "", "metadata": {}, "score": "69.23169"}
{"text": "Rather than expanding the GSC , we supplement the GSC with an SSC from the same domain and train the chunker on the combined GSC and SSC to improve chunker performance .Related work .During the past decade , much research has been devoted to systems that combine different classifiers , also called multiple classifier systems or ensemble - based systems [ 1 ] .", "label": "", "metadata": {}, "score": "69.290016"}
{"text": "Starting from raw bracketings of four common HTML tags ( anchors , bold , italics and underlines ) , we refine approximate partial phrase boundaries to yield accurate parsing constraints .Conversion procedures fall out of our ... \" .We show how web mark - up can be used to improve unsupervised dependency parsing .", "label": "", "metadata": {}, "score": "69.37357"}
{"text": "Uzuner O , Luo Y , Szolovits P : Evaluating the state - of - the - art in automatic de - identification .J Am Med Inform Assoc 2007 , 14 ( 5 ) : 550 - 563 .View Article .", "label": "", "metadata": {}, "score": "69.38502"}
{"text": "Abbreviations .Declarations .Acknowledgements .We are thankful to the people who developed and made available the machine learning tools : GENIA tagger and Mallet , terminology services : UMLS and the labeled corpora used in this study .The i2b2 corpus of deidentified clinical reports used in this research were provided by the i2b2 National Center for Biomedical Computing funded by U54LM008748 and were originally prepared for the Shared Tasks for Challenges in NLP for Clinical Data organized by Dr. Ozlem Uzuner , i2b2 and SUNY .", "label": "", "metadata": {}, "score": "69.4063"}
{"text": "Did you test with nltk.tag.pos_tag ( ) ?It loads a pickle to do the tagging .I 'm asking because that seemed to perform comparable / better , and was already setup .I have not tested nltk.tag.pos_tag ( ) ( I 'm pretty sure it was n't released when I wrote this series ) .", "label": "", "metadata": {}, "score": "69.65391"}
{"text": "J Am Med Inform Assoc 2011 , 18 ( 5 ) : 580 - 587 .View Article .Johnson HL , Baumgartner WA , Krallinger M , Cohen KB , Hunter L : Corpus refactoring : a feasibility study .Journal of Biomedical Discovery and Collaboration 2007 , 2 ( 1 ) : 4 .", "label": "", "metadata": {}, "score": "69.72177"}
{"text": "first introduced by Warren Weaver in 1949 W. Weaver .In Machine Translation . of .Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .In 1975 .Kelly and Stone .", "label": "", "metadata": {}, "score": "69.74449"}
{"text": "Partners Healthcare , Beth Israel Deaconess Medical Center and University of Pittsburgh Medical Center contributed discharge summaries for this corpus , and University of Pittsburgh Medical Center also contributed progress reports .This corpus was annotated for patient medical problems ( signs / symptoms and disorders ) , treatments and tests .", "label": "", "metadata": {}, "score": "69.811005"}
{"text": "MCR annotations included concepts that were not pertaining to patients .For instance , disease names in organizational unit names , e.g. \" cancer \" in \" cancer department \" .Concepts that are not directly related to the patient were not annotated in i2b2 corpus .", "label": "", "metadata": {}, "score": "69.821686"}
{"text": "The combined system performs better than any of the individual chunkers , including GATE and MetaMap which proved to have F - scores lower than each of the three trainable chunkers , in agreement with our previous findings [ 4 ] .", "label": "", "metadata": {}, "score": "70.019775"}
{"text": "Since the guidelines differ , we observe no corresponding structure in the WSJ .It is telling that the parser labels this BIO example by attaching ev- ery token to the final proper noun \" P1 - 1 \" , exactly as the WSJ guidelines indicate .", "label": "", "metadata": {}, "score": "70.095"}
{"text": "The cause for this is clear when the annotation guide- lines are considered .The proper nouns in WSJ are names of companies , people and places , while in BIO they are names of genes , proteins and chemi- cals .", "label": "", "metadata": {}, "score": "70.11349"}
{"text": "However the corpora were constructed with different annotation guidelines .The experiments were carried out using an existing machine learning - based tagging system , MedTagger [ 9 ] , that participated in the 2010 i2b2/VA NLP challenge .In an earlier study , we had reported performance gain for machine learning taggers by pooling corpora across institutions and report types [ 17 ] .", "label": "", "metadata": {}, "score": "70.27315"}
{"text": "Semi - supervised Training for the Averaged Perceptron POS Tagger .Proceedings of the 12 EACL , pages 763 - 771 . , Yoshimasa .and Jun'ichi Tsujii .Revision as of 15:46 , 10 December 2012 .Contents .Performance measure : per token accuracy .", "label": "", "metadata": {}, "score": "70.93268"}
{"text": "Yoshimasa Tsuruoka YT , Jin - Dong K , Tomoko O , John MN , Sophia A , Junichi T : Developing a robust part - of - speech tagger for biomedical text .In Advances in informatics - 10th panhellenic conference on informatics .", "label": "", "metadata": {}, "score": "71.09583"}
{"text": ": BioCreative III interactive task : an overview .BMC Bioinformatics 2011 , 12 ( Suppl 8) : S4 .View Article .Kim JD , Nguyen N , Wang Y , Tsujii J , Takagi T , Yonezawa A : The genia event and protein coreference tasks of the BioNLP shared task 2011 .", "label": "", "metadata": {}, "score": "71.34583"}
{"text": "is being used in a textual context .A more technical discussion of WSD follows below .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .In earlier systems the senses were more typically generic senses selected by the originators of the system .", "label": "", "metadata": {}, "score": "71.347946"}
{"text": "Tested across six domains , our system outperforms all non - oracle baselines including the best domain - independent parsing model .Thus , we are able to demonstrate the value of customizing parsing models to specific domains . ... train models in many different domains but sidestep the problem of domain detection .", "label": "", "metadata": {}, "score": "71.43141"}
{"text": "The brown , conll2000 , and treebank corpora are what they are , and you should n't assume that a pos tagger trained on them will be accurate on a different corpus .For example , a pos tagger trained on one part of the brown corpus may be 90 % accurate on other parts of the brown corpus , but only 50 % accurate on the conll2000 corpus .", "label": "", "metadata": {}, "score": "71.46655"}
{"text": "In contrast , the text segment ' removal of mass ' is annotated as two concept phrases as it can not be rearranged to express the same concept without the preposition .MCR guidelines did not explicitly address this issue .Conjunctions .", "label": "", "metadata": {}, "score": "71.76039"}
{"text": "View Article .Boyack KW , Newman D , Duhon RJ , Klavans R , Patek M , Biberstine JR , Schijvenaars B , Skupin A , Ma N , B\u00f6rner K : Clustering more than two million biomedical publications : comparing the accuracies of nine text - based similarity approaches .", "label": "", "metadata": {}, "score": "71.77145"}
{"text": "Further investigations will have to reveal how the quality of an SSC affects classifier performance and whether the use of SSCs in other application areas is equally advantageous as their use in text chunking .Conclusions .We have shown that an automatically created SSC can be a viable alternative for or a supplement to a GSC when training chunkers in a biomedical domain .", "label": "", "metadata": {}, "score": "71.895035"}
{"text": "Silver standard as alternative for gold standard .To test whether an SSC could serve as a substitute for a GSC , we compared the performance of chunkers trained on silver standard annotations of the abstracts in the PennBioIE corpus with the performance of the chunkers trained on the gold standard annotations of the same corpus .", "label": "", "metadata": {}, "score": "72.00435"}
{"text": "Conclusions .The effectiveness of pooling corpora , is dependent on several factors , which include compatibility of annotation guidelines , distribution of report types and size of local and foreign corpora .Simple methods to rectify some of the guideline differences can facilitate pooling .", "label": "", "metadata": {}, "score": "72.008606"}
{"text": "The meaning . of a .word in a particular usage can only be determined by examining its context . . .This is , in general , a trivial task for the human language processing system , for .# The boy leapt from the bank into the cold water .", "label": "", "metadata": {}, "score": "72.01432"}
{"text": "Each experiment was repeated 5 times and the average performance measures were computed , i.e. 5 times 5-fold cross - validation was performed .We had increased the runs for cross - validating the subsets from 3 to 5 .", "label": "", "metadata": {}, "score": "72.09119"}
{"text": "We used a simple voting approach to create an SSC .More sophisticated voting methods exist , such as weighted voting [ 17 ] or Borda count [ 18 ] , but these methods require information about the confidence or rank of the chunks , information that is not available for the chunkers in this study .", "label": "", "metadata": {}, "score": "72.20665"}
{"text": "Computer Recognition of English Word Senses , Amsterdam : North - Holland . published a book explicitly listing their rules for disambiguation of word senses .Revision as of 11:55 , 4 January 2011 .Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .", "label": "", "metadata": {}, "score": "72.365204"}
{"text": "\"LREC 2008 \" .EMNLP 2002 ' ' .\" TALN'11 \" . \"PACLIC 2009 \" .Proceedings of the 4th International Conference on Language Resources and Evaluation ( LREC'04 ) ' ' .Lisbon , Portugal . . .", "label": "", "metadata": {}, "score": "72.40006"}
{"text": "BMC Bioinformatics 2009 , 10 ( 1 ) : 403 .View Article .Wang Y , S\u00e6tre R , Kim J - D , Pyysalo S , Ohta T , Tsujii JI : Improving the inter - corpora compatibility for protein annotations .", "label": "", "metadata": {}, "score": "72.61964"}
{"text": "I played around with Brown / Treebank / conll2000 a little bit .Did you test with nltk.tag.pos_tag ( ) ?It loads a pickle to do the tagging .I 'm asking because that seemed to perform comparable / better , and was already setup .", "label": "", "metadata": {}, "score": "72.773544"}
{"text": "Wilbur J , Smith L , Tanabe T : BioCreative 2 gene mention task .In Proceedings of the second BioCreative challenge workshop .Madrid , Spain : Proceedings of the second biocreative challenge evaluation workshop Vol : 23 ; 2007:7 - 16 .", "label": "", "metadata": {}, "score": "72.81108"}
{"text": "Since these annotations are new with respect to the WSJ guidelines , it is impossi- ble to parse these without injecting knowledge of the annotation guidelines.3 common , comprising 33 % of BIO and 30 % of WSJ tokens , the most popular POS tag by far .", "label": "", "metadata": {}, "score": "72.8291"}
{"text": "Revision as of 04:20 , 25 June 2012 .Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .", "label": "", "metadata": {}, "score": "72.84569"}
{"text": "An example is the above BIO NP , in which the phrase \" glutathione transferase P1 - 1 \" is an appositive indicating which \" enzyme \" is meant .However , since there are no commas , the parser thinks \" P1 - 1 \" is the head .", "label": "", "metadata": {}, "score": "73.03687"}
{"text": "View Article .Carpenter B : LingPipe for 99.99 % recall of gene mentions .Proceedings of the Second BioCreative Challenge Evaluation Workshop ; Valencia 2007 , 307 - 309 .Aronson AR : Effective mapping of biomedical text to the UMLS Metathesaurus : the MetaMap program .", "label": "", "metadata": {}, "score": "73.14332"}
{"text": "Columbus , Ohio .1572326 : Association for Computational Linguistics ; 2008:94 - 95 .View Article .Jonnalagadda S : An effective approach to biomedical information extraction with limited training data ( PhD Dissertation , Arizona State University ) .Phoenix , Arizona : PhD Phoenix ; 2011 .", "label": "", "metadata": {}, "score": "73.230606"}
{"text": "The CoNLL In Proc .Lawrence Saul and Fernando Pereira . gate and mixed - order markov models for statistical language modeling .In EMNLP . Aggre-1055 .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .", "label": "", "metadata": {}, "score": "73.239746"}
{"text": "Named entity recognition is generally considered more difficult than chunking , having to deal with increased complexities in boundary recognition , disambiguation , and spelling variation of entities .Clearly , the better a silver standard will approach a gold standard for the domain of interest , the better the performance of systems trained on an SSC .", "label": "", "metadata": {}, "score": "73.35722"}
{"text": "NN , NNP - NNP - NNP , NN - IN - NN , and IN - NN - NN .However , when we examine the coarse POS tags , which do not distinguish between nouns , these dif- ferences disappear .", "label": "", "metadata": {}, "score": "73.51117"}
{"text": "Semi - supervised Training for the Averaged Perceptron POS Tagger .Proceedings of the 12 EACL , pages 763 - 771 . . . .( The convention is for this to be measured on all tokens , including punctuation tokens and other unambiguous tokens . )", "label": "", "metadata": {}, "score": "73.66434"}
{"text": "In this paper , we address two issues that are related to domain adaptation .The first question is how much genre variation will affect NLP systems ' performance .We investigate the effect of genre variation on the performance of three NLP tools , namely , word segmenter , POS tagger , and parser .", "label": "", "metadata": {}, "score": "73.8083"}
{"text": "In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 Abstract .", "label": "", "metadata": {}, "score": "73.95547"}
{"text": "The combination of systems always performed better than any of the individual systems , but performance increase of the combined system was larger when the individual systems were trained on GENIA or PennBioIE GSCs than when they were trained on the PennBioIE SSC ( cf .", "label": "", "metadata": {}, "score": "74.66708"}
{"text": "Part of Speech Tagging with NLTK Part 3 - Brill Tagger .In regexp and affix pos tagging , I showed how to produce a Python NLTK part - of - speech tagger using Ngram pos tagging in combination with Affix and Regex pos tagging , with accuracy approaching 90 % .", "label": "", "metadata": {}, "score": "74.81075"}
{"text": "Spoustov\u00e1 , Drahom\u00edra \" Johanka \" , Jan Haji\u010d , Jan Raab and Miroslav Spousta .Semi - supervised Training for the Averaged Perceptron POS Tagger .Proceedings of the 12 EACL , pages 763 - 771 .Abstract .Background .", "label": "", "metadata": {}, "score": "74.864105"}
{"text": "The 0.9 version of the corpus was released in 2004 and includes the CYP and Oncology corpora of the Linguistic Data Consortium .The CYP corpus consists of 324 Medline abstracts on the inhibition of cytochrome P450 enzymes .The Oncology corpus consists of 318 Medline abstracts on cancer and molecular genetics .", "label": "", "metadata": {}, "score": "74.88867"}
{"text": "Smith L , Tanabe LK , Ando RJ , Kuo CJ , Chung IF , Hsu CN , Lin YS , Klinger R , Friedrich CM , Ganchev K , et al .: Overview of BioCreative II gene mention recognition .", "label": "", "metadata": {}, "score": "75.09871"}
{"text": "PubMed View Article .Kim J , Ohta T , Pyysalo S , Kano Y , Tsujii J : Overview of BioNLP'09 shared task on event extraction .Proceedings of the Workshop on BioNLP : Shared Task ; Boulder 2009 , 1 - 9 .", "label": "", "metadata": {}, "score": "75.17381"}
{"text": "Springer .S\u00f8gaard , Anders .Semi - supervised condensed nearest neighbor for part - of - speech tagging .The 49th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies ( ACL - HLT ) .Portland , Oregon .", "label": "", "metadata": {}, "score": "75.191666"}
{"text": "Wang Y , Patrick J : Cascading classifiers for named entity recognition in clinical notes .In Proceedings of the workshop on biomedical information extraction .Borovets , Bulgaria .1859783 : Association for Computational Linguistics ; 2009:42 - 49 .Li D , Kipper - Schuler K , Savova G : Conditional random fields and support vector machines for disorder named entity recognition in clinical texts .", "label": "", "metadata": {}, "score": "75.23697"}
{"text": "Performance figures of the CALBC SSC against GSCs for named - entity recognition are not yet available , but we presume that they will be much lower .However , despite the differences between an SSC and GSC , chunking systems trained on these corpora showed remarkably similar performances .", "label": "", "metadata": {}, "score": "75.57352"}
{"text": "McClosky et al .( 2010 ) coined the term multiple source domain adaptation .Similar to us , McClosky et al .( 2010 ) regard a target domain as mixture of source domains , b .. by Joseph Le Roux , Jennifer Foster , Joachim Wagner , Rasul Samad , Zadeh Kaljahi , Anton Bryl . \" ...", "label": "", "metadata": {}, "score": "75.63777"}
{"text": "We immediately recognise that in the first sentence bank refers . to .the edge . of a . river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .", "label": "", "metadata": {}, "score": "75.7112"}
{"text": "More information on characteristics and performance of these chunkers can be found in our previous comparative study of chunkers [ 4 ] , which also included Genia Tagger .Since Genia Tagger comes with a fixed pre - trained model based on the corpora that we use in this study , it could bias the results of our experiments and was not included .", "label": "", "metadata": {}, "score": "76.01652"}
{"text": "In this paper , we have examined the factors associated with the use of corpus from other institutions .Overview of current work .We trained and tested taggers on a corpus from Mayo Clinic Rochester [ 24 ] and a corpus from the 2010 i2b2/VA NLP challenge [ 25 ] , and examined the effect of pooling the corpora [ 26 ] .", "label": "", "metadata": {}, "score": "76.0347"}
{"text": "Corpora .There are only a few publicly available corpora in the biomedical domain that incorporate chunk annotations .We used the GENIA Treebank corpus [ 12 ] and the PennBioIE corpus [ 13 ] .The GENIA corpus [ 12 ] has been developed at the University of Tokyo .", "label": "", "metadata": {}, "score": "76.229614"}
{"text": "Spoustov\u00e1 , Drahom\u00edra \" Johanka \" , Jan Haji\u010d , Jan Raab and Miroslav Spousta .Semi - supervised Training for the Averaged Perceptron POS Tagger .Proceedings of the 12 EACL , pages 763 - 771 .", "label": "", "metadata": {}, "score": "76.26622"}
{"text": "In Proc . of the 16th Nordic Conference on Computational Linguistics ( NODALIDA ) .Extended Sandra K\u00a8 ubler . schemes influence parsing results ? or how not to com- pare apples and oranges .In RANLP .How do treebank annotation 1054 .", "label": "", "metadata": {}, "score": "76.97061"}
{"text": "Springer .Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics ( ACL 2007 ) ' ' , pages 760 - 767 .Semi - supervised condensed nearest neighbor for part - of - speech tagging .The 49th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies ( ACL - HLT ) .", "label": "", "metadata": {}, "score": "77.01584"}
{"text": "In this paper , we address two issues that are related to domain adaptation .The first question is how much genre variation will affect NLP systems ' per ... \" .Domain adaptation is an important task in order for NLP systems to work well in real applications .", "label": "", "metadata": {}, "score": "77.2509"}
{"text": "The features were fed to a sequence tagger using a conditional random field ( CRF ) model [ 32 ] with a token window size of five .Experiment .We designed our experiments to examine effect of using pooled training sets on the performance of machine learning taggers for concept extraction ( Figure 5 ) .", "label": "", "metadata": {}, "score": "77.97619"}
{"text": "J Am Med Inform Assoc 2008 , 15 ( 1 ) : 14 - 24 .View Article .Uzuner O , Solti I , Cadag E : Extracting medication information from clinical text .J Am Med Inform Assoc 2010 , 17 ( 5 ) : 514 - 518 .", "label": "", "metadata": {}, "score": "78.36551"}
{"text": "Chunking is a natural language processing technique that splits text into groups of words that constitute a grammatical unit , e.g. , a noun phrase or a verb phrase .It is an important processing step in systems that try to automatically extract information from text .", "label": "", "metadata": {}, "score": "78.58217"}
{"text": "In a very recent study , Chowdhury and Lavelli compared a gene recognition system trained on an initial version of the CALBC SSC against the system trained on the BioCreative GSC [ 6 ] .Methods .Chunking systems .To generate a silver standard , we used five well - known and publicly available chunkers : GATE chunker 5.0 [ 7 ] , Lingpipe 3.8 [ 8 ] , MetaMap 2008v2 [ 9 ] , OpenNLP 2.1 [ 10 ] , and Yamcha 0.33 [ 11 ] .", "label": "", "metadata": {}, "score": "78.828415"}
{"text": "MCR annotation guideline defined signs / symptoms and disorders , which we mapped to the problem class .Signs / symptoms were defined as concepts that mapped to SNOMED - CT subset of semantic type signs / symptoms .Disease / syndrome had a looser definition that extended beyond the semantic types for ' i2b2 medical problem ' , to include injury or poisoning , behavioral dysfunction , cell dysfunction , experimental model of disease and anatomical abnormality but excluded virus / bacterium .", "label": "", "metadata": {}, "score": "78.898575"}
{"text": "The i2b2 annotations included articles , e.g. \" the cough \" and \" a fever \" , while MCR annotations did not .Nearly 11 % of the i2b2 annotations began with an article ( Table 1 ) .This contributes to the generally longer length of the i2b2 annotations ( Figure 2 ) .", "label": "", "metadata": {}, "score": "79.18004"}
{"text": "The problem of WSD was first introduced by Warren Weaver in 1949 [ 3 ] .In 1975 Kelly and Stone [ 4 ] published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .", "label": "", "metadata": {}, "score": "79.71707"}
{"text": "The problem of WSD was first introduced by Warren Weaver in 1949 [ 3 ] .In 1975 Kelly and Stone [ 4 ] published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .", "label": "", "metadata": {}, "score": "79.71707"}
{"text": "The creation of gold standard corpora ( GSCs ) , however , is expensive and time - consuming .GSCs therefore tend to be small and to focus on specific subdomains , which limits their usefulness .We investigated the use of a silver standard corpus ( SSC ) that is automatically generated by combining the outputs of multiple chunking systems .", "label": "", "metadata": {}, "score": "79.85632"}
{"text": "Results .We have tested the two scenarios using three chunkers , Lingpipe , OpenNLP , and Yamcha , and two different corpora , GENIA and PennBioIE .When the outputs of the chunkers were combined , the combined system showed little improvement when using the SSC .", "label": "", "metadata": {}, "score": "80.10791"}
{"text": "Thus , the performance of chunkers trained on either SSC or GSC was always tested on the GSC .Silver standard as supplement of gold standard .To test whether an SSC would have additional value as a supplement for a given GSC , we compared the performance of chunkers trained on a subset of the GENIA GSC with the performance of the chunkers trained on the same subset supplemented with an SSC .", "label": "", "metadata": {}, "score": "80.421906"}
{"text": "In addition to a change in the annotation guide- lines for NPs , we observed an important difference in the distribution of POS tags .NN tags were almost twice as likely in the BIO domain ( 14 % in WSJ and 25 % in BIO ) .", "label": "", "metadata": {}, "score": "80.64184"}
{"text": "All authors read and approved the manuscript .Authors ' Affiliations .Department of Medical Informatics , Erasmus University Medical Center .References .Polikar R : Ensemble based systems in decision making .IEEE Circuit Syst Mag 2006 , 6 : 21 - 45 .", "label": "", "metadata": {}, "score": "80.81986"}
{"text": "electronic computer either current or imaginable \" .Y. Bar - Hillel .Language and Information .Addison - Wesley , 1964 .However , the situation is not as bad as Bar - Hillel feared , there have been several advances in .", "label": "", "metadata": {}, "score": "81.66883"}
{"text": "Obviously , to create the SSC we need trained chunkers , and thus a GSC for their initially training .We explored the use of a GSC from another , but related , domain than the domain of interest .Alternatively , we supplemented a GSC with an SSC in the same domain of interest .", "label": "", "metadata": {}, "score": "81.8645"}
{"text": "The authors are thankful for the constructive comments of the reviewers .This study was supported by National Science Foundation ABI:0845523 , Strategic Health IT Advanced Research Projects ( SHARP ) award ( 90TR0002 ) to Mayo Clinic from Health and Human Services ( HHS ) and National Library of Medicine ( NLM:1K99LM011389 , 5R01LM009959 - 02 ) grants .", "label": "", "metadata": {}, "score": "81.950806"}
{"text": "Harvard University Press .Koby Crammer , Ofer Dekel , Joseph Keshet , Shai Shalev-Shwartz , and Yoram Singer .Online passive- aggressive algorithms .Journal of Machine Learning Research , 7:551 - 585 , Mar. R. Johansson and P. Nugues .", "label": "", "metadata": {}, "score": "82.187805"}
{"text": "The SSC as a substitute for a GSC corresponds with a use scenario in which a chunker created for one subdomain has to be adapted to another , where a GSC for the new domain is not available .In the second use scenario , we supplemented a ( small ) GSC with an SSC for the same domain as the GSC .", "label": "", "metadata": {}, "score": "82.5001"}
{"text": "5 Acknowledgments We thank Joel Wallenberg and Nikhil Dinesh for their informative and helpful linguistic expertise , Kevin Lerman for his edge labeler code , and Koby Crammer for helpful conversations .Dredze is sup- ported by a NDSEG fellowship ; Ganchev and Taluk- dar by NSF ITR EIA-0205448 ; and Blitzer by DARPA under Contract No . NBCHD03001 .", "label": "", "metadata": {}, "score": "83.813095"}
{"text": "The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .", "label": "", "metadata": {}, "score": "84.22783"}
{"text": "The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .", "label": "", "metadata": {}, "score": "84.22783"}
{"text": "This indicates that most of the loss comes from missing these edges .The primary problem for nouns is the difference between structures in each domain . tion guidelines for the Penn Treebank flattened noun phrases to simplify annotation ( Marcus et al . , 1993 ) , so there is no complex structure to NPs . K\u00a8 ubler ( 2006 ) showed that it is difficult to compare the Penn Treebank to other treebanks with more com- plexnounstructures , suchasBIO.ConsidertheWSJ phrase \" the New York State Insurance Department \" .", "label": "", "metadata": {}, "score": "84.415054"}
{"text": "The problem of WSD was first introduced by Warren Weaver in 1949 W. Weaver .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press . . . .", "label": "", "metadata": {}, "score": "84.45114"}
{"text": "MCR annotations ( red line ) are shorter than the i2b2 annotations ( blue dashed line ) .Possessive pronouns .i2b2 annotations included possessive pronouns , e.g. \" his cancer \" , while MCR annotations did not .3 % of i2b2 annotations began with ' his ' ( 174 ) or ' her ' ( 200 ) .", "label": "", "metadata": {}, "score": "84.7163"}
{"text": "Copyright .\u00a9 Kang et al ; licensee BioMed Central Ltd. 2012 .( The convention is for this to be measured on all tokens , including punctuation tokens and other unambiguous tokens . )The splits of data for this task were not standardized early on ( unlike for parsing ) and early work uses various data splits defined by counts of tokens or by sections .", "label": "", "metadata": {}, "score": "86.32138"}
{"text": "These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon . \" ...", "label": "", "metadata": {}, "score": "86.32671"}
{"text": "Hi !i 'd like to cite this for my dissertation but i ca n't find ur name anywhere ! karen .Hi !i 'd like to cite this for my dissertation but i ca n't find ur name anywhere !", "label": "", "metadata": {}, "score": "88.719955"}
{"text": "Journal of American Medical Informatics Assocociation 2010 , 17 ( 5 ) : 507 - 513 .View Article .Uzuner O , South BR , Shen S , Duvall SL : 2010i2b2/VA challenge on concepts , assertions , and relations in clinical text .", "label": "", "metadata": {}, "score": "89.24795"}
{"text": "In LREC'08 .Marrakech , Morocco : Proceedings of the Sixth International Conference on Language Resources and Evaluation LREC'08 ; 2008:3143 - 3150 .Bodenreider O : The unified medical language system ( UMLS ) : integrating biomedical terminology .Nucleic Acids Res 2004 , 32 ( Database issue ) : D267 - 270 .", "label": "", "metadata": {}, "score": "89.7637"}
{"text": "Copyright .\u00a9 Wagholikar et al . ; licensee BioMed Central Ltd. 2013 .This article is published under license to BioMed Central Ltd.Conference : EMNLP - CoNLL 2007 , Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning , June 28 - 30 , 2007 , Prague , Czech Republic .", "label": "", "metadata": {}, "score": "89.95191"}
{"text": "The creation of a gold standard corpus ( GSC ) is tedious and expensive : annotation guidelines have to be established , domain experts must be trained , the annotation process is time - consuming , and annotation disagreements have to be resolved .", "label": "", "metadata": {}, "score": "90.16506"}
{"text": "Portland , Oregon .Proceedings of HLT - NAACL 2003 ' ' , pages 252 - 259 .Proceedings of the Fifteenth Conference on Computational Natural Language Learning ' ' , pp 238 - 246 , 2011 .Revision as of 15:46 , 10 December 2012 .", "label": "", "metadata": {}, "score": "93.09138"}
{"text": "Portland , Oregon .Proceedings of HLT - NAACL 2003 ' ' , pages 252 - 259 .Proceedings of the Fifteenth Conference on Computational Natural Language Learning ' ' , pp 238 - 246 , 2011 .Revision as of 15:46 , 10 December 2012 .", "label": "", "metadata": {}, "score": "93.09138"}
{"text": "In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 The problem of WSD was first introduced by Warren Weaver in 1949 W. Weaver .", "label": "", "metadata": {}, "score": "94.24524"}
{"text": "Proceedings of the CoNLL Shared Task Session of EMNLP - CoNLL 2007 , pp .1051 - 1055 , Prague , June 2007 .c ?upenn.edu 2L2F - INESC - ID Lisboa / IST , Rua Alves Redol 9 , 1000 - 029 , Lisboa , Portugal javg@l2f.inesc-id.pt Abstract We describe some challenges of adaptation in the 2007 CoNLL Shared Task on Domain Adaptation .", "label": "", "metadata": {}, "score": "96.32296"}
{"text": "HL conceived the study , helped with the experiments , participated in the study design and analysis , and drafting of the manuscript .All authors read and approved the final manuscript .Authors ' Affiliations .Division of Biomedical Statistics and Informatics , Mayo Clinic .", "label": "", "metadata": {}, "score": "96.40027"}
{"text": "If the portions of the lists are otherwise independent , they should not be included .For example , the text segment ' metastases in the liver and pancreas ' is a valid concept phrase including ' and ' , while the segment ' diarrhea , nausea and vomiting ' is not valid .", "label": "", "metadata": {}, "score": "100.05284"}
{"text": "Another problem concerns appositives .For ex- ample , the phrase \" Howard Mosher , president and chief executive officer , \" has \" Mosher \" as the head of \" Howard \" and of the appositive NP delimited by commas .", "label": "", "metadata": {}, "score": "112.99391"}
{"text": "What 's your topic ?My name 's Jacob Perkins , and I should probably put it somewhere obvious .Jacob .Cool !What 's your topic ?My name 's Jacob Perkins , and I should probably put it somewhere obvious .", "label": "", "metadata": {}, "score": "114.517235"}
