{"text": "This allows the use of a much wider range of parallel corpora for training , and can be combined with a standard phrase - table using conventional smoothing methods .Experimental results demonstrate BLEU improvements for triangulated models over a standard phrase - based system .", "label": "", "metadata": {}, "score": "29.34284"}
{"text": "5 ] and applied in their respective translation systems for phrase table smoothing .Chiang et al .[ 15 ] suggested morphology - based and provenance - based improvements to the Koehn - Och - Marcu method recently ...A system for guiding a search for information is presented .", "label": "", "metadata": {}, "score": "31.196999"}
{"text": "Of course , in practice a document will yield many candidate phrases .The phrase identification server 250 repeats these steps for every document in the document set that is being used for phrase extraction .The result is an initial set of candidate phrases , and for each candidate phrase a list of document phrase scores , from the documents in which it was considered a reasonable candidate .", "label": "", "metadata": {}, "score": "31.970753"}
{"text": "These latter documents are then included in the search results .This eliminates the need for the system to then separately process the posting list of the second query phrase , thereby providing faster search times .Of course , this approach may be extended to any number of phrases in a query , yielding in significant computational and timing savings .", "label": "", "metadata": {}, "score": "33.035988"}
{"text": "Note that this approach provides highly relevant documents even if the documents do not contain a high frequency of the input query terms q , since related phrase information was used to both identify relevant documents , and then rank these documents .", "label": "", "metadata": {}, "score": "33.175797"}
{"text": "A candidate phrase that appears repeatedly , or in significant locations with the a document will have a high document phrase score for that document .( 2 ) Cross - Document Phrase Merging .The first stage 302 of the phrase extraction process provided information about how strongly various candidate phrases are indicated to be real phrases by individual documents .", "label": "", "metadata": {}, "score": "34.134148"}
{"text": "Note that these are not phrases in the linguistic sense , but simply subsequences of words .For a sentence .referred to as a phrase table .Part of the overall MT training process is to estimate this table and the associated probabilities .", "label": "", "metadata": {}, "score": "34.243114"}
{"text": "In this paper , we investigate lexicon models for hierarchical phrase - based statistical machine translation .We explore sourceto - target models with phrase - level as well as sentence - level scoring and target - to - source models with scoring on phrase level only .", "label": "", "metadata": {}, "score": "34.535988"}
{"text": "Statistics on the phrase pair are accumulated over the entire corpus .In our experiments below , we rely on word - to - word IBM models [ 2 ] for alignment .Although more elaborate techniques have appeared more recently [ 13 , 14 ] , their impact on the resulting machine translation quality is still unclear [ 15 ] .", "label": "", "metadata": {}, "score": "34.864677"}
{"text": "In that case , these subphrases are determined to be redundant , and are eliminated from the candidate phrase list .( 4 ) Refine Phrase List with Heuristics and Language Models .The list of candidate phrases produced by stage 306 can be further refined with an optional processing stage using heuristics and/or language specific models .", "label": "", "metadata": {}, "score": "35.25976"}
{"text": "Any way to enforce linguistic constraints might result in a reduced need for data , and ultimately in more complete models , given the same corpus [ 34 ] .Neither approach would change the statistical nature of the system , but they would help it bypass the phrase acquisition bottleneck .", "label": "", "metadata": {}, "score": "35.713413"}
{"text": "Next , these counts themselves are used as weights are also used to multiply the related phrases for each document that is being scored .This approach has the benefit of allowing documents that do not have the query phrases as related phrases to still score appropriately .", "label": "", "metadata": {}, "score": "35.97259"}
{"text": "After processing the document , the phrase map table contains a set of word sequences , each a string with between two and N words , along with additional information about the word sequence .For each word sequence , the phrase identification server 250 assigns a phrase score that indicates how good the word sequence is as a candidate phrase .", "label": "", "metadata": {}, "score": "36.135044"}
{"text": "( ii ) generating a plurality of phrasifications based on the words as ordered combinations of leaf nodes .The system of . claim 19 , wherein scoring each candidate phrasification comprises : . applying a factor to account for a confidence level of each component phrase in the candidate phrasification .", "label": "", "metadata": {}, "score": "36.67563"}
{"text": "Again , this process is repeated for the documents in the search results ( either on demand or aforehand ) .For each such document then the resulting document description comprises the N top ranked sentences from the document .Duplicate Document Detection and Elimination .", "label": "", "metadata": {}, "score": "36.963562"}
{"text": "The query phrasification module 810 then scores each phrasification using a phrase scoring function .The phrase scoring function is designed to trade off precision versus recall in terms of selecting a final set of phrases .The general model for a phrase scoring function is as follow : .", "label": "", "metadata": {}, "score": "36.978184"}
{"text": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word - to - word alignments from an MT system , and syntactic structure from parse - trees of source and target language sentences .", "label": "", "metadata": {}, "score": "37.120552"}
{"text": "As an example , the system can include approximately 100,000 to 200,000 phrases , which will represent real phrases used in documents , rather than mere combinations of words .Given a set of phrases ( whether assembled in the foregoing manner or by other methods ) , the documents can be indexed by the phrase .", "label": "", "metadata": {}, "score": "37.14618"}
{"text": "Each candidate phrase 's individual document phrase scores are then combined across the documents in which it appears to create a combined score .The document phrase scores and the combined score for a candidate phrase are evaluated to determine how strongly the document collection supports the usage of the candidate phrase as a real phrase .", "label": "", "metadata": {}, "score": "37.27513"}
{"text": "We show for the first time that incorporating the predictions of a word sense disambigua - tion system within a typical phrase - based statistical machine translation ( SMT ) model consistently improves translation quality across all three different IWSLT Chinese - English test sets , as well as producing st ... \" .", "label": "", "metadata": {}, "score": "37.347305"}
{"text": "Work related to our learning curve experiments can also be found in [ 10 ] .It is important to remark that while there are many discussions about automatic evaluation of SMT systems , this work does not consider them .We work within the well - defined setting where a loss function has been agreed upon , that can measure the similarity between two sentences , and a paired training set has been provided .", "label": "", "metadata": {}, "score": "37.52182"}
{"text": "The result set 835 includes for each document listed therein , the phrase relevance score of the document with respect to each phrase of the query that the document contained .This set of phrase relevance scores for each document is then input by the front end server 140 into the second scoring algorithm , along with the query .", "label": "", "metadata": {}, "score": "37.539085"}
{"text": "Ranking .a )Ranking Documents Based on Contained Phrases .The search system 120 provides a ranking stage 604 in which the documents in the search results are ranked , using the phrase information in each document 's related phrase bit vector , and the cluster bit vector for the query phrases .", "label": "", "metadata": {}, "score": "37.712166"}
{"text": "In Section 3.4 , we report the correlation coefficient between all the measures .Each correlation coefficient is computed using the results of the 160 experiments described above .Acknowledgments .This work is supported by the EU IST Project SMART ( FP6 - 033917 ) .", "label": "", "metadata": {}, "score": "37.77884"}
{"text": "This user model is intersected with a list of phrases related to the query phrases , to identify phrases common to both groups .The common set is then ordered according to the related phrase information .The resulting set of related phrases is then used to rank the sentences of a document according to the number of instances of these related phrases present in each document .", "label": "", "metadata": {}, "score": "37.832108"}
{"text": "A document is retrieved in response to a query containing a number of query terms , typically based on having some number of query terms present in the document .The retrieved documents are then ranked according to other statistical measures , such as frequency of occurrence of the query terms , host domain , link analysis , and the like .", "label": "", "metadata": {}, "score": "38.15581"}
{"text": "When extracting longer phrases , we expect training set performance to be higher , but test performance to drop ( overfitting ) .Optimizing test performance requires the right trade - off .In this section , we analyze how the phrase length can affect the performance in terms of BLEU score .", "label": "", "metadata": {}, "score": "38.24691"}
{"text": "For each of these related phrases , the presentation system 130 ranks the sentences of the document according to the frequency of occurrence of each of these phrases , and then selects the top N ( e.g. , 5 to 10 ) ranking sentences .", "label": "", "metadata": {}, "score": "38.423935"}
{"text": "Next , given the phrases related to an accessed document , the clusters associated with these phrases can be determined from the cluster bit vectors for each phrase .For each cluster , each phrase that is a member of the cluster is determined by looking the phrase up in its related phrase table that contains the cluster number , or cluster bit vector representation as described above .", "label": "", "metadata": {}, "score": "38.44642"}
{"text": "2 ) Assignment of phrases and documents to index servers .In the first stage , the phrase posting lists are generated by the indexing server master 260 by processing a set of documents from the document collection , and in each document , identifying which phrases are related to the document .", "label": "", "metadata": {}, "score": "38.790146"}
{"text": "If the hit had a score above the threshold , the word sequence is added to a candidate phrase table along with its score .Next , the phrase identification server 250 determines whether or not subphrases of each candidate phrase are of interest as potential candidate phrases themselves .", "label": "", "metadata": {}, "score": "38.883904"}
{"text": "That is , each good phrase is used with sufficient frequency and independence to represent meaningful concepts or ideas expressed in the corpus .Unlike existing systems which use predetermined or hand selected phrases , the good phrase list reflects phrases that actual are being used in the corpus .", "label": "", "metadata": {}, "score": "38.894485"}
{"text": "Experimental results on the test data of the previous campaign are presented . ... to Canadian universities for research and education purposes . \" ...Current phrase - based SMT systems perform poorly when using small training sets .This is a consequence of unreliable translation estimates and low coverage over source and target phrases .", "label": "", "metadata": {}, "score": "38.9443"}
{"text": "For purposes of explanation , a current document d being processed will be referred to as URL 0 , and the target document of an outlink on document d will be referred to as URL 1 .That is , each link in the document collection has a pair of scores , an outlink score and an inlink score .", "label": "", "metadata": {}, "score": "38.98898"}
{"text": "In addition , for each such cluster , a counter is maintained and incremented each time a phrase in that cluster is added to the user model .These counts may be used as weights , as described below .Thus , the user model is built from phrases included in clusters that are present on a document that the user has expressed an interest in by accessing the document .", "label": "", "metadata": {}, "score": "39.19832"}
{"text": "The phrase identification server 250 continues through the rest of the phrases , devolving 4-word sequences into 3-word sequences , then into 2-word sequences .None of these subphrases will hit either threshold in this example .", "label": "", "metadata": {}, "score": "39.19938"}
{"text": "The training part is used to obtain the language model and phrase tables .The development set is used to estimate the log - linear weights . using MERT , and the test set is set aside during the estimation process in order to provide an unbiased estimate of the translation performance .", "label": "", "metadata": {}, "score": "39.207325"}
{"text": "Particular nodes are identified in the phrase tree that can be transformed into their logical equivalents .A cost function is applied to the existing node and its logical equivalent form ; the cost function provides an estimate of the inter - server communication cost for processing the node .", "label": "", "metadata": {}, "score": "39.294025"}
{"text": "A second scoring function is used during query processing .This second scoring function takes as input the phrase relevance scores for a set of documents , and the phrases of a query , and determines a final relevance score for each document .", "label": "", "metadata": {}, "score": "39.32556"}
{"text": "This arrangement allows for very fast checking of a word sequence to determine if it is a known phrase .In addition , for each phrase , an expected probability of the phrase in the index is maintained and updated , based on the frequency of the phrase and the number of documents in the index .", "label": "", "metadata": {}, "score": "39.350822"}
{"text": "In one embodiment of the information retrieval system , a bifurcated document relevance scoring model is provided .Here , the final document score for each document in the search results is based on two scoring functions .A first scoring function , a phrase relevance scoring function , is applied during document indexing .", "label": "", "metadata": {}, "score": "39.438496"}
{"text": "Given a search query , the system identifies the phrases present in the query , along with their related phrases , and their phrase extensions .For a given document , each sentence of the document has a count of how many of the query phrases , related phrases , and phrase extensions are present in the sentence .", "label": "", "metadata": {}, "score": "39.47834"}
{"text": "The procedure is similar to ( Chiang , 2007 ) except that we maintain tree structures on the target side , instead of strings .We use a statistical CFG parser to parse the English side of the training data , and extract dependency trees with Magerman 's rules ( 1995 ) .", "label": "", "metadata": {}, "score": "39.51552"}
{"text": "We will later analyze the contribution of each component to the overall score .The typical processing pipeline is as follows .Given a parallel training corpus , long sentences are filtered out , and the remaining material is lowercased and tokenized .", "label": "", "metadata": {}, "score": "39.60241"}
{"text": "Our results provide the first known empir - ical evidence that lexical semantics are in - deed useful for SMT , despite claims to the contrary . \" ...In this paper , we propose a novel string - todependency algorithm for statistical machine translation .", "label": "", "metadata": {}, "score": "39.634533"}
{"text": "This phrase - based machine translation approach relies on a specific representation of the translation process , such as the choice of contiguous word sequences ( phrases ) as basic units in the language and translation models .How far can this representation take us towards the target of improving translation quality ?", "label": "", "metadata": {}, "score": "39.693058"}
{"text": "Additionally , scoring functions that are applied to query completions can be improved or otherwise facilitated by using artificial intelligence - based components .[ 0094 ] .Such a classification can employ a probabilistic and/or statistical - based analysis ( for example , factoring into the analysis utilities and costs ) to predict or infer an action that a user desires to be automatically performed .", "label": "", "metadata": {}, "score": "39.744286"}
{"text": "The high performance observed in the train - on - test conditions shows that there exists at least one choice of tunable parameters with which the phrase - based translation system can deliver much higher performance .This is useful to bound the space of \" possible performances , ' ' although in ideal situations .", "label": "", "metadata": {}, "score": "39.758205"}
{"text": "For each document , there is a list of counts of the number of occurrences of the related phrases R of phrase g j that also appear in document d. .In one embodiment , the related phrase information is a related phase bit vector .", "label": "", "metadata": {}, "score": "39.86446"}
{"text": "We present an extensive experimental study of Phrase - based Statistical Machine Translation , from the point of view of its learning capabilities .Very accurate Learning Curves are obtained , using high - performance computing , and extrapolations of the projected performance of the system under different conditions are provided .", "label": "", "metadata": {}, "score": "39.96183"}
{"text": "Two techniques are employed : ( 1 ) simple string edit distance , and ( 2 ) a heuristic strategy that pairs initial ( presumably summary ) sentences from different news stories in the same cluster .We evaluate both datasets using a word alignment algorithm and a metric borrowed from machine translation .", "label": "", "metadata": {}, "score": "40.038315"}
{"text": "Of course , separate servers can be used for guide and search functions .[ 0072 ] .With reference to .FIGS .9 - 14 , flowcharts in accordance with various methods or procedures are presented .For example , those skilled in the art will understand and appreciate that a methodology could alternatively be represented as a series of interrelated states or events , such as in a state diagram .", "label": "", "metadata": {}, "score": "40.0532"}
{"text": "This evaluation is based on the combined phrase score , as well as the set of document phrase scores for the candidate phrase .In general , the phrase identification server 250 applies a rule that a candidate phrase is retained where : .", "label": "", "metadata": {}, "score": "40.057426"}
{"text": "An information retrieval system may also use the phrase information to identify and eliminate duplicate documents , either while indexing ( crawling ) the document collection , or when processing a search query .For a given document , each sentence of the document has a count of how many related phrases are present in the sentence .", "label": "", "metadata": {}, "score": "40.20494"}
{"text": "FIG .8 a ) , then a different step is taken to determine the inlink score .In this case , the indexing system 110 creates a related phrase bit vector for URL 1 for phrase A ( as if phrase A was present in URL 1 ) and indicating which of the related phrases of phrase A appear in URL 1 .", "label": "", "metadata": {}, "score": "40.2557"}
{"text": "2 In what follows we compare two strategies for unsupervised construction of such a corpus , one employing string similarity and the other associating sentences that may overlap very little at the s .. \" ...We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .", "label": "", "metadata": {}, "score": "40.25678"}
{"text": "The second method can use a set of acoustic phrases associated with an audioinputurilist attribute .This attribute can specify one or more URI 's for which audio can be retrieved .Retrieved audio can then be used for phrase enrollment purposes .", "label": "", "metadata": {}, "score": "40.263443"}
{"text": "More particularly , given a document accessed by user , the related phrases that are present in this document , are included in a user model or profile .During subsequent searches , the phrases in the user model are used to filter the phrases of the search query and to weight the document scores of the retrieved documents .", "label": "", "metadata": {}, "score": "40.311672"}
{"text": "In some cases , a selected portion of a text of a document is presented to provide the user with a glimpse of the document 's content .Direct \" Boolean \" matching of query terms has well known limitations , and in particular does not identify documents that do not have the query terms , but have related words .", "label": "", "metadata": {}, "score": "40.365654"}
{"text": "In many systems , queries may also tend towards long strings that can be unwieldy to enter .These and other factors can increase the time and effort needed to locate desired information .[ 0004 ] .User interfaces for search functions also impact both the ease of performing a search and the accuracy of search results .", "label": "", "metadata": {}, "score": "40.3873"}
{"text": "4.2 Collocation Correction with Phrase - based SMT We implement our approach in the fram ... . \" ...We report on efforts to build large - scale translation systems for eight European language pairs .We achieve most gains from the use of larger training corpora and basic modeling , but also show promising results from integrating more linguistic annotation .", "label": "", "metadata": {}, "score": "40.403164"}
{"text": "In an enrollment session , new acoustically provided phrases can be added to a personal grammar by initially providing a phrase , which may need to be repeated numerous times to ensure consistency is achieved for the phrase .If the new phrase does not clash with existing phrases in the personal grammar , a new phrase entry can be generated .", "label": "", "metadata": {}, "score": "40.44936"}
{"text": "Method according to . claim 1 , .Method according to . claim 1 , . wherein the number of performed recognition steps , obtained recognition results and/or received or recognized speech phrases ( SPj ) after which an adaptation of the current acoustic model ( CAM ) is performed is determined during the process of recognition or adaptation .", "label": "", "metadata": {}, "score": "40.492905"}
{"text": "An adaptation of the current acoustic model may take place after the receipt and/or recognition of every speech phrase and/or utterance or after a given number of them and in particular during the system and the method is online and in use .", "label": "", "metadata": {}, "score": "40.53122"}
{"text": "The bit vector value may also be used as a component in a more complex scoring function , and additionally may be weighted .The documents can then be ranked according to their document scores .Phrase information may also be used in an information retrieval system to personalize searches for a user .", "label": "", "metadata": {}, "score": "40.559513"}
{"text": "We investigate unsupervised techniques for acquiring monolingual sentence - level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web - based news sources .Two techniques are employed : ( 1 ) simple string edit distance , and ( 2 ) a heuristic strategy ... \" .", "label": "", "metadata": {}, "score": "40.562637"}
{"text": "Training the translation models requires several steps such as aligning words , computing the lexical translation , extracting and scoring the phrases , and creating the reordering model .When the models have been created , the development set is used to run the minimum error rate training ( MERT ) algorithm [ 17 ] to optimize their weights .", "label": "", "metadata": {}, "score": "40.672737"}
{"text": "As can be appreciated , each of these nodes could as well be complex nodes as well , with further child nodes , which are in likewise restructured .The query phrasification module 810 then generates all possible phrasification from the restructured word tree .", "label": "", "metadata": {}, "score": "40.687126"}
{"text": "The result is that clusters can be characterized \" local \" to each good phrase , and some clusters will then overlap by having one or more common related phrases .For a given good phrase g j then the ordering of the related phrases by information gain provides a taxonomy for naming the clusters of the phrase : the cluster name is the name of the related phrase in the cluster having the highest information gam .", "label": "", "metadata": {}, "score": "40.700172"}
{"text": "Finally , the top N ( e.g. , 5 ) sentences following the sort are used as the description of the document .This set of sentences can be formatted and included in the presentation of the document in the modified search results 703 .", "label": "", "metadata": {}, "score": "40.81022"}
{"text": "Method according to . claim 1 , .Method according to . claim 1 , . wherein the adaptation strength is set to be dependent on an elapsed period of time , a total number of received and/or recognized speech phrases ( SPj ) , a total number of adaptations performed on said current acoustic model ( CAM ) and/or the like .", "label": "", "metadata": {}, "score": "40.864494"}
{"text": "Clearly , all measures correlate strongly with each other , such that the choice of the performance measure is fairly arbitrary , as long as one is consistent .For this reason , we have chosen to use BLEU throughout this paper as it is the most widely used automatic score in machine translation .", "label": "", "metadata": {}, "score": "40.93411"}
{"text": "The indexing of documents by phrases and use of the clustering information provides yet another advantage of the indexing system 110 , which is the ability to determine the topics that a document is about based on the related phrase information .", "label": "", "metadata": {}, "score": "40.93622"}
{"text": "We begin with the context of the current research , and then move to a formal problem description and an overview of the four main subproblems : translational equivalence modeling , mathematical modeling , parameter estimation , and decoding .Along the way , we present a taxonomy of some different approaches within these areas .", "label": "", "metadata": {}, "score": "40.97805"}
{"text": "For each subset , a new instance of the PBSMT system has been created , for a total of 100 models .Each model has been tested on the test set and on a subset of 2,000 pairs the training set .", "label": "", "metadata": {}, "score": "41.24032"}
{"text": "For example , SVMs are configured by a learning or training phase within a classifier constructor and feature selection module .Thus , the classifier(s ) can be used to automatically perform a number of functions including , but not limited to , scoring suggestions for further refinement or improvement actions .", "label": "", "metadata": {}, "score": "41.26402"}
{"text": "Among possible methods , two stand out as particularly promising .The first is to generate phrase pairs by using grammatical or various linguistic rules ( e.g. , turning existing entries into new entries , by applying various forms of inflection ) .", "label": "", "metadata": {}, "score": "41.34396"}
{"text": "During training , known results are used to build a lattice of hierarchical categories taken from WordNet .These lattices are then compared to the novel lattices derived from the test four - tuples .The results of the system are 90.53 % correct attachment decisions .", "label": "", "metadata": {}, "score": "41.533184"}
{"text": "They are automatically filled during the training phase , when a bilingual corpus is used to identify both phrases and their probabilities .Since future translations are produced by maximizing a scoring function estimating translation quality , using the content of the two tables , we see that the contents of the translation and language models tables correspond to the tunable parameters of the learning system .", "label": "", "metadata": {}, "score": "41.57433"}
{"text": "In addition to the decoded phrase , the voice recognition engine can preferably provide other types of information to the voice navigator , which can be used for aiding the voice navigator in determining how the decoded phrase is to be used .", "label": "", "metadata": {}, "score": "41.749992"}
{"text": "The cost functions can be based on the tier assignments of each phrase , the length of each phrase , or a cost of a subtree of the node .An optimized phrase tree is then used as a query schedule by the index servers .", "label": "", "metadata": {}, "score": "41.78716"}
{"text": "Abstract .wherein for the process of recognition - in particular for a set of speech phrases ( SP 1 , . . ., SPN)-a current acoustic model ( CAM ) is used , . wherein said current acoustic model ( CAM ) is adapted during the recognition process based on at least one recognition result already obtained , and .", "label": "", "metadata": {}, "score": "41.81669"}
{"text": "Phrases are extracted from a document collection in a manner that identifies real phrases as used in by language users , as opposed to mere combinations of words .Generally , this is done by collecting a large body of word sequences that are candidates phrases based on the structural features in the documents .", "label": "", "metadata": {}, "score": "41.822826"}
{"text": "The retrieved documents are then presented to the user , typically in their ranked order , and without any further grouping or imposed hierarchy .In some cases , a selected portion of a text of a document is presented to provide the user with a glimpse of the document 's content .", "label": "", "metadata": {}, "score": "41.838005"}
{"text": "S(p ) : Number of all instances of the possible phrase ; and .M(p ) : Number of interesting instances of the possible phrase .These ( and other ) distinguishing appearances are indicated by various HTML markup language tags and grammatical markers .", "label": "", "metadata": {}, "score": "41.863056"}
{"text": "The stages of phrasification are as follows .The query phrasification module 810 receives from the user interface server 130 the Boolean word tree 800 .The query phrasification module 810 restructures 902 the word tree using de Morgan 's laws into an equivalent tree comprising a single top level OR node , each of the disjuncts being an AND of a number of leaf nodes and/or NOTs of leaf nodes .", "label": "", "metadata": {}, "score": "41.879154"}
{"text": "Accordingly , appropriate thresholds can be assigned to tiers 1 and 2 ( e.g. , 0 for tier 1 , and 1,000 for tier 2 ) , and all phrase posting lists with less than 1,000 documents therein are assigned to tier 1 .", "label": "", "metadata": {}, "score": "41.87966"}
{"text": "This unrealistic case is not affected by the Zipf 's law , because almost all the words necessary to translate the training material have , by definition , already been observed .The model is therefore able to match long phrases when producing the \" test on training set ' ' translations .", "label": "", "metadata": {}, "score": "41.92659"}
{"text": "We therefore reach the conclusion that estimating entries in the phrase translation tables is the dominant factor in determining performance .What controls the creation of phrase - translation tables ?This is mostly limited by Zipf 's law , since the probability of encountering phrases that have not been seen in the training set does not vanish even after observing very large corpora .", "label": "", "metadata": {}, "score": "41.9518"}
{"text": "Current phrase - based SMT systems perform poorly when using small training sets .This is a consequence of unreliable translation estimates and low coverage over source and target phrases .This paper presents a method which alleviates this problem by exploiting multiple translations of the same source phrase .", "label": "", "metadata": {}, "score": "41.960766"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a block diagram of the software architecture of one embodiment of the present invention .FIG .2 is a block diagram of the indexing system .FIG .3 is a flow diagram of a method for phrase extraction .", "label": "", "metadata": {}, "score": "42.01391"}
{"text": "A document is retrieved in response to a query containing a number of query terms , typically based on having some number of query terms present in the document .Very generally , this is done by decomposing the query into its individual terms , and the accessing the respective posting lists of the individual terms .", "label": "", "metadata": {}, "score": "42.031998"}
{"text": "II .Indexing System .In one embodiment , the indexing system 110 provides three primary functional operations : 1 ) identification of phrases and related phrases , 2 ) indexing of documents with respect to phrases , and 3 ) generation and maintenance of a phrase - based taxonomy .", "label": "", "metadata": {}, "score": "42.03707"}
{"text": "SUMMARY OF THE INVENTION .An information retrieval system and methodology uses phrases to index and search documents in the document collection .Phrases are also used to decompose inputs ( e.g. , queries ) into phrase trees , to schedule and optimize the execution of searches , to support the updating and maintenance of the indexes , and to support bifurcated relevance scoring of documents .", "label": "", "metadata": {}, "score": "42.07232"}
{"text": "b )The evaluation cost of a phrase node is equal to its one of the cost ( e.g. phrase posting list length or other a priori cost measure ) .c )The subtree cost of an AND node is defined as follows .", "label": "", "metadata": {}, "score": "42.10221"}
{"text": "For each candidate phrase , the phrase identification server 250 combines its document phrase scores into combined score to get a total measure of the support of the candidate phrase within the document collection .The combined score can be a sum , average , or other aggregate value of the individual document phrase scores .", "label": "", "metadata": {}, "score": "42.133133"}
{"text": "All models are used during search , i.e. they are incorporated directly into the log - linear model combination of the decoder .Phrase table smoothing with triplet lexicon models and with discriminative word lexicons are novel contributions .We also propose a new regularization technique for IBM model 1 by means of the Kullback - Leibler divergence with the empirical unigram distribution as regularization term .", "label": "", "metadata": {}, "score": "42.14042"}
{"text": "To be consistent and to avoid anomalies due to overfitting or particular data combinations , each set of pairs of sentences has been randomly sampled .The number of pairs is fixed , and a program selects them randomly from the whole original training , development , or test set using a uniform distribution .", "label": "", "metadata": {}, "score": "42.17284"}
{"text": "This approach generates an information retrieval score of the relevance of the phrase to the document itself .The information retrieval scoring algorithm can be the same as or different from the one used by the search system 110 for final document scoring .", "label": "", "metadata": {}, "score": "42.206726"}
{"text": "This yields an efficient algorithm for obtaining the exact solution of each line search in Powell 's method and therefore provides a way to iteratively optimize the log - linear weights . using MERT .A number of alternatives have been proposed , such as on - line discriminative training [ 19 , 20 ] .", "label": "", "metadata": {}, "score": "42.210327"}
{"text": "We achieve most gains from the use of larger training corpora and basic modeling , but also show promising results from integrating more linguistic annotation . \" ...In this paper , we investigate lexicon models for hierarchical phrase - based statistical machine translation .", "label": "", "metadata": {}, "score": "42.215332"}
{"text": "The second child , phrase B , is not a local child node , but is assigned to different index server .Under rule ( 2)(v)(2 ) , the index server A synthesizes a new query , ( [ explicit data ] AND B ) , as shown in .", "label": "", "metadata": {}, "score": "42.247936"}
{"text": "Development and test sets are fixed .One instance of the SMT system has been run for each of all possible combinations of the language and translation training data sizes .BLEU score value has been associated to each pair : language and translation set size .", "label": "", "metadata": {}, "score": "42.29437"}
{"text": "For each subset , a new instance of the PBSMT system has been created , for a total of 200 models .Two hundred experiments have then been run on an independent test set ( of 2,000 sentences , also not included in any other phase of the experiment ) .", "label": "", "metadata": {}, "score": "42.312767"}
{"text": "Additionally or alternatively , a user 's click on a low - ranked result can be taken as an indication that the suggested query was of poor quality and needs to be improved .[ 0055 ] .Feedback from a user can also be used immediately to improve search results , phrase suggestions , or both .", "label": "", "metadata": {}, "score": "42.334343"}
{"text": "Role of Training Set Size on Performance on New Sentences .In this section , we analyze how training set size affects the performance by creating learning curves ( BLEU score versus training set size ) .The general framework for this set of experiments consists of creating subsets of the complete corpus by subsampling from a uniform distribution without replacement .", "label": "", "metadata": {}, "score": "42.338863"}
{"text": "The algorithms and operations presented herein are not inherently related to any particular computer or other apparatus .Various general - purpose systems may also be used with programs in accordance with the teachings herein , or it may prove convenient to construct more specialized apparatus to perform the required method steps .", "label": "", "metadata": {}, "score": "42.344643"}
{"text": "The algorithms and operations presented herein are not inherently related to any particular computer or other apparatus .Various general - purpose systems may also be used with programs in accordance with the teachings herein , or it may prove convenient to construct more specialized apparatus to perform the required method steps .", "label": "", "metadata": {}, "score": "42.344643"}
{"text": "However the ideal case is seldom , if ever , realized and steps can be taken to improve completed queries and thereby improve the quality of search results that are presented to the user .[ 0091 ] .User feedback can be obtained in a variety of ways .", "label": "", "metadata": {}, "score": "42.413887"}
{"text": "a user interface that accepts a phrase and receives at least one suggestion based at least in part on the phrase ; and .a phrase suggestion engine that matches the phrase with the at least one suggestion .The system of .", "label": "", "metadata": {}, "score": "42.468636"}
{"text": "In a second embodiment , the search system 120 scores each document in the result set according which related phrases of the query phrase Q it contains .This is done as follows : .Given each query phrase Q , there will be some number N of related phrases Qr to the query phrase , as identified during the phrase identification process .", "label": "", "metadata": {}, "score": "42.508923"}
{"text": "Next , the meaning of a document is represented by the phrases associated with the page .As described above , given a query and document , the relevant phrases for the document are determined from the body scores ( the related bit vectors ) for all phrases indexed to the document .", "label": "", "metadata": {}, "score": "42.56528"}
{"text": "These accessed documents for the basis for selecting which phrases will become part of the user model .For each such accessed document , the search system 120 retrieves the document model for the document , which is a list of phrases related to the document .", "label": "", "metadata": {}, "score": "42.580265"}
{"text": "The log - linear parameters are then estimated by minimum error rate training ( MERT ) .The weights .is the set of sentence pairs over which MERT is performed .Solving ( 3 ) is difficult because the decoding necessary to produce the hypothesis translation is expensive .", "label": "", "metadata": {}, "score": "42.65942"}
{"text": "For example , the word tree : .( A OR B ) AND ( C OR D ) .is restructured to : .( A AND C ) OR ( A AND D ) OR ( B AND C ) OR ( B AND D ) .", "label": "", "metadata": {}, "score": "42.79772"}
{"text": "In addition , a given shard may be stored in duplicate at a number of index servers , so as to provide increased query processing capability .Another aspect of the storage arrangement for the phrase posting lists is the use of tiers .", "label": "", "metadata": {}, "score": "42.808155"}
{"text": "[ 0112 ] .In this regard , it will also be recognized that the disclosed and described components and methods can include a system as well as a computer - readable medium having computer - executable instructions for performing the acts and/or events of the various disclosed and described methods .", "label": "", "metadata": {}, "score": "42.88403"}
{"text": "This approach essentially requires that a document have the query phrases that are included in the user model in order to be highly ranked .As an alternative embodiment , which does not impose the foregoing tight constraint , the mask bit vector can be cast into array , so that each bit is used to weight the cluster counts for the related phrases in the user model .", "label": "", "metadata": {}, "score": "42.912533"}
{"text": "There are shown in the drawings , embodiments which are presently preferred , it being understood , however , that the invention is not limited to the precise arrangements and instrumentalities shown .FIG .1 is a schematic diagram of a system that permits acoustically provided phrases to be enrolled using VoiceXML code that natively supports voice enrolled grammars in accordance with an embodiment of the inventive arrangements disclosed herein .", "label": "", "metadata": {}, "score": "42.929565"}
{"text": "Phrases are also used to cluster documents in the search results , create document descriptions , and eliminate duplicate documents from the search results , and from the index . selecting a first document and a second document from a set of documents ; . comparing , by operation of a processor adapted to manipulate data within a computer system , a document description of the first document with a document description of the second document , . wherein the document description of the first document comprises a selected subset of sentences of the first document , the sentences being selected and ordered in the document description as a function of a number of related phrases in the selected sentences , . wherein the document description of the second document comprises a selected subset of sentences of the second document , the sentences being selected and ordered in the document description as a function of a number of related phrases in the selected sentences , . responsive to the document description of the first document matching the document description of the second document , identifying the first document and the second document as duplicate documents in the set of documents .", "label": "", "metadata": {}, "score": "42.979668"}
{"text": "Figure 3 : Chinese - English learning curve obtained using UN corpus and Portage .In all the figures , the curves are increasing linearly or slightly more slowly than that , suggesting a learning curve that is \" at best ' ' logarithmically increasing with the training set size .", "label": "", "metadata": {}, "score": "42.979736"}
{"text": "This is useful because the language model feature typically favours shorter sentences ( because each additional trigram can only lower the language model probability ) .This is a simple , yet effective feature .The process of training a machine translation system involves estimating the various parameters of the model : the log - linear parameters . as well as the parameters internal to the feature functions , such as the phrase translation probabilities and language model n -gram and backoff probabilities .", "label": "", "metadata": {}, "score": "43.05612"}
{"text": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .This method requires a source - language dependency parser , target language word segmentation and an unsupervised word alignment component .", "label": "", "metadata": {}, "score": "43.110207"}
{"text": "Our findings are also consistent with the curves presented by [ 33 ] , although their results are limited to a much lower data set size ( less than . sentences ) and presented on a linear scale .Incidentally , that paper also presents a recent attempt into using active learning for improving MT and meets the challenge of \" diminishing returns ' ' identified in the learning curves : a constant performance improvement requires increasing amounts of data .", "label": "", "metadata": {}, "score": "43.11586"}
{"text": "A further set documents that can be used for this process are the search query logs for the system 100 , which comprise a large set of search queries .In this case , text breaks are indicated by syntactic objects in the query ( e.g. , quotation marks , Boolean operators such as AND , NOT , and OR , and similar operators ) or other visual separations such as punctuation marks .", "label": "", "metadata": {}, "score": "43.263695"}
{"text": "In this manner , for a given document and a given phrase , the related phrase information can be used to score the document .The value of the bit vector itself ( as a value ) may be used as the document score .", "label": "", "metadata": {}, "score": "43.281517"}
{"text": "Depending on the implementation , either of these components can be the primary sort key , and the other can be the secondary sort key .The sorted results are then presented to the user .Sorting the documents on the outbound score component makes documents that have many related phrases to the query as anchor hits , rank most highly , thus representing these documents as \" expert \" documents .", "label": "", "metadata": {}, "score": "43.296543"}
{"text": "This results in a set of related phrases which related to the query or the user , called set Qu .Now , the presentation system 130 uses this ordered list of phrases as the basis for ranking the sentences in each document in the search results , in a manner similar to the general document description process described above .", "label": "", "metadata": {}, "score": "43.32901"}
{"text": "A typical implementation will have between 10 and 1000 segments , depending on the number of documents in the document collection .As described above , the indexing server master 260 creates the index by processing a set of documents from the document collection , and in each document , identifying which phrases are related to the document .", "label": "", "metadata": {}, "score": "43.41722"}
{"text": "Phrases are assigned to tiers using a phrase assignment function that represents the query processing costs for a given phrase posting list , and assigns phrases of similar cost to the same tier .The use of shards can take advantage of the tiers of the index servers .", "label": "", "metadata": {}, "score": "43.43935"}
{"text": "The method involves analyzing a target application program ( 22 ) to determine a plurality of target application states ( 24 ) .Method for implementing a multi - action voice macro ( 140 ) for a voice recognition navigator program ( 102 ) on a computer system .", "label": "", "metadata": {}, "score": "43.492096"}
{"text": "It is generally acknowledged that the performance of rule - based machine translation ( RMBT ) systems can be greatly improved through domain - specic system adaptation .To that end , RBMT users often choose to invest signicant re - sources into the development of ad hoc MT dictionaries .", "label": "", "metadata": {}, "score": "43.537266"}
{"text": "It is generally acknowledged that the performance of rule - based machine translation ( RMBT ) systems can be greatly improved through domain - specic system adaptation .To that end , RBMT users often choose to invest signicant re - sources into the development of ad hoc MT dictionaries .", "label": "", "metadata": {}, "score": "43.537266"}
{"text": "From the related phrase bit vector , we can determine primary and secondary topics for the document d. A primary topic is indicated by a bit pair ( 1,1 ) , and a secondary topic is indicated by a bit pair ( 1,0 ) .", "label": "", "metadata": {}, "score": "43.578445"}
{"text": "[ 0005 ] .The following presents a simplified summary in order to provide a basic understanding .This summary is not an extensive overview .It is neither intended to identify key or critical elements nor to delineate scope .Its sole purpose is to present some concepts in a simplified form as a prelude to a more detailed description that is presented later .", "label": "", "metadata": {}, "score": "43.59853"}
{"text": "4 illustrates a method of identifying related phrases .FIG .5 illustrates a method of indexing documents for related phrases .FIG .6 illustrates a method of retrieving documents based on phrases .FIG .7 illustrates operations of the presentation system to present search results .", "label": "", "metadata": {}, "score": "43.716568"}
{"text": "The document description can then be presented to the user when the document is included in search results , so that the user obtains a better understanding of the document , relative to the query .A further refinement of this process of generating document descriptions allows the system to provide personalized descriptions , that reflect the interests of the user .", "label": "", "metadata": {}, "score": "43.763763"}
{"text": "The related phrase information of a given phrase is preferably stored in a format , such as a bit vector , which expresses the relative significance of each related phrase to the given phrase .For example , a related phrase bit vector has a bit for each related phrase of the given phrase , and the bits are ordered according to the prediction measures ( e.g. , information gain ) for the related phrases .", "label": "", "metadata": {}, "score": "43.768074"}
{"text": "First , the presentation system 130 ranks the sentences of the document by the number of instances of query phrases Q , related query phrases Qr , and phrase extensions Qp , thereby maintaining for each sentence of a document counts of these three aspects .", "label": "", "metadata": {}, "score": "43.788048"}
{"text": "The phrase posting lists in each tier will be stored in one or more index servers associated therewith .Thus , a number M of tiers are established , each tier associated with a set of index servers .For example , a system can be arranged with first , second and third tiers , though additional tiers can be used .", "label": "", "metadata": {}, "score": "43.878372"}
{"text": "Referring again to .FIG .1 , the front end server 140 ranks the documents in the result set , using a ranking function .As noted above , the phrase posting lists can contain for each document an information retrieval score .", "label": "", "metadata": {}, "score": "43.889133"}
{"text": "Our results suggest that performance , as measured by BLEU , increases by a constant factor for each doubling of the data .Although that factor varies depending on corpus and language pair , this result seems consistent over all experimental conditions we tried .", "label": "", "metadata": {}, "score": "43.89885"}
{"text": "The packaging of the set of results also can vary greatly in forming content depending upon a specific implementation .For example , results can be formatted as a set of documents that are represented by hyperlinks that can be clicked on by a user to access the specific results within the result set .", "label": "", "metadata": {}, "score": "43.93917"}
{"text": "Another aspect of the information retrieval system is a method of phrasification , which is identifying a set of phrases within any input text comprising a set of terms ( and optionally operators ) , such as input search queries .An input text is accepted in the form of a Boolean tree of words and operators ( either express or inferred ) .", "label": "", "metadata": {}, "score": "43.947556"}
{"text": "One of our key findings is that the current performance of phrase - based statistical machine translation systems is not limited by the representation power of the hypothesis class , but rather by model estimation from data .In other words , we demonstrate that parameter choices exist that can deliver significantly higher performance , but that inferring them from finite samples is the problem .", "label": "", "metadata": {}, "score": "43.972977"}
{"text": "Next , the inlink score is determined as follow .For each inlink to URL 1 containing the anchor phrase A , the indexing system 110 scans URL 1 , and determines whether phrase A appears in the body of URL 1 .", "label": "", "metadata": {}, "score": "43.996582"}
{"text": "The relationship of the tiers to each other with respect to the number of shards therein can also be beneficially selected to further improve query processing .Thus , the number of shards increases from the first tier to the last tier .", "label": "", "metadata": {}, "score": "44.0555"}
{"text": "In other instances , certain structures and devices are shown in block diagram form in order to facilitate description .[ 0028 ] .Further , it should be noted that although specific examples presented herein include or reference specific components , an implementation of the components and methods disclosed and described herein is not necessarily limited to those specific components and can be employed in other contexts as well .", "label": "", "metadata": {}, "score": "44.105846"}
{"text": "This process is repeated across the document set for the indexing pass .Typically , an indexing pass can analyze between one and billions of documents , as desired by the system implementer .This process can be implemented as follows , for a given document .", "label": "", "metadata": {}, "score": "44.169754"}
{"text": "The document descriptions can be either general or personalized to the user .a ) General Topic Document Descriptions .As before , given a query , the search system 120 has determined the related query phrases Qr and the phrase extensions of the query phrases as well , and then identified the relevant documents for the query .", "label": "", "metadata": {}, "score": "44.211136"}
{"text": "The heuristic rules eliminate candidate phrases that begin with certain words ( e.g. , \" or \" , \" and \" , etc ) and other artifacts from the above screening process .Additionally , other refinement techniques may be applied , such as the use of generative language models to further analyze the documents and identify good or bad phrases , for example language specific models of grammar and syntax .", "label": "", "metadata": {}, "score": "44.26237"}
{"text": "16 .[ 0036 ] .In these and other environments , the disclosed and described components and methods can be used to assist data entry tasks and potentially overcome data entry errors , for example , in the misrecognition of a spoken word entry , among others , by suggesting phrases .", "label": "", "metadata": {}, "score": "44.280697"}
{"text": "This significance information can include an information retrieval score for the phrase with respect to the document , as well as other information ; the information retrieval scoring algorithm can be the same as that used during ranking of search results , or a different algorithm .", "label": "", "metadata": {}, "score": "44.28866"}
{"text": "SUMMARY OF THE INVENTION .This present invention extends the VoiceXML language model to natively support voice enrolled grammars .Specifically , three VoiceXML tags can be added to the language model to add , modify , and delete acoustically provided phrases to voice enrolled grammars .", "label": "", "metadata": {}, "score": "44.306488"}
{"text": "In any case , the addition of massive amounts of data from the same distribution will result in small improvements in the performance .The small error bars that we have obtained also allow us to regard the stability of the SMT when trained on the same training set size .", "label": "", "metadata": {}, "score": "44.338593"}
{"text": "An information retrieval system indexes documents in the document collection by the valid or good phrases .For each phrase , a posting list identifies the documents that contain the phrase .In addition , for a given phrase , a second list , vector , or other structure is used to store data indicating which of the related phrases of the given phrase are also present in each document containing the given phrase .", "label": "", "metadata": {}, "score": "44.350727"}
{"text": "The method of . claim 13 , further comprising presenting results that are based at least in part upon the query .A system for guiding a search for information stored in a machine - readable format , comprising : . means for creating a suggestion from a phrase entered by a user at a user interface ; and .", "label": "", "metadata": {}, "score": "44.35172"}
{"text": "This phrase list is updated to the phrase data 255 .Each phrase is assigned a unique phrase numerical identifier ; the phrase identifier can be a hash of the phrase , using SHA-1 or a similar hash function , to generate a unique value .", "label": "", "metadata": {}, "score": "44.380253"}
{"text": "FIGS .12A and 12B further explains the advantages of the tiers and shards during query processing .The AND node is scheduled at the same server as phrase A , that is at index server A. The pattern of execution is described below .", "label": "", "metadata": {}, "score": "44.394676"}
{"text": "Once the active vocabulary has been retrieved by the voice navigator , it is preferably provided to a voice recognition engine software program , which will decode spoken utterances which correspond to the active vocabulary .Upon recognizing a spoken utterance .", "label": "", "metadata": {}, "score": "44.406708"}
{"text": "For a given user , the lists will be empty the first time the user provides a query .Next , a query q is received from the user .The related phrases Qr of q are retrieved , along with the phrase extensions , in the manner described above .", "label": "", "metadata": {}, "score": "44.492867"}
{"text": "One way to achieve this could be to either introduce an oracle to which the system can ask for annotation when needed or a process that uses linguistic knowledge to create new table entries based on existing table entries and some grammatical rules .", "label": "", "metadata": {}, "score": "44.555504"}
{"text": "The scoring function provides a scaled score ( e.g. , 0 - 100 ) that takes into consideration the location of each word sequence and its position , and optionally its typeface characteristics .In one embodiment , word sequences that are \" exact \" position hits are most highly scored , followed by \" initial \" hits , \" medial hits \" , and then \" final \" hits .", "label": "", "metadata": {}, "score": "44.62095"}
{"text": "This arrangement is beneficial since during query processing , the phrases in the query can be selectively processed only by those index servers 200 in the tiers that contain the phrase posting lists for those phrases .Once a phrase posting list is assigned to a tier , it is stored in one or more the index servers 200 in the tier , as illustrated in .", "label": "", "metadata": {}, "score": "44.622288"}
{"text": "b )Personalized Topic Based Document Descriptions .In embodiments where personalization of the search results is provided , the document descriptions can likewise be personalized to reflect the user interests as expressed in the user model .The presentation system 130 does this as follows .", "label": "", "metadata": {}, "score": "44.636616"}
{"text": "Abstract .The present invention extends the VoiceXML language model to natively support voice enrolled grammars .Specifically , three VoiceXML tags can be added to the language model to add , modify , and delete acoustically provided phrases to voice enrolled grammars .", "label": "", "metadata": {}, "score": "44.649643"}
{"text": "First , a query processing cost measure is selected which represents some cost for the index servers 200 when processing queries against a phrase posting list .The cost measure may be a direct measure of processing time , communication times or bandwidth , memory requirements , or the like .", "label": "", "metadata": {}, "score": "44.805305"}
{"text": "Finally , tier 3 stores 100 phrase posting lists , but across 1,000 shards .Again , the number of shards in this tier is an integer multiple of the number of shards in the previous tier .The assignment of phrases to tiers can be implemented in various ways .", "label": "", "metadata": {}, "score": "44.906166"}
{"text": "Of course , other types of computers can be used , and it is expected that as more powerful computers are developed in the future , they can be configured in accordance with the teachings here .Phrase Extraction .The first function of the indexing system 110 is to identify valid phrases for use in indexing documents ; this process is called phrase extraction , since it seeks to extract valid ( or \" real \" ) phrases from the document collection .", "label": "", "metadata": {}, "score": "44.947292"}
{"text": "A query schedule based on the phrases is created from the phrases , and then optimized to reduce query processing and communication costs .The execution of the query schedule is managed to further reduce or eliminate query processing operations at various ones of the index servers .", "label": "", "metadata": {}, "score": "44.96864"}
{"text": "The phrase tree is processed with a set of scheduling rules that assign each phrase only to the index servers which serve the shard containing the phrase .Thus , instead of having every index server process a phrase , only the index servers that contain the document in their respective shards will do so .", "label": "", "metadata": {}, "score": "45.03594"}
{"text": "The documents are than ranked based on the final score .Additional document information can be associated with each document from the document information server 150 .This embodiment enables the phrase posting lists to store a very small amount of data for each document .", "label": "", "metadata": {}, "score": "45.04315"}
{"text": "Each sub - context tree is preferably comprised of a plurality of sub - context objects .As explained in greater detail below , each sub - context object is preferably comprised of a data set which includes a plurality of sub - context attributes .", "label": "", "metadata": {}, "score": "45.04631"}
{"text": "identify the phrases of each selected phrasification as valid phrases for the input text ; and .one or more processors configured for executing the instructions .The system of . claim 19 , wherein decomposing the input text comprises : .", "label": "", "metadata": {}, "score": "45.07628"}
{"text": "FIG .1 is block diagram of the software architecture of one embodiment of the present invention .FIG .2 illustrates a method of identifying phrases in documents .FIG .3 illustrates a document with a phrase window and a secondary window .", "label": "", "metadata": {}, "score": "45.160404"}
{"text": "Alternatively , the user model for a given user may be persisted over time , and then down - weighted or aged .IV .Result Presentation .The presentation system 130 receives the scored and sorted search results from the search system 120 , and performs further organizational , annotation , and clustering operations prior to presenting the results to the user .", "label": "", "metadata": {}, "score": "45.18553"}
{"text": "Clusters are identified from related phrases that have very high prediction measure between all of the phrases in the cluster .Clusters can be used to organize the results of a search , including selecting which documents to include in the search results and their order , as well as eliminating documents from the search results .", "label": "", "metadata": {}, "score": "45.21919"}
{"text": "These and other actions manifest a higher level of interest in the document .When another query is received from the user , the related query phrases Qr are retrieved .These related query phrases Qr are intersected with the phrases listed in the user model to determine which phrases are present in both the query and the user model .", "label": "", "metadata": {}, "score": "45.225834"}
{"text": "According to a further adavantageous embodiment of the inventive method for recognizing speech an adaptation of the current acoustic model is repeatedly performed in each case after given numbers of performed recognition steps and/or obtained recognition results .Further , an adaptation of said current acoustic model can be repeatedly performed in each case after given numbers of received and/or recognized speech phrases .", "label": "", "metadata": {}, "score": "45.288155"}
{"text": "Next , the query phrasification module 810 scores 906 each phrasification , using the expected probability of each phrase in the phrasification , as obtained from the phrase data 255 .In some cases , the probability for a phrase is zero since it is not contained in the phrase data , and hence is not a real phrase .", "label": "", "metadata": {}, "score": "45.31959"}
{"text": "A phrase assignment function assigns a phrase to a tier using attributes of the phrase posting list , such as its length , and the capacities of the available index servers ( e.g. , their available memory , processing speed , and the like ) .", "label": "", "metadata": {}, "score": "45.33933"}
{"text": "Generally then , the phrase identification server 250 identifies a word sequence as a good candidate phrase if its score is above an initial phrase identification threshold .This threshold may be a function of the number of words in the sequence , so that the threshold value is lower for longer sequences , since very meaningful long phrases occur more rarely than short ones .", "label": "", "metadata": {}, "score": "45.34535"}
{"text": "Using long phrases will help when the system has to translate sequences of words that match what was encountered in the training corpus , but this becomes increasingly unlikely as the phrases become longer .On the other hand , short sentences are more often reused , but may also be more ambiguous and lead to errors more often .", "label": "", "metadata": {}, "score": "45.473682"}
{"text": "The results set , or least a portion thereof , is presented to a user at process block 1260 .At decision block 1270 , a determination is made whether the suggested query has been modified from its original form .Such modification can take place because of the operation of the dynamic search client that incrementally or continually refines or updates a phrase that is created or entered by a user .", "label": "", "metadata": {}, "score": "45.5577"}
{"text": "The query execution stage takes advantage of the sharding of the phrase posting lists to minimize inter - server communications cost , both in terms of reducing the size of the document lists transmitted between index servers , as well as eliminating any processing that would return null results .", "label": "", "metadata": {}, "score": "45.569866"}
{"text": "The method according to claim 1 wherein said sub - context object path is defined by a series of digits in said link field which identify the ordinal value assigned to each sub - context object , relative to the sub - context object 's parent , at each level along the path .", "label": "", "metadata": {}, "score": "45.626053"}
{"text": "In conventional methods for recognizing speech a current acoustic model is used for the process of recognition , in particular for a set of given speech phrases to be recognized within an incoming speech flow .The implemented current acoustic model contains information which is relevant for the recognition process per se , in particular for all potential speakers ( speaker - independent recognition ) .", "label": "", "metadata": {}, "score": "45.790443"}
{"text": "I. . ... andard word alignment and translation models described in Section IV - A1 .The system also used two large language models , both trained on the same data : a 4-gram language model using modified Kneser - Ney smoothing , and a suffix array language model with arbitrary history l .. \" ...", "label": "", "metadata": {}, "score": "45.823685"}
{"text": "In many cases , certain documents , while having different content from each other , are sufficiently related to form a meaningful group of related documents , essentially a cluster .Most users however , do not review beyond the first 30 or 40 documents in the search results .", "label": "", "metadata": {}, "score": "45.87107"}
{"text": "Upon such identification , the classifier can trigger a completion task automatically .[ 0095 ] .A support vector machine ( SVM ) is an example of a classifier that can be employed .The SVM operates by finding a hypersurface in the space of possible inputs , which hypersurface attempts to split the triggering criteria from the non - triggering events .", "label": "", "metadata": {}, "score": "45.96257"}
{"text": "A further aspect of the indexing system 110 is the ability to annotate 504 each document d during the indexing process with information that provides for improved ranking during subsequent searches .The annotation process 506 is as follows .A given document d in the document collection may have some number of outlinks to other documents .", "label": "", "metadata": {}, "score": "45.96836"}
{"text": "The context of a whole corpus of automatic translations rather than a single sentence is taken into account in order to achieve high alignment quality .The confusion network is rescored with a special language model , and the consensus translation is extracted as the best path .", "label": "", "metadata": {}, "score": "46.00437"}
{"text": "At best , some prior systems will index documents with respect to a predetermined and very limited set of ' known ' phrases , which are typically selected by a human operator .Indexing of phrases is typically avoided because of the perceived computational and memory requirements to identify all possible phrases of say three , four , or five or more words .", "label": "", "metadata": {}, "score": "46.04606"}
{"text": "\" This helps ensure that the user 's most likely search is in fact executed .The related phrase information may also be used by the system to identify or select which documents to include in the search result .The related phrase information indicates for a given phrase and a given document , which related phrases of the given phrase are present in the given document .", "label": "", "metadata": {}, "score": "46.048027"}
{"text": "In each case , we count the number of phrases of each length that were actually used to produce the translation .The right panel of Figure 5 reports these distribution .It shows that , while the models use a fair amount of longer phrases to translate the training material , these longer phrases are essentially never used for translating the test set : 98 % of the phrases are 5-grams or shorter .", "label": "", "metadata": {}, "score": "46.078224"}
{"text": "f .N . )i .N .P .p .i . )C .p .i . ) where , . where .The \u03b1 and \u03b2 parameters are adjusted by the system designer to trade off the precision and recall of the resulting search for the phrasification .", "label": "", "metadata": {}, "score": "46.079937"}
{"text": "Although many language pairs would yield different translation performance , in this paper , we are not interested in the translation performance per se : we focus our attention on analyzing the SMT system as a learning system .Since our goal was to obtain high - accuracy learning curves , that can be trusted both for comparing different system settings and to extrapolate performance under unseen conditions , we conducted a large - scale series of tests , to reduce uncertainty in the estimations and to obtain the strongest possible signals .", "label": "", "metadata": {}, "score": "46.104942"}
{"text": "This query phrase and all of its sub - phrases is removed from the list of candidates , and the list is resorted and the process repeated .The result of this process is a set of valid query phrases Qp .", "label": "", "metadata": {}, "score": "46.12686"}
{"text": "[0075 ] .FIG .10 is a flow diagram showing processing of a method 1000 that can be used in accordance with certain disclosed components .Processing begins at START block 1005 and proceeds to process block 1010 where a phrase is received .", "label": "", "metadata": {}, "score": "46.142075"}
{"text": "A candidate phrase is also retained where it is moderately supported , as indicated by having a combined phrase score above a second predetermined threshold .This shows that the candidate phrase has a sufficient widespread use to be considered a real phrase .", "label": "", "metadata": {}, "score": "46.1519"}
{"text": "is received and preprocessed to a sequence of representing signals . . ., RSj , . . . .FIG .2 shows in more detail the processing within the embodiment of .FIG .1 also by means of a schematical block diagram .", "label": "", "metadata": {}, "score": "46.185448"}
{"text": "FIG .2 is a flow chart illustrating the process for developing a sub - context tree for target applications according to the method of the invention .FIG .3 is a block diagram showing an application program having a plurality of application states .", "label": "", "metadata": {}, "score": "46.224545"}
{"text": "CROSS REFERENCE TO RELATED APPLICATIONS .The application is related to the following co - pending applications : .Phrase Identification in an Information Retrieval System , application Ser .No .10/900,021 , filed on Jul. 26 , 2004 ; .", "label": "", "metadata": {}, "score": "46.287548"}
{"text": "The second bit position stores a flag that indicates whether a related phrase g l of g k is also present in document d. It is useful to note that for a given phrase g , the length of the related phrase bit vector , and the association of the related phrases to the individual bits of the vector , will be the same with respect to all documents containing g. This implementation has the property of allowing the system to readily compare the related phrase bit vectors for any ( or all ) documents containing g , to see which documents have a given related phrase .", "label": "", "metadata": {}, "score": "46.296654"}
{"text": "In the case of the root query execution module 830 , the merged document list serves as the search result set . 2 ) If the current node is scheduled at the current server , then the following rules are used .", "label": "", "metadata": {}, "score": "46.373005"}
{"text": "263 - 311 , 1994 .View at Google Scholar .P. Koehn , F. J. Och , and D. Marcu , \" Statistical phrase - based translation , \" in Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology , pp .", "label": "", "metadata": {}, "score": "46.37683"}
{"text": "As a result , this data - driven clustering of related phrases avoids the biases that are inherent in any manually directed \" editorial \" selection of related terms and concepts , as is common in many systems .Indexing Documents with Phrases and Related Phrases .", "label": "", "metadata": {}, "score": "46.39662"}
{"text": "Now , documents from each cluster can be presented to the user in various ways .In one application , a fixed number of documents from each cluster can be presented , for example , the 10 top scoring documents in each cluster .", "label": "", "metadata": {}, "score": "46.411434"}
{"text": "In this manner multiple word phrases , for example phrases of four , five , or more terms , can be identified .This avoids the problem of having to identify and index every possible phrases resulting from the all of the possible sequences of a given number of words .", "label": "", "metadata": {}, "score": "46.434307"}
{"text": "First , if the candidate phrase 's score is below the strong phrase threshold , the phrase identification server 250 applies the following rules for scoring the child phrases : .If the candidate phrase hit position was \" exact \" and had a score of X , the first child is indicated as an initial hit position with score X , and the second child is indicated as a final hit position with score X. .", "label": "", "metadata": {}, "score": "46.484665"}
{"text": "6 illustrates the main functional operations of the search system 120 : .600 : Identify phrases in the query .602 : Retrieve documents relevant to query phrases .604 : Rank documents in search results according to phrases .The details of each of these of these stages is as follows .", "label": "", "metadata": {}, "score": "46.515106"}
{"text": "This implementation has the property that related phrases that have multiple or one - way information gain appear in the same cluster .An example of the cluster bit vectors are as follows , using the above phrases : .To summarize then , after this process there will be identified for each good phrase g j , a set of related phrases R , which are sorted in order of information gain I(g j , g k ) from highest to lowest .", "label": "", "metadata": {}, "score": "46.528908"}
{"text": "When summed and sorted over the search results , the most frequently occurring related phrases Qr will be indicated , each of which will be a cluster of documents .The most frequently occurring related phrase is the first cluster , which takes as its name its related phrase Qr , and so on for the top three to five clusters .", "label": "", "metadata": {}, "score": "46.551903"}
{"text": "We investigate the learning - theoretic implications of this setting , including the interplay between approximation error and estimation error , model selection , and accuracy in parameters estimation .We do not address more general themes about the opportunity for SMT to be evaluated by automatic metrics .", "label": "", "metadata": {}, "score": "46.657032"}
{"text": "In a further preferred embodiment of the inventive method for recognizing speech an adaptation of said current acoustic model is repeatedly performed after each fixed and/or predetermined number of performed recognition steps . obtained recognition results and/or received / recognized speech phrases , in particular after each recognition step / result and/or received / recognized speech phrase .", "label": "", "metadata": {}, "score": "46.679066"}
{"text": "An information retrieval system uses phrases to index , retrieve , organize and describe documents .Phrases are identified that predict the presence of other phrases in documents .Documents are the indexed according to their included phrases .Related phrases and phrase extensions are also identified .", "label": "", "metadata": {}, "score": "46.6951"}
{"text": "We also provide insight into the way statistical machine translation learns from data , including the respective influence of translation and language models , the impact of phrase length on performance , and various unlearning and perturbation analyses .Our results support and illustrate the fact that performance improves by a constant amount for each doubling of the data , across different language pairs , and different systems .", "label": "", "metadata": {}, "score": "46.73831"}
{"text": "Method according to . claim 10 , . wherein the threshold number ( t j ) is set for each of said speech phrases ( SPj ) independently .Method according to . claim 10 , . wherein said threshold numbers ( t j ) are predetermined , fixed and/or changed and varied during the processes of recognition and/or of adaptation .", "label": "", "metadata": {}, "score": "46.75393"}
{"text": "Up to six state - of - the - art statistical phrase - based translation systems from different project partners were combined in the experiments .Significant improvements in translation quality from Spanish to English and from English to Spanish in comparison with the best of the individual MT systems were achieved under official evaluation conditions .", "label": "", "metadata": {}, "score": "46.756508"}
{"text": "Specific instances of assistance or guidance during creation of the query can dynamically change in response to user additions to , or refinements of , the query .[0007 ] .A search system includes a dynamic user interface that guides a user through the creation of a search query .", "label": "", "metadata": {}, "score": "46.791885"}
{"text": "FIG .14 is a flow diagram showing processing of a method that can be used in conjunction with components disclosed or described herein .[ 0024 ] .FIG .15 is a schematic block diagram of a sample - computing environment .", "label": "", "metadata": {}, "score": "46.87462"}
{"text": "If a hit is encountered that would result in a single word being written out as a text break , than that hit is ignored , and the phrase identification server 250 continues to the next word in the document .The location can be indicated by section indicators ( e.g. title , body , list , table ) or word position .", "label": "", "metadata": {}, "score": "46.93331"}
{"text": "Removing these weak good phrases results in a very robust likely of good phrases .To identify good phrases , a predictive measure is used which expresses the increased likelihood of one phrase appearing in a document given the presence of another phrase .", "label": "", "metadata": {}, "score": "46.962086"}
{"text": "We also believe that in this particular situation , the presence of the error bars may help to better understand the stability of the system .Using the framework described above , four different settings have been set to produce learning curves , see Table 3 .", "label": "", "metadata": {}, "score": "46.979782"}
{"text": "12A and .FIG .12B illustrate an example of query execution on one or more index servers .The figures depict a preferred embodiment of the present invention for purposes of illustration only .One skilled in the art will readily recognize from the following discussion that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles of the invention described herein .", "label": "", "metadata": {}, "score": "47.001686"}
{"text": "Consequently , the user receives a much more diversified and robust set of results , and does not have to waste time reviewing documents that are duplicates of each other .The presentation system 130 provides the functionality as follows .The presentation system 130 processes each document in the search result set 701 .", "label": "", "metadata": {}, "score": "47.044907"}
{"text": "This article describes a machine translation system based on an automatic post - editing strategy : initially translate the input text into the target - language using a rule - based MT system , then automatically post - edit the output using a statistical phrase - based system .", "label": "", "metadata": {}, "score": "47.117054"}
{"text": "This article describes a machine translation system based on an automatic post - editing strategy : initially translate the input text into the target - language using a rule - based MT system , then automatically post - edit the output using a statistical phrase - based system .", "label": "", "metadata": {}, "score": "47.117054"}
{"text": "If there are multiple hits on the same sequence of words , the phrase identification server 250 keeps all of this information in the phrase map table .The phrase identification server 250 also may apply linguistic rules to the text break to further categorize it .", "label": "", "metadata": {}, "score": "47.190228"}
{"text": "Some will be quick to point out that maximizing , for example , BLEU may neither be necessary for , nor guarantee good translation performance .Although we acknowledge that automatic MT metrics may not tell the whole story as far as translation quality is concerned , our systematic study aims at characterizing the behaviour of SMT systems that are built by maximizing such metrics .", "label": "", "metadata": {}, "score": "47.218285"}
{"text": "II .Indexing System .The indexing system 110 provides three primary functional operations : 1 ) identification of phrases 2 ) indexing of documents with respect to phrases , and 3 ) generation and maintenance of the phrase - based indices .", "label": "", "metadata": {}, "score": "47.244385"}
{"text": "R. Zens , F.-J. Och , and H. Ney , \" Phrase - based statistical machine translation , \" in Proceedings of the 25th Annual German Conference on AI ( KI ' 02 ) , pp .18 - 32 , Springer , London , UK , 2002 .", "label": "", "metadata": {}, "score": "47.29613"}
{"text": "FIG .3 illustrates an overall flow diagram of the phrase extraction process .There are four basic stages the phrase identification process : .302 : Extract initial set of candidate phrases ; .304 : Identify valid phrases based on document collection information ; .", "label": "", "metadata": {}, "score": "47.34009"}
{"text": "The strength of adaptation and its dependence on the adaptation numbers and/or occurrence numbers is chosen in a way so as to decrease the influence of frequently occuring speech phrases in the received speech flow on the adatation process with respect to the current acoustic model .", "label": "", "metadata": {}, "score": "47.358936"}
{"text": "Identification of Related Phrases and Clusters of Related Phrases .Referring to .FIG .4 , the related phrase identification process includes the following functional operations .400 : Identify related phrases having a high information gain value .402 : Identify clusters of related phrases .", "label": "", "metadata": {}, "score": "47.37458"}
{"text": "Those of skill in the art of information retrieval will appreciate the flexibility of generality of the phrase information allows for a large variety of uses and applications in indexing , document annotation , searching , ranking , and other areas of document analysis and processing .", "label": "", "metadata": {}, "score": "47.39436"}
{"text": "We describe an efficient decoder and show that using these treebased models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser . \" ...Previous work has used monolingual parallel corpora to extract and generate paraphrases .", "label": "", "metadata": {}, "score": "47.398205"}
{"text": "The above scheduling rules make use of the query costs that were previously described .This cost measure can specific to phrases , for example the length of its posting list , or more generalized such as a cost measure associated with the phrase 's tier , or even the tier number itself as a proxy for cost .", "label": "", "metadata": {}, "score": "47.398758"}
{"text": "It is moderately supported by a range of documents ( e.g. , the combined score is above a second threshold ) , or .It occurs very broadly ( e.g. , the number of documents from which it received a minimum score is above a third threshold ; ) .", "label": "", "metadata": {}, "score": "47.50235"}
{"text": "[ 0009 ] .The disclosed and described components and methods comprise the features hereinafter fully described and particularly pointed out in the claims .The following description and the annexed drawings set forth in detail certain illustrative aspects .These aspects are indicative , however , of but a few of the various ways in which the disclosed components and methods can be employed .", "label": "", "metadata": {}, "score": "47.5125"}
{"text": "It should further be noted that if either the phrase posting list length - based cost or the subtree cost function is used , then the optimization stage 1020 can be performed before the scheduling stage 1010 .To help further explain the phrasification , scheduling and optimization processes , the following example is provided .", "label": "", "metadata": {}, "score": "47.550045"}
{"text": "A system for guiding a search for information is presented .The system comprises a user interface that accepts a phrase and receives at least one suggestion based at least in part on the phrase .The system also includes a phrase suggestion engine that matches the phrase with the at least one suggestion .", "label": "", "metadata": {}, "score": "47.56826"}
{"text": "The above algorithm , when completed by the various query execution modules yields a final merged document list ( at 1(ii ) ) resulting from the execution by the lower level servers on their respective portions of the query schedule .This document list , with additional document information and annotations serves as the search result set 835 .", "label": "", "metadata": {}, "score": "47.583454"}
{"text": "Traditional approaches to machine translation ( MT ) [ 1 ] relied to a large extent on linguistic analysis .The ( relatively ) recent development of statistical approaches [ 2 ] and especially phrase - based machine translation , or PBMT [ 3 , 4 ] , has put the focus on the intensive use of large parallel corpora .", "label": "", "metadata": {}, "score": "47.68807"}
{"text": "Although the rate of improvement may depend on both the data and the estimation method , it is unlikely that the general shape of the learning curve will change without major changes in the modeling and inference phases .Possible research directions that address this issue include the integration of linguistic rules or the development of active learning procedures .", "label": "", "metadata": {}, "score": "47.703133"}
{"text": "For example , if a user accesses a search result that was ranked first in a set of search results , a certain number of points can be added to a score associated with the search completion used .Additionally or alternatively , if the user accesses a result that was ranked lowly , points can be deducted from an associated score .", "label": "", "metadata": {}, "score": "47.741714"}
{"text": "We use our theory to introduce a linear algorithm that can be used to derive from word - aligned , parallel corpora the minimal set of syntactically motivated transformation rules that explain human translation data . ...English sentences with a state - of - the - art statistical parser ( Collins , 1999 ) .", "label": "", "metadata": {}, "score": "47.746502"}
{"text": "\" While this approach may produce search results having documents that are conceptually related at the level of individual words , it does not typically capture topical relationships that inhere between co - occurring phrases .SUMMARY OF THE INVENTION .An information retrieval system and methodology uses phrases to index , search , rank , and describe documents in the document collection .", "label": "", "metadata": {}, "score": "47.808563"}
{"text": "FIG .1(B ) is a simple example of a hierarchical tree for the top - level window object in FIG .1(A ) .As shown in FIGS . 2 and 3 , in order to develop a complete hierarchical representation of a target application 22 , the target application is first analyzed in step 40 to determine a set of n application states 24 .", "label": "", "metadata": {}, "score": "47.820763"}
{"text": "This is done by generating the hash of the word sequence , and checking it against the phrase table in the phrase data 255 .The sequences that are considered as potential phrases include all subsequences of consecutive words within the window , multi - word sequences including one or more skipped words , and sequences including permutations ( reorderings ) of two or more words .", "label": "", "metadata": {}, "score": "47.83085"}
{"text": "M ) and creating all possible partitions of the conjuncts A , B , C . . .M into disjoint phrases .For example , the subtree : .( A AND B AND C AND D ) . generates the following phrasifications , where each group of terms in quotes is a phrase : . \"", "label": "", "metadata": {}, "score": "47.836002"}
{"text": "The output of this stage 304 is a further revised list of candidate phrases , which are initially deemed to be real and valid phrases , together with the combined score .( 3 ) Remove Redundant Phrases .A side - effect of the initial extraction stage 302 is that both a candidate phrase and its subphrases may be emitted from the same document , if the phrase scored between the initial threshold and the strong phrase threshold .", "label": "", "metadata": {}, "score": "47.843388"}
{"text": "In accordance to the invention and the proposed method therein track is kept in which context a model function mixture and their components , in particular a distribution function or a Gaussian , was adapted .Several explicit solutions can be proposed .", "label": "", "metadata": {}, "score": "47.886787"}
{"text": "As a further refinement , the search system 120 can cull certain documents from the result set .In some cases documents may be about many different topics ; this is particularly the case for longer documents .In many cases , users prefer documents that are strongly on point with respect to a single topic expressed in the query over documents that are relevant to many different topics .", "label": "", "metadata": {}, "score": "47.907276"}
{"text": "In other words , the essential limiting factor for phrase - based SMT systems seems to be the Zipf law found in natural language .Our large - scale analysis also suggests that the current bottleneck of the phrase - based SMT approach is the lack of sufficient data , not the function class used for the representation of translation systems .", "label": "", "metadata": {}, "score": "47.913265"}
{"text": "Automatic Taxonomy Generation in Search Results Using Phrases , application Ser .No .10/900,259 , filed on Jul. 26 , 2004 ; and .Phrase - Based Generation of Document Descriptions , application Ser .No .10/900,075 , filed on Jul. 26 , 2004 ; all of which are co - owned , and incorporated by reference herein .", "label": "", "metadata": {}, "score": "47.971382"}
{"text": "FIG .8 b illustrates this case , where phrase A appears in both URL 0 ( as anchor text ) and in the body of URL 1 .In this case , the related phrase bit vector for phrase A for URL 1 is used as the inlink score for the link from URL 0 to URL 1 containing phrase A. .", "label": "", "metadata": {}, "score": "47.99854"}
{"text": "First , the grouping by tiers and the partitioning by shards can be independently controlled , or one can be made dependent on the other , as shown above .Second , this independent control can be exercised to a very granular degree , so that each phrase posting list can be very selectively assigned to a tier and a number of shards .", "label": "", "metadata": {}, "score": "48.002518"}
{"text": "Performance of an SMT system is a function of the dimension of the training data that can be logarithmic as seen in the previous section .We have modelled this relation in the following way : . of the data as increasing set size .", "label": "", "metadata": {}, "score": "48.019447"}
{"text": "An automatic score measures the quality of machine - translated sentences by comparing them to a set of human translations , called reference sentences .The score needs to be able to discriminate good translations from bad ones , whilst considering aspects such as adequacy and fluency .", "label": "", "metadata": {}, "score": "48.040604"}
{"text": "Ahonen - Myka , H. et al . , \" Finding Co - Occurring Text Phrases by Combining Sequence and Frequent Set Discovery \" , Proceedings of 16th International Joint Conference on Artificial Intelligence IJCAI-99 Workshop on Text Mining : Foundations Techniques and Applications , Jul. 31 , 1999-Aug .", "label": "", "metadata": {}, "score": "48.11161"}
{"text": "Each phrase posting list is assigned to a tier based on its length , by assigning each phrase posting list to the tier in which its length will \" fit \" between the minimum length of that tier and the minimum length of the next tier .", "label": "", "metadata": {}, "score": "48.123314"}
{"text": "Variations of the specific implementations and examples presented herein will become apparent from the following detailed description when considered in conjunction with the drawings .BRIEF DESCRIPTION OF THE DRAWINGS . [0010 ] .FIG .1 is a system block diagram of a dynamic search system .", "label": "", "metadata": {}, "score": "48.196068"}
{"text": "Documents are the indexed according to their included phrases , using phrase posting lists .The phrase posting lists are stored in an cluster of index servers .The phrase posting lists can be tiered into groups , and sharded into partitions .", "label": "", "metadata": {}, "score": "48.217834"}
{"text": "FIG .7 , the order of these operations is independent , and may be varied as desired for a given embodiment , and thus the inputs may be pipelined instead of being in parallel as shown .Dynamic Taxonomy Generation for Presentation .", "label": "", "metadata": {}, "score": "48.21974"}
{"text": "In practice this trade - off is easily observed , by noticing how the training error can be driven to zero by using a rich hypothesis class , which typically results into overfitting and increased test error .In the context of statistical machine translation ( SMT ) , where large bilingual corpora are used to train adaptive software to translate text , this task is further complicated by the peculiar distribution underlying the data , where the probability of encountering new words or expressions never vanishes .", "label": "", "metadata": {}, "score": "48.25643"}
{"text": "The remaining documents can then be scored .This means further that it is unnecessary for the search system 120 to process the posting lists of Q 2 to see which documents it is present in as well , thereby saving compute time .", "label": "", "metadata": {}, "score": "48.347675"}
{"text": "The spoken names are added to a speaker dependent recognition grammar , which can thereafter recognize future utterances of the names .This technique is sometimes referred to as speaker - dependent recognition .Use of voice enrolled grammars permits users to vocally customize personal services , such as Voice Activated Dialing services .", "label": "", "metadata": {}, "score": "48.391384"}
{"text": "This update identifies that the good phrase g i appears in this specific document .In one embodiment , the posting list for a phrase g j takes the following logical form : .Phrase g j : list : ( document d , [ list : related phase counts ] [ related phrase information ] ) .", "label": "", "metadata": {}, "score": "48.458252"}
{"text": "In this specific example , the suggested phrase can include a group of key words or a natural language query in sentence form , among others .The query suggestion engine 720 can then send a suggested query to a structuring engine 730 .", "label": "", "metadata": {}, "score": "48.46961"}
{"text": "The process of constructing and using the user model for personalized ranking is as follows .First , for a given user , a list of the last K queries and P documents accessed is maintained , where K and P are preferably about 250 each .", "label": "", "metadata": {}, "score": "48.481323"}
{"text": "Nguyen , H. et al . , \" Mining ' Hidden Phrase ' Definitions from the Web \" , Proceedings of the 5th Asian - Pacific Web Conference , Apr. 23 , 2002-Apr .Pretschner , A. et al . , \" Ontology Based Personalized Search \" , Tools with Artificial Intelligence , Proceedings of the 11th IEEE International Conference , Nov. 9 , 1999-Nov .", "label": "", "metadata": {}, "score": "48.482086"}
{"text": "Table 5 : Performance obtained training the regressor on 80 % of the data and testing on 20 % .This process has been iterated 1,000 times .Experiments have been performed independently on the Europarl and Giga corpus dataset .Role of Phrase Length in the Translation Table ( Model Selection ) .", "label": "", "metadata": {}, "score": "48.485672"}
{"text": "These experiments suggest that the phrase length has a limited impact on actual test performance .Going to larger n- grams seems to bring little benefit in terms of performance as the model continues to prefer short phrases during the decoding phase .", "label": "", "metadata": {}, "score": "48.519028"}
{"text": "In Figure 8 , BLEU score as function of the development size is reported .The optimization procedure increases the quality of the translations .This improvement does not seem to be significant after a certain size of the development set .", "label": "", "metadata": {}, "score": "48.551376"}
{"text": "In typical embodiment , the good phrase list 208 will include about 6.5\u00d710 5 phrases .A list of bad phrases is not necessary to store , as the system need only keep track of possible and good phrases .By the final pass through the document collection , the list of possible phrases will be relatively short , due to the expected distribution of the use of phrases in a large corpus .", "label": "", "metadata": {}, "score": "48.582653"}
{"text": "One , containing 1,159,914 pairs of sentences , has been used to train the model .This step has been done only once , and all the experiments use the same translation , language , and reordering models .The second set has 100,000 pairs of sentences , and it is used to randomly select the development sets .", "label": "", "metadata": {}, "score": "48.63003"}
{"text": "Our expe ... \" .In this paper , we propose a novel string - todependency algorithm for statistical machine translation .With this new framework , we employ a target dependency language model during decoding to exploit long distance word relations , which are unavailable with a traditional n - gram language model .", "label": "", "metadata": {}, "score": "48.639343"}
{"text": "Accordingly , a given document will appear in the posting lists of many different phrases , and in each such posting list , the related phrase vector for that document will be specific to the phrase that owns the posting list .", "label": "", "metadata": {}, "score": "48.64814"}
{"text": "We describe an open - source toolkit for statistical machine translation whose novel contributions are ( a ) support for linguistically motivated factors , ( b ) confusion network decoding , and ( c ) efficient data formats for translation models and language models .", "label": "", "metadata": {}, "score": "48.663994"}
{"text": "We describe an open - source toolkit for statistical machine translation whose novel contributions are ( a ) support for linguistically motivated factors , ( b ) confusion network decoding , and ( c ) efficient data formats for translation models and language models .", "label": "", "metadata": {}, "score": "48.663994"}
{"text": "4 - 6 .One particular embodiment of the cost measure is the length of the phrase posting list .This is used as an indirect measure of query processing costs , as larger phrase posting lists require a greater number of index servers 200 , and hence an increased amount of potential inter - server communication during query processing .", "label": "", "metadata": {}, "score": "48.755455"}
{"text": "Thus , the phrase assignment function can be used to optimize for one aspect of performance , say communications costs , and the shard assignment function can be used to optimize for a different aspect of performance , such as increased parallelism amongst the index servers .", "label": "", "metadata": {}, "score": "48.80999"}
{"text": "Abstract .An information retrieval system uses phrases to index , retrieve , organize and describe documents .Phrases are identified that predict the presence of other phrases in documents .Documents are the indexed according to their included phrases .Related phrases and phrase extensions are also identified .", "label": "", "metadata": {}, "score": "48.87896"}
{"text": "In each case , we found the same overall behaviour , of a logarithmic growth in performance with training set size .The question becomes as follows : on which aspect of these systems should we act to achieve better performance ?", "label": "", "metadata": {}, "score": "48.955605"}
{"text": "Accordingly , in one embodiment , the search system 120 sorts the documents in the search results according to the value of their related phrase bit vectors .The documents containing the most related phrases to the query phrases Q will have the highest valued related phrase bit vectors , and these documents will be the highest - ranking documents in the search results .", "label": "", "metadata": {}, "score": "48.979103"}
{"text": "In addition , while a particular feature may have been disclosed with respect to only one of several implementations , such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application .", "label": "", "metadata": {}, "score": "49.043"}
{"text": "A user may have to perform many iterations of this process until desired results are obtained .Therefore , there is a need for systems and methods that can minimize query errors and assist in query creation to perform effective searches .", "label": "", "metadata": {}, "score": "49.17446"}
{"text": "As a preliminary matter , it is useful to define a user 's interests ( e.g. , a user model ) in terms of queries and documents , both of which can be represented by phrases .For an input search query , a query is represented by the query phrases Q , the related phrases of Qr , and phrase extensions Qe of the query phrases Qp .", "label": "", "metadata": {}, "score": "49.215027"}
{"text": "Similarly , during preparation of the results of a search query , the documents in the search result set can be processed to eliminate duplicates .The present invention has further embodiments in system and software architectures , computer program products and computer implemented methods , and computer generated user interfaces and presentations .", "label": "", "metadata": {}, "score": "49.281403"}
{"text": "In this case , the document may be assigned a different document identifier for each instance , and when the document is retrieved in search results , only the most recent instance of the document will be returned .A given segment will contain documents that are indexed in various phrase posting lists across the tiers and shards .", "label": "", "metadata": {}, "score": "49.282135"}
{"text": "A segment may store the index information for any number of documents .The phrase posting lists in each segment can then be tiered , sharded and assigned to the index servers as described , so as to form segment shards .", "label": "", "metadata": {}, "score": "49.35073"}
{"text": "Processing continues at process block 1360 where results of the search based upon the completed query are presented to the user along with the matched additional content .At decision block 1370 , a determination is made whether the suggestion upon which the completed query originally obtained has changed .", "label": "", "metadata": {}, "score": "49.42047"}
{"text": "4 is a block diagram of one embodiment of the storage architecture for the phrase posting lists in the index servers .FIG .5 is a block diagram of another embodiment of the storage architecture for the phrase posting lists in the index servers .", "label": "", "metadata": {}, "score": "49.457443"}
{"text": "We have isolated 4,000 pairs of sentences from the Europarl training set , and we have selected from the remaining part 629,957 pairs .A Moses model is trained using this set .Using the 4,000 sentences pairs , we have created 10 random subsets for each of the 16 chosen sizes , where each size can contain a number of pairs from 250 to 4,000 by a step of 250 pairs .", "label": "", "metadata": {}, "score": "49.527218"}
{"text": "More specifically , a prediction measure is used that relates the actual co - occurrence rate of two phrases to an expected co - occurrence rate of the two phrases .Information gain , as the ratio of actual co - occurrence rate to expected co - occurrence rate , is one such prediction measure .", "label": "", "metadata": {}, "score": "49.55062"}
{"text": "Role of Test Set Size on Measuring Performance .BLEU score , the metric used in this work to evaluate the quality of the translation , is test set dependent .It means that different test sets regardless of the dimension can produce variation in the value of the BLEU score .", "label": "", "metadata": {}, "score": "49.577435"}
{"text": "F. J. Och and H. Weber , \" Improving statistical natural language translation with categories and rules , \" in Proceedings of the 17th International Conference on Computational Linguistics , vol .2 , pp .985 - 989 , Stroudsburg , Pa , USA , 1998 .", "label": "", "metadata": {}, "score": "49.581154"}
{"text": "Another aspect of the present invention can include VoiceXML code for manipulating voice phrases contained within a voice enrolled grammar .The VoiceXML code can be stored on a medium accessible by a computing device , which is capable of executing programmatic instructions of the VoiceXML code .", "label": "", "metadata": {}, "score": "49.62555"}
{"text": "Each word or phrase comprising the sub - context object name , private vocabulary and sub - context command vocabulary is stored as part of an associated voice macro for causing a pre - determined sequence of actions to take place .", "label": "", "metadata": {}, "score": "49.637638"}
{"text": "If the current node is an explicit data node containing a document list , then return the associated explicit data .( ii )If the current node is a phrase node , retrieve all index shards present on the current server that represent part of the given phrase , and return the OR ( union ) of their phrase posting lists .", "label": "", "metadata": {}, "score": "49.64869"}
{"text": "FIG .2 the incoming speech flow is received and preprocessed .Then the recognizing process is performed in step 23 leading to the recognized result in the form of a recognized speech phrase , word or the like in Step 24 .", "label": "", "metadata": {}, "score": "49.70649"}
{"text": "These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art .These operations , while described functionally or logically , are understood to be implemented by computer programs .", "label": "", "metadata": {}, "score": "49.77824"}
{"text": "These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art .These operations , while described functionally or logically , are understood to be implemented by computer programs .", "label": "", "metadata": {}, "score": "49.77824"}
{"text": "As a result , the overall time for query processing is significantly reduced .This is in contrast to conventional indexing systems which require any index server to be able to communicate with any other index server during query processing .Another aspect of the information retrieval system is a method for maintaining and updating the index servers , so as to ensure generally continuous and availability of the index .", "label": "", "metadata": {}, "score": "49.788834"}
{"text": "Finally , the navigator will search all of the remaining sub - context object names 82 for other sub - context objects in the current sub - context object tree .Once the navigator has matched the decoded word or phrase to a particular vocabulary phrase 142 contained within the target sub - context object , the desired action represented by the decoded phrase within the sub - context object must be performed by the navigator 102 .", "label": "", "metadata": {}, "score": "49.796734"}
{"text": "The first stage 600 of the search system 120 is to identify any phrases that are present in the query in order to effectively search the index .The following terminology is used in this section : . q : a query as input and receive by the search system 120 .", "label": "", "metadata": {}, "score": "49.840256"}
{"text": "The user can then select or accept a suggestion or can continue to create a phrase .If the user continues to create a phrase , a new suggestion can then be created and sent again to the search server 440 for the identification of new suggestions .", "label": "", "metadata": {}, "score": "49.8599"}
{"text": "It is an object of the present invention to provide a method for recognizing speech in which the influence of frequently occuring speech phrases or words within the received speech flow on the adaptation process with respect to the current acoustic model is balanced .", "label": "", "metadata": {}, "score": "49.940754"}
{"text": "This is reflected in the two main components of the typical SMT model : the language model and the translation model .The language model is typically built using a table of n -grams , with associated probabilities , which is sufficient to define a Markov chain .", "label": "", "metadata": {}, "score": "49.94123"}
{"text": "The selected phrasifications are organized as a Boolean phrase tree 815 having a root OR node , with each of the selected phrasification being a disjunct of the root node .Query Scheduling & Query Optimization .FIG .10 illustrates the stages for query scheduling 1010 and query optimization 1020 handled by the query scheduling module 820 , after query phrasification and prior to query execution .", "label": "", "metadata": {}, "score": "49.94909"}
{"text": "Index servers in next tier(s ) , can store progressively longer phrase posting lists , using the appropriate limits on the tiers and the phrase assignment function .The last tier , i.e. , the M th tier , can be used to store the phrase posting lists for very high frequency phrases .", "label": "", "metadata": {}, "score": "49.949818"}
{"text": "\" Test on training set ' ' is a test set selected by the training set for each training set size and no optimization phase .In the \" test on test set ' ' learning curve , there seems to be no significant advantage to using phrases longer than 4 words .", "label": "", "metadata": {}, "score": "49.978382"}
{"text": "Once index server A has received the responses from all index servers B i , it forms the union ( OR ) of their results , and that is the result of evaluating the AND .It then returns this result back to the root query execution module 830 of the front end server 140 .", "label": "", "metadata": {}, "score": "50.005173"}
{"text": "By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .SMT has made tremendous strides in less than two decades , and many popular techniques have only emerged within the last few years .", "label": "", "metadata": {}, "score": "50.020103"}
{"text": "Starting with the highest phrase number as the first candidate phrase , the search system 120 determines if there is another candidate phrase within a fixed numerical distance within the sorted list , i.e. , the difference between the phrase numbers is within a threshold amount , e.g. 20,000 .", "label": "", "metadata": {}, "score": "50.06504"}
{"text": "In an age where the creation of intelligent behaviour is increasingly data driven , this is a question of great importance to all of artificial intelligence .In phrase - based approaches to statistical machine translation , translations are generated in response to some input source text .", "label": "", "metadata": {}, "score": "50.068913"}
{"text": "Usually , for each phoneme different models are used depending on the left and right phonemic or acoustical context .Accordingly , there exist several thousands or ten - thousands of models .To reduce the computational burden similar distribution functions or Gaussians of different phone models are merged and the resulting Gaussians or distribution functions are shared across the models .", "label": "", "metadata": {}, "score": "50.08174"}
{"text": "Disclosed components and methods are described with reference to the drawings , wherein like reference numerals are used to refer to like elements throughout .In the following description , for purposes of explanation , numerous specific details are set forth in order to provide a thorough understanding of the disclosed subject matter .", "label": "", "metadata": {}, "score": "50.116535"}
{"text": "III .Search System .The search system 120 operates to receive a query and search for documents relevant to the query , and provide a list of these documents ( with links to the documents ) in a set of search results .", "label": "", "metadata": {}, "score": "50.11987"}
{"text": "wherein the VoiceXML code comprises at least one VoiceXML tag for editing of the at least one voice - enrolled grammar and an identifier associated with the at least one VoiceXML tag that identifies at least one voice phrase of the at least one voice - enrolled grammar to be edited , and .", "label": "", "metadata": {}, "score": "50.12094"}
{"text": "An Exact hit flag indicates that the text break satisfies both of the above criteria .A Medial hit flag indicates that the text break does not satisfy either of the above criteria .Additional information can also be recorded for each word sequence such as linguistic markers ( e.g. , capitalization ) , or inclusion of the phrase as anchor text in a hyperlink .", "label": "", "metadata": {}, "score": "50.16267"}
{"text": "What is the best function class to map Spanish documents into English documents ?This is a question of linguistic nature and has been the subject of a long debate .With the growing availability of bilingual parallel corpora , the 1990 s saw the development of statistical machine translation ( SMT ) models .", "label": "", "metadata": {}, "score": "50.164433"}
{"text": "We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities , and show how it can be refined to take contextual information into account .We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments , and contrast the quality with paraphrases extracted from automatic alignments . ... ol .", "label": "", "metadata": {}, "score": "50.18167"}
{"text": "A related problem is the need for users to properly construct queries in order to locate desired information .[ 0003 ] .Search systems include such systems as web search engines and database interfaces , among others .When a user performs a search for information , that user typically must create and construct a query that the user believes will produce desired results .", "label": "", "metadata": {}, "score": "50.189445"}
{"text": "The method according to claim 1 further comprising the steps of : . determining a set of attributes associated with each of said window objects , and assigning a matching set of attributes to each of the sub - context objects ; and .", "label": "", "metadata": {}, "score": "50.20983"}
{"text": "FIG .5 there is shown two tiers , Tier 1 and Tier 2 , each of which is associated with some set of index servers 200 .The entirety of the phrase posting lists are divided amongst the two tiers , so that some phrase posting lists are assigned to the index servers 200 in Tier 1 , and the remaining phrase posting lists are assigned to the index servers 200 in Tier 2 .", "label": "", "metadata": {}, "score": "50.243767"}
{"text": "2 as step 48 .One of the purposes of the foregoing context data file is to enable a voice navigator to associate decoded spoken commands to specific window objects .FIG .6 is a flow chart which illustrates the manner by which a voice navigator program makes use of the context data file to locate a window object to which a voice command has been directed .", "label": "", "metadata": {}, "score": "50.25438"}
{"text": "According to a preferred embodiment of the invention , an internal representation of a particular target application program is preferably developed in the form of a hierarchical tree .This process is preferably performed by means of an analysis of a particular target application program for which a voice navigator system is to be used .", "label": "", "metadata": {}, "score": "50.297127"}
{"text": "7 is a block diagram showing the interaction between a voice navigator program , voice recognition engine and a target application context file .FIG .8(A ) is a flow chart showing the process by which a voice navigator according to the present invention can locate a target window object , based upon a decoded phrase .", "label": "", "metadata": {}, "score": "50.345047"}
{"text": "The method of .claim 1 , wherein scoring each candidate phrasification comprises : . applying a factor to account for a confidence level of each component phrase in the candidate phrasification .The method of .claim 1 , wherein scoring each candidate phrasification further comprises : . applying the probability of occurrence of each component phrase , and the number of component phrases in the candidate phrasification to a function that includes at least one parameter for adjusting precision and recall of the candidate phrasification .", "label": "", "metadata": {}, "score": "50.425438"}
{"text": "Unfortunately , current estimation procedures are unable to reach such high - performing regions of the parameter space .This was also noted by a recent paper by Wisniewski et al . who note that \" the current bottleneck of translation performances is not the representation power of the [ phrase - based translation systems ] but rather in their scoring functions '' [ 38 ] .", "label": "", "metadata": {}, "score": "50.43145"}
{"text": "391 - 398 , IEEE Computational Intelligence Society , Chicago , IL , USA .The present invention extends the VoiceXML language model to natively support voice enrolled grammars .Specifically , three VoiceXML tags can be added to the language model to add , modify , and delete acoustically provided phrases to voice enrolled grammars .", "label": "", "metadata": {}, "score": "50.470764"}
{"text": "According to a further embodiment , it is advantageous to make the threshold values t j or u j ( in .FIGS . 1 , 2 ) dependent on the overall or global number x of adaptation steps in a recognition session .", "label": "", "metadata": {}, "score": "50.520565"}
{"text": "2 shows a table illustrating three VoiceXML elements that natively support voice enrolled grammars in accordance with an embodiment of the inventive arrangements disclosed herein .FIG .3 is a sample portion of VoiceXML code that demonstrates a use of the addvoicephrase element .", "label": "", "metadata": {}, "score": "50.552444"}
{"text": "The name attribute should be unique among form items in the form .If the name is not unique , then a badfetch error can be thrown when a related document is fetched .Upon successful enrollment , a value of the name attribute can be the phraseid for an enrolled voice phrase .", "label": "", "metadata": {}, "score": "50.584473"}
{"text": "FIG .7 illustrates the main functional operations of the presentation system 130 : .700 : Cluster documents according to topic clusters .702 : Generate document descriptions .704 : Eliminate duplicate documents .Each of these operations takes as an input the search results 701 and outputs modified search results 703 .", "label": "", "metadata": {}, "score": "50.58483"}
{"text": "1 shows by means of a schematical block diagram fundamental or basic steps of an embodiment for the inventive method for recognizing speech .In first step 11 of the recognition and adaptation process 10 of .FIG .1 the incoming speech flow being built up as a concatenation of possible speech phrases . . .", "label": "", "metadata": {}, "score": "50.643906"}
{"text": "This information is then recorded in conjunction with each good phrase g j .In one embodiment , the cluster number is determined by a cluster bit vector that also indicates the orthogonality relationships between the phrases .The cluster bit vector is a sequence of bits of length n , the number of good phrases in the good phrase list 208 .", "label": "", "metadata": {}, "score": "50.681324"}
{"text": "Those of ordinary skill in the art will readily recognize that specifics of the query , the search that is performed using that query , and the set of results that is obtained will vary based upon , among other things , specific implementation details .", "label": "", "metadata": {}, "score": "50.699738"}
{"text": "Documents are the indexed according to their included phrases , using phrase posting lists .The phrase posting lists are stored in an cluster of index servers ....An information retrieval system uses phrases to index , retrieve , organize and describe documents .", "label": "", "metadata": {}, "score": "50.737663"}
{"text": "No .10/900,055 , filed on Jul. 26 , 2004 ; .Phrase - Based Searching in an Information Retrieval System , application Ser .No .10/900,041 , filed on Jul. 26 , 2004 ; .Phrase - Based Personalization of Searches in an Information Retrieval System , application Ser .", "label": "", "metadata": {}, "score": "50.76576"}
{"text": "The indexing system 110 operates on an index 150 and data repository 160 of phrase data .These data repositories are further described below .Phrase Identification .The phrase identification operation of the indexing system 110 identifies \" good \" and \" bad \" phrases in the document collection that are useful to indexing and searching documents .", "label": "", "metadata": {}, "score": "50.798256"}
{"text": "Whichever form of the node has the lower cost ( the original OR node or the resulting AND node ) , is kept in the final schedule tree .The particular cost evaluation function can be selected by the system implementer , based on which query cost measure is being used ( e.g. , tier based cost , phrase posting list cost , etc . ) .", "label": "", "metadata": {}, "score": "50.80922"}
{"text": "The second concern was to distinguish between the role of the numerical and lexical parts in the language and translation models .Various perturbation experiments show that the accuracy in estimating the numerical parameters is not a crucial aspect of performance , while the estimation of the lexical parts of the tables is a major factor in determining performance .", "label": "", "metadata": {}, "score": "50.92248"}
{"text": "868 - 876 , 2007 .J. Blatz , E. Fitzgerald , G. Foster , et al . , \" Confidence estimation for machine translation , \" in Proceedings of the 20th international Conference on Computational Linguistics ( COLING ' 04 ) , vol .", "label": "", "metadata": {}, "score": "50.991516"}
{"text": "Referring to .FIG .2 , there is shown in the indexing system 110 in further detail for one embodiment .The indexing system 110 includes a server cluster master 220 , a set of segment shard files 225 , a swap master server 240 , and a phrase identification server 250 , and a database of phrase data 255 .", "label": "", "metadata": {}, "score": "50.99434"}
{"text": "This may be interpreted to mean that the author of the document d used several related phrases g j , g k , and g l together in drafting the document .A bit pair of ( 1,0 ) indicates that both g j and g k are present , but no further secondary related phrases from g k are present , and thus this is a less significant topic .", "label": "", "metadata": {}, "score": "51.013756"}
{"text": "This can either represent the effect of insufficient statistics in estimating them , or the use of imperfect parameter estimation biases .These parameters are probabilities , phrases , and associations between source / target phrases contained inside translation and language model tables .", "label": "", "metadata": {}, "score": "51.024384"}
{"text": "Qr : related phrases of Qp .Qe : phrase extensions of Qp .Q : the union of Qp and Qr .A query q is received from a client 190 , having up to some maximum number of characters or words .", "label": "", "metadata": {}, "score": "51.0255"}
{"text": "occurrence numbers and/or adaptation numbers for each of the possible speech phrases to be recognized are counted .The strength of adaptation with respect to a specific speech phrase in question is made dependent on at least the specific adaptation number and/or occurrence number of said specific speech phrase .", "label": "", "metadata": {}, "score": "51.026245"}
{"text": "While the foregoing specification illustrates and describes the preferred embodiments of this invention , it is to be understood that the invention is not limited to the precise construction herein disclosed .The invention can be embodied in other specific forms without departing from the spirit or essential attributes .", "label": "", "metadata": {}, "score": "51.06989"}
{"text": "These sites come from the Canadian government , the European Union , the United Nations , and other international organizations .In addition to covering a wide range of themes , they also contain documents with different styles and genres .We estimate that the rate of misaligned sentence pairs was around 13 % .", "label": "", "metadata": {}, "score": "51.076416"}
{"text": "The dynamic search system 100 also includes a search server 120 .The search server 120 can perform phrase suggestion tasks and search tasks .[ 0031 ] .It should be understood that a type of data that can be used as a phrase can vary according to specific features of the user interface that is provided .", "label": "", "metadata": {}, "score": "51.082405"}
{"text": "For the second set of experiments , data has been randomly sampled in training and test sets one thousand times .Training set has been used to estimate the alphas and the residual , and test set to predict the BLEU score values .", "label": "", "metadata": {}, "score": "51.09318"}
{"text": "When a given query with some number of terms is processed then in such an indexing system , it becomes necessary to access all of the index servers for each query .Thus , even a simple single word query requires each of the index servers ( e.g. , 1,000 servers ) to determine whether it contains documents containing the word .", "label": "", "metadata": {}, "score": "51.12697"}
{"text": "For example , assume the following phrases are initially present in URL 0 and URL 1 : .( In the above , and following tables , the secondary related phrase bits are not shown ) .The URL 0 row is the outlink score of the link from anchor text A , and the URL 1 row is the inlink score of the link .", "label": "", "metadata": {}, "score": "51.14406"}
{"text": "Phrase Map Table : .There are four possible values for the hit position : Initial , Final , Exact , Medial .An Initial hit flag indicates that this particular sequence of N words was the first sequence of N words after the buffer was emptied .", "label": "", "metadata": {}, "score": "51.241405"}
{"text": "Here then a large number of shards is used to partition the phrase posting lists .From the foregoing , the use of tiers and shards can be now explained more generally .The phrase posting lists may be considered to be an array of rows and columns .", "label": "", "metadata": {}, "score": "51.245453"}
{"text": "The method of .claim 1 , wherein decomposing the input text comprises : .( i ) restructuring a word tree derived from the input text , where the word tree comprises leaf nodes that are words and non - leaf nodes that are Boolean operators AND , OR , or NOT ; and .", "label": "", "metadata": {}, "score": "51.291775"}
{"text": "This considerably reduces the size of the phrase posting lists , enables more documents to be indexed , and reduces query access times .The above process by which the query schedule is passed from one index server to another can be further improved as follows : An explicit data node can only present in a query schedule if its parent is an AND node .", "label": "", "metadata": {}, "score": "51.29503"}
{"text": "Does the performance improve with more data because certain parameters are estimated better , or just because the lists are growing ?In the second case , it is likely that more sophisticated statistical algorithms to improve the estimation of probabilities will have limited impact .", "label": "", "metadata": {}, "score": "51.33371"}
{"text": "So always these words would be recognized no matter what was said .Speech recognizers involve statistical models in the acoustic models , in particular for the description of acoustic properties of the incoming speech .Word models are a concatenation of the corresponding refined models , for instance of corresponding phoneme models .", "label": "", "metadata": {}, "score": "51.3365"}
{"text": "FIG .5 illustrates a next embodiment , introducing the concept of tiers of index servers 200 .A number of tiers is selected for a given implementation .In typical embodiments , there are between 2 and 10 tiers .Each phrase posting list is then assigned to one tier of index servers 200 .", "label": "", "metadata": {}, "score": "51.33936"}
{"text": "If the possible phrase is present in the good phrase list 208 , then a phrase number is returned for phrase ; the possible phrase is now a candidate phrase .After all possible phrases in each window have been tested to determine if they are good candidate phrases , the search system 120 will have a set of phrase numbers for the corresponding phrases in the query .", "label": "", "metadata": {}, "score": "51.37532"}
{"text": "A rescheduling of the restructured node is not necessary in this case .Subtree cost : A third query cost measure is an evaluation cost of any subtree of a scheduled query tree , which approximates the network load that would be generated by executing that subtree .", "label": "", "metadata": {}, "score": "51.379425"}
{"text": "Once all of the documents in the indexing set have been processed , the next stage is the assignment of phrase posting lists to the index servers 200 for storage and serving .This is done by generally grouping the phrase posting lists into tiers and partitioning the phrase posting lists into shards , which are then stored in various index servers 200 .", "label": "", "metadata": {}, "score": "51.39261"}
{"text": "If the candidate phrase 's score is equal to or above the strong phrase threshold , the phrase identification server 250 applies the following rules instead : .If the candidate phrase hit position was \" exact \" and had a score of X , then skip further scoring .", "label": "", "metadata": {}, "score": "51.417492"}
{"text": "An analysis of a large corpus of annotated learner English confirms this assumption .We evaluate our approach on real - world learner data and show that L1-induced paraphrases outperform traditional approaches based on edit distance , homophones , and WordNet synonyms . ... where f denotes a foreign phrase in the L1 language .", "label": "", "metadata": {}, "score": "51.41912"}
{"text": "In a first example of an adaptation based on maximum likelihood linear regression ( MLLR ) one or a few transformation matrices are estimated on the speech of the single user to transform a large set of Gaussians .This procedure is done every few utterances .", "label": "", "metadata": {}, "score": "51.42813"}
{"text": "In each row g j of the matrix , there will be one or more other phrases that are related to phrase g j .For each related phrase m in R j , the indexing system 110 determines if each of the other related phrases in R is also related to g j .", "label": "", "metadata": {}, "score": "51.446877"}
{"text": "The method of .claim 1 , wherein comparing the document description of the first document with a document description of the second document further comprises : . retrieving a stored document description of the first document comprising selected sentences of the document , wherein the selected sentences are ordered in the document description as a function of a number of related phrases in the selected sentences ; and . retrieving a stored document description of the second document comprising selected sentences of the document , wherein the selected sentences are ordered in the document description as a function of a number of related phrases in the selected sentences .", "label": "", "metadata": {}, "score": "51.49782"}
{"text": "The subset of selected phrasifications can vary from one ( i.e. , highest scoring phrasification ) to some fixed number ( e.g. , top 10 scoring phrasifications ) , or a selected percentage ( 50 % ) of the top scoring phrasifications .", "label": "", "metadata": {}, "score": "51.518074"}
{"text": "Next , the phrase tree is scheduled by the query scheduling module 820 .These lengths will be used as the query costs , and thus are assigned to the respective nodes of the phrase tree according to scheduling rule ( a ) : .", "label": "", "metadata": {}, "score": "51.53253"}
{"text": "The set of all documents in the index is divided into a number of segments ; the segments are independent of the tiers and shards described above .Each document is typically represented in only one of the segments , though in some instances a document may appear in multiple segments .", "label": "", "metadata": {}, "score": "51.576294"}
{"text": "Authors in [ 30 ] reported \" almost linear \" improvements in BLEU score by doubling the training set size .In the presentation [ 32 ] , the claim is that BLEU increases with each doubling of the training set size , by 0.5 and 2.5 BLEU points for the language and translation models , respectively , in the context of Arabic - English translation .", "label": "", "metadata": {}, "score": "51.59868"}
{"text": "A system for detecting a duplicate document , comprising : . a document description system , executed by a processor , and configured to associate a set of documents with a set of corresponding document descriptions and store the associations in a memory , . wherein a document description of the first document comprises a selected subset of sentences of the first document , the sentences being selected and ordered in the document description as a function of a number of related phrases in the selected sentences ; . wherein the document description of the second document comprises a selected subset of sentences of the second document , the sentences being selected and ordered in the document description as a function of a number of related phrases in the selected sentences , . a duplicate detection system , executed by a processor and configured to : . select a first document and a second document from the document description system ; . compare the document description corresponding to the first document with the document description corresponding to the second document , and . responsive to the document description corresponding to the first document matching the document description corresponding to the second document , indentifying the first document and the second document as duplicate documents in the set of documents .", "label": "", "metadata": {}, "score": "51.6529"}
{"text": "b )To each NOT node , assign the set of index servers 200 and the query cost associated with the ( unique ) child of the node .c )For each AND node : .( i )Sort the children nodes in ascending order according to their query costs , such that the leftmost child node of the AND is the one with the least cost ; .", "label": "", "metadata": {}, "score": "51.718018"}
{"text": "The evaluation of a machine translation system is a lively and hotly debated topic in this field .Ideally , human beings can evaluate the quality of a translated sentence .However , this is unfeasible for rapid development of automatically trained systems with multiple parameter tuning , as human evaluation is expensive , slow , and sometimes inconsistent and subjective .", "label": "", "metadata": {}, "score": "51.796616"}
{"text": "[ 0069 ] .As the user enters a phrase , results are displayed in a results area 860 .In this example , the results are based upon a preliminary search , which can be cached , using the topmost suggestion .", "label": "", "metadata": {}, "score": "51.820152"}
{"text": "Generally , the incoming speech flow can be classified as a concatenation of words or subword units , whereas the speech phrase subunits are based on a finer structure , for instance on the basis of phonemes , syllables or the like .", "label": "", "metadata": {}, "score": "51.853195"}
{"text": "These costs are then used to initially sequence the order of execution of the nodes in the phrase tree so as to reduce inter - machine communication .The scheduling rules also assign to each operator node in the query tree a set of index servers that will be responsible for evaluating it ; these assignments are made so as to minimize the amount of inter - server communication .", "label": "", "metadata": {}, "score": "51.86895"}
{"text": "This description is then stored in association with the document , for example as a string or a hash of the sentences .During indexing , a newly crawled document is processed in the same manner to generate the document description .", "label": "", "metadata": {}, "score": "51.886223"}
{"text": "This reduces overall communication costs ( amount of data being transferred between index servers 200 ) as well as ensuring the fewest possible number of intersections of phrase posting lists need to be performed for the AND node .Scheduling rule ( d ) is the OR rule .", "label": "", "metadata": {}, "score": "51.900177"}
{"text": "[ 0111 ] .What has been described above includes illustrative examples of certain components and methods .It is , of course , not possible to describe every conceivable combination of components or methodologies , but one of ordinary skill in the art will recognize that many further combinations and permutations are possible .", "label": "", "metadata": {}, "score": "51.909706"}
{"text": "Small test set sizes produce a big variance in BLEU score .When increasing the test set size , the error bars tend to reduce .using two different test sets of the same size depend on the test set choice and not on different techniques .", "label": "", "metadata": {}, "score": "51.91234"}
{"text": "New phrases are always being generated , from sources such technology , arts , world events , and law .Other phrases will decline in usage over time .Some existing information retrieval systems attempt to provide retrieval of concepts by using co - occurrence patterns of individual words .", "label": "", "metadata": {}, "score": "51.932556"}
{"text": "In either context , it will be appreciated that the documents are typically distributed across many different computer systems and sites .Without loss of generality then , a set of documents generally , regardless of format or location ( e.g. , which website or database ) will be collectively referred to as a corpus or document collection .", "label": "", "metadata": {}, "score": "52.017673"}
{"text": "The indexing server master 260 can use various measures of significance , including maintaining a count of the frequency of occurrences of the phrase within the document , the position of the occurrences .The updated phrase posting lists are stored to the segment shard files 225 , as will be further explained below , from which they will be copied to the index servers 200 .", "label": "", "metadata": {}, "score": "52.048103"}
{"text": "Next , for each of the referencing documents R , the related phrase bit vector for each anchor phrase Q is obtained .This is a measure of how topical the anchor phrase Q is to the document R. This value is here called the outbound score component .", "label": "", "metadata": {}, "score": "52.055077"}
{"text": "Each of these operations is now described in detail .First , recall that the co - occurrence matrix 212 contains good phrases g j , each of which predicts at least one other good phrase g k with an information gain greater than the information gain threshold .", "label": "", "metadata": {}, "score": "52.09996"}
{"text": "Figure 5 shows that the number of phrases peaks around 4-grams and 5-grams , then steadily decreases .This means that the phrase extraction algorithm finds it more and more difficult to extract longer phrases .We investigate this further by plotting the distribution of phrases actually used while translating .", "label": "", "metadata": {}, "score": "52.119877"}
{"text": "Finally , according to the involvement of the speech phrase SPj or word in question its specific adaptation number a j is incremented in step 27 , and then the processing is returned back for receiving further speech flow in step 22 .", "label": "", "metadata": {}, "score": "52.120655"}
{"text": "308 : Refine the phrase list with heuristics .Each of these stages will now be discussed in further detail .( 1 ) Initial phrase extraction .The phrase identification server 250 generates 302 an initial list of phrases by iterating over each document in a set of documents , identifying candidate phrases within each document , and then testing the collected candidates to determine the whether they are valid .", "label": "", "metadata": {}, "score": "52.159092"}
{"text": "Relative Importance of TM and LM .In the previous section , experiments have been run using the same training set size for language and translation models .In general , there is a large difference in terms of cost of retrieving training data for language and translation models ; the former can be trained using monolingual data , while the second needs bilingual texts .", "label": "", "metadata": {}, "score": "52.190525"}
{"text": "However , in a preferred embodiment , the navigator will perform a prioritized search , wherein the private vocabulary 84 corresponding to the foreground window object is checked first for a vocabulary word which matches the decoded word or phrase received from the voice recognition engine .", "label": "", "metadata": {}, "score": "52.248528"}
{"text": "A proportional presentation would use a proportionate number of documents from each cluster , relative to the total number of documents .Topic Based Document Descriptions .A second function of the presentation system 130 is the creation 702 of a document description that can inserted into the search result presentation for each document .", "label": "", "metadata": {}, "score": "52.27307"}
{"text": "New York , USA .Jing , Y. et al . , \" An Association Thesaurus for Information Retrieval \" , Proceedings of RIAO-94 , 4th International Conference on Intelligent Multimedia Information Retrieval Systems and Management , Oct. 11 , 1994-Oct . 13 , 1994 [ online ] [ Retrieved on Aug. 9 , 2005 ] Retrieved from the Internet : .", "label": "", "metadata": {}, "score": "52.276154"}
{"text": "295 - 302 , Philadelphia , Pa , USA , 2001 .R. C. Moore , W.-T. Yih , and A. Bode , \" Improved discriminative bilingual word alignment , \" in Proceedings of the 21stInternational Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics ( ACL ' 06 ) , pp .", "label": "", "metadata": {}, "score": "52.288437"}
{"text": "The phrase identification server 250 scans over each document 's body and anchors , and maintains a buffer of the last N words of text encountered ; N is preferably between 5 and 20 words .A \" hit \" is an event during this iteration over the documents where the phrase identification server 250 adds a candidate phrase instance to a phrase map table stored in the phrase data 255 .", "label": "", "metadata": {}, "score": "52.303032"}
{"text": "The phrase suggestion engine 220 uses the phrase as a root or other basis to determine an appropriate phrase to suggest as a replacement or substitute for the entered phrase .This determination can be predictive based upon available dictionary words , past searches by the user or other users , or some other available means .", "label": "", "metadata": {}, "score": "52.32876"}
{"text": "Yet SMT translation qual - ity still obviously suffers from inaccurate lexical choice .In this paper , we address this problem by investigating a new strat - egy for integrating WSD into an SMT sys - tem , that performs fully phrasal multi - word disambiguation .", "label": "", "metadata": {}, "score": "52.348293"}
{"text": "The method of .claim 14 , wherein making the change comprises updating the voice phrase contained in the voice - enrolled grammar .The method of .An apparatus comprising : . at least one processor programmed with VoiceXML code to : . prompt a user to provide speech input ; and .", "label": "", "metadata": {}, "score": "52.377098"}
{"text": "Each phrase posting list includes a number of document identifiers therein .In this first embodiment , each of the P phrase posting lists is partitioned into a number ( S ) of portions called \" shards \" ; the partitioning process can be called \" sharding .", "label": "", "metadata": {}, "score": "52.39988"}
{"text": "On test data extracted by the heuristic strategy , however , performance of the two training sets is similar , with AERs of 13.2 % and 14.7 % respectively .Analysis of 100 pairs of sentences from each set reveals that the edit distance data lacks many of the complex lexical and syntactic alternations that characterize monolingual paraphrase .", "label": "", "metadata": {}, "score": "52.421192"}
{"text": "Alternatively , this value can directly obtained by the search system 120 by looking up each query phrase Q in the index 150 , accessing the document from the posting list of the query phrase Q , and then accessing the related phrase bit vector .", "label": "", "metadata": {}, "score": "52.42858"}
{"text": "A requesting server can determine which documents need to be transmitted to which recipient server by using the document number of each document and the shard assignment function ; this will identify which of its documents could be at the recipient server .", "label": "", "metadata": {}, "score": "52.463875"}
{"text": "( Sum(1/k ! ) ) permutations , where the sum over k goes from 1 to n , are evaluated as potential phrases .A phrase window may be terminated by an end of line , a paragraph return , the end of the document , a markup tag , or other indicia of a change in content or format .", "label": "", "metadata": {}, "score": "52.476738"}
{"text": "That is , the voice enrolled grammars can be referenced and utilized just like text enrolled grammars can be referenced and utilized .For example using the present invention , voice enrolled grammars can be referenced by standard text - based Speech Recognition Grammar Specification ( SRGS ) grammars to create more complex , usable grammars .", "label": "", "metadata": {}, "score": "52.487034"}
{"text": "The method of . claim 10 , wherein a related phrase includes a spell - corrected version of one of the component phrases .The method of . claim 10 , wherein a related phrase includes a phrase chosen for semantic similarity to at least one of the component phrases .", "label": "", "metadata": {}, "score": "52.5333"}
{"text": "Within each shard , each of the phrase posting lists is then ordered by document identifier .The shard assignment function is flexible in that the particular assignment operation can itself be a function of the phrase that is being sharded .", "label": "", "metadata": {}, "score": "52.553497"}
{"text": "Within this field , the configuration and management of large networks comprise storage devices and computers that are communicatively coupled to dissimilar computers and storage devices over a network , such as the Internet .Finally , it should be noted that the language used in the specification has been principally selected for readability and instructional purposes , and may not have been selected to delineate or circumscribe the inventive subject matter .", "label": "", "metadata": {}, "score": "52.603554"}
{"text": "Within this field , the configuration and management of large networks comprise storage devices and computers that are communicatively coupled to dissimilar computers and storage devices over a network , such as the Internet .Finally , it should be noted that the language used in the specification has been principally selected for readability and instructional purposes , and may not have been selected to delineate or circumscribe the inventive subject matter .", "label": "", "metadata": {}, "score": "52.603554"}
{"text": "A semantically bounded text sequence is identified by a semantic boundary marker that indicates that the next word to be read is semantically disjoint from the previous word or set of words in the buffer .Whenever the phrase identification server 250 encounters a text break , or whenever the buffer contains N words , the phrase identification server 250 adds the contents of the buffer ( forming a word sequence ) to a phrase map table .", "label": "", "metadata": {}, "score": "52.63768"}
{"text": "In addition the various lists , a co - occurrence matrix 212 ( G ) for the good phrases is maintained .The matrix G has a dimension of m\u00d7m , where m is the number of good phrases .Each entry G(j , k ) in the matrix represents a pair of good phrases ( g j , g k ) .", "label": "", "metadata": {}, "score": "52.655815"}
{"text": "I. System Overview .Referring now to .FIG .1 , there is shown the software architecture of an embodiment of a search system 100 in accordance with one embodiment of present invention .In this embodiment , the system includes a indexing system 110 , a search system 120 , a presentation system 130 , and a front end server 140 .", "label": "", "metadata": {}, "score": "52.6672"}
{"text": "FIG .7 is a system block diagram of a dynamic search client system that includes structuring functions .[0017 ] .FIG .8 is a diagram of a user interface .[ 0018 ] .FIG .9 is a flow diagram showing processing of a method that can be used in conjunction with components disclosed or described herein .", "label": "", "metadata": {}, "score": "52.734493"}
{"text": "Next , the search system 120 adjusts the valid phrases Qp for capitalization .When parsing the query , the search system 120 identifies potential capitalizations in each valid phrase .This may be done using a table of known capitalizations , such as \" united states \" being capitalized as \" United States \" , or by using a grammar based capitalization algorithm .", "label": "", "metadata": {}, "score": "52.76686"}
{"text": "If g i appears later in the document , and the related phrase is found again within the later secondary window , again the count is incremented .If any of these secondary related phrases counts / bits are set , then this indicates that the secondary related phrases of g j are also present in document d. .", "label": "", "metadata": {}, "score": "52.811523"}
{"text": "The strong phrase threshold can be adjusted so that all candidate phrases are devolved ( e.g. , setting the strong phrase threshold to infinity ) or it can be set low ( even below the initial phrase threshold ) , to limit the subphrase analysis .", "label": "", "metadata": {}, "score": "52.848156"}
{"text": "Another possible means of obtaining a score to be applied to a query completion includes asking a user to indicate whether a particular result is within a class of results expected by the user .Such an indication can be binary in the sense that a user can simply check a box or activated radio button or use some other means to indicate whether a result was responsive to query intended by the user .", "label": "", "metadata": {}, "score": "52.852356"}
{"text": "[ 0006 ] .A user interface is provided that interacts with a user to assist the user during the creation of a search query .This assistance can guide the user during the creation of the query to develop a query that is likely to obtain search results desired by the user .", "label": "", "metadata": {}, "score": "52.853905"}
{"text": "SUMMARY OF THE INVENTION .A method for implementing multi - action voice macros by representing a target software application program to a voice recognition navigator program in the form of an internal object tree .Each application state of a target application program is defined as a set of window objects within the application for performing a specific user task .", "label": "", "metadata": {}, "score": "52.859577"}
{"text": "For each percentage value , ten experiments have been run .All the perturbations have been applied on a model trained with 629,957 pairs of sentences randomly selected form the Europal data using Moses as translation system .The unlearning curves are shown in Figure 7 .", "label": "", "metadata": {}, "score": "52.90409"}
{"text": "It should be noted that particulars of structuring a query can and usually will vary greatly depending upon a specific implementation .[0081 ] .At process block 1240 , the structured query is sent to a search server .The search server can access some store of data , such as a relational database , and use the structured query to locate information within that store of data that is responsive to the structured query .", "label": "", "metadata": {}, "score": "52.917126"}
{"text": "TMs were limited to a phrase length of 7 words , and LMs were limited to 3 .Hardware .All the experiments have been run on high - performance clusters of machines .Additional information : ClearSpeed accelerator boards on the thick nodes ; SilverStorm Infiniband high - speed connectivity throughout for parallel code message passing ; General Parallel File System ( GPFS ) providing data access from all the nodes with a total of 11 terabytes of storage .", "label": "", "metadata": {}, "score": "52.93358"}
{"text": "In ( a ) , \" words swap TM ' ' has been obtained by swapping the target phrases inside the TM .In ( b ) , two unlearning curves have been compared . \"Numerical swap LM ' ' has been obtained applying numerical swaps only to the LM and \" numerical swap TM ' ' applying numerical swaps only to the LM .", "label": "", "metadata": {}, "score": "52.958736"}
{"text": "The first statistical models were word based [ 2 , 11 ] , combining a Markovian language model with a generative word - to - word translation model , in a noisy channel model inspired by speech recognition research .Current state - of - the - art SMT uses phrase - based models , which generalized and superseded word - based models .", "label": "", "metadata": {}, "score": "53.020508"}
{"text": "This process will include identification of the parent - child relationship of the objects on the user interface screen , and the attributes of each object .The software tools which may be used for this purpose can be either commercially available programs designed for analyzing window attribute data , or custom programs specifically developed for performing such analysis .", "label": "", "metadata": {}, "score": "53.021877"}
{"text": "In those cases , the related phrase bit vectors can be directly accessed , and then used next to retrieve corresponding documents .This process is more fully described as follows .Given any two query phrases Q 1 and Q 2 , there are three possible cases of relations : . 1 ) Q 2 is a related phrase of Q 1 ; . 2 ) Q 2 is not a related phrase of Q 1 and their respective related phrases Qr 1 and Qr 2 do not intersect ( i.e. , no common related phrases ) ; and .", "label": "", "metadata": {}, "score": "53.025723"}
{"text": "The posting list include sa list of documents d ( by their document identifiers , e.g. a document number , or alternatively a URL ) in which the phrase occurs .In addition , the co - occurrence matrix 212 is updated , as further explained below .", "label": "", "metadata": {}, "score": "53.118332"}
{"text": "If the candidate phrase hit position was \" final \" and had a score of X , the first child is indicated as a medial hit with score X/2 , the second child is indicated as final hit with score X. .", "label": "", "metadata": {}, "score": "53.145233"}
{"text": "The index is typically divided amongst a large number of index servers , in which each index server will contain an index that includes all of the unique terms , and for each of these terms , some portion of the posting list .", "label": "", "metadata": {}, "score": "53.165527"}
{"text": "However , the mapping between words is stored in a very redundant way within the TM , and this depends on the way the translation table is created , based on sentence alignments .Once an alignment has been found between two sentences , essentially every n -gram ( for every value of n ) is a candidate for insertion in the translation table .", "label": "", "metadata": {}, "score": "53.191605"}
{"text": "At process block 1440 , results from a set of results are presented to user .Processing continues to process block 1450 where user feedback is obtained .In this specific example , it can be assumed that results in a set of results are ranked and that an overall level of quality of the results in the set is a suitable proxy for a level of quality of the completed user query .", "label": "", "metadata": {}, "score": "53.237373"}
{"text": "This is because each the first word in the phrase window 302 is always a candidate phrase , and the appropriate instance counts will be accumulated .Thus , the indexing system 110 can automatically index both individual words ( i.e. , phrases with a single word ) and multiple word phrases .", "label": "", "metadata": {}, "score": "53.313137"}
{"text": "This learning curve reports BLEU score versus the percentage of perturbation applied .These results have been obtained using a fixed training set size equal to 62,995 and 629,957 pairs of sentences and Moses as translation system .Figure 7 : Unlearning curves .", "label": "", "metadata": {}, "score": "53.374645"}
{"text": "First , the search system 120 determines a score adjustment value for each document .The score adjustment value is a mask formed from the bits in the positions corresponding to the query phrases Q 1 and Q 2 in the related phrase bit vector for a document .", "label": "", "metadata": {}, "score": "53.396126"}
{"text": "[ 0071 ] .Those of ordinary skill in the art should also recognize that other information may be combined with user - entered phrase to further refine search results .For example , all of the user 's activities at the computer can be monitored or logged .", "label": "", "metadata": {}, "score": "53.42398"}
{"text": "The present invention has further embodiments in computer system and software architectures , computer program products and computer implemented methods , and computer generated user interfaces and search result contents .The foregoing are just some of the features of an information retrieval system and methodology based on phrases .", "label": "", "metadata": {}, "score": "53.43222"}
{"text": "Raising the threshold over 1.0 serves to reduce the possibility that two otherwise unrelated phrases co - occur more than randomly predicted .As noted the computation of information gain is repeated for each column k of the matrix G with respect to a given row j. Once a row is complete , if the information gain for none of the good phrases g k exceeds the information gain threshold , then this means that phrase g j does not predict any other good phrase .", "label": "", "metadata": {}, "score": "53.43831"}
{"text": "This can be accomplished by various means and the invention is not limited in this regard .For example the navigator may rely upon recursive function calls or the stack data structure maintained by the navigator program to create a record of the path which has been traversed .", "label": "", "metadata": {}, "score": "53.505394"}
{"text": "According to the embodiment described above the adaptation strength and therefore the influence of a speech phrase on the adaptation process may recover in periods of the adaptation process having infrequent or no occurrences of the speech phrase in question .This enables the inventive method to give frequently occuring speech phrases a lower adaptation strength and therefore a lower influence on the adaptation process of said current acoustic model .", "label": "", "metadata": {}, "score": "53.544086"}
{"text": "It has been distinguished between truly unknown words ( or stems ) and unseen forms of known stems .The unknown words are the direct effect of Zipf 's law in a language , as new words can come , but the training set is not flexible enough to cover them .", "label": "", "metadata": {}, "score": "53.556595"}
{"text": "They contain different modules to preprocess data and train the language models and the translation models .These models can be tuned using minimum error rate training [ 17 ] .Both use standard external tools for training the language model , such as SRILM [ 23 ] , and Moses also uses GIZA++ [ 24 ] for word alignments .", "label": "", "metadata": {}, "score": "53.685173"}
{"text": "[ 0086 ] .At process block 1340 , results of the search before the process block 1330 are obtained .Processing continues at process block 1350 where the search results are matched with additional content .In this manner , additional content such as advertising can be keyed to specific interests of the user .", "label": "", "metadata": {}, "score": "53.766083"}
{"text": "At process block 1130 , the phrase is segmented and a search based on that segment is performed at process block 1140 .Results of that search are presented at process block 1150 .[ 0078 ] .At decision block 1160 , a determination is made whether the user has selected a result from among the results presented at process block 1150 .", "label": "", "metadata": {}, "score": "53.80018"}
{"text": "For example , one aspect of the present invention can include a VoiceXML language that includes voice enrolled grammar language elements as part of its language mode .The elements can include an addvoicephrase , a deletevoicephrase , and/or an updatevoicephrase element .", "label": "", "metadata": {}, "score": "53.909218"}
{"text": "Another aspect of the information retrieval system is a method by which a query schedule is executed by the set of tiered and sharded index servers .The query schedule identifies for each node which index server the node is assigned to .", "label": "", "metadata": {}, "score": "53.99225"}
{"text": "claim 16 , wherein the means for referencing a set of suggestions includes means for referencing a ranking of suggestions .The system of .claim 16 , further comprising means for searching for results that are based at least in part upon a query derived from the suggestion .", "label": "", "metadata": {}, "score": "54.0512"}
{"text": "Also notable is that servers can coordinate information in a variety of ways .The search server itself can include a group of individual servers or can simply be a component on the user 's own machine .Servers can communicate with each other directly instead of , or in addition to , communicating with the user interface or other client component .", "label": "", "metadata": {}, "score": "54.058296"}
{"text": "The language pairs cover European as well as non - European languages , and the sizes range from 1.2 M to 22.5 M sentence pairs .We expect that translation between European languages will be easier than from Chinese to English ; however , we are not so much interested in the actual translation performance as in the way this performance evolves with increasing data and under a number of conditions .", "label": "", "metadata": {}, "score": "54.060436"}
{"text": "The phraseid attribute can be a required attribute that represents an i d of a voice phrase being added .An alternative to the phraseid attribute is the phraseidexpr attribute , which is associated with a phrase expression instead of a reference to an expression .", "label": "", "metadata": {}, "score": "54.08647"}
{"text": "Accordingly , reference should be made to the following claims , rather than to the foregoing specification , as indicating the scope of the invention .", "label": "", "metadata": {}, "score": "54.09016"}
{"text": "This setting has been applied to Europarl and Giga corpus datasets using Moses as SMT system . vary across the datasets and correspond to an increase of 1.3 to 1.5 BLEU point for the LM and 1.8 to 1.9 for the TM , for each doubling of the data .", "label": "", "metadata": {}, "score": "54.09518"}
{"text": "The program can also be provided as a digitally encoded signal conveyed via a carrier wave .The described program can be a single program or can be implemented as multiple subprograms , each of which interact within a single computing device or interact in a distributed fashion across a network space .", "label": "", "metadata": {}, "score": "54.098324"}
{"text": "In one embodiment , the search system 120 calculates a score for each document that is a function ( e.g. , linear combination ) of two scores , a body hit score and an anchor hit score .The weights of 0.30 and 0.70 can be adjusted as desired .", "label": "", "metadata": {}, "score": "54.106773"}
{"text": "The voice navigator program associates the decoded phrase with the sub - context object containing a vocabulary element corresponding to the decoded phrase .When a voice command is received which matches a word or phrase contained within one of the sub - context vocabularies , the associated voice macro is activated .", "label": "", "metadata": {}, "score": "54.10971"}
{"text": "The attributes of this next higher level sub - context object are then compared to the foreground window 's attributes in step 119 .Again , if there is no match , the process of traversing up the active sub - context tree to the parent object is repeated until a foreground sub - context object which matches the foreground window , is found .", "label": "", "metadata": {}, "score": "54.125965"}
{"text": "FIG .1 is a schematical block diagram showing the fundamental steps of an embodiment of the inventive method for recognizing speech .FIG .2 is a schematical block diagram showing in more detail the embodiment of FIG .1 . DETAILED DESCRIPTION OF THE DRAWINGS .", "label": "", "metadata": {}, "score": "54.13462"}
{"text": "One effective way to do that is to post - edit the translations produced by a vanilla RBMT system using a specially - trained statistical machine translation ( SMT ) system .Our experiments indicate that this method is just as effective as manual customization of system dictionaries in reducing the need for manual post - editing . ... entence - length feature .", "label": "", "metadata": {}, "score": "54.13463"}
{"text": "The foregoing section described the processes and structures by which the phrase - based index is created .Further aspects of the present invention are the processes and structures used to maintain and update the index over time .Referring again to .", "label": "", "metadata": {}, "score": "54.205452"}
{"text": "The front end server 140 receives queries from a user of a client 170 , and provides those queries to the search system 120 .The search system 120 is responsible for searching for documents relevant to the search query ( search results ) , including identifying any phrases in the search query , and then ranking the documents in the search results using the presence of phrases to influence the ranking order .", "label": "", "metadata": {}, "score": "54.215565"}
{"text": "That is , the voice enrolled grammars can be referenced and utilized just like text enrolled grammars can be referenced and utilized .For example , using the present invention , voice enrolled grammars can be reference by standard text - based Speech Recognition Grammar specification ( SRGS ) grammars to create more complex , usable grammars .", "label": "", "metadata": {}, "score": "54.219284"}
{"text": "Moderate support is exemplarily shown by the phrase having its combined document phrase scores being above a second threshold .Finally , broad support is exemplarily shown by the phrase occurring in a minimum number of documents having a minimum phrase score ; the minimum required score can be set at a level to further control or limit the required breadth of support .", "label": "", "metadata": {}, "score": "54.237926"}
{"text": "The presentation system 130 then stable sorts this set of user related phrases Ur according to the value of the bit vectors themselves , prepending the sorted list to the list of query related phrases Qr , and removes any duplicate phrases .", "label": "", "metadata": {}, "score": "54.26438"}
{"text": "Data .We used three different sentence - aligned corpora , covering different language pairs and sizes : ( 1 ) Europarl Release v3 Spanish - English [ 7 ] , ( 2 ) UN Chinese - English corpus provided by the Linguistic Data Consortium , ( 3 ) Giga corpus French - English [ 8 ] .", "label": "", "metadata": {}, "score": "54.32537"}
{"text": "Another problem with existing individual term based indexing systems lies in the arrangement of the server computers used to access the index .In a conventional indexing system for large scale corpora like the Internet , the index comprises the posting lists for upwards of 200,000 unique terms .", "label": "", "metadata": {}, "score": "54.327583"}
{"text": "For example , depending upon certain real - life events , probabilities can be assigned to various search terms in order to attempt to maximize all likelihood that a user obtains responsive information to his query .[0058 ] .One possible mode of operation of the dynamic search client 500 follows .", "label": "", "metadata": {}, "score": "54.33457"}
{"text": "Phrase Based Personalization of Search .Another aspect of the search system 120 is the capability to personalize 606 or customize the ranking of the search results in accordance with a model of the user 's particular interests .In this manner , documents that more likely to be relevant to the user 's interests are ranked higher in the search results .", "label": "", "metadata": {}, "score": "54.402447"}
{"text": "In recent years , various software systems have been developed to enable an application program executing on a computer to recognize and respond to voice commands .Such programs are advantageously designed as independent or stand - alone systems which provide voice recognition capabilities to existing commercially available target application programs .", "label": "", "metadata": {}, "score": "54.44259"}
{"text": "If all of the predicted phrases g k are phrase extensions of phrase g j , then phrase g j is incomplete , and is removed from the good phrase list 208 , and added to an incomplete phrase list 216 .", "label": "", "metadata": {}, "score": "54.5287"}
{"text": "In a typical embodiment of the phrase extraction process , anywhere from 1,000,000 to 10,000,000,000 phrases can be identified .Indexing System with Tiers and Shards .The next functional operation of the indexing system 110 is to index documents in the collection using the phrase data 255 , and store the index information in the segment shard files 225 , from which the index servers 200 will be updated .", "label": "", "metadata": {}, "score": "54.5305"}
{"text": "0008 ] .A method of searching is provided .The method includes dynamically suggesting to a user at least one search query that the user may select as the user constructs the search query .The user can add , delete , or change search terms to focus the query to obtain desired results .", "label": "", "metadata": {}, "score": "54.55659"}
{"text": "A document may have one or more pages , partitions , segments or other components , as appropriate to its content and type .Equivalently a document may be referred to as a \" page , \" as commonly used to refer to documents on the Internet .", "label": "", "metadata": {}, "score": "54.635136"}
{"text": "Description .BACKGROUND OF THE INVENTION .The present invention relates to a method for recognizing speech according to the preamble of claim 1 , and in particular to a method for recognizing speech which avoids over - adaptation to certain words during online speaker adaptation .", "label": "", "metadata": {}, "score": "54.64186"}
{"text": "That means that the speech phrase subunit is evaluated with respect to the acoustical neighbourhood appearing in the evaluated utterance .In applications of common methods and devices for recognizing speech it appears that based on the specific context in which the applied methods and devices have to work the speech input contains distinct speech phrases , words or sounds in certain contexts much more often than most other words .", "label": "", "metadata": {}, "score": "54.64859"}
{"text": "8(A ) and ( b ) .In step 114 , the navigator compares the attributes of the target sub - context object with the attributes of the foreground window .In order to understand what is meant by the term \" foreground window \" , it is helpful to have some background regarding the concept of z - order and the manner in which the Windows operating system organizes the various window objects which may appear on a user interface screen .", "label": "", "metadata": {}, "score": "54.671806"}
{"text": "0070 ] .It should be appreciated that other complex data can be presented to the user instead of , or in addition to , preliminary search results .Such presentations can be in the form of sponsored links to advertisers ' web sites , online services , multimedia previews , or another appropriate information presentation .", "label": "", "metadata": {}, "score": "54.69547"}
{"text": "The selection of shard assignment function is then determined by document collection statistics , such as frequency or probability of the phrase .The following simplified example illustrates the basic concept of sharding , using a single shard assignment function .Assume the following phrase posting lists P 1 , P 2 , P 3 , and P 4 , each of which has some set of documents , indicated by document .", "label": "", "metadata": {}, "score": "54.715862"}
{"text": "Method according to . claim 1 , . wherein the current acoustic model ( CAM ) is based on a set of model function mixtures ( MFM 1 , . . ., MFMn ) and .Method according to . claim 1 , . wherein words , subword units , phones , phonemes , syllables , letters and/or the like and/or combinations thereof are used as said speech phrases ( SPj ) and/or as said speech phrase subunits ( SPSj k ) of said current acoustic model ( CAM ) and . wherein in each case said speech phrases ( SPj ) are combinations or concatenations of said speech phrase subunits ( SPSj k ) .", "label": "", "metadata": {}, "score": "54.74871"}
{"text": "Within a given phrase posting list there are identified the documents associated with the phrase .These documents are then assigned across some set of shards using a shard assignment function , which has the property that a given document is always assigned to the same shard , regardless of the phrase posting list in which it appears .", "label": "", "metadata": {}, "score": "54.75126"}
{"text": "A shard assignment function is then used for each tier to partition the phrase posting list assigned to the tier amongst the shards .As before , each shard is stored in one of the index servers associated with that tier .", "label": "", "metadata": {}, "score": "54.755745"}
{"text": "506 : Reorder index entries according to posting list size .These stages are now described in further detail .A set of documents is traversed or crawled , as before ; this may be the same or a different set of documents .", "label": "", "metadata": {}, "score": "54.785072"}
{"text": "Richer hypothesis classes can fit the training data more accurately but generalize less well than poorer classes , a phenomenon known as overfitting .The choice of the appropriate expressive power , within a parametrized class of models , is called model selection and is one of the most crucial steps in the design of learning systems .", "label": "", "metadata": {}, "score": "54.807213"}
{"text": "As described above , for any given phrase g j , each document d in the g j 's posting list has an associated related phrase bit vector that identifies which related phrases g k and which secondary related phrases g l are present in document d. The more related phrases and secondary related phrases present in a given document , the more bits that will be set in the document 's related phrase bit vector for the given phrase .", "label": "", "metadata": {}, "score": "54.86121"}
{"text": "If neither the phraseid nor phraseidexpr is specified , a badfetch error and be thrown .The src attribute can be a required attribute that represents the new or existing personal grammar that will be updated with the new phraseid .An alternative to the src attribute is the srcexpr attribute , which is associated with a grammar 's identifier instead of a reference to a grammar identifier .", "label": "", "metadata": {}, "score": "54.89834"}
{"text": "claim 1 , wherein the probability of occurrence of the component phrases of a candidate phrasification is based on an estimated probability figure .The method of .claim 1 , wherein the probability of occurrence of the component phrases of a candidate phrasification is based on a proportion of documents to be searched that contain the component phrase .", "label": "", "metadata": {}, "score": "54.940586"}
{"text": "Information retrieval systems , generally called search engines , are now an essential tool for finding information in large scale , diverse , and growing information systems such as the Internet .Generally , search engines create an index that relates documents ( or \" pages \" ) to the individual words present in each document .", "label": "", "metadata": {}, "score": "54.94808"}
{"text": "Using alignment techniques from phrasebased statistical machine translation , we show how paraphrases ... \" .Previous work has used monolingual parallel corpora to extract and generate paraphrases .We show that this task can be done using bilingual parallel corpora , a much more commonly available resource .", "label": "", "metadata": {}, "score": "55.009804"}
{"text": "Feature function weights in the log - linear model are set using Och 's minimum ... . \" ...Abstract - This paper describes an approach for computing a consensus translation from the outputs of multiple machine translation ( MT ) systems .", "label": "", "metadata": {}, "score": "55.011295"}
{"text": "2 stores shard 2 for all of the phrase posting lists , and so forth through index server 200 .S , which stores the S th shard for all phrase posting lists .Additionally , a given shard ( e.g. one containing high frequency phrases ) may be duplicated and stored on multiple index servers 200 in order to increase performance .", "label": "", "metadata": {}, "score": "55.016037"}
{"text": "ii ) compute the actual co - occurrence rate A(j , k ) of g j and g k .This is the raw co - occurrence count R(j , k ) divided by T , the total number of documents ; . iii ) g j is said to predict g k where the actual co - occurrence rate A(j , k ) exceeds the expected co - occurrence rate E(j , k ) by a threshold amount .", "label": "", "metadata": {}, "score": "55.06427"}
{"text": "The following steps are taken by the indexing system 110 for each document that is crawled .Traverse the words of the document with a phrase window length of n , where n is a desired maximum phrase length .The length of the window will typically be at least 2 , and preferably 4 or 5 terms ( words ) .", "label": "", "metadata": {}, "score": "55.084396"}
{"text": "Preferred and advantageous embodiments of the method for recognizing speech according to the invention are within the scope of the dependent subclaims .It is therefore the basic idea of the present invention to distinguish the occuring speech phrases within the incoming speech flow by their frequency of occurrence and/or by their frequency of serving as a basis for the adaptation process of the current acoustic model .", "label": "", "metadata": {}, "score": "55.10526"}
{"text": "As a result , when a search query using the anchor text is entered , the desired page is typically returned , even if in fact this page has little or nothing to do with the anchor text .Each phrase in the index 150 is also given a phrase number , based on its frequency of occurrence in the corpus .", "label": "", "metadata": {}, "score": "55.118973"}
{"text": "d )For an OR node , an initial evaluation cost of the OR node is assigned that is equal to the sum of the evaluation costs of its children .Otherwise , the evaluation cost of an OR node is equal to its initial evaluation cost .", "label": "", "metadata": {}, "score": "55.134277"}
{"text": "6 shows an example of a three tier embodiment , here using three tiers , Tier 1 , Tier 2 , and Tier 3 .Tier 1 stores a set of 10,000 phrase posting lists , each of which has one shard .", "label": "", "metadata": {}, "score": "55.192417"}
{"text": "( ii ) Unlearning by Randomization of Parameters .The second kind of noise that we add to the model is based on a swap of a particular quantity inside two entries of language or translation model .This is meant to test how robust the system is to perturbations of the all - important associations between phrases / numbers and to the associations between source / target phrases .", "label": "", "metadata": {}, "score": "55.235012"}
{"text": "If no , the phrase is matched with suggestions at process block 1020 .If yes , processing continues at process block 1025 where a suggestion subset is obtained to narrow the set of possible suggestions based upon earlier phrase information .", "label": "", "metadata": {}, "score": "55.318382"}
{"text": "Certain aspects of the present invention include process steps and instructions described herein in the form of an algorithm .It should be noted that the process steps and instructions of the present invention could be embodied in software , firmware or hardware , and when embodied in software , could be downloaded to reside on and be operated from different platforms used by real time network operating systems .", "label": "", "metadata": {}, "score": "55.344223"}
{"text": "Certain aspects of the present invention include process steps and instructions described herein in the form of an algorithm .It should be noted that the process steps and instructions of the present invention could be embodied in software , firmware or hardware , and when embodied in software , could be downloaded to reside on and be operated from different platforms used by real time network operating systems .", "label": "", "metadata": {}, "score": "55.344223"}
{"text": "According to a further preferred embodiment for recognizing speech the counted adaptation numbers and/or occurrence numbers are not only counted from the very beginning of the recognition session but they are allowed to also be decreased and/or reduced during the continuation of the current recognition session .", "label": "", "metadata": {}, "score": "55.34939"}
{"text": "Tiers then are understood to group the rows together ( though not necessarily in any particular order within each group ) ; this can be considered a \" horizontal \" grouping .Shards by contrast can be understood as \" vertical \" partitions , since they divide up each row into a number of portions .", "label": "", "metadata": {}, "score": "55.370575"}
{"text": "6 is a block diagram of yet another embodiment of the storage architecture for the phrase posting lists in the index servers .FIG .7 is an illustration of the merging of segment shard files into index shard files .FIG .", "label": "", "metadata": {}, "score": "55.4532"}
{"text": "tried by MERT , new hypothesis translations are added to the list .As the number of hypotheses produced by the decoder is finite , this is guaranteed to converge , and in practice , it does fairly quickly .An additional difficulty is that the landscape of the cost , for example , BLEU , is piecewise constant and highly irregular .", "label": "", "metadata": {}, "score": "55.532463"}
{"text": "The score is also scaled by the location of the hit , with locations towards the start of the document ( e.g. , title ) being more highly scaled .Typeface can also be used for scaling , including increasing the score for bold text , or a large font size .", "label": "", "metadata": {}, "score": "55.560677"}
{"text": "We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models .Compared to the standard practice of intersecting predictions of independently - trained models , joint training provides a 32 % reduction in AER .", "label": "", "metadata": {}, "score": "55.575287"}
{"text": "Tools . \" ...Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .SMT has made tremendous strides in less than two decades , and many popular tec ... \" .", "label": "", "metadata": {}, "score": "55.586956"}
{"text": "7 , which is a block diagram showing the interaction between a voice navigator 102 , voice recognition engine 104 , target application context file 106 , and target application 22 .According to a preferred embodiment of the invention , an active vocabulary set for the current target application state is obtained by retrieving and combining one or more sub - context object vocabulary sets 80 contained within each sub - context object of a current sub - context tree 108 .", "label": "", "metadata": {}, "score": "55.664284"}
{"text": "In accordance to the measures described above an adaptation of the current acoustic model is not necessarily performed after each step of recognition but an adaptation takes place after given numbers of recognition steps or recognition results obtained .The ruling numbers can be determined in an on - line process during recognition or adaptation .", "label": "", "metadata": {}, "score": "55.689156"}
{"text": "A dynamic search client used in such a capacity can provide an easy to use , natural , and intuitive interface to a data storage system that uses complex query forms and requires a large amount of specialized training to use .", "label": "", "metadata": {}, "score": "55.73342"}
{"text": "Each index server B i receives the query ( [ sublist data ] AND B ) , preferably operating in parallel .Each index server B i determines if the AND node can be executed locally .If so , the node is executed and the index server finds only the sublist data and another node ( the local shard of phrase B 's posting list ) which can be executed locally .", "label": "", "metadata": {}, "score": "55.74073"}
{"text": "The hierarchical tree allows the voice navigator to have an internal representation of the manner in which every window object of a target application is associated with every other such object .For example , in FIG .1(A ) , the screen display shown is for a top - level window object 26 of a target application state .", "label": "", "metadata": {}, "score": "55.74942"}
{"text": "Beginning then from the least cost child node , the child nodes are partitioned into subsequences , each subsequence containing a set of children which have the same assigned set of index servers 200 .To each subsequence , assign an evaluation cost equal to the minimum evaluation cost of any child node of that subsequence .", "label": "", "metadata": {}, "score": "55.766052"}
{"text": "If for example a given speech phrase occurs in a first period of recognition very often , its adaptation strength is reduced according to the invention so as to avoid over - adaptation with respect to that particular speech phrase .Then a second period of recognition may occur in which this distinct speech phrase is not contained and not received .", "label": "", "metadata": {}, "score": "55.78675"}
{"text": "The distortion feature controls the reordering between phrases .Note that only very short - range reordering may be handled within phrases .Long - range reordering must be handled by target phrase permutations .This feature allows to regulate the amount of reordering depending on , for example , the language pair .", "label": "", "metadata": {}, "score": "55.86802"}
{"text": "Abstract .This paper describes a system that resolves prepositional phrase attachment ambiguity in English sentence process- ing .This attachment problem is ubiquitous in English text , and is widely known as a place where semantics determines syntactic form .The decision is made based on a four - tuple composed of the head verb of the verb phrase , the head noun of the noun phrase , and the preposition and head noun in the prepositional phrase .", "label": "", "metadata": {}, "score": "55.921432"}
{"text": "d )For each OR node : .( i )If the OR node is the child of an AND node and is not the leftmost child thereof , assign to the OR node the same set of index servers 200 and cost from the node which is immediately to its left ; .", "label": "", "metadata": {}, "score": "55.949642"}
{"text": "If a user speaks a particular phrase or word repeatedly the speaker adaptation transforms the specific distribution or model function mixture , in particular Gaussians , in a way that they optimally fit to that particular phrase , utterance or word .", "label": "", "metadata": {}, "score": "55.984818"}
{"text": "We have undertaken a large scale experimental and theoretical investigation of these questions .We use this data to inform a discussion about learning curves .We have also investigated the model - selection properties of n -gram size , where the n -grams are the phrases used as building blocks in the translation process .", "label": "", "metadata": {}, "score": "56.05202"}
{"text": "The method of . claim 2 , wherein the document discarded has a lower document significance measure than the other document .The method of .claim 3 , wherein the document significance measure includes a page rank of the document .", "label": "", "metadata": {}, "score": "56.074432"}
{"text": "New \" and \" York restaurants \" ; and . \" New York restaurants \" .Some number of the highest scoring phrasifications are then selected as best representing valid phrases in the input text .Another aspect of the information retrieval system is a method of query scheduling the creates an schedule for executing a search of the phrases of a query so as to minimize query processing costs by the index servers , as well as to reduce inter - server communications .", "label": "", "metadata": {}, "score": "56.21772"}
{"text": "claim 3 , wherein discarding at least one of the first document or the second document from the set of documents comprises removing the first document or the second document from an index .The method of .claim 1 , wherein comparing the document description of the first document with a document description of the second document further comprises : . for the first document , generating the document description of the first document by selecting sentences of the document , and ordering the selected sentences in the document description as a function of a number of related phrases in the selected sentences ; and .", "label": "", "metadata": {}, "score": "56.290577"}
{"text": "The tree allows the navigator to associate decoded spoken commands to specific window objects .A set of attributes is assigned to each of the sub - context objects within the sub - context tree .These attributes can include , but are not limited to a window class name , a window identification number , a window text string , and a window enumeration index value for a corresponding window object .", "label": "", "metadata": {}, "score": "56.36883"}
{"text": "1 is a schematic diagram of a system 100 that permits acoustically provided phrases to be enrolled using VoiceXML code that natively supports voice enrolled grammars in accordance with an embodiment of the inventive arrangements disclosed herein .In system 100 , a speaker 105 or audio source 110 participating in enrollment sessions 150 - 154 with enrollment server 120 can modify a set of phrases contained within a voice enrolled grammar 130 - 136 .", "label": "", "metadata": {}, "score": "56.42667"}
{"text": "Our key assumption is that collocation errors are often caused by semantic similarity in the first language ( L1language ) of the writer .An analysis ... \" .We present a novel approach for automatic collocation error correction in learner English which is based on paraphrases extracted from parallel corpora .", "label": "", "metadata": {}, "score": "56.427956"}
{"text": "In such a case prior art adaptation methods would not only adapt the involved particular acoustic models or phoneme models to the speaker but also to the specific acoustic properties in the context of these frequently occuring words , phrases or utterances .", "label": "", "metadata": {}, "score": "56.429672"}
{"text": "This is because the rate of improvement of translation performance is at best logarithmic with the training set size .We estimate that bridging the gap between training and test error would require about .paired bilingual sentences , which is larger than the current estimated size of the web .", "label": "", "metadata": {}, "score": "56.471283"}
{"text": "The system of . claim 19 , wherein related words of the input text include synonyms of the words of the input text .The system of . claim 19 , wherein related words of the input text include words chosen for semantic similarity to at least one of the words of the input text .", "label": "", "metadata": {}, "score": "56.493042"}
{"text": "In fact , a common belief in SMT is that learning curves follow logarithmic laws ; to analyze this in our experiments , we show all the learning curves in the linear log scale , where we can study if the curve has a linear behaviour .", "label": "", "metadata": {}, "score": "56.520065"}
{"text": "A briefly discussion about the presence of unknown words when we test on a subset of the training set is given by Section 4.3 .Figure 11 : Number of unknown words translating training and test sets versus training set size .", "label": "", "metadata": {}, "score": "56.52492"}
{"text": "The system of .claim 28 , wherein a related phrase includes a phrase synonymous with one of the component phrases .The system of .claim 28 , wherein a related phrase includes a phrase synonymous with one of the component phrases .", "label": "", "metadata": {}, "score": "56.599243"}
{"text": "For example , the search system 120 can remove any documents that contain more than two clusters .This cluster threshold can be predetermined , or set by the user as a search parameter .b )Ranking Documents Based on Anchor Phrases .", "label": "", "metadata": {}, "score": "56.637527"}
{"text": "545 547 ; Ordered Group Manipulation Methodology via Configurable Model Bar .IBM Technical Disclosure Bulletin , vol .38 , No . 02 , Feb. 1995 , pp .57 61 ; Voice Augmented Menu Automated Telephone Response System .System for providing personalized content over a telephone interface to a user according to the corresponding personalization profile including the record of user actions or the record of user behavior An information retrieval system uses phrases to index , retrieve , organize and describe documents .", "label": "", "metadata": {}, "score": "56.65459"}
{"text": "To perform such suggestion tasks , the phrase suggestion engine 220 can access a phrase data store 230 .The phrase suggestion engine 220 can use a portion of a phrase entered by a user at the user interface 210 as a root or some other basis to suggest , predict , infer , or otherwise determine a likely phrase that the user is entering .", "label": "", "metadata": {}, "score": "56.663776"}
{"text": "The user interface 210 then presents the response of an affirmation or failure message to the user .It should be noted that such searches performed by the search engine can also be performed incrementally as each individual phrase is suggested by the phrase suggestion engine 220 .", "label": "", "metadata": {}, "score": "56.683865"}
{"text": "In a preferred embodiment according to the invention , the aforementioned plurality of application states 24 can be determined by a program developer alone or with the help of specifically developed software analysis tool .The foregoing analysis can be performed in several ways , and the invention is not limited in this regard .", "label": "", "metadata": {}, "score": "56.750607"}
{"text": "In current voice recognition navigator systems , each voice command typically represents one user action .These actions could be a series of keystrokes , mouse click events , or other macro implementations .A macro is a single command phrase which causes a pre - recorded sequence of actions to take place .", "label": "", "metadata": {}, "score": "56.81372"}
{"text": "0097 ] .In order to provide additional context for implementing various aspects of the subject invention , .FIGS .15 - 16 and the following discussion is intended to provide a brief , general description of a suitable computing environment within which various aspects of the subject invention may be implemented .", "label": "", "metadata": {}, "score": "56.83206"}
{"text": "1(A ) is an example of a screen display for a top - level window object .FIG .1(B ) is an example of a tree which shows the hierarchical relationship of the top - level window object in FIG .", "label": "", "metadata": {}, "score": "56.89175"}
{"text": "[ 0051 ] .Based upon the phrase or phrases submitted and other factors such as whether the phrase or phrases is or are to be treated as a prefix , a suffix , or otherwise , the search server will identify at least one suggestion .", "label": "", "metadata": {}, "score": "57.02759"}
{"text": "Specifically , the method 1400 can be used to obtain user feedback regarding the quality of a completed query for use in improving for future query completions .Such user feedback can take a variety of forms , specifically including forms that can be used in a scoring system .", "label": "", "metadata": {}, "score": "57.05793"}
{"text": "FIG .5(A ) is an example of a single sub - context object 54 which contains the foregoing attributes .However , it should be understood that each of the sub - context objects preferably contains similar information .In addition to the foregoing analysis , each window object of the target application program is preferably analyzed to determine specific information regarding its functions .", "label": "", "metadata": {}, "score": "57.083275"}
{"text": "The present invention has been described in particular detail with respect to one possible embodiment .Those of skill in the art will appreciate that the invention may be practiced in other embodiments .Further , the system may be implemented via a combination of hardware and software , as described , or entirely in hardware elements .", "label": "", "metadata": {}, "score": "57.08413"}
{"text": "The present invention has been described in particular detail with respect to one possible embodiment .Those of skill in the art will appreciate that the invention may be practiced in other embodiments .Further , the system may be implemented via a combination of hardware and software , as described , or entirely in hardware elements .", "label": "", "metadata": {}, "score": "57.08413"}
{"text": "The explicit data nodes can also be used to transport additional data ( e.g. , scheduling information , metadata ) to the index servers 200 .The execution process thus begins with the root query execution module 830 executing on the root node of the query schedule , and proceeds by recursive descent via the query execution modules of the index servers .", "label": "", "metadata": {}, "score": "57.08898"}
{"text": "The sub - context object path 1 52 identifies the path the voice navigator must follow , starting from the root of the sub - context tree , to locate the sub - context object containing the linked macro to be performed .", "label": "", "metadata": {}, "score": "57.147568"}
{"text": "Understanding the most important reasons for failure of a PBSMT system is a fundamental task .In [ 39 ] , a classification of different types of error has been proposed .In this section , we focus our attention on a particular type of error : unknown words .", "label": "", "metadata": {}, "score": "57.151085"}
{"text": "We propose a theory that gives formal semantics to word - level alignments defined over parallel corpora .We use our theory to introduce a linear algorithm that can be used to derive from word - aligned , parallel corpora the minimal set of syntactically motivated transformation rules that explain human ... \" .", "label": "", "metadata": {}, "score": "57.159966"}
{"text": "The search system 120 then makes a second pass through the capitalized phrases , and selects only those phrases are leftmost and capitalized where both a phrase and its subphrase is present in the set .For example , a search on \" president of the united states \" will be capitalized as \" President of the United States \" .", "label": "", "metadata": {}, "score": "57.20771"}
{"text": "The next step is to determine 402 which related phrases together form a cluster of related phrases .A cluster is a set of related phrases in which each phrase has high information gain with respect to at least one other phrase .", "label": "", "metadata": {}, "score": "57.22352"}
{"text": "2142 - 2147 , Genova , Italy , 2006 .N. Draper and H. Smith , Applied Regression Analysis , John Wiley & Sons , New York , NY , USA , 1981 .F. J. Och , \" Statistical machine translation : foundations and recent advances , \" in Proceedings of the Tutorial at MT Summit , 2005 .", "label": "", "metadata": {}, "score": "57.22461"}
{"text": "This window is then shifted right M - N times , where M is the number of terms in the query .At each window position , there will be N terms ( or fewer ) terms in the window .These terms constitute a possible query phrase .", "label": "", "metadata": {}, "score": "57.228798"}
{"text": "This measure considers the fact that after a large number x of adaptation steps it is not important to restrict the contribution of a certain word or phoneme compared to a case with low numbers of x. .In each case x has to be initialized and incremented as shown in steps 21 and 27 , respectively .", "label": "", "metadata": {}, "score": "57.286446"}
{"text": "claim 1 , wherein decomposing the input text includes replacing one or more of the component phrases with a related phrase .The method of . claim 10 , further comprising assigning a confidence level to component phrases of a candidate phrasification , wherein component phrases not present in the input text are assigned a lesser confidence level than a component phrases present in the original input text .", "label": "", "metadata": {}, "score": "57.304695"}
{"text": "If a phrase Q in the query has a set of phrase extensions Qe ( as further explained below ) , then the search system 120 first forms the union of the posting lists of the phrase extensions , prior to doing the intersection with the posting lists .", "label": "", "metadata": {}, "score": "57.32913"}
{"text": "Without loss of generality then , the documents generally , regardless of format or location ( e.g. , which website or database ) will be collectively referred to as a corpus or document collection .Each document has an associated identifier that uniquely identifies the document ; the identifier is preferably a URL , but other types of identifiers ( e.g. , document numbers ) may be used as well .", "label": "", "metadata": {}, "score": "57.365543"}
{"text": "The user can then terminate the construction of the query and select from among the preliminary results presented .Additionally or alternatively , the user can continue to refine the search query and obtain new or updated search results dynamically as such refinement occurs or within a short duration of time thereafter .", "label": "", "metadata": {}, "score": "57.429047"}
{"text": "When a document is crawled , the above described document description process is performed to obtain the selected sentences , and then the hash of these sentences .If the hash table is filled , then again the newly crawled document is deemed to be a duplicate of a previous document .", "label": "", "metadata": {}, "score": "57.439022"}
{"text": "Significantly , the design of an independently developed voice navigator system , which is capable of associating voice commands with equivalent keyboard or mouse actuated control functions for a wide variety of commercially available application programs , has been hindered by certain difficulties .", "label": "", "metadata": {}, "score": "57.439148"}
{"text": "The basic aspects of the present invention may further be summarized as follows : .Speaker adaptation methods for speech recognizing systems and methods transform an acoustic model in a way to better fit to the acoustic properties and speaking behaviour of a given and specific speaker .", "label": "", "metadata": {}, "score": "57.472446"}
{"text": "Description .CROSS REFERENCE TO RELATED APPLICATIONS .The application is related to the following co - pending applications : I .NDEX S .ERVER A .RCHITECTURE U .SING T .IERED AND S .HARDED P .HRASE P .", "label": "", "metadata": {}, "score": "57.478264"}
{"text": "The computer - readable recordable storage medium of .The computer - readable recordable storage medium of .claim 1 , wherein editing the at least one voice - enrolled grammar based on the speech input comprises : . adding a first voice phrase to a voice - enrolled grammar , the speech input comprising the first voice phrase ; and/or . deleting a second voice phrase from an existing voice enrolled grammar , the speech input comprising the second voice phrase .", "label": "", "metadata": {}, "score": "57.499985"}
{"text": "One way to do this is to concatenate the selected sentences , and then take use a hash table to store the document identifier .For example , the presentation system 130 can hash the concatenated sentences , and if the hash table already has an entry for the hash value , then this indicates that the current document and presently hashed document are duplicates .", "label": "", "metadata": {}, "score": "57.605145"}
{"text": "5 illustrates this process , in which there are the following functional stages for indexing a document : .500 : Post document to the posting lists of good phrases found in the document .502 : Update instance counts and related phrase bit vector for related phases and secondary related phrases .", "label": "", "metadata": {}, "score": "57.623314"}
{"text": "As shown in FIG .5(B ) , the link field may designate a plurality of linked macros which are to be executed based upon a single vocabulary phrase 142 .Likewise , the linked macros may themselves include link fields which cause the navigator to automatically execute additional macros in response to a single voice command .", "label": "", "metadata": {}, "score": "57.628696"}
{"text": "2 , the indexing server master 260 , server cluster master 220 , swap master server 240 , index shard files 115 , and segment shard files 225 are the components principally involved in updating the index .As described above , the index for the document collection is divided into a number of tiers and shards , which are then served by the various index servers 200 .", "label": "", "metadata": {}, "score": "57.6617"}
{"text": "[0079 ] .FIG .12 is a flow diagram of a general processing flow of a method 1200 that can be used with the dynamic search client , such as one or more of the dynamic search clients that have been disclosed and described in conjunction with previous figures .", "label": "", "metadata": {}, "score": "57.693268"}
{"text": "Global grammars can be used to terminate phrase enrollment and in some cases may result in an assignment to the input item name .In addition , the behavior of an input collection phase can be identical to the VoiceXML input collection phases as defined in Appendix C of the VoiceXML 2.0 specification .", "label": "", "metadata": {}, "score": "57.717453"}
{"text": "[ 0064 ] .FIG .7 is a system block diagram of a dynamic search client system 700 that includes structuring functions .The dynamic search client system 700 , as shown in this specific example , is specifically adapted for data retrieval tasks that include or support an ability to use structured queries , such as queries composed in the Structured Query Language ( SQL ) or another structured language .", "label": "", "metadata": {}, "score": "57.74361"}
{"text": "The noised probability is obtained as ., ten experiments have been run .In this case , we randomly select two fixed training set sizes equal to 62,995 and 629,957 pairs of sentences form the Europarl corpora and use Moses as translation system .", "label": "", "metadata": {}, "score": "57.759804"}
{"text": "In addition , the present invention is not described with reference to any particular programming language .It is appreciated that a variety of programming languages may be used to implement the teachings of the present invention as described herein , and any references to specific languages are provided for disclosure of enablement and best mode of the present invention .", "label": "", "metadata": {}, "score": "57.759975"}
{"text": "In addition , the present invention is not described with reference to any particular programming language .It is appreciated that a variety of programming languages may be used to implement the teachings of the present invention as described herein , and any references to specific languages are provided for disclosure of enablement and best mode of the present invention .", "label": "", "metadata": {}, "score": "57.759975"}
{"text": "The user interface server 130 receives a query from a client 170 , and passes the query , in the form of a Boolean query word tree to the front end server 140 .Additionally , the front end server 140 can also expose an application programming interface that allows other applications to directly input properly formed queries .", "label": "", "metadata": {}, "score": "57.767292"}
{"text": "\" Other forms or types of suggestions are possible and will become apparent to those of ordinary skill in the art upon reading this disclosure .Such other forms or types include , but are not limited to , spelling correction , noisy input correction , and grammar correction .", "label": "", "metadata": {}, "score": "57.80566"}
{"text": "Processing of the method 1200 begins at START block 1210 and continues to process block 1220 .At process block 1220 , a query suggestion is obtained .The query suggestion can be a query suggested by a query suggestion engine such as one of the query suggestion engines disclosed and described in conjunction with previous figures .", "label": "", "metadata": {}, "score": "57.829643"}
{"text": "Each of these shards is then stored in one or more of the index servers 200 .In this simple example , four index servers 200 would be used , one for each shard .One benefit of sharding phrase posting lists is that it allows multiple different index servers 200 to operate in parallel during query processing , without requiring them to cross - communicate their query processing results .", "label": "", "metadata": {}, "score": "57.857822"}
{"text": "8 illustrates the overall data and process flow for the processing of search queries as handled by the front end server 140 .Generally , the process takes as input a Boolean word tree 801 from the user interface server 130 , wherein the leaf nodes include individual words from the query and the non - leaf nodes contain Boolean operators AND , OR , or NOT .", "label": "", "metadata": {}, "score": "57.883957"}
{"text": "The completed query can be created by a dynamic search client that provides suggestions , such as one or more of the dynamic search clients that have been disclosed and described in conjunction with previous figures .Processing continues to process block 1330 where a search that uses the completed query is performed .", "label": "", "metadata": {}, "score": "57.920536"}
{"text": "The documents can then be shown to the user , grouped accordingly under the appropriate cluster names as headings .For example , assume a search query of \" blue merle agility training \" , for which the search system 120 retrieves 100 documents .", "label": "", "metadata": {}, "score": "57.932343"}
{"text": "This high threshold is used to identify the co - occurrences of good phrases that are well beyond the statistically expected rates .Statistically , it means that phrases g j and g k co - occur 100 times more than the expected co - occurrence rate .", "label": "", "metadata": {}, "score": "57.937263"}
{"text": "Estimating a machine translation system is therefore similar to learning the mapping between the source / input and the target / output , a problem which has been extensively studied in statistics and in machine learning .This justifies our view of a typical phrase - based machine translation model as a learning system and motivates our analysis of the performance on that system .", "label": "", "metadata": {}, "score": "58.02773"}
{"text": "6 , the navigator continues to compare the respective children of the window object and the sub - context object until a unique match is found .Finally , in step 100 an active vocabulary set is obtained from the sub - context tree which corresponds to a current application state .", "label": "", "metadata": {}, "score": "58.099472"}
{"text": "The columns g k in each row g j of the co - occurrence matrix 212 are then sorted by the information gain values I(g j , g k ) , so that the related phrase g k with the highest information gain is listed first .", "label": "", "metadata": {}, "score": "58.134113"}
{"text": "A peculiar point is the determination of the adaptation numbers and/or the occurence numbers of the distinct speech phrases which may occur during the incoming speech flow .Additionally , the threshold number may be set for each of said speech phrases or for classes of them independently .", "label": "", "metadata": {}, "score": "58.14132"}
{"text": "Note that the column j for the phrase g j is not removed , as this phrase itself may be predicted by other good phrases .This step is concluded when all rows of the co - occurrence matrix 212 have been evaluated .", "label": "", "metadata": {}, "score": "58.148968"}
{"text": "The shard assignment function for a given phrase posting list is selected based on attributes of the phrase and its posting list .Each of the shards is then assigned to one of the index servers .The shard will be stored at the index server , either in memory or on disk or a combination of both .", "label": "", "metadata": {}, "score": "58.160503"}
{"text": "6 , the voice navigator program is preferably executed on a computer system simultaneously with the target application program in step 90 .In step 92 , the voice navigator program accesses the context data file to retrieve information stored in the sub - context trees concerning the structure , attributes and vocabulary associated with the target application program .", "label": "", "metadata": {}, "score": "58.17565"}
{"text": "Description .BACKGROUND .Field of the Invention .The present invention relates the VoiceXML software language and , more particularly , a VoiceXML language extension for natively supporting voice enrolled grammars .Description of the Related Art .Voice enrolled grammars are an industry standard speech recognition feature that permits users to enroll phrases into a recognition grammar using their voice .", "label": "", "metadata": {}, "score": "58.18257"}
{"text": "The specific types of messages which the navigator sends will depend upon the particular window object and the spoken utterance .The matching step described above is preferably accomplished by comparing the attributes of each descendant sub - context object to the attributes of each of the enumerated descendent window objects .", "label": "", "metadata": {}, "score": "58.20349"}
{"text": "While we refer to \" words swap ' ' when , given two entries of the translation model , we swap the target language phrases .Three different sets of experiments have been run applying \" numerical swap ' ' only to the language model , \" numerical swap ' ' only to the translation model and \" words swap ' ' only to the translation model .", "label": "", "metadata": {}, "score": "58.229362"}
{"text": "For the Hansard corpus , we took the human annotation of word alignment ... . \" ...We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models .", "label": "", "metadata": {}, "score": "58.261223"}
{"text": "I. System Overview .Referring now to .FIG .1 , there is shown the software architecture of an information retrieval system 100 in accordance with one embodiment of present invention .This embodiment of the information retrieval system 100 includes an indexing system 110 , a search system 120 , a user interface server 130 , a set of index shard files 115 , and a document information database 155 .", "label": "", "metadata": {}, "score": "58.27818"}
{"text": "A.1 .Effect of Data Size in Optimization Set .In this section , we study the role of the optimization / development set with regard to the quality of translation .In particular , we analyze how different sizes of the development set affect the performance and the computational cost of the optimization phase .", "label": "", "metadata": {}, "score": "58.290604"}
{"text": "minimum .[ . cost .Y .i . ) .] i .n . cost .X . ij . ) . . .This means that the inversion will be performed where the cost of processing the factored node Y is either less than the minimum of the costs for the disjunct nodes X , or greater than the summed cost of these nodes .", "label": "", "metadata": {}, "score": "58.299618"}
{"text": "claim 1 , wherein the probability of occurrence of each component phrase in a candidate phrasification is based on an incidence of the component phrase in an indexed document collection .The method of .claim 1 , wherein the probability of occurrence of each component phrase in a candidate phrasification is based on in natural language .", "label": "", "metadata": {}, "score": "58.319565"}
{"text": "To store this information , two basic representations are available .First , as indicated above , the information may be stored in the co - occurrence matrix 212 , wherein : .Alternatively , the matrix representation can be avoided , and all information stored in the good phrase list 208 , wherein each row therein represents a good phrase g j : .", "label": "", "metadata": {}, "score": "58.342934"}
{"text": "Our first concerns were to distinguish between approximation and estimation error : the performance limitations due to the use of a limited language model versus those due to the need to estimate the parameters of that model from a finite sample .", "label": "", "metadata": {}, "score": "58.351395"}
{"text": "A bit is set if the related phrase g k in R is in the same cluster as phrase g j .More generally , this means that the corresponding bit in the cluster bit vector is set if there is information gain in either direction between g j and g k .", "label": "", "metadata": {}, "score": "58.35291"}
{"text": "35 - 43 , Columbus , Ohio , USA , 2008 . Y. Al - Onaizan , J. Curin , M. Jahr , et al . , \" Statistical machine translation : final report , \" Tech .Rep. , Johns Hopkins University , Summer Workshop on Language Engineering , Center for Speech and Language Processing , Baltimore , Md , USA , 1999 .", "label": "", "metadata": {}, "score": "58.387085"}
{"text": "The networks can further include circuit - based communication components and mobile communication components , such as telephony switches , modems cellular communication towers , and the like .The networks can include line based and/or wireless communication pathways .FIG .", "label": "", "metadata": {}, "score": "58.39341"}
{"text": "As this is an enormous search space , it is no wonder that both algorithmic and statistical challenges are encountered when training these systems .From a statistical learning point of view , this raises interesting questions : How much of the overall error of the translation system is due to representation limitations , and how much to the difficulty of extracting suitable Translation and Language model tables from a finite sample ?", "label": "", "metadata": {}, "score": "58.399654"}
{"text": "For each pair of query phrases the search system 120 determines the appropriate case by looking up the related phrase bit vector of the query phrases Qp .The search system 120 proceeds by retrieving the posting list for query phrase Q 1 , which contains the documents containing Q 1 , and for each of these documents , a related phrase bit vector .", "label": "", "metadata": {}, "score": "58.41832"}
{"text": "As the sub - context tree is created , a specific set of attributes 70 is defined for each of the sub - context objects based upon the attributes of a corresponding window object of the current application state .This process is illustrated in FIG .", "label": "", "metadata": {}, "score": "58.43619"}
{"text": "Gedeon , T.D. et al . , \" Hierarchical Co - Occurrence Relations \" , Systems , Man , and Cybernetics , IEEE International Conference in San Diego , CA , Oct. 11 , 1998-Oct .14 , 1998 , pp .", "label": "", "metadata": {}, "score": "58.43625"}
{"text": "The audioinputurilist attribute can be an optional attribute used to specify the location of audio to use for batch mode phrase enrollment of enrollment where the audio is collected in a separate dialog using VoiceXML record or ' recordutterance ' .The attribute type can be a comma separated URI list of one ( 1 ) or more elements used to satisfy the collection of a phrase up to minconsistent or maxattempts .", "label": "", "metadata": {}, "score": "58.44413"}
{"text": "The value for E(g j ) can be updated each time the counts for g j are incremented , or during this third stage .Next , for each other good phrase g k ( e.g. , the columns of the matrix ) , it is determined whether g j predicts g k .", "label": "", "metadata": {}, "score": "58.45308"}
{"text": "The system of . claim 19 , wherein the probability of occurrence of the component phrases of a candidate phrasification is based on an estimated probability figure .The system of . claim 19 , wherein the probability of occurrence of the component phrases of a candidate phrasification is based on a proportion of documents to be searched that contain the component phrase .", "label": "", "metadata": {}, "score": "58.46638"}
{"text": "wherein the method further comprises detecting an error during the updating when an attempt to update the third voice phrase is made and the third voice phrase is not able to be updated .A method comprising : . prompt a user to provide speech input ; and .", "label": "", "metadata": {}, "score": "58.469254"}
{"text": "The front end server 140 provides the optimized phrase tree to the search system 120 .The search system 120 is responsible for managing execution of the search by the index servers 200 .The index servers 200 process the phrase tree by accessing the index shard files 115 , and returning search results comprising a set of documents relevant to the phrases of the query .", "label": "", "metadata": {}, "score": "58.486317"}
{"text": "F. J. Och , \" Minimum error rate training in statistical machine translation , \" in Proceedings of the 41st Annual Meeting on Association for Computational Linguistics , pp .160 - 167 , Sapporo , Japan , 2003 .W. H. Press , S. A. Teukolsky , W. T. Vetterling , and B. P. Flannery , Numerical Recipes in C++ , Cambridge University Press , Cambridge , Mass , USA , 2002 . A. Arun and P. Koehn , \" Online learning methods for discriminative training of phrase based statistical machine translation , \" in Proceedings of 11th the Machine Translation Summit , Copenhagen , Denmark , 2007 .", "label": "", "metadata": {}, "score": "58.497963"}
{"text": "Accordingly , each phrase g j remaining on the good phrase list 208 will predict some number of other phrases , based on the information gain threshold previously discussed .Now , for each phrase g j the indexing system 110 performs a string match with each of the phrases g k that is predicts .", "label": "", "metadata": {}, "score": "58.602444"}
{"text": "These shortcoming result from a lack of native support for voice enrolled grammars in the VoiceXML language model .Existing solutions implementing voice enrolled grammars with VoiceXML based products use the Web programming model and/or a VoiceXML object tag to access voice enrollment features , neither of which provide native language access .", "label": "", "metadata": {}, "score": "58.60418"}
{"text": "In particular , it avoids the need to write additional navigator computer code for handling the special or custom design controls implemented in a particular target application .In addition to defining the foregoing sub - context attributes 70 , each window object is preferably analyzed to discover a vocabulary set 80 .", "label": "", "metadata": {}, "score": "58.617924"}
{"text": "The underlying log - linear model may be interpreted as a maximum entropy model : . is linear in the log domain , which motivates the description of this framework as \" log - linear model ' ' [ 3 , 4 , 12 ] .", "label": "", "metadata": {}, "score": "58.618176"}
{"text": "If a phrase p does not qualify for the good phrase list 208 , then it is checked for qualification for being a bad phrase .A phrase p is a bad phrase if : .These conditions indicate that the phrase is both infrequent , and not used as indicative of significant content and again these thresholds may be scaled per number of documents in the partition .", "label": "", "metadata": {}, "score": "58.64549"}
{"text": "Instead , the invention can be used with voice navigators designed to operate with any one of several commercially available operating systems which incorporate a graphical user interface .Each Windows based application contains one or more window objects .The term \" window object \" refers to a combination of computer code and data which together comprise a sub - part of each Windows based application , which is presented to a user as part of a graphical user interface on a user interface screen .", "label": "", "metadata": {}, "score": "58.64584"}
{"text": "The modified voice enrolled grammar 136 can be contained within a grammar date store 146 used by a speech recognition engine 140 , which is able to convert speech 160 into speech - recognized text 162 .More specifically , during enrollment session 150 , acoustically provided voice phrase ( Phrase_A ) can be provided to enrollment server 120 along with a request to add the phrase to a voice enrolled grammar 130 .", "label": "", "metadata": {}, "score": "58.64793"}
{"text": "Local children nodes - i.e . , phrases that are stored at the index server - are processed to create a list of document .The index server then transmits this document list either back to the index server that called it , or to a next index server for further processing .", "label": "", "metadata": {}, "score": "58.703636"}
{"text": "Average .and error on the Europarl and Giga corpus datasets are shown in Table 5 .The proposed model is able to approximate well enough the BLEU score using Moses as translation system and in - domain test sets .According to this setting and assuming that we are in the standard case where .", "label": "", "metadata": {}, "score": "58.706223"}
{"text": "Another way of saying this is that the accuracy of the predication is 99.999 % because the occurrence rate is 100:1 .Accordingly , any entry ( g j , g k ) that is less the Related Phrase threshold is zeroed out , indicating that the phrases g j , g k are not related .", "label": "", "metadata": {}, "score": "58.737885"}
{"text": "For each model , we count the unknown words .Figure 11 shows unknown words as function of the training model .It is clear that small training sets are able to cover a small part of the word space .When increasing the dimension of the training set , the number of unknown words decreases .", "label": "", "metadata": {}, "score": "58.775986"}
{"text": "\" The search system 100 operates over a large corpus of documents , such as the Internet and World Wide Web , but can likewise be used in more limited collections , such as for the document collections of a library or private enterprises .", "label": "", "metadata": {}, "score": "58.77681"}
{"text": "The system of . claim 2 , further comprising a search engine that provides a result set based at least in part upon a query created using the suggestion .The system of .claim 4 , wherein the user interface includes a speech processing component that accepts an audio data input to recognize the phrase .", "label": "", "metadata": {}, "score": "58.837326"}
{"text": "( i ) forward a subtree rooted at the current node to the server(s ) assigned to the current node .The current server is designated a requesting server , and it receives in return one or more document lists from the assigned server(s ) .", "label": "", "metadata": {}, "score": "58.839886"}
{"text": "FIG .12 is a flow diagram showing processing of a method that can be used in conjunction with components disclosed or described herein .[ 0022 ] .FIG .13 is a flow diagram showing processing of a method that can be used in conjunction with components disclosed or described herein .", "label": "", "metadata": {}, "score": "58.847324"}
{"text": "Conclusion .Data - driven solutions to classic AI problems are now commonplace , ranging from computer vision to information retrieval tasks , and machine translation is one of the main successes of this approach .The idea of putting learning systems at the centre of all AI methodologies introduces however the need to understand the properties and limitations of these learning components .", "label": "", "metadata": {}, "score": "58.8619"}
{"text": "If the first case applies to Q 2 , the search system 120 scans the related phrase bit vector for each document d in Q 1 's posting list to determine if it has a bit set for Q 2 .If this bit is not set in for document d in Q 1 's posting list , then it means that Q 2 does not appear in that document .", "label": "", "metadata": {}, "score": "58.87235"}
{"text": "This bit vector is a bi - bit vector as described above .For each related phrase Qr of the query that is also present in the user model , both of the bits for this related phrase are set in the mask bit vector .", "label": "", "metadata": {}, "score": "58.924217"}
{"text": "A further problem is that phrases continually enter and leave the lexicon in terms of their usage , much more frequently than new individual words are invented .New phrases are always being generated , from sources such technology , arts , world events , and law .", "label": "", "metadata": {}, "score": "59.04062"}
{"text": "If the user interface is responsive to handwritten input , the phrase can include any datum that can be recognized by that user interface and specifically can include any symbol that can be input .[ 0032 ] .The search server 120 includes both a guide engine 130 and a search engine 140 .", "label": "", "metadata": {}, "score": "59.1898"}
{"text": "FIG .9 is an illustration of the query phrasification process .FIG .10 is an illustration of the query scheduling process .FIG .11A and .FIG .11B illustrate optimization by factoring of common nodes in a query schedule .", "label": "", "metadata": {}, "score": "59.201088"}
{"text": "The HTML document can include settings or search selections or preferences that are selectable through on - screen buttons or the like .Among the technologies that may be employed are web services , other scripting languages , other modules to replace Applets , and other types of data storage and retrieval systems .", "label": "", "metadata": {}, "score": "59.286873"}
{"text": "The user must predict what is a necessary or sufficient query to obtain desired results .Inaccurate predictions result in undesired results .Queries that are too short may inadequately refine the result set .Queries that are too long may inadvertently exclude desirable results .", "label": "", "metadata": {}, "score": "59.306484"}
{"text": "Specifically , the method 1300 can be used to provide additional content , such as advertising , and that can be keyed to a specific user query and change as the user query changes .[0085 ] .Processing of the method 1300 begins at start block 1310 and continues to process block 1320 .", "label": "", "metadata": {}, "score": "59.311344"}
{"text": "This analysis is generally performed in order to determine a command vocabulary set for controlling such objects and their associated macros .In order to perform this dynamic analysis , there are several features of every window in a target application that the speech navigator can probe to determine the attributes of a particular object .", "label": "", "metadata": {}, "score": "59.35573"}
{"text": "We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation .The focus of this description is on improvements which were incorporated into the system over the last year .", "label": "", "metadata": {}, "score": "59.383156"}
{"text": "The phrase is sent to the query suggestion module 620 so that the query suggestion module 620 can suggest a possible query .The possible query suggestion can be a simple word suggestion or phrase suggestion , or a more complex suggestion , such as those types of suggestions previously described in conjunction with other figures .", "label": "", "metadata": {}, "score": "59.385498"}
{"text": "The linked macros may be stored within the same sub - context object as the voice macro or in other sub - context objects .These linked macros represent additional actions which are to be performed in conjunction with the direct action defined by the voice macro .", "label": "", "metadata": {}, "score": "59.389324"}
{"text": "The system of . claim 19 , wherein scoring each phrasification comprises : . applying a scoring model : .S .f .N . )i .N .P .p .i . )C .p .", "label": "", "metadata": {}, "score": "59.40969"}
{"text": "Similarly , the query suggestion module 520 and the query data store 530 can also be implemented on a remote computer to obtain similar benefits from information gathered from a large number of users .By leveraging larger amounts of information from a wide variety of users , query suggestion tasks can be further refined to take into account such things as context and most likely desired results .", "label": "", "metadata": {}, "score": "59.489716"}
{"text": "The query schedule 825 can be stored as a Boolean schedule tree which is semantically equivalent to the original tree , and each of whose nodes is additionally annotated to identify the set of servers on which it should be executed .", "label": "", "metadata": {}, "score": "59.5038"}
{"text": "Accordingly , these requests can be sent from whichever index server 200 is responsible for the OR node itself .The left sibling rule ( d)(i ) is used where the OR node is a child of an AND , because an OR node itself can not be the child of an OR and a NOT can only have one child .", "label": "", "metadata": {}, "score": "59.51689"}
{"text": "Therefore , received speech phrases or words which do occur frequently influence the modification and adaptation on the current acoustic model much more than words or phrases which do occur infrequently .As a result , after having applied conventional methods for adaptation these frequently occuring speech phrases or words are recognized with a very small error rate but the recognition rate for other vocabulary is worse .", "label": "", "metadata": {}, "score": "59.52751"}
{"text": "The query scheduling module 820 executes the following steps for scheduling 1010 , as summarized in .FIG .10 .For purposes of discussion , the order of child nodes of any Boolean node is assumed to be left to right based on some assigned value ( i.e. , the left most child node has the lowest value ) . 1 ) Normalize ( 1012 ) the phrase tree by eliminating ANDs of ANDs and ORs of ORs . 2 ) Recursively traverse the normalized phrase tree , in depth - first order , assigning ( 1014 ) to each node a query cost and a plurality of index servers 200 according to the following scheduling rules : . a )", "label": "", "metadata": {}, "score": "59.53772"}
{"text": "A possible phrase p on the possible phrase list 206 is moved to the good phrase list 208 if the frequency of appearance of the phrase and the number of documents that the phrase appears in indicates that it has sufficient usage as semantically meaningful phrase .", "label": "", "metadata": {}, "score": "59.554283"}
{"text": "ELEVANCE S .CORING , filed Mar. 30 , 2007 , all of which are co - owned , and incorporated by reference herein .FIELD OF THE INVENTION .The present invention relates to information retrieval systems for large scale document collections , such as the Internet .", "label": "", "metadata": {}, "score": "59.56687"}
{"text": "4 is an example of a sub - context tree developed for one of the application states shown in FIG .3 . FIG .5(A ) is a representation of a sub - context object containing window attributes and a plurality of vocabulary sub - sets .", "label": "", "metadata": {}, "score": "59.57802"}
{"text": "FIG .7 conceptually illustrates the various embodiments by which the segment shard files are merged into index shard files .The individual index servers 200 then copy the new index shard files from the update index 230 into their own memory / disk .", "label": "", "metadata": {}, "score": "59.590767"}
{"text": "claim 4 , wherein editing the at least one voice - enrolled grammar based on the speech input further comprises : . updating a third voice phrase included in an existing voice - enrolled grammar by replacing the third voice phrase with a new voice phrase , the speech input comprising the third voice phrase and/or the new voice phrase .", "label": "", "metadata": {}, "score": "59.608536"}
{"text": "claim 28 , wherein a related phrase includes a spell - corrected version of one of the component phrases .The system of .claim 28 , wherein a related phrase includes a phrase chosen for semantic similarity to at least one of the component phrases .", "label": "", "metadata": {}, "score": "59.646538"}
{"text": "0068 ] .A text entry box 830 allows a user to enter a phrase .As shown , a phrase has been entered .Suggestions , along with a number of possible hits or results for a search on that suggestion , are listed in a drop - down text field 840 .", "label": "", "metadata": {}, "score": "59.72151"}
{"text": "This process is illustrated in FIG .2 as step 46 .The sub - context object vocabulary set 80 is comprised of a series of vocabulary sub - sets .Each vocabulary sub - set is comprised of one or more macros which contain a vocabulary phrase corresponding to specific user inputs when a particular window object is the foreground window .", "label": "", "metadata": {}, "score": "59.747295"}
{"text": "The result of the intersection is a set of documents that are relevant to the query .In one embodiment , the search system 120 can use an optimized mechanism to identify documents responsive to the query without having to intersect all of the posting lists of the query phrases Q. As a result of the structure of the index 150 , for each phrase g j , the related phrases g k are known and identified in the related phrase bit vector for g k .", "label": "", "metadata": {}, "score": "59.77352"}
{"text": "claim 1 , wherein selecting a first document and a second document from a set of documents further comprises : . selecting the first document and second document during indexing of the first document .The method of .claim 1 , further comprising storing a document description in association with the document to which the document description corresponds .", "label": "", "metadata": {}, "score": "59.821854"}
{"text": "These phrase posting lists are assigned for serving to plurality of index servers .The phrase posting list assignments are made so as to minimize the inter - server communications required for subsequent query processing .There are various embodiments of how the phrase posting lists can be assigned to the index servers , which have the following general structure .", "label": "", "metadata": {}, "score": "59.824055"}
{"text": "If the determination is yes , processing returns to process block 1320 where a new completed query is obtained .If the determination from decision block 1370 is no , processing terminates at end block 1380 .[ 0088 ] .FIG .", "label": "", "metadata": {}, "score": "59.82905"}
{"text": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions . \" ...This paper is based on the work carried out in the framework of the Verbmobil project , which is a limited - domain speech translation task ( German - English ) .", "label": "", "metadata": {}, "score": "59.851322"}
{"text": "The presentation system 130 is responsible for modifying the search results including removing near duplicate documents , and generating topical descriptions of documents , and providing the modified search results back to the front end server 140 , which provides the results to the client 170 .", "label": "", "metadata": {}, "score": "59.86029"}
{"text": "The mask bit vector is then used to mask the related phrase bit vector for each document in the current set of search results by ANDing the related phrase bit vector with the mask bit vector .This has the effect of adjusting the body score and the anchor hit score by the mask bit vector .", "label": "", "metadata": {}, "score": "59.891167"}
{"text": "It should be noted that various aspects of the invention can be implemented as a program for controlling computing equipment to implement the functions described herein , or a program for enabling computing equipment to perform processes corresponding to the steps disclosed herein .", "label": "", "metadata": {}, "score": "59.8928"}
{"text": "This apparatus may be specially constructed for the required purposes , or it may comprise a general - purpose computer selectively activated or reconfigured by a computer program stored on a computer readable medium that can be accessed by the computer .", "label": "", "metadata": {}, "score": "59.908516"}
{"text": "This apparatus may be specially constructed for the required purposes , or it may comprise a general - purpose computer selectively activated or reconfigured by a computer program stored on a computer readable medium that can be accessed by the computer .", "label": "", "metadata": {}, "score": "59.908516"}
{"text": "The query scheduling module 820 then optimizes phrase tree into a query schedule 825 by which this phrase tree is executed .The query execution module 830 then manages the execution of the query schedule by the index servers 200 .The index servers 200 create a set of results ( documents ) which are returned to the front end server 140 , which in turns creates a final search result set 835 and provides it to the user interface server 130 .", "label": "", "metadata": {}, "score": "59.91352"}
{"text": "The use of the query costs allows the query scheduling module 820 to schedule the which index servers 200 are used in which order , in order reduce overall processing costs .The rationale for the remaining rules is as follows .", "label": "", "metadata": {}, "score": "60.000877"}
{"text": "FIG .5 is system block diagram of a dynamic search client that also includes user feedback functions .[ 0015 ] .FIG .6 is a system block diagram of a dynamic search client that also includes content association functions .", "label": "", "metadata": {}, "score": "60.01297"}
{"text": "5(B ) is an example of a data structure for a multi - action voice macro .FIG .5(C ) is a example of a data structure for a link field .FIG .6 is a flow chart showing the manner in which a voice navigator program makes use of a context data file .", "label": "", "metadata": {}, "score": "60.039062"}
{"text": "The impressive capability of current machine translation systems is not only a testament to an incredibly productive and creative research community , but can also be seen as a paradigm for other artificial intelligence tasks .Data - driven approaches to all main areas of AI currently deliver the state - of - the - art performance , from summarization to speech recognition to machine vision to information retrieval .", "label": "", "metadata": {}, "score": "60.045242"}
{"text": "They may be called speech phrases or speech phrase subunits .According to a preferred embodiment of the inventive method for recognizing speech words , subword units , phones , phonemes , syllables , letters and/or the like and/or combinations or concatenations thereof are used as said speech phrases and/or as said speech phrase subunits of said current acoustic model .", "label": "", "metadata": {}, "score": "60.06592"}
{"text": "The following discussion refers to .FIG .11A showing an OR node whose children are AND nodes , each of which have common children Y i along with other ( unshared ) children X ij .The de Morgan inversion would replace this tree with the logically equivalent tree shown in .", "label": "", "metadata": {}, "score": "60.078705"}
{"text": "Because the AND node is not assigned to the front end server 140 but instead to index server A , the entire query schedule is transmitted to index server A under rule ( 1)(i ) .Index server A then executes on ( A AND B ) .", "label": "", "metadata": {}, "score": "60.11976"}
{"text": "If j is 2 , then the phrase identification server 250 skips this step .The devolution rule is designed to avoid double counting , and so it depends on the position of the hits .First , the phrase identification server 250 compares the phrase 's score to a second threshold , which is used to further identify strong phrases .", "label": "", "metadata": {}, "score": "60.14599"}
{"text": "Adaptation means to extract specific information which is necessary to focus on the particular voice characteristics of the current speaker .The process of adapting said current acoustic model is therefore based on an evaluation of speech phrase subunits which are contained in a speech phrase under process and/or recently recognized .", "label": "", "metadata": {}, "score": "60.150112"}
{"text": "BLEU and NIST are based on averaging n -gram precisions , combined with a length penalty which penalizes short translations containing only sure words .These metrics differ on the way the precisions are combined and on the length penalty .Meteor evaluates a translation by computing a score based on the word alignment between the translation and a given reference translation .", "label": "", "metadata": {}, "score": "60.165165"}
{"text": "( a )One of the children of the AND is identical to one of the children of the OR , i.e. , having the form ( A OR ( A AND B ) ) ; or .( b )There are at least two AND children of the OR such that each of the AND children itself has a child in common ; i.e. , having the form ( A AND B ) OR ( A AND C ) , . then a basic optimization step is attempted .", "label": "", "metadata": {}, "score": "60.19364"}
{"text": "The set of experiments in Figure 7(a ) is harder to explain without discussing the inner workings of the translation model and Moses .Here , we swapped n -grams in the translation table , essentially breaking the connection between words and their translation .", "label": "", "metadata": {}, "score": "60.2146"}
{"text": "Each of the target application states ( 24 ) is comprised of a plurality of window objects .A set of user inputs is determined to which each of the window objects will be responsive .Each user input is assigned a corresponding voice macro ( 140 ) which simulates the user inputs in response to a spoken utterance .", "label": "", "metadata": {}, "score": "60.230175"}
{"text": "FIG .16 is a schematic block diagram of an exemplary computer .DETAILED DESCRIPTION .[ 0026 ] .As used in this application , the terms \" component , \" \" system , \" \" module , \" and the like are intended to refer to a computer - related entity , such as hardware , software ( for instance , in execution ) , and/or firmware .", "label": "", "metadata": {}, "score": "60.24113"}
{"text": "In such an arrangement , the maxattempts attribute and the minconsistent attribute can be set to a value of one and attributes for clash and consistency levels can be set to the most lenient values .The audioinputurilist attribute can reference one audio source .", "label": "", "metadata": {}, "score": "60.27672"}
{"text": "Accordingly , upon locating the proper vocabulary phrase , the navigator 102 first executes the direct action 144 .This is accomplished by comparing the target sub - context object to a window object of the current application state to obtain a unique window handle for the window object .", "label": "", "metadata": {}, "score": "60.369484"}
{"text": "The maximum phrase length is typically set to the length of the longest phrase in the phrase data 255 .The length of the window will typically be at least 2 , and preferably 4 or 5 terms ( words ) .", "label": "", "metadata": {}, "score": "60.396957"}
{"text": "Significantly , it should be noted that the foregoing examples are not intended to limit the scope of the invention , and the direct action field 144 can contain any other type of direct action information which is appropriate for a particular vocabulary phrase 142 .", "label": "", "metadata": {}, "score": "60.40741"}
{"text": "Understanding how sophisticated behaviour can be learnt from data is hence not just a concern for machine learning , or to individual applied communities , such as statistical machine translation , but rather a general concern for modern artificial intelligence .The analysis of learning curves and the identification of the various limitations to performance are a crucial part of the machine learning method , and one where statistics and algorithms interact closely .", "label": "", "metadata": {}, "score": "60.46152"}
{"text": "Aligning the English phrase to be paraphrased was the German - English section of the Europarl corpus , version 2 ( Koehn , 2002 ) .Because we wanted to test our method independently of the quality of word alignment algorithms , we also developed a gold standard of word alignments for the set of phrases that we wanted to paraphr ... .", "label": "", "metadata": {}, "score": "60.519817"}
{"text": "The present invention may be realized hardware , software , or a combination of hardware and software .The present invention may be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems .", "label": "", "metadata": {}, "score": "60.523346"}
{"text": "This segment phrase index is then tiered and sharded as described above to form segment - based shards , or more simply the segment shard files 225 , as mentioned referenced above .Each segment shard file is stored under the management of the server cluster master 220 .", "label": "", "metadata": {}, "score": "60.547707"}
{"text": "The direct action field defines a direct action which is to be performed in response to a spoken command corresponding to the vocabulary phrase for the voice macro .The voice navigator program preferably accesses the information stored in electronic memory as sub - context trees , in order to match a current target application state to a corresponding sub - context tree .", "label": "", "metadata": {}, "score": "60.62265"}
{"text": "8(B ) .As the navigator traverses the defined path away from the foreground sub - context object , each descendent of the foreground sub - context object along that path is matched to its associated windows object , which is a descendent of the foreground window .", "label": "", "metadata": {}, "score": "60.655937"}
{"text": "There may be some index servers B i for which none of the document identifiers yield the index server 's index number .If one of those sublists is ( or would be ) empty , i.e. there were no hits at all in the posting list for A which were equal to ( 1 mod 10 ) , then this sublist is not sent to an index server .", "label": "", "metadata": {}, "score": "60.67994"}
{"text": "This query segment is used by the matching engine 330 as a basis for finding suggestions in the query suggestion data store 340 .The query segment may be used as a prefix , a root , a suffix , or a basis for other , typically similar or related , terms .", "label": "", "metadata": {}, "score": "60.811768"}
{"text": "[ 0076 ] .If the determination made at decision block 1030 is yes , processing continues to process block 1035 where some number , N , of suggestions is selected .At process block 1040 , those suggestions are sent to the user .", "label": "", "metadata": {}, "score": "60.827286"}
{"text": "Processing of the method 1400 begins at start block 1410 .Processing continues to process block 1420 where a completed query that is based at least in part upon a suggestion is obtained .The complete query can be created by a dynamic search client that provides suggestions , such as one or more of the dynamic search clients that have been disclose and described in conjunction with previous figures .", "label": "", "metadata": {}, "score": "60.84147"}
{"text": "The indexing system 110 then sorts 506 all of the posting lists in the index 150 in declining order according to the number of documents listedphrase number of in each posting list , so that the most frequently occurring phrases are listed first .", "label": "", "metadata": {}, "score": "60.868896"}
{"text": "P. Koehn , \" Statistical significance tests for machine translation evaluation , \" in Proceedings of the Conference on Empirical Methods in Natural Language Processing , pp .388 - 395 , Barcelona , Spain , 2004 . A. Stolcke , \" Srilm - an extensible language modeling toolkit , \" in Proceedings of the International Conference on Spoken Language Processing , Denver , Colo , USA , 2002 .", "label": "", "metadata": {}, "score": "60.880653"}
{"text": "A voice enrolled grammar , unlike a text - based grammar , can be used in situations where a textual representation of a phrase is unavailable .This is often the case when a phrase represents a proper noun , such as a name .", "label": "", "metadata": {}, "score": "60.918743"}
{"text": "For each of these subsets , the requesting query execution module creates a new query that is identical to the received query schedule but in which the explicit data node is replaced by the subset document list .The query scheduling , optimization and execution process takes advantage of the tiered and shared structure of the index servers 200 to minimize the overall execution costs for any given query .", "label": "", "metadata": {}, "score": "60.930862"}
{"text": "If there are no children in the remote group , return the local result as the result to the requesting server . 2 ) If the are children in the remote group , construct a new .AND node whose first child is an explicit data node containing the local result , and whose remaining children are the children of the remote group .", "label": "", "metadata": {}, "score": "60.968876"}
{"text": "The search server 440 then transmits information including a suggestion to the receiver module 450 .The receiver module 450 then conveys the received suggestion to the presentation component 460 .The presentation component can cause the user interface 410 to display a list of suggestions to the user .", "label": "", "metadata": {}, "score": "61.000027"}
{"text": "claim 4 , wherein the user interface includes a handwriting processing component that accepts handwritten data input to recognize the phrase .The system of .claim 6 , further comprising a result display component that displays at least a part of the result set from the search engine .", "label": "", "metadata": {}, "score": "61.002754"}
{"text": "Abstract - This paper describes an approach for computing a consensus translation from the outputs of multiple machine translation ( MT ) systems .The consensus translation is computed by weighted majority voting on a confusion network , similarly to the well - established ROVER approach of Fiscus for combining speech recognition hypotheses .", "label": "", "metadata": {}, "score": "61.01832"}
{"text": "Accordingly , it is most efficient ( lowest cost ) to maintain execution on this particular index server 200 .If this is not the case , it is most efficient to center evaluation of the OR node so that the most expensive child is local , and the less - expensive children need to transmit their data over the network .", "label": "", "metadata": {}, "score": "61.03447"}
{"text": "The query suggestion data store 340 can also be implemented as a table or tables in a database , again , with or without probability information .Other appropriate data structures can be employed , depending upon the needs or desires of a specific implementer .", "label": "", "metadata": {}, "score": "61.058025"}
{"text": "The method of claim 1 , wherein said target application sub - context tree is organized in a tree structure wherein the parent - child relationships between sub - context objects is the same as the parent - child relationships between the corresponding target application window objects .", "label": "", "metadata": {}, "score": "61.12142"}
{"text": "III .Search Query Processing .As described above with respect to .FIG .1 , the front end server 140 receives a query from the user interface server 130 , and in cooperation with the search system 110 creates a set of search results to be provided to the user interface server 130 .", "label": "", "metadata": {}, "score": "61.135155"}
{"text": "The presentation system 130 does this as follows .As in other aspects of the system 100 , the presentation system 130 makes use of the related phrase bit vector for each document d in the search results .More specifically , for each query phrase Q , and for each document d in Q 's posting list , the related phrase bit vector indicates which related phrases Qr are present in the document .", "label": "", "metadata": {}, "score": "61.14638"}
{"text": "[ 0043 ] .Upon completion of a query that includes one or more suggested phrases , the user interface 210 sends the query to the search engine 240 .The search engine 240 uses the query to find information in the search data store 250 that is responsive to the query .", "label": "", "metadata": {}, "score": "61.14876"}
{"text": "[ 0083 ] .If the determination made a decision block 1270 is yes , processing returns to process block 1220 where the newly - modified suggested query is obtained and thereafter structured at process block 1230 .If the determination made at decision block 1270 is no , processing terminates at end block 1280 .", "label": "", "metadata": {}, "score": "61.157917"}
{"text": "As previously noted , the speech recognition engine 140 can include a date store 146 that contains the voice enrolled grammar 136 .Engine 140 can include an acoustic model processor 142 and a language model processor 144 .The language model processor 144 can utilize words , phrases , weights , and rules defined by grammars 136 of data store 146 .", "label": "", "metadata": {}, "score": "61.20262"}
{"text": "FIG .6 is merely illustrative , in practice the actual number of phrase posting lists per index server 200 will vary ) .Tier 2 stores 1,000 phrase posting lists , each of which is partitioned into 10 shards .Here , in this tier each index server 200 stores the entirety of a shard for its assigned phrase posting lists .", "label": "", "metadata": {}, "score": "61.21487"}
{"text": "Query Phrasification .FIG .9 illustrates the process flow of the query phrasification module 810 according to one embodiment .Other embodiments can have different and/or additional stages than the ones shown in the figure .The query phrasification module 810 takes as input the Boolean word tree 800 ; this Boolean word tree can be of any complexity , including any number of conjuncts and disjuncts , including nested groups .", "label": "", "metadata": {}, "score": "61.232292"}
{"text": "The phraseid object can specify a successfully enrolled phraseid , when the recordphraseaudio attribute is false .The maxattempts object can return a number of attempts made whenever an enrollment session fails due to an occurrence of a maximum number of attempts without achieving a minimum consistency among voice phrases .", "label": "", "metadata": {}, "score": "61.2631"}
{"text": "Additionally , the user interface 610 can cooperate with other components to provide an interactive search environment to the user .[ 0060 ] .A query suggestion module 620 can provide suggestions for queries that have been entered , at least in part , by a user through the user interface 610 .", "label": "", "metadata": {}, "score": "61.31145"}
{"text": "FIG .10 is a flow diagram showing processing of a method that can be used in conjunction with components disclosed or described herein .[ 0020 ] .FIG .11 is a flow diagram showing processing of a method that can be used in conjunction with components disclosed or described herein .", "label": "", "metadata": {}, "score": "61.315327"}
{"text": "In a first pass ( e.g. , if there are no stored query information for the user ) , the search system 120 operates to simply return the relevant documents in the search result to the user 's query , without further customized ranking .", "label": "", "metadata": {}, "score": "61.377495"}
{"text": "We have created 10 random subsets of the complete Europarl corpus containing 629,957 pairs of sentences .For each subset , ten PBMT systems have been estimated .Each instance of Moses has been trained using a different maximum phrase length , from 1 to 10 .", "label": "", "metadata": {}, "score": "61.51007"}
{"text": "Once the navigator executes the portion of the voice macro 140 contained in direct action field 144 , it then proceeds to perform any additional actions specified as linked macros in link field 148 .Using the information contained in the link field 148 , the navigator traverses the current sub - context tree to locate the linked macro .", "label": "", "metadata": {}, "score": "61.571274"}
{"text": "Details of refinement of a query completion can and usually will vary according to specific implementation details .Processing of the method 1400 terminates at END block 1470 .[0093 ] .In connection with prediction , learning , or inference - based tasks , various artificial intelligence - based schemes or components can be used for carrying out or implementing certain ones of the components disclosed and described herein .", "label": "", "metadata": {}, "score": "61.589626"}
{"text": "The phraseid attribute can be a required attribute that represents the i d of the phrase to be updated .Phraseidexpr can be used in place of phraseid .The phraseid or phraseidexpr attribute can be returned in application.lastresult$. utterance when a personal grammar is used for normal speech recognition .", "label": "", "metadata": {}, "score": "61.627228"}
{"text": "In this ... \" .This paper is based on the work carried out in the framework of the Verbmobil project , which is a limited - domain speech translation task ( German - English ) .In the nal evaluation , the statistical approach was found to perform best among ve competing approaches .", "label": "", "metadata": {}, "score": "61.727158"}
{"text": "FIG .1 is a system block diagram of a dynamic search system 100 .The dynamic search system 100 includes a user interface 110 that provides access to the system for a human user .The user interface 110 can be implemented as a command - line interface ( \" CLI \" ) , a graphical user interface ( \" GUI \" ) , a text - based interface , or may combine aspects of any of the foregoing interfaces in addition to other appropriate aspects .", "label": "", "metadata": {}, "score": "61.795494"}
{"text": "The indexing system 110 identifies phrases in documents , and indexes the documents according to their phrases , by accessing various websites 190 and other document collections over the network 180 , and processing documents contained therein .The indexing system 110 maintains the index information in the index shard files 115 .", "label": "", "metadata": {}, "score": "61.993034"}
{"text": "Each of these stages will now be described in further detail .The first stage 200 is a process by which the indexing system 110 crawls a set of documents in the document collection , making repeated partitions of the document collection over time .", "label": "", "metadata": {}, "score": "62.044243"}
{"text": "Also , both an application running on a server and the server can be components .One or more components can reside within a process and a component can be localized on one computer and/or distributed between two or more computers .", "label": "", "metadata": {}, "score": "62.0467"}
{"text": "The src attribute can be a required attribute that represents an existing personal grammar that will be updated with the new phraseid .Srcexpr can be used in place of src .The grammar can be updated at the URI using HTTP PUT request .", "label": "", "metadata": {}, "score": "62.096466"}
{"text": "We present Minimum Bayes - Risk ( MBR ) decoding for statistical machine translation .This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of l ... \" .", "label": "", "metadata": {}, "score": "62.2101"}
{"text": "The gentle decline in performance seems to suggest that fine tuning of parameters is not what controls the performance here , and that perhaps advanced statistical estimation or more observations of the same n -grams would not lead to much better performance .", "label": "", "metadata": {}, "score": "62.237747"}
{"text": "These are combined into a Boolean phrase tree ( note that in this format , the ' left most ' nodes are towards the bottom ) : . \" restaurants \" .AND . \" new york \" .OR . \" restaurant \" .", "label": "", "metadata": {}, "score": "62.282593"}
{"text": "The words in each conjunct are then processed to generate a set of possible partitionings of the words into phrases .These partitionings are called \" phrasifications .\" For example , the given the set for words \" New \" \" York \" \" restaurants \" , the possible phrasifications are : . \"", "label": "", "metadata": {}, "score": "62.30007"}
{"text": "claim 1 , wherein related words of the input text include synonyms of the words of the input text .The method of .claim 1 , wherein related words of the input text include words chosen for semantic similarity to at least one of the words of the input text .", "label": "", "metadata": {}, "score": "62.355804"}
{"text": "If the determination at decision block 1030 is no , processing continues to process block 1050 where the initial suggestion subset is left .Processing then continues at process block 1020 .[ 0077 ] .FIG .11 is a flow diagram depicting acts in a method 1100 .", "label": "", "metadata": {}, "score": "62.41765"}
{"text": "Translation of training sentences allows us to estimate the training error .The learning curves in Figure 4 illustrate how the performance is affected by the phrase length .The \" test on test set ' ' curve is less influenced by the phrase length than the \" test on training set ' ' curve .", "label": "", "metadata": {}, "score": "62.4383"}
{"text": "The consistencylevel attribute can be an optional attribute used to specify a level of similarity needed between utterances to obtain a consistent pronunciation .A value of the consistencylevel attribute can be between 0.0 and 1.0 .The higher the level of the consistencylevel attribute , the closer a match .", "label": "", "metadata": {}, "score": "62.441093"}
{"text": "Upon locating such linked macro , the navigator engages in a process of matching the sub - context object where the linked macro resides , to a specific window object .This matching process is accomplished in the same manner as described above for the purposes of implementing the direct action 144 .", "label": "", "metadata": {}, "score": "62.542973"}
{"text": "In accordance with this specific example , the information transmitted from the user interface 110 to the guide engine 130 is in the form of one or more phrases .One example of a phrase is a single character that is typed on a keyboard by the user .", "label": "", "metadata": {}, "score": "62.59505"}
{"text": "In at least this case , the search engine 240 can use previous result sets or perform additional computational or search tasks on the query to improve search performance as the user enters additional data .[0044 ] .FIG .", "label": "", "metadata": {}, "score": "62.61415"}
{"text": "This is an active area of research in machine translation [ 35 - 37 ] .The results of the perturbation analysis in Section 5 suggest that the limiting factor in the translation tables is not in the numeric part of the model - the parameters being estimated - but in the phrases contained in it , the entries of the phrase table .", "label": "", "metadata": {}, "score": "62.614933"}
{"text": "ISTS , filed Mar. 30 , 2007 ; Q .UERY S .CHEDULING U .SING H .IERARCHICAL T .IERS OF I .NDEX S .ERVERS , filed Mar. 30 , 2007 ; I .NDEX U .", "label": "", "metadata": {}, "score": "62.619774"}
{"text": "The figures depict a preferred embodiment of the present invention for purposes of illustration only .One skilled in the art will readily recognize from the following discussion that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles of the invention described herein .", "label": "", "metadata": {}, "score": "62.642475"}
{"text": "If neither the src nor the srcexpr is specified , a badfetch error can be thrown .The phrasenl attribute can be an optional attribute used to specify a semantic tag value to associate with the phraseid .Phrasenlexpr can be used in place of phrasenl .", "label": "", "metadata": {}, "score": "62.650536"}
{"text": "The method of .claim 1 , wherein the document description of the first document matches the document description of the second document when a hash value of the first document description equals a hash value of the second document description .", "label": "", "metadata": {}, "score": "62.653606"}
{"text": "If the candidate phrase is not in the good phrase list 208 then it is added to the possible phrase list 206 , unless it is already present therein .Each entry p on the possible phrase list 206 has three associated counts : .", "label": "", "metadata": {}, "score": "62.776096"}
{"text": "If yes , processing continues to process block 1180 where a new segment is created .Processing then continues to process block 1140 where a search based upon the new segment is performed .If the determination made at decision block 1160 is yes , processing terminates at END block 1190 .", "label": "", "metadata": {}, "score": "62.840412"}
{"text": "The method according to claim 1 wherein said link field is further defined to include a sub - context action command for identifying the location of said linked macro within the sub - context object containing said linked macro .The method according to claim 6 wherein said sub - context action command is defined to include a major function value which identifies a vocabulary set containing said linked macro .", "label": "", "metadata": {}, "score": "62.846863"}
{"text": "ACL Workshop on SMT , 2007 . \" ...We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation .The focus of this description is on improvements which were incorporated into the system over the last year .", "label": "", "metadata": {}, "score": "62.8556"}
{"text": "claim 1 , wherein decomposing the input text into a candidate phrasification includes grouping and rearranging words of the input text .The method of .claim 1 , wherein decomposing the input text includes replacing one or more of the input words with a related word .", "label": "", "metadata": {}, "score": "62.947723"}
{"text": "The search system 120 provides the search results and associated document information to the user interface server 130 .The user interface server 130 formats the search results , including creating the layout of the search results and associated document information , and other supplemental information or content ( e.g. , advertisements ) , and providing the formatted search results back to the client 170 .", "label": "", "metadata": {}, "score": "63.01503"}
{"text": "How much space for improvement is there , given new data or new statistical estimation methods or given different models with different complexities ?Before we present experimental results that address these questions , we will describe the setup that was used to obtain these results .", "label": "", "metadata": {}, "score": "63.070892"}
{"text": "It will be appreciated that the tiers are logical assignments of the index servers 200 that governs their functional roles , and not physical tiers in which the computers hosting the servers are located .Nonetheless , the tiers can be illustrated , as in the figures , as being separate from each other , which of course is not necessary in practice .", "label": "", "metadata": {}, "score": "63.078316"}
{"text": "Use of such elements allows for an implementer of the disclosed system to choose elements that are appropriate for a specific implementation .Preferably , the user interface 110 is interactive and provides responsive information to the user as the user types .", "label": "", "metadata": {}, "score": "63.112083"}
{"text": "In FIG .4 , a set of exemplary sub - context objects 50 , 52 , 54 , 56 , 58 , 60 , 62 , 64 , 66 and 68 are shown .The hierarchical relationship of the sub - context tree is chosen so that the parent - child relationship of the various sub - context objects is the same as the parent - child relationship between the window objects comprising each application state .", "label": "", "metadata": {}, "score": "63.144867"}
{"text": "The number of times that either phrase g j or phrase g k appears as distinguished text in a secondary window ; and .C(j , k ) : Conjunctive Interesting count : the number of times that both g j and phrase g k appear as distinguished text in a secondary window .", "label": "", "metadata": {}, "score": "63.27072"}
{"text": "Both learning curves show a big improvement when moving from the word - to - word translation ( phrase length equal to one ) to the phrase - based model ( higher phrase lengths ) .Figure 4 : BLEU versus n -gram length .", "label": "", "metadata": {}, "score": "63.294434"}
{"text": "claim 4 , wherein the user interface further comprises a presentation component that presents the suggestion to the user .A method of guiding a search for information stored in a machine - readable format , comprising : . creating a suggestion from a phrase entered by a user at a user interface ; and . creating at least one query based at least in part upon the suggestion .", "label": "", "metadata": {}, "score": "63.375397"}
{"text": "The system of . claim 15 , wherein the means for creating a suggestion includes means for referencing a set of suggestions .The system of .claim 16 , wherein the means for referencing a set of suggestions includes means for referencing a probability measure .", "label": "", "metadata": {}, "score": "63.376938"}
{"text": "If there are NOTs in the query , these are treated treat those as being hard boundaries for the purpose of phrasification .For example , if the query is : .( A AND B AND NOT C AND NOT D AND E AND F ) .", "label": "", "metadata": {}, "score": "63.435265"}
{"text": "Accordingly , it would be desirable to allow a sequence of macros to be executed based on a single voice command .It would further be desirable to minimize the amount of memory required to store a navigator program containing macros , and render the development of such programs more efficient .", "label": "", "metadata": {}, "score": "63.464935"}
{"text": "The guide engine 130 can then use the phrase as a basis to generate suggestions .[ 0034 ] .FIG .2 is a system block diagram of a dynamic search client 200 .The dynamic search client 200 includes a user interface 210 .", "label": "", "metadata": {}, "score": "63.60315"}
{"text": "Equivalently a document may be referred to as a \" page , \" as commonly used to refer to documents on the Internet .No limitation as to the scope of the invention is implied by the use of the generic term \" documents .", "label": "", "metadata": {}, "score": "63.75508"}
{"text": "For example , a given news article produced by a news bureau such as the Associated Press , may be replicated in a dozen or more websites of individual newspapers .Including all of these duplicate documents in response to a search query only burdens the user with redundant information , and does not usefully respond to the query .", "label": "", "metadata": {}, "score": "63.772034"}
{"text": "( i ) Unlearning by Adding Noise .A percentage of noise has been added to each probability , . , in the Language model , including conditional probability , and translation model , bidirectional phrase translation probabilities and lexicalized weighting .", "label": "", "metadata": {}, "score": "63.79682"}
{"text": "It is important to notice , however , that introducing a more aggressive type of noise ( Figure 7(b ) ) that essentially replaces entire parameters with random values does lead to a more significant decline in performance .This was obtained by swapping random entries , and so after 100 percent of swaps essentially every entry is a random number ( because the locations to swap are chosen with replacement ) .", "label": "", "metadata": {}, "score": "63.842712"}
{"text": "The present invention relates to an information retrieval system for indexing , searching , and classifying documents in a large scale corpus , such as the Internet .BACKGROUND OF THE INVENTION .Information retrieval systems , generally called search engines , are now an essential tool for finding information in large scale , diverse , and growing corpuses such as the Internet .", "label": "", "metadata": {}, "score": "63.84449"}
{"text": "Replacements are not allowed .These choices also depend on the high computational cost of the tuning algorithm .For each size , ten random sets have been selected .For each set , an instance of the system has been run .", "label": "", "metadata": {}, "score": "63.934498"}
{"text": "CROSS REFERENCE TO RELATED APPLICATIONS .( Not Applicable ) .STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT .( Not Applicable ) .BACKGROUND OF THE INVENTION .Technical Field .This invention relates to the field of computer software systems and more specifically to a method for allowing a speech navigator to efficiently execute a plurality of functions , based upon only a single spoken command .", "label": "", "metadata": {}, "score": "63.96254"}
{"text": "Based on the Proceedings of a Conference , Stirling , UK , Jul. 3 6 , 1990 ; Author : F. Carrez ; D. Mery ; C. Rattray ; R.G. Clark .IBM Technical Disclosure Bulletin , vol .36 , No .", "label": "", "metadata": {}, "score": "63.997147"}
{"text": "The operations and responsibilities of the various servers will be further described below .Each of the various servers is implemented as server program executing on server - class computer comprising a CPU , memory , network interface , peripheral interfaces , and other well known components .", "label": "", "metadata": {}, "score": "64.068756"}
{"text": "As each level of the tree is downwardly traversed by the navigator , it checks to determine whether the current window object matches the target window object .If it is , then the window handle for that target window object is obtained in step 136 .", "label": "", "metadata": {}, "score": "64.13262"}
{"text": "Software .Several software packages are available for training PBSMT systems .In this work , we use both Moses [ 5 ] and Portage [ 6 ] .Moses is a complete open - source phrase - based translation toolkit for academic purposes , while Portage is a similar package available to partners of the National Research Council Canada .", "label": "", "metadata": {}, "score": "64.16989"}
{"text": "Referring to now .FIG .2 , the phrase identification process has the following functional stages : .200 : Collect possible and good phrases , along with frequency and co - occurrence statistics of the phrases .202 : Classify possible phrases to either good or bad phrases based on frequency statistics .", "label": "", "metadata": {}, "score": "64.25746"}
{"text": "R i .The product value here is a score of how topical anchor phrase Q is to document D. This score is here called the \" inbound score component .\" This product effectively weights the current document D 's related bit vector by the related bit vectors of anchor phrases in the referencing document R. If the referencing documents R themselves are related to the query phrase Q ( and thus , have a higher valued related phrase bit vector ) , then this increases the significance of the current document D score .", "label": "", "metadata": {}, "score": "64.43553"}
{"text": "A computer - readable recordable storage medium having recorded thereon computer - executable instructions that , when executed by a computer , cause the computer to carry out a method , the method comprising : . prompting a user to provide speech input ; and . processing he speech input , wherein the processing comprises editing at least one voice - enrolled grammar based on the speech input , the at least one voice - enrolled grammar comprising at least one word or phrase added to the voice - enrolled grammar by the user , . wherein the computer - executable instructions are implemented as VoiceXML code , . wherein editing the at least one voice - enrolled grammar based on the speech input comprises : . adding a first voice phrase to a voice - enrolled grammar , the speech input comprising the first voice phrase ; and/or . deleting a second voice phrase from an existing voice enrolled grammar , the speech input comprising the second voice phrase , and .", "label": "", "metadata": {}, "score": "64.48796"}
{"text": "The networks can include any hardware / software / and firmware necessary to convey digital content encoded within carrier waves .Content can be contained within analog or digital signals and conveyed through data or voice channels .The networks can include local components and data pathways necessary for communications to be exchanged among computing device components and between integrated device components and peripheral devices .", "label": "", "metadata": {}, "score": "64.49628"}
{"text": "Concepts are often expressed in phrases , such as \" dark matter , \" \" President of the United States , \" or idioms like \" under the weather \" or \" dime a dozen \" .At best , some prior systems will index documents with respect to a predetermined and very limited set of ' known ' phrases , which are typically selected by a human operator .", "label": "", "metadata": {}, "score": "64.53917"}
{"text": "A computer - readable recordable storage medium having recorded thereon computer - executable instructions that , when executed by a computer , cause the computer to carry out a method , the method comprising : . prompting a user to provide speech input ; and .", "label": "", "metadata": {}, "score": "64.58548"}
{"text": "A computer - readable recordable storage medium having recorded thereon computer - executable instructions that , when executed by a computer , cause the computer to carry out a method , the method comprising : . prompting a user to provide speech input ; and .", "label": "", "metadata": {}, "score": "64.58548"}
{"text": "A computer - readable recordable storage medium having recorded thereon computer - executable instructions that , when executed by a computer , cause the computer to carry out a method , the method comprising : . prompting a user to provide speech input ; and .", "label": "", "metadata": {}, "score": "64.58548"}
{"text": "A computer - readable recordable storage medium having recorded thereon computer - executable instructions that , when executed by a computer , cause the computer to carry out a method , the method comprising : . prompting a user to provide speech input ; and .", "label": "", "metadata": {}, "score": "64.58548"}
{"text": "A computer - readable recordable storage medium having recorded thereon computer - executable instructions that , when executed by a computer , cause the computer to carry out a method , the method comprising : . prompting a user to provide speech input ; and .", "label": "", "metadata": {}, "score": "64.58548"}
{"text": "BACKGROUND .[0002 ] .The amount of data available to information seekers has grown astronomically , whether as the result of the proliferation of information sources on the Internet , or as a result of private efforts to organize business information within a company , or any of a variety of other causes .", "label": "", "metadata": {}, "score": "64.60482"}
{"text": "This merging process can be handled by each index server for its respective shards , or by a separate set of merging servers .Once the index shards are merged , they are swapped in to replace the existing versions being served by the index servers .", "label": "", "metadata": {}, "score": "64.625336"}
{"text": "The user , at process block 940 , selects a suggestion from among the suggestions sent .Upon selecting a suggestion , a complete query is formed from the suggestion and sent to a search server at process block 945 .The search server then generates a set of search results and transmits those results back to the user at process block 950 .", "label": "", "metadata": {}, "score": "64.64845"}
{"text": "The voice recognition engine software preferably operates in conjunction with the voice navigator software and can be part of the same application program .The voice recognition engine 104 receives user inputs from a computer operating system 110 in the form of electronically detected spoken utterances .", "label": "", "metadata": {}, "score": "64.688324"}
{"text": "A user can position a cursor within a text box associated with a search and begin typing on a keyboard .The input module 420 will then accept the characters typed by the user and send those characters to the transmitter module .", "label": "", "metadata": {}, "score": "64.71838"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .There are presently shown in the drawings embodiments which are presently preferred , it being understood , however , that the invention is not limited to the precise arrangements and instrumentalities shown , wherein : .", "label": "", "metadata": {}, "score": "64.7245"}
{"text": "So if we remove an n -gram , chances are that other similar ( longer or shorter ) n -grams are present and can take over .In this way , it is not possible to directly compare the unlearning curve for the n -grams part with that for the numeric part of the tables .", "label": "", "metadata": {}, "score": "64.81419"}
{"text": "As with the level designation , the ordinal value count preferably begins from zero .Finally , the sub - context action command 154 is preferably comprised of two digits which , for convenience shall be referred to herein as x and y.", "label": "", "metadata": {}, "score": "64.84224"}
{"text": "The user interface segments the phrase at process block 920 and sends a segment to a guide engine at process block 925 .The guide engine selects suggestions at process block 930 .At process block 935 , the suggestions are sent to the user .", "label": "", "metadata": {}, "score": "64.90343"}
{"text": "Phraseidexpr can be used in place of phraseid .The phraseid or phraseidexpr attribute can be returned in application.lastresult$. utterance when a personal grammar is used for normal speech recognition .If neither the phraseid or phraseidexpr is specified , a badfetch error can be thrown .", "label": "", "metadata": {}, "score": "64.91134"}
{"text": "[0073 ] .FIG .9 is a flow diagram showing processing of a method 900 that can be used .Processing begins at START block 905 and proceeds to process block 910 where a user activates a search interface .", "label": "", "metadata": {}, "score": "64.93425"}
{"text": "n i which identify the ordinal value assigned to each sub - context object at each level along the path .The number of digits contained in this field ( i.e. , the value of \" i \" in the progression ) will depend upon the level where the sub - context object containing the linked macro is located .", "label": "", "metadata": {}, "score": "65.06665"}
{"text": "Voice recognition systems are designed to allow user data to be entered in a target application program by means of spoken words ( e.g. dictation of a report in a word processing application program ) .In addition , some systems also enable such target application programs to respond to voice commands for controlling the software ( e.g. , opening and closing windows , choosing program options , and causing the application software to perform certain functions ) .", "label": "", "metadata": {}, "score": "65.07188"}
{"text": "Therefore , prior art adaptation methods and conventional speech recognizing methods suffer from the problem of over - adaptation by frequently occuring words .In an extreme , where e.g. the used models are clean models and the system is used in noisy environment , the involved acoustic models would be adapted not only to the speaker but also to the environment .", "label": "", "metadata": {}, "score": "65.11049"}
{"text": "Model Perturbation : Analysis and Unlearning Curves .Much research has focused on devising improved principles for the statistical estimation of the parameters in language and translation models .The introduction of discriminative graphical models has marked a departure from traditional maximum likelihood estimation principles , and various approaches have been proposed .", "label": "", "metadata": {}, "score": "65.16529"}
{"text": "Both of these ideas of course are being pursued at the moment .It is of course important to remark that these limitations only refer to the current systems , where language is modelled as a Markov chain , and by entirely changing language model , different limitations could be found .", "label": "", "metadata": {}, "score": "65.17007"}
{"text": "On the other hand , optimization is really expensive in terms of computational cost .In Figure 9 , it increases roughly linearly with the development set size .It is nice to note how the computational time is strongly related to the number of optimization steps in Figure 10 . A.2 .", "label": "", "metadata": {}, "score": "65.18892"}
{"text": "FIG .3 is a sample portion of VoiceXML code 300 that demonstrates a use of the addvoicephrase element 310 .The code 300 defines attributes 320 for element 310 .Code 300 also includes prompts for an enrollment session 330 , where an acoustically provided phrase that is added to a grammar using element 310 is obtained .", "label": "", "metadata": {}, "score": "65.195816"}
{"text": "claim 14 , wherein making the change comprises adding the voice phrase to the voice - enrolled grammar .The method of .The method of .claim 14 , wherein making the change comprises deleting the voice phrase from the voice - enrolled grammar .", "label": "", "metadata": {}, "score": "65.298676"}
{"text": "To conserve processing resources or for other reasons , a limit can be set that provides a maximum number of times that a particular query can be modified or otherwise refines an update algorithm .[ 0084 ] .FIG .13 is a flow diagram of a general processing flow of the method 1300 that can be used with the dynamic search client .", "label": "", "metadata": {}, "score": "65.392006"}
{"text": "Alternatively , if the sub - context object is on level three , then the object path field will include 3 digits .Thus , if the linked macro was located in sub - context object 66 in FIG .4 , the sub - context object level 150 would be 3 ( the root of the tree is the zero level ) .", "label": "", "metadata": {}, "score": "65.44649"}
{"text": "On a given document URL 0 , the indexing system 110 identifies each outlink to another document URL 1 , in which the anchor text A is a phrase in the good phrase list 208 .FIG .8 a illustrates schematically this relationship , in which anchor text \" A \" in document URL 0 is used in a hyperlink 800 .", "label": "", "metadata": {}, "score": "65.56206"}
{"text": "These attributes can include , but are not limited to a window class name 72 , a window identification number 74 , a window text string 76 , and a window enumeration index value 78 , as shown in FIG .5(A ) .", "label": "", "metadata": {}, "score": "65.636154"}
{"text": "processing the speech input , wherein the processing comprises editing at least one voice - enrolled grammar based on the speech input , the at least one voice - enrolled grammar comprising at least one word or phrase added to the voice - enrolled grammar by the user , . wherein editing the at least one voice - enrolled grammar comprises editing in accordance with attributes associated with the at least one VoiceXML tag .", "label": "", "metadata": {}, "score": "65.64664"}
{"text": "The system of . claim 19 , wherein decomposing the input text includes replacing one or more of the input words with a related word .The system of . claim 19 , wherein decomposing the input text includes replacing one or more of the component phrases with a related phrase .", "label": "", "metadata": {}, "score": "65.70631"}
{"text": "L. Specia , M. Turchi , Z. Wang , J. Shawe - Taylor , and C. Saunders , \" Improving the confidence of machine translation quality estimates , \" in Proceedings of 12th the Machine Translation Summit , 2009 . D. Vilar , J. Xu , L. F. D'Haro , and H. Ney , \" Error analysis of statistical machine translation output , \" in Proceedings of the 5th International Conference on Language Resources and Evaluation ( LREC ' 06 ) , Genova , Italy , 2006 .", "label": "", "metadata": {}, "score": "65.712326"}
{"text": "The first unlearning curve ( Figure 6 ) , obtained by adding to each parameter a random number ( sampled from within a range ) proportional to its size , is meant to test the role of detailed tuning of parameters .", "label": "", "metadata": {}, "score": "65.9626"}
{"text": "In one configuration of system 100 , modifications to the grammars 130 - 136 can occur during a dialog session based upon input directly provided by speaker 105 .In another configuration , modifications to the grammars 130 - 136 can be handled as batch processes , which receive input from audio source 110 .", "label": "", "metadata": {}, "score": "66.0955"}
{"text": "processing the speech input , wherein the processing comprises editing at least one voice - enrolled grammar based on the speech input , the at least one voice - enrolled grammar comprising at least one word or phrase added to the voice - enrolled grammar by the user , . wherein the computer - executable instructions are implemented as VoiceXML code , . wherein editing the at least one voice - enrolled grammar based on the speech input comprises : . adding a first voice phrase to a voice - enrolled grammar , the speech input comprising the first voice phrase ; and/or . deleting a second voice phrase from an existing voice enrolled grammar , the speech input comprising the second voice phrase , and .", "label": "", "metadata": {}, "score": "66.15075"}
{"text": "Using this information , the navigator can utilize available operating system functions to enumerate the child window objects of the foreground window in step 124 .The navigator then matches a child of the foreground sub - context object to a child of the foreground window object to determine a current window object in step 126 .", "label": "", "metadata": {}, "score": "66.20925"}
{"text": "FIG .4 .The number of shards in each tier is variable ; as shown in .FIG .5 , there are S 1 shards in Tier 1 and S 2 shards in Tier 2 .Each index server 200 knows the number of shards ( and hence index servers 200 ) in the next tier , and thus can readily determine via the shard assignment function which index servers 200 in that next tier are to receive its shard during query processing .", "label": "", "metadata": {}, "score": "66.224106"}
{"text": "The search server 630 can also access information from a content associator 650 .As with other data stores , the associated content data store 660 can be a database , can be a file , can be a group of files , or can be any suitable means of storing information for retrieval in accordance with the specific implementation .", "label": "", "metadata": {}, "score": "66.33421"}
{"text": "The number of documents crawled per pass can vary , and is preferably about 1,000,000 per partition .It is preferred that only previously uncrawled documents are processed in each partition , until all documents have been processed , or some other termination criteria is met .", "label": "", "metadata": {}, "score": "66.47862"}
{"text": "The search for the optimal translation in ( 2 ) is also referred to as decoding as , in the original analogy of the noisy channel , it corresponds to retrieving the clean message ., we usually assume that the feature functions decompose linearly across basic constituents of the sentences .", "label": "", "metadata": {}, "score": "66.5171"}
{"text": "The test set is used to evaluate the quality of models on the data .All experiments using Moses have been run using the default parameter configuration .The training , development , and test set sentences are tokenized and lowercased .", "label": "", "metadata": {}, "score": "66.55784"}
{"text": "If neither the phrasenl nor the phrasenlexpr attribute is specified , a badfetch error is thrown .The weight attribute can be an optional attribute that specifies a phrase weight .The weight attribute can be implemented as a float type having a value form 0.0 to 1.0 .", "label": "", "metadata": {}, "score": "66.5865"}
{"text": "The window stack is oriented along an imaginary axis , extending outwardly from the screen .The foreground window is the window at the top of the z - order .It is the window that the user is working with at a particular moment .", "label": "", "metadata": {}, "score": "66.606895"}
{"text": "The deletevoicephrase element can be a VoiceXML element configured to delete a voice phrase from an existing voice enrolled grammar .The updatevoicephrase element can be a VoiceXML element configured to update a voice phrase included in an existing voice enrolled grammar .", "label": "", "metadata": {}, "score": "66.656334"}
{"text": "The two effects interact with richer classes being better approximators of the target behaviour but requiring more training data to reliably identify the best hypothesis .The resulting trade - off , equally well known in statistics and in machine learning , can be expressed in terms of bias versus variance , capacity control , or model selection .", "label": "", "metadata": {}, "score": "66.803795"}
{"text": "As noted above , the co - occurrence matrix 212 is an m\u00d7m matrix of storing data associated with the good phrases .Each row j in the matrix represents a good phrase g j and each column k represented a good phrase g k .", "label": "", "metadata": {}, "score": "66.82654"}
{"text": "Query Optimization .The goal of query optimization 1020 is to restructure the query to minimize computational and network costs .This is done by evaluating 1022 the structure of the schedule tree using a query cost analysis to select between logically equivalent versions of various nodes of the schedule tree .", "label": "", "metadata": {}, "score": "66.870186"}
{"text": "Descripci\u00f3n .CROSS - REFERENCE TO RELATED APPLICATION .[ 0001 ] .This application claims benefit under 35 U.S.C. \u00a7 119(e ) from U.S. Provisional Patent Application Ser .No .60/655,583 , entitled \" DYNAMIC CLIENT INTERACTION FOR SEARCH \" and filed on Feb. 23 , 2005 .", "label": "", "metadata": {}, "score": "66.88101"}
{"text": "In a preferred embodiment , the link fields 148 are defined as shown in FIG .5(C ) .As shown therein , each of the link fields 148 is preferably comprised of three link parameters which include a sub - context object level 150 , a sub - context object path 152 , and a sub - context action command 154 .", "label": "", "metadata": {}, "score": "66.894394"}
{"text": "The dynamic search client 200 also includes a phrase suggestion engine 220 .The phrase suggestion engine 220 can interact with the user interface 210 in order to assist in suggesting phrases to substitute for that which a user is entering .", "label": "", "metadata": {}, "score": "67.07477"}
{"text": "Generally , program modules include routines , programs , components , data structures , etc . , that perform particular tasks and/or implement particular abstract data types .[ 0098 ] .The illustrated aspects of the invention may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network .", "label": "", "metadata": {}, "score": "67.17633"}
{"text": "Additionally , phrase related values used for speech recognition grammars can conform to the naming rules specified for by a Speech Recognition Grammar Specification ( SRGS ) compliant grammar .The addvoicephrase 212 element can be a VoiceXML input item that can be used to add a phrase to a new or existing voice enrolled grammar .", "label": "", "metadata": {}, "score": "67.19149"}
{"text": "11B .This means the inversion will be performed where the cost for processing the common children node Yi is either less than the minimum of the costs for the unshared nodes X ij , or greater than the maximum cost of these nodes .", "label": "", "metadata": {}, "score": "67.24153"}
{"text": "A possible phrase p is removed from the possible phrase list 206 and placed on the good phrase list 208 if : .These thresholds are scaled by the number of documents in the partition ; for example if 2,000,000 documents are crawled in a partition , then the thresholds are approximately doubled .", "label": "", "metadata": {}, "score": "67.31291"}
{"text": "Other directed and undirected model classification approaches include , for example , naive Bayes , Bayesian networks , decision trees , and probabilistic classification models providing different patterns of independence can be employed .Classification as used herein also includes statistical regression that is utilized to develop models of priority .", "label": "", "metadata": {}, "score": "67.3241"}
{"text": "In other cases , however , it will be impossible for the navigator program to uniquely and unambiguously match a window object to its corresponding sub - context object .This can occur under circumstances where two window objects , and two corresponding sub - context objects , share a common set of attributes .", "label": "", "metadata": {}, "score": "67.37365"}
{"text": "claim 1 , wherein scoring each phrasification comprises : . applying a scoring model : .S .f .N . )i .N .P .p .i . )C .p .i . ) to each phrasification where , .", "label": "", "metadata": {}, "score": "67.461876"}
{"text": "In each phrase window 302 , each candidate phrase is checked in turn to determine if it is already present in the good phrase list 208 or the possible phrase list 206 .If the candidate phrase is not present in either the good phrase list 208 or the possible phrase list 206 , then the candidate has already been determined to be \" bad \" and is skipped .", "label": "", "metadata": {}, "score": "67.78039"}
{"text": "According to another example in which an adaptation is based on maximum a posteriori estimation ( MAP ) each Gaussian observed in the speech signal of an utterance is transformed individually .Since Gaussians are shared across phoneme models , adaptation only on the same word would cause the Gaussian to adapt to a specific context .", "label": "", "metadata": {}, "score": "67.79426"}
{"text": "The clashlevel attribute can be an optional attribute used to specify a level of similarity between two different pronunciations that is needed to be unambiguous .A value of the clashlevel attribute can be between 0.0 and 1.0 .The higher value for the clashlevel attribute can represent an increased opportunity for clashes while reducing a likelihood of recognition ambiguity among other phrases .", "label": "", "metadata": {}, "score": "67.794876"}
{"text": "The VoiceXML code can include a VoiceXML native tag selected from a list of tags consisting of an addvoicephrase tag , a deletevoicephrase tag , and an updatevoicephrase tag .The code can also include an identifier associated with the VoiceXML native tag that identifies a voice phrase .", "label": "", "metadata": {}, "score": "67.801834"}
{"text": "[0067 ] .FIG .8 is a diagram of a user interface 800 that can be employed with various disclosed and described components of a dynamic search client .The user interface 800 includes a group of function selection links 810 that allow a user to designate a field for a search .", "label": "", "metadata": {}, "score": "68.10585"}
{"text": "A default value for the maxattempts attribute can be four ( 4 ) .A range of values for the maxattempts attribute can be 0 .The minconsistent attribute can be an optional attribute used to specify the minimum number of consistent pronunciations that must be obtained to voice enroll a phrase .", "label": "", "metadata": {}, "score": "68.113144"}
{"text": "In such case , the minor function value y designates the ordinal value of the macro to be activated within the private vocabulary 84 or sub - context object command vocabulary 86 .Once the sub - context object tree has been constructed in the foregoing manner , each of the sub - context trees is stored in an electronic memory device as a context data file in a computer system .", "label": "", "metadata": {}, "score": "68.11752"}
{"text": "Additionally , the user interface 510 can cooperate with other components to provide an interactive search environment to the user .[ 0053 ] .A query suggestion module 520 can communicate with the user interface 510 to obtain portions of a phrase entered by a user .", "label": "", "metadata": {}, "score": "68.1366"}
{"text": "After a restructuring 1022 an optional rescheduling on the restructured nodes may be performed , depending on which query costs analysis is being used .An implementation of this process by the query scheduling module 820 is as follows .The query scheduling module 820 first executes a breadth - first traversal of the schedule tree , and evaluating each node therein .", "label": "", "metadata": {}, "score": "68.14116"}
{"text": "claim 1 , further comprising : . receiving a query comprising at least one phrase ; . retrieving a plurality of documents responsive to the query to form the set of documents as a search result set including the first document and the second document ; and .", "label": "", "metadata": {}, "score": "68.21089"}
{"text": "The method according to claim 11 wherein said step of executing said linked macro is performed by said navigator program by the steps of : . locating said linked macro in said sub - context tree based upon said sub - context object path , sub - context object level , and sub - context object action command ; . matching the sub - context object containing said linked macro to a target window object of the current target application state .", "label": "", "metadata": {}, "score": "68.28257"}
{"text": "It may be new phrase just coming into usage , and thus during subsequent crawls becomes increasingly common .In that case , its respective counts will increases and may ultimately satisfy the thresholds for being a good phrase .The third stage of the indexing operation is to prune 204 the good phrase list 208 using a predictive measure derived from the co - occurrence matrix 212 .", "label": "", "metadata": {}, "score": "68.42533"}
{"text": "The file system is Ibrix and provides data access from all nodes , with a total of 17 TB of storage .Experiments using Portage are distributed over several CPUs , the total number of which depends on the various stages in the estimation process .", "label": "", "metadata": {}, "score": "68.54964"}
{"text": "In step 98 , the navigator compares a set of window objects which are children of the top - level window object to a set of sub - context objects which are children of the top - level sub - context object .", "label": "", "metadata": {}, "score": "68.56067"}
{"text": "W. Locke and A. Booth , Machine Translation of Languages , MIT Press , Cambridge , Mass , USA , 1955 .P. F. Brown , S. D. Pietra , V. J. D. Pietra , and R. L. Mercer , \" The mathematic of statistical machine translation : parameter estimation , \" Computational Linguistics , vol .", "label": "", "metadata": {}, "score": "68.61708"}
{"text": "A phrase window may be terminated by an end of line , a paragraph return , a markup tag , or other indicia of a change in content or format .FIG .3 illustrates a portion of a document 300 during a traversal , showing the phrase window 302 starting at the word \" stock \" and extending 5 words to the right .", "label": "", "metadata": {}, "score": "68.64731"}
{"text": "Google in [ 30 ] has shown that performance improves logarithmically in the linear scale with the number of tokens in the language model training set when this quantity is huge ( from billions to trillions of tokens ) .In this section , we are interested to understand whether there is a trade - off between the training data size used to build language and translation models and how performances are affected by their differences .", "label": "", "metadata": {}, "score": "68.699615"}
{"text": "FIG .2 is a system block diagram of a dynamic search client .[ 0012 ] .FIG .3 is a system block diagram of a guide engine and user interface system .[ 0013 ] .FIG .4 is a system block diagram of a dynamic search user interface .", "label": "", "metadata": {}, "score": "68.74077"}
{"text": "\"A \" AND \" B CD \" .\"A B \" AND \" C D \" .\"A B C \" AND \" D \" .\"A \" AND \" B \" AND \" CD \" .\"", "label": "", "metadata": {}, "score": "68.98628"}
{"text": "For example , if there are twenty segments in the index , then a given index shard for group of phrase posting lists in a designated tier and shard is associated with the corresponding twenty segments shard for this same group , tier and shard of phrase posting lists .", "label": "", "metadata": {}, "score": "69.03203"}
{"text": "FIG .7 , the index servers 200 themselves perform the combining operation , reading the segment shard files from the update index 230 into their own memory , and doing the merge operation locally .The swap master server 240 directs the merging process in which the merges are performed by the individual index servers 200 .", "label": "", "metadata": {}, "score": "69.049446"}
{"text": "The search engine 140 also communicates with the user interface 110 to accept information from the user interface 110 and transmit information back .The information transmitted from the search engine 140 to the user interface 110 is typically in the form of search results .", "label": "", "metadata": {}, "score": "69.13989"}
{"text": "This is done to avoid having to return the usually large set of all results that are not in a given set .( v )If the current node is an AND node , separate the children nodes into two groups : those children which are scheduled to execute on the current server ( local group ) and those which are scheduled to execute on other servers ( remote group ) .", "label": "", "metadata": {}, "score": "69.28438"}
{"text": "Preferably , the presentation system 130 keeps the document that has a higher page rank or other query independent measure of document significance .In addition , the presentation system 130 can modify the index 150 to remove the duplicate document , so that it will not appear in future search results for any query .", "label": "", "metadata": {}, "score": "69.34656"}
{"text": "138 - 145 , Morgan Kaufmann Publishers , San Francisco , Calif , USA , 2002 .S. Banerjee and A. Lavie , \" Meteor : an automatic metric for mt evaluation with improved correlation with human judgments , \" in Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics , Ann Arbor , Mich , USA , 2005 .", "label": "", "metadata": {}, "score": "69.55667"}
{"text": "A range of values for the minconsistent attribute can be one ( 1 ) to maxattempts .The badphrasesuri attribute can be an optional attribute used to specify an SRGS grammar that contains phrases that should not be spoken as part of the enrollment .", "label": "", "metadata": {}, "score": "69.615166"}
{"text": "To batch enroll , maxattempts should set to one ( 1 ) , minconsistent should be set to one ( 1 ) and one audio URI should be exist .The addvoicephrase 212 element can return one or more object 232 that is either a complex or simple result depending upon an enrollment outcome .", "label": "", "metadata": {}, "score": "69.61524"}
{"text": "One problem with conventional type dynamic analysis navigators is that their basic design does not easily permit macros associated with one user command to be combined with macros associated with other user commands .This is because , in the case of dynamic analysis navigators , a vocabulary set and its associated macros are available to a user only when a particular screen object associated with such vocabulary and macro is the foreground object .", "label": "", "metadata": {}, "score": "69.91305"}
{"text": "The evaluation cost of a NOT node is equal to the evaluation cost of its child .The subtree cost function has the effect that the de Morgan inversion is be performed if and only if the evaluation cost of the inverted tree is less than the evaluation cost of the original tree .", "label": "", "metadata": {}, "score": "69.92912"}
{"text": "The phrasenl can be an optional attribute used to specify a semantic tag value to associate with the phrase ID .Phrasenlexpr can be used in place of phrasenl .The phrasenl or phrasenlexpr attribute can be returned in application.lastresult$. interpretation when a personal grammar is recognized .", "label": "", "metadata": {}, "score": "70.02492"}
{"text": "For instance , the natural language query sent by the query suggestion engine 720 can be transformed into an SQL statement .The SQL statement can be sent by the structuring engine 730 to the search engine 740 .The search engine 740 can use the SQL statement to identify and obtain responsive information from a search data store 750 .", "label": "", "metadata": {}, "score": "70.278"}
{"text": "claim 1 , wherein comparing the document description of the first document with a document description of the second document further comprises : . generating for the first document a document description by selecting sentences of the first document , and ordering in the document description as a function of a number of related phrases in each sentence ; and . retrieving for the second document a stored document description comprising selected sentences of the second document , wherein the selected sentences are ordered in the document description as a function of a number of related phrases in each sentence .", "label": "", "metadata": {}, "score": "70.543465"}
{"text": "The query execution module 830 of the front end server 140 is responsible for managing the overall execution of the query schedule ; this query execution module 830 is called the root query execution module 830 .An instance of a query execution module 830 is also present in each index server 200 .", "label": "", "metadata": {}, "score": "70.64703"}
{"text": "The attributes 222 associated with the addvoicephrase 212 element can include attributes of name , phraseid , phraseidexpr , src , srcexpr , phrasenl , phrasenlexpr , weight , recordphraseaudio , consistencylevel , classlevel , maxattempts , minconsisistent , badphrasesuri , audioinputurilist , and other such attributes .", "label": "", "metadata": {}, "score": "70.772995"}
{"text": "Thus , a phrase g j predicts another phrase g k when the information gain I of g k in the presence of g j exceeds a threshold .And good phrase g j predicts good phrase g k where : .", "label": "", "metadata": {}, "score": "70.80494"}
{"text": "Laptop computer , or other machine , or whether those files are located on a logical desktop of a GUI or at some other location in a file system .A Results check box 820 allows the user to select whether results of partial searches are to be shown .", "label": "", "metadata": {}, "score": "70.8768"}
{"text": "Grammar 130 can originally include Phrase_B , Phrase_C , Phrase_D. VoiceXML code 122 , which can include a VoiceXML native tag 123 for adding a voice phrase , can cause Phrase_A to be added to the grammar 130 , which results in modified grammar 132 .", "label": "", "metadata": {}, "score": "70.93142"}
{"text": "However , the phrase \" Australian Shepherd Club of America \" appears as anchor text for a hyperlink ( indicated by the underline ) to website .The process of traversing each document with both the sequence window 302 and the secondary window 304 , is repeated for each document in the partition .", "label": "", "metadata": {}, "score": "70.9704"}
{"text": "In many cases , input can be collected multiple times until either it 's consistent or until the input has exceeded a maximum number of attempts , which can be indicated by a maxattempts attribute .The addvoicephrase 212 input item can provide two methods to obtain input .", "label": "", "metadata": {}, "score": "71.028625"}
{"text": "As noted above , the a separate set of merge servers can perform the merging operation directly on the server cluster master 220 , in which case they are controlled by the swap master server 240 in the manner just described .", "label": "", "metadata": {}, "score": "71.178185"}
{"text": "( \" restaurants \" , L 3 , IS 3 ) .OR : L 2 + L 3 , IS 3 .( \" restaurant \" , L 2 , IS 2 ) .The query schedule 825 is passed the query execution module 830 .", "label": "", "metadata": {}, "score": "71.193306"}
{"text": "A typical combination of hardware and software may be a general purpose computer system with a computer program that , when being loaded and executed , controls the computer system such that it carries out the methods described herein .The present invention also may be embedded in a computer program product , which comprises all the features enabling the implementation of the methods described herein , and which when loaded in a computer system is able to carry out these methods .", "label": "", "metadata": {}, "score": "71.20436"}
{"text": "The method according to claim 6 further comprising the step of executing said direct action represented by the decoded phrase .The method according to claim 9 wherein said step of executing said desired action represented by the decoded phrase is performed by said navigator program by matching said target sub - context object to a target window object of the current target application state .", "label": "", "metadata": {}, "score": "71.28078"}
{"text": "It should be noted that the window handle is an essential piece of information which is necessary to allow the associated window object to be uniquely identified .The window handle is a dynamic , instance specific , operating system identification number , which permits a window object to be uniquely identified within the operating system at any given moment in the execution of the target application .", "label": "", "metadata": {}, "score": "71.550995"}
{"text": "The expected value E is the percentage of documents in the collection expected to contain g j .This is computed , for example , as the ratio of the number of documents containing g j to the total number T of documents in the collection that have been crawled : P(j)/T. .", "label": "", "metadata": {}, "score": "71.79453"}
{"text": "The value of the message associated with this event , which can be returned in object 232 , can be a comma delimited list of phraseids and a comma delimited list of confusable phrases .The error.enroll.maxattempts event can be generated when consistency is not achieved within a maximum number of attempts , as determined by the maxattempts attribute .", "label": "", "metadata": {}, "score": "71.935394"}
{"text": "If the current node is an OR node , execute all of the children of this OR node ( in parallel , if possible ) and return the OR ( union ) of their results .( iv )If the current node is a NOT node , execute its child , and return the negation of its results .", "label": "", "metadata": {}, "score": "72.1202"}
{"text": "RDF+XML BibTeX RDF+N - Triples JSON RefWorks Dublin Core Simple Metadata Refer METS HTML Citation ASCII Citation OpenURL ContextObject EndNote OpenURL ContextObject in Span MODS MPEG-21 DIDL EP3 XML Reference Manager RDF+N3 Multiline CSV .Nadh , Kailash and Huyck , Christian R. ( 2009 ) Prepositional phrase attachment ambiguity resolution using semantic hierarchies .", "label": "", "metadata": {}, "score": "72.17262"}
{"text": "In a given phrase window 302 , identify all good phrases in the window , starting at position i. Each good phrase is denoted as g i .Thus , g 1 is the first good phrase , g 2 would be the second good phrase , and so forth .", "label": "", "metadata": {}, "score": "72.1799"}
{"text": "A search engine 240 can also interact with the user interface 210 of the dynamic search client 200 .The search engine 240 can be located on a remote server , such as in the case of many of the search engines used to find content on the World Wide Web .", "label": "", "metadata": {}, "score": "72.24553"}
{"text": "5(B ) .The multi - action voice macro 140 includes vocabulary phrase 142 which corresponds to a spoken user command which is recognizable by the navigator .In addition , the multi - action voice macro 140 defines a specific pre - determined sequence of actions to be performed when the vocabulary phrase 142 is spoken .", "label": "", "metadata": {}, "score": "72.29851"}
{"text": "New \" AND \" York \" AND \" Ethiopian \" AND \" restaurants \" .The possible phrasification can be extended to include all permutations of the order of the conjuncts as well ( e.g. , phrasification where the sequence of A , B , C . . .", "label": "", "metadata": {}, "score": "72.33197"}
{"text": "To complete the update of the index servers 200 , the segment shard files 225 from various segments are combined into the index shard files 115 which are served from the index servers 200 .To do this , the index specifications for all segments are read by the server cluster master 220 , and locations of the segment shard files corresponding to the most recent versions of each segment are determined .", "label": "", "metadata": {}, "score": "72.36383"}
{"text": "The query suggestion module 520 can also access information from a user feedback module 540 in order to adjust a manner in which the query would otherwise be completed .[0054 ] .Information in the feedback data store 550 can be compiled from analysis of a user 's interaction with the results of search queries over time .", "label": "", "metadata": {}, "score": "72.39318"}
{"text": "claim 9 , wherein creating a suggestion includes referencing a set of suggestions .The method of . claim 10 , wherein referencing a set of suggestions includes referencing a probability measure .The method of . claim 10 , wherein referencing a set of suggestions includes referencing a ranking of suggestions .", "label": "", "metadata": {}, "score": "72.45803"}
{"text": "The navigator will first traverse the sub - context tree upwardly from sub - context object 66 , one level at a time , until it finds a match between a sub - context object and the current foreground window object .", "label": "", "metadata": {}, "score": "72.629944"}
{"text": "Srcexpr can be used in place of src .The grammar can be updated at the URI using HTTP PUT request .When the deleted phrase is the last phrase in the grammar , an HTTP DELETE request can be sent to the server .", "label": "", "metadata": {}, "score": "72.91046"}
{"text": "A method for implementing a multi - action voice macro for a voice recognition navigator program on a computer system , said method comprising the steps of : . scanning a target application program to determine a plurality of target application states , each of said target application states being comprised of a plurality of window objects ; . organizing each of said target application states in the form of a sub - context tree , each of said sub - context trees being comprised of a plurality of sub - context objects , said sub - context tree defining a hierarchical relationship among said sub - context objects ; . determining a set of user inputs to which each of said window objects will be responsive , and assigning a corresponding set of said voice macros to each of the sub - context objects for simulating each of said user inputs in response to a spoken utterance ; . defining each of said voice macros to include a vocabulary phrase , said vocabulary phrase defining the spoken utterance to which each of said voice macros is responsive ; . storing the sub - context trees in an electronic memory device as a context data file ; . executing said voice recognition navigator program on said computer system simultaneously with said target application program so that a spoken utterance corresponding to said vocabulary phrase will cause said linked macro to be executed .", "label": "", "metadata": {}, "score": "72.97688"}
{"text": "This search server 630 uses the suggested query to obtain responsive information from the search data store 640 .[ 0063 ] .The content associator 650 accesses the responsive information obtained by the search server 630 and analyzes that responsive information to form a second query .", "label": "", "metadata": {}, "score": "73.02035"}
{"text": "The OR node with \" restaurants \" can be provided by the user , or by a query expansion source .The input query has the following Boolean word tree : .( New and York and Restaurant or Restaurants ) .", "label": "", "metadata": {}, "score": "73.0898"}
{"text": "The OR node is assigned to its most expensive child IS 2 , as per scheduling rule ( d ) .Next , the query scheduling module 820 optimizes the schedule tree , beginning with topmost OR node and descend depth - first .", "label": "", "metadata": {}, "score": "73.14196"}
{"text": "4 is a sample portion of VoiceXML code that demonstrates a use of the deletevoicephrase element .FIG .5 is a sample portion of VoiceXML code that demonstrates a use of the updatevoicephrase element .DETAILED DESCRIPTION OF THE INVENTION .", "label": "", "metadata": {}, "score": "73.209946"}
{"text": "The addvoicephrase 212 can collect input from an input source referenced by the audioinputurilist attribute for each utterance collection necessary to achieve consistency .If the list length can not satisfy the consistency requirement then an error event associated with the maximum number of attempts ( e.g. error.enroll.maxattampts ) can be triggered .", "label": "", "metadata": {}, "score": "73.368256"}
{"text": "Once enrolled , the voice enrolled grammar 130 - 136 can be referenced and used by the speech recognition engine 140 just like a text - based grammar .Accordingly , voice enrolled grammars 136 can be referenced by any standard text - based grammar , such as a Speech Recognition Grammar Specification ( SRGS ) compliant grammar to create more complex , usable grammars .", "label": "", "metadata": {}, "score": "73.59111"}
{"text": "The matching step 94 is preferably performed first by attempting to match a window object from the current application state to a first or top - level sub - context object from each of the sub - context trees .More specifically , the navigator program attempts to match a set of window attributes of the top - level window object of the target application program , to a set of attributes of one of the top - level sub - context objects contained within the sub - context tree .", "label": "", "metadata": {}, "score": "73.59985"}
{"text": "[0048 ] .The user interface 410 also includes a transmitter module 430 that sends information , including suggestions , to a search server 440 .The search server 440 performs certain actions relating to suggestions and transmits information to a receiver module 450 of the user interface 410 .", "label": "", "metadata": {}, "score": "73.64395"}
{"text": "Rather , such a system is likely to also retrieve and highly rank documents that are about Australia ( and have nothing to do with dogs ) , and documents about \" shepherds \" generally .The problem here is that conventional systems index documents based on individual terms , than on concepts .", "label": "", "metadata": {}, "score": "73.657425"}
{"text": "One example of a possible mode of operation of the guide engine and user interface system 300 follows .In operation , the user interface 305 accepts an entered phrase from a user .As the user types the phrase at a keyboard , portions of the phrase , such as single characters or groups of characters , are transmitted to the query segment engine 320 of the guide engine 310 .", "label": "", "metadata": {}, "score": "74.16788"}
{"text": "Specifics of the change are determined be specifics associated with the VoiceXML native tag .The addvoicephrase tag can cause the identified voice phrase to be added to the grammar .The deletevoicephrase tag can cause the identified voice phrase to be deleted from the grammar .", "label": "", "metadata": {}, "score": "74.18225"}
{"text": "The sub - context object command vocabulary corresponds to spoken navigation commands for window objects which are treated by the navigator as active , although the associated window object is not the foreground window .Once the sub - context vocabulary set 80 has been defined , each word or phrase is preferably arranged within a macro format .", "label": "", "metadata": {}, "score": "74.26869"}
{"text": "The central processing unit ( or CPU ) is electronically coupled to the one or more electronic memory storage devices , data entry device and display unit by suitable means which are well know by those of ordinary skill in this field .", "label": "", "metadata": {}, "score": "74.31991"}
{"text": "Table 200 can contextually apply to the tags 123 , 125 , and/or 127 of system 100 .It should be appreciated that specific names and details for each of the elements of table 200 are for illustrative purposes only and that alternative implementations of the concepts expressed herein are contemplated .", "label": "", "metadata": {}, "score": "74.38378"}
{"text": "For example , in a typical Boolean system , a search on \" Australian Shepherds \" would not return documents about other herding dogs such as Border Collies that do not have the exact query terms .Rather , such a system is likely to also retrieve and highly rank documents that are about Australia ( and have nothing to do with dogs ) , and documents about \" shepherds \" generally .", "label": "", "metadata": {}, "score": "74.612976"}
{"text": "In a distributed computing environment , program modules may be located in local and/or remote memory storage devices .[0099 ] .FIG .15 is a schematic block diagram of a sample - computing environment 1500 .The system 1500 includes one or more client(s ) 1510 .", "label": "", "metadata": {}, "score": "74.655914"}
{"text": "The clashlevel attribute can default to a platform specific value .A value of ' 0.0 ' for the clashlevel attribute can signify that a clash test will not be performed .The maxattempts attribute can be an optional attribute used to specify the maximum number of training attempts that will be used to achieve a consistent statistical model .", "label": "", "metadata": {}, "score": "74.76541"}
{"text": "SING S .EGMENT S .WAPPING , filed Mar. 30 , 2007 ; P .HRASE E .XTRACTION U .SING S .UBPHRASE S .CORING , filed Mar. 30 , 2007 ; and B .IFURCATED D .", "label": "", "metadata": {}, "score": "74.832886"}
{"text": "An index shard may be stored by an index server 200 in memory , on disc , in a combination thereof .Thus , in .FIG .4 , there is shown index server 200 .1 through 200 .Index server 200 .", "label": "", "metadata": {}, "score": "74.91359"}
{"text": "It should also be noted that the addvoicephrase 212 element can support the same sub - elements as the other VoiceXML 2.0 input items with the exception of those elements related to speech and DTMF input ( e.g. , grammar , link , option ) .", "label": "", "metadata": {}, "score": "74.96146"}
{"text": "An example of the functioning the dynamic search client 200 follows .In operation , a user can enter a phrase at the user interface 210 .Such entry can be by typing , speaking , gesturing , or any other data entry method that can be employed with the user interface 210 .", "label": "", "metadata": {}, "score": "75.05222"}
{"text": "Therefore , results of a preliminary search can change as well .The user can submit a suggestion as a query at any time by clicking on the Search button 850 .Similarly , the user can terminate the creation of a suggested query by navigating directly to one of the preliminary search results displayed in the results area 860 .", "label": "", "metadata": {}, "score": "75.06172"}
{"text": "Each index server 200 manages the swap process as follows .This is done so that the index servers 200 can continue to service queries for documents in the phrase posting lists of the older shards .Preferably , phrase posting lists served by single index server 200 are divided into enough shards that a single shard contains no more than this desired percentage of phrases or documents therein .", "label": "", "metadata": {}, "score": "75.06244"}
{"text": "The search server 630 can use the suggested query as part of a search of information contained in a search data store 640 .The search data store 640 can be any suitable data store such as an index of websites or a database , among others .", "label": "", "metadata": {}, "score": "75.370926"}
{"text": "[ 0049 ] .In an exemplary mode of operation of the dynamic search user interface 400 , the user interface 410 is implemented as a hypertext markup language ( \" HTML \" ) document that includes JavaScript , a Java Applet , or another suitable component .", "label": "", "metadata": {}, "score": "75.50131"}
{"text": "For example , if the class name is \" BUTTON \" the window text of the button would be the words which would normally appear on the face of the button .Accordingly , the navigator would use the window text to determine the spoken command which can be used to activate the button .", "label": "", "metadata": {}, "score": "75.8763"}
{"text": "The search server 630 can then provide information that is responsive to the query along with associated content to the user interface 610 for presentation to the user . [0062 ] .A possible manner of operating the dynamic search client 600 follows .", "label": "", "metadata": {}, "score": "76.12926"}
{"text": "Finally , a linked action count field 146 is preferably provided which indicates the number of additional linked actions which are included as link parameters 148 .The precise content of the direct action field 144 will depend to a large extent upon the particular type of window object represented by the sub - context object in which the multi - action voice macro 140 is contained .", "label": "", "metadata": {}, "score": "76.24339"}
{"text": "The adaptation process is then performed by transforming the functions , model function mixtures and/or the model function mixture components themselves and/or by changing at least in part the contributions of model function mixture components of model function mixtures .Therefore , an adaptation of the current acoustic model can be performed in an easy way by damping and/or increasing the influence of the distinct model function mixture components - i.e . their amplitudes or contributions - on the whole modelling character of each of said model function mixtures within said current acoustic model .", "label": "", "metadata": {}, "score": "76.53844"}
{"text": "Values for the recordphraseaudio attribute can include a true and a false value , where false can be a default .When a value of recordphraseaudio is true , then shadow variables for bestrecording , bestrecordingsize , and bestrecordingduration can be assigned to the input item variable upon successful enrollment .", "label": "", "metadata": {}, "score": "76.715904"}
{"text": "The sub - context action objects 51 include a set of attributes describing actions which are independent of said window objects of the current application state .For example , such sub - context actions may be comprised of macros which simulate user interface events .", "label": "", "metadata": {}, "score": "76.73201"}
{"text": "The deletevoicephrase 214 element can be a VoiceXML executable item that is used to delete a phrase from an existing voice enrolled grammar .The deletevoicephrase 214 element can be associated with numerous attributes 224 , which include a phraseid attribute , phraseidexpr attribute , a src attribute , a srcexpr attribute , and the like .", "label": "", "metadata": {}, "score": "76.8735"}
{"text": "1 , the user interface 210 can be adapted in a wide variety of ways specific to a desired implementation .[ 0035 ] .As will be appreciated from this disclosure and detailed description , various implementations of the components and methods disclosed and described herein can be constructed or performed on a wide variety of general - purpose computing devices , such as the computer of .", "label": "", "metadata": {}, "score": "76.958786"}
{"text": "For example , a window object for an application program may contain therein , additional window objects such as buttons , text boxes , edit boxes , dialog boxes , etc .FIG .1(A ) illustrates a typical screen display for a top - level window object containing several additional window objects which are children of the top level window object .", "label": "", "metadata": {}, "score": "77.02833"}
{"text": "( Abstract )Mondrian : A Learning Graphical Editor IN Informatique 92 .International Conference Interface to Real and Virtual Worlds .Proceedings and Exhibition Catalog , Montpellier , France , Mar. 23 27 , 1992 :Author : H. Lieberman .", "label": "", "metadata": {}, "score": "77.22828"}
{"text": "In this specific example , information in the associated content data store 660 includes advertising .Content obtained from the associated content data store 660 that is responsive to the second query is provided to the search server 630 .The search server 630 sends both the responsive information and the associated contents to the user interface 610 for presentation to the user .", "label": "", "metadata": {}, "score": "77.236664"}
{"text": "FIG .3 , the secondary window 304 is 30 words .The co - occurrence matrix 212 thus maintains : .R(j , k ) : Raw Co - occurrence count .The number of times that phrase g j appears in a secondary window 304 with phrase g k ; .", "label": "", "metadata": {}, "score": "77.26688"}
{"text": "The Europarl corpus contains material extracted from the proceedings of the European parliament , and the UN data contains material from the United Nations .Both therefore cover a wide range of themes , but are fairly homogeneous in terms of style and genre .", "label": "", "metadata": {}, "score": "77.32831"}
{"text": "The newphraseid attribute can be a required attribute that represents the i d of the new phrase to be added .Newphraseidexpr can be used in place of newphraseid .The newphraseid or newphraseidexpr attribute can be returned in application.lastresult$. utterance when a personal grammar is used for normal speech recognition .", "label": "", "metadata": {}, "score": "77.536316"}
{"text": "In that case , the second phrase has significant information gain with respect to the first phrase .Semantically , related phrases will be those that are commonly used to discuss or describe a given topic or concept , such as \" President of the United States \" and \" White House .", "label": "", "metadata": {}, "score": "77.62314"}
{"text": "Some existing information retrieval systems attempt to provide retrieval of concepts by using co - occurrence patterns of individual words .In these systems a search on one word , such as \" President \" will also retrieve documents that have other words that frequently appear with \" President \" , such as \" White \" and \" House .", "label": "", "metadata": {}, "score": "77.70255"}
{"text": "Implementation for the bestrecording variable can be platform specific .The bestrecordingsize variable can store a size of the recording ( in bytes ) , or can remain undefined if no audio is collected .The bestrecordingduration variable can store a duration of the recording ( in milliseconds ) , or undefined if no audio is collected .", "label": "", "metadata": {}, "score": "77.706276"}
{"text": "The query is processed to identify any phrases that are present in the query , so as to retrieve the associated posting lists for the query phrases , and the related phrase information .In addition , in some instances a user may enter an incomplete phrase in a search query , such as \" President of the \" .", "label": "", "metadata": {}, "score": "77.777725"}
{"text": "If additional multi - step macros are provided for each window object , it will have the undesired effect of increasing the amount of memory which is required to store the navigator program .Further , providing a large number of complex macros for each screen object to be controlled by a navigator program causes the program to be more complex , more expensive to develop , and more prone to errors .", "label": "", "metadata": {}, "score": "78.50293"}
{"text": "The navigator searches for the current foreground window object first because it is the only window handle which is easily accessible .However , once provided with the window handle of the foreground window object , the navigator traces its way back down the sub - context object tree along the same path , at each level requesting the window handle for the child windows objects .", "label": "", "metadata": {}, "score": "78.53941"}
{"text": "After processing the document text , the phrase map table can be considered as : .Note that its first child , \" The quick brown fox \" , gets a score of 1 , per rule ( 2 ) above , and is already in the table , so this additional score is added , as shown below .", "label": "", "metadata": {}, "score": "78.57607"}
{"text": "A specific example of a suitable interface is an interface that is based upon a web browser .Another possible interface is a Braille interface that conveys information that the user can receive through touching the interface .As previously described in conjunction with .", "label": "", "metadata": {}, "score": "78.59233"}
{"text": "Prompting can continuously occur up to number of attempts reference by the maxattempts attribute so the audio source referenced by the audioinputurilist attribute can be used each time the prompt count is increased .It should be noted that the audio source referenced by the audioinputurilist attribute can be used for batch mode operation where audio has previously been collected .", "label": "", "metadata": {}, "score": "78.790436"}
{"text": "Examples of window text might include words such as \" OK \" or \" CANCEL \" in the case of a push - button , or a list of items in the case of a list box .Finally , the navigator may also probe the application program for the window identification number as a way to internally distinguish controls which may otherwise look similar .", "label": "", "metadata": {}, "score": "78.79817"}
{"text": "A user interface 305 can transmit information to a guide engine 310 .A query segment engine 320 can accept information from the user interface 305 , such as a phrase , and create a query segment from that information .The created query segment is then sent to a matching engine 330 .", "label": "", "metadata": {}, "score": "79.25089"}
{"text": "\" new york \" AND \" restaurants \" . \" new \" AND \" york restaurants \" . \" new \" AND \" york \" AND \" restaurants \" .The query phrasification module 810 scores each of these phrasification using phrase scoring function , keeping the top N. Assume that the top selected phrases are : . \" new york \" AND \" restaurant \" .", "label": "", "metadata": {}, "score": "79.824265"}
{"text": "AND : L 2 , IS 2 .( \" restaurant \" , L 2 , IS 2 ) .Scheduling rule ( d ) is applied to the OR node .The result is : .( \" new york \" , L 1 , IS 1 ) .", "label": "", "metadata": {}, "score": "79.95766"}
{"text": "[ 0047 ] .FIG .4 is a system block diagram of a dynamic search user interface 400 .A user interface 410 includes an input module 420 that accepts phrases input by a user .It should be recognized that a specific implementation of the input module 420 depends in part upon the type of user interface implemented .", "label": "", "metadata": {}, "score": "80.04037"}
{"text": "In this example , the query cost is posting list length , so the phrase list length based cost function is used .Accordingly , the de Morgan inversion is applied to result in the following schedule tree : .( \" new york \" , L 1 , IS 1 ) .", "label": "", "metadata": {}, "score": "80.04079"}
{"text": "Learning to Translate : A Statistical and Computational Analysis .Received 15 July 2011 ; Accepted 30 January 2012 .Academic Editor : Peter Tino .Copyright \u00a9 2012 Marco Turchi et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "80.267456"}
{"text": "185 - 188 , Prague , Czech Republic , 2007 .P. Koehn , \" Europarl : a parallel corpus for statistical machine translation , \" in Proceedings of the 10 th Machine Translation Summit , pp .79 - 86 , Phuket , Thailand , 2005 .", "label": "", "metadata": {}, "score": "80.33879"}
{"text": "The audio.ref object can include a duration of audio referenced by the audio.ref object .The duration can be in milliseconds by default .The audio.size object can include a length a audio , which can be in bytes by default .", "label": "", "metadata": {}, "score": "80.35054"}
{"text": "Additionally or alternatively , the user can manipulate a control of the user interface 510 , such as a slider , to indicate relative numbers of corrections , as opposed to suggestions , are desired .[ 0056 ] .The user feedback module 540 or the feedback data store 550 , or both , can be implemented as server on a remote computer .", "label": "", "metadata": {}, "score": "80.768265"}
{"text": "0105 ] .The various types of volatile and non - volatile memory or storage provided with the computer 1612 can be used to store components of various implementations of the data port signaling system disclosed and described herein .For example , with reference to .", "label": "", "metadata": {}, "score": "80.90153"}
{"text": "A search data store 250 can contain information that can be accessed and searched by the search engine 240 .The search data store 250 can be a file , a group of files , a database , or any other appropriate data store that can contain information to be searched .", "label": "", "metadata": {}, "score": "81.24648"}
{"text": "Referring to the example of .FIG .3 , assume that the \" stock dogs \" is on the good phrase list 208 , as well as the phrases \" Australian Shepherd \" and \" Australian Shepard Club of America \" .", "label": "", "metadata": {}, "score": "81.32127"}
{"text": "For example the phrases \" bolt action rifle \" and \" 22 \" would both have \" gun \" as a related phase .In this case , the search system 120 retrieves the posting lists of both phrases Q 1 and Q 2 and intersects the lists to produce a list of documents that contain both phrases .", "label": "", "metadata": {}, "score": "81.36453"}
{"text": "For example , if the search query is \" President of the United , \" the search system 120 can automatically suggest to the user \" President of the United States \" as the search query .After the last stage of the indexing process is completed , the good phrase list 208 will contain a large number of good phrases that have been discovered in the corpus .", "label": "", "metadata": {}, "score": "81.5515"}
{"text": "FIG .5 is system block diagram of a dynamic search client 500 that also includes user feedback functions .The dynamic search client 500 includes a user interface 510 .The user interface 510 can be a text - based interface , a graphical user interface , a command line interface , or any other suitable interface , specifically including any of the interfaces previously discussed in conjunction with other figures .", "label": "", "metadata": {}, "score": "81.604996"}
{"text": "For example , a developer may choose to develop a custom window object to replace a standard type of control such as a \" BUTTON \" , \" EDIT BOX \" , \" LISTBOX \" , or \" SCROLLBAR \" .Thus , the navigator can operate the control in the same manner as it would the standard control .", "label": "", "metadata": {}, "score": "81.7016"}
{"text": "The elements 210 can include an addvoicephrase 212 element , a deletevoicephrase 214 element , and an updatevoicephrase 216 element .Each element 212 - 216 can have a defined set of attributes 220 , returns 230 , and associated events 240 .", "label": "", "metadata": {}, "score": "81.81273"}
{"text": "In contrast the phone model for /t/ could still be adapted because it occured in different acoustical contexts \" Goethe \" , \" Stettener \" and \" Haupt \" .In the following the method for recognizing speech according to the invention will be explained in more detail taking reference to a schematical drawing on the basis of preferred embodiments of the inventive method for recognizing speech .", "label": "", "metadata": {}, "score": "82.100525"}
{"text": "( Abstract ) Macros and Screen Access ( computer use by the blind )IN Proceedings of the Seventh Annual Conference Technology and Persons with Disabilities , Proceedings of Conference .Technology and Persons with Disabilities , Los Angeles , CA , USA , Mar. 18 21 , 1992 ; Authors T. Henter ; H.J. Murphy .", "label": "", "metadata": {}, "score": "82.22919"}
{"text": "[ 0045 ] .The query suggestion data store 340 can be implemented in a variety of ways .For example , the query suggestion data store 340 can be a flat dictionary file containing common search terms to be used as suggestions .", "label": "", "metadata": {}, "score": "82.539314"}
{"text": "[ 0059 ] .FIG .6 is a system block diagram of a dynamic search client 600 that also includes content association functions .The dynamic search client 600 includes a user interface 610 .The user interface 610 to be a text - based interface , a graphical user interface , a command line interface , or any other suitable interface , specifically including any of the interfaces previously discussed in conjunction with other figures .", "label": "", "metadata": {}, "score": "82.71815"}
{"text": "VoiceXML code 124 , which can include a VoiceXML native tag 125 for deleting a voice phrase , can cause Phrase_D to be removed from the grammar 132 , which results in modified grammar 134 .Grammar 134 can , thus , include Phrase_A , Phrase_B , Phrase_C. VoiceXML code 126 , which can include a VoiceXML native tag 127 for updating a voice phrase , can cause Phrase_B to be modified , which results in modified grammar 136 .", "label": "", "metadata": {}, "score": "83.10779"}
{"text": "An example of such a processor would include the Pentium brand microprocessor available from Intel Corporation or any similar unit such as a 586 , 486 or 386 type microprocessor .The various hardware requirements for the computer system as described herein can generally be satisfied by any one of many commercially available high speed personal computers offered by manufacturers such as Compaq , Hewlett Packard , or IBM Corp.", "label": "", "metadata": {}, "score": "83.338806"}
{"text": "An incomplete phrase is a phrase that only predicts its phrase extensions , and which starts at the left most side of the phrase ( i.e. , the beginning of the phrase ) .The \" phrase extension \" of phrase p is a super - sequence that begins with phrase p. For example , the phrase \" President of \" predicts \" President of the United States \" , \" President of Mexico \" , \" President of AT&T \" , etc .", "label": "", "metadata": {}, "score": "83.40697"}
{"text": "For example , assume that the phrase \" weave poles \" appears in 75 of the 100 documents , \" teeter \" appears in 60 documents , \" red merle \" appears in 50 documents .Then the first cluster is named \" weave poles \" and a selected number of documents from that cluster are presented ; the second cluster is named \" teeter , \" and selected number are presented as well , and so forth .", "label": "", "metadata": {}, "score": "83.49235"}
{"text": "The foreground window object is usually the one from which the user has most recently requested some action of the application program .It should be noted , however , that other types of operating systems may indicate the foreground window by other means .", "label": "", "metadata": {}, "score": "83.5688"}
{"text": "For the simplest embodiment of this storage process , the index server cluster 160 is logically structured as shown in .FIG .4 .In .FIG .4 there is shown the index server cluster 160 with various index servers 200 .", "label": "", "metadata": {}, "score": "83.703"}
{"text": "The system 1500 also includes one or more server(s ) 1520 .The server(s ) 1520 can be hardware and/or software ( e.g. , threads , processes , computing devices ) .The servers 1520 can house threads or processes to perform transformations by employing the subject invention , for example .", "label": "", "metadata": {}, "score": "83.952255"}
{"text": "The window class name indicates the type of the object ( e.g. , \" BUTTON \" , \" LISTBOX \" , \" EDIT BOX \" , or \" SCROLLBAR \" ) .The window text feature is specific text associated with a window which allows a application program user to understand the function or relevance of a particular window .", "label": "", "metadata": {}, "score": "83.963684"}
{"text": "\"A B \" AND \" C \" AND \" D \" .\"A \" AND \" B \" AND \" C \" AND \" D \" .A more concrete example is \" New York Ethiopian restaurants \" , which yields the following phrasification : . \" New York Ethiopian restaurants \" . \"", "label": "", "metadata": {}, "score": "84.568344"}
{"text": "For example then , \" President of the United \" is an incomplete phrase because the only other phrase that it predicts is \" President of the United States \" which is an extension of the phrase .The incomplete phrase list 216 itself is very useful during actual searching .", "label": "", "metadata": {}, "score": "85.16168"}
{"text": "These values identify the specific linked macro to be activated within the sub - context object identified by the link field 148 .This is so because there is typically only one default macro for the sub - context name 82 .", "label": "", "metadata": {}, "score": "85.53145"}
{"text": "Similarly , the server(s ) 1520 are operably connected to one or more server data store(s ) 1530 that can be employed to store information local to the servers 1540 .[ 0101 ] .With reference to .FIG .16 , an exemplary environment 1600 for implementing various components includes a computer 1612 .", "label": "", "metadata": {}, "score": "85.54806"}
{"text": "Within the top level window object 26 are various other child window objects .In FIG . 1 ( A ) , these include a window object 28 , and buttons 34 , 36 .In addition , list box 30 , and edit box 32 are children of window object 28 .", "label": "", "metadata": {}, "score": "85.8669"}
{"text": "With reference to phrase suggestion tasks , the phrase suggestion engine 220 can suggest a phrase to substitute in place of the phrase that is being entered or has been entered by the user .For example , if a user enters \" aut , \" the phrase suggestion engine 220 can suggest the term \" automobile . \"", "label": "", "metadata": {}, "score": "86.102356"}
{"text": "( \" restaurants \" , L 3 , IS 3 ) .OR : L 3 + L 2 , IS 2 .( \" new york \" , L 1 , IS 1 ) .AND : L 2 , IS 2 .", "label": "", "metadata": {}, "score": "86.2608"}
{"text": "For each such update , the swap master server 240 determines from the index specification which index shard files 115 need to be updated on the index servers 200 , based on the version information for the segment shards 225 .The index specification is used then to determine which index servers 200 are associated with these index shards .", "label": "", "metadata": {}, "score": "86.387146"}
{"text": "Additionally , the user interface 710 can cooperate with other components to provide an interactive search environment to the user .[ 0066 ] .The user interface 710 can communicate with a query suggestion engine 720 .Specifically , the user interface 710 can provide a phrase to the query completion engine 720 .", "label": "", "metadata": {}, "score": "87.288086"}
{"text": "One possible means of communication between a client 1510 and a server 1520 can be in the form of a data packet adapted to be transmitted between two or more computer processes .The system 1500 includes a communication framework 1540 that can be employed to facilitate communications between the client(s ) 1510 and the server(s ) 1520 .", "label": "", "metadata": {}, "score": "87.32095"}
{"text": "The weight attribute can be an optional attribute used to specify the phrase weight as a float from 0.0 to 1.0 .No return object 236 is associated with the updatevoicephrase 216 element , which can be an executable item that does not return anything .", "label": "", "metadata": {}, "score": "87.32605"}
{"text": "Thus : .When the phrase identification server 250 processes \" quick brown fox jumps \" , its first child 's contribution is thus cancelled by the negative contribution : the only occurrence of \" quick brown fox \" occurred within a strong phrase .", "label": "", "metadata": {}, "score": "87.47983"}
{"text": "This determination allows for the fact that additional phrase information provided by the user can result in a change of the field of a query that can be based upon a suggestion .For example , a user who enters \" bruin \" as a phrase can initially be presented with completions that relate to species of bears .", "label": "", "metadata": {}, "score": "87.69091"}
{"text": "This cluster test is repeated for each pair ( g l , g m ) in R. .For example , assume the good phrase \" Bill Clinton \" is related to the phrases \" President \" , \" Monica Lewinsky \" , because the information gain of each of these phrases with respect to \" Bill Clinton \" exceeds the Related Phrase threshold .", "label": "", "metadata": {}, "score": "87.70301"}
{"text": "The system bus 1618 couples system components including , but not limited to , the system memory 1616 to the processing unit 1614 .The processing unit 1614 can be any of various available processors .Dual microprocessors and other multiprocessor architectures also can be employed as the processing unit 1614 .", "label": "", "metadata": {}, "score": "88.64787"}
{"text": "The swap master server 240 instructs the index servers 200 in the update group to begin the merge process .This process is typically done during a window of low load activity , such as late at night .The swap master server 240 provides each index server 200 in the update group with information identifying where the segment shard files 225 for its update are held ( which machine and directory ) .", "label": "", "metadata": {}, "score": "88.96285"}
{"text": "AND .( \" new york \" , L 1 , IS 1 ) .OR .( \" restaurant \" , L 2 , IS 2 ) .AND .( \" new york \" , L 1 , IS 1 ) .", "label": "", "metadata": {}, "score": "89.35912"}
{"text": "These phrases then form the set R. To determine the clusters , the indexing system 110 evaluates the information gain of each of these phrases to the others by determining their corresponding information gains .Thus , the indexing system 110 determines the information gain I(\"President \" , \" Monica Lewinsky \" ) , I(\"President \" , \" purse designer \" ) , and so forth , for all pairs in R. This is because while \" Bill Clinton \" does not predict \" purse designer \" with sufficient information gain , \" Monica Lewinsky \" does predict both of these phrases .", "label": "", "metadata": {}, "score": "89.46152"}
{"text": "In another example , if a user enters the term \" cars , \" the phrase suggestion engine 220 can suggest \" sports cars dealers in Seattle , Wash. \" .[ 0039 ] .Additionally or alternatively , the phrase suggestion engine 220 can suggest a query based upon a pattern that can include wildcards .", "label": "", "metadata": {}, "score": "89.56954"}
{"text": "( new AND york AND restaurant ) OR ( new AND york AND restaurants ) .The query phrasification module 810 generates the phrasification : . \" new york restaurant \" .\" new york \" AND \" restaurant \" . \" new \" AND \" york restaurant \" . \" new \" AND \" york \" AND \" restaurant \" .", "label": "", "metadata": {}, "score": "89.75815"}
{"text": "Network interface 1648 encompasses wired and/or wireless communication networks such as local - area networks ( LAN ) and wide - area networks ( WAN ) .LAN technologies include Fiber Distributed Data Interface ( FDDI ) , Copper Distributed Data Interface ( CDDI ) , Ethernet , Token Ring and the like .", "label": "", "metadata": {}, "score": "90.15257"}
{"text": "8(B ) is a continuation of the flow chart of FIG .8(A ) .DETAILED DESCRIPTION OF THE INVENTION .The present invention shall be described with respect to a Windows based operating system .As used herein , the term Windows should be understood as referring to the Windows family of operating systems available from Microsoft Corporation .", "label": "", "metadata": {}, "score": "90.93794"}
{"text": "The error deleting 440 section shows how error handling is performed for an error.enroll.deletephrase event .FIG .5 is a sample portion of VoiceXML code 500 that demonstrates a use of the updatevoicephrase element 510 .The code 500 defines attributes 520 for element 510 .", "label": "", "metadata": {}, "score": "92.33136"}
{"text": "[0065 ] .The dynamic search client system 700 includes a user interface 710 .The user interface 710 can be a text - based interface , a graphical user interface , a command line interface , or any other suitable interface , specifically including any of the interfaces previously discussed in conjunction with other figures .", "label": "", "metadata": {}, "score": "92.702835"}
{"text": "As the user enters each portion of the query , the user interface 510 can send each portion to the query suggestion module 520 .The query suggestion module 520 accesses information from the feedback data store 550 that is provided by the user feedback module 540 and , using that information , selects an appropriate suggestion from the query data store 530 .", "label": "", "metadata": {}, "score": "93.43292"}
{"text": "The error maxattempts 342 section shows how error handling is performed for an error.enroll.maxattempts event .FIG .4 is a sample portion of VoiceXML code 400 that demonstrates a use of the deletevoicephrase element 410 .The code 400 defines attributes 420 for element 410 .", "label": "", "metadata": {}, "score": "93.57856"}
{"text": "This method may be extended by adding other such boundary points within the query , based on annotations in the original Boolean query of words .For example , if the user typed explicit quotes in the query : . \" New York \" fast food .", "label": "", "metadata": {}, "score": "95.00985"}
{"text": "In the above example , voice enrollment can be used to add an acoustically provided phrase of [ Bob Smith ] to a personal grammar .It should be noted that the acoustically provided phrase is used not only to enroll [ Bob Smith ] but is recorded and presented back to the user in other interactions .", "label": "", "metadata": {}, "score": "95.41586"}
{"text": "It is to be appreciated that the disclosed components and methods can be implemented with various operating systems or combinations of operating systems .[ 0107 ] .A user enters commands or information into the computer 1612 through input device(s ) 1636 .", "label": "", "metadata": {}, "score": "95.45465"}
{"text": "The second case described above is where anchor phrase A does not appear in URL 1 .Here , this shows that the URL 1 does not contain the anchor phrase \" Australian Shepard \" , but does contain the related phrases \" blue merle \" , \" red merle \" , and \" tricolor \" .", "label": "", "metadata": {}, "score": "96.45414"}
{"text": "The related phrases of these query phrases as : . \" blue merle \" : : \" Australian Shepherd , \" \" red merle , \" \" tricolor , \" \" aussie \" ; . \" agility training \" : : \" weave poles , \" \" teeter , \" \" tunnel , \" \" obstacle , \" \" border collie \" .", "label": "", "metadata": {}, "score": "98.87881"}
{"text": "For example the query \" cheap bolt action rifle \" has two phrases \" cheap \" and \" bolt action rifle \" .In this case , the search system 120 does the regular intersection of the posting lists of Q 1 and Q 2 to obtain the documents for scoring .", "label": "", "metadata": {}, "score": "99.718544"}
{"text": "Such a selection by the user can be employed to cause the query suggestion engine 520 to aggressively look for spelling corrections , grammatical suggestions , or for uses of entered phrases in other subject domains .For example , if the user enters \" Saturn , \" a first set of suggestions presented to the user can have a common theme of astronomy - related results .", "label": "", "metadata": {}, "score": "100.47547"}
{"text": "16 illustrates a disk storage 1624 .The disk storage 1624 includes , but is not limited to , devices like a magnetic disk drive , floppy disk drive , tape drive , Jaz drive , Zip drive , LS-100 drive , flash memory card , or memory stick .", "label": "", "metadata": {}, "score": "100.61229"}
{"text": "1 , the guide engine 130 can be implemented as a software module that can be stored on the disk storage 1624 .At runtime , the guide module 130 can be loaded into the volatile memory 1620 from where machine - interpretable code of the signal module 160 can be accessed by the processing unit 1614 and thereby placed into execution . [ 0106 ] .", "label": "", "metadata": {}, "score": "101.758286"}
{"text": "The following is an example of the buildup of the phrase map table for a simple HTML document : .The quick brown fox .The quick brown fox jumps over the lazy god .As the phrase identification server 250 scans through these words one at a time , the following occurs .", "label": "", "metadata": {}, "score": "101.86075"}
{"text": "The search system 120 would identify the following candidate phrases , \" Hillary Rodham Clinton Bill on , \" \" Hillary Rodham Clinton Bill , \" and \" Hillary Rodham Clinton \" .The first two are discarded , and the last one is kept as a valid query phrase .", "label": "", "metadata": {}, "score": "101.98962"}
{"text": "No return object 234 is associated with the deletevoicephrase 214 element , which can be an executable item that does not return anything .The deletevoicephrase 214 element can generate an event 244 of error.enroll.deletevoicephrase when a voice phrase deletion attempt was made using the deletevoicephrase 214 element and when the phrase was unable to be deleted .", "label": "", "metadata": {}, "score": "103.028625"}
{"text": "Of the five related phrases of \" Australian Shepard \" , only one , \" Aussie \" appears in URL 0 .Intuitively then , URL 0 is only weakly about Australian Shepherds .URL 1 , by comparison , not only has the phrase \" Australian Shepherd \" present in the body of the document , but also has many of the related phrases present as well , \" blue merle , \" \" red merle , \" and \" tricolor . \"", "label": "", "metadata": {}, "score": "103.36238"}
{"text": "Interface port(s ) 1638 include , for example , a serial port , a parallel port , a game port , and a universal serial bus ( USB ) .Output device(s ) 1640 use some of the same type of ports as input device(s ) 1636 .", "label": "", "metadata": {}, "score": "103.92583"}
{"text": "FIG .16 describes software that acts as an intermediary between users and the basic computer resources described in the suitable operating environment 1600 .Such software includes an operating system 1628 .The operating system 1628 , which can be stored on the disk storage 1624 , acts to control and allocate resources of the computer system 1612 .", "label": "", "metadata": {}, "score": "106.94607"}
{"text": "For example , the phrase \" President of the United States \" is a phrase that predicts other phrases such as \" George Bush \" and \" Bill Clinton . \"However , other phrases are not predictive , such as \" fell down the stairs \" or \" top of the morning , \" \" out of the blue , \" since idioms and colloquisms like these tend to appear with many other different and unrelated phrases .", "label": "", "metadata": {}, "score": "110.98384"}
{"text": "\" New York \" AND \" Ethiopian restaurants \" .\" New York Ethiopian \" AND \" restaurants \" . \"New \" AND \" York \" AND \" Ethiopian restaurants \" . \"New \" AND \" York Ethiopian \" AND \" restaurants \" .", "label": "", "metadata": {}, "score": "114.28143"}
{"text": "[ 0108 ] .Output adapter 1642 is provided to illustrate that there are some output devices 1640 like monitors , speakers , and printers , among other output devices 1640 , which require special adapters .The output adapters 1642 include , by way of illustration and not limitation , video and sound cards that provide a means of connection between the output device 1640 and the system bus 1618 .", "label": "", "metadata": {}, "score": "115.01555"}
{"text": "[0109 ] .Computer 1612 can operate in a networked environment using logical connections to one or more remote computers , such as remote computer(s ) 1644 .For purposes of brevity , only a memory storage device 1646 is illustrated with remote computer(s ) 1644 .", "label": "", "metadata": {}, "score": "115.60829"}
{"text": "Volatile memory 1620 includes random access memory ( RAM ) , which acts as external cache memory .[ 0104 ] .Computer 1612 also includes removable / non - removable , volatile / non - volatile computer storage media .For example , .", "label": "", "metadata": {}, "score": "115.76508"}
{"text": "[ 0103 ] .The system memory 1616 includes volatile memory 1620 and nonvolatile memory 1622 .The basic input / output system ( BIOS ) , containing the basic routines to transfer information between elements within the computer 1612 , such as during start - up , is stored in nonvolatile memory 1622 .", "label": "", "metadata": {}, "score": "123.2152"}
{"text": "[ 0110 ] .Communication connection(s ) 1650 refers to the hardware / software employed to connect the network interface 1648 to the bus 1618 .While communication connection 1650 is shown for illustrative clarity inside computer 1612 , it can also be external to computer 1612 .", "label": "", "metadata": {}, "score": "126.0737"}
