{"text": "4 is an example parse tree according to the present invention ; .FIG .5 is another example parse tree according to the present invention ; .FIG .6 is another example parse tree according to the present invention ; and .", "label": "", "metadata": {}, "score": "61.31462"}
{"text": "Memory usage expands roughly with the square of the sentence length .You may wish to set a -maxLength and to skip long sentences .The factored parser requires several times as much memory as just running the PCFG parser , since it runs 3 parsers .", "label": "", "metadata": {}, "score": "61.66406"}
{"text": "1 is a block diagram of the sentence lexer according to the present invention ; .FIG .2 is a block diagram of the parser according to the present invention ; .FIG .3 is a diagram showing two complete parse trees produced according to the present invention ; .", "label": "", "metadata": {}, "score": "62.30354"}
{"text": "These trees are implemented via a variety of techniques , which are generally equivalent to doubly - linked lists .Doubly - linked lists must be created with head and tail nodes , which terminate the list and are designed to keep traversals of the list in bounds .", "label": "", "metadata": {}, "score": "62.318096"}
{"text": "Four of the parsers assume input that has already been word segmented , while the fifth does word segmentation internal to the parser .This is discussed further below .The parser also comes with 3 Chinese example sentences , in files whose names all begin with chinese .", "label": "", "metadata": {}, "score": "62.891975"}
{"text": "This can be integrated with ModelFetcher ( if the model is already installed , download_and_install_model is a no - op ) : .You can also load parser and reranker models manually : .Parsing a single sentence and reading information about the top parse with parse ( ) .", "label": "", "metadata": {}, "score": "64.01041"}
{"text": "Parse tree converter 240 receives the output of the parser 230 , and converts the parse trees into predicates .Following the Parse tree converter , parser filters 250 operate or the predicates to remove erroneously generated predicates based on rules about the probability of syntactic analyses , as well as rules about the compatibility of concepts with each other .", "label": "", "metadata": {}, "score": "65.37095"}
{"text": "In other cases , syntactic ambiguity will result in multiple possible parses .The parser should not generate any output trees for a sentence that does not reduce according to the rules ; rather it should generate a tree for every possible parse of an ambiguous sentence .", "label": "", "metadata": {}, "score": "65.89927"}
{"text": "has a complicated analysis , and can not afford semantic status to each word relative to all the other words within the dictionary .The Kucera et al . system uses three parsing stages , each of which needs more than one pass through the sentence to complete its analysis .", "label": "", "metadata": {}, "score": "66.11502"}
{"text": "Around 2009 , we parsed large volumes of text at a rate of about 1,000,000 sentences a day by distributing the work over 6 dual core / dual processor machines .Sure ! !These instructions concentrate on parsing from the command line , since you need to use that to be able to set most options .", "label": "", "metadata": {}, "score": "66.707825"}
{"text": "[ graphical display of the parse appears ] An ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}, "score": "66.83755"}
{"text": "Consequently , a parser that handles both of these conditions is needed .The parser 230 must pursue all possible parse trees , in effect branching and pursuing more than one path at every ambiguity .The standard LALR parser is a finite state machine designed to build a parse tree from the set of grammar rules ( called productions ) one input symbol at a time .", "label": "", "metadata": {}, "score": "66.93236"}
{"text": "claim 38 , further comprising the step of representing said parse trees by modified hexadecimal numbers that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "67.19577"}
{"text": "Parsing file : chinese-onesent-unseg.txt with 1 sentences .Parsing [ sent .1 len .falling back to PCFG parse .Parsed 5 words in 1 sentences ( 6.08 wds / sec ; 1.22 sents / sec ) .1 sentences were parsed by fallback to PCFG .", "label": "", "metadata": {}, "score": "68.41142"}
{"text": "The ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}, "score": "68.62237"}
{"text": "No .4,887,212 to Zamora et al . discloses a parser for syntactic analysis of text using a fast and compact technique .After part - of - speech tagging and disambiguation , syntactic analysis occurs in four steps .The grammar of Zamora et al . operates by making multiple passes to guess at noun phrases and verb phrases and then attempts to reconcile the results .", "label": "", "metadata": {}, "score": "68.84216"}
{"text": "hippietrail Sep 14 ' 11 at 10:45 .@johanbev : This is seriously misrepresenting the number of parse trees .There are n't a thousand parse tree for a seven word sentence .I would at best agree that there are \" dozens \" of parsings of many ADVERB / ADJECTIVE phrase sentences , but these are all different in where they bind the phrases .", "label": "", "metadata": {}, "score": "69.04402"}
{"text": "Below are some statistics for 32-bit operation with the supplied englishPCFG and englishFactoredGrammars .We have parsed sentences as long as 234 words , but you need lots of RAM and patience .You can use the -outputFormat wordsAndTags option .", "label": "", "metadata": {}, "score": "69.97008"}
{"text": "7 is another example parse tree incorporating real words according to the present invention .DETAILED DESCRIPTION OF THE INVENTION .In the following detailed discussion of the present invention , numerous terms , specific to the subject matter of a system and method for concept - based searching , are used .", "label": "", "metadata": {}, "score": "70.332634"}
{"text": "The procedure is similar to ( Chiang , 2007 ) except that we maintain tree structures on the target side , instead of strings .We use a statistical CFG parser to parse the English side of the training data , and extract dependency trees with Magerman 's rules ( 1995 ) .", "label": "", "metadata": {}, "score": "70.56811"}
{"text": "This is identical to the sentence produced above , and results in the same parse tree , and the same predicate structure .Thus , when the ontological parser in this example embodiment receives this question , it generates a predicate identical to that from a declarative sentence , and they can be matched .", "label": "", "metadata": {}, "score": "70.59723"}
{"text": "We use our theory to introduce a linear algorithm that can be used to derive from word - aligned , parallel corpora the minimal set of syntactically motivated transformation rules that explain human translation data . ...English sentences with a state - of - the - art statistical parser ( Collins , 1999 ) .", "label": "", "metadata": {}, "score": "70.62416"}
{"text": "1 len .2 len .Parsed 14 words in 2 sentences ( 6.55 wds / sec ; 0.94 sents / sec ) .Parsing file : chinese - onesent with 1 sentences .Parsing [ sent .1 len .Parsed 10 words in 1 sentences ( 10.78 wds / sec ; 1.08 sents / sec ) .", "label": "", "metadata": {}, "score": "71.04967"}
{"text": "Despite such an improvement over a decimal representation , the branching factor of only 16 is still unacceptably small .A solution to this is to use a modified hexadecimal representation .Since it is unlikely that a reasonable , specialized ontology will need more than eight levels of general concept representation , a 16-digit hexadecimal number can be interpreted slightly differently , as an octet of hexadecimal pairs : .", "label": "", "metadata": {}, "score": "71.59454"}
{"text": "Given this grammar , an LALR parser generator would fail to produce a parser because of a shift / reduce conflict .The modified LALR parser generator algorithm that the ontological parser of the present invention uses must be aware of the possibility of more than one possible course of action , and should recursively try both actions .", "label": "", "metadata": {}, "score": "71.65783"}
{"text": "Consequently , ten is too small to constrain the branching factor for each level .The use of a hexadecimal representation would improve this some by increasing the branching factor to 16 .Thus , using a 16-digit ( i.e. , a 64-bit ) hexadecimal number gives 16 branches at each node for 16 levels : 16 16 possible concepts .", "label": "", "metadata": {}, "score": "71.80148"}
{"text": "This structure guarantees that an arbitrary number of nodes may be inserted into the list without losing track of the locations of existing nodes , as well as enabling the list to be searched from either the top or bottom .However , the great flexibility of tree data structures , which may encompass trees of arbitrary depth , also imposes a significant cost in computability .", "label": "", "metadata": {}, "score": "72.07742"}
{"text": "The sentence receiver is a software abstraction that may be realized through any number of techniques .The parser 230 takes a sequence of instances from an ontology , in the form of a sentence , and converts them into a collection of parse trees .", "label": "", "metadata": {}, "score": "72.278946"}
{"text": "For example , another possible encoding of the ontology tree might involve a 40-digit decimal number .In such a case , 4 digits could be assigned to each node of the tree , implying that the tree could have up to 10 levels of depth .", "label": "", "metadata": {}, "score": "72.80272"}
{"text": "It first runs a ( simpler ) PCFG parser and then an untyped dependency parser , and then runs a third parser which finds the parse with the best joint score across the two other parsers via a product model .This is described in the NIPS Fast Exact Inference paper .", "label": "", "metadata": {}, "score": "73.04429"}
{"text": "The system and method of the present invention isolates predicate - argument relationships into a consistent format regardless of text types .The predicate - argument relationships can be used in search , grammar - checking , summarization , and categorization applications , among others .", "label": "", "metadata": {}, "score": "73.098724"}
{"text": "HPSG and statistical models are not the same thing .To my knowledge , most syntactic frameworks fall into the latter category , but I ca n't think of any which fall into the former .- Alan H. Sep 13 ' 11 at 23:15 .", "label": "", "metadata": {}, "score": "73.15558"}
{"text": "No .5,386,406 to Hedin et al . discloses a system for converting natural - language expressions into a language - independent conceptual schema .The output of the Hedin et al . system is not suitable for use in a wide variety of applications ( e.g. machine translation , document summarization , categorization ) .", "label": "", "metadata": {}, "score": "73.48884"}
{"text": "People are often confused about how to get from that example to parsing paragraphs of text .You need to split the text into sentences first and then to pass each sentence to the parser .To do that , we use the included class DocumentPreprocessor .", "label": "", "metadata": {}, "score": "73.53783"}
{"text": "There is a call , setConstraints , which you can make before using the LexicalizedParserQuery to run the parser .If you add a ParserConstraint object spanning a set of words , the parser will only produce parse trees which include that span of words as a constituent .", "label": "", "metadata": {}, "score": "73.9657"}
{"text": "Additionally , semantic feature compatibility checking is not possible with Jensen 's system .U.S. Pat .No .5,721,938 to Stuckey discloses a parsing technique , which organizes natural language into symbolic complexes , which treat all words as either nouns or verbs .", "label": "", "metadata": {}, "score": "74.669846"}
{"text": "- Ron Maimon Mar 13 ' 12 at 4:10 .X ' structures are used in LFG , too .The performance is excellent with modern algorithms until constraints are evaluated .Ron Kaplan wrote a few papers on the combination of CF parsing with constraints .", "label": "", "metadata": {}, "score": "74.71865"}
{"text": "Using only few basic text features , we show similar performance ( in F1 score ) to existing pure discriminative parsers and existing \" benchmark \" parsers ( like Collins parser , probabilistic context - free grammars based ) , with a huge speed advantage .", "label": "", "metadata": {}, "score": "74.72827"}
{"text": "You can use it as follows : .There are several options , including one for batch - processing lots of files ; see the Javadoc documentation of the main method of PTBTokenizer .Parsing speed depends strongly on the distribution of sentence lengths - and on your machine , etc .", "label": "", "metadata": {}, "score": "74.7288"}
{"text": "A 10-digit decimal number allows 10 10 , or 10 billion possible concepts to be stored in the tree .That is a sufficient number of total concepts , but the branching factor is too small .There can be a maximum of ten possible branches out of each node to the next level .", "label": "", "metadata": {}, "score": "75.025986"}
{"text": "The previous techniques of natural language processing are often limited to the performance of a particular purpose and can not be used for other purposes .Conventional parsing techniques may be designed to function as part of a grammar checking system , but can not function as part of a search engine , summarization application , or categorization application .", "label": "", "metadata": {}, "score": "75.04374"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 20 , wherein said parser filters remove parse trees that violate one of statistical and ontological criteria for well - formedness .", "label": "", "metadata": {}, "score": "75.15762"}
{"text": "The second method is to perform research from the ground up in defining an ontology , assigning elements on an as - needed basis .Since minimal representation size is a main goal of parameterizing the ontology , one would want to eliminate many of the redundancies found in general - purpose ontologies such as WordNet .", "label": "", "metadata": {}, "score": "75.176605"}
{"text": "This distinction may have some psychological validity , but it is not computationally attractive to maintain this distinction in separate array elements .A compromise approach is to attempt to make judgments about redundancy , and write software to merge branches as specified by the judgments of a knowledge engineer .", "label": "", "metadata": {}, "score": "75.34918"}
{"text": "You will need a collection of syntactically annotated data such as the Penn Treebank to train the parser .If they are not in the same format as currently supported Treebanks , you may need to write classes to read in the trees , etc .", "label": "", "metadata": {}, "score": "75.401855"}
{"text": "Since algorithm design and implementation are distinct and separable issues , an embodiment of a parameterized ontology 's data structures has not yet been discussed .The following is a suggested implementation .The proposed data structure includes an integer value , where each digit of the integer corresponds to a specific branch taken at the corresponding level in the tree .", "label": "", "metadata": {}, "score": "75.51754"}
{"text": "We investigate unsupervised techniques for acquiring monolingual sentence - level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web - based news sources .Two techniques are employed : ( 1 ) simple string edit distance , and ( 2 ) a heuristic strategy ... \" .", "label": "", "metadata": {}, "score": "75.52341"}
{"text": "It does not attempt to determine grammaticality , though it will normally prefer a \" grammatical \" parse for a sentence if one exists .This is appropriate in many circumstances , such as when wanting to interpret user input , or dealing with conversational speech , web pages , non - native speakers , etc . .", "label": "", "metadata": {}, "score": "75.66763"}
{"text": "Tokuume et al . , U.S. Pat .No .5,101,349 , discloses a natural language processing system that makes provisions for validating grammar from the standpoint of syntactic well - formedness , but does not provide facilities for validating the semantic well - formedness of feature structures .", "label": "", "metadata": {}, "score": "75.81592"}
{"text": "If your file is extremely large , splitting it into multiple files and parsing them sequentially will reduce memory usage .A 64-bit application requires more memory than a 32-bit application ( Java uses lots of pointers ) .", "label": "", "metadata": {}, "score": "75.855934"}
{"text": "The conversion code generally expects Penn Treebank style trees which have been stripped of functional tags and empty elements .This generally corresponds to the output of the Stanford , Charniak or Collins / Bikel parsers .The exception is that it gets value from the -TMP annotation on bare temporal NPs in order to recognize them as having temporal function ( tmod ) .", "label": "", "metadata": {}, "score": "75.88516"}
{"text": "2 In what follows we compare two strategies for unsupervised construction of such a corpus , one employing string similarity and the other associating sentences that may overlap very little at the s .. \" ...We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .", "label": "", "metadata": {}, "score": "75.9047"}
{"text": "3 Answers 3 .The simplest answer is that high performance NLP applications do not use X - bar theory as an explicit representation .A major factor in this is that parsing is most commonly evaluated against the Penn Treebank or various dependency annotated corpora , neither of which would be considered X - bar structures .", "label": "", "metadata": {}, "score": "76.005455"}
{"text": "The parser is a tool for analyzing syntactic relationships between entities .Referring to .FIG .1 , the sentence lexer 100 is shown .Document iterator 120 receives documents or text input 110 , and outputs individual sentences to the lexer 130 .", "label": "", "metadata": {}, "score": "76.02051"}
{"text": "We describe an efficient decoder and show that using these treebased models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser . \" ...Previous work has used monolingual parallel corpora to extract and generate paraphrases .", "label": "", "metadata": {}, "score": "76.10321"}
{"text": "However , stochastical models are used to try to guess the most probable one .I 'm not sure if this task is more difficult for transformation based grammars , but I woudn't be surprised if it was .- johanbev Sep 14 ' 11 at 10:40 .", "label": "", "metadata": {}, "score": "76.1161"}
{"text": "Training the RNN parser is a two step process .First , because the RNN parser uses the parsings of a simpler PCFG parser to train , it is useful to precache the results of that parser before training the RNN parser .", "label": "", "metadata": {}, "score": "76.42314"}
{"text": "Our expe ... \" .In this paper , we propose a novel string - todependency algorithm for statistical machine translation .With this new framework , we employ a target dependency language model during decoding to exploit long distance word relations , which are unavailable with a traditional n - gram language model .", "label": "", "metadata": {}, "score": "76.44176"}
{"text": "Such a representation scheme gives each node in the tree a unique identifier that completely determines the relative place of that node in the tree structure .It also provides a simple way to compare relative positions of two discovered node instances .", "label": "", "metadata": {}, "score": "76.44816"}
{"text": "Note that it does not come with any parsing models but includes a downloader .The primary maintenance for the parser takes place at GitHub .Fetching parsing models .Before you can parse , you 'll need some parsing models .", "label": "", "metadata": {}, "score": "76.539734"}
{"text": "The following is an example of a sentence and demonstrates both how it is parsed as a sentence within a document , and how a question to an information retrieval system would produce matching predicates to retrieve the document containing this sentence .", "label": "", "metadata": {}, "score": "76.59"}
{"text": "If you want to obtain the same results , you can either POS - tag your corpus before tagging it ( see # 12 ) or you can disable the POS tagger in CoreNLP by updating the list of annotators : .", "label": "", "metadata": {}, "score": "76.83928"}
{"text": "The k best parses are extracted efficiently using the algorithm of Huang and Chiang ( 2005 ) .This may be because the parser chose an incorrect structure for your sentence , or because the phrase structure annotation conventions used for training the parser do n't match your expectations .", "label": "", "metadata": {}, "score": "76.85806"}
{"text": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word - to - word alignments from an MT system , and syntactic structure from parse - trees of source and target language sentences .", "label": "", "metadata": {}, "score": "76.86505"}
{"text": "Two techniques are employed : ( 1 ) simple string edit distance , and ( 2 ) a heuristic strategy that pairs initial ( presumably summary ) sentences from different news stories in the same cluster .We evaluate both datasets using a word alignment algorithm and a metric borrowed from machine translation .", "label": "", "metadata": {}, "score": "77.001205"}
{"text": "All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .The present system imposes a logical structure on text , and a semantic representation is the form used for storage .", "label": "", "metadata": {}, "score": "77.03291"}
{"text": "Since the parser is both probabilistic and operating on multiple streams of possible ontological entities , it is necessary to prune out spurious parse trees generated by the parser 230 .Parser filters 250 are designed to prune out spurious parse trees generated by the parser 230 , by removing trees that violate either statistical or ontological criteria for well - formed - ness .", "label": "", "metadata": {}, "score": "77.473015"}
{"text": "4 .Each arrowhead in .FIG .4 represents a concept node .The deeper into the tree ( i.e. , the higher the numbered level of the concept node ) , the more specific the concept is .Consider one path through FIG .", "label": "", "metadata": {}, "score": "77.606415"}
{"text": "Basic usage .The easiest way to construct a parser is with the load_unified_model_dir class method .A unified model is a directory that contains two subdirectories : parser/ and reranker/ , each with the respective model files : .Parsing a single sentence and reading information about the top parse with parse ( ) .", "label": "", "metadata": {}, "score": "77.63423"}
{"text": "Using alignment techniques from phrasebased statistical machine translation , we show how paraphrases ... \" .Previous work has used monolingual parallel corpora to extract and generate paraphrases .We show that this task can be done using bilingual parallel corpora , a much more commonly available resource .", "label": "", "metadata": {}, "score": "77.676636"}
{"text": "Similar features will have similar paths through the tree .Referring to .FIG .5 , an example is illustrated .Node A is represented with the decimal number \" 1212 . \"Node B is represented with the decimal number \" 1220 .", "label": "", "metadata": {}, "score": "77.746"}
{"text": "Enter your e - mail into the ' Cc ' field , and we will keep you updated with your request 's status .Description .We propose a new fast purely discriminative algorithm for natural language parsing , based on a \" deep \" recurrent convolutional graph transformer network ( GTN ) .", "label": "", "metadata": {}, "score": "77.887344"}
{"text": "The design of the ontology - based parser is based on the premise that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .", "label": "", "metadata": {}, "score": "77.93859"}
{"text": "However , the intended output of the parser is the set of predicate structures that it builds for each sentence , and so the preferred parse tree receiver is a software module called a parse tree converter , which extracts predicate structures from the parse trees .", "label": "", "metadata": {}, "score": "77.95318"}
{"text": "If POS - tagging sentences prior to parsing is an option , that speeds things up ( less possibilities to search ) .The main tool remaining is to run multiple parsers at once in parallel .If you have a machine with enough memory and multiple cores , you can very usefully run several parsing threads at once .", "label": "", "metadata": {}, "score": "78.06865"}
{"text": "Use Ctrl+Left / Right to switch messages , Ctrl+Up / Down to switch threads , Ctrl+Shift+Left / Right to switch pages .Tools . by Hieu Hoang , Alexandra Birch , Chris Callison - burch , Richard Zens , Marcello Federico , Nicola Bertoldi , Chris Dyer , Brooke Cowan , Wade Shen , Christine Moran , Ond\u0159ej Bojar , Alexandra Constantin , Evan Herbst , 2007 . \" ...", "label": "", "metadata": {}, "score": "78.10581"}
{"text": "We show for the first time that incorporating the predictions of a word sense disambigua - tion system within a typical phrase - based statistical machine translation ( SMT ) model consistently improves translation quality across all three different IWSLT Chinese - English test sets , as well as producing st ... \" .", "label": "", "metadata": {}, "score": "78.30999"}
{"text": "In the predicate representation scheme of the present invention , there are only a few distinct frames for predicate structures , as many as needed to cover the different numbers of arguments taken by different verbs .Predicates may be enhanced with selectional restriction information , which can be coded automatically for entire semantic classes of words , rather than on an individual basis , because of the ontological scheme .", "label": "", "metadata": {}, "score": "78.37871"}
{"text": "The path starts at the root node ( Level 1 ) and takes the 2nd branch to level 2 , then takes the 3rd branch from that node to get to level 3 .The final \" 0 \" is a terminator , indicating that this particular node of the tree is not at the lowest possible level of the tree ; it does not necessarily indicate that no nodes branch from this level .", "label": "", "metadata": {}, "score": "78.383865"}
{"text": "For instance : .Parsing file : chinese - onesent with 1 sentences .Parsing [ sent .1 len .Parsed 10 words in 1 sentences ( 7.10 wds / sec ; 0.71 sents / sec ) .There are many kinds of ' vanilla ' , but , providing your treebank is in Penn Treebank format , then , yes , this is easy to do .", "label": "", "metadata": {}, "score": "78.66875"}
{"text": "Often numerous passes through the input sentence(s ) are required to fully parse the input , thereby adding to the time required to parse the input .Often the previous techniques do not have very robust feature checking capabilities .In particular , the techniques do not check for both syntactic and semantic compatibility .", "label": "", "metadata": {}, "score": "78.84888"}
{"text": "The ontology - based parser is designed around the idea that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .", "label": "", "metadata": {}, "score": "78.91611"}
{"text": "The LALR parser is widely used and is better known as the approach used by parser generators such as yacc and bison .While the description is a preferred embodiment , it will be understood that any implementation of a context - free grammar within a similar architecture , including such variants as an LALR-2 parser ( which looks ahead by two words ) , are within the scope of the present invention .", "label": "", "metadata": {}, "score": "78.91705"}
{"text": "If you call the parser programmatically and then convert the parse tree to a list of grammatical relations , you have to call setGenerateOriginalDependencies(true ) on your instance of TreebankLanguagePack as shown in the following snippet : .Alternatively , if you use SemanticGraphFactory.makeFromTree ( ) to build a SemanticGraph from a constitueny tree , then use the following method with originalDependencies set to true .", "label": "", "metadata": {}, "score": "79.11009"}
{"text": "This limits the versatility of the techniques .U.S. Pat .No .4,864,502 to Kucera et al . discloses a device that tags and parses natural - language sentences , and provides interactive facilities for grammar correction by an end user .", "label": "", "metadata": {}, "score": "79.11429"}
{"text": "Similarly , for information retrieval purposes , an embodiment of the ontological parser optimized for queries may make use of all these filters , but add a pseudo - predicate filter and a pseudo - concept filter .The stop word filter removes stop words from sentences .", "label": "", "metadata": {}, "score": "79.128265"}
{"text": "No .5,146,496 to Jensen discloses a technique for identifying predicate - argument relationships in natural language text .The Jensen system must create intermediate feature structures to store semantic roles , which are then used to fill in predicates whose deep structures have missing arguments .", "label": "", "metadata": {}, "score": "79.2206"}
{"text": "It would certainly be possible to compute these dynamically , since any tree - search algorithm must keep track of which branches it traverses in trying to locate a particular node .However , as the search backtracks and corrects its path a fair number of adjustments and recalculations of the current node value would likely result .", "label": "", "metadata": {}, "score": "79.345695"}
{"text": "The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}, "score": "79.349075"}
{"text": "The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}, "score": "79.349075"}
{"text": "This HeadFinder will give consistent left - branching binarization .If you would like to also get out the true probabilities that a vanilla PCFG parser would produce , there are a couple more options that you need to set : . -smoothTagsThresh", "label": "", "metadata": {}, "score": "79.3705"}
{"text": "The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .Ontological parsing is a grammatical analysis technique built on the proposition that the most useful information that can be extracted from a sentence is the set of concepts within it , as well as their formal relations to each other .", "label": "", "metadata": {}, "score": "79.43458"}
{"text": "When the model is finished training , or when you want to test one of the intermediate models , you can run it using the standard LexicalizedParser commands .In our experiments , we found that simpler PCFG models actually make better underlying PCFG models .", "label": "", "metadata": {}, "score": "79.60208"}
{"text": "In general , though , you should not use this part of the feature and simply use \" .Yes , for the PCFG parser ( only ) .With a PCFG parser , you can give the option -printPCFGkBest n and it will print the n highest - scoring parses for a sentence .", "label": "", "metadata": {}, "score": "79.606766"}
{"text": "On test data extracted by the heuristic strategy , however , performance of the two training sets is similar , with AERs of 13.2 % and 14.7 % respectively .Analysis of 100 pairs of sentences from each set reveals that the edit distance data lacks many of the complex lexical and syntactic alternations that characterize monolingual paraphrase .", "label": "", "metadata": {}, "score": "79.62341"}
{"text": "The configuration of the parser 200 is shown in FIG .2 .First , the sentence receiver 220 obtains sentences 210 consisting of ontological entities produced by the sentence lexer 100 .These sentences are parsed by the parser 230 , which is designed to use a context - free grammar , although other grammatical models may be used without departing from the scope and spirit of the invention .", "label": "", "metadata": {}, "score": "79.687164"}
{"text": "As long as grammatical roles can be identified , the present system and method can be easily adapted to any language .For example , certain case - marked languages , such as Japanese or German , can be parsed through a grammar which simply records the grammatical relationships encoded by particular markers , and the resulting output is still compatible with the parsing results achieved for other languages .", "label": "", "metadata": {}, "score": "79.703354"}
{"text": "Would n't the ambiguities also being a factor , leading to either multiplying numbers of parse trees , or potentially choosing the wrong parse tree ? -hippietrail Sep 14 ' 11 at 10:37 .Ambiguity is a problem for all NLP systems .", "label": "", "metadata": {}, "score": "79.768776"}
{"text": "system checks only for syntactic correctness .U.S. Pat .No .4,914,590 to Loatman et al . discloses a natural language understanding system .The goal of the Loatman et al . system is to provide a formal representation of the context of a sentence , not merely the sentence itself .", "label": "", "metadata": {}, "score": "79.82492"}
{"text": "For English , the parser by default now produces Universal Dependencies , which are extensively documented on that page .You can also have it produce the prior Stanford Dependencies representation .For this , and for the Chinese dependencies , you can find links to documentation on the Stanford Dependencies page .", "label": "", "metadata": {}, "score": "80.21733"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a non - negative number indicates agreement .", "label": "", "metadata": {}, "score": "80.33679"}
{"text": "Those other concepts are the arguments of the predicate , and are generally nouns , because predicate relationships are usually between entities .As stated previously , the ontological parser has two major components , a sentence lexer 100 and a parser 200 .", "label": "", "metadata": {}, "score": "80.507935"}
{"text": "The parser is supplied with 5 Chinese grammars ( and , with access to suitable training data , you could train other versions ) .You can find them inside the supplied stanford - parser- YYYY - MM - DD -models.jar file ( in the GUI , select this file and then navigate inside it ; at the command line , use jar -tf to see its contents ) .", "label": "", "metadata": {}, "score": "80.519745"}
{"text": "Our results provide the first known empir - ical evidence that lexical semantics are in - deed useful for SMT , despite claims to the contrary . \" ...In this paper , we propose a novel string - todependency algorithm for statistical machine translation .", "label": "", "metadata": {}, "score": "80.87961"}
{"text": "You can give the options -outputFormat typedDependencies or -outputFormat typedDependenciesCollapsed to get typed dependencies ( or grammatical relations ) output ( for English and Chinese only , currently ) .You can print out lexicalized trees ( head words and tags at each phrasal node with the -outputFormatOptions lexicalize option .", "label": "", "metadata": {}, "score": "80.98241"}
{"text": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .This method requires a source - language dependency parser , target language word segmentation and an unsupervised word alignment component .", "label": "", "metadata": {}, "score": "81.11333"}
{"text": "Having described several embodiments of the concept - based indexing and search system in accordance with the present invention , it is believed that other modifications , variations and changes will be suggested to those skilled in the art in view of the description set forth above .", "label": "", "metadata": {}, "score": "81.17316"}
{"text": "First of all , we gather all of the sentence to form our little universe in the list .Then we parse all the sentences , first is to ensure they are in grammatical forms that fit to our set of rules by pattern matching of the sentences using regular expressions .", "label": "", "metadata": {}, "score": "81.20279"}
{"text": "The above data structure naturally lends itself to one particular algorithm for comparing the identity or subsumption of ontological features .The algorithm relies on the implementation of the tree by associating with each node in the tree an integer value that represents the position of that node within the hierarchical structure .", "label": "", "metadata": {}, "score": "81.316925"}
{"text": "claim 6 , wherein said parse trees is represented by modified hexadecimal digits that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format comprising the steps of : . converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and . converting said sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the natural language sentence and binds arguments into predicates .", "label": "", "metadata": {}, "score": "81.39015"}
{"text": "If the word exists within the ontology 140 , it is returned as an ontological entity ; if not , it is returned as a word tagged with default assumptions about its ontological status .In one embodiment , words are automatically assumed to be nouns ; however , the words may be other parts of speech .", "label": "", "metadata": {}, "score": "81.486916"}
{"text": "The decision - making process occurs at intermediate parsing stages , and parse probabilities are considered before all parse paths have been pursued .Intermediate parse probability calculations have to be stored , and the system has to check for intermediate feature clashes .", "label": "", "metadata": {}, "score": "81.52037"}
{"text": "\" It is worth noting that once the first digit difference is detected , there is no further need to compute remaining digits .They diverge at level 3 , the third digit in the representation , and thereafter lie along completely different sub - trees that do not intersect .", "label": "", "metadata": {}, "score": "81.58243"}
{"text": "The system of the present invention maintains arguments as variables during the parsing process , and automatically fills in long - distance dependencies as part of the parsing process .No post - parsing analysis is needed to obtain this benefit , and the parsing time is not impacted by the maintenance of these variables , thus resulting in faster parsing execution .", "label": "", "metadata": {}, "score": "81.711975"}
{"text": "In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .The output predicate structures contain numeric tags that represent the location of each concept within the ontology .", "label": "", "metadata": {}, "score": "81.83888"}
{"text": "In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .The output predicate structures contain numeric tags that represent the location of each concept within the ontology .", "label": "", "metadata": {}, "score": "81.83888"}
{"text": "And its pattern .( \\w+ , ) + ( \\w+ ) ( , ) ?The design requirement of a reasonable logical sentence parser should at least draw a subset of the grammatical logical structure of a discipline of the English grammar .", "label": "", "metadata": {}, "score": "81.91558"}
{"text": "The parser of the Stuckey system is only suitable for grammar - checking applications .U.S. Pat .No .5,960,384 to Brash discloses a parsing method and apparatus for symbolic expressions of thought such as English - language sentences .The parser of the Brash system assumes a strict compositional semantics , where a sentence 's interpretation is the sum of the lexical meanings of nearby constituents .", "label": "", "metadata": {}, "score": "82.003075"}
{"text": "Programmatically , you can do the same things by creating a TokenizerFactory with the appropriate options , such as : .getWordsFromString(str ) ) ; .There is nevertheless a potential cost of making tokenization changes .This normalization was added in the first place because the parser is trained on American English , normalized according to Penn Treebank conventions .", "label": "", "metadata": {}, "score": "82.14151"}
{"text": "However , appropriate probabilities for each rule can only be determined by experimentation .In the initial version , probabilities will be assigned by linguistic intuition ; as iterations of the design progress , probabilities will be determined through experimentation .Since sentence probabilities are generally very small numbers , the parse probability filter should pass any parse tree with a probability of at least 30 % of the highest probability parse .", "label": "", "metadata": {}, "score": "82.14627"}
{"text": "Adverbs detail the meaning of the verbs they accompany , but do not change them .Since the meaning of the sentence remains the same , adverbs can be removed to simplify parsing .The pseudo - predicate filter operates in one embodiment , as a query ontological parser .", "label": "", "metadata": {}, "score": "82.23538"}
{"text": "At every cycle , a new character is read from the input stream and the character and current state are used to look up , in the action table , which action to perform .The actions are in one of the following forms : .", "label": "", "metadata": {}, "score": "82.26752"}
{"text": "These grammar rules , called productions , specify language that the target parser is supposed to recognize .Each production indicates that a specific combination of input symbols , called terminals , and assembled groups of terminals , called non - terminals , can be assembled into a new non - terminal .", "label": "", "metadata": {}, "score": "82.28148"}
{"text": "Genia ( biomedical English ) .Originally we used the treebank beta version reformatted by Andrew Clegg , his training split , but more recently ( 1.6.5 + ? ) we 've used the official Treebank , and David McClosky 's splits .", "label": "", "metadata": {}, "score": "82.34282"}
{"text": "We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models .Compared to the standard practice of intersecting predictions of independently - trained models , joint training provides a 32 % reduction in AER .", "label": "", "metadata": {}, "score": "82.367676"}
{"text": "Yes , you can .However , for good results , you should make sure that you provide correctly tokenized input and use exactly the correct tag names .( That is , the input must be tokenized and normalized exactly as the material in the treebank underlying the grammar is . )", "label": "", "metadata": {}, "score": "82.40407"}
{"text": "And we need to keep a dictionary of action words ( or verbs ) in all the tenses .In the real world PC implementation we should have the complete dictionary as reference .So we like to define the following ( most simple ) : .", "label": "", "metadata": {}, "score": "82.424095"}
{"text": "Getting information about the top parse : .ptb_parse ( S1 ( S ( NP ( DT This ) ) ( VP ( VBZ is ) ( NP ( DT a ) ( NN sentence ) ) ) ( .If you have an existing tokenizer , tokenization can also be specified by passing a list of strings : .", "label": "", "metadata": {}, "score": "82.49613"}
{"text": "Getting information about the top parse : .ptb_parse ( S1 ( S ( NP ( DT This ) ) ( VP ( VBZ is ) ( NP ( DT a ) ( NN sentence ) ) ) ( .If you have an existing tokenizer , tokenization can also be specified by passing a list of strings : .", "label": "", "metadata": {}, "score": "82.49613"}
{"text": "The supplied file makeSerialized.csh shows exactly what options we used to train the parsers that are included in the distribution .If you want to train the parser on a new language and/or treebank format , you can ( and people have done so ) , but you need to spend a while learning about the code , especially if you wish to develop language - specific features .", "label": "", "metadata": {}, "score": "82.55305"}
{"text": "The pseudo - concept filter operates in one embodiment , a query ontological parser .It removes concepts from queries , which are not likely to be the actual concept the user intends .Pseudo - concepts are largely nouns , and can be captured by a stop word list .", "label": "", "metadata": {}, "score": "82.589035"}
{"text": "SUMMARY OF THE INVENTION .The foregoing and other deficiencies are addressed by the present invention , which is directed to an ontology - based parser for natural language processing .More particularly , the present invention relates to a system that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}, "score": "82.59878"}
{"text": "The parse probability filter vetoes parse trees that fall below a minimum probability for valid semantic interpretation .The parse probability filter will calculate the probability of a sentence parse by taking the product of the probabilities of the syntactic rules used to generate a given parse tree .", "label": "", "metadata": {}, "score": "82.60585"}
{"text": "The ontological parser is designed to be modular , so that improvements and language - specific changes can be made to individual components without reengineering the other components .The components are discussed in detail below .The ontological parser has two major functional elements , a sentence lexer and a parser .", "label": "", "metadata": {}, "score": "82.637184"}
{"text": "A key to intelligent design is leaving room for expansion .As long as the maximum depth of trees is not reached , adding additional levels is transparent .The trade - off in a parameterized ontology is selecting the size of a data structure so that it is no larger than it needs to be , but with adequate room for correcting mistakes or expanding coverage later on .", "label": "", "metadata": {}, "score": "82.767456"}
{"text": "The scripting language gave developers a mechanism for specifying rules related to the underlying frame - based representation in a large - scale spoken - language recognition and generation system .Since the completion of the project , developers have used the scripting language for tasks such as spoken language translation and foreign language learning .", "label": "", "metadata": {}, "score": "82.838715"}
{"text": "See the parser.lexparser package documentation , the LexicalizedParser.main method documentation , the TreePrint class , and the documentation of variables in the Train , Test , and Options classes , and appropriate language - particular TreebankLangParserParams .For the rest , you need to look at the source code .", "label": "", "metadata": {}, "score": "82.83972"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 39 , wherein a most significant digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .", "label": "", "metadata": {}, "score": "82.93383"}
{"text": "For best results , we recommend that you first segment input text with a high quality word segmentation system which provides word segmentation according to Penn Chinese Treebank conventions ( note that there are many different conventions for Chinese word segmentation ... ) .", "label": "", "metadata": {}, "score": "83.15233"}
{"text": "You pass to the parse method a List .If the items in this list implement HasTag , such as being of type TaggedWord or CoreLabel , and the tag value is not null , then the parser will use the tags that you provide .", "label": "", "metadata": {}, "score": "83.18219"}
{"text": "FIG .3 , for the input string ' ab . 'An example of a context - free grammar that would be used in implementing the parser is as follows : .The modified LALR parser generator , grammar , and modified LALR parsing engine discussed previously should generate a non - deterministic recursive parser .", "label": "", "metadata": {}, "score": "83.44821"}
{"text": "Instead , they must traverse the list of links and compare structures on a node - by - node basis to guarantee identity .Complicating this procedure is the fact that concepts may be cross - linked across multiple branches of a tree , sharing multiple structures .", "label": "", "metadata": {}, "score": "83.5117"}
{"text": "This representation also provides optimized execution of the difference comparison , since using hexadecimals instead of decimals optimizes the logical digit - by - digit comparison to a computer - efficient byte - by - byte comparison .It should also be noted that the above examples of decimal , hexadecimal , or multi - digit hexadecimal are typical parameter choices for the node encoding included in the present invention .", "label": "", "metadata": {}, "score": "83.58038"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 6 , wherein a first digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .", "label": "", "metadata": {}, "score": "83.66617"}
{"text": "For example , in a search engine application , it may be useful to check whether or not a particular noun can serve as an argument of a predicate .The features of the noun should be more specific than the features of the argument position it is attached to .", "label": "", "metadata": {}, "score": "83.84773"}
{"text": "In this sample embodiment , this predicate is then passed through the parser filters , where it successfully passes the parse probability and selectional feature compatibility tests .In the foregoing example , \" have \" is a verb unlikely to have any selectional restrictions on arguments .", "label": "", "metadata": {}, "score": "83.854774"}
{"text": "The Brash system makes no provisions for the possibility that immediate relationships are not in fact the correct expression of sentence - level concepts , because it assumes that syntactic constituency is always defined by immediate relationships .The Brash system does not incorporate ontologies as the basis for its lexical resource , and therefore does not permit the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}, "score": "83.8582"}
{"text": "The ontology - based parser contains functional components for receiving documents in a plurality of formats , tokenizing them into instances of concepts from an ontology , and assembling the resulting concepts into predicates .The ontological parser has two major functional elements , a sentence lexer and a parser .", "label": "", "metadata": {}, "score": "83.8917"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .", "label": "", "metadata": {}, "score": "84.01119"}
{"text": "Use this if all you want is a tokenizer : . [ ' Tokenize ' , ' this ' , ' sentence ' , ' , ' , ' please ' , ' . ' ] Slides .Related content .Report a problem or upload files .", "label": "", "metadata": {}, "score": "84.206215"}
{"text": "There is n't a separate included tagger ; the parser does POS tagging as part of parsing .Yes , you can .You can use the main method of EnglishGrammaticalStructure ( for English , or the corresponding class for Chinese ) .", "label": "", "metadata": {}, "score": "84.36696"}
{"text": "This frequently seems to confuse people , because the main predicate of the clause is now not a verb .But we believe that this is the best thing to do for several reasons : .Consistency of treatment of auxiliary / copula between English periphrastic verb forms and adjectival / nominal predications .", "label": "", "metadata": {}, "score": "84.501"}
{"text": "The noun must follow either immediately after the adjective , or have only adjective and conjunction words appearing between the noun and the adjective .If no such noun or conjunction is found , the adjective filter will veto the sentence .", "label": "", "metadata": {}, "score": "84.527756"}
{"text": "Thus , for example , the node to Node A 's immediate left , is represented by \" 1211 .\" When the difference comparison is made , it works out to be \" 0001 , \" which implies a correspondingly close ontological relationship between the two concepts .", "label": "", "metadata": {}, "score": "84.66423"}
{"text": "It has , however , been abandoned in recent versions of minimalism .- Alan H. Sep 13 ' 11 at 22:58 .@AlanH. : As far as I understand HPSG , it lacks the X ' node , X being a node rather than a leaf . -", "label": "", "metadata": {}, "score": "84.66655"}
{"text": "The default HeadFinder is written specifically for the PTB .If you train a parser on trees that use a different set of productions , the default HeadFinder will not know how to handle this and will throw this exception .The easiest way to get around this problem is to use LeftHeadFinder instead .", "label": "", "metadata": {}, "score": "84.671196"}
{"text": "Crucially , a limitation of this assumption is that substantially more effort must be applied in crafting the ontology , since re - indexing large volumes of text becomes extraordinarily expensive as the text grows .The designers of a parameterized ontology must be certain that their coverage is adequate before making a decision to freeze the structure .", "label": "", "metadata": {}, "score": "84.71731"}
{"text": "DVParser with no flags .The memory requirements of the parser is not actually that high , but the more threads added with -trainingThreads , the more memory will be required to train .As the parser is training , it will output intermediate models every 20 minutes ( by default ) .", "label": "", "metadata": {}, "score": "84.838104"}
{"text": "Either form of list will pass the tags to the parser .Or you can do this with code that you write .Here 's an example that very manually makes the List in question : . ; List .There are other constraints which can be added , but they have to be added programmatically .", "label": "", "metadata": {}, "score": "85.08292"}
{"text": "Without the temporal annotation , some simple temporals like today will still be recognized , but a bare temporal like last week in I left last week will be tagged as an object ( dobj ) .With the Stanford parser , you can get marking of temporal NPs in the tree output by giving the option -retainTmpSubcategories , either on the command line or by passing it to the setOptionFlags(String [ ] ) method of the parser .", "label": "", "metadata": {}, "score": "85.33896"}
{"text": "See especially the sample invocation in the parser.lexparser package documentation .The included file makeSerialized.csh effectively documents how the included grammars were made .The included file ParserDemo.java gives a good first example of how to call the parser programmatically , including getting Tree and typedDependencies output .", "label": "", "metadata": {}, "score": "85.42752"}
{"text": "claim 6 , wherein said predicates and arguments are represented by encodings comprising at least one digit separated into multiple groups to provide multiple ontological levels and a branching factor at each node .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 2 , further comprising lexer filters for modifying said individual sentences based on word meanings .", "label": "", "metadata": {}, "score": "85.465805"}
{"text": "It should be readily apparent that the ordering of elements of the code can be arbitrary , but must be used consistently in order to compare features .There are two ways to construct a parameterized ontology .The first method is to simply freeze an existing ontology , write a program to find the maximum tree depths and number of branches , and then write another program to recode the pointer information into array elements and depths .", "label": "", "metadata": {}, "score": "85.559746"}
{"text": "Hebrew : UTF-8 .However , the parser is able to parse text in any encoding , providing you pass the correct encoding option on the command line , for example : .-encoding ISO_8859 - 15 .( Or , when used within a program , it is your job to open files with the right kind of Reader / Writer . ) caseless.ser.gz - Loading parser from serialized file edu / stanford / nlp / models / lexparser / englishPCFG .", "label": "", "metadata": {}, "score": "85.572876"}
{"text": "In general , with appropriate grammars loaded , you can parse with and ask for output of the PCFG , ( untyped ) dependency , or factored parsers .For English , although the grammars and parsing methods differ , the average quality of englishPCFG.ser.gz and englishFactored.ser.gz is similar , and so many people opt for the faster englishPCFG.ser.gz , though englishFactored.ser.gz sometimes does better because it does include lexicalization .", "label": "", "metadata": {}, "score": "85.60845"}
{"text": "We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities , and show how it can be refined to take contextual information into account .We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments , and contrast the quality with paraphrases extracted from automatic alignments . ... ol .", "label": "", "metadata": {}, "score": "85.71126"}
{"text": "The modular design of the ontological parser permits the use of any part - of - speech - tagged ontology , with only minimal rewriting of the lexer and parser to accommodate format - specific issues .However , maximum benefits are recognized through the use of a parameterized ontology , an innovation heretofore unavailable in any parser or information retrieval system .", "label": "", "metadata": {}, "score": "85.75124"}
{"text": "Knowledge bases contain instances of real data , which represent a location somewhere within the ontology .Validating the equivalence of an instance with a concept in an ontology entails comparing the features of an instance with the features of a concept .", "label": "", "metadata": {}, "score": "85.77877"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees that fall below a minimum probability for semantic interpretation .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "85.80991"}
{"text": "The advantages of the present system are the provision of a semantic representation of comparable utility with significantly reduced processing requirements , and no need to train the system to produce semantic representations of text content .The system and method for ontological parsing of natural language according to the present invention has a far simpler analysis process than conventional parsing techniques , and utilizes a dictionary containing tags with syntactic information .", "label": "", "metadata": {}, "score": "85.887245"}
{"text": "A side benefit from this algorithm is that it provides an intuitive , natural ranking algorithm .Larger values from the subtraction operation mean further distance apart in the tree , so even when two concepts are in the same branch , the representation provides a convenient metric of conceptual distance .", "label": "", "metadata": {}, "score": "85.89397"}
{"text": "noun .a high ramp overhanging a slope from which skiers compete to make the longest jump .verb .( intransitive ) to perform a ski jump .Derived Forms . ski jumper , noun .Collins English Dictionary - Complete & Unabridged 2012 Digital Edition \u00a9 William Collins Sons & Co. Ltd. 1979 , 1986 \u00a9 HarperCollins Publishers 1998 , 2000 , 2003 , 2005 , 2006 , 2007 , 2009 , 2012 Cite This Source Yes , it 's called information theory . ;) - Alan H. Sep 13 ' 11 at 22:54 .", "label": "", "metadata": {}, "score": "85.89496"}
{"text": "While multiple LexicalizedparserQuery threads share the same grammar ( LexicalizedParser ) , the memory space savings are n't huge , as most of the memory goes to the transient data structures used in chart parsing .So , if you are running lots of parsing threads concurrently , you will need to give a lot of memory to the JVM .", "label": "", "metadata": {}, "score": "86.038345"}
{"text": "The system and method of the present invention also provides a robust feature - checking system that accounts for semantic compatibility as well as syntactic compatibility .The ontology of the present invention converts all inflected words to their canonical forms .", "label": "", "metadata": {}, "score": "86.1427"}
{"text": "The result is that the time complexity of structure - comparison algorithms attains the polynomial order of the number of features ( or nodes ) being compared .This fact makes the use of ontologies inefficient for high - performance computing applications , such as searching terabyte - sized databases with wide - ranging conceptual content .", "label": "", "metadata": {}, "score": "86.2432"}
{"text": "An Abstract Attempt .Below I have randomly written some outrageous pattern matching schemes that in a way to promote a simple way to confine our search to a set of very simple grammatical sentences .A simple sentence pattern may be : .", "label": "", "metadata": {}, "score": "86.62614"}
{"text": "This would add 8 bytes of total storage to each node in the tree .For a 10,000-concept tree , this is only 80 KB .For a 100,000-concept tree , it is 800 KB .And for a 1,000,000-concept tree , it is 8 MB .", "label": "", "metadata": {}, "score": "86.7043"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said noun filter groups proper nouns into single lexical nouns .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "86.74931"}
{"text": "I ca n't find my book to verify this , but I believe that HPSG essentially re - creates x - bar structure through various independent principles of phrase structure .But I could be wrong about that , so take it with a grain of salt ! -", "label": "", "metadata": {}, "score": "86.81596"}
{"text": "Pseudo - predicate verbs include \" give \" , \" show \" , and \" find \" .Not all instances of these verbs are pseudo - predicates ; however , the first instance of them in a query often is .", "label": "", "metadata": {}, "score": "86.857574"}
{"text": "In addition to the SMT decoder , the toolki ... \" .We describe an open - source toolkit for statistical machine translation whose novel contributions are ( a ) support for linguistically motivated factors , ( b ) confusion network decoding , and ( c ) efficient data formats for translation models and language models .", "label": "", "metadata": {}, "score": "86.93913"}
{"text": "Here are example commands for parsing two of the test files , one in UTF-8 and one in GB18030 .The ( Linux ) computer that this is being run on is set up to work with UTF-8 ( and this webpage is also in UTF-8 ) , so for the case of GB18030 , the output is piped through the Unix iconv utility for display .", "label": "", "metadata": {}, "score": "87.12155"}
{"text": "During the sentence lexer stage , words are labeled with information from the ontology , including these numerical codes .The argument position for each predicate structure may be tagged with codes from any level of the ontology .The parser will only output predicate structures where the noun inherits at least those features specified by the code .", "label": "", "metadata": {}, "score": "87.1332"}
{"text": "A brief demo program included with the download will demonstrate how to load the tool and start processing text .When using this demo program , be sure to include all of the appropriate jar files in the classpath .For part - of - speech tags and phrasal categories , this depends on the language and treebank on which the parser was trained ( and was decided by the treebank producers not us ) .", "label": "", "metadata": {}, "score": "87.53658"}
{"text": "claim 28 , wherein the step of parsing comprises the step of looking ahead one word , scanning input from left - to - right , and constructing said parse tree .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "87.63159"}
{"text": "We propose a theory that gives formal semantics to word - level alignments defined over parallel corpora .We use our theory to introduce a linear algorithm that can be used to derive from word - aligned , parallel corpora the minimal set of syntactically motivated transformation rules that explain human ... \" .", "label": "", "metadata": {}, "score": "87.72685"}
{"text": "The parser uses considerable amounts of memory .If you see a java.lang.OutOfMemoryError , you either need to give the parser more memory or to take steps to reduce the memory needed .( You give java more memory at the command line by using the -mx flag , for example -mx500 m . )", "label": "", "metadata": {}, "score": "87.93705"}
{"text": "Both are competing methods for the PC ( predicate calculus ) .And both methodologies are important .Ina regular scope , we definitely need a complete parser in future for the English Language - which links dictionary , thesaurus , and translators will have a universal impact .", "label": "", "metadata": {}, "score": "88.116844"}
{"text": "For example , this command ( with appropriate paths ) will convert a Penn Treebank file to uncollapsed typed dependencies : . java -cp stanford-parser.jar edu.stanford.nlp.trees.EnglishGrammaticalStructure -treeFile wsj/02/wsj_0201 .mrg -basic .Also , here is a sample Java class that you can download that converts from an input file of trees to typed dependencies .", "label": "", "metadata": {}, "score": "88.13249"}
{"text": "claim 23 , wherein said parse probability filter vetoes parse trees that fall below a minimum probability for semantic interpretation .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said system is modular to permit the use of any part - of - speech - tagged ontology .", "label": "", "metadata": {}, "score": "88.134895"}
{"text": "This will change the size of the n - best list and pick the defaults for all other options .It returns a dictionary of the current options : .Use this if all you want is a tokenizer : . [ ' Tokenize ' , ' this ' , ' sentence ' , ' , ' , ' please ' , ' . ' ] Parsing shell .", "label": "", "metadata": {}, "score": "88.4429"}
{"text": "This operation may be accomplished in several ways : .If the ontology used by the parser only contains string labels for the nodes in a tree structure , the tree leading to the restriction must be established as a sub - tree of the selectional features of the argument .", "label": "", "metadata": {}, "score": "88.969925"}
{"text": "a parse tree converter that receives the output of said parser component and converts said parse trees into predicates .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 19 , wherein said parser component further comprises : . parser filters operating on said predicates to remove erroneous predicates .", "label": "", "metadata": {}, "score": "89.08992"}
{"text": "Instead the system and method of the present invention incorporates a sophisticated syntactic analysis component , which allows facts about parts - of - speech to determine the correct syntactic analysis .Additionally , by incorporating ontologies as the basis for the lexical resource , the present invention permits the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}, "score": "89.17513"}
{"text": "The present invention relates to an ontological parser for natural language processing .More particularly , the present invention relates to a system and method for ontological parsing of natural language that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}, "score": "89.27091"}
{"text": "An example command line for this process , with some of the most useful flags , is java -mx4 g edu.stanford.nlp.parser.dvparser.CacheParseHypotheses -model /path / to / pcfg / pcfg.ser.gz -treebank /path / to / wsj 200 - 2199 -output cached.wsj.ser.gz -numThreads 6 .", "label": "", "metadata": {}, "score": "89.4315"}
{"text": "claim 30 , further comprising the step of assigning numbers to said concepts .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 34 , further comprising the step of subtracting said numbers to determine if features are in agreement , wherein a negative number indicates feature incompatibility .", "label": "", "metadata": {}, "score": "89.50631"}
{"text": "The option -smoothTagsThresh 0 stops any probability mass being reserved for unknown words .Naturally , such a parser will be unable to parse any sentence with unknown words in it .The 2003 unlexicalized parsing paper lists several modifications that gradually improve the performance of the Stanford parser for English .", "label": "", "metadata": {}, "score": "89.51785"}
{"text": "All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .Background of the Invention .Numerous techniques have been developed to process natural language input .", "label": "", "metadata": {}, "score": "89.706436"}
{"text": "The difference is simply a digit - by - digit comparison that starts with the most significant bit and continues until the first decimal digit difference is located .Importantly , though , the differences due to inheritance along incompatible sub - trees do not correspond to elements of natural - language meaning .", "label": "", "metadata": {}, "score": "89.71037"}
{"text": "An example of this command line is java -mx12 g edu.stanford.nlp.parser.dvparser.DVParser -cachedTrees /path / to / cached .wsj.ser.gz -train -testTreebank /path / to / wsj 2200 - 2219 -debugOutputFrequency 500 -trainingThreads 8 -parser /path / to / pcfg / pcfg.ser.gz -dvIterations 40 -dvBatchSize 25 -wordVectorFile /path / to / embedding -model /scr / nlp / data / dvparser / wsj / train / averaged / averaged . ser.gz .", "label": "", "metadata": {}, "score": "89.81955"}
{"text": "The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .A system for ontological parsing that converts natural - language text into predicate - argument format comprising : . a sentence lexer for converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and .", "label": "", "metadata": {}, "score": "89.8552"}
{"text": "Reduce actions cause the parser to finish the current production and replace the assembled symbols with the symbol that replaces them ; .Accepts cause the parser to finish assembling a complete parse tree and halt ; .Errors cause the parser to give up because no grammar rule is available to reconcile what has already been parsed with what remains in the input stream .", "label": "", "metadata": {}, "score": "89.97362"}
{"text": "Predicate structures are representations of logical relationships between the words in a sentence .Every predicate structure contains a predicate , which is either a verb or a preposition , and a set of arguments , which may be any part of speech .", "label": "", "metadata": {}, "score": "90.21623"}
{"text": "I believe the problem with parsing X - bar structures is mainly performance based , it is difficult to get a parser to be fast enough to be useful .The transformations make the parsing non monotonic , which makes everything a royal pain for a computer .", "label": "", "metadata": {}, "score": "90.33389"}
{"text": "During the training phase , the model learned a statistical mapping between the source language syntax and the target language syntax using pairs of parsed German and English sentences as training data .These statistics helped the model predict the syntactic structure of the output during the testing phase .", "label": "", "metadata": {}, "score": "90.38345"}
{"text": "The modal verb filter will contain a set of modal verbs similar to the stop word list contained in stop word filter .Any Lexeme whose text is in that set and whose concept is a verb is identified as a modal verb , and will be removed .", "label": "", "metadata": {}, "score": "90.43628"}
{"text": "Similarly , the filter would need to check twice to determine that \" car \" is in agreement with \" transportation , \" and once for \" vehicle . \"In contrast , a parameterized ontology assigns numbers to these concepts , such that each level is a larger number than the previous level .", "label": "", "metadata": {}, "score": "90.59207"}
{"text": "Another object of the present invention is to provide a system and method for parsing natural language input that realizes enormous speed benefits from the parameterized ontology that the parser utilizes .BRIEF DESCRIPTION OF THE DRAWINGS .These and other attributes of the present invention will be described with respect to the following drawings in which : .", "label": "", "metadata": {}, "score": "90.694336"}
{"text": "This assumption is that the number of branches in an ontological hierarchy , and their depth , can be determined by designing it to fixed parameters at the time of creation , and by selecting maximum values for the branches and the depths .", "label": "", "metadata": {}, "score": "90.709984"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said stop word filter removes stop words from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "90.796295"}
{"text": "This process is described in the several papers on the topic by Marie - Catherine de Marneffe .Confusingly , the current code to generate Stanford Dependencies requires a phrase structure ( CFG ) parse .It does n't require or use a dependency parse .", "label": "", "metadata": {}, "score": "90.85314"}
{"text": "This answer is specific to English .It mostly applies to other languages although some components are missing in some languages .The file englishPCFG.ser.gz comprises just an unlexicalized PCFG grammar .It is basically the parser described in the ACL 2003 Accurate Unlexicalized Parsing paper .", "label": "", "metadata": {}, "score": "90.93648"}
{"text": "In this ... \" .This paper is based on the work carried out in the framework of the Verbmobil project , which is a limited - domain speech translation task ( German - English ) .In the nal evaluation , the statistical approach was found to perform best among ve competing approaches .", "label": "", "metadata": {}, "score": "91.029755"}
{"text": "To turn these off , you can use the following options : .At present , we do n't have any documentation beyond what you get in the download and what 's on this page .If you would like to help by producing better documentation , feel free to write to parser-support@lists.stanford.edu .", "label": "", "metadata": {}, "score": "91.09862"}
{"text": "They are : .PCFG .Factored .Factored , segmenting .Xinhua ( mainland , newswire ) .xinhuaPCFG.ser.gz . xinhuaFactored.ser.gz .xinhuaFactoredSegmenting.ser.gz .Mixed Chinese .chinesePCFG.ser.gz . chineseFactored.ser.gz .The PCFG parsers are smaller and faster .But the Factored parser is significantly better for Chinese , and we would generally recommend its use .", "label": "", "metadata": {}, "score": "91.16189"}
{"text": "It can be invoked from the command line .For example , this will download and install the standard WSJ model : . shell% python -m bllipparser .ModelFetcher -i WSJ .Run python -mbllipparser .ModelFetcher with no arguments for a full listing of options and available parsing models .", "label": "", "metadata": {}, "score": "91.29686"}
{"text": "LexicalizedParser -encoding utf-8 /u / nlp / data / lexparser / chineseFactored .ser.gz chinese-onesent-utf8.txt Loading parser from serialized file /u / nlp / data / lexparser / chineseFactored . ser.gz ... done [ 20.7 sec].Parsing file : chinese-onesent-utf8.txt with 2 sentences .", "label": "", "metadata": {}, "score": "91.30728"}
{"text": "If the ontological tree structure is carefully crafted , proximity within the tree should , in some measure , correspond to ontological proximity .Therefore , detecting the first digit difference , as above , gives a reasonable measure of the degree of ontological proximity of the two concepts .", "label": "", "metadata": {}, "score": "91.339005"}
{"text": "In this case , it would download WSJ and install it to /tmp / models / WSJ .Note that it returns the path to the downloaded model .Basic usage .The easiest way to construct a parser is with the from_unified_model_dir class method .", "label": "", "metadata": {}, "score": "91.39209"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said pseudo - concept filter removes concepts from queries .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "91.45065"}
{"text": "In particular , you can now download a version of our CRF - based word segmenter ( similar to the system we used in the Second Sighan Bakeoff ) from our software page .However , for convenience , we also provide an ability for the parser to do word segmentation .", "label": "", "metadata": {}, "score": "91.45499"}
{"text": "Similar to the lexer filters 150 , the parser filters 250 may be chained together to form a list of filters to be applied to each candidate parse tree .Each parser filter 250 will keep track of the filter that should be applied immediately before it , and will submit candidate parse trees to that filter before performing a filtering function .", "label": "", "metadata": {}, "score": "91.46298"}
{"text": "Statistical Syntactic Parsing I also built a statistical syntactic parser for Spanish as part of my PhD work .The parser extended my advisor Michael Collins ' English - language parser .The Spanish version allowed the model to take into account the morphological features of nouns , adjectives , determiners , and so on when making probabilistic decisions about Spanish syntax .", "label": "", "metadata": {}, "score": "91.59253"}
{"text": "Yet SMT translation qual - ity still obviously suffers from inaccurate lexical choice .In this paper , we address this problem by investigating a new strat - egy for integrating WSD into an SMT sys - tem , that performs fully phrasal multi - word disambiguation .", "label": "", "metadata": {}, "score": "91.606865"}
{"text": "However , it is clear from the tree above that not all differences are equally meaningful .In order for the magnitude of the difference to be relevant , it must first be the case that one of the concepts inherits all the properties of the others .", "label": "", "metadata": {}, "score": "91.79636"}
{"text": "At the API level , with the factored parser , if you ask for getBestDependencyParse ( ) , then you will get the best untyped dependency parse .If you call that method with englishPCFG.ser.gz , it will return null , as there is no dependency parse .", "label": "", "metadata": {}, "score": "91.832924"}
{"text": "For example , in an information retrieval application , it is capable of pulling out stopwords and unintended query words ( as in the pseudo - concept and pseudo - predicate filters ) .In the embodiment discussed above , the grammar violation checking of the system and method of the present invention filters both by the probability of a syntactically successful parse and the compatibility of the lexical semantics of words in the ontology .", "label": "", "metadata": {}, "score": "91.92728"}
{"text": "The stop word filter will contain a set of words accepted as stop words ; any lexeme whose text is in that set is considered to be a stop word .An adjective filter serves to remove lexemes representing adjective concepts from sentences .", "label": "", "metadata": {}, "score": "91.963326"}
{"text": "We present Minimum Bayes - Risk ( MBR ) decoding for statistical machine translation .This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of l ... \" .", "label": "", "metadata": {}, "score": "92.15798"}
{"text": "Or it may be because the parser made a mistake .While our goal is to improve the parser when we can , we ca n't fix individual examples .The parser is just choosing the highest probability analysis according to its grammar .", "label": "", "metadata": {}, "score": "92.77074"}
{"text": "For some sentences the parse tree output by the standalone parser and the tree output by the CoreNLP pipeline can be different .The reason for this is that if you run the CoreNLP pipeline with the default annotators , it will run a part - of - speech ( POS ) tagger before running the parser .", "label": "", "metadata": {}, "score": "92.86081"}
{"text": "As we build up our blocks of knowledge and computation of the AI , we draw our attention onto the applications of which - these conclusively are in the domain of semantic networks .Share .About the Author .I was born in China and immigrated to the United States when I was young .", "label": "", "metadata": {}, "score": "92.993454"}
{"text": "Atamiri Sep 22 ' 13 at 15:13 .I believe that Sandiway Fong has made at least one principles & parameters parser , which might be old enough to have proper x - bar structure .There are n't many in that area doing computational linguistics , but probably the big name is Robert Berwick , so you might want to look at some of his work as well .", "label": "", "metadata": {}, "score": "93.102905"}
{"text": "You may use the parse method that takes a String argument to have this done for you or you may be able to use of classes in the process package , such as DocumentPreprocessor and PTBTokenizer for tokenization , much as the main method of the parser does .", "label": "", "metadata": {}, "score": "93.12398"}
{"text": "Often , that works out okay , but , overall , results wo n't be quite as good .The default character encoding depends on the language that you are parsing .It is defined in the appropriate TreebankLanguagePack class .That is , it will never default to your platform default character encoding .", "label": "", "metadata": {}, "score": "93.21852"}
{"text": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions . \" ...This paper is based on the work carried out in the framework of the Verbmobil project , which is a limited - domain speech translation task ( German - English ) .", "label": "", "metadata": {}, "score": "93.34404"}
{"text": "A predicate structure built from \" eat \" might thus require that the object of the predicate have a code beginning with \" 112 .\" As can be seen from the tree shown , it is clear that all the foods listed inherit the \" 112 \" prefix .", "label": "", "metadata": {}, "score": "93.370735"}
{"text": "If you want to display the output in a command window , you separately also need to work out what character set your computer supports for display .If that is different to the encoding of the file , you will need to convert the encoding for display .", "label": "", "metadata": {}, "score": "93.44226"}
{"text": "Languages such as Japanese or Russian , which permit free ordering of words , but mark intended usage by morphological changes , would be difficult to parse using the Brash system .The patent to Hemphill et al .( U.S. Pat .", "label": "", "metadata": {}, "score": "93.642715"}
{"text": "Yes .The parser treats a filename as - as meaning to read from stdin and by default writes to stdout ( this can be changed with the -writeOutputFiles option ) .Note : the tokenizer uses lookahead , so you will either need to close the input to get the last sentence parsed , or use another option like -sentences newline .", "label": "", "metadata": {}, "score": "93.775566"}
{"text": "If a noun is found and it satisfies the restrictions of the adjective , the adjective filter will apply the selectional features of the adjective to the noun by adding all of the adjective 's selectional features to the noun 's set of selectional features .", "label": "", "metadata": {}, "score": "93.85822"}
{"text": "Two rules are included in this example of a pseudo - concept filter implementation .The first rule is that any word relating to the user , or his current situation , such as \" I \" or \" me \" is always deleted .", "label": "", "metadata": {}, "score": "94.202576"}
{"text": "By default , the tokenizer used by the English parser ( PTBTokenizer ) performs various normalizations so as to make the input closer to the normalized form of English found in the Penn Treebank .One of these normalizations is the Americanization of spelling variants ( such as changing colour to color ) .", "label": "", "metadata": {}, "score": "94.22605"}
{"text": "The term concept as used herein means an abstract formal representation of meaning , which corresponds to multiple generic or specific words in multiple languages .Concepts may represent the meanings of individual words or phrases , or the meanings of entire sentences .", "label": "", "metadata": {}, "score": "94.37839"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said adverb filter removes lexemes containing adverb concepts from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "94.43104"}
{"text": "This is an element of the dependency analysis we adopted .It 's not uncontroversial , and it could have been done differently , but we 'll try to explain briefly why we did things the way we did .The general philosophy of the grammatical relations design is that main predicates should be heads and auxiliaries should not .", "label": "", "metadata": {}, "score": "94.48016"}
{"text": "Aligning the English phrase to be paraphrased was the German - English section of the Europarl corpus , version 2 ( Koehn , 2002 ) .Because we wanted to test our method independently of the quality of word alignment algorithms , we also developed a gold standard of word alignments for the set of phrases that we wanted to paraphr ... .", "label": "", "metadata": {}, "score": "94.52231"}
{"text": "claim 22 , wherein said parser filters include a selectional restriction filter and a parse probability filter .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 23 , wherein said selectional restriction filter vetoes parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .", "label": "", "metadata": {}, "score": "94.93086"}
{"text": "The main problem is global economy conditions , which in some models require the syntax to generate many permutations of a given sentence and then evaluate them after the fact .Research .Syntax - Based Statistical Machine Translation The focus of my PhD thesis was to develop a German - to - English statistical machine translation system .", "label": "", "metadata": {}, "score": "94.95218"}
{"text": "For the Hansard corpus , we took the human annotation of word alignment ... . \" ...We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models .", "label": "", "metadata": {}, "score": "95.19409"}
{"text": "And the result is as follows : .So in the graph , the strait blue pointers represent direct connection of two nodes with action label .And the curved separator represents a OR condition with labeled action .Up to here we do need some more details in our dictionary - we probably need a thesaurus to tell us what words are similar or opposite , so we can tell that \" love \" and \" hate \" are opposite each other .", "label": "", "metadata": {}, "score": "95.2521"}
{"text": "That is , they will just say Jill busy .Connection to logical representations : If you were to translate these sentences into a simple predicate logic form , you would presumably use busy(jill ) and teacher(jill ) .The treatment of the adjective or noun as the predicate in a predicate logic form parallels what we do in our grammatical relations representation .", "label": "", "metadata": {}, "score": "95.43982"}
{"text": "Starting with version 1.6.2 of the parser , there is a fairly flexible scheme for options in tokenization style .You can give options such as this one to turn off Americanization of spelling : .Or this one to change several options : .", "label": "", "metadata": {}, "score": "95.46205"}
{"text": "claim 28 , further comprising the step of modifying said natural language sentence based on word meanings .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the steps of : . receiving sentences including ontological entities ; . parsing said sentences including ontological entities into parse trees representing concepts in the corresponding sentence including ontological entities ; and . converting said parse trees into predicates .", "label": "", "metadata": {}, "score": "95.4985"}
{"text": "claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a negative number indicates feature incompatibility .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "95.52763"}
{"text": "Extras includeExtras , boolean threadSafe , Predicate . filter , . boolean originalDependencies )The Designing of a Logic Reasoning Methodology .Introduction .The interest of building a PC parser ( predicate calculus ) has been always puzzling me .Ever since the time I was first introduced to the simplicity of deductive reasoning in the early 90s , I have always wanted to create a parser for the rules which to be named as my PC parser .", "label": "", "metadata": {}, "score": "95.53175"}
{"text": "Lexer filters 150 are modular plug - ins , which modify sentences based on knowledge about word meanings .The preferred embodiment contains several filters 150 , although more may be developed , and existing filters may be removed from future versions , without altering the scope of the invention .", "label": "", "metadata": {}, "score": "95.72662"}
{"text": "This gives a reasonable , but not excellent , Chinese word segmentation system .( It 's performance is n't as good as the Stanford CRF word segmenter mentioned above . )To use it , you use the -segmentMarkov option or a grammar trained with this option .", "label": "", "metadata": {}, "score": "95.76871"}
{"text": "Still another object of the present invention is to provide a system and method for parsing natural language input that transforms data using a syntactic parser and ontology , where the ontology is used as a lexical resource .Yet another object of the present invention is to provide a system and method for parsing natural language input that provides ontological entities as output that are predicate - argument structures .", "label": "", "metadata": {}, "score": "95.79639"}
{"text": "That is , sentences like Jill is busy or Jill is a teacher .We continue to regard the adjective or noun as the predicate of which the subject is the argument , rather than changing and now regarding the copular verb is as the head and busy / teacher as a complement .", "label": "", "metadata": {}, "score": "95.9367"}
{"text": "By default , our Chinese parser uses GB18030 ( the native character encoding of the Penn Chinese Treebank and the national encoding of China ) for input and output .However , it is very easy to parse text in another character encoding : you simply give the flag -encoding encoding to the parser , where encoding is a character set encoding name recognized within Java , such as : UTF-8 , Big5-HKSCS , or GB18030 .", "label": "", "metadata": {}, "score": "96.004654"}
{"text": "Parsing file : - i ca n't believe @mistamau does n't know who channing tatum is ... # loser Parsing [ sent .1 len .Parsed 14 words in 1 sentences ( 4.29 wds / sec ; 0.31 sents / sec ) .", "label": "", "metadata": {}, "score": "96.29594"}
{"text": "A predicate structure is a data type that includes a predicate and multiple additional concepts ; as a grouping of concepts , it is itself a concept .An ontology is a hierarchically organized complex data structure that provides a context for the lexical meaning of concepts .", "label": "", "metadata": {}, "score": "96.394264"}
{"text": "So to form a list of logical predicate sentences as a closure to our conclusion , we call this clearly as the propositions .And the propositions must be true and can directly lead to our presumption or we say our test string in order for the predicate test to be true .", "label": "", "metadata": {}, "score": "96.54262"}
{"text": "We would recommend their use for parsing material from mainland China .The chinese grammars also include some training material from Hong Kong SAR and Taiwan .We 'd recommend their use if parsing material from these areas or a mixture of text types .", "label": "", "metadata": {}, "score": "97.12891"}
{"text": "Many who work in that line do n't consider that important , because they do n't consider what they do to be a model of performance but purely a model of knowledge .But not everyone buys that .See this article , for example .", "label": "", "metadata": {}, "score": "97.50653"}
{"text": "By default , DocumentPreprocessor uses PTBTokenizer for tokenization .If you need to change that , either because you have a better Tokenizer for your domain or because you have already tokenized your text , you can do that by passing in a TokenizerFactory such as a WhitespaceTokenizerFactory for no tokenization beyond splitting on whitespace .", "label": "", "metadata": {}, "score": "97.58128"}
{"text": "We can then subtract numbers to see if the features are in agreement , and a non - negative result suffices to prove this .Since 1 is nonnegative , we know that the features are in agreement .If concepts are identical , they will subtract to zero , which is equivalent to passing the filter by having two identical strings .", "label": "", "metadata": {}, "score": "97.80359"}
{"text": "He also finished in June 2008 . )Marin Tutors , Marin County , CA , 1999 - 2000 ( This was a private tutoring business I started .I tutored some 10 to 20 students once or twice weekly in their homes . )", "label": "", "metadata": {}, "score": "98.29634"}
{"text": "You can invoke it with the -escaper flag , by using a command like the following ( which also shows output being sent to a file ) : . stp .Word segmentation : Chinese is not normally written with spaces between words .", "label": "", "metadata": {}, "score": "98.84491"}
{"text": "Yes , you can .Various tokenizers are included .The one used for English is called PTBTokenizer .It is a hand - written rule - based ( FSM ) tokenizer , but is quite accurate over newswire - style text .", "label": "", "metadata": {}, "score": "98.88299"}
{"text": "a jump made by a skier from a ski jump . verb ( used without object ) .to execute or make a ski jump .Origin of ski jump Expand .Related forms Expand . ski jumper , noun .Cite This Source .", "label": "", "metadata": {}, "score": "98.91516"}
{"text": "The standard LALR parser generator algorithm fails when the grammar does not provide the parser generator enough information to decide whether the correction to perform given a certain current state and input symbol is to shift or to reduce .The generator algorithm also fails when the grammar does not provide the parser generator enough information to decide which of two or more rules should be reduced .", "label": "", "metadata": {}, "score": "98.94948"}
{"text": "Consider a sample path through an ontology : .In this example , if the argument position of a predicate must be an example of transportation , then any of the three more - specific words will be an acceptable argument for the predicate .", "label": "", "metadata": {}, "score": "98.956924"}
{"text": "A proper noun is any word or phrase representing a non - generic noun concept .Although a number of proper nouns are already present in the lexicon , they are already properly treated as regular lexical items .Since proper nouns behave syntactically as regular nouns , there is no need to distinguish proper nouns and nouns already in the lexicon .", "label": "", "metadata": {}, "score": "99.169785"}
{"text": "A selectional restriction filter vetoes any parse tree where there are conflicts between the selectional features of the concepts serving as arguments to another concept and the restrictions of that concept .Selectional restrictions are imposed on the argument positions of predicate structures .", "label": "", "metadata": {}, "score": "99.56743"}
{"text": "PTBEscapingProcessor .If calling the parser within your own program , the main parse methods take a List of words which should already be correctly tokenized and escaped before calling the parser .You do n't need to and can not give the -tokenized option .", "label": "", "metadata": {}, "score": "99.618034"}
{"text": "There is considerable Javadoc documentation included in the javadoc/ directory of the distribution .You should start by looking at the javadoc for the parser.lexparser package and the LexicalizedParser class .( The documentation appearing on the nlp.stanford.edu website refers to code under development and is not necessarily consistent with the released version of the parser . )", "label": "", "metadata": {}, "score": "99.67374"}
{"text": "The modal verb filter removes modal verbs from sentence objects .Modal verbs are verbs such as \" should \" , \" could \" , and \" would \" .Such verbs alter the conditions under which a sentence is true , but do not affect the basic meaning of the sentence .", "label": "", "metadata": {}, "score": "99.806244"}
{"text": "In recent distributions , the models are included in a jar file inside the parser distribution .For example , in the 2012 - 11 - 12 distribution , the models are included in stanford - parser-2.0.4-models.jarThe easiest way to access these models is to include this file in your classpath .", "label": "", "metadata": {}, "score": "100.350815"}
{"text": "The relevant options are -sentences ( see above ) , -tokenized , -tokenizerFactory , -tokenizerMethod , and -tagSeparator .If , for example , you want to denote a POS tag by appending /POS on a word , you would include the options -tokenized -tagSeparator / -tokenizerFactory edu.stanford.nlp.process.WhitespaceTokenizer -tokenizerMethod newCoreLabelTokenizerFactory in your invocation of LexicalizedParser .", "label": "", "metadata": {}, "score": "100.41859"}
{"text": "Awards .NSF - Johns Hopkins Post - CLSP Workshop Grant Recipient , 2006 - 2007 .Departmental Honors and Distinction , American Studies Department , Stanford University , 1994 Not Logged In . bllipparser 2014.02.09 .The BLLIP parser ( also known as the Charniak - Johnson parser or Brown Reranking Parser ) is described in the paper Charniak and Johnson ( Association of Computational Linguistics , 2005 ) .", "label": "", "metadata": {}, "score": "101.154755"}
{"text": "With this code , you should be able to parse the sentence in a file with a command like this ( details depending on your shell , OS , etc . ) : . java -mx200 m -cp \" stanford - parser .", "label": "", "metadata": {}, "score": "101.8087"}
{"text": "For example , consider a tree shown in FIG .7 .It is clear that in some cases , it is useful to know the distance between words , but that it is not equally useful in all cases .However , since neither of these terms shares any properties beyond \" organic \" with \" amino acid , \" it is not helpful to know the distance between \" bread \" and \" amino acid , \" even though they are only one level apart .", "label": "", "metadata": {}, "score": "101.836845"}
{"text": "The / DT quick / JJ brown / JJ fox / NN jumped / VBD over / IN the / DT lazy / JJ dog / NN .with the command : . ser.gz fox.txt .Partially - tagged input ( only indicating the POS of some words ) is also OK .", "label": "", "metadata": {}, "score": "101.88223"}
{"text": "In 1993 I was enrolled in the Washington State University 's Computer Science program and graduated in year 1996 .Between 1997 to 1999 , I was in their Master degree program in Collaborative Learning .Between year 2000 to 2001 , I worked in a litigation company in Utah .", "label": "", "metadata": {}, "score": "101.91115"}
{"text": "We feel that this is more useful for most semantic interpretation applications , because it directly connects the main predicate with its arguments , while the auxiliary is rendered as modifying the verb ( aux(singing , is ) ) .Most people seem to agree .", "label": "", "metadata": {}, "score": "101.92116"}
{"text": "From here we test all joint edges ( or arcs ) to see if they are legal .This should be a O(n ) algorithm since we test each edge only once .But if we are to test Lucy Hates Tom - presented in the red curved arrow , we should n't be parsing all edges legally .", "label": "", "metadata": {}, "score": "101.92691"}
{"text": "Dunja Mladinic , Turning Yahoo into an Automatic Web Page Classifier , ECAI 98:13th European Conference on Artificial Intelligence , Brighton , UK , Aug. 23 to Aug. 28 , 1998 , pp .473 - 474 , John Wiley & Sons , Ltd. .", "label": "", "metadata": {}, "score": "101.94689"}
{"text": "There 's not much in the way of secret sauce to speed that up ( partly by the design of the parsers as guaranteed to find model optimal solutions ) .If you 're not using englishPCFG.ser.gz for English , then you should be - it 's much faster than the Factored parser .", "label": "", "metadata": {}, "score": "102.44514"}
{"text": "Between 2005 to 2008 I was working as a SDET in Microsoft .Since 2009 and 2010 , I started to have a deeper symptom of Schizophrenia partly caused by memories of the War .I was diagnosed as to have a Schizoaffective disorder early in year 2011 and have been off work since .", "label": "", "metadata": {}, "score": "102.92521"}
{"text": "For part of speech and phrasal categories , here are relevant links : .Please read the documentation for each of these corpora to learn about their tagsets and phrasal categories .You can often also find additional documentation resources by doing web searches .", "label": "", "metadata": {}, "score": "103.228546"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said sentence lexer comprises : . a document iterator that receives text input and outputs individual sentences ; . a lexer that receives said individual sentences from said document iterator and outputs individual words ; and . an ontology that receives said individual words from said lexer and returns ontological entities or words tagged with default assumptions about an ontological status of said individual words to said lexer .", "label": "", "metadata": {}, "score": "103.28297"}
{"text": "Again using January 2014 version 3.3.1 as an example , you would not make your classpath -cp stanford - parser-3.3.1.jar Instead , you would make it Windows : -cp stanford - parser-3.3.1 . jar : stanford - parser-3.3.1-models.jar .In order to see exactly which models are available , you can use jar tvf stanford - parser-3.3.1-models.jar This will show you that to access the Arabic Factored model , for example , you would use the path edu / stanford / nlp / models / lexparser / arabicFactored . ser.gz .", "label": "", "metadata": {}, "score": "103.36706"}
{"text": "Of course , parsing will suffer unless your tokenization accurately matches the tokenization of the underlying treebank , for instance Penn Treebank tokenization .A common occurrence is that your text is already correctly tokenized but does not escape characters the way the Penn Treebank does ( turning parentheses into -LRB- and -RRB- , and putting a backslash in front of forward slashes and asterisks - presumably a holdover from Lisp ) .", "label": "", "metadata": {}, "score": "104.33835"}
{"text": "On the other hand , if we test : L Hates T ; we will have a unresolved condition at 2 nd sentence , so the conclusion would be false .Another approach to implement this simple logical grammar parser ( or of PC - predicate logic reasoning ) , we will take a look at the graphical presentation and interpretation of nodes by traversal to derive or similarly to parse the conclusion .", "label": "", "metadata": {}, "score": "104.564964"}
{"text": "( Since these parsers were written , direct typed dependency parsers have been increasingly explored .Both us and others have now built parsers that directly parse to Stanford Dependencies .See the Stanford Dependencies page for more information . )For Chinese ( and Arabic , German , and \" WSJ \" ) , you can look at the included file makeSerialized.csh , and easily see exactly what files the models are trained on , in terms of LDC or Negra file numbers .", "label": "", "metadata": {}, "score": "104.99153"}
{"text": "ParsingShell /path / to / model .Once in the shell , type a sentence to have the parser parse it : .Tokens : I saw the astronomer with the telescope .If you have nltk installed , you can use its tree visualization to see the output : .", "label": "", "metadata": {}, "score": "106.37498"}
{"text": "Where word after \" be \" is an adverb , a verb in continuous form , or in the past tense describing the action is done as with the \" be \" to form an adverb describing the subject .Doug is furious about the situation .", "label": "", "metadata": {}, "score": "106.920135"}
{"text": "When you do this , the tags for a token will be used in decreasing priority .token 0 ( ' Time ' ) should have tag VB , JJ , or NN and token 1 ( ' flies ' ) is unconstrained : .", "label": "", "metadata": {}, "score": "109.102135"}
{"text": "Following that , it would be passed to the lexer 120 , which would access the ontology 140 , and return the sequence : .The - det octopus - noun have - verb a - det heart - noun .Here , det stands for determiner , which is a word with a purely grammatical function , namely specifying a noun phrase .", "label": "", "metadata": {}, "score": "109.95502"}
{"text": "We draw the test pointer in yellow ... .So we go from node ' L ' , and we see that ' L ' can either ' Love ' Tom or ' Love ' Chris ; and ' L ' Hate Chris .", "label": "", "metadata": {}, "score": "110.71189"}
{"text": "E.g. .A dog is a friend .Dogs are friends .Doug is a friend .Doug is furious .An prepositional sentence pattern has relationship of subject and object with object prepositions such as \" after , around , from , .... \" .", "label": "", "metadata": {}, "score": "112.70166"}
{"text": "In the parser 220 , the tree shown in .FIG .6 is produced .The parse tree converter 230 then converts this tree into a predicate , where octopus is the subject of have , and heart is the object .", "label": "", "metadata": {}, "score": "115.794"}
{"text": "Do - verb octopus - noun have - verb heart - noun .In the preferred embodiment 's lexer filters , the pseudo predicate filter removes the first verb \" do , \" because it is not the main verb of the sentence . \"", "label": "", "metadata": {}, "score": "118.95076"}
{"text": "Undergraduate Mentor , MIT , 2005 - 2008 ( I mentored two undergraduates at MIT , one who worked with me as a UROP during the summer of 2005 .She graduated in June 2008 and is now working at Oracle .", "label": "", "metadata": {}, "score": "119.00785"}
{"text": "Description .Applicants hereby incorporate by reference co - pending application Ser .No .09/627,295 filed in the U.S. Patent and Trademark Office on Jul. 27 , 2000 , entitled \" Concept - Based Search and Retrieval System . \" BACKGROUND OF THE INVENTION .", "label": "", "metadata": {}, "score": "119.03273"}
{"text": "Thus , when the sentence passes through the lexer filters 150 as discussed in the previous example embodiment , the stop word filter removes \" a \" and \" the , \" leaving : . octopus - noun have - verb heart - noun .", "label": "", "metadata": {}, "score": "120.624855"}
{"text": "In this example , token 0 ( ' Time ' ) should have tag VB and token 1 ( ' flies ' ) should have tag NNS : .You do n't need to specify a tag for all words : token 0 ( ' Time ' ) should have tag VB and token 1 ( ' flies ' ) is unconstrained : .", "label": "", "metadata": {}, "score": "120.91572"}
{"text": "And we also know by thesaurus and negation ( PC ) that Lucy Hates Tom is false means Lucy Loves Tom is true .So both parses draw the same conclusion .Using graphical presentation to solve logical reasoning may refer to this method can be called a semantic network - because it solves with records of knowledge .", "label": "", "metadata": {}, "score": "121.09944"}
{"text": "In this example , token 0 ( ' Time ' ) should have tag VB and token 1 ( ' flies ' ) should have tag NNS : .You do n't need to specify a tag for all words : Here , token 0 ( ' Time ' ) should have tag VB and token 1 ( ' flies ' ) is unconstrained : .", "label": "", "metadata": {}, "score": "122.25957"}
{"text": "Suppose that a user of a search engine which makes use of this parser asks the question : .Do octopuses have hearts ?The sentence lexer 100 will read the question , and a sentence made of ontological entities is produced .", "label": "", "metadata": {}, "score": "122.84648"}
{"text": "For simplicity we like to begin with a most reasonably simple discipline ( grammatical rules ) of our logical construct .By examples , so we like to same in the most simple and elegant manner of the following : .Tom is late ( simple adverb predicate ) .", "label": "", "metadata": {}, "score": "123.11167"}
{"text": "Chris loves Lucy but Lucy hates Chris ( this is a simple conjunction of AND operator ) .Chris loves gun and rose ( this can be separated into two simple predicate ) .Chris knows neither Tom nor Nancy ( another simple conjugation ) .", "label": "", "metadata": {}, "score": "126.18154"}
{"text": "And we have a predicate list which sort of like the following : .T loves L .If not ( A loves B ) then A hates B .L hates C .And we supply our test sentence : L loves T ?", "label": "", "metadata": {}, "score": "126.883865"}
{"text": "To understand the relationship of logic reasoning and English language , we need to see the grammatical rules of English language ; and how a predicate calculus can be constructed on it .A simple English sentence may be : Tom loves Lucy where Tom is the subject , \" love \" is the action , and Lucy is the object .", "label": "", "metadata": {}, "score": "134.47006"}
{"text": "The flowing is our little list of propositions ( predicates ) : .Chris loves Lucy but Lucy hates Chris .Lucy loves either Tom or Chris ( Lucy must love one , we know it for sure ! )So we want to parse our conclusion that Lucy loves Tom .", "label": "", "metadata": {}, "score": "137.40277"}
{"text": "The example sentence is : .The octopus has a heart .First , the sentence lexer 100 would process this sentence .The first component of the sentence lexer 100 , the document iterator 110 , would extract this sentence from the document it was contained in .", "label": "", "metadata": {}, "score": "138.97392"}
