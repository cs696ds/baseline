{"text": "The resulting grammars are extremely compact com- pared to other high - performance parsers , yet the parser gives the best published accuracies on several languages , as well as the best generative parsing numbers in English .In addi- tion , we give an associated coarse - to - fine inference scheme which vastly improves inference time with no loss in test set accuracy .", "label": "", "metadata": {}, "score": "28.069265"}
{"text": "In this thesis , we focus on the task of semantic parsing , which maps a natural language sentence into a complete , formal meaning representation in a meaning representation language .We present two novel state - of - the - art learned syntax - based semantic parsers using statistical syntactic parsing techniques , motivated by the following two reasons .", "label": "", "metadata": {}, "score": "30.559706"}
{"text": "Building on this work , we demonstrate substan ... \" .For many years , statistical machine translation relied on generative models to provide bilingual word alignments .In 2005 , several independent efforts showed that discriminative models could be used to enhance or replace the standard generative approach .", "label": "", "metadata": {}, "score": "31.190409"}
{"text": "We present a new approach to learning a semantic parser ( a system that maps natural language sentences into logical form ) .Unlike previous methods , it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .", "label": "", "metadata": {}, "score": "32.00714"}
{"text": "The natural language inputs are parsed using a parser which is generally similar to that disclosed in the 1981 dissertation of Ken Ross entitled \" Parsing English Phrase Structure \" .The system is coded in LISP , and has been demonstrated on a LISP machine from LMI Incorporated .", "label": "", "metadata": {}, "score": "32.46737"}
{"text": "Combining multiple grammars that were self - trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5\\% on the WSJ test set and 89.6\\% on our Broadcast News test set .This work shows how to improve state - of - the - art monolingual natural language processing models using unannotated bilingual text .", "label": "", "metadata": {}, "score": "32.821243"}
{"text": "The ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}, "score": "33.110523"}
{"text": "Thus , after a portable specification has been constructed in this manner , it can be stored .As noted , whenever this interface is called up thereafter , the portable specification will be used to regenerate a grammar and lexicon , the well - formedness test will be applied , and the natural language menu interace will then be up and running .", "label": "", "metadata": {}, "score": "33.17669"}
{"text": "No .4,887,212 to Zamora et al . discloses a parser for syntactic analysis of text using a fast and compact technique .After part - of - speech tagging and disambiguation , syntactic analysis occurs in four steps .The grammar of Zamora et al . operates by making multiple passes to guess at noun phrases and verb phrases and then attempts to reconcile the results .", "label": "", "metadata": {}, "score": "33.679985"}
{"text": "It does not attempt to determine grammaticality , though it will normally prefer a \" grammatical \" parse for a sentence if one exists .This is appropriate in many circumstances , such as when wanting to interpret user input , or dealing with conversational speech , web pages , non - native speakers , etc . .", "label": "", "metadata": {}, "score": "33.681393"}
{"text": "We also discuss the more general , and computationally more difficult , problem of finding good parsing strategies for non - binarizable rules , and present an approximate polynomial - time algorithm for this problem . \" ...For many years , statistical machine translation relied on generative models to provide bilingual word alignments .", "label": "", "metadata": {}, "score": "33.858856"}
{"text": "However , in the presently preferred embodiment , the full reachability matrix is not compiled , but instead a list is compiled , for each node in the grammar , listing the other leftmost daughter nodes which can be dominated by that node .", "label": "", "metadata": {}, "score": "34.175156"}
{"text": "As a simple example , consider the following set of rules : .Given the lexicon shown earlier , the above grammar will determine whether sentences containing words in the lexicon are grammatical or ungrammatical , once a nonterminal symbol is assigned as the designated symbol for the grammar .", "label": "", "metadata": {}, "score": "34.213314"}
{"text": "This grammar and lexicon pair define a particular domain - specific natural language interface , suitable for use in a grammar - dirven , menu - based system .The prototype uses a particular core grammar and lexicon .The grammar assumes that the natural language is English , but it could have been another natural language .", "label": "", "metadata": {}, "score": "34.346542"}
{"text": "Our method does not assume any knowledge about the target language ( in particular no tagging dictionary is assumed ) , making it applicable to a wide array of resource - poor languages .We use graph - based label propagation for cross - lingual knowledge transfer and use the projected labels as features in an unsupervised model ( Berg - Kirkpatrick et al .", "label": "", "metadata": {}, "score": "34.51854"}
{"text": "This has substantial advantages in the present invention , as described below .An example of the operation of this simplified version of a parsing procedure will now be given .Suppose , for example , that the grammar to be applied is as follows : .", "label": "", "metadata": {}, "score": "34.624046"}
{"text": "An ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}, "score": "34.707355"}
{"text": "In future work , we intend to pursue several directions in developing accurate semantic parsers for a variety of application domains .This will involve exploiting prior knowledge about the natural - language syntax and the application domain .We also plan to construct a syntax - aware word - based alignment model for lexical acquisition .", "label": "", "metadata": {}, "score": "34.818474"}
{"text": "Unlike existing preordering models , we train feature - rich discriminative classifiers that directly predict the target - side word order .Our approach combines the strengths of lexical reordering and syntactic preordering models by performing long - distance reorderings using the structure of the parse tree , while utilizing a discriminative model with a rich set of features , including lexical features .", "label": "", "metadata": {}, "score": "35.209625"}
{"text": "Translations to languages other than CSL 's dbms are planned ; specifically , an interface to SQL has been demonstrated .Translations from languages other than English can easily be implemented .Changes in the functionality of the core grammar will be reflected by changes in the core lexicon , so this list is open - ended too .", "label": "", "metadata": {}, "score": "35.273605"}
{"text": "Programmatically , you can do the same things by creating a TokenizerFactory with the appropriate options , such as : .getWordsFromString(str ) ) ; .There is nevertheless a potential cost of making tokenization changes .This normalization was added in the first place because the parser is trained on American English , normalized according to Penn Treebank conventions .", "label": "", "metadata": {}, "score": "35.301315"}
{"text": "Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .In this paper , we demonstrate a discriminative approach to training simple word alignment models that are comparable in accuracy to the more complex generative models normally used .", "label": "", "metadata": {}, "score": "35.392952"}
{"text": "For English , the parser by default now produces Universal Dependencies , which are extensively documented on that page .You can also have it produce the prior Stanford Dependencies representation .For this , and for the Chinese dependencies , you can find links to documentation on the Stanford Dependencies page .", "label": "", "metadata": {}, "score": "35.446785"}
{"text": "has a complicated analysis , and can not afford semantic status to each word relative to all the other words within the dictionary .The Kucera et al . system uses three parsing stages , each of which needs more than one pass through the sentence to complete its analysis .", "label": "", "metadata": {}, "score": "35.44879"}
{"text": "People are often confused about how to get from that example to parsing paragraphs of text .You need to split the text into sentences first and then to pass each sentence to the parser .To do that , we use the included class DocumentPreprocessor .", "label": "", "metadata": {}, "score": "35.593956"}
{"text": "Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with lambda - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain .", "label": "", "metadata": {}, "score": "35.6642"}
{"text": "All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .The present system imposes a logical structure on text , and a semantic representation is the form used for storage .", "label": "", "metadata": {}, "score": "35.87531"}
{"text": "Such as facility is used by the NLMenu System .It is straightforward to add a well - formed state table to a Parser modified in the way just described .Before beginning a parse with new input and a set of beta - gamma pairs , the beta - gammas can be compared and those with common subgoals can be merged .", "label": "", "metadata": {}, "score": "35.93202"}
{"text": "For future work , I propose to extend our PCFG induction model in several ways : improving the lexicon learning algorithm , discriminative re - ranking of top - k parses , and integrating the meaning representation language ( MRL ) grammar for extra structural information .", "label": "", "metadata": {}, "score": "36.153416"}
{"text": "The process of taking a sentence and determining whether it is grammatical , given a grammar , is called parsing .The result of parsing a sentence is one or more parse trees if the input is a valid sentence .If the input is not a sentence , parsing produces no parse trees .", "label": "", "metadata": {}, "score": "36.281395"}
{"text": "However , it is possible that there may be more than one valid parse tree .The user then selects between the alternative parses displayed , so that the end product is a single unambiguous parse of an input sentence .The process by which such an unambiguous parse is translated into an executable machine command ( or an output according to some constrained system , for other applications ) will now be described .", "label": "", "metadata": {}, "score": "36.449284"}
{"text": "By default , the parser that was generated will not print out error messages to the screen .The user will have to do this either by printing the returned error messages , or by inserting tests and print instructions in the Erlang code associated with the syntax rules of the grammar file .", "label": "", "metadata": {}, "score": "36.465523"}
{"text": "Despite its simplicity , a product of eight automatically learned grammars improves parsing accuracy from 90.2 % to 91.8 % on English , and from 80.3 % to 84.5 % on German .Pruning can massively accelerate the computation of feature expectations in large models .", "label": "", "metadata": {}, "score": "36.599365"}
{"text": "Third , the present invention also provides a well - formedness test , which tests a grammar - lexicon pair to ensure that they are well - formed .This automatic debugging for an automatically generated natural - language expert system is novel and provides major advantages .", "label": "", "metadata": {}, "score": "36.606754"}
{"text": "In particular , we introduce set - valued features to encode the predicted morphological properties and part - of - speech confusion sets of the words being parsed .We also investigate the use of joint parsing and part - of - speech tagging in the neural paradigm .", "label": "", "metadata": {}, "score": "36.61765"}
{"text": "We present a method for acquiring reliable predicate - argument structures from raw corpora for automatic compilation of case frames .Such lexicon compilation requires highly reliable predicate - argument structures to practically contribute to Natural Language Processing ( NLP ) applications , such as par ... \" .", "label": "", "metadata": {}, "score": "36.653065"}
{"text": "The ability to parse a word at a time is essential for the NLMenu System .However , it is also beneficial for more traditional natural language interfaces .It can increase the perceived speed of any parser since work can proceed as the user is typing and composing his input .", "label": "", "metadata": {}, "score": "36.679626"}
{"text": "Our work is also the first attempt to use the same automatically - learned grammar for both parsing and generation .Unlike previous systems that require manually - constructed grammars and lexicons , our systems require much less knowledge engineering and can be easily ported to other languages and domains .", "label": "", "metadata": {}, "score": "36.766968"}
{"text": "The design of the ontology - based parser is based on the premise that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .", "label": "", "metadata": {}, "score": "36.794144"}
{"text": "In recent years there has been considerable interest in corpus - based methods for constructing natural language parsers .These empirical approaches replace hand - crafted grammars with linguistic models acquired through automated training over language corpora .A common thread among such methods to date is the use of propositional or probablistic representations for the learned knowledge .", "label": "", "metadata": {}, "score": "36.84187"}
{"text": "This would result in increased efficiency throughout the system .Below , such an extension is described .It is essentially a simplified version of the grammars formulated and characterized as Local Grammars in Ross ( 1981 ) and Saenz ( 1982 ) .", "label": "", "metadata": {}, "score": "36.89038"}
{"text": "This paper presents an approach for inducing transformation rules that map natural - language sentences into a formal semantic representation language .The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .", "label": "", "metadata": {}, "score": "36.984123"}
{"text": "Additionally , semantic feature compatibility checking is not possible with Jensen 's system .U.S. Pat .No .5,721,938 to Stuckey discloses a parsing technique , which organizes natural language into symbolic complexes , which treat all words as either nouns or verbs .", "label": "", "metadata": {}, "score": "37.001022"}
{"text": "Unlike previous work on projecting syntactic resources , we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers .The projected parsers from our system result in state - of - the - art performance when compared to previously studied unsupervised and projected parsing systems across eight different languages .", "label": "", "metadata": {}, "score": "37.021725"}
{"text": "The first submission , the highest ranked constituency parsing system , uses a combination of PCFG - LA product grammar parsing and self - training .In the second submission , also a constituency parsing ... \" .The DCU - Paris13 team submitted three systems to the SANCL 2012 shared task on parsing English web text .", "label": "", "metadata": {}, "score": "37.133095"}
{"text": "The parser is supplied with 5 Chinese grammars ( and , with access to suitable training data , you could train other versions ) .You can find them inside the supplied stanford - parser- YYYY - MM - DD -models.jar file ( in the GUI , select this file and then navigate inside it ; at the command line , use jar -tf to see its contents ) .", "label": "", "metadata": {}, "score": "37.152203"}
{"text": "In general , with appropriate grammars loaded , you can parse with and ask for output of the PCFG , ( untyped ) dependency , or factored parsers .For English , although the grammars and parsing methods differ , the average quality of englishPCFG.ser.gz and englishFactored.ser.gz is similar , and so many people opt for the faster englishPCFG.ser.gz , though englishFactored.ser.gz sometimes does better because it does include lexicalization .", "label": "", "metadata": {}, "score": "37.209145"}
{"text": "Preliminary experimental results show that this system can learn correct and useful mappings .The correctness is evaluated by comparing a known lexicon to one learned from the training input .The usefulness is evaluated by examining the effect of using the lexicon learned by WOLFIE to assist a parser acquisition system , where previously this lexicon had to be hand - built .", "label": "", "metadata": {}, "score": "37.359684"}
{"text": "Natural language interfaces to computer systems that have been constructed employ a grammar which characterizes the set of acceptable input strings .A parser then access this grammar to produce a parse tree ( parse trees for ambiguous input ) for the input string .", "label": "", "metadata": {}, "score": "37.467514"}
{"text": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .", "label": "", "metadata": {}, "score": "37.55079"}
{"text": "This is identical to the sentence produced above , and results in the same parse tree , and the same predicate structure .Thus , when the ontological parser in this example embodiment receives this question , it generates a predicate identical to that from a declarative sentence , and they can be matched .", "label": "", "metadata": {}, "score": "37.61943"}
{"text": "In this proposal , we present a new approach to semantic parsing based on string - kernel - based classification .Our system takes natural language sentences paired with their formal meaning representations as training data .For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .", "label": "", "metadata": {}, "score": "37.740387"}
{"text": "In this paper we present a novel approach for inducing word alignments from sentence aligned data .We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for t ... \" .", "label": "", "metadata": {}, "score": "37.77215"}
{"text": "In our method the first , monolingual view consists of supervised predictors learned separately for each language .The second , bilingual view consists of log - linear predictors learned over both languages on bilingual text .Our training procedure estimates the parameters of the bilingual model using the output of the monolingual model , and we show how to combine the two models to account for dependence between views .", "label": "", "metadata": {}, "score": "37.912743"}
{"text": "# # STR84 # # .To do predictive parsing with a grammar like the one described above , in addition to calculating the reachability matrix for the context - free portions of the grammar rules , the percolation and blocking rules must be taken into account .", "label": "", "metadata": {}, "score": "38.07338"}
{"text": "The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .Ontological parsing is a grammatical analysis technique built on the proposition that the most useful information that can be extracted from a sentence is the set of concepts within it , as well as their formal relations to each other .", "label": "", "metadata": {}, "score": "38.079605"}
{"text": "None of the previous work in the field claims the advantages of portability that the present system offers : . an end user can construct his own natural language using an interactive system .he can finetune the interface by specidying which tables will be covered , the access rights to those tables , the attributes to be covered and the joins that the natural language system will support .", "label": "", "metadata": {}, "score": "38.080376"}
{"text": "Except for very small grammars , this first solution would require a prohibitive amount of storage for the reachability matrix .A second solution is to do the same the calculation at the point where the reachability information is required rather than prestoring the answer in the reachability matrix .", "label": "", "metadata": {}, "score": "38.105736"}
{"text": "As long as grammatical roles can be identified , the present system and method can be easily adapted to any language .For example , certain case - marked languages , such as Japanese or German , can be parsed through a grammar which simply records the grammatical relationships encoded by particular markers , and the resulting output is still compatible with the parsing results achieved for other languages .", "label": "", "metadata": {}, "score": "38.257774"}
{"text": "The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}, "score": "38.261864"}
{"text": "The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}, "score": "38.261864"}
{"text": "The implementation of these experts , once their function has been defined , is quite simple .The critical part which should be noted is that , in translation from a partial parse to a list of displayed items , the lexicon must be modified to generate non - word items at this point .", "label": "", "metadata": {}, "score": "38.367737"}
{"text": "The main innovation of the algorithm is its use of state - of - the - art statistical machine translation techniques .A statistical word alignment model is used for lexical acquisition , and the parsing model itself can be seen as an instance of a syntax - based translation model .", "label": "", "metadata": {}, "score": "38.37274"}
{"text": "The ontology - based parser is designed around the idea that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .", "label": "", "metadata": {}, "score": "38.419792"}
{"text": "This limits the versatility of the techniques .U.S. Pat .No .4,864,502 to Kucera et al . discloses a device that tags and parses natural - language sentences , and provides interactive facilities for grammar correction by an end user .", "label": "", "metadata": {}, "score": "38.454132"}
{"text": "We highlight the use of this resource via two experiments , including one that reports competitive accuracies for unsupervised grammar induction without gold standard part - of - speech tags .We present an online learning algorithm for training structured prediction models with extrinsic loss functions .", "label": "", "metadata": {}, "score": "38.455856"}
{"text": "For example , noun phrases might be split into subcategories for subjects and objects , singular and plural , and so on .This splitting process admits an efficient incremental inference scheme which reduces parsing times by orders of magnitude .Furthermore , it produces the best parsing accuracies across an array of languages , in a fully language - general fashion .", "label": "", "metadata": {}, "score": "38.49193"}
{"text": "When the model is finished training , or when you want to test one of the intermediate models , you can run it using the standard LexicalizedParser commands .In our experiments , we found that simpler PCFG models actually make better underlying PCFG models .", "label": "", "metadata": {}, "score": "38.639603"}
{"text": "A brief demo program included with the download will demonstrate how to load the tool and start processing text .When using this demo program , be sure to include all of the appropriate jar files in the classpath .For part - of - speech tags and phrasal categories , this depends on the language and treebank on which the parser was trained ( and was decided by the treebank producers not us ) .", "label": "", "metadata": {}, "score": "38.660984"}
{"text": "We present experiments with sequence models on part - of - speech tagging and named entity recognition tasks , and with syntactic parsers on dependency parsing and machine translation reordering tasks .Low - latency solutions for syntactic parsing are needed if parsing is to become an integral part of user - facing natural language applications .", "label": "", "metadata": {}, "score": "38.849155"}
{"text": "We show that the automatically induced latent variable grammars of Petrov et al .2006 vary widely in their underlying representations , depending on their EM initialization point .We use this to our advantage , combining multiple automatically learned grammars into an unweighted product model , which gives significantly improved performance over state - of - the - art individual grammars .", "label": "", "metadata": {}, "score": "38.87308"}
{"text": "Finally , we test the system on an alternate sentence representation , and on a set of large , artificial corpora with varying levels of ambiguity and synonymy .One difficulty in using machine learning methods for building natural language interfaces is building the required annotated corpus .", "label": "", "metadata": {}, "score": "38.891518"}
{"text": "Unlike previous work , our final model does not require any additional resources at run - time .Compared to a state - of - the - art approach , we achieve more than 20 % relative error reduction .Additionally , we annotate a corpus of search queries with part - of - speech tags , providing a resource for future work on syntactic query analysis .", "label": "", "metadata": {}, "score": "38.910248"}
{"text": "An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job - search queries .ML ID : 75 .An Inductive Logic Programming Method for Corpus - based Parser Construction [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney January 1997 .", "label": "", "metadata": {}, "score": "39.02002"}
{"text": "Traditional approaches to parsing are highly complex and problem specific .Recently , Sutskever et al .( 2014 ) presented a task - agnostic method for learning to map input sequences to output sequences that achieved strong results on a large scale machine translation problem .", "label": "", "metadata": {}, "score": "39.127808"}
{"text": "When more than one parser rule can be applied , and/or when more than one rule of the grammar can be applied through parser rule 1 , alternative parsing paths must be followed .Eventually , all of the alternative parsing paths will result in either successful or unseccessful parses .", "label": "", "metadata": {}, "score": "39.143776"}
{"text": "WSJ data ( Petrov and Klein , 2007 ; Foster , 2010 ) .The parser uses the English signature list described in Attia et al ( 2010 ) to assign partof - speech tags to unknown words . \" ...Domain adaptation is an important task in order for NLP systems to work well in real applications .", "label": "", "metadata": {}, "score": "39.17932"}
{"text": "However , the intended output of the parser is the set of predicate structures that it builds for each sentence , and so the preferred parse tree receiver is a software module called a parse tree converter , which extracts predicate structures from the parse trees .", "label": "", "metadata": {}, "score": "39.21495"}
{"text": "Error in Language , . which , although accurate , is not likely to inspire confidence in the end - user of the compiler of which the generated parser is a part .5.4 Table Representation and Compaction .The tables for both top - down and bottom - up parsing may be quite large for typical programming languages .", "label": "", "metadata": {}, "score": "39.316803"}
{"text": "We focus on two important sub - tasks , semantic parsing and tactical generation .The key idea is that both tasks can be treated as the translation between natural languages and formal meaning representation languages , and therefore , can be performed using state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}, "score": "39.401543"}
{"text": "There is n't a separate included tagger ; the parser does POS tagging as part of parsing .Yes , you can .You can use the main method of EnglishGrammaticalStructure ( for English , or the corresponding class for Chinese ) .", "label": "", "metadata": {}, "score": "39.54499"}
{"text": "Invited paper .Semantic parsing is the task of mapping a natural language sentence into a complete , formal meaning representation .Over the past decade , we have developed a number of machine learning methods for inducing semantic parsers by training on a corpus of sentences paired with their meaning representations in a specified formal language .", "label": "", "metadata": {}, "score": "39.590324"}
{"text": "The parsing and generation algorithms learn all of their linguistic knowledge from annotated corpora , and can handle natural - language sentences that are conceptually complex .A nice feature of our algorithms is that the semantic parsers and tactical generators share the same learned synchronous grammars .", "label": "", "metadata": {}, "score": "39.63749"}
{"text": "They can also provide insight into important issues in human language acquisition .However , within AI , computational linguistics , and machine learning , there has been relatively little research on developing systems that learn such semantic parsers .This paper briefly reviews our own work in this area and presents semantic - parser acquistion as an important challenge problem for AI .", "label": "", "metadata": {}, "score": "39.74766"}
{"text": "The second method is to perform research from the ground up in defining an ontology , assigning elements on an as - needed basis .Since minimal representation size is a main goal of parameterizing the ontology , one would want to eliminate many of the redundancies found in general - purpose ontologies such as WordNet .", "label": "", "metadata": {}, "score": "39.78801"}
{"text": "The parser of the Stuckey system is only suitable for grammar - checking applications .U.S. Pat .No .5,960,384 to Brash discloses a parsing method and apparatus for symbolic expressions of thought such as English - language sentences .The parser of the Brash system assumes a strict compositional semantics , where a sentence 's interpretation is the sum of the lexical meanings of nearby constituents .", "label": "", "metadata": {}, "score": "39.790443"}
{"text": "For most natural language processing tasks , a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well - formed strings .This paper reviews our work on using inductive logic programming methods to learn deterministic shift - reduce parsers that translate natural language into a semantic representation .", "label": "", "metadata": {}, "score": "39.833687"}
{"text": "We present several models to this end ; in particular a partially observed conditional random field model , where coupled token and type constraints provide a partial signal for training .Averaged across eight previously studied Indo - European languages , our model achieves a 25 % relative error reduction over the prior state of the art .", "label": "", "metadata": {}, "score": "39.98664"}
{"text": "You can give the options -outputFormat typedDependencies or -outputFormat typedDependenciesCollapsed to get typed dependencies ( or grammatical relations ) output ( for English and Chinese only , currently ) .You can print out lexicalized trees ( head words and tags at each phrasal node with the -outputFormatOptions lexicalize option .", "label": "", "metadata": {}, "score": "40.051086"}
{"text": "Most recent work on semantic analysis of natural language has focused on ' ' shallow ' ' semantics such as word - sense disambiguation and semantic role labeling .Our work addresses a more ambitious task we call semantic parsing where natural language sentences are mapped to complete formal meaning representations .", "label": "", "metadata": {}, "score": "40.065437"}
{"text": "In addition , our discriminative approach integrally admits features beyond local tree configurations .We present a multi - scale training method along with an efficient CKY - style dynamic program .On a variety of domains and languages , this method produces the best published parsing accuracies with the smallest reported grammars .", "label": "", "metadata": {}, "score": "40.111366"}
{"text": "The model is formally a latent variable CRF grammar over trees , learned by iteratively splitting grammar productions ( not categories ) .Different regions of the grammar are refined to different degrees , yielding grammars which are three orders of magnitude smaller than the single - scale baseline and 20 times smaller than the split - and - merge grammars of Petrov et al .", "label": "", "metadata": {}, "score": "40.116653"}
{"text": "First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .", "label": "", "metadata": {}, "score": "40.150406"}
{"text": "No .5,386,406 to Hedin et al . discloses a system for converting natural - language expressions into a language - independent conceptual schema .The output of the Hedin et al . system is not suitable for use in a wide variety of applications ( e.g. machine translation , document summarization , categorization ) .", "label": "", "metadata": {}, "score": "40.207237"}
{"text": "The system and method of the present invention isolates predicate - argument relationships into a consistent format regardless of text types .The predicate - argument relationships can be used in search , grammar - checking , summarization , and categorization applications , among others .", "label": "", "metadata": {}, "score": "40.22988"}
{"text": "Core grammar translations to SQL has been prototyped by CSL for DSG .Extensions to handle other aggregate operators like TOTAL , and format specifying operations like ORDERing rows are being added .Subject to prototyping , the grammar of conjunction may change .", "label": "", "metadata": {}, "score": "40.24552"}
{"text": "However , I believe that logical approaches may have the most relevance and impact at the level of semantic interpretation , where a logical representation of sentence meaning is important and useful .We have explored the use of inductive logic programming for learning parsers that map natural - language database queries into executable logical form .", "label": "", "metadata": {}, "score": "40.246464"}
{"text": "( In fact , we now also have translations to SQL for our core grammar / lexicon . )The prototype assumes a fixed set of parameters for substitution , though even now extensions are being made to the parameter list .", "label": "", "metadata": {}, "score": "40.25114"}
{"text": "The translations in the lexical entries in the prototype function that follows are translations to CSL 's relational dbms at present .Whenever interfacing to a new target database system , only this portion need be re - written .The lexicon is extensible .", "label": "", "metadata": {}, "score": "40.33972"}
{"text": "These rules are not to be interpreted as assigning feature values .They are , instead , well - formedness conditions which indicate whether a subtree is valid , according to the grammar .As an example of the feature mechanism in action , consider a hypothetical language with the following properties .", "label": "", "metadata": {}, "score": "40.37403"}
{"text": "The WELL - FORMEDNESS - TEST was used in the development of the GUIDED SQL interface as well as in debugging the various core grammar / lexicon pairs , specifically the ones with translations to SQL and the lisp machine relational dbms .", "label": "", "metadata": {}, "score": "40.422966"}
{"text": "I first present a historical view of the shifting emphasis of research on various tasks in natural language processing and then briefly review our own work on learning for semantic interpretation .I will then attempt to encourage others to study such problems and explain why I believe logical approaches have the most to offer at the level of producing semantic interpretations of complete sentences .", "label": "", "metadata": {}, "score": "40.45135"}
{"text": "Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing user - friendly natural language interfaces to computing systems .Most of the research in natural language understanding , however , has mainly focused on shallow semantic analysis like case - role analysis or word sense disambiguation .", "label": "", "metadata": {}, "score": "40.469368"}
{"text": "Thus , using the make - portable - interface function , a large number of portable specifications can be stored , and each portable specification can be rapidly constructed into the required grammar and lexicon when that particular natural language interface is called upon .", "label": "", "metadata": {}, "score": "40.482574"}
{"text": "Such lexicon compilation requires highly reliable predicate - argument structures to practically contribute to Natural Language Processing ( NLP ) applications , such as paraphrasing , text entailment , and machine translation .We first apply chunking to raw corpora and then extract reliable chunks to ensure that high - quality predicate - argument structures are obtained from the chunks .", "label": "", "metadata": {}, "score": "40.545547"}
{"text": "A static test of the well - formedness of generated grammars and lexicons in included in Appendix A ( the function call WELL - FORMEDNESS - TEST ) .With it , we can show that generated interfaces are statically correct .", "label": "", "metadata": {}, "score": "40.55154"}
{"text": "In order to do this , the parser must be able to begin parsing as soon as the first word or phrase is input .It can not , as the parsers which have generally been employed in prior art natural language understanding systems do , wait until the entire sentence is input before it begins to parse .", "label": "", "metadata": {}, "score": "40.758137"}
{"text": "Then we will briefly discuss menu - based grammar - driven interfaces .Then we will relate these to the invention and discuss known prior art as it concerns automatically generating interfaces to a database .INTRODUCTION .Natural language interfaces to software fall into two categories : ( 1 ) those based on pseudo - English , where a user must learn a command language that is English - like .", "label": "", "metadata": {}, "score": "40.822426"}
{"text": "Nonetheless , the resulting grammars encode many linguistically interpretable patterns and give the best published parsing accuracies on three German treebanks .We demonstrate that log - linear grammars with latent variables can be practically trained using discriminative methods .Central to efficient discriminative training is a hierarchical pruning procedure which allows feature expectations to be efficiently approximated in a gradient - based procedure .", "label": "", "metadata": {}, "score": "40.888832"}
{"text": "Because we do not have gold - standard references for training a secondary conditional reranker , we incorporate weak supervision of evaluations against the perceptual world during the process of improving model performance .All these approaches are evaluated on the two publicly available domains that have been actively used in many other grounded language learning studies .", "label": "", "metadata": {}, "score": "40.896652"}
{"text": "Our best results show a 26-fold speedup compared to a sequential C implementation .We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data .We first demonstrate that delexicalized parsers can be directly transferred between languages , producing significantly higher accuracies than unsupervised parsers .", "label": "", "metadata": {}, "score": "40.976162"}
{"text": "Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations .Finally , we show that hybridizing these two approaches results in still more accurate generation systems .Automatic and human evaluation of generated sentences are presented across two domains and four languages .", "label": "", "metadata": {}, "score": "41.07768"}
{"text": "In lisp : . it finds the following problems : .In lisp : .In lisp : .In lisp : . in lisp : .The significance of the WELL - FORMEDNESS - TEST is as follows : As simple as these tests are , I know of no other system that employs such static tests to see if the grammar is well - formed .", "label": "", "metadata": {}, "score": "41.085716"}
{"text": "If you want to obtain the same results , you can either POS - tag your corpus before tagging it ( see # 12 ) or you can disable the POS tagger in CoreNLP by updating the list of annotators : .", "label": "", "metadata": {}, "score": "41.152752"}
{"text": "We have developed methods for automatically learning semantic parsers from annotated corpora using inductive logic programming and other learning methods .We have explored learning semantic parsers for mapping natural - language sentences to case - role analyses , formal database queries , and formal command languages ( i.e. the Robocup coaching language for use in advice - taking learners ) .", "label": "", "metadata": {}, "score": "41.20067"}
{"text": "If you call the parser programmatically and then convert the parse tree to a list of grammatical relations , you have to call setGenerateOriginalDependencies(true ) on your instance of TreebankLanguagePack as shown in the following snippet : .Alternatively , if you use SemanticGraphFactory.makeFromTree ( ) to build a SemanticGraph from a constitueny tree , then use the following method with originalDependencies set to true .", "label": "", "metadata": {}, "score": "41.266346"}
{"text": "This answer is specific to English .It mostly applies to other languages although some components are missing in some languages .The file englishPCFG.ser.gz comprises just an unlexicalized PCFG grammar .It is basically the parser described in the ACL 2003 Accurate Unlexicalized Parsing paper .", "label": "", "metadata": {}, "score": "41.27037"}
{"text": "The remainder of this section describes in detail how a portable specification data structure ( already computed at this point ) is used to generate a semantic grammar and lexicon from a core grammar and lexicon .First , the function MAKE - PORTABLE - INTERFACE is described .", "label": "", "metadata": {}, "score": "41.411133"}
{"text": "The modular design of the ontological parser permits the use of any part - of - speech - tagged ontology , with only minimal rewriting of the lexer and parser to accommodate format - specific issues .However , maximum benefits are recognized through the use of a parameterized ontology , an innovation heretofore unavailable in any parser or information retrieval system .", "label": "", "metadata": {}, "score": "41.493187"}
{"text": "( Such grammars are known in the art as \" semantic grammars \" . )For convenience , we restate parser rule 1 again : .The second rule of the parser shows how the place holding symbol t is used to indicate that a perfected partial parse can be transferred from stack beta to stack alpha : .", "label": "", "metadata": {}, "score": "41.619995"}
{"text": "ML ID : 273 . \"Grounded \" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts .Borschinger et al .( 2011 ) introduced an approach to grounded language learning based on unsupervised PCFG induction .", "label": "", "metadata": {}, "score": "41.683617"}
{"text": "The previous techniques of natural language processing are often limited to the performance of a particular purpose and can not be used for other purposes .Conventional parsing techniques may be designed to function as part of a grammar checking system , but can not function as part of a search engine , summarization application , or categorization application .", "label": "", "metadata": {}, "score": "41.72254"}
{"text": "Given this grammar , an LALR parser generator would fail to produce a parser because of a shift / reduce conflict .The modified LALR parser generator algorithm that the ontological parser of the present invention uses must be aware of the possibility of more than one possible course of action , and should recursively try both actions .", "label": "", "metadata": {}, "score": "41.741604"}
{"text": "This ' universal ' treebank is made freely available in order to facilitate research on multilingual dependency parsing .We consider the construction of part - of - speech taggers for resource - poor languages .Recently , manually constructed tag dictionaries from Wiktionary and dictionaries projected via bitext have been used as type constraints to overcome the scarcity of annotated data in this setting .", "label": "", "metadata": {}, "score": "41.777782"}
{"text": "Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing computing systems that understand natural language input .This thesis presents a new machine learning approach for semantic parsing based on string - kernel - based classification .", "label": "", "metadata": {}, "score": "41.800648"}
{"text": "The system learns to parse and generate commentaries without any engineered knowledge about the English language .Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games .The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model .", "label": "", "metadata": {}, "score": "41.862694"}
{"text": "In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .Active learning methods ( Cohn , Atlas , & Ladner , 1994 ) attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .", "label": "", "metadata": {}, "score": "41.881294"}
{"text": "For a natural language system that needed to handle all paraphrases ( as traditional systems must ) , context - free grammars are unacceptable .They do not have enough power to characterize a fragment of natural language that is very large .", "label": "", "metadata": {}, "score": "41.907116"}
{"text": "The advantages of the present system are the provision of a semantic representation of comparable utility with significantly reduced processing requirements , and no need to train the system to produce semantic representations of text content .The system and method for ontological parsing of natural language according to the present invention has a far simpler analysis process than conventional parsing techniques , and utilizes a dictionary containing tags with syntactic information .", "label": "", "metadata": {}, "score": "41.935413"}
{"text": "See the Related Reading section at the end of this chapter , especially Fischer and LeBlanc ( 1988 ) and Hammond and Rayward - Smith(1984 ) .5.3.2 Generator Errors .One particularly insidious error occurs when a syntax error is made in the BNF which is input to the parser generator .", "label": "", "metadata": {}, "score": "42.13011"}
{"text": "Empirical results show that the learned parsers generalize well to novel sentences and out - perform previous approaches based on connectionist techniques .ML ID : 25 .Learning Search - Control Heuristics for Logic Programs : Applications to Speedup Learning and Language Acquisition [ Details ] [ PDF ] John M. Zelle March 1993 .", "label": "", "metadata": {}, "score": "42.166443"}
{"text": "There is a call , setConstraints , which you can make before using the LexicalizedParserQuery to run the parser .If you add a ParserConstraint object spanning a set of words , the parser will only produce parse trees which include that span of words as a constituent .", "label": "", "metadata": {}, "score": "42.16876"}
{"text": "The ontology - based parser contains functional components for receiving documents in a plurality of formats , tokenizing them into instances of concepts from an ontology , and assembling the resulting concepts into predicates .The ontological parser has two major functional elements , a sentence lexer and a parser .", "label": "", "metadata": {}, "score": "42.22775"}
{"text": "Previous sentence segmentation systems have typically been very local , using low - level prosodic and lexical features to independently decide whether or not to segment at each word boundary position .In this work , we leverage global syntactic information from a syn- tactic parser , which is better able to capture long distance depen- dencies .", "label": "", "metadata": {}, "score": "42.252487"}
{"text": "We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .A TAT is capable of generating both terminals and non - terminals and per - forming reordering at both low and high levels .", "label": "", "metadata": {}, "score": "42.289997"}
{"text": "We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .A TAT is capable of generating both terminals and non - terminals and per - forming reordering at both low and high levels .", "label": "", "metadata": {}, "score": "42.289997"}
{"text": "The grammars and lexicons produced by the MAKE - PORTABLE - INTERFACE function are for use with such a system and would be very inadequate in traditional systems .The principal reason is that they are purposely engineered to be simple , to be expressive , and to provide only a limited set of grammatical and lexical ways of expressing a statement .", "label": "", "metadata": {}, "score": "42.325386"}
{"text": "Initial experiments show that this approach is able to construct accurate parsers which generalize well to novel sentences and significantly outperform previous approaches to learning case - role mapping based on connectionist techniques .Planned extensions of the general framework and the specific applications as well as plans for further evaluation are also discussed .", "label": "", "metadata": {}, "score": "42.332123"}
{"text": "The paper gives a very efficient algorithm to compute it .This kernel is also an improvement over the word subsequence kernel because it only counts linguistically meaningful word subsequences which are based on word dependencies .It overcomes some of the difficulties encountered by syntactic tree kernels as well .", "label": "", "metadata": {}, "score": "42.338284"}
{"text": "However , the presently - preferred embodiment uses a parser which will be described in great detail .As discussed above , the end result which the present invention seeks to achieve is to permit the user to input well - understood sentences in a convenient language , which is preferably a subset of a natural language ( such as English ) .", "label": "", "metadata": {}, "score": "42.42094"}
{"text": "One could imagine experts used in other ways as well : a large grammar could be partitioned and experts which were executed for effect could be used to swap from one partition to another .The function .WELL - FORMEDNESS - TEST ( nlmenu - grammar , nlmenu - lexicon ) . invokes a static collection of tests to find bugs in either an automatically generated nlmenu grammar and lexicon pair of a manually - generated one .", "label": "", "metadata": {}, "score": "42.42759"}
{"text": "The annotations are produced automatically with statistical models that are specifically adapted to historical text .The corpus will facilitate the study of linguistic trends , especially those related to the evolution of syntax .Syntactic analysis of search queries is important for a variety of information- retrieval tasks ; however , the lack of annotated data makes training query analysis models difficult .", "label": "", "metadata": {}, "score": "42.46128"}
{"text": "The portable spec will be extended to capture more semantic situations .The portable spec is extensible , but changes to it affect both the core grammar and lexicon and the Build Interface mentioned in the next subsection .Some of the planned extensions include : .", "label": "", "metadata": {}, "score": "42.468857"}
{"text": "They differ only in the generated table .The L in LR indicates that the string is parsed from left to right ; the R indicates that the reverse of a right derivation is produced .Given a grammar , we want to develop a deterministic bottom - up method for parsing legal strings described by the grammar .", "label": "", "metadata": {}, "score": "42.658417"}
{"text": "The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .A system for ontological parsing that converts natural - language text into predicate - argument format comprising : . a sentence lexer for converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and .", "label": "", "metadata": {}, "score": "42.6612"}
{"text": "No .5,146,496 to Jensen discloses a technique for identifying predicate - argument relationships in natural language text .The Jensen system must create intermediate feature structures to store semantic roles , which are then used to fill in predicates whose deep structures have missing arguments .", "label": "", "metadata": {}, "score": "42.702934"}
{"text": "system checks only for syntactic correctness .U.S. Pat .No .4,914,590 to Loatman et al . discloses a natural language understanding system .The goal of the Loatman et al . system is to provide a formal representation of the context of a sentence , not merely the sentence itself .", "label": "", "metadata": {}, "score": "42.705112"}
{"text": "The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .The learned transformation rules incrementally map a natural - language sentence or its syntactic parse tree into a parse - tree for the target formal language .", "label": "", "metadata": {}, "score": "42.719807"}
{"text": "I will first present a system we completed that can describe events in RoboCup 2D simulation games by learning only from sample language commentaries paired with traces of simulated activities without any language - specific prior knowledge .By applying an EM - like algorithm , the system was able to simultaneously learn a grounded language model as well as align the ambiguous training data .", "label": "", "metadata": {}, "score": "42.792618"}
{"text": "A simple extension using transductive SVMs enables the system to do semi - supervised learning and improve its performance utilizing unannotated sentences which are usually easily available .Another extension involving EM - like retraining makes the system capable of learning under ambiguous supervision in which the correct meaning representation for each sentence is not explicitly given , but instead a set of possible meaning representations is given .", "label": "", "metadata": {}, "score": "42.810787"}
{"text": "In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .The output predicate structures contain numeric tags that represent the location of each concept within the ontology .", "label": "", "metadata": {}, "score": "42.813713"}
{"text": "In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .The output predicate structures contain numeric tags that represent the location of each concept within the ontology .", "label": "", "metadata": {}, "score": "42.813713"}
{"text": "In contrast , for experts , the code is executed and it can do arbitrary things but it must return a pair of values : a phrase to add to the sentence being formed and a translation .Since it should be possible to rubout over experts , expert code should not have side - effects .", "label": "", "metadata": {}, "score": "42.816734"}
{"text": "Besides being robust , this approach is also flexible and able to learn under a wide range of supervision , from extra to weaker forms of supervision .It can easily utilize extra supervision given in the form of syntactic parse trees for natural language sentences by using a syntactic tree kernel instead of a string kernel .", "label": "", "metadata": {}, "score": "42.857887"}
{"text": "Demos of learned natural - language database interfaces : .Tutorial on semantic parsing presented at ACL 2010 : .Using natural language to write programs is a touchstone problem for computational linguistics .We present an approach that learns to map natural - language descriptions of simple \" if - then \" rules to executable code .", "label": "", "metadata": {}, "score": "42.858665"}
{"text": "The ability to predict the set of possible nth words of a sentence , given the first n-1 words of the sentence is the final modification necessary to enable this parser to be used for menu - based natural language understanding .", "label": "", "metadata": {}, "score": "42.86676"}
{"text": "The sentence receiver is a software abstraction that may be realized through any number of techniques .The parser 230 takes a sequence of instances from an ontology , in the form of a sentence , and converts them into a collection of parse trees .", "label": "", "metadata": {}, "score": "42.889984"}
{"text": "The following is an example of a sentence and demonstrates both how it is parsed as a sentence within a document , and how a question to an information retrieval system would produce matching predicates to retrieve the document containing this sentence .", "label": "", "metadata": {}, "score": "42.893562"}
{"text": "This is because the augmentations need to be taken into account when predicting the items that can come next .The present invention can be applied to augmented grammars as discussed above , but the capability is not included in the presently - preferred embodiment .", "label": "", "metadata": {}, "score": "42.89578"}
{"text": "A simplified version of the parser will first be described , and then the modifications which permit word - at - a - time parsing and prediction will be described .The preferred parser can be specified in terms of nonstandard turing machine instructions , as described by Griffiths and Petrick , which operate on the upper elements of an alpha stack and a beta stack in accordance with the current state of the upper elements of the two stacks .", "label": "", "metadata": {}, "score": "42.89711"}
{"text": "Four of the parsers assume input that has already been word segmented , while the fifth does word segmentation internal to the parser .This is discussed further below .The parser also comes with 3 Chinese example sentences , in files whose names all begin with chinese .", "label": "", "metadata": {}, "score": "42.95227"}
{"text": "We obtain gains in ... \" .Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .We present an algorithm for identifying and deleting incorrect word alignment links , using features of the extracted rules .", "label": "", "metadata": {}, "score": "43.032173"}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .", "label": "", "metadata": {}, "score": "43.10402"}
{"text": "In other cases , syntactic ambiguity will result in multiple possible parses .The parser should not generate any output trees for a sentence that does not reduce according to the rules ; rather it should generate a tree for every possible parse of an ambiguous sentence .", "label": "", "metadata": {}, "score": "43.10494"}
{"text": "# # STR79 # # .Any arbitrary context - free grammar is permitted as input to the parser except for those grammars containing two classes of rules .The problem with the first class of rules is that they make it very difficult for the predictive version of the aglorithm to determine all and only those words that can come next in a sentence .", "label": "", "metadata": {}, "score": "43.11691"}
{"text": "Similarly , for information retrieval purposes , an embodiment of the ontological parser optimized for queries may make use of all these filters , but add a pseudo - predicate filter and a pseudo - concept filter .The stop word filter removes stop words from sentences .", "label": "", "metadata": {}, "score": "43.12561"}
{"text": "The second question is how one can estimate NLP systems ' performance when gold standard on the test data does not exist .To answer the question , we extend the parsing prediction model in ( Ravi et al . , 2008 ) to provide prediction for word segmentation and POS tagging as well .", "label": "", "metadata": {}, "score": "43.19284"}
{"text": "His system interfaces to heirarchically structured collections of files .In his system , all domain - specific information is stored in the lexicon .He describes an experience of porting his natural language interface to a new domain database in 5 hours , which is quite good by the standards of the other systems mentioned above , but the process still involves an expert .", "label": "", "metadata": {}, "score": "43.196365"}
{"text": "Starting from a mono - phone model , we learn increasingly refined models that capture phone internal structures , as well as context - dependent variations in an automatic way .Our approaches reduces error rates compared to other baseline approaches , while streamlining the learning procedure .", "label": "", "metadata": {}, "score": "43.267998"}
{"text": "Experimental results are presented on learning to map English coaching instructions for Robocup soccer into an existing formal language for coaching simulated robotic agents .ML ID : 140 .Learning Semantic Parsers : An Important But Under - Studied Problem [ Details ] [ PDF ] Raymond J. Mooney In Papers from the AAAI 2004 Spring Symposium on Language Learning : An Interdisciplinary Perspective , 39 - -44 , Stanford , CA , March 2004 .", "label": "", "metadata": {}, "score": "43.365677"}
{"text": "The two models we present overcome such limitations by employing a learned semantic lexicon as a basic correspondence unit between NL and MR for PCFG rule generation .Finally , we present a method of adapting discriminative reranking to grounded language learning in order to improve the performance of our proposed generative models .", "label": "", "metadata": {}, "score": "43.366497"}
{"text": "Next , I present a PCFG induction model for grounded language learning that extends the model of Borschinger , Jones , and Johnson ( 2011 ) by utilizing a semantic lexicon .Our model overcomes such limitations by employing a semantic lexicon as the basic building block for PCFG rule generation .", "label": "", "metadata": {}, "score": "43.382645"}
{"text": "If the word exists within the ontology 140 , it is returned as an ontological entity ; if not , it is returned as a word tagged with default assumptions about its ontological status .In one embodiment , words are automatically assumed to be nouns ; however , the words may be other parts of speech .", "label": "", "metadata": {}, "score": "43.43508"}
{"text": "The associated code may not only be used to build structures associated with phrases , but may also be used for syntactic and semantic tests , printout actions ( for example for tracing ) , etc . during the parsing process .", "label": "", "metadata": {}, "score": "43.542145"}
{"text": "Semantic parsing is the construction of a complete , formal , symbolic meaning representation of a sentence .While it is crucial to natural language understanding , the problem of semantic parsing has received relatively little attention from the machine learning community .", "label": "", "metadata": {}, "score": "43.56345"}
{"text": "Future work includes extending the algorithm and performing tests on a more realistic corpus .ML ID : 56 .Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers [ Details ] [ PDF ] John M. Zelle PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , 1995 .", "label": "", "metadata": {}, "score": "43.56977"}
{"text": "Firstly , lexical items ( terminal nodes ) will have syntactic features associated with them .This idea is not new ( see , for example , Chomsky ( 1965 ) ) .In general , the values of syntactic features have been thought to be binary .", "label": "", "metadata": {}, "score": "43.57576"}
{"text": "For some sentences the parse tree output by the standalone parser and the tree output by the CoreNLP pipeline can be different .The reason for this is that if you run the CoreNLP pipeline with the default annotators , it will run a part - of - speech ( POS ) tagger before running the parser .", "label": "", "metadata": {}, "score": "43.601936"}
{"text": "The conversion code generally expects Penn Treebank style trees which have been stripped of functional tags and empty elements .This generally corresponds to the output of the Stanford , Charniak or Collins / Bikel parsers .The exception is that it gets value from the -TMP annotation on bare temporal NPs in order to recognize them as having temporal function ( tmod ) .", "label": "", "metadata": {}, "score": "43.63395"}
{"text": "Tokuume et al . , U.S. Pat .No .5,101,349 , discloses a natural language processing system that makes provisions for validating grammar from the standpoint of syntactic well - formedness , but does not provide facilities for validating the semantic well - formedness of feature structures .", "label": "", "metadata": {}, "score": "43.65485"}
{"text": "In a complete database - query application , parsers learned by CHILL outperform an existing hand - crafted system , demonstrating the promise of empricial techniques for automating the construction certain NLP systems .ML ID : 71 .Semantic Lexicon Acquisition for Learning Parsers [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney 1997 .", "label": "", "metadata": {}, "score": "43.67976"}
{"text": "We study this problem as a new task - multiple source parser adaptation .Our system trains on corpora from many different domains .It learns not only statistics of those domains but quantitative measures of domain differences and how those differences affect parsing accuracy .", "label": "", "metadata": {}, "score": "43.727364"}
{"text": "You can use it as follows : .There are several options , including one for batch - processing lots of files ; see the Javadoc documentation of the main method of PTBTokenizer .Parsing speed depends strongly on the distribution of sentence lengths - and on your machine , etc .", "label": "", "metadata": {}, "score": "43.735027"}
{"text": "A mixture grammar fit with the EM algorithm shows improvement over a single PCFG , both in parsing accuracy and in test data likelihood .We argue that this improvement comes from the learning of specialized grammars that capture non - local correlations .", "label": "", "metadata": {}, "score": "43.797836"}
{"text": "We take two popular dependency parsers - one graph - based and one transition - based - and compare results for both .Results show that using semisupervised learning in the form of self - training and co - training yields only very modest improvements in parsing accuracy .", "label": "", "metadata": {}, "score": "43.849308"}
{"text": "Automatically generated help can be added as a fifth component to each entry .What follows is a pseudo - coded version of the actual Lisp code describing MAKE - SEMANTIC - LEXICON .In the NLMENU system as implemented , experts are segments of code that are exeuctred as the query is being specified by the user .", "label": "", "metadata": {}, "score": "43.864655"}
{"text": "Compared to a previous generative model for semantic alignment , it also supports full semantic parsing .Experimental results on the Robocup sportscasting corpora in both English and Korean indicate that our approach produces more accurate semantic alignments than existing methods and also produces competitive semantic parsers and improved language generators .", "label": "", "metadata": {}, "score": "43.877544"}
{"text": "This paper presents a general framework , learning search - control heuristics for logic programs , which can be used to improve both the efficiency and accuracy of knowledge - based systems expressed as definite - clause logic programs .The approach combines techniques of explanation - based learning and recent advances in inductive logic programming to learn clause - selection heuristics that guide program execution .", "label": "", "metadata": {}, "score": "43.939293"}
{"text": "This paper presents approaches for automatically transforming a meaning representation grammar ( MRG ) to conform it better with the natural language semantics .It introduces grammar transformation operators and meaning representation macros which are applied in an error - driven manner to transform an MRG while training a semantic parser learning system .", "label": "", "metadata": {}, "score": "43.95635"}
{"text": "This translation is a portion of the meaning of a sentence in which the word appears .In order to properly combine the translations of the words in a sentence together , there is a rule associated with each context - free rule indicating the order in which the translations of the symbols on the right side of the arrow of a context - free rule are to be combined .", "label": "", "metadata": {}, "score": "43.988503"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 20 , wherein said parser filters remove parse trees that violate one of statistical and ontological criteria for well - formedness .", "label": "", "metadata": {}, "score": "44.03409"}
{"text": "The present invention provides an automatic interactive system whereby such an interface is constructed .A method for generating a context - free grammar comprising the steps of : .( a ) generating a domain - independent core grammar ; .", "label": "", "metadata": {}, "score": "44.081314"}
{"text": "A grammar to parse list expressions ( with empty associated code ) : .Nonterminals list elements element .Terminals atom ' ( ' ' ) ' .Rootsymbol list .When a grammar rule is used by the parser to parse ( part of ) the input string as a grammatical phrase , the associated code is evaluated , and the value of the last expression becomes the value of the parsed phrase .", "label": "", "metadata": {}, "score": "44.118668"}
{"text": "We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .The main innovation of WASP is its use of state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}, "score": "44.138763"}
{"text": "We use a publicly available structured output SVM to create a max - margin syntactic aligner with a soft cohesion constraint .The resulting aligner is the first , to our knowledge , to use a discriminative learning method to train an ITG bitext parser . ... rence for links to appear near one another ( Vogel et al .", "label": "", "metadata": {}, "score": "44.141308"}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .Training the system requires sentences annotated with augmented parse trees .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .", "label": "", "metadata": {}, "score": "44.1414"}
{"text": "Thus , the prohibition of such rules merely requires that these alternative grammatical treatments be used .A sample grammar and lexicon is provided below , as Appendix C. .Simpler and smaller grammars would result if the class of grammars allowed was extended to allow augmentations to be associated with the context - free rules .", "label": "", "metadata": {}, "score": "44.168156"}
{"text": "Self - training creates semi - supervised learners from existing supervised learners with minimal effort .We first show results on self - training for constituency parsing within a single domain .While self - training has failed here in the past , we present a simple modification which allows it to succeed , producing state - of - the - art results for English constituency parsing .", "label": "", "metadata": {}, "score": "44.18481"}
{"text": "We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process ( HDP ) .Our HDP - PCFG model allows the complexity of the grammar to grow as more training data is available .In addition to presenting a fully Bayesian model for the PCFG , we also develop an efficient variational inference procedure .", "label": "", "metadata": {}, "score": "44.213882"}
{"text": "With traditional parsers where the entire sentence must be input before any parsing is done , no parsing can be done while the user formulates and inputs his query .However , if processing begins as soon as the first word or phrase is input , then the time it takes for a user to input his sentence can be put to productive use .", "label": "", "metadata": {}, "score": "44.24595"}
{"text": "These grammar rules , called productions , specify language that the target parser is supposed to recognize .Each production indicates that a specific combination of input symbols , called terminals , and assembled groups of terminals , called non - terminals , can be assembled into a new non - terminal .", "label": "", "metadata": {}, "score": "44.333847"}
{"text": "Given this fixed network representation , we learn a final layer using the structured perceptron with beam - search decoding .On the Penn Treebank , our parser reaches 94.26 % unlabeled and 92.41 % labeled attachment accuracy , which to our knowledge is the best accuracy on Stanford Dependencies to date .", "label": "", "metadata": {}, "score": "44.404163"}
{"text": "A wide variety of grammar formalisms and parsing strategies have been developed .For all natural language systems , the user is required to type his question using the keyboard of a computer terminal .When the entire query has been received , the natural language interface processes the input .", "label": "", "metadata": {}, "score": "44.41799"}
{"text": "For a semantic parser to work well , conformity between natural language and meaning representation grammar is necessary .However meaning representation grammars are typically designed to best suit the application which will use the meaning representations with little consideration for how well they correspond to natural language semantics .", "label": "", "metadata": {}, "score": "44.424194"}
{"text": "These classifiers are further refined using EM - type iterations based on their performance on the training data .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .Our experiments on two real - world data sets that have deep meaning representations show that this approach compares favorably to other existing systems in terms of accuracy and coverage .", "label": "", "metadata": {}, "score": "44.42772"}
{"text": "We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser .Existing methods incrementally expand the lexicon by greedily adding entries , considering a single training datapoint at a time .We propose using corpus - level statistics for lexicon learning decisions .", "label": "", "metadata": {}, "score": "44.444756"}
{"text": "The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two languages .We develop a theory of binarization for synchronous context - free grammars and present a linear - time algorithm for binarizing synchronous rules when possible .", "label": "", "metadata": {}, "score": "44.5345"}
{"text": "SUMMARY OF THE INVENTION .The foregoing and other deficiencies are addressed by the present invention , which is directed to an ontology - based parser for natural language processing .More particularly , the present invention relates to a system that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}, "score": "44.542736"}
{"text": "It will determine whether or not a given string can be parsed into a tree dominated by the specified root node .The following addition is required to enable the parser to produce the parse tree(s ) for the input string .", "label": "", "metadata": {}, "score": "44.54373"}
{"text": "We also show that our techniques can be applied to full - scale parsing applications by demonstrating its effectiveness in learning state - split grammars .Treebank parsing can be seen as the search for an optimally refined grammar consistent with a coarse training treebank .", "label": "", "metadata": {}, "score": "44.57479"}
{"text": "Below are some statistics for 32-bit operation with the supplied englishPCFG and englishFactoredGrammars .We have parsed sentences as long as 234 words , but you need lots of RAM and patience .You can use the -outputFormat wordsAndTags option .", "label": "", "metadata": {}, "score": "44.603012"}
{"text": "This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with representations of their meaning , and allows for both synonymy and polysemy .", "label": "", "metadata": {}, "score": "44.634033"}
{"text": "You will need a collection of syntactically annotated data such as the Penn Treebank to train the parser .If they are not in the same format as currently supported Treebanks , you may need to write classes to read in the trees , etc .", "label": "", "metadata": {}, "score": "44.69705"}
{"text": "ML ID : 47 .Acquisition of a Lexicon from Semantic Representations of Sentences [ Details ] [ PDF ] Cynthia A. Thompson In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL-95 ) , 335 - 337 , Cambridge , MA , 1995 .", "label": "", "metadata": {}, "score": "44.70102"}
{"text": "ML ID : 130 .Acquiring Word - Meaning Mappings for Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Journal of Artificial Intelligence Research , 18:1 - 44 , 2003 .This paper focuses on a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .", "label": "", "metadata": {}, "score": "44.71808"}
{"text": "We describe experiments on learning latent variable grammars for various German treebanks , using a language - agnostic statistical approach .In our method , a minimal initial grammar is hierarchically refined using an adaptive split - and - merge EM procedure , giving compact , accurate grammars .", "label": "", "metadata": {}, "score": "44.730507"}
{"text": "We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for the use of arbitrary and overlapping features over these data .", "label": "", "metadata": {}, "score": "44.736526"}
{"text": "Specifically , an ini- tial hypothesis lattice is constrcuted using local features .Candidate sentences are then assigned syntactic language model scores .These global syntactic scores are combined with local low - level scores in a log - linear model .", "label": "", "metadata": {}, "score": "44.749058"}
{"text": "( 2 )Those based on the premise that a user should be allowed to express himself in any way that is natural to him and that the system will make sense of his input .Keyword extraction techniques suffice only in simple applications .", "label": "", "metadata": {}, "score": "44.77513"}
{"text": "We will describe the driver first , as usual , The method described here is a shift - reduce parsing method ; that is , we parse by shifting input onto the stack until we have enough to recognize an appropriate right - hand side of production .", "label": "", "metadata": {}, "score": "44.78913"}
{"text": "In the predicate representation scheme of the present invention , there are only a few distinct frames for predicate structures , as many as needed to cover the different numbers of arguments taken by different verbs .Predicates may be enhanced with selectional restriction information , which can be coded automatically for entire semantic classes of words , rather than on an individual basis , because of the ontological scheme .", "label": "", "metadata": {}, "score": "44.80947"}
{"text": "Building natural language parsing systems by hand is a tedious , error - prone undertaking .We build on previous research in automating the construction of such systems using machine learning techniques .The result is a combined system that learns semantic lexicons and semantic parsers from one common set of training examples .", "label": "", "metadata": {}, "score": "44.830833"}
{"text": "However , this hard constraint can also rule out correct alignments , and its utility decreases as alignment models become more ... \" .Word alignment methods can gain valuable guidance by ensuring that their alignments maintain cohesion with respect to the phrases specified by a monolingual dependency tree .", "label": "", "metadata": {}, "score": "44.84188"}
{"text": "Given any beta - gamma pair representing one of the parse paths active n-1 words of the sentence have been input , it is possible to determine the set of words that will allow that state to continue .To to this , look at the topmost symbol on stack beta of the tuple .", "label": "", "metadata": {}, "score": "44.847088"}
{"text": "Experimental results show that the number of examples needed to reach a given level of performance can be significantly reduced with this method .ML ID : 90 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixth Workshop on Very Large Corpora , Montreal , Quebec , Canada , August 1998 .", "label": "", "metadata": {}, "score": "44.89008"}
{"text": "In the future , we intend to pursue several directions in developing more accurate semantic parsing algorithms and automating the annotation process .This work will involve exploring alternative tree representations for better generalization in parsing .We also plan to apply discriminative reranking methods to semantic parsing , which allows exploring arbitrary , potentially correlated features not usable by the baseline learner .", "label": "", "metadata": {}, "score": "45.079662"}
{"text": "Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .", "label": "", "metadata": {}, "score": "45.110405"}
{"text": "SYNSEM also significantly improves results with limited training data , and is shown to be robust to syntactic errors .ML ID : 246 .Training a Multilingual Sportscaster : Using Perceptual Context to Learn Language [ Details ] [ PDF ] David L. Chen , Joohyun Kim , Raymond J. Mooney Journal of Artificial Intelligence Research , 37:397 - -435 , 2010 .", "label": "", "metadata": {}, "score": "45.11904"}
{"text": "It has been used ( in experimental settings ) by people who are not experts in natural language processing to create natural language interfaces to databases .Grosz offers no documentation to support a claim that usable , portable natural language interfaces result from TEAM .", "label": "", "metadata": {}, "score": "45.127693"}
{"text": "Therefore , the generators are said to be the inverse of the parsers , an elegant property that has been widely advocated .Furthermore , we show that our parsers and generators can handle formal meaning representation languages containing logical variables , including predicate logic .", "label": "", "metadata": {}, "score": "45.13173"}
{"text": "Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning .This work describes systems for detecting semantic categories present in news video .", "label": "", "metadata": {}, "score": "45.150192"}
{"text": "Overall , for parser generation the choice is between LALR(1 ) and LL(1 ) , with the decision often being made based upon the nature of a grammar .If a grammar already exists and it is LL(1 ) , then that is probably the method of choice .", "label": "", "metadata": {}, "score": "45.200966"}
{"text": "1 is a block diagram of the sentence lexer according to the present invention ; .FIG .2 is a block diagram of the parser according to the present invention ; .FIG .3 is a diagram showing two complete parse trees produced according to the present invention ; .", "label": "", "metadata": {}, "score": "45.225037"}
{"text": "See especially the sample invocation in the parser.lexparser package documentation .The included file makeSerialized.csh effectively documents how the included grammars were made .The included file ParserDemo.java gives a good first example of how to call the parser programmatically , including getting Tree and typedDependencies output .", "label": "", "metadata": {}, "score": "45.28383"}
{"text": "A more general facility for allowing users to specify arbitrary joins in planned .Phrasing the find - parts - whose part # is - equal to - the part # of - shipment would allow such joins .At present , the system does allow natural language update to the database .", "label": "", "metadata": {}, "score": "45.293983"}
{"text": "For example , in a search engine application , it may be useful to check whether or not a particular noun can serve as an argument of a predicate .The features of the noun should be more specific than the features of the argument position it is attached to .", "label": "", "metadata": {}, "score": "45.304703"}
{"text": "In addition , the test can be used as follows : One of the values returned by WELL - FORMEDNESS - TEST ( grammar , nil ) is a list of all lexical categories that the grammar writer must write lexical entries for .", "label": "", "metadata": {}, "score": "45.41413"}
{"text": "Semantic parsing , on the other hand , involves deep semantic analysis in which word senses , semantic roles and other components are combined to produce useful meaning representations for a particular application domain ( e.g. database query ) .Prior research in machine learning for semantic parsing is mainly based on inductive logic programming or deterministic parsing , which lack some of the robustness that characterizes statistical learning .", "label": "", "metadata": {}, "score": "45.42639"}
{"text": "The user can control precisely what tables to include , etc and so can control the coverage of the natural language interface .The interface is easy to change if the user changes table descriptions or adds or deletes tables .Finally , a given core grammar can be constructed to probably cover any subportion of a target relational database interface language .", "label": "", "metadata": {}, "score": "45.454414"}
{"text": "Unfortunately , LR(0 ) parsers do n't recognize the constructs one finds in typical programming languages .If we consider the next possible symbol for each of the items in a state , as well as for creating the table , we would have an LR(1 ) parser .", "label": "", "metadata": {}, "score": "45.563675"}
{"text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural - language interface for database queries .CHILL treats parser acquisition as the learning of search - control rules within a logic program representing a shift - reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge .", "label": "", "metadata": {}, "score": "45.568157"}
{"text": "The exact form of a grammar rule is prototype - specific .The basic operation of the MAKE - SEMANTIC - GRAMMAR function is identifier substitution .Generally this occurs in a context of looping through one of the categories , say non - numeric - attributes , and substituting , for every rel and attr pair , an argument list into one or more forms .", "label": "", "metadata": {}, "score": "45.608505"}
{"text": "Yes , you can .However , for good results , you should make sure that you provide correctly tokenized input and use exactly the correct tag names .( That is , the input must be tokenized and normalized exactly as the material in the treebank underlying the grammar is . )", "label": "", "metadata": {}, "score": "45.628887"}
{"text": "Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output , but are often very computationally intensive .The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two langu ... \" .", "label": "", "metadata": {}, "score": "45.670403"}
{"text": "Those other concepts are the arguments of the predicate , and are generally nouns , because predicate relationships are usually between entities .As stated previously , the ontological parser has two major components , a sentence lexer 100 and a parser 200 .", "label": "", "metadata": {}, "score": "45.72972"}
{"text": "No additional knowledge about the target domain is included .A more realistic approach assumes that only raw text from the target domain is available .This assumption lends itself well to semi - supervised learning methods since these utilize both labeled and unlabeled examples .", "label": "", "metadata": {}, "score": "45.784973"}
{"text": "To parse breadth first and introduce the ability to begin parsing given only one word of the input and these are put on stack alpha .If not other instructions apply and !MORE is on top of stack alpha , the parser must begin to backtrack as described earlier .", "label": "", "metadata": {}, "score": "45.801144"}
{"text": "However , appropriate probabilities for each rule can only be determined by experimentation .In the initial version , probabilities will be assigned by linguistic intuition ; as iterations of the design progress , probabilities will be determined through experimentation .Since sentence probabilities are generally very small numbers , the parse probability filter should pass any parse tree with a probability of at least 30 % of the highest probability parse .", "label": "", "metadata": {}, "score": "45.835815"}
{"text": "Such a representation scheme gives each node in the tree a unique identifier that completely determines the relative place of that node in the tree structure .It also provides a simple way to compare relative positions of two discovered node instances .", "label": "", "metadata": {}, "score": "45.842247"}
{"text": "Once all backtracking is completed , the next word , followed by !MORE , is put on alpha and parsing begins again with a set of states , each containing the new input word on alpha an done of the saved tuples containing beta and gamma .", "label": "", "metadata": {}, "score": "45.850098"}
{"text": "We introduce a semi - supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word - alignment quality on a small , manually word - aligned sub ... \" .", "label": "", "metadata": {}, "score": "45.85936"}
{"text": "At the API level , with the factored parser , if you ask for getBestDependencyParse ( ) , then you will get the best untyped dependency parse .If you call that method with englishPCFG.ser.gz , it will return null , as there is no dependency parse .", "label": "", "metadata": {}, "score": "45.877174"}
{"text": "Experimental results are presented demonstrating WOLFIE 's ability to learn useful lexicons for a database interface in four different natural languages .The lexicons learned by WOLFIE are compared to those acquired by a competing system developed by Siskind ( 1996 ) .", "label": "", "metadata": {}, "score": "45.902905"}
{"text": "Because each refinement introduces only limited complexity , both learning and inference can be done in an incremental fashion .In this dissertation , we describe several coarse - to - fine systems .In the domain of syntactic parsing , complexity is in the grammar .", "label": "", "metadata": {}, "score": "45.94612"}
{"text": "In this case , the nodes below the S on the alpha stack provide the desired complete parse .If the root node ( i.e. the object of the parsing ) is not a sentence parse , but , for example , a noun phrase parse , then the condition indicating a successful parse would be correspondingly different , e.g. ( NP # , NP # ) .", "label": "", "metadata": {}, "score": "45.953125"}
{"text": "The ontological parser is designed to be modular , so that improvements and language - specific changes can be made to individual components without reengineering the other components .The components are discussed in detail below .The ontological parser has two major functional elements , a sentence lexer and a parser .", "label": "", "metadata": {}, "score": "45.954773"}
{"text": "This process is described in the several papers on the topic by Marie - Catherine de Marneffe .Confusingly , the current code to generate Stanford Dependencies requires a phrase structure ( CFG ) parse .It does n't require or use a dependency parse .", "label": "", "metadata": {}, "score": "45.95533"}
{"text": "The Endsymbol may be declared in the grammar file ( see below ) .The simplest case is to segment the input string into a list of identifiers ( atoms ) and use those atoms both as categories and values of the tokens .", "label": "", "metadata": {}, "score": "45.972458"}
{"text": "It is possible to write a grammar that uses only character tokens as terminal symbols , thereby eliminating the need for a scanner , but this would make the parser larger and slower .The user should implement a scanner that segments the input text , and turns it into one or more lists of tokens .", "label": "", "metadata": {}, "score": "45.984955"}
{"text": "This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with meaning representations .", "label": "", "metadata": {}, "score": "46.029766"}
{"text": "The function takes a data structure of parameters called a PORTABLE SPEC as its argument and returns a semantic grammar and a corresponding semantic lexicon .An NLMENU - driven system need not include this component .The component adds the functionality to a grammar - driven , menu - based system that makes it easy for a user to build his own natural language interfaces to databases .", "label": "", "metadata": {}, "score": "46.15824"}
{"text": "We can construct such a finite - state machine from the productions in the grammar where each state is a set of Items .We create the table using the grammar for expressions above .The reader is asked in Exercise 2 to extend this to recognize a sequence of assignment statements .", "label": "", "metadata": {}, "score": "46.196068"}
{"text": "Instead the system and method of the present invention incorporates a sophisticated syntactic analysis component , which allows facts about parts - of - speech to determine the correct syntactic analysis .Additionally , by incorporating ontologies as the basis for the lexical resource , the present invention permits the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}, "score": "46.254673"}
{"text": "One possibility is to construct a much larger reachability matrix which contains feature information .This can be done by having one entry in the reachability matrix for every possible set of attributes and values that can be associated with each of the symbols .", "label": "", "metadata": {}, "score": "46.290325"}
{"text": "Learning Language Semantics from Ambiguous Supervision [ Details ] [ PDF ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the 22nd Conference on Artificial Intelligence ( AAAI-07 ) , 895 - 900 , Vancouver , Canada , July 2007 .", "label": "", "metadata": {}, "score": "46.293636"}
{"text": "We also intend to broaden the scope of application domains , for example , domains where the sentences are noisy as typical in speech , or domains where corpora available for training do not have natural language sentences aligned with their unique meaning representations .", "label": "", "metadata": {}, "score": "46.31501"}
{"text": "This code is appropriate since it records the current core grammar ( as of 11 - 23 - 82 ) in use in the prototype at CSL .TABLE 3__________________________________________________________________________(loop for ( rel .TABLE 4__________________________________________________________________________(loop for ( rel .FUNCTION MAKE - SEMANTIC - LEXICON .", "label": "", "metadata": {}, "score": "46.324566"}
{"text": "Around 2009 , we parsed large volumes of text at a rate of about 1,000,000 sentences a day by distributing the work over 6 dual core / dual processor machines .Sure ! !These instructions concentrate on parsing from the command line , since you need to use that to be able to set most options .", "label": "", "metadata": {}, "score": "46.478542"}
{"text": "To manage this complexity , we translate into target language clusterings of increasing vocabulary size .This approach gives dramatic speed - ups while additionally increasing final translation quality .The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .", "label": "", "metadata": {}, "score": "46.491844"}
{"text": "To achieve these results we need to mitigate the lack of domain knowledge in the model by providing it with a large amount of automatically parsed data .We extend and improve upon recent work in structured training for neural network transition - based dependency parsing .", "label": "", "metadata": {}, "score": "46.547997"}
{"text": "However , as we will see , the bottom - up parsing method described here pushes terminals and nonterminals on a stack until an appropriate right - hand side is found , and right - recursion can be somewhat inefficient in that many symbols must be pushed before a right - hand side is found .", "label": "", "metadata": {}, "score": "46.559998"}
{"text": "This point is significant since it widens the scope of the usefulness of that patent .It happens though that many advantages ( noted above ) accrue from using natural language grammars and lexicons with that NLMENU interface driver .The above sections indicate that in the past , it has been expensive to build and maintain natural language interfaces to databases .", "label": "", "metadata": {}, "score": "46.610153"}
{"text": "Often numerous passes through the input sentence(s ) are required to fully parse the input , thereby adding to the time required to parse the input .Often the previous techniques do not have very robust feature checking capabilities .In particular , the techniques do not check for both syntactic and semantic compatibility .", "label": "", "metadata": {}, "score": "46.61783"}
{"text": "For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .", "label": "", "metadata": {}, "score": "46.686363"}
{"text": "However , it does not scale to problems with a large set of potential meanings for each sentence , such as the navigation instruction following task studied by Chen and Mooney ( 2011 ) .This paper presents an enhancement of the PCFG approach that scales to such problems with highly - ambiguous supervision .", "label": "", "metadata": {}, "score": "46.70764"}
{"text": "ML ID : 45 .Learning Semantic Grammars With Constructive Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In Proceedings of the 11th National Conference on Artificial Intelligence , 817 - 822 , 1993 .", "label": "", "metadata": {}, "score": "46.72258"}
{"text": "A method for generating a grammar for use as a predictive grammar and parser in a natural language menu system , comprising the steps of : .( a ) generating a domain - independent core grammar ; .( c ) generating a domain specification directed to a predetermined natural language menu application ; and .", "label": "", "metadata": {}, "score": "46.75614"}
{"text": "Now , if this is done for all of the beta - gamma pairs that resulted after parsing the first n-1 and the union of the sets that result is taken , the resulting set is a list of all of the lexical categories that could come next .", "label": "", "metadata": {}, "score": "46.77498"}
{"text": "Returns a descriptive string in English of an error tuple returned by yecc : file/1,2 .This function is mainly used by the compiler invoking Yecc .Pre - Processing .A scanner to pre - process the text ( program , etc . ) to be parsed is not provided in the yecc module .", "label": "", "metadata": {}, "score": "46.98176"}
{"text": "Experimental results are presented that demonstrate WOLFIE 's ability to learn useful lexicons for a realistic domain .The lexicons learned by WOLFIE are also compared to those learned by another lexical acquisition system , that of Siskind ( 1996 ) .", "label": "", "metadata": {}, "score": "46.99642"}
{"text": "It first runs a ( simpler ) PCFG parser and then an untyped dependency parser , and then runs a third parser which finds the parse with the best joint score across the two other parsers via a product model .This is described in the NIPS Fast Exact Inference paper .", "label": "", "metadata": {}, "score": "47.08075"}
{"text": "Empirical methods for building natural language systems has become an important area of research in recent years .Most current approaches are based on propositional learning algorithms and have been applied to the problem of acquiring broad - coverage parsers for relatively shallow ( syntactic ) representations .", "label": "", "metadata": {}, "score": "47.098125"}
{"text": "The Brash system makes no provisions for the possibility that immediate relationships are not in fact the correct expression of sentence - level concepts , because it assumes that syntactic constituency is always defined by immediate relationships .The Brash system does not incorporate ontologies as the basis for its lexical resource , and therefore does not permit the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}, "score": "47.216793"}
{"text": "So they can not be used with an old - style natural language system .But of course , they were designed to be used with a menu - based , grammar - driven interface so this is not really much of a sacrifice .", "label": "", "metadata": {}, "score": "47.279152"}
{"text": "In this proposal , we present a novel statistical approach to semantic parsing , WASP , which can handle meaning representations with a nested structure .The WASP algorithm learns a semantic parser given a set of sentences annotated with their correct meaning representations .", "label": "", "metadata": {}, "score": "47.280388"}
{"text": "See the parser.lexparser package documentation , the LexicalizedParser.main method documentation , the TreePrint class , and the documentation of variables in the Train , Test , and Options classes , and appropriate language - particular TreebankLangParserParams .For the rest , you need to look at the source code .", "label": "", "metadata": {}, "score": "47.28516"}
{"text": "It is also possible for experts to be executed only for effect , to set the stage for a later expert , say .In the BUILD INTERFACEs NLMENU interface , both the MODIFY and the CREATE lexical entries are experts which initialize some global variables whose values are used later in the command by other experts .", "label": "", "metadata": {}, "score": "47.343193"}
{"text": "Starting with version 1.6.2 of the parser , there is a fairly flexible scheme for options in tokenization style .You can give options such as this one to turn off Americanization of spelling : .Or this one to change several options : .", "label": "", "metadata": {}, "score": "47.445328"}
{"text": "Latent variable grammars take an observed ( coarse ) treebank and induce more fine - grained grammar categories , that are better suited for modeling the syntax of natural languages .Estimation can be done in a generative or a discriminative framework , and results in the best published parsing accuracies over a wide range of syntactically divergent languages and domains .", "label": "", "metadata": {}, "score": "47.51215"}
{"text": "The system and method of the present invention also provides a robust feature - checking system that accounts for semantic compatibility as well as syntactic compatibility .The ontology of the present invention converts all inflected words to their canonical forms .", "label": "", "metadata": {}, "score": "47.54164"}
{"text": "Semantic parsing is the process of mapping a natural - language sentence into a formal representation of its meaning .A shallow form of semantic representation is a case - role analysis ( a.k.a . a semantic role labeling ) , which identifies roles such as agent , patient , source , and destination .", "label": "", "metadata": {}, "score": "47.564293"}
{"text": "We show that our method performs overall better and faster than previous approaches in both domains .ML ID : 160 .Learning Transformation Rules for Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate , Yuk Wah Wong , Ruifang Ge , and Raymond J. Mooney April 2004 .", "label": "", "metadata": {}, "score": "47.58211"}
{"text": "We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches .Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic - based approach .", "label": "", "metadata": {}, "score": "47.62973"}
{"text": "It is implemented using Robinson 's DIAGRAM grammar and the acquisition dialogue has been extended to include domain - specific verbs .It is intended for use by a database expert who is not necessarily a natural language expert .In her section on future research in ( Grosz , 1982b ) , Grosz states : . \"", "label": "", "metadata": {}, "score": "47.705124"}
{"text": "In this sample embodiment , this predicate is then passed through the parser filters , where it successfully passes the parse probability and selectional feature compatibility tests .In the foregoing example , \" have \" is a verb unlikely to have any selectional restrictions on arguments .", "label": "", "metadata": {}, "score": "47.741585"}
{"text": "We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language ( NL ) sentences into their formal meaning representations ( MRs ) .Given NL sentences annotated with their MRs , the initial supervised semantic parser learns the mapping by training Support Vector Machine ( SVM ) classifiers for every production in the MR grammar .", "label": "", "metadata": {}, "score": "47.7623"}
{"text": "So , for our system , the sacrifice is not very great .Additionally , a parser that could process input using augmented context - free grammars would necessarily be slower than the parser we employ .Thus , this \" sacrifice \" actually results in our system being able to parse faster .", "label": "", "metadata": {}, "score": "47.823708"}
{"text": "SPECIFIC EXTENSIONS AND TESTS .( i ) Extensions to the core grammar .The specific embodment of the MAKE - PORTABLE - INTERFACE function described above covers only a part of the retrieval functionality of one specific formal relational database interface language .", "label": "", "metadata": {}, "score": "47.89485"}
{"text": "( iv )An nlmenu - driven user interface for building specs .Work in progress at CSL involves prototyping an interface that allows a user to specify or modify or otherwise operate on a portable spec or interface .( v ) Proofs of correctness .", "label": "", "metadata": {}, "score": "47.928"}
{"text": "Some commercial systems exist .Larry Harris of Artificial Intelligence Corp , Roger Schank of Cognitive Systems Inc , and Gary Hendrix of Symantec are all marketing natural language interfaces to software systems .Natural language systems are not in wide spread use today for two reasons : current systems are not easy to use nor are they easy to build and maintain .", "label": "", "metadata": {}, "score": "47.9802"}
{"text": "The drivers for both LL(1 ) and LR - family parsers are easy to write .Table generation is easier for LL(1 ) than it is for LR - family parser generators .Error handling is similar for both LL(1 ) and LR - family parsers , with LL(1 ) being somewhat simpler .", "label": "", "metadata": {}, "score": "48.007133"}
{"text": "The grammar starts with an optional header section .The header is put first in the generated file , before the module declaration .The purpose of the header is to provide a means to make the documentation generated by EDoc look nicer .", "label": "", "metadata": {}, "score": "48.034477"}
{"text": "All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .Background of the Invention .Numerous techniques have been developed to process natural language input .", "label": "", "metadata": {}, "score": "48.04328"}
{"text": "We apply this alignment model to both French - English and Romanian - English language pairs .An exception is Taskar et al .( 2005 ) who presented a word matching model for discriminative alignment which they they were able to solve optimally .", "label": "", "metadata": {}, "score": "48.054596"}
{"text": "We present a number of semi - supervised parsing experiments on the Irish language carried out using a small seed set of manually parsed trees and a larger , yet still relatively small , set of unlabelled sentences .We take two popular dependency parsers - one graph - based and one transition - based - and ... \" .", "label": "", "metadata": {}, "score": "48.08878"}
{"text": "Training the RNN parser is a two step process .First , because the RNN parser uses the parsings of a simpler PCFG parser to train , it is useful to precache the results of that parser before training the RNN parser .", "label": "", "metadata": {}, "score": "48.276917"}
{"text": "Parsing then begins again with one parser state for each beta - gamma pair .This procedure is repeated until there are no more words in the input string .This function will be described in slightly more detail .To do this , a depth - first control structure must be described first .", "label": "", "metadata": {}, "score": "48.30558"}
{"text": "The pseudo - concept filter operates in one embodiment , a query ontological parser .It removes concepts from queries , which are not likely to be the actual concept the user intends .Pseudo - concepts are largely nouns , and can be captured by a stop word list .", "label": "", "metadata": {}, "score": "48.37613"}
{"text": "This distinction may have some psychological validity , but it is not computationally attractive to maintain this distinction in separate array elements .A compromise approach is to attempt to make judgments about redundancy , and write software to merge branches as specified by the judgments of a knowledge engineer .", "label": "", "metadata": {}, "score": "48.385216"}
{"text": "Automatic Construction of Semantic Lexicons for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixteenth National Conference on Artificial Intelligence ( AAAI-99 ) , 487 - 493 , Orlando , FL , July 1999 .", "label": "", "metadata": {}, "score": "48.39101"}
{"text": "However , most ... \" .It is well known that parsing accuracy suffers when a model is applied to out - of - domain data .It is also known that the most beneficial data to parse a given domain is data that matches the domain ( Sekine , 1997 ; Gildea , 2001 ) .", "label": "", "metadata": {}, "score": "48.420986"}
{"text": "We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task .For languages from different families the improvements often exceed 2 BLEU .Many of these gains are also significant in human evaluations .We present a new collection of treebanks with homogeneous syntactic dependency annotation for six languages : German , English , Swedish , Spanish , French and Korean .", "label": "", "metadata": {}, "score": "48.42267"}
{"text": "During the sentence lexer stage , words are labeled with information from the ontology , including these numerical codes .The argument position for each predicate structure may be tagged with codes from any level of the ontology .The parser will only output predicate structures where the noun inherits at least those features specified by the code .", "label": "", "metadata": {}, "score": "48.474037"}
{"text": "I am looking to write some pseudo - code of a recursive descent parser .Now , I have no experience with this type of coding .I have read some examples online but they only work on grammar that uses mathematical expressions .", "label": "", "metadata": {}, "score": "48.48242"}
{"text": "If a target system does not support some important operation like JOIN ( of two tables or files to return another ) , then the interface simply will not support joins .If semantic domains are not supported , then the portable spec can be simplified accordingly .", "label": "", "metadata": {}, "score": "48.497025"}
{"text": "ML ID : 68 .Learning to Parse Database Queries using Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In AAAI / IAAI , 1050 - 1055 , Portland , OR , August 1996 .", "label": "", "metadata": {}, "score": "48.514748"}
{"text": "If a parse is found , it is one of possibly many parses for the sentence .In either case , continue on and pursue all other alternative paths by backtracking to the last choice point , picking another applicable rule , and continuing in the manner described earlier .", "label": "", "metadata": {}, "score": "48.521244"}
{"text": "The parser is a tool for analyzing syntactic relationships between entities .Referring to .FIG .1 , the sentence lexer 100 is shown .Document iterator 120 receives documents or text input 110 , and outputs individual sentences to the lexer 130 .", "label": "", "metadata": {}, "score": "48.52688"}
{"text": "For example , a further embodiment of the present invention , which is presently under development , realizes the present invention on a Texas Instruments Professional Computer , instructed by source code which is written in \" C \" .It should also be noted that the particular parser used in the preferred embodiment is not necessary to the invention , but other parsers can be used .", "label": "", "metadata": {}, "score": "48.542633"}
{"text": "Unlike many current corpus - based approaches that use propositional or probabilistic learning algorithms , CHILL uses techniques from inductive logic programming ( ILP ) to learn relational representations .The reported experiments compare CHILL 's performance to that of a more naive application of ILP to parser acquisition .", "label": "", "metadata": {}, "score": "48.590256"}
{"text": "Experiments show the potential of the approach .ML ID : 301 .Grounded Language Learning Models for Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joo Hyun Kim PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2013 .", "label": "", "metadata": {}, "score": "48.695114"}
{"text": "The handle is a right - hand side of a production , taking into account the rules of the grammar .We will see that our method finds the correct handle .5.2 LR - Family Parsing .The shift - reduce method to be described here is called LR - parsing .", "label": "", "metadata": {}, "score": "48.70594"}
{"text": "Thus , the end result of the operation , after the user has input a complete sentence , is a parsed command which is in accordance with the predefined grammar , and therefore can be trivially translated into an executable instruction , as will be discussed below .", "label": "", "metadata": {}, "score": "48.7844"}
{"text": "Thus , after inputting the nth word , a complete parse up to that word has been performed .For the parser to proceed in a breadth - first manner , it is only given the first word of the input string .", "label": "", "metadata": {}, "score": "48.79595"}
{"text": "They are hard to debug .And there is no established way to guarantee that they cover the desired data or fit the functionality of the target computer system .So , using existing technology , natural language interfaces to databases will be built only for important database applications .", "label": "", "metadata": {}, "score": "48.82669"}
{"text": "International Conference on Computational Linguistics ( COLING 2010 ) , 543 - -551 , Beijing , China , August 2010 .We present a probabilistic generative model for learning semantic parsers from ambiguous supervision .Our approach learns from natural language sentences paired with world states consisting of multiple potential logical meaning representations .", "label": "", "metadata": {}, "score": "48.857105"}
{"text": "The performance of SCISSOR is further improved by using discriminative reranking for incorporating non - local features .The second semantic parser , SYNSEM , exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .", "label": "", "metadata": {}, "score": "48.882126"}
{"text": "We first present a system that learned to sportscast for RoboCup simulation games by observing how humans commentate a game .Using the simple assumption that people generally talk about events that have just occurred , we pair each textual comment with a set of events that it could be referring to .", "label": "", "metadata": {}, "score": "48.882607"}
{"text": "We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality . ... evious work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word - alignment as a supervised task .", "label": "", "metadata": {}, "score": "48.891823"}
{"text": "Some sort of method is needed to construct the grammar .Some sort of database query language must be the target .A big difference between the present invention and what others have done is that the MAKE - PORTABLE - INTERFACE function generates small grammars which are designed for use with a grammar - driven , menu - based system .", "label": "", "metadata": {}, "score": "48.98871"}
{"text": "Craig Thompson abstacted out a core grammar and lexicon as described above which took advantage of most of the findings of that report .At the present time , however , the important finding involving the ability to return attributes from more than one relation has not been fully implemented , though an implementation is in progress .", "label": "", "metadata": {}, "score": "49.08158"}
{"text": "So the grammar can be small .Unhilighted menus contain all menu choices for the menu category to indicate the scope of the interface to the user at all times .This interface is really a special case of grammar - driven , menu - based interfaces . to ask for a menu - like list of next phrases .", "label": "", "metadata": {}, "score": "49.083923"}
{"text": "We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior knowledge .Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .", "label": "", "metadata": {}, "score": "49.085194"}
{"text": "proposed an ensemble method ( Reichart and Rappoport , 2007 ) .They regarded parses as being of high quality if 20 different parsers agreed .They used an SVM regression approach on the basis of text - based and parse - based features .", "label": "", "metadata": {}, "score": "49.121986"}
{"text": "Our methods result in state - of - the - art performance on the task of executing sequences of natural language instructions , achieving up to 25 % error reduction , with lexicons that are up to 70 % smaller and are qualitatively less noisy .", "label": "", "metadata": {}, "score": "49.130615"}
{"text": "The lexicon learned consists of words paired with meaning representations .Wolfie is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .", "label": "", "metadata": {}, "score": "49.16031"}
{"text": "An example command line for this process , with some of the most useful flags , is java -mx4 g edu.stanford.nlp.parser.dvparser.CacheParseHypotheses -model /path / to / pcfg / pcfg.ser.gz -treebank /path / to / wsj 200 - 2199 -output cached.wsj.ser.gz -numThreads 6 .", "label": "", "metadata": {}, "score": "49.18541"}
{"text": "Our generative self - trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without self - training .Additionally , we show that multiple self - trained grammars can be combined in a product model to achieve even higher accuracy .", "label": "", "metadata": {}, "score": "49.20235"}
{"text": "Adverbs detail the meaning of the verbs they accompany , but do not change them .Since the meaning of the sentence remains the same , adverbs can be removed to simplify parsing .The pseudo - predicate filter operates in one embodiment , as a query ontological parser .", "label": "", "metadata": {}, "score": "49.209534"}
{"text": "It is well known that parsing accuracy suffers when a model is applied to out - of - domain data .It is also known that the most beneficial data to parse a given domain is data that matches the domain ( Sekine , 1997 ; Gildea , 2001 ) .", "label": "", "metadata": {}, "score": "49.239197"}
{"text": "This invention is dependent on a grammar - driven , menu - based system , but not vica - versa .The specific prototype described in dependent on the NLMENU system described in the companion patent .The principles behind the invention are : a domain - independent core natural language grammar and a corresponding core lexicon have been designed for use with an nlmenu driver .", "label": "", "metadata": {}, "score": "49.268555"}
{"text": "In this thesis , we focus on devising effective models for simultaneously disambiguating such supervision and learning the underlying semantics of language to map NL sentences into proper logical MRs .We present probabilistic generative models for learning such correspondences along with a reranking model to improve the performance further .", "label": "", "metadata": {}, "score": "49.304123"}
{"text": "It works -- several automatically generated interfaces have been successfully tried .In this section , I will be describing other 's work in building transportable natural language interfaces to databases .That work is often not described precisely enough for another researcher to know exactly what techniques were used or how successful those techniques were .", "label": "", "metadata": {}, "score": "49.365005"}
{"text": "In the second submission , also a constituency parsing system , the n - best lists of various parsing models are combined using an approximate sentence - level product model .The third system , the highest ranked system in the dependency parsing track , uses voting over dependency arcs to combine the output of three constituency parsing systems which have been converted to dependency trees .", "label": "", "metadata": {}, "score": "49.394897"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a non - negative number indicates agreement .", "label": "", "metadata": {}, "score": "49.39639"}
{"text": "Our research further demonstrates the breadth of the applicability of neural network methods to dependency parsing , as well as the ease with which new features can be added to neural parsing models .We present structured perceptron training for neural network transition - based dependency parsing .", "label": "", "metadata": {}, "score": "49.50183"}
{"text": "Or it may be because the parser made a mistake .While our goal is to improve the parser when we can , we ca n't fix individual examples .The parser is just choosing the highest probability analysis according to its grammar .", "label": "", "metadata": {}, "score": "49.539665"}
{"text": "For example : .Rootsymbol sentence .This symbol should appear in the lhs of at least one grammar rule .This is the most general syntactic category which the parser ultimately will parse every input string into .After the rootsymbol declaration comes an optional declaration of the end_of_input symbol that your scanner is expected to use .", "label": "", "metadata": {}, "score": "49.562675"}
{"text": "Web - scale experiments show that the DMV , perhaps because it is unlexicalized , does not benefit from orders of magnitude more annotated but noisier data .Our model , trained on a single blog , generalizes to 53.3 % accuracy out - of - domain , against the Brown corpus - nearly 10 % higher than the previous published best .", "label": "", "metadata": {}, "score": "49.59574"}
{"text": "We present a system that learns to transform natural - language navigation instructions into executable formal plans .Given no prior linguistic knowledge , the system learns by simply observing how humans follow navigation instructions .The system is evaluated in three complex virtual indoor environments with numerous objects and landmarks .", "label": "", "metadata": {}, "score": "49.637512"}
{"text": "Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers .ML ID : 200 .Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus [ Details ] [ PDF ] Yuk Wah Wong and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL-2007 ) , Prague , Czech Republic , June 2007 .", "label": "", "metadata": {}, "score": "49.64168"}
{"text": "The Lisp code ( Lisp machine ) for the parser and for the construction and manipulation of the menus is included in the Appendices below .The grammar which characterizes the allowed queries to the database is also included .The items displayed on the menu to the user , and which can be selected by the user , need not be only words or phrases .", "label": "", "metadata": {}, "score": "49.691513"}
{"text": "ML ID : 180 .A Statistical Semantic Parser that Integrates Syntax and Semantics [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of CoNLL-2005 , Ann Arbor , Michigan , June 2005 .We introduce a learning semantic parser , Scissor , that maps natural - language sentences to a detailed , formal , meaning - representation language .", "label": "", "metadata": {}, "score": "49.703964"}
{"text": "Tennant performed the first and only extensive evaluation of a natural language interface .In his evaluation of the PLANES system , he found that only simple queries of 6 or 7 words were input to the system and 1/3 of the queries were not understood by the system .", "label": "", "metadata": {}, "score": "49.73296"}
{"text": "For example , this command ( with appropriate paths ) will convert a Penn Treebank file to uncollapsed typed dependencies : . java -cp stanford-parser.jar edu.stanford.nlp.trees.EnglishGrammaticalStructure -treeFile wsj/02/wsj_0201 .mrg -basic .Also , here is a sample Java class that you can download that converts from an input file of trees to typed dependencies .", "label": "", "metadata": {}, "score": "49.757927"}
{"text": "The parser generator converts the BNF into tables .The form of the tables depends upon whether the generated parser is a top - down parser or a bottom - up parser .Top - down parsers are easy to generate ; bottom up parsers are more difficult to generate .", "label": "", "metadata": {}, "score": "49.806404"}
{"text": "For best results , we recommend that you first segment input text with a high quality word segmentation system which provides word segmentation according to Penn Chinese Treebank conventions ( note that there are many different conventions for Chinese word segmentation ... ) .", "label": "", "metadata": {}, "score": "49.80996"}
{"text": "A new system , Wolfie , learns semantic lexicons to be used as background knowledge by a previously developed parser acquisition system , Chill .The combined system is tested on a real world domain of answering database queries .We also compare this combination to a combination of Chill with a previously developed lexicon learner , demonstrating superior performance with our system .", "label": "", "metadata": {}, "score": "49.809975"}
{"text": "The lexicon , or the mapping from words to meanings , is one component that is typically difficult to update and that changes from one domain to the next .Therefore , automating the acquisition of the lexicon is an important task in automating the acquisition of NLP systems .", "label": "", "metadata": {}, "score": "49.84102"}
{"text": "Previous generative word alignment models have made structural assumptions such as the 1-to-1 , 1-to - N , or phrase - based consecutive word assumptions , while previous discriminative models have either made such ... \" .Word alignment is the problem of annotating parallel text with translational correspondence .", "label": "", "metadata": {}, "score": "49.954166"}
{"text": "The meaning of these commands is as follows .The quoted text that follows is the TUTORIAL text taken from the BUILD INTERFACEs interface .TUTORIAL ON CREATING , MODIFYING , SHARING , AND DROPPING NLMENU INTERFACES .Using BUILD INTERFACES , a user can do the following operations : .", "label": "", "metadata": {}, "score": "49.964233"}
{"text": "This sort of modification has been demonstrated in a prototype system that CSL is building for the DSG product .Taken together , the advantages listed above pave the way for low cost , maintainable interfaces to relational database systems .All of the advantages are novel when considered with respect to prior art .", "label": "", "metadata": {}, "score": "49.975037"}
{"text": "Experimental results with a complete database - query application for U.S. geography show that CHILL is able to learn parsers that outperform a pre - existing , hand - crafted counterpart .These results demonstrate the ability of a corpus - based system to produce more than purely syntactic representations .", "label": "", "metadata": {}, "score": "50.02382"}
{"text": "This gives a reasonable , but not excellent , Chinese word segmentation system .( It 's performance is n't as good as the Stanford CRF word segmenter mentioned above . )To use it , you use the -segmentMarkov option or a grammar trained with this option .", "label": "", "metadata": {}, "score": "50.03918"}
{"text": "The present invention provides three major innovations which make such a natural language menu system more useful to users .First , a \" build - interface \" function is used , which creates a portable specification , i.e. a compact statement of the parameters which are sufficient to define the desired natural language interface to a relational database , according to the inputs received from a particular user expert .", "label": "", "metadata": {}, "score": "50.124603"}
{"text": "S Jerrold Kaplan ( Kaplan , 1979 ) describes a portable interface which includes an augmented transition network .He restricts his grammar to handle only questions beginning with WH - words , like \" who \" , \" what \" , . . .", "label": "", "metadata": {}, "score": "50.140884"}
{"text": "Similarly , a reduce - reduce error occurs when the parser has to choose between more than one equally acceptable production .One way to resolve such conflicts is to attempt to rewrite the grammar .Another method is to analyze the situation and decide , if possible , which action is the correct one .", "label": "", "metadata": {}, "score": "50.142494"}
{"text": "Toward this goal , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .", "label": "", "metadata": {}, "score": "50.15113"}
{"text": "At any stage of the parse , we will have the following configuration : . where the s 's are states , the x 's are sequences of terminals or nonterminals , and the a 's are input symbols .This is somewhat like a finite - state machine where the state on top ( the right here ) of the stack contains the \" accumulation of information \" about the parse until this point .", "label": "", "metadata": {}, "score": "50.159058"}
{"text": "Learning Language from Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen December 2009 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .Most current natural language processing ( NLP ) systems are built using statistical learning algorithms trained on large annotated corpora which can be expensive and time - consuming to collect .", "label": "", "metadata": {}, "score": "50.190285"}
{"text": "7sISI - University of Southern California ISI - TR-616 Acknowledgments This work was supporte ... . \" ...Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .", "label": "", "metadata": {}, "score": "50.209343"}
{"text": "Similarly , the filter would need to check twice to determine that \" car \" is in agreement with \" transportation , \" and once for \" vehicle . \"In contrast , a parameterized ontology assigns numbers to these concepts , such that each level is a larger number than the previous level .", "label": "", "metadata": {}, "score": "50.218605"}
{"text": "The reachability matrix indicates whether X can dominate A where A is on a left branch .The reachability conditions are satisfied if X can dominate A in this configuration .The reachability matrix is a Boolean matrix , which contains a logical value for each pair of nodes ( N , M ) in the grammar to indicate whether any legal parse tree could have node N as a leftmost daughter of node M. This matrix is then multiplied by itself repeatedly , until it stabilizes , that is until further multiplication of the final matrix by the immediate reachability matrix produces no further change in the final matrix .", "label": "", "metadata": {}, "score": "50.255596"}
{"text": "S ) .Note that the # is not required in the Lisp implementation , since an empty list is easily tested for .As noted , the parser set forth above must be modified for use in the present invention .", "label": "", "metadata": {}, "score": "50.27428"}
{"text": "This is an element of the dependency analysis we adopted .It 's not uncontroversial , and it could have been done differently , but we 'll try to explain briefly why we did things the way we did .The general philosophy of the grammatical relations design is that main predicates should be heads and auxiliaries should not .", "label": "", "metadata": {}, "score": "50.30448"}
{"text": "Integrating Top - down and Bottom - up Approaches in Inductive Logic Programming : Applications in Natural Language Processing and Relational Data Mining [ Details ] [ PDF ] Lappoon R. Tang PhD Thesis , Department of Computer Sciences , University of Texas , Austin , TX , August 2003 .", "label": "", "metadata": {}, "score": "50.325222"}
{"text": "If the grammar is not SLR(1 ) , then there may be more than one entry in the table .If both a \" shift \" action and \" reduce \" action occur in the same entry , and the parsing process consults that entry , then a shift - reduce conflict is said to occur .", "label": "", "metadata": {}, "score": "50.325974"}
{"text": ".. our corpus .The second question is how one can estimate NLP systems ' performance when gold standard on the test data does not exist .Our experiments show that the predicted scores are close to the real scores when tested on the CTB data .", "label": "", "metadata": {}, "score": "50.35289"}
{"text": "In this paper , we explored a learning approach which combines different learning methods in inductive logic programming ( ILP ) to allow a learner to produce more expressive hypothese than that of each individual learner .Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method .", "label": "", "metadata": {}, "score": "50.364967"}
{"text": "You can also implement them all at once by playing a little trick , which allows you to get the leftmost derivation with a tail recursive parser .( Morally it 's fairly similar ... ) - Kristopher Micinski Mar 22 ' 12 at 1:13", "label": "", "metadata": {}, "score": "50.40649"}
{"text": "By default , the tokenizer used by the English parser ( PTBTokenizer ) performs various normalizations so as to make the input closer to the normalized form of English found in the Penn Treebank .One of these normalizations is the Americanization of spelling variants ( such as changing colour to color ) .", "label": "", "metadata": {}, "score": "50.450268"}
{"text": "a parse tree converter that receives the output of said parser component and converts said parse trees into predicates .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 19 , wherein said parser component further comprises : . parser filters operating on said predicates to remove erroneous predicates .", "label": "", "metadata": {}, "score": "50.52353"}
{"text": "We have not yet completed a formal proof that the software is correct , since details of the embodiment will affect such a proof and the embodiment is subject to modifications as explained below .Such a proof goes something like this : covered functionality in target language ( SQL or LMRDBAAS ) is identified and then natural language constructions are identified that translate to those identified target functions .", "label": "", "metadata": {}, "score": "50.529335"}
{"text": "In general , though , you should not use this part of the feature and simply use \" .Yes , for the PCFG parser ( only ) .With a PCFG parser , you can give the option -printPCFGkBest n and it will print the n highest - scoring parses for a sentence .", "label": "", "metadata": {}, "score": "50.55079"}
{"text": "Translations that are functions are of the form \" lambda x . . .x . . . \" .This amounts to a simplified version of \" lambda \" conversion as used by all work in Montague Grammar ( See Montague 1973 ) .", "label": "", "metadata": {}, "score": "50.57561"}
{"text": "In particular , you can now download a version of our CRF - based word segmenter ( similar to the system we used in the Second Sighan Bakeoff ) from our software page .However , for convenience , we also provide an ability for the parser to do word segmentation .", "label": "", "metadata": {}, "score": "50.587936"}
{"text": "Descripci\u00f3n .Included is a microfiche appendix of 4 microfiche and 385 frames .BACKGROUND AND SUMMARY OF THE INVENTION .The present invention relates to a system for user - customizing a natural language menu command system .In general , the task of writing a natural language interface to some target computer system involves writing a natural language grammar and a corresponding lexicon and a set of semantic translations to the target system .", "label": "", "metadata": {}, "score": "50.59073"}
{"text": "On full - scale treebank parsing experiments , the discriminative latent models outperform both the comparable generative latent models as well as the discriminative non - latent baselines .We present a maximally streamlined approach to learning HMM - based acoustic models for automatic speech recognition .", "label": "", "metadata": {}, "score": "50.598343"}
{"text": "An example of this command line is java -mx12 g edu.stanford.nlp.parser.dvparser.DVParser -cachedTrees /path / to / cached .wsj.ser.gz -train -testTreebank /path / to / wsj 2200 - 2219 -debugOutputFrequency 500 -trainingThreads 8 -parser /path / to / pcfg / pcfg.ser.gz -dvIterations 40 -dvBatchSize 25 -wordVectorFile /path / to / embedding -model /scr / nlp / data / dvparser / wsj / train / averaged / averaged . ser.gz .", "label": "", "metadata": {}, "score": "50.60604"}
{"text": "Timewise , both LL(1 ) and LR - family parsers are linear for the average case ( in the number of tokens processed ) .It is easier to write a grammar for LR - family parsers than for LL(1 ) parsers since LL requires that there be no left - recursion or common prefixes .", "label": "", "metadata": {}, "score": "50.636517"}
{"text": "Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries .ML ID : 219 .Learning for Semantic Parsing with Kernels under Various Forms of Supervision [ Details ] [ PDF ] [ Slides ] Rohit J. Kate PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}, "score": "50.645844"}
{"text": "I would like to write it in c # or java syntax since it is easier for me to relate .UPDATE : . 3 Answers 3 .It is also important to note that you will need some other program to tokenize the input for you , then you can just ask that program for the next token from your input .", "label": "", "metadata": {}, "score": "50.673603"}
{"text": "Across eight European languages , our approach results in an average absolute improvement of 10.4 % over a state - of - the - art baseline , and 16.7 % over vanilla hidden Markov models induced with the Expectation Maximization algorithm .", "label": "", "metadata": {}, "score": "50.732803"}
{"text": "This HeadFinder will give consistent left - branching binarization .If you would like to also get out the true probabilities that a vanilla PCFG parser would produce , there are a couple more options that you need to set : . -smoothTagsThresh", "label": "", "metadata": {}, "score": "50.743317"}
{"text": "A third choice , and the one seen as most promising , is to calculate the reachability matrix for the context - free version of the rules and then to associate an equation or set of equations with each item in the matrix .", "label": "", "metadata": {}, "score": "50.778656"}
{"text": "Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind ( 1996 ) , with results favorable to Wolfie .", "label": "", "metadata": {}, "score": "50.79901"}
{"text": "It should be noted that the present invention is applicable to constraining natural language inputs in accordance with any system which can be formally represented by a comparable grammar and lexicon .That is , the present invention is not applicable solely to data base query systems , but can be used to generate well - formed executable machine commands in any machine language using natural language input .", "label": "", "metadata": {}, "score": "50.80274"}
{"text": "With 100 K unlabeled and 2 K labeled questions , uptraining is able to improve parsing accuracy to 84 % , closing the gap between in - domain and out - of - domain performance .We study self - training with products of latent variable grammars in this paper .", "label": "", "metadata": {}, "score": "50.851635"}
{"text": "5.3.1 Better Error Handling .It is possible to detect the error earlier than when it is pushed onto the stack .Error recovery algorithms can be more clever than those which replace symbols on the stack or in the input .", "label": "", "metadata": {}, "score": "50.871826"}
{"text": "Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .On the other hand , our grammars are much more compact and substantially more accurate than previous work on automatic annotation .Despite its simplicity , our best grammar achieves an F1 of 89.9 % on the Penn Treebank , higher than most fully lexicalized systems .", "label": "", "metadata": {}, "score": "50.89689"}
{"text": "We compare a number of semantic parsing approaches on the highly noisy training data collected from ordinary users , and find that loosely synchronous systems perform best .ML ID : 317 .Intelligent robots frequently need to understand requests from naive users through natural language .", "label": "", "metadata": {}, "score": "50.928593"}
{"text": "One core issue toward this goal is \" grounded \" language learning , a process of learning the semantics of natural language with respect to relevant perceptual inputs .In order to ground the meanings of language in a real world situation , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .", "label": "", "metadata": {}, "score": "50.96526"}
{"text": "You can rewrite your grammar ( possibly , depending on else rule ) equivalently as : .Which may or may not be what you want .But the pseudocode sort of jumps out from this .For each alternate , I created an if statement that looked at the unique prefix .", "label": "", "metadata": {}, "score": "50.983322"}
{"text": "The above data structure naturally lends itself to one particular algorithm for comparing the identity or subsumption of ontological features .The algorithm relies on the implementation of the tree by associating with each node in the tree an integer value that represents the position of that node within the hierarchical structure .", "label": "", "metadata": {}, "score": "50.99141"}
{"text": "Not popular terminology , but if it is used it would correspond to an N - tuple or row .Tag : Not current terminology .This section describes a manually built nlmenu interface in which a user is guided to build and maintain other nlmenu interfaces .", "label": "", "metadata": {}, "score": "51.001854"}
{"text": "Generating a Parser .To call the parser generator , use the following command : . yecc : file(Grammarfile ) .An error message from Yecc will be shown if the grammar is not of the LALR type ( for example too ambiguous ) .", "label": "", "metadata": {}, "score": "51.010353"}
{"text": "This frequently seems to confuse people , because the main predicate of the clause is now not a verb .But we believe that this is the best thing to do for several reasons : .Consistency of treatment of auxiliary / copula between English periphrastic verb forms and adjectival / nominal predications .", "label": "", "metadata": {}, "score": "51.060146"}
{"text": "The result is that the time complexity of structure - comparison algorithms attains the polynomial order of the number of features ( or nodes ) being compared .This fact makes the use of ontologies inefficient for high - performance computing applications , such as searching terabyte - sized databases with wide - ranging conceptual content .", "label": "", "metadata": {}, "score": "51.06897"}
{"text": "The class of grammars currently used by the parser is context - free grammars ( or CFG 's ) .Any arbitrary context - free grammar is permitted , with two minor exceptions to be discussed after context - free grammars are defined .", "label": "", "metadata": {}, "score": "51.15375"}
{"text": "ILP algorithms , which learn relational ( first - order ) rules , are used in a parser acquisition system called CHILL that learns rules to control the behavior of a traditional shift - reduce parser .Using this approach , CHILL is able to learn parsers for a variety of different types of analyses , from traditional syntax trees to more meaning - oriented case - role and database query forms .", "label": "", "metadata": {}, "score": "51.182255"}
{"text": "Second , how can we efficiently infer optimal structures within them ?Hierarchical coarse - to - fine methods address both questions .Coarse - to - fine approaches exploit a sequence of models which introduce complexity gradually .At the top of the sequence is a trivial model in which learning and inference are both cheap .", "label": "", "metadata": {}, "score": "51.2331"}
{"text": "Instead , they must traverse the list of links and compare structures on a node - by - node basis to guarantee identity .Complicating this procedure is the fact that concepts may be cross - linked across multiple branches of a tree , sharing multiple structures .", "label": "", "metadata": {}, "score": "51.275036"}
{"text": "END - USERS can build natural language interfaces to their own data ; the interfaces are robust with respect to database changes ; they can be customized to cover user - specified subsets of data and functionality in a precise manner ; and they are provably correct .", "label": "", "metadata": {}, "score": "51.27925"}
{"text": "The LALR parser is widely used and is better known as the approach used by parser generators such as yacc and bison .While the description is a preferred embodiment , it will be understood that any implementation of a context - free grammar within a similar architecture , including such variants as an LALR-2 parser ( which looks ahead by two words ) , are within the scope of the present invention .", "label": "", "metadata": {}, "score": "51.31668"}
{"text": "The parser uses considerable amounts of memory .If you see a java.lang.OutOfMemoryError , you either need to give the parser more memory or to take steps to reduce the memory needed .( You give java more memory at the command line by using the -mx flag , for example -mx500 m . )", "label": "", "metadata": {}, "score": "51.352463"}
{"text": "State - of - the - art natural language processing models are anything but compact .Syntactic parsers have huge grammars , machine translation systems have huge transfer tables , and so on across a range of tasks .With such complexity come two challenges .", "label": "", "metadata": {}, "score": "51.37005"}
{"text": "Also as Kristopher points out your grammar has something called a dangling else , meaing that you have a production that starts with the same thing up to a point : .So this begs the question if your parser sees an ' if ' token , which production should it choose to process the input ?", "label": "", "metadata": {}, "score": "51.37185"}
{"text": "ML ID : 171 .Learning to Transform Natural to Formal Languages [ Details ] [ PDF ] [ Slides ] Rohit J. Kate , Yuk Wah Wong and Raymond J. Mooney In Proceedings of the Twentieth National Conference on Artificial Intelligence ( AAAI-05 ) , 1062 - 1068 , Pittsburgh , PA , July 2005 .", "label": "", "metadata": {}, "score": "51.413704"}
{"text": "He can decide to make an interface that covers only a semantically related subset of his tables .He can choose to include some attributes and hide other attributes so that they can not be mentioned .He can choose to support various kinds of joins with natural language phrases .", "label": "", "metadata": {}, "score": "51.441063"}
{"text": "The system of the present invention maintains arguments as variables during the parsing process , and automatically fills in long - distance dependencies as part of the parsing process .No post - parsing analysis is needed to obtain this benefit , and the parsing time is not impacted by the maintenance of these variables , thus resulting in faster parsing execution .", "label": "", "metadata": {}, "score": "51.479095"}
{"text": "Partial inputs from the user are successfully parsed , and the parser indicates all possible legal next entries which could follow the input received so far from the user .The set of legal next words is then displayed to the user as active portions of the menu , so that the user need only select one of the legal next words from the menu .", "label": "", "metadata": {}, "score": "51.505196"}
{"text": "You may use the parse method that takes a String argument to have this done for you or you may be able to use of classes in the process package , such as DocumentPreprocessor and PTBTokenizer for tokenization , much as the main method of the parser does .", "label": "", "metadata": {}, "score": "51.564648"}
{"text": "The BNF shown in Example 1 states that a program consists of a sequence of statements , each of which is an assignment statement with a right - hand side consisting of an arithmetic expression .This BNF is input to the parser generator to produce tables which are then accessed by the driver as the input is read .", "label": "", "metadata": {}, "score": "51.59068"}
{"text": "ML ID : 99 .Learning for Semantic Interpretation : Scaling Up Without Dumbing Down [ Details ] [ PDF ] Raymond J. Mooney In Workshop Notes for the Workshop on Learning Language in Logic , 7 - 15 , Bled , Slovenia , 2000 .", "label": "", "metadata": {}, "score": "51.60978"}
{"text": "The supplied file makeSerialized.csh shows exactly what options we used to train the parsers that are included in the distribution .If you want to train the parser on a new language and/or treebank format , you can ( and people have done so ) , but you need to spend a while learning about the code , especially if you wish to develop language - specific features .", "label": "", "metadata": {}, "score": "51.65596"}
{"text": "Next , we describe two PCFG induction models for grounded language learning that extend the previous grounded language learning model of Borschinger , Jones , and Johnson ( 2011 ) .Borschinger et al .'s approach works well in situations of limited ambiguity , such as in the sportscasting task .", "label": "", "metadata": {}, "score": "51.677155"}
{"text": "I taught ( really just , helped ) the parsing section of a PL class last semester .I really recommend looking at the parsing slides from our page : here .Basically , for recursive descent parsing , you ask yourself the following question : .", "label": "", "metadata": {}, "score": "51.705982"}
{"text": "If you want to display the output in a command window , you separately also need to work out what character set your computer supports for display .If that is different to the encoding of the file , you will need to convert the encoding for display .", "label": "", "metadata": {}, "score": "51.709698"}
{"text": "( Since these parsers were written , direct typed dependency parsers have been increasingly explored .Both us and others have now built parsers that directly parse to Stanford Dependencies .See the Stanford Dependencies page for more information . )For Chinese ( and Arabic , German , and \" WSJ \" ) , you can look at the included file makeSerialized.csh , and easily see exactly what files the models are trained on , in terms of LDC or Negra file numbers .", "label": "", "metadata": {}, "score": "51.7358"}
{"text": "Memory usage expands roughly with the square of the sentence length .You may wish to set a -maxLength and to skip long sentences .The factored parser requires several times as much memory as just running the PCFG parser , since it runs 3 parsers .", "label": "", "metadata": {}, "score": "51.74461"}
{"text": "ML ID : 314 .Semantic Parsing using Distributional Semantics and Probabilistic Logic [ Details ] [ PDF ][Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .", "label": "", "metadata": {}, "score": "51.765232"}
{"text": "Parsing file : chinese-onesent-unseg.txt with 1 sentences .Parsing [ sent .1 len .falling back to PCFG parse .Parsed 5 words in 1 sentences ( 6.08 wds / sec ; 1.22 sents / sec ) .1 sentences were parsed by fallback to PCFG .", "label": "", "metadata": {}, "score": "51.7926"}
{"text": "The algorithm works like this : .Do you see the pattern here : . for each nonterminal in your grammar : parse the first thing , then see what you have to look at to decide what you should parse next .", "label": "", "metadata": {}, "score": "51.806786"}
{"text": "However , it is not always possible to restrict the set of possible alignments to such limited numbers .Thus , we present another system that allows each sentence to be aligned to one of exponentially many connected subgraphs without explicitly enumerating them .", "label": "", "metadata": {}, "score": "51.859756"}
{"text": "With this code , you should be able to parse the sentence in a file with a command like this ( details depending on your shell , OS , etc . ) : . java -mx200 m -cp \" stanford - parser .", "label": "", "metadata": {}, "score": "51.876713"}
{"text": "Consequently , a parser that handles both of these conditions is needed .The parser 230 must pursue all possible parse trees , in effect branching and pursuing more than one path at every ambiguity .The standard LALR parser is a finite state machine designed to build a parse tree from the set of grammar rules ( called productions ) one input symbol at a time .", "label": "", "metadata": {}, "score": "51.982304"}
{"text": "This section is very similar to the previous section with regard to how out and inner loops and substitution lists instantiate forms .Here each form being substituted into results in a LEXICAL ENTRY consisting of a 4-tuple with fields ( category , menu - item , menu - window , translation ) .", "label": "", "metadata": {}, "score": "52.126312"}
{"text": "ML ID : 95 .Active Learning for Natural Language Parsing and Information Extraction [ Details ] [ PDF ] Cynthia A. Thompson , Mary Elaine Califf and Raymond J. Mooney In Proceedings of the Sixteenth International Conference on Machine Learning ( ICML-99 ) , 406 - 414 , Bled , Slovenia , June 1999 .", "label": "", "metadata": {}, "score": "52.12996"}
{"text": "It can easily be seen from this example that the formal manipulation rules as set forth above translate very simply into programmable operations .For example , the final status of stack beta , in the very last step of the preceding worked - out example , could be easily represented in Lisp by a list formatted , e.g. , as follows : .", "label": "", "metadata": {}, "score": "52.146393"}
{"text": "Furthermore , the interface that results is not portable to new domains , not robust with respect to changes in the target system , not easy to debug , and may not cover the target system ( a proof that it does so may be extremely difficult ) .", "label": "", "metadata": {}, "score": "52.19818"}
{"text": "We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system .We use a corpus of weakly - labeled reference reorderings to guide parser training .Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress .", "label": "", "metadata": {}, "score": "52.286324"}
{"text": "If POS - tagging sentences prior to parsing is an option , that speeds things up ( less possibilities to search ) .The main tool remaining is to run multiple parsers at once in parallel .If you have a machine with enough memory and multiple cores , you can very usefully run several parsing threads at once .", "label": "", "metadata": {}, "score": "52.291443"}
{"text": "When the values of the features of the two nodes for which reachability matrix information is required are known , they are plugged into this equation .The result of this equation will be either true or false indicating reachability .A sacrifice has been made to achieve this 0 % failure rate , however .", "label": "", "metadata": {}, "score": "52.31958"}
{"text": "In addition , the use of experts does not affect the final translation of the natural language input into machine commands , since each expert concludes its function and retires immediately before the next word is selected .In addition , where a very large number of items can be chosen from next , an expert can be used to display subcategories of the possible next items .", "label": "", "metadata": {}, "score": "52.361786"}
{"text": "However , constructing such corpora can be expensive and time - consuming due to the expertise it requires to annotate such data .In this thesis , we explore alternative ways of learning which do not rely on direct human supervision .", "label": "", "metadata": {}, "score": "52.37657"}
{"text": "FUNCTION MAKE - SEMANTIC GRAMMAR .Formally , .It is important to note that while a semantic grammer is produced , this description does not really suggest a specific data structure for the grammar .Possibilities include a list of grammar rules and translations , a pointer to a file where the semantic grammar that was produced now resides in some format , or a database relation GRAMMARS with components : ( OWNER , INTERFACE - NAME , RULE , TRANSLATION ) .", "label": "", "metadata": {}, "score": "52.378136"}
{"text": "Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .A long - standing goal for the field of artificial intelligence is to enable computer understanding of human languages .A core requirement in reaching this goal is the ability to transform individual sentences into a form better suited for computer manipulation .", "label": "", "metadata": {}, "score": "52.397007"}
{"text": "# # STR78 # # .To see why this is so , note that the meaning of the subtree VP would be the result of applying the meaning of the V to the meaning of the NP because of the rule ( 1 2 ) .", "label": "", "metadata": {}, "score": "52.39852"}
{"text": "A normal lexical entry hsa the form : .( ( grammar terminal ) ( menu phrase ) ( menu pane ) ( translation ( lexical item help ) ) .Lexical entries that invoke experts have ( translations ) of a special form , namely : ( translation ) is of the form ( EXPERT code ) , that is , a keyword followed by code .", "label": "", "metadata": {}, "score": "52.44835"}
{"text": "However , it is clear from the tree above that not all differences are equally meaningful .In order for the magnitude of the difference to be relevant , it must first be the case that one of the concepts inherits all the properties of the others .", "label": "", "metadata": {}, "score": "52.451447"}
{"text": "It employs the algorithm described above and uses the Lisp Machine 's software for creating the menus required and manipulating them as described above .The prototype implementation is a natural language database query system which accesses the parts - suppliers database described in Date ( 1975 ) , p. 79 .", "label": "", "metadata": {}, "score": "52.49332"}
{"text": "Our best model produces the lowest alignment error rate yet reported on Canadian Hansards bilingual data . ...e probabalistic models developed at IBM by Brown et al .( 1993 ) , sometimes augmented by an HMMbased model or Och and Ney 's \" Model 6 \" ( Och and Ney , 2003 ) . \" ...", "label": "", "metadata": {}, "score": "52.50699"}
{"text": "We will state the algorithm and then show how it can be applied to the grammar of Example 3 .If the dot is interpreted as separating the part of the string that has been parsed from the part yet to be parsed , State 0 indicates the state where we \" expect \" to see an E ( an expression ) .", "label": "", "metadata": {}, "score": "52.539974"}
{"text": "These methods require labeled examples of syntactic structures to learn statistical patterns governing these structures .Labeled data typically requires expert annotators which makes it both time consuming and costly to produce .Furthermo ... \" .Current efforts in syntactic parsing are largely data - driven .", "label": "", "metadata": {}, "score": "52.64332"}
{"text": "This paper reviews our recent work on applying inductive logic programming to the construction of natural language processing systems .We have developed a system , CHILL , that learns a parser from a training corpus of parsed sentences by inducing heuristics that control an initial overly - general shift - reduce parser .", "label": "", "metadata": {}, "score": "52.661892"}
{"text": "The present invention relates to an ontological parser for natural language processing .More particularly , the present invention relates to a system and method for ontological parsing of natural language that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}, "score": "52.743942"}
{"text": "The option -smoothTagsThresh 0 stops any probability mass being reserved for unknown words .Naturally , such a parser will be unable to parse any sentence with unknown words in it .The 2003 unlexicalized parsing paper lists several modifications that gradually improve the performance of the Stanford parser for English .", "label": "", "metadata": {}, "score": "52.759827"}
{"text": "Below , I will briefly outline an interface being built for eliciting the information contained in a portable spec from a user and from the data dictionary of a dbms .As for maintaining such an interface when new columns are added to tables or new tables are added or deleted , etc , one need only modify the portable spec to reflect the changes and regenerate the interface .", "label": "", "metadata": {}, "score": "52.768383"}
{"text": "So there is no intent to cover more natural language than a domain requires .The MAKE - PORTABLE - INTERFACE function described in this patent is NOT the first and only work in the area of generating interfaces of some kind from descriptions of the data , but its purposes are different , its immplementation is simpler , and it works .", "label": "", "metadata": {}, "score": "52.854233"}
{"text": "Finally , we also show that ensembles of different semantic parser learning systems can obtain the best overall performance .ML ID : 215 .Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}, "score": "52.883133"}
{"text": "Instead , features will be allowed to take on more than two values .This option was first discussed for syntax in Friedman ( 1973 ) and her paper provides arguments in favor of this approach within a transformational framework .Features values are constrained to be strings of a finite number of concatenated symbols .", "label": "", "metadata": {}, "score": "52.896267"}
{"text": "The most important feature of this procedure is that it can predict the set of possible terminal symbols that could be the nth input item , if it has completed parsing up to the ( n-1)th input item .It is this facility that enables the proper menus and proper items in those menus to be displayed so that the next input item can be chosen from a menu .", "label": "", "metadata": {}, "score": "52.905468"}
{"text": "The system does not use any prior language knowledge and was able to learn to sportscast in both English and Korean .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans .", "label": "", "metadata": {}, "score": "52.91857"}
{"text": "ML ID : 66 .Corpus - Based Lexical Acquisition For Semantic Parsing [ Details ] [ PDF ] Cynthia Thompson February 1996 .Ph.D. proposal .Building accurate and efficient natural language processing ( NLP ) systems is an important and difficult problem .", "label": "", "metadata": {}, "score": "52.933933"}
{"text": "The problem occurs in the domain of lexical acquisition .The ambiguous and synonymous nature of words causes the difficulty of using standard induction techniques to learn a lexicon .Additionally , negative examples are typically unavailable or difficult to construct in this domain .", "label": "", "metadata": {}, "score": "52.94179"}
{"text": "There is considerable Javadoc documentation included in the javadoc/ directory of the distribution .You should start by looking at the javadoc for the parser.lexparser package and the LexicalizedParser class .( The documentation appearing on the nlp.stanford.edu website refers to code under development and is not necessarily consistent with the released version of the parser . )", "label": "", "metadata": {}, "score": "53.014496"}
{"text": "EXPORTS .Grammarfile is the file of declarations and grammar rules .Returns ok upon success , or error if there are errors .An Erlang file containing the parser is created if there are no errors .The options are : .", "label": "", "metadata": {}, "score": "53.03553"}
{"text": "( See the next section on experiments ) .This has been demonstrated already in the prototype where an automatically generated interface requested by the EG of TI was manually altered to provide a way to specify picture drawing functionality to an NLMENU interface .", "label": "", "metadata": {}, "score": "53.042885"}
{"text": "You pass to the parse method a List .If the items in this list implement HasTag , such as being of type TaggedWord or CoreLabel , and the tag value is not null , then the parser will use the tags that you provide .", "label": "", "metadata": {}, "score": "53.061478"}
{"text": "Generative Models of Grounded Language Learning with Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joohyun Kim Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , June 2012 . \"", "label": "", "metadata": {}, "score": "53.095642"}
{"text": "More precisely , an inductive logic programming ( ILP ) method , TABULATE , is developed for learning multiple models that are integrated via linear weighted combination to produce probabilistic models for statistical semantic parsing .Initial experimental results from three different domains suggest that an integration of statistical and logical approaches to semantic parsing can outperform a purely logical approach .", "label": "", "metadata": {}, "score": "53.153694"}
{"text": "Discriminative learning allows easy incorporation of any feature one might have access to during the alignment search .Because the features are handled so easily , ... . \" ...Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .", "label": "", "metadata": {}, "score": "53.157505"}
{"text": "Each gives him a user - view of a semantically related set of data .This notion of a view is like the notion of a database schema found in network and hierarchical but not relational systems .In relational systems , there is no convenient way for loosely grouping tables together that are semantically related .", "label": "", "metadata": {}, "score": "53.192245"}
{"text": "Next come the grammar rules .Each rule has the general form .The left hand side is a non - terminal category .The right hand side is a sequence of one or more non - terminal or terminal symbols with spaces between .", "label": "", "metadata": {}, "score": "53.193607"}
{"text": "Across various hierarchical encoding schemes and for multiple language pairs , we show speed - ups of up to 50 times over single - pass decoding while improving BLEU score .Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram - to - trigram decoder .", "label": "", "metadata": {}, "score": "53.21403"}
{"text": "Automating the construction of semantic grammars is a difficult and interesting problem for machine learning .This paper shows how the semantic - grammar acquisition problem can be viewed as the learning of search - control heuristics in a logic program .", "label": "", "metadata": {}, "score": "53.24826"}
{"text": "The difference is simply a digit - by - digit comparison that starts with the most significant bit and continues until the first decimal digit difference is located .Importantly , though , the differences due to inheritance along incompatible sub - trees do not correspond to elements of natural - language meaning .", "label": "", "metadata": {}, "score": "53.285156"}
{"text": "The LR - family grammars can also handle a wider range of language constructs ; in fact the language constructs generated by LL(1 ) grammars are a proper subset of the LR(1 ) constructs .For the LR - family the language constructs recognized are : .", "label": "", "metadata": {}, "score": "53.29023"}
{"text": "Specifically , this invention addresses the following problems : Existing natural language interfaces to databases are seldom portable ; almost all are application - specific .They take from man - weeks to man - years for a specialist to build .", "label": "", "metadata": {}, "score": "53.34877"}
{"text": "YACC contain facilities for specifying precedence and associativity of operators and for specifying errors .An error production in YACC is of the form : . where is an erroneous construct .We will look at this example again in Chapter 6 when we discuss semantic analysis .", "label": "", "metadata": {}, "score": "53.411934"}
{"text": "A more general approach to scanner implementation is to use a scanner generator .A scanner generator in Erlang called leex is under development .Grammar Definition Format .Erlang style comments , starting with a ' % ' , are allowed in grammar files .", "label": "", "metadata": {}, "score": "53.426258"}
{"text": "ML ID : 272 .Learning Language from Ambiguous Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .Building a computer system that can understand human languages has been one of the long - standing goals of artificial intelligence .", "label": "", "metadata": {}, "score": "53.478085"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said sentence lexer comprises : . a document iterator that receives text input and outputs individual sentences ; . a lexer that receives said individual sentences from said document iterator and outputs individual words ; and . an ontology that receives said individual words from said lexer and returns ontological entities or words tagged with default assumptions about an ontological status of said individual words to said lexer .", "label": "", "metadata": {}, "score": "53.57791"}
{"text": "The Inverse Entailment approach to ILP , implemented in the Progol and Aleph systems , starts with the construction of a bottom clause , the most specific hypothesis covering a seed example .When mining relational data with a large number of background facts , the bottom clause becomes intractably large , making learning very inefficient .", "label": "", "metadata": {}, "score": "53.60904"}
{"text": "The parse probability filter vetoes parse trees that fall below a minimum probability for valid semantic interpretation .The parse probability filter will calculate the probability of a sentence parse by taking the product of the probabilities of the syntactic rules used to generate a given parse tree .", "label": "", "metadata": {}, "score": "53.62249"}
{"text": "Thus , the presently preferred embodiment uses a modification of this parser , as will now be set forth .For consistency with the published literature , the formalism of the parser will now trivally be altered .A 3-stack informal turing machine formalism will now be used , which differs slightly from the previous format in that the incomplete parse trees which were formerly held below the place holding symbol \" t \" in stack beta will now be held separately in a gamma stack .", "label": "", "metadata": {}, "score": "53.65655"}
{"text": "The call format may be different if a customized prologue file has been included when generating the parser instead of the default file lib / parsetools / include / yeccpre.hrl .Message is something which may be converted into a string by calling Module : format_error(Message ) and printed with io : format/3 .", "label": "", "metadata": {}, "score": "53.69522"}
{"text": "( d ) inserting the domain specification into the domain - independent core grammar and lexicon to define a domain dependent context - free grammar .The method of claim 1 , wherein the domain dependent context - free grammar is suitable for use as a predictive grammar and parser in a natural language menu system .", "label": "", "metadata": {}, "score": "53.722443"}
{"text": "Hebrew : UTF-8 .However , the parser is able to parse text in any encoding , providing you pass the correct encoding option on the command line , for example : .-encoding ISO_8859 - 15 .( Or , when used within a program , it is your job to open files with the right kind of Reader / Writer . ) caseless.ser.gz - Loading parser from serialized file edu / stanford / nlp / models / lexparser / englishPCFG .", "label": "", "metadata": {}, "score": "53.798714"}
{"text": "Instead , we use distributional semantics to generate only the relevant part of an on - the - fly ontology .Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .", "label": "", "metadata": {}, "score": "53.825172"}
{"text": "To determine all the words that can come next , given that goal , the set of all nodes that are reachable from that node as a left daughter must be determined .Fortunately , this information is easily obtainable from the reachability matrix discussed earlier .", "label": "", "metadata": {}, "score": "53.940506"}
{"text": "Then we describe function MAKE - SEMANTIC - GRAMMAR .Finally , we describe the function MAKE - SEMANTIC - LEXICON .It is important to note initially that there is no assumption about who specifies the parameters to the function .", "label": "", "metadata": {}, "score": "53.941116"}
{"text": "Predicate structures are representations of logical relationships between the words in a sentence .Every predicate structure contains a predicate , which is either a verb or a preposition , and a set of arguments , which may be any part of speech .", "label": "", "metadata": {}, "score": "53.952957"}
{"text": "Primary acoustic , speech , and vision systems were trained to discriminate instances of the categories .Higher - level systems exploited correlations among the categories , incorporated sequential context , and combined the joint evidence from the three information sources .", "label": "", "metadata": {}, "score": "53.963806"}
{"text": "Questions with answers .In recent distributions , the models are included in a jar file inside the parser distribution .For example , in the 2012 - 11 - 12 distribution , the models are included in stanford - parser-2.0.4-models.jarThe easiest way to access these models is to include this file in your classpath .", "label": "", "metadata": {}, "score": "53.96531"}
{"text": "The LR table is created by considering different \" states \" of a parse .Each state consists of a description of similar parse states .These similar parse states are denoted by marked productions called items .E E \u00b7 + T . which indicates the state of the parse where we have seen a string derivable from E and are looking for a string derivable from + T. .", "label": "", "metadata": {}, "score": "53.975616"}
{"text": "Standard inference can be used at test time .Our approach is able to scale to very large problems and yields significantly improved target domain accuracy .It is well known that parsing accuracies drop significantly on out - of - domain data .", "label": "", "metadata": {}, "score": "53.996407"}
{"text": "There are ten pairs of states that can be merged in the items for Two of them and their merged states are : .State i State j State i - j E .LALR(1 ) parsers parse fewer language than do LR(1 ) parsers .", "label": "", "metadata": {}, "score": "54.025223"}
{"text": "SLR(1 ) parsers recognize many , but not all , of the constructs in typical programming languages .There is another type of parser which recognizes almost as many constructs as an LR(1 ) parser .This is called a LALR(1 ) parser and is constructed by first constructing the LR(1 ) items and states and them merging many of them .", "label": "", "metadata": {}, "score": "54.066326"}
{"text": "The relevant options are -sentences ( see above ) , -tokenized , -tokenizerFactory , -tokenizerMethod , and -tagSeparator .If , for example , you want to denote a POS tag by appending /POS on a word , you would include the options -tokenized -tagSeparator / -tokenizerFactory edu.stanford.nlp.process.WhitespaceTokenizer -tokenizerMethod newCoreLabelTokenizerFactory in your invocation of LexicalizedParser .", "label": "", "metadata": {}, "score": "54.089798"}
{"text": "All of these tasks are accomplished within the same framework , using a single , general learning method that can acquire new syntactic and semantic categories for resolving ambiguities .Experimental evidence from both aritificial and real - world corpora demonstrate that CHILL learns parsers as well or better than previous artificial neural network or probablistic approaches on comparable tasks .", "label": "", "metadata": {}, "score": "54.097717"}
{"text": "The best accuracies were in the 80 - 84\\% range for F1 and LAS ; even part - of - speech accuracies were just above 90\\% .Coarse - to - fine inference has been shown to be a robust approximate method for improving the efficiency of structured prediction models while preserving their accuracy .", "label": "", "metadata": {}, "score": "54.121273"}
{"text": "We feel that this is more useful for most semantic interpretation applications , because it directly connects the main predicate with its arguments , while the auxiliary is rendered as modifying the verb ( aux(singing , is ) ) .Most people seem to agree .", "label": "", "metadata": {}, "score": "54.171837"}
{"text": "While multiple LexicalizedparserQuery threads share the same grammar ( LexicalizedParser ) , the memory space savings are n't huge , as most of the memory goes to the transient data structures used in chart parsing .So , if you are running lots of parsing threads concurrently , you will need to give a lot of memory to the JVM .", "label": "", "metadata": {}, "score": "54.253525"}
{"text": "You can invoke it with the -escaper flag , by using a command like the following ( which also shows output being sent to a file ) : . stp .Word segmentation : Chinese is not normally written with spaces between words .", "label": "", "metadata": {}, "score": "54.31983"}
{"text": "5.2.1 LR - Family : Parser Driver .The driver reads the input and consults the table .The table has four different kinds of entries called actions : .Shift : .Shift is indicated by the \" S # \" entries in the table where # is a new state .", "label": "", "metadata": {}, "score": "54.32004"}
{"text": "The default ( \" \" ) is to add the extension .erl to Grammarfile stripped of the . yrl extension .Indicates a customized prologue file which the user may want to use instead of the default file lib / parsetools / include / yeccpre.hrl which is otherwise included at the beginning of the resulting parser file .", "label": "", "metadata": {}, "score": "54.339027"}
{"text": "The foregoing has described the \" build - interface \" function .The \" make - portable - spec \" function will now be discussed .The invention described herein is a component of a grammar - drive , menu - based system .", "label": "", "metadata": {}, "score": "54.36321"}
{"text": "7 is another example parse tree incorporating real words according to the present invention .DETAILED DESCRIPTION OF THE INVENTION .In the following detailed discussion of the present invention , numerous terms , specific to the subject matter of a system and method for concept - based searching , are used .", "label": "", "metadata": {}, "score": "54.36434"}
{"text": "The file erl_parse . yrl in the lib / stdlib / src directory contains the grammar for Erlang .Note .Syntactic tests are used in the code associated with some rules , and an error is thrown ( and caught by the generated parser to produce an error message ) when a test fails .", "label": "", "metadata": {}, "score": "54.439606"}
{"text": "To translate a source sentence , we first employ a parser to pro - duce a source parse tree and then ap - ply TATs to transform the tree into a tar - get string .Our experiments show that the TAT - based model significantly outper - forms Pharaoh , a state - of - the - art decoder for phrase - based models . .", "label": "", "metadata": {}, "score": "54.473038"}
{"text": "The term concept as used herein means an abstract formal representation of meaning , which corresponds to multiple generic or specific words in multiple languages .Concepts may represent the meanings of individual words or phrases , or the meanings of entire sentences .", "label": "", "metadata": {}, "score": "54.48342"}
{"text": "Knowledge bases contain instances of real data , which represent a location somewhere within the ontology .Validating the equivalence of an instance with a concept in an ontology entails comparing the features of an instance with the features of a concept .", "label": "", "metadata": {}, "score": "54.491825"}
{"text": "The \" universal projection \" problem involves a solution to the problem of a natural way to allow users to specify precisely what attributes they want returned when specifying a query .A general solution plus several particular solutions are being prototyped at CSL .", "label": "", "metadata": {}, "score": "54.510292"}
{"text": "LexicalizedParser -encoding utf-8 /u / nlp / data / lexparser / chineseFactored .ser.gz chinese-onesent-utf8.txt Loading parser from serialized file /u / nlp / data / lexparser / chineseFactored . ser.gz ... done [ 20.7 sec].Parsing file : chinese-onesent-utf8.txt with 2 sentences .", "label": "", "metadata": {}, "score": "54.519657"}
{"text": "Participants were to build a single parsing system that is robust to domain changes and can handle noisy text that is commonly encountered on the web .There was a constituency and a dependency parsing track and 11 sites submitted a total of 20 systems .", "label": "", "metadata": {}, "score": "54.55837"}
{"text": "ML ID : 269 .Learning to Interpret Natural Language Navigation Instructions from Observations [ Details ] [ PDF ] [ Slides ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th AAAI Conference on Artificial Intelligence ( AAAI-2011 ) , 859 - 865 , August 2011 .", "label": "", "metadata": {}, "score": "54.559135"}
{"text": "Yes .The parser treats a filename as - as meaning to read from stdin and by default writes to stdout ( this can be changed with the -writeOutputFiles option ) .Note : the tokenizer uses lookahead , so you will either need to close the input to get the last sentence parsed , or use another option like -sentences newline .", "label": "", "metadata": {}, "score": "54.572945"}
{"text": "Parse tree converter 240 receives the output of the parser 230 , and converts the parse trees into predicates .Following the Parse tree converter , parser filters 250 operate or the predicates to remove erroneously generated predicates based on rules about the probability of syntactic analyses , as well as rules about the compatibility of concepts with each other .", "label": "", "metadata": {}, "score": "54.65306"}
{"text": "To facilitate future research in unsupervised induction of syntactic structure and to standardize best - practices , we propose a tagset that consists of twelve universal part - of - speech categories .In addition to the tagset , we develop a mapping from 25 different treebank tagsets to this universal set .", "label": "", "metadata": {}, "score": "54.662933"}
{"text": "Larris Harris is responsible for the first important commercial venture that is based on AI technology .He developed the ROBOT system , now called INTELLECT and marketed on ON - LINE ENGLISH by Cullinaine .A database administrator is needed to create and build a lexicon for a fixed grammar and the system interfaces to a single file .", "label": "", "metadata": {}, "score": "54.772545"}
{"text": "And it is hard to find all such bugs by hand .One might forget to define some lexical categories , or define ( misspell ) categories that the grammar ca n't access .Or one might write rules such that the left hand side is not accessible from the root .", "label": "", "metadata": {}, "score": "54.779884"}
{"text": "The symbol \" t \" is merely a placeholding symbol , which is used in this formalism to permit proper application of the succeeding parser rules .Where an element is associated beneath another element , this provides one step in building up the tree of associated nodes which will eventually form a complete parse .", "label": "", "metadata": {}, "score": "54.94168"}
{"text": "This assumes that this is the first line of the input text , and that ' $ end ' is the distinguished end_of_input symbol .The Erlang scanner in the io module can be used as a starting point when writing a new scanner .", "label": "", "metadata": {}, "score": "54.942276"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 6 , wherein a first digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .", "label": "", "metadata": {}, "score": "55.023476"}
{"text": "For instance : .Parsing file : chinese - onesent with 1 sentences .Parsing [ sent .1 len .Parsed 10 words in 1 sentences ( 7.10 wds / sec ; 0.71 sents / sec ) .There are many kinds of ' vanilla ' , but , providing your treebank is in Penn Treebank format , then , yes , this is easy to do .", "label": "", "metadata": {}, "score": "55.026966"}
{"text": "In general , the translation of leftmost number applies to the translation of the number to its right as the argument .The result of this then is a function which applies to the translation of the item to its right as the argument .", "label": "", "metadata": {}, "score": "55.142517"}
{"text": "The companion patent by Tennant , Ross , and Saenz describes an invention that overcomes the difficulties involving \" ease of use \" of natural language interfaces ( and also formal language interfaces -- see next subsection ) .The second reason why natural language interfaces to databases are not in common use today is the large amount of time it has traditionally taken to construct a natural language interface .", "label": "", "metadata": {}, "score": "55.14354"}
{"text": "ML ID : 229 .A Dependency - based Word Subsequence Kernel [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the conference on Empirical Methods in Natural Language Processing ( EMNLP-2008 ) , 400 - -409 , Waikiki , Honolulu , Hawaii , October 2008 .", "label": "", "metadata": {}, "score": "55.162598"}
{"text": "We present a new generative alignment model which avoids these structural limitations , and show that it is effective when trained using both unsupervised and semi - supervised training methods . ... lar to work using discriminative log - linear models for alignment , which is similar to discriminative log - linear models used for the SMT decoding ( translation ) problem ( Och and Ney , 2002 ; Och , 2003 ) .", "label": "", "metadata": {}, "score": "55.24272"}
{"text": "By default , our Chinese parser uses GB18030 ( the native character encoding of the Penn Chinese Treebank and the national encoding of China ) for input and output .However , it is very easy to parse text in another character encoding : you simply give the flag -encoding encoding to the parser , where encoding is a character set encoding name recognized within Java , such as : UTF-8 , Big5-HKSCS , or GB18030 .", "label": "", "metadata": {}, "score": "55.27864"}
{"text": ", 2009 ; Biber & Gray , 2010 ) , but the most interesting usages apply the divergence to a machine learning system .Despite the fact that authors have shown that a divergence ( Van Asch & Daelemans , 2010 ; Plank , 2011 ) or a linear combination of divergences ( McClosky , 2010 ) can be successfully used to link the sim ... . \" ...", "label": "", "metadata": {}, "score": "55.376766"}
{"text": "Our first- , second- , and third - order models achieve accuracies comparable to those of their unpruned counterparts , while exploring only a fraction of the search space .We observe speed - ups of up to two orders of magnitude compared to exhaustive search .", "label": "", "metadata": {}, "score": "55.390827"}
{"text": "A side benefit from this algorithm is that it provides an intuitive , natural ranking algorithm .Larger values from the subtraction operation mean further distance apart in the tree , so even when two concepts are in the same branch , the representation provides a convenient metric of conceptual distance .", "label": "", "metadata": {}, "score": "55.395935"}
{"text": "Unfortunately the relationship between alignment quality and statistical machine translation performance has not been well understood .In the recent literature the alignment task has frequently been decoupled from the ... \" .Automatic word alignment plays a critical role in statistical machine translation .", "label": "", "metadata": {}, "score": "55.402885"}
{"text": "Here are example commands for parsing two of the test files , one in UTF-8 and one in GB18030 .The ( Linux ) computer that this is being run on is set up to work with UTF-8 ( and this webpage is also in UTF-8 ) , so for the case of GB18030 , the output is piped through the Unix iconv utility for display .", "label": "", "metadata": {}, "score": "55.408905"}
{"text": "Unlike conventional reranking used in syntactic and semantic parsing , gold - standard reference trees are not naturally available in a grounded setting .Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .", "label": "", "metadata": {}, "score": "55.469215"}
{"text": "These trees are implemented via a variety of techniques , which are generally equivalent to doubly - linked lists .Doubly - linked lists must be created with head and tail nodes , which terminate the list and are designed to keep traversals of the list in bounds .", "label": "", "metadata": {}, "score": "55.497093"}
{"text": "Using the present invention , people who have never seen a lisp machine before can formulate interesting queries using automatically generated natural language interfaces , as often happens in our demos .None of the other researchers have reported that their automatically generated natural language unterfaces are usable ( with the exception of Larry Harris and he has not carefully documented his claims in the literature ) .", "label": "", "metadata": {}, "score": "55.516373"}
{"text": "Yes , you can .Various tokenizers are included .The one used for English is called PTBTokenizer .It is a hand - written rule - based ( FSM ) tokenizer , but is quite accurate over newswire - style text .", "label": "", "metadata": {}, "score": "55.517784"}
{"text": "Associated with each phrase structure rule , there is a set of rules which indicates how to pass the features around .These will be referred to as feature percolation rules .Once a feature value is assigned for a particular node , it does not change .", "label": "", "metadata": {}, "score": "55.51865"}
{"text": "The ADVANTAGES of this invention are that an end user can construct his own interface knowing nothing about grammars and lexicons so no specialist is required .The process of specifying the parameters to the MAKE - PORTABLE - INTERFACE routine takes minutes , not weeks or months .", "label": "", "metadata": {}, "score": "55.57415"}
{"text": "Specific HELP is available on each of these operations using ( ( the HELP key ) ) .Using the BUILD INTERFACES CREATE or MODIFY commands , a user can specify all the parameters he needs to create a new natural language interface .", "label": "", "metadata": {}, "score": "55.5956"}
{"text": "For example , another possible encoding of the ontology tree might involve a 40-digit decimal number .In such a case , 4 digits could be assigned to each node of the tree , implying that the tree could have up to 10 levels of depth .", "label": "", "metadata": {}, "score": "55.59729"}
{"text": "Specifically , I will present two probabilistic generative models for learning such correspondences .The models are applied to two publicly available datasets in two different domains , sportscasting and navigation , and compared with previous work on the same data .", "label": "", "metadata": {}, "score": "55.60146"}
{"text": "Despite the much simplified training process , our acoustic model achieves state - of - the - art results on phone classification ( where it outperforms almost all other methods ) and competitive performance on phone recognition ( where it outperforms standard CD triphone / subphone / GMM approaches ) .", "label": "", "metadata": {}, "score": "55.613815"}
{"text": "The algorithm uses a similarity graph to encourage similar n - grams to have similar POS tags .We demonstrate the efficacy of our approach on a domain adaptation task , where we assume that we have access to large amounts of unlabeled data from the target domain , but no additional labeled data .", "label": "", "metadata": {}, "score": "55.63308"}
{"text": "We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .", "label": "", "metadata": {}, "score": "55.63891"}
{"text": "For part of speech and phrasal categories , here are relevant links : .Please read the documentation for each of these corpora to learn about their tagsets and phrasal categories .You can often also find additional documentation resources by doing web searches .", "label": "", "metadata": {}, "score": "55.64579"}
{"text": "The process by which an unskilled user constructs a portable specification for a natural language menu interface will now be described with reference to the example shown in FIGS . 1 - 11 .The relevant database must initially be loaded into the system .", "label": "", "metadata": {}, "score": "55.662952"}
{"text": "APPLICATION AREAS OTHER THAN RELATIONAL DATABASES .Generating interfaces to hierarchical or network or other databases or to a single file databases : .There is every reason to believe that translations written for a relational system would be replaced by equivalent translations for a newtwork or hierarchical or other dbms .", "label": "", "metadata": {}, "score": "55.740776"}
{"text": "We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .", "label": "", "metadata": {}, "score": "55.805458"}
{"text": "A grammar for parsing infix arithmetic expressions into prefix notation , without operator precedence : .The same with operator precedence becomes simpler : .Rootsymbol E. Left 100 ' + ' .An overloaded minus operator : .Nonterminals E uminus .", "label": "", "metadata": {}, "score": "55.81721"}
{"text": "ML ID : 57 .Lexical Acquisition : A Novel Machine Learning Problem [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Technical Report , Artificial Intelligence Lab , University of Texas at Austin , January 1996 .", "label": "", "metadata": {}, "score": "55.82694"}
{"text": "This structure guarantees that an arbitrary number of nodes may be inserted into the list without losing track of the locations of existing nodes , as well as enabling the list to be searched from either the top or bottom .However , the great flexibility of tree data structures , which may encompass trees of arbitrary depth , also imposes a significant cost in computability .", "label": "", "metadata": {}, "score": "55.92595"}
{"text": "By using a top - down approach to heuristically guide the construction of generalizations of a bottom clause , Beth combines the strength of both approaches .Learning patterns for detecting potential terrorist activity is a current challenge problem for relational data mining .", "label": "", "metadata": {}, "score": "55.96117"}
{"text": "Learning for Semantic Parsing Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] [ Slides ] Ruifang Ge PhD Thesis , Department of Computer Science , University of Texas at Austin , Austin , TX , May 2010 .165 pages .", "label": "", "metadata": {}, "score": "56.019356"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said noun filter groups proper nouns into single lexical nouns .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "56.031967"}
{"text": "FIG .3 , for the input string ' ab . 'An example of a context - free grammar that would be used in implementing the parser is as follows : .The modified LALR parser generator , grammar , and modified LALR parsing engine discussed previously should generate a non - deterministic recursive parser .", "label": "", "metadata": {}, "score": "56.058056"}
{"text": "is put on stack gamma . \" indicates that there are no contents to the stack . ) , V2 . . .Vn t X , A Y ) ( 1 ) .Briefly , the reachability matrix excludes impossible word sequences , such as \" the the \" , among other things .", "label": "", "metadata": {}, "score": "56.104355"}
{"text": "Formally , a PORTABLE SPEC is described as follows : .In the appendix are included the BUILD - INTERFACE nlmenu grammar , lexicon , window descriptions , and expert definitions that precisely define the current prototype BUILD interfaces interface .The lexical entries contain help text that describes the meaning of the commands and categories like TABLE JOINS , etc .", "label": "", "metadata": {}, "score": "56.12107"}
{"text": "A pointing device ( or selection from a keyboard ) is used to make the selections of completing phrases from a menu or menus .So an NLMENU - driven interface answers the set of objections to natural language interfaces that involve \" ease of use \" of the interface .", "label": "", "metadata": {}, "score": "56.142014"}
{"text": "The ATIS corpus of airline information queries was used to test the acquisition of syntactic parsers , and CHILL performed competitively with recent statistical methods .English queries to a small database on U.S. geography were used to test the acquisition of a complete natural language interface , and the parser that CHILL acquired was more accurate than an existing hand - coded system .", "label": "", "metadata": {}, "score": "56.15291"}
{"text": "The k best parses are extracted efficiently using the algorithm of Huang and Chiang ( 2005 ) .This may be because the parser chose an incorrect structure for your sentence , or because the phrase structure annotation conventions used for training the parser do n't match your expectations .", "label": "", "metadata": {}, "score": "56.194496"}
{"text": "Active learning methods attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .However , existing results for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to two non - classification tasks in natural language processing : semantic parsing and information extraction .", "label": "", "metadata": {}, "score": "56.240646"}
{"text": "Let 's throw this out of your grammar , and work with a slightly simpler grammar : . we 're also going to assume that NUM is something you get from the lexer ( i.e. , it 's just a token ) .", "label": "", "metadata": {}, "score": "56.270668"}
{"text": "This is done by running through all rules and compiling a list .This process ( highlighted menu , user selection , parse , new highlighted menu ) is then continued , until the user indicates that he is finished with the sentence which he wishes to input .", "label": "", "metadata": {}, "score": "56.321785"}
{"text": "The results show that an unsupervised technique based on topic models is effective - it outperforms random data selection on both languages examined , English and Dutch .Moreover , the technique works better than manually assigned labels gathered from meta - data that is available for English . ...", "label": "", "metadata": {}, "score": "56.407074"}
{"text": "IS creating the new non terminal the only way of fixing this problem ?I do nt know if I am allowed to change the grammar - user1072706 Mar 22 ' 12 at 11:38 .For this one you can just check to see if the else is there since they are in the same non - terminal , but the better solution is to modify the grammar .", "label": "", "metadata": {}, "score": "56.417507"}
{"text": "You can use recursive descent to generate a parse tree , then change the order of traversal to process arithmetic .-Hunter McMillen Mar 22 ' 12 at 0:54 .@HunterMcMillen , exactly true , and this gets done , but it 's a nasty hack for more complicated structures at times , and having to do it instead when you can use a parser generator instead is often proffered . -", "label": "", "metadata": {}, "score": "56.428703"}
{"text": "We show how web mark - up can be used to improve unsupervised dependency parsing .Starting from raw bracketings of four common HTML tags ( anchors , bold , italics and underlines ) , we refine approximate partial phrase boundaries to yield accurate parsing constraints .", "label": "", "metadata": {}, "score": "56.45067"}
{"text": "We show how web mark - up can be used to improve unsupervised dependency parsing .Starting from raw bracketings of four common HTML tags ( anchors , bold , italics and underlines ) , we refine approximate partial phrase boundaries to yield accurate parsing constraints .", "label": "", "metadata": {}, "score": "56.45067"}
{"text": "The algorithm is the same as for creating LR(0 ) items except the closure step which now needs to be modified to include the lookahead character : .Closure : .IF A x \u00b7 X y , L is in the state , where L is the set of lookaheads , THEN add X \u00b7 z , FIRST ( y/ ) for each / in L to the state for every X z. .", "label": "", "metadata": {}, "score": "56.456497"}
{"text": "We can then subtract numbers to see if the features are in agreement , and a non - negative result suffices to prove this .Since 1 is nonnegative , we know that the features are in agreement .If concepts are identical , they will subtract to zero , which is equivalent to passing the filter by having two identical strings .", "label": "", "metadata": {}, "score": "56.469425"}
{"text": "It would certainly be possible to compute these dynamically , since any tree - search algorithm must keep track of which branches it traverses in trying to locate a particular node .However , as the search backtracks and corrects its path a fair number of adjustments and recalculations of the current node value would likely result .", "label": "", "metadata": {}, "score": "56.501076"}
{"text": "And simply walking a sentence and consuming it is n't quite the same as parsing it .You 'll want to do something as you consume the pieces , possibly building up a parse tree ( which means these functions probably return something ) .", "label": "", "metadata": {}, "score": "56.625626"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees that fall below a minimum probability for semantic interpretation .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "56.676544"}
{"text": "That is , some users should be permitted to look at , but not to modify , some tables .The system of the presently preferred embodiment includes an access check off table , whereby the person creating the table can define who has access to that table , and for what purposes .", "label": "", "metadata": {}, "score": "56.68656"}
{"text": "Integrating Statistical and Relational Learning for Semantic Parsing : Applications to Learning Natural Language Interfaces for Databases [ Details ] [ PDF ] Lappoon R. Tang May 2000 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .", "label": "", "metadata": {}, "score": "56.736206"}
{"text": "To do this , apply one of the rules that are applicable , get a new state , and then apply one of the applicable rules to that new state .Continue this until either no rules apply or no parse is found .", "label": "", "metadata": {}, "score": "56.741768"}
{"text": "As in LL(1 ) parsing , the driver discovers that something is wrong when a token which can not be used in a reduction is pushed onto the stack .Error repair consists of adding or deleting tokens to restore the parse to a state where parsing may continue .", "label": "", "metadata": {}, "score": "56.785114"}
{"text": "The values initially associated with terminal category phrases , i.e. input tokens , are the token tuples themselves .Below is an example of the grammar above with structure building code added : .With this code added to the grammar rules , the parser produces the following value ( structure ) when parsing the input string ( a b c ) .", "label": "", "metadata": {}, "score": "56.82882"}
{"text": "Default is false .If this flag is set , an extra field containing Warnings is added to the tuple returned upon success .Default is false .This is a short form for both return_errors and return_warnings .Determines whether the parser generator should give full information about resolved and unresolved parse action conflicts ( true ) , or only about those conflicts that prevent a parser from being generated from the input grammar ( false , the default ) .", "label": "", "metadata": {}, "score": "56.832893"}
{"text": "Initially , the system will passively observe a human giving instruction to another human , and try to learn the correspondences between the instructions and the intended plan .After the system has a decent understanding of the language , it can then participate in the interactions to learn more directly by playing either the role of the instructor or the follower .", "label": "", "metadata": {}, "score": "56.850754"}
{"text": "Second , adopting a syntax - based approach allows us to directly leverage the enormous progress made in statistical syntactic parsing .The first semantic parser , SCISSOR , adopts an integrated syntactic - semantic parsing approach , in which a statistical syntactic parser is augmented with semantic parameters to produce a semantically - augmented parse tree ( SAPT ) .", "label": "", "metadata": {}, "score": "56.864395"}
{"text": "There 's not much in the way of secret sauce to speed that up ( partly by the design of the parsers as guaranteed to find model optimal solutions ) .If you 're not using englishPCFG.ser.gz for English , then you should be - it 's much faster than the Factored parser .", "label": "", "metadata": {}, "score": "56.93878"}
{"text": "For example , in an information retrieval application , it is capable of pulling out stopwords and unintended query words ( as in the pseudo - concept and pseudo - predicate filters ) .In the embodiment discussed above , the grammar violation checking of the system and method of the present invention filters both by the probability of a syntactically successful parse and the compatibility of the lexical semantics of words in the ontology .", "label": "", "metadata": {}, "score": "57.00496"}
{"text": "Still another object of the present invention is to provide a system and method for parsing natural language input that transforms data using a syntactic parser and ontology , where the ontology is used as a lexical resource .Yet another object of the present invention is to provide a system and method for parsing natural language input that provides ontological entities as output that are predicate - argument structures .", "label": "", "metadata": {}, "score": "57.017162"}
{"text": "We introduce a dialog agent for mobile robots that understands human instructions through semantic parsing , actively resolves ambiguities using a dialog manager , and incrementally learns from human - robot conversations by inducing training data from user paraphrases .Our dialog agent is implemented and tested both on a web interface with hundreds of users via Mechanical Turk and on a mobile robot over several days , tasked with understanding navigation and delivery requests through natural language in an office environment .", "label": "", "metadata": {}, "score": "57.051872"}
{"text": "This rule means that the translation of A is taken as a function and applied to the translation of B as its argument .This resulting new translation is then taken as a function and applied to the translation of 4 as its argument .", "label": "", "metadata": {}, "score": "57.067245"}
{"text": "Unary 300 uminus .The Yecc grammar that is used for parsing grammar files , including itself : .Nonterminals grammar declaration rule head symbol symbols attached_code token tokens .Rootsymbol grammar .Endsymbol ' $ end ' .Erlang code .", "label": "", "metadata": {}, "score": "57.082703"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said pseudo - concept filter removes concepts from queries .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "57.085907"}
{"text": "1 len .2 len .Parsed 14 words in 2 sentences ( 6.55 wds / sec ; 0.94 sents / sec ) .Parsing file : chinese - onesent with 1 sentences .Parsing [ sent .1 len .Parsed 10 words in 1 sentences ( 10.78 wds / sec ; 1.08 sents / sec ) .", "label": "", "metadata": {}, "score": "57.136124"}
{"text": "Labeled data typically requires expert annotators which makes it both time consuming and costly to produce .Furthermore , once training data has been created for one textual domain , portability to similar domains is limited .This domain - dependence has inspired a large body of work since syntactic parsing aims to capture syntactic patterns across an entire language rather than just a specific domain .", "label": "", "metadata": {}, "score": "57.18708"}
{"text": "ML ID : 92 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia Ann Thompson PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , December 1998 .", "label": "", "metadata": {}, "score": "57.249092"}
{"text": "In turn , the features of these nodes could be determined by their mother node , daughter nodes , or sister nodes .This in effect means that information from anywhere in the tree can be transmitted to the nodes which determine the features of Nom1 .", "label": "", "metadata": {}, "score": "57.255928"}
{"text": "The modal verb filter will contain a set of modal verbs similar to the stop word list contained in stop word filter .Any Lexeme whose text is in that set and whose concept is a verb is identified as a modal verb , and will be removed .", "label": "", "metadata": {}, "score": "57.25741"}
{"text": "A key to intelligent design is leaving room for expansion .As long as the maximum depth of trees is not reached , adding additional levels is transparent .The trade - off in a parameterized ontology is selecting the size of a data structure so that it is no larger than it needs to be , but with adequate room for correcting mistakes or expanding coverage later on .", "label": "", "metadata": {}, "score": "57.274883"}
{"text": "This , for example , makes it possible to parse from a file , token by token .The tokenizer used above has to be implemented so as to return one of the following : .This conforms to the format used by the scanner in the Erlang io library module .", "label": "", "metadata": {}, "score": "57.329216"}
{"text": "Without the temporal annotation , some simple temporals like today will still be recognized , but a bare temporal like last week in I left last week will be tagged as an object ( dobj ) .With the Stanford parser , you can get marking of temporal NPs in the tree output by giving the option -retainTmpSubcategories , either on the command line or by passing it to the setOptionFlags(String [ ] ) method of the parser .", "label": "", "metadata": {}, "score": "57.332222"}
{"text": "MORE is inserted after that word .If no other instructions apply and !MORE is on top of stack alpha , the current contents of the beta and gamma stacks are saved and the parser backtracks to the last place that parse paths were split .", "label": "", "metadata": {}, "score": "57.335873"}
{"text": "If the ontological tree structure is carefully crafted , proximity within the tree should , in some measure , correspond to ontological proximity .Therefore , detecting the first digit difference , as above , gives a reasonable measure of the degree of ontological proximity of the two concepts .", "label": "", "metadata": {}, "score": "57.37139"}
{"text": "Often , that works out okay , but , overall , results wo n't be quite as good .The default character encoding depends on the language that you are parsing .It is defined in the appropriate TreebankLanguagePack class .That is , it will never default to your platform default character encoding .", "label": "", "metadata": {}, "score": "57.380005"}
{"text": "The stop word filter will contain a set of words accepted as stop words ; any lexeme whose text is in that set is considered to be a stop word .An adjective filter serves to remove lexemes representing adjective concepts from sentences .", "label": "", "metadata": {}, "score": "57.4819"}
{"text": "Current statistical parsers tend to perform well only on their training domain and nearby genres .While strong performance on a few related domains is sufficient for many situations , it is advantageous for parsers to be able to generalize to a wide variety of domains .", "label": "", "metadata": {}, "score": "57.578533"}
{"text": "Current statistical parsers tend to perform well only on their training domain and nearby genres .While strong performance on a few related domains is sufficient for many situations , it is advantageous for parsers to be able to generalize to a wide variety of domains .", "label": "", "metadata": {}, "score": "57.578533"}
{"text": "This can be done either directly by accessing the phrase structure rules or indirectly by first computing the reachability matrix and then looking at all pairs X and Y such that X can dominate Y as a left daughter .The preferred embodiment uses the first method .", "label": "", "metadata": {}, "score": "57.58249"}
{"text": "Genia ( biomedical English ) .Originally we used the treebank beta version reformatted by Andrew Clegg , his training split , but more recently ( 1.6.5 + ? ) we 've used the official Treebank , and David McClosky 's splits .", "label": "", "metadata": {}, "score": "57.63774"}
{"text": "So a user might than choose from a menu of all suplier names in the database .The menu phrase is of the form \" x \" or \" x or y \" or \" x , y , . . .", "label": "", "metadata": {}, "score": "57.7585"}
{"text": "I must write methods S ( ) l ( ) and E ( ) and return some error messages but the tutorials I have found online have not helped a lot .Can anyone point me in the right direction ? , give me some examples ?", "label": "", "metadata": {}, "score": "57.797283"}
{"text": "When the user mouses one of these , he is then presented , in a little window , with a list of the names of specific suppliers , which is gathered from the database in real time .Thus , these non - word items displayed on the menu add a great deal of versatility and user convenes to this system .", "label": "", "metadata": {}, "score": "57.851402"}
{"text": "This chapter discusses parser generators , a much - researched and developed area of computer science .The space occupied by the generated parse tables is considerable , containing thousands of entries .LL(1 ) tables are smaller than LALR(1 ) , by a ratio of about two - to - one .", "label": "", "metadata": {}, "score": "57.88262"}
{"text": "Two new integrated ILP systems for these tasks that overcome limitations of existing methods will be presented .Cocktail is a new ILP algorithm for inducing semantic parsers .For this task , two features of a parse state , functional structure and context , provide important information for disambiguation .", "label": "", "metadata": {}, "score": "57.890816"}
{"text": "Dougherty ( 1970 , 1971 ) enriches the mechanism which Chomsky ( 1965 ) utilizes to assign features and thereby is able to assign features to some nonterminal nodes .The grammar used by the TQA ( Transformational Question Answering ) described in Plath ( 1973 ) assignes features to non - terminal nodes by transformation .", "label": "", "metadata": {}, "score": "57.894394"}
{"text": "These works aim to predict the parser performance on a given target sentence .Ravi et al .( 2008 ) frame this as a regression problem .Kawahara and Uchimoto ( 2008 ) treat ... . \" ...Genre classification has been found to improve performance in many applications of statistical NLP , including language modeling for spoken language , domain adaptation of statistical parsers , and machine translation .", "label": "", "metadata": {}, "score": "57.90578"}
{"text": "Languages such as Japanese or Russian , which permit free ordering of words , but mark intended usage by morphological changes , would be difficult to parse using the Brash system .The patent to Hemphill et al .( U.S. Pat .", "label": "", "metadata": {}, "score": "57.94802"}
{"text": "Refer to the yacc documentation on the use of operator precedence .The output file contains Erlang source code for a parser module with module name equal to the Parserfile parameter .After compilation , the parser can be called as follows ( the module name is assumed to be myparser ): .", "label": "", "metadata": {}, "score": "58.018814"}
{"text": "Finally , we also plan to investigate ways to combine our semantic parser with some recently developed semantic parsers to form committees in order to get the best overall performance .ML ID : 181 .Learning for Semantic Parsing Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong 2005 .", "label": "", "metadata": {}, "score": "58.062805"}
{"text": "It should be readily apparent that the ordering of elements of the code can be arbitrary , but must be used consistently in order to compare features .There are two ways to construct a parameterized ontology .The first method is to simply freeze an existing ontology , write a program to find the maximum tree depths and number of branches , and then write another program to recode the pointer information into array elements and depths .", "label": "", "metadata": {}, "score": "58.129913"}
{"text": "the interface will be error free .the interface can be treated as a database object and granted to other users who can then use the natural language to access their data .Thus , it is object of the present invention to provide a method for rapidly instructing a natural - language menu interface system which is customized according to a particular users needs .", "label": "", "metadata": {}, "score": "58.18239"}
{"text": "Again using January 2014 version 3.3.1 as an example , you would not make your classpath -cp stanford - parser-3.3.1.jar Instead , you would make it Windows : -cp stanford - parser-3.3.1 . jar : stanford - parser-3.3.1-models.jar .In order to see exactly which models are available , you can use jar tvf stanford - parser-3.3.1-models.jar This will show you that to access the Arabic Factored model , for example , you would use the path edu / stanford / nlp / models / lexparser / arabicFactored . ser.gz .", "label": "", "metadata": {}, "score": "58.210243"}
{"text": "The elimination of the second class of rules causes no difficulty and does not impair a grammar writer in any way .The elimination of the first class of rules causes a small inconvenience in that it prevents grammar writers from using the existence of null nodes in parse trees to account for certain unbounded dependencies like those found in questions like \" Who do you think I saw ? \" which are said in some linguistic theories to contain a null noun phrase after the word \" saw \" .", "label": "", "metadata": {}, "score": "58.39955"}
{"text": "Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .", "label": "", "metadata": {}, "score": "58.46722"}
{"text": "Two papers by Kurt Konolige ( Konolige 1979 ) and ( Konolige , 1980 ) are related to this work .The 1979 paper ( a tech report ) describes a framework for a portable natural language interface to a database .", "label": "", "metadata": {}, "score": "58.4699"}
{"text": "The decision - making process occurs at intermediate parsing stages , and parse probabilities are considered before all parse paths have been pursued .Intermediate parse probability calculations have to be stored , and the system has to check for intermediate feature clashes .", "label": "", "metadata": {}, "score": "58.47621"}
{"text": "Step ( 1 ) .Parsing begins with state 0 on the stack and the input terminated by \" $ \" : .Stack Input Action .Consulting the table , across from state 0 and under input I d , is the action S5 which means to S hift ( push ) the input onto the stack and go to state 5 .", "label": "", "metadata": {}, "score": "58.510094"}
{"text": "Stack Input Action .We remove everything on the stack that includes the handle .Here , this is i d 5 .The stack now contains only 0 .Since the left - hand side of production 6 will be pushed on the stack , consult the GOTO part of the table across from state 0 ( the exposed top state ) and under F ( the left - hand side of the production ) .", "label": "", "metadata": {}, "score": "58.67927"}
{"text": "This paper revisits an assump - tion that genre variation is continuous along multiple dimensions , and an early use of principal component analysis to find these dimensions .Results on a very heterogeneous corpus of post-1990s American English reveal four major dimensions , three of which echo those found in prior work and the fourth depending on features not used in the earlier study .", "label": "", "metadata": {}, "score": "58.736618"}
{"text": "I consume keywords and call the functions corresponding to production rules as I encounter them .Translating from pseudocode to real code is n't too complicated , but it is n't trivial .Those peeks and consumes probably do n't actually operate on strings .", "label": "", "metadata": {}, "score": "58.737877"}
{"text": "We would recommend their use for parsing material from mainland China .The chinese grammars also include some training material from Hong Kong SAR and Taiwan .We 'd recommend their use if parsing material from these areas or a mixture of text types .", "label": "", "metadata": {}, "score": "58.759567"}
{"text": "5.2.4 LR - Family Members .In Section 5.2.2 , LR(0 ) states were created : no lookahead was used to create them .We did , however , consider the next input symbol(one symbol lookahead ) when creating the table ( see SLR table construction algorithm ) .", "label": "", "metadata": {}, "score": "58.764946"}
{"text": "In the inner loop , for every rel attr pair , the substitution is done .In the example above , 9 such rules will result from the pair of loops .The other patent describes the meaning of the translations .", "label": "", "metadata": {}, "score": "58.835674"}
{"text": "These define what interfaction takes place when a user chooses ( specific tablename - attributename from the EXPERTS menu .EDITED - ITEMS -- the owner of an interface may edit the phrasing of menu items .The system keeps track of the original and new phrasing .", "label": "", "metadata": {}, "score": "58.855164"}
{"text": "That patent application solves many of the problems having to do with \" ease - of - use \" of natural language interfaces .The present invention solves the second problem , of making natural language interfaces easy to build and maintain , in the very important special case of relational databases and in the context of a grammar - driven , menu - based interface drive .", "label": "", "metadata": {}, "score": "58.89324"}
{"text": "Existing hand - crafted systems can provide in - depth analysis of domain sub - languages , but are often notoriously fragile and costly to build .Existing machine - learned systems are considerably more robust , but are limited to relatively shallow NLP tasks .", "label": "", "metadata": {}, "score": "58.984436"}
{"text": "For future work , I am proposing to solve the more complex task of learning how to give and receive navigation instructions in a virtual environment .In this setting , each instruction corresponds to a navigation plan that is not directly observable .", "label": "", "metadata": {}, "score": "59.00351"}
{"text": "Having described several embodiments of the concept - based indexing and search system in accordance with the present invention , it is believed that other modifications , variations and changes will be suggested to those skilled in the art in view of the description set forth above .", "label": "", "metadata": {}, "score": "59.064285"}
{"text": "( The relational tables can be real or virtual , i.e. recreated ad hoc from existing tables . )First , the user is offered a selection of functions which can be performed , such as create interface , drop interface , grant access to interface , etc .", "label": "", "metadata": {}, "score": "59.1941"}
{"text": "The LOGICAL VIEW of a database can consist of a set of two dimensional tables .Physically , these tables might actually be represented in a hierarchy or network structure , since those structures are often more efficient .DATA INDEPENDENCE is the property of a database system whereby the logical view of data stays the same even when the physical view is changed .", "label": "", "metadata": {}, "score": "59.20648"}
{"text": "Most natural language interfaces to database systems have been prototypes , built by the research community .The primary application for natural language interfaces has been to natural language database query systems .Some of these prototype systems include the LUNAR system ( Woods et al .", "label": "", "metadata": {}, "score": "59.282093"}
{"text": "To turn these off , you can use the following options : .At present , we do n't have any documentation beyond what you get in the download and what 's on this page .If you would like to help by producing better documentation , feel free to write to parser-support@lists.stanford.edu .", "label": "", "metadata": {}, "score": "59.302616"}
{"text": "If your file is extremely large , splitting it into multiple files and parsing them sequentially will reduce memory usage .A 64-bit application requires more memory than a 32-bit application ( Java uses lots of pointers ) .", "label": "", "metadata": {}, "score": "59.30896"}
{"text": "In this paper , we address two issues that are related to domain adaptation .The first question is how much genre variation will affect NLP systems ' performance .We investigate the effect of genre variation on the performance of three NLP tools , namely , word segmenter , POS tagger , and parser .", "label": "", "metadata": {}, "score": "59.31128"}
{"text": "This operation may be accomplished in several ways : .If the ontology used by the parser only contains string labels for the nodes in a tree structure , the tree leading to the restriction must be established as a sub - tree of the selectional features of the argument .", "label": "", "metadata": {}, "score": "59.325336"}
{"text": "The second modification is a mechanism which will allow feature names and values to be assigned to nonterminal nodes .The idea that nonterminal nodes have features associated with them has been implicit in many syntactic analyses which have been proposed .", "label": "", "metadata": {}, "score": "59.355553"}
{"text": "Since the parser is both probabilistic and operating on multiple streams of possible ontological entities , it is necessary to prune out spurious parse trees generated by the parser 230 .Parser filters 250 are designed to prune out spurious parse trees generated by the parser 230 , by removing trees that violate either statistical or ontological criteria for well - formed - ness .", "label": "", "metadata": {}, "score": "59.36676"}
{"text": "A predicate structure is a data type that includes a predicate and multiple additional concepts ; as a grouping of concepts , it is itself a concept .An ontology is a hierarchically organized complex data structure that provides a context for the lexical meaning of concepts .", "label": "", "metadata": {}, "score": "59.405663"}
{"text": "A proper noun is any word or phrase representing a non - generic noun concept .Although a number of proper nouns are already present in the lexicon , they are already properly treated as regular lexical items .Since proper nouns behave syntactically as regular nouns , there is no need to distinguish proper nouns and nouns already in the lexicon .", "label": "", "metadata": {}, "score": "59.521782"}
{"text": "This means that the feature values of the nodes of any subtree can only depend on the feature values within that subtree .This is accomplished by restricting feature percolation rules so that features will only percolate up the tree , not down .", "label": "", "metadata": {}, "score": "59.608482"}
{"text": "Training data consists of natural language sentences annotated with multiple potential meaning representations , only one of which is correct .Such ambiguous supervision models the type of supervision that can be more naturally available to language - learning systems .Given such weak supervision , our approach produces a semantic parser that maps sentences into meaning representations .", "label": "", "metadata": {}, "score": "59.646652"}
{"text": "DESCRIPTION OF THE PREFERRED EMBODIMENTS .The invention provides a means of generating a semantic grammar and a semantic lexicon from a condensed collection of parameters .The basic operation of the natural language menu interface system will first be described , and then the features of the present invention , which permit very rapid construction of a user - customized implementation of such a natural language interface system , will then be described .", "label": "", "metadata": {}, "score": "59.806053"}
{"text": "Endsymbol ' $ end ' .Next comes one or more declarations of operator precedences , if needed .These are used to resolve shift / reduce conflicts ( see yacc documentation ) .Examples of operator declarations : .Left 300 ' + ' .", "label": "", "metadata": {}, "score": "59.82066"}
{"text": "Either form of list will pass the tags to the parser .Or you can do this with code that you write .Here 's an example that very manually makes the List in question : . ; List .There are other constraints which can be added , but they have to be added programmatically .", "label": "", "metadata": {}, "score": "59.85733"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .", "label": "", "metadata": {}, "score": "59.973328"}
{"text": "YACC produces a parser which is a C program .This C program can be compiled and linked with other compiler modules , including the scanner generated by LEX or any other scanner .Versions which have been ported to other operating systems can produce programs in other languages such as Pascal or Ada .", "label": "", "metadata": {}, "score": "59.99472"}
{"text": "The method of claim 4 , wherein step ( d ) is done independently from and prior to execution of the natural language menu system .A system for generating a context - free grammar suitable for use as an input to a natural language menu system , comprising : . an input file containing a definition for a domain - independent context - free grammar ; . an input file containing a definition for a domain - independent lexicon ; . a file containing a domain specification which is specific to a preselected application to be run under the natural language menu system ; . a processor coupled to the grammar and lexicon input files and to the domain specification file , wherein the domain specification file is merged with the grammar and lexicon input files to create a domain dependent context free grammar .", "label": "", "metadata": {}, "score": "60.068405"}
{"text": "Since algorithm design and implementation are distinct and separable issues , an embodiment of a parameterized ontology 's data structures has not yet been discussed .The following is a suggested implementation .The proposed data structure includes an integer value , where each digit of the integer corresponds to a specific branch taken at the corresponding level in the tree .", "label": "", "metadata": {}, "score": "60.129463"}
{"text": "The menu - item is a string ( word or phrase or whatever ) to display as an item in some menu - window .The menu - window identifies in which pane a menu - item will appear .( This menu - window component is specificly for use with the NLMENU system and might not be needed in some other sort of grammar - drive , menu - based iterface driver . )", "label": "", "metadata": {}, "score": "60.14247"}
{"text": "Petrick ( 1973 ) adopts this mechanism , using somewhat different notation .The work of these researchers have been built upon in the design of the feature percolation mechanism described here .The mechanism is a constrained version of Knuth 's .", "label": "", "metadata": {}, "score": "60.14492"}
{"text": "Acknowledgement This work is supported by National High Technology Research and Development Program contract \" Generally Technical Research and Basic Database Establishment of Chinese Platform\"(Subj ... . by Er Fraser Daniel Marcu - In Technical Report ISI - TR-616 . html , ISI / University of Southern California , 2006 . \" ...", "label": "", "metadata": {}, "score": "60.15681"}
{"text": "Accept is indicated by the \" Accept \" entry in the table .When we come to this entry in the table , we accept the input string .Parsing is complete .Error : .The blank entries in the table indicate a syntax error .", "label": "", "metadata": {}, "score": "60.194588"}
{"text": "By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser , the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus .ML ID : 264 .", "label": "", "metadata": {}, "score": "60.314144"}
{"text": "This representation also provides optimized execution of the difference comparison , since using hexadecimals instead of decimals optimizes the logical digit - by - digit comparison to a computer - efficient byte - by - byte comparison .It should also be noted that the above examples of decimal , hexadecimal , or multi - digit hexadecimal are typical parameter choices for the node encoding included in the present invention .", "label": "", "metadata": {}, "score": "60.34886"}
{"text": "\" It is worth noting that once the first digit difference is detected , there is no further need to compute remaining digits .They diverge at level 3 , the third digit in the representation , and thereafter lie along completely different sub - trees that do not intersect .", "label": "", "metadata": {}, "score": "60.440323"}
{"text": "Bottom - Up Parsing .5.0 Introduction .5.1 Metalanguage for Bottom - Up Parser Generation .The metalanguage for a bottom - up parser is not as restrictive as that for a top - down parser .Left - recursion is not a problem because the tree is built from the leaves up .", "label": "", "metadata": {}, "score": "60.509468"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said adverb filter removes lexemes containing adverb concepts from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "60.580208"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 39 , wherein a most significant digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .", "label": "", "metadata": {}, "score": "60.682816"}
{"text": "MENU - BASED , GRAMMAR DRIVEN NATURAL LANGUAGE INTERFACES .The companion application ( simultaneously - filed U.S. patent application Ser .This guarantees grammatical coverage .A \" semantic grammar \" ( a context - free grammar that encodes the semantics of the domain ) ( Burton , 1976 ) is used to guarantee semantic coverge .", "label": "", "metadata": {}, "score": "60.68362"}
{"text": "Learning for Semantic Parsing [ Details ] [ PDF ] Raymond J. Mooney In A. Gelbukh , editors , Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , 311 - -324 , Mexico City , Mexico , February 2007 .", "label": "", "metadata": {}, "score": "60.68781"}
{"text": "the attributes list can be deduced from the non - numeric and numeric attribtes lists .the attributes mentioned associated with a relation should really be associated with that relation in the described database .The following routines do not verify that these integrity constraints hold though they could easily be modified to do so .", "label": "", "metadata": {}, "score": "60.746635"}
{"text": "The new Viewer adds three features for more powerful search : wildcards , morphological inflections , and capitalization .These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text .", "label": "", "metadata": {}, "score": "60.776787"}
{"text": "Extras includeExtras , boolean threadSafe , Predicate . filter , . boolean originalDependencies )A system for interactively generating a natural - language input interface , without any computer - skill programming work being required .A system for interactively generating a natural - language input interface , without any computer - skill programming work being required .", "label": "", "metadata": {}, "score": "60.87881"}
{"text": "Dunja Mladinic , Turning Yahoo into an Automatic Web Page Classifier , ECAI 98:13th European Conference on Artificial Intelligence , Brighton , UK , Aug. 23 to Aug. 28 , 1998 , pp .473 - 474 , John Wiley & Sons , Ltd. .", "label": "", "metadata": {}, "score": "60.99723"}
{"text": "The configuration of the parser 200 is shown in FIG .2 .First , the sentence receiver 220 obtains sentences 210 consisting of ontological entities produced by the sentence lexer 100 .These sentences are parsed by the parser 230 , which is designed to use a context - free grammar , although other grammatical models may be used without departing from the scope and spirit of the invention .", "label": "", "metadata": {}, "score": "61.006737"}
{"text": "II -- Nouns and their Determiner agree in Number and Gender .III -- Adjectives and Nouns agree in Gender .IV -- The language is SVO and in Noun Phrases , the order of constituents is Determiner - Adjective - Noun .", "label": "", "metadata": {}, "score": "61.008736"}
{"text": "This section must start with the pseudo declaration , or key words .Erlang code .No syntax rule definitions or other declarations may follow this section .To avoid conflicts with internal variables , do not use variable names beginning with two underscore characters ( ' _ _ ' ) in the Erlang code in this section , or in the code associated with the individual syntax rules .", "label": "", "metadata": {}, "score": "61.04535"}
{"text": "We present a new edition of the Google Books Ngram Corpus , which describes how often words and phrases were used over a period of five centuries , in eight languages ; it reflects 6 % of all books ever published .", "label": "", "metadata": {}, "score": "61.242092"}
{"text": "B is on top of stack beta , .C is on top of stack gamma , . and \" Conditions \" are satisfied .then replace A by D , B by E , and C by F. .Given this interpretation of the turing machine instruction , the MSBT parser is instantiated by the following turing machine instructions .", "label": "", "metadata": {}, "score": "61.392372"}
{"text": "The first association is always a direct translation from a specific word ( e.g. \" cat \" ) to its directly associated category ( \" noun \" ) .However , it should be preliminarily noted here that the categories used need not be as broad as familiar English - language parts of speech , but , at least for database - query applications , are preferably modified to include some semantic information .", "label": "", "metadata": {}, "score": "61.491245"}
{"text": "claim 6 , wherein said predicates and arguments are represented by encodings comprising at least one digit separated into multiple groups to provide multiple ontological levels and a branching factor at each node .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 2 , further comprising lexer filters for modifying said individual sentences based on word meanings .", "label": "", "metadata": {}, "score": "61.520218"}
{"text": "This paper reviews our prior work on this topic and discusses directions for future research .ML ID : 196 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .", "label": "", "metadata": {}, "score": "61.553925"}
{"text": "The noun must follow either immediately after the adjective , or have only adjective and conjunction words appearing between the noun and the adjective .If no such noun or conjunction is found , the adjective filter will veto the sentence .", "label": "", "metadata": {}, "score": "61.58442"}
{"text": "At its ... \" .Genre classification has been found to improve performance in many applications of statistical NLP , including language modeling for spoken language , domain adaptation of statistical parsers , and machine translation .It has also been found to benefit retrieval of spoken or written docu - ments .", "label": "", "metadata": {}, "score": "61.605377"}
{"text": "If a noun is found and it satisfies the restrictions of the adjective , the adjective filter will apply the selectional features of the adjective to the noun by adding all of the adjective 's selectional features to the noun 's set of selectional features .", "label": "", "metadata": {}, "score": "61.617455"}
{"text": "( ii ) Extensions to the core lexicon .A facility for editing menu - items has been added .Automatically generated help has been added as a fifth component to the lexicon .( This help will be present with each lexical item and will be available to the user of an interface who wants an explanation of particular phrases . )", "label": "", "metadata": {}, "score": "61.758503"}
{"text": "We shift the T onto the stack followed by state 2 .Continuing , .Step ( 19 ) .The parse is in state 1 looking at \" $ \" .The table indicates that this is the accept state .", "label": "", "metadata": {}, "score": "61.77172"}
{"text": "Symbols are classified as being either terminal symbols or nonterminal symbols .Terminal symbols are those symbols which appear in the lexicon ( or dictionary ) and thereby classify words according to categories .For example , terminal symbols commonly used in linguistic work are shown to the left of the colon in the example lexicon below .", "label": "", "metadata": {}, "score": "61.78637"}
{"text": "Some of the problems involving \" ease of use \" of natural language interfaces are : . users type poorly and often use ungrammatical constructions .--users had no way of knowing the grammatical coverage of the system ( what constructions were allowed in its grammar ) and they had no clear path to learn such limitations .", "label": "", "metadata": {}, "score": "61.88832"}
{"text": "The formal statement is : .Rule 3 : # # STR4 # # .Thus , the initial condition of the procedure can be represented as ( W 1 W 2 . . .W n # , S # ) .", "label": "", "metadata": {}, "score": "61.910736"}
{"text": "Inductive Logic Programming for Natural Language Processing [ Details ] [ PDF ] Raymond J. Mooney In Stephen Muggleton , editors , Inductive Logic Programming : Selected papers from the 6th International Workshop , 3 - 22 , Berlin , 1996 .", "label": "", "metadata": {}, "score": "61.921295"}
{"text": "Another object of the present invention is to provide a system and method for parsing natural language input that realizes enormous speed benefits from the parameterized ontology that the parser utilizes .BRIEF DESCRIPTION OF THE DRAWINGS .These and other attributes of the present invention will be described with respect to the following drawings in which : .", "label": "", "metadata": {}, "score": "62.05988"}
{"text": "We present a novel approach which employs a randomized sequence of pruning masks .Formally , we apply auxiliary variable MCMC sampling to generate this sequence of masks , thereby gaining theoretical guarantees about convergence .Because each mask is generally able to skip large portions of an underlying dynamic program , our approach is particularly compelling for high - degree algorithms .", "label": "", "metadata": {}, "score": "62.216637"}
{"text": "When ( 3 ) is applied , attach the B on alpha B as the right daughter of the top symbol on gamma .The parse tree will now appear on stack alpha , instead of just the root symbol .The statement of the parser given above is neutral with respect to the control structure that the procedure employs .", "label": "", "metadata": {}, "score": "62.30296"}
{"text": "At every cycle , a new character is read from the input stream and the character and current state are used to look up , in the action table , which action to perform .The actions are in one of the following forms : .", "label": "", "metadata": {}, "score": "62.33008"}
{"text": "The entire states 0 and 1 are : .State 0 State 1 .5.2.6 LR - Family : LALR(1 ) Table Generation .It is often the case that two states in an LR(1 ) state have the exact same items except for the lookahead .", "label": "", "metadata": {}, "score": "62.433285"}
{"text": "claim 23 , wherein said parse probability filter vetoes parse trees that fall below a minimum probability for semantic interpretation .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said system is modular to permit the use of any part - of - speech - tagged ontology .", "label": "", "metadata": {}, "score": "62.46393"}
{"text": "Finally , we will investigate the impact of different statistical syntactic parsers on semantic parsing using the automated SAPT - generation process .ML ID : 184 .A Kernel - based Approach to Learning Semantic Parsers [ Details ] [ PDF ] [ Slides ] Rohit J. Kate 2005 .", "label": "", "metadata": {}, "score": "62.505875"}
{"text": "Of course , parsing will suffer unless your tokenization accurately matches the tokenization of the underlying treebank , for instance Penn Treebank tokenization .A common occurrence is that your text is already correctly tokenized but does not escape characters the way the Penn Treebank does ( turning parentheses into -LRB- and -RRB- , and putting a backslash in front of forward slashes and asterisks - presumably a holdover from Lisp ) .", "label": "", "metadata": {}, "score": "62.604607"}
{"text": "However , most previous work on domain adaptation relied on the implicit assumption that domains are somehow given .As more and more data becomes available , automatic ways to select data that is beneficial for a new ( unknown ) target domain are becoming attractive .", "label": "", "metadata": {}, "score": "62.637375"}
{"text": "Semantic lexicons can also be learned from semantically annotated sentences and are an important source of knowledge for semantic parsing .Learning for semantic parsing is part of our research on natural language learning .\" The fish trap exists because of the fish .", "label": "", "metadata": {}, "score": "62.68486"}
{"text": "It is used for suppressing the warning about conflicts that is ordinarily given if the grammar is ambiguous .An example : .Expect 2 .The warning is given if the number of shift / reduce conflicts differs from 2 , or if there are reduce / reduce conflicts .", "label": "", "metadata": {}, "score": "62.688805"}
{"text": "claim 28 , wherein the step of parsing comprises the step of looking ahead one word , scanning input from left - to - right , and constructing said parse tree .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "62.82062"}
{"text": "Crucially , a limitation of this assumption is that substantially more effort must be applied in crafting the ontology , since re - indexing large volumes of text becomes extraordinarily expensive as the text grows .The designers of a parameterized ontology must be certain that their coverage is adequate before making a decision to freeze the structure .", "label": "", "metadata": {}, "score": "62.840508"}
{"text": "Further possible applications of the presented approaches include summarized machine translation tasks and learning from real perception data assisted by computer vision and robotics .ML ID : 291 .Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .", "label": "", "metadata": {}, "score": "62.89311"}
{"text": "Control rules are induced using a novel ILP algorithm which handles difficult issues arising in the induction of search - control heuristics .Both the control - rule framework and the induction algorithm are crucial to CHILL 's success .The main advantage of CHILL over propositional counterparts is its flexibility in handling varied representations .", "label": "", "metadata": {}, "score": "63.077316"}
{"text": "The value of the Parserfile option stripped of the .erl extension is used by Yecc as the module name of the generated parser file .Yecc will add the extension . yrl to the Grammarfile name , the extension .hrl to the Includefile name , and the extension .", "label": "", "metadata": {}, "score": "63.10003"}
{"text": "Add support for semantic domains , fixed value ranges ( as in ( January , 111 , December ) , domain ordering predicates , domain tests , default values , .Add user titles for column headings , so descriptive headings are used instead of short fixed length names that are required for some existing databases .", "label": "", "metadata": {}, "score": "63.106567"}
{"text": "The 1980 paper briefly describes a method of applying metal rules to context - free rules to generate other context - free rules .The method is not described with respect to a grammar for databases and there is no mention of semantic grammars .", "label": "", "metadata": {}, "score": "63.13494"}
{"text": "By default , DocumentPreprocessor uses PTBTokenizer for tokenization .If you need to change that , either because you have a better Tokenizer for your domain or because you have already tokenized your text , you can do that by passing in a TokenizerFactory such as a WhitespaceTokenizerFactory for no tokenization beyond splitting on whitespace .", "label": "", "metadata": {}, "score": "63.169266"}
{"text": "claim 38 , further comprising the step of representing said parse trees by modified hexadecimal numbers that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "63.260292"}
{"text": "Two rules are included in this example of a pseudo - concept filter implementation .The first rule is that any word relating to the user , or his current situation , such as \" I \" or \" me \" is always deleted .", "label": "", "metadata": {}, "score": "63.45692"}
{"text": "Consequently , ten is too small to constrain the branching factor for each level .The use of a hexadecimal representation would improve this some by increasing the branching factor to 16 .Thus , using a 16-digit ( i.e. , a 64-bit ) hexadecimal number gives 16 branches at each node for 16 levels : 16 16 possible concepts .", "label": "", "metadata": {}, "score": "63.49626"}
{"text": "NUMERIC ATTRIBUTES -- for each relation , the attributes to be included in the interface that come from numeric domains .COMPUTABLE ATTRIBUTES -- for each relation , the attributes to be included in the interface that come from numeric domains and that are avergeable , totalable , . . . .", "label": "", "metadata": {}, "score": "63.517757"}
{"text": "Experimental results show the improvements obtained over the purely supervised parser , particularly when the annotated training set is small .ML ID : 198 .This paper explores the use of statistical machine translation ( SMT ) methods for tactical natural language generation .", "label": "", "metadata": {}, "score": "63.595642"}
{"text": "Add support for transitive closures as in \" find all managers and their managers and so on \" .Add a define facility so one can say Define--(moun type in)--TO BE--(NP ) as in Define -- old employee -- TO BE -- employees whose age is greater than 65 .", "label": "", "metadata": {}, "score": "63.672783"}
{"text": "Pseudo - predicate verbs include \" give \" , \" show \" , and \" find \" .Not all instances of these verbs are pseudo - predicates ; however , the first instance of them in a query often is .", "label": "", "metadata": {}, "score": "63.67784"}
{"text": "By only observing how humans follow navigation instructions , the system was able to infer the corresponding hidden navigation plans and parse previously unseen instructions in new environments for both English and Chinese data .With the rise in popularity of crowdsourcing , we also present results on collecting additional training data using Amazon 's Mechanical Turk .", "label": "", "metadata": {}, "score": "63.68736"}
{"text": "By following the reduce actions in reverse , starting with R2 , the last reduce action , and continuing until R6 the first reduce action , a parse tree can be created .Exercise 1 asks the reader to draw this parse tree .", "label": "", "metadata": {}, "score": "63.722748"}
{"text": "The need for NLIs has become more pronounced given the widespread access to complex databases now available through the Internet .However , such systems are difficult to build and must be tailored to each application .A current research topic involves using machine learning methods to automate the development of NLI 's .", "label": "", "metadata": {}, "score": "63.72694"}
{"text": "These instructions are of the following form , where A , B , C , D , E , and F can be arbitrary strings of symbols from the terminal and nonterminal alphabet .This is to be interpreted as follows : .", "label": "", "metadata": {}, "score": "63.74413"}
{"text": "A system for generating a user customized natural language menu interface from a database supplied by the user and from inputs supplied interactively by a user , comprising : . display means for showing to a user expert a menu of options ; . input means coupled to said display means , for moving a cursor 's apparent position on said display means by the action of said user ; . means for the system to access said data base ; . means for displaying on said displaying means a generalized relation between two or more tables in said database , with generalized indications of corresponding natural - language connecting phrases ; . means for interactively receiving from said user a plurality of said relations between tables in said database , together with natural - language connecting phrases corresponding to said relations between tables and said database ; and .", "label": "", "metadata": {}, "score": "63.75264"}
{"text": "Appendix B sets forth a sample database , such as might be provided to the present invention for tranlation into a user - customized interface .This appendix also contains a sample of a portable spec in a generated grammar and lexicon , such as might be generated , by the present invention , from this database .", "label": "", "metadata": {}, "score": "63.802765"}
{"text": "A 10-digit decimal number allows 10 10 , or 10 billion possible concepts to be stored in the tree .That is a sufficient number of total concepts , but the branching factor is too small .There can be a maximum of ten possible branches out of each node to the next level .", "label": "", "metadata": {}, "score": "63.831055"}
{"text": "The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .", "label": "", "metadata": {}, "score": "63.850292"}
{"text": "In the recent literature the alignment task has frequently been decoupled from the translation task , and assumptions have been made about measuring alignment quality for machine translation which , it turns out , are not justified .In particular , none of the tens of papers published over the last five years has shown that significant decreases in Alignment Error Rate , AER ( Och and Ney , 2003 ) , result in significant increases in translation quality .", "label": "", "metadata": {}, "score": "63.88714"}
{"text": "Thus , we push F 3 onto the stack .Step ( 3 ) .Thus , the right - hand side of production 4 is the handle on the stack .The algorithm says to pop the stack up to and including the F. That exposes state 0 .", "label": "", "metadata": {}, "score": "64.03346"}
{"text": "Most of the other parsing and generation algorithms presented in this thesis are extensions of WASP or its inverse .We demonstrate the effectiveness of our parsing and generation algorithms by performing experiments in two real - world , restricted domains .", "label": "", "metadata": {}, "score": "64.04946"}
{"text": "The significance of this invention is that it makes it possible , for a MUCH broader class of users and applications , to use menu - based natural language interfaces to databases .Natural language interfaces to computer systems are not in common use today for two main reasons : they are difficult to use and expensive to build and maintain .", "label": "", "metadata": {}, "score": "64.0831"}
{"text": "A PORTABLE SPEC contains all the information necessary to specify a complete user interface .Specific HELP is available on many of these categories using ( ( the HELP key ) ) .The categories are as follows : .TABLES -- the set of relations or views that the interface covers .", "label": "", "metadata": {}, "score": "64.08766"}
{"text": "The associated code contains pseudo variables ' $ 1 ' , ' $ 2 ' , ' $ 3 ' , etc . which refer to ( are bound to ) the values associated previously by the parser with the symbols of the right hand side of the rule .", "label": "", "metadata": {}, "score": "64.09166"}
{"text": "If X is in the set of terminals ., Y ) ( 8) .where : is a special symbol which is neither a terminal or a nonterminal symbol .C1 is a Ci type variable as defined earlier .( Rules 4 through 10 are added to permit use of grammar rules which contain parentheses and curly brackets .", "label": "", "metadata": {}, "score": "64.09914"}
{"text": "The categories are as follows : . relations -- the set of relations ( including views ) covered .non - numeric - attibutes -- for each relation , the attributes to be included in the iterface that come from non - numeric domains .", "label": "", "metadata": {}, "score": "64.11911"}
{"text": "Even at that time , the question of portability was raised with the question \" How much can we automate the process of changing database environments ? \"( SIGMOD , 1978 ) .Work at SRI : SRI has been an important center for research into natural language interfaces to databases for several years .", "label": "", "metadata": {}, "score": "64.14375"}
{"text": "Lexer filters 150 are modular plug - ins , which modify sentences based on knowledge about word meanings .The preferred embodiment contains several filters 150 , although more may be developed , and existing filters may be removed from future versions , without altering the scope of the invention .", "label": "", "metadata": {}, "score": "64.16728"}
{"text": ".. a top - scoring MT system in the Chinese newswire track of the 2008 NIST evaluation .However , except for ( Fraser and Marcu , 2007b ) , none of these advances in alignment quality has improv ... . \" ...", "label": "", "metadata": {}, "score": "64.19394"}
{"text": "It can also appear at the right hand side of rules .Next comes a declaration of the terminal categories , which are the categories of tokens produced by the scanner .For example : .Terminals article adjective noun verb .", "label": "", "metadata": {}, "score": "64.21508"}
{"text": "means for integrating said relations interactively selected by said user into a portable specification for natural - language - menu interface , and forstoring said portable specification .BRIEF DESCRIPTION OF THE DRAWINGS .The present invention will be discussed with reference to the accompanying drawings , wherein : .", "label": "", "metadata": {}, "score": "64.2267"}
{"text": "These results support the claim that ILP techniques as implemented in CHILL represent a viable alternative with significant potential advantages over neural - network , propositional , and probablistic approaches to empirical parser construction .ML ID : 48 .This paper presents results from recent experiments with CHILL , a corpus - based parser acquisition system .", "label": "", "metadata": {}, "score": "64.26961"}
{"text": "For example , if a peripheral system accessory included electronic output from a scale , an expert item in a parts database could be indicated as \" ( specific weight read from scale # 7 ) \" .As noted , the presently preferred method of user presentation is a CRT screen , on which the various menus are displayed , together with a mouse which moves a curser on the screen .", "label": "", "metadata": {}, "score": "64.36618"}
{"text": "If there is no associated code after the right hand side of the rule , the value ' $ undefined ' is associated with the phrase .The right hand side of a grammar rule may be empty .This is indicated by using the special symbol ' $ empty ' as rhs .", "label": "", "metadata": {}, "score": "64.44041"}
{"text": "For example , a flat graphics display ( e.g. electroluminescent ) could be used instead of a CRT , and user control of the curser could be accomplished , e.g. , by a joystick or by voice recognition .INSERT A .", "label": "", "metadata": {}, "score": "64.53859"}
{"text": "The Rules section contains the BNF .The left - hand side is separated from the right - hand side by a color , \" : \" .The actions may appear interspersed in the right - hand side ; this means they will be executed when all the tokens or nonterminals to the action 's left are shifted .", "label": "", "metadata": {}, "score": "64.55576"}
{"text": "According to the present invention , there is provided : .A system for generating a user customized natural language menu interface from a database supplied by the user and from inputs supplied interactively by a user , comprising : . display means for showing to a user expert a menu of options ; . input means , for moving a cursor 's apparent position on said display means by the action of said user ; . means for receiving a database ; . means for displaying on said display means a generalized relation between two or more tables in said database , with generalized indications of corresponding natural - language connecting phrases ; and .", "label": "", "metadata": {}, "score": "64.558136"}
{"text": "ML ID : 222 .Learning to Sportscast : A Test of Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] [ Video ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .", "label": "", "metadata": {}, "score": "64.66877"}
{"text": "Hendrix 's approach offers a competing way to do the same sort of thing my approach does , but it differs in the ways noted above .In ( Grosz et al , 1982a ) and ( Grosz , 1982b ) , Grosz reports on a software component called TEAM .", "label": "", "metadata": {}, "score": "64.6837"}
{"text": "They are : .PCFG .Factored .Factored , segmenting .Xinhua ( mainland , newswire ) .xinhuaPCFG.ser.gz . xinhuaFactored.ser.gz .xinhuaFactoredSegmenting.ser.gz .Mixed Chinese .chinesePCFG.ser.gz . chineseFactored.ser.gz .The PCFG parsers are smaller and faster .But the Factored parser is significantly better for Chinese , and we would generally recommend its use .", "label": "", "metadata": {}, "score": "64.7185"}
{"text": "ML ID : 223 .Transforming Meaning Representation Grammars to Improve Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the Twelfth Conference on Computational Natural Language Learning ( CoNLL-2008 ) , 33 - -40 , Manchester , UK , August 2008 .", "label": "", "metadata": {}, "score": "64.826126"}
{"text": "These check the features of nodes and filter out ill - formed structures based on the values of these features .These rules are called feature blocking rules and will be written as conditions on the values of the features of the nodes to the right of the arrow .", "label": "", "metadata": {}, "score": "64.93646"}
{"text": "claim 30 , further comprising the step of assigning numbers to said concepts .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 34 , further comprising the step of subtracting said numbers to determine if features are in agreement , wherein a negative number indicates feature incompatibility .", "label": "", "metadata": {}, "score": "64.98131"}
{"text": "Meanwhile , Graphics Processor Units ( GPUs ) have become widely available , offering the opportunity to alleviate this bottleneck by exploiting the fine - grained data parallelism found in the CKY algorithm .In this paper , we explore the design space of parallelizing the dynamic programming computations carried out by the CKY algorithm .", "label": "", "metadata": {}, "score": "65.07941"}
{"text": "-Hunter McMillen Mar 22 ' 12 at 15:54 .This is not the easiest grammar to start with because you have an unlimited amount of lookahead on your first production rule : .Now , was that else supposed to bind to the if 5 then fragment ?", "label": "", "metadata": {}, "score": "65.10163"}
{"text": "ADVANTAGES AND SACRIFICES .Listed below are 5 advantages and one sacrifice .The first advantage is that an end user can easity build and maintain his own natural language interfaces covering his own application domain .A portable - spec is a straightforward data structure and it is no harder to build one than it is to create the set of relations in the first place ( and this is an easy process in modern relational databases ) .", "label": "", "metadata": {}, "score": "65.25166"}
{"text": "Consider a sample path through an ontology : .In this example , if the argument position of a predicate must be an example of transportation , then any of the three more - specific words will be an acceptable argument for the predicate .", "label": "", "metadata": {}, "score": "65.36102"}
{"text": "Tested across six domains , our system outperforms all non - oracle baselines including the best domain - independent parsing model .Thus , we are able to demonstrate the value of customizing parsing models to specific domains . ... train models in many different domains but sidestep the problem of domain detection .", "label": "", "metadata": {}, "score": "65.364845"}
{"text": "\") in the bill table .Sometimes a key consists of several attributes as in the votes table where both the conman and the bill # attributes are neede to uniquely idenfiy rows in the table .Important OPERATIONS on relational databases are : .", "label": "", "metadata": {}, "score": "65.37515"}
{"text": "In general , N will be the Nth node to the right of the arrow ( for N 0 ) .The first feature rule is interpreted as setting the value of FEATURE1 for the NP node to the result of applying the function F1 to the values of FEATURE2 of the NP node and FEATURE3 of the Nom node .", "label": "", "metadata": {}, "score": "65.49099"}
{"text": "If no instructions apply and the above conditions are not true , then that path has ended without producing a valid parse of the input string .To obtain all valid parses of the input string , all paths must be pursued until they either produce a valid parse or end without producing a parse .", "label": "", "metadata": {}, "score": "65.51564"}
{"text": "3-way - joins -- a specification of \" relationships \" where one .2-way - joins -- specification of supported joins .The portable spec categories are not unrelated .The following integrity constraints hold : . the relations list can be deduced from the non - numeric and numeric attributes lists .", "label": "", "metadata": {}, "score": "65.57193"}
{"text": "Tree least general generalizations ( TLGGs ) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences .The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears .", "label": "", "metadata": {}, "score": "65.61672"}
{"text": "Also , please note that this type of parsing typically wo n't produce what you want for arithmetic .Recursive descent parsers ( unless you use a little trick with tail recursion ? ) wo n't produce leftmost derivations .This is why people typically use fancier parser generator tools .", "label": "", "metadata": {}, "score": "65.68814"}
{"text": "For example , in the example shown in FIG .10 , a relation between pitchers and teams is specified , together with the natural - language phrases which will call up this relation .It should be noted that the terminology produced by the automatic interface generating method of the present invention may be somewhat awkward .", "label": "", "metadata": {}, "score": "65.728"}
{"text": "McClosky et al .( 2010 ) coined the term multiple source domain adaptation .Similar to us , McClosky et al .( 2010 ) regard a target domain as mixture of source domains , b .. by Joseph Le Roux , Jennifer Foster , Joachim Wagner , Rasul Samad , Zadeh Kaljahi , Anton Bryl . \" ...", "label": "", "metadata": {}, "score": "65.87668"}
{"text": "Certain rules are assigned precedence : each rule gets its precedence from the last terminal symbol mentioned in the right hand side of the rule .It is also possible to declare precedence for non - terminals , \" one level up \" .", "label": "", "metadata": {}, "score": "65.93755"}
{"text": "Also , things get more complex if you do require lookahead .I would recommend Language Implementation Patterns by Terence Parr ( the guy who wrote antlr , a recursive descent parser generator ) when looking at these kinds of problems .", "label": "", "metadata": {}, "score": "65.98468"}
{"text": "NORMALIZATION is a design process whereby a complex data structure ( often a hierarchy , or tree structure , or a network , or graph structure ) is decomposed into relations .Notes on current terminology : .Flat file : used more to describe the physical structure of a relation , not the logical structure .", "label": "", "metadata": {}, "score": "66.05788"}
{"text": "The path starts at the root node ( Level 1 ) and takes the 2nd branch to level 2 , then takes the 3rd branch from that node to get to level 3 .The final \" 0 \" is a terminator , indicating that this particular node of the tree is not at the lowest possible level of the tree ; it does not necessarily indicate that no nodes branch from this level .", "label": "", "metadata": {}, "score": "66.078"}
{"text": "It is such an ambitious task that it sometimes is referred to as an AI - complete problem , implying that its difficulty is equivalent to solving the central artificial intelligence problem -- making computers as intelligent as people .Despite its complexity , natural language understanding continues to be a fundamental problem in natural language processing in terms of its theoretical and empirical importance .", "label": "", "metadata": {}, "score": "66.18654"}
{"text": "claim 28 , further comprising the step of modifying said natural language sentence based on word meanings .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the steps of : . receiving sentences including ontological entities ; . parsing said sentences including ontological entities into parse trees representing concepts in the corresponding sentence including ontological entities ; and . converting said parse trees into predicates .", "label": "", "metadata": {}, "score": "66.2897"}
{"text": "The code ( setq phrse ( get - type - in \" type a supplier name \" ) ) pops up a type - in window and the user types a supplier name , say \" Jones \" . \" Jones \" is then used as the next phrase in the sentence and the translation ( quote \" Jones \" ) is treated as the ( translation ) .", "label": "", "metadata": {}, "score": "66.364395"}
{"text": "DELETE rows from the table which pass some test build a new table by .SELECTing some rows of interest .PROJECTing one just some columns of interest .JOINing two tables where they agree in some attribute columns .( see examples on the attached sheet ) .", "label": "", "metadata": {}, "score": "66.577614"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said stop word filter removes stop words from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "66.68036"}
{"text": "F \u00b7 ( E ) .F \u00b7 I d State 7 State 8 State 9 State 10 State 11 .F \u00b7 I d .These are called LR(0 ) items because no lookahead was considered when creating them .Step 4 .", "label": "", "metadata": {}, "score": "66.72261"}
{"text": "Thus , a YACC input file looks like the following : .Example 6 shows a YACC input file for the language consisting of sequences of assignment statements .EXAMPLE 6 Sequences of assignment statements in YACC .In Example 6 , the lexical analyzer is the one output by LEX , or users may write their own ( and call it \" lex.yy.c \" ) .", "label": "", "metadata": {}, "score": "66.818344"}
{"text": "What is significant about this interface is : . it provides an interactive means of eliciting the information needed to create a portable spec from a user .Menus are tailored to the particular user and only show him tables he owns , attributes associated with those tables , etc , so he can not err .", "label": "", "metadata": {}, "score": "66.859924"}
{"text": "This assumption is that the number of branches in an ontological hierarchy , and their depth , can be determined by designing it to fixed parameters at the time of creation , and by selecting maximum values for the branches and the depths .", "label": "", "metadata": {}, "score": "66.967674"}
{"text": "Usually , this will include the key attributes but it may also include non - key attributes .TWO TABLE JOINS -- a specification of supported joins involving two table THREE .TABLE JOINS -- a specification of \" relationships \" where one table relates two others .", "label": "", "metadata": {}, "score": "66.989136"}
{"text": "Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .One of the main goals of natural language processing ( NLP ) is to build automated systems that can understand and generate human languages .", "label": "", "metadata": {}, "score": "67.06469"}
{"text": "In ( Hendrix and Lewis , 1981 ) , the authors describe TED , a prototype system for creating new domains for natural language systems without the need for specially trained experts .Hendrix described a dialogue in which information ( like some of that found in the portable spec ) is elicited from a user .", "label": "", "metadata": {}, "score": "67.092125"}
{"text": "claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a negative number indicates feature incompatibility .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "67.245804"}
{"text": "The default HeadFinder is written specifically for the PTB .If you train a parser on trees that use a different set of productions , the default HeadFinder will not know how to handle this and will throw this exception .The easiest way to get around this problem is to use LeftHeadFinder instead .", "label": "", "metadata": {}, "score": "67.33143"}
{"text": "Since E \u00b7 E + T also has E after \u00b7 , we add E E \u00b7 + T. Step 2 does n't apply , and we are finished with State 1 .State 1 .E ' E \u00b7 .E E \u00b7 + T .", "label": "", "metadata": {}, "score": "67.395386"}
{"text": "DVParser with no flags .The memory requirements of the parser is not actually that high , but the more threads added with -trainingThreads , the more memory will be required to train .As the parser is training , it will output intermediate models every 20 minutes ( by default ) .", "label": "", "metadata": {}, "score": "67.41304"}
{"text": "LIST INTERFACES -- see the interfaces the user owns or has been granted .SHOW PORTABLE SPEC -- see a portable spec , the data structure from which a NL interface is generated ( see below ) .CREATE INTERFACE -- create a new interface ( a new portable spec ) .", "label": "", "metadata": {}, "score": "67.41411"}
{"text": "4 is an example parse tree according to the present invention ; .FIG .5 is another example parse tree according to the present invention ; .FIG .6 is another example parse tree according to the present invention ; and .", "label": "", "metadata": {}, "score": "67.46177"}
{"text": "There are two major ILP approaches : top - down and bottom - up .The former searches the hypothesis space from general to specific while the latter the other way round .Integrating both approaches has been demonstrated to be more effective .", "label": "", "metadata": {}, "score": "67.501434"}
{"text": "APPENDICES .The description of the invention incorporates the following appendices : .Appendix A is a listing of the actual code which is used , in the presently preferred embodiment of the present invention , on an LMI Lisp Michine .", "label": "", "metadata": {}, "score": "67.66054"}
{"text": "claim 6 , wherein said parse trees is represented by modified hexadecimal digits that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format comprising the steps of : . converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and . converting said sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the natural language sentence and binds arguments into predicates .", "label": "", "metadata": {}, "score": "67.74812"}
{"text": "We show that dependency parsers have more difficulty parsing questions than constituency parsers .In particular , deterministic shift - reduce dependency parsers , which are of highest interest for practical applications because of their linear running time , drop to 60 % labeled accuracy on a question test set .", "label": "", "metadata": {}, "score": "67.84114"}
{"text": "For example , consider a tree shown in FIG .7 .It is clear that in some cases , it is useful to know the distance between words , but that it is not equally useful in all cases .However , since neither of these terms shares any properties beyond \" organic \" with \" amino acid , \" it is not helpful to know the distance between \" bread \" and \" amino acid , \" even though they are only one level apart .", "label": "", "metadata": {}, "score": "67.963936"}
{"text": "z ) .type - in experts , which get the user to type names , filenames , dates , integers , . . . .menu - based popup experts that allow the user to specify dates , units experts ( 1000 feet ) , and range experts ( male or female ) .", "label": "", "metadata": {}, "score": "68.01239"}
{"text": "In this example , the input string is \" xyz \" , which is to be parsed as an \" S \" .2.2-Rule ( 3 ) z # # # STR55##Rule ( 2 ) # # STR56 # # S # Rule ( 1 ) applicable 3 ways -See continuations 3.1 , 3.2 and 3.3Cont . 3.2 Rule ( 1 ) z # # # STR65 # # # # STR66##Rule ( 1 ) # # # STR67 # # # # STR68##Rule ( 2 ) # # STR69 # # # # STR70##Rule ( 3 ) # # # STR71##BAD PATH - NO INSTRUCTIONS APPLYCont . 3.3 Rule ( 1 ) z # # # STR72 # # # # STR73##Rule ( 1 ) $ # # # STR74 # # # # STR75##Rule ( 2 ) # # STR76 # # # # STR77##BAD PATH - NO INSTRUCTIONS APPLYDONE _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "68.080925"}
{"text": "The modal verb filter removes modal verbs from sentence objects .Modal verbs are verbs such as \" should \" , \" could \" , and \" would \" .Such verbs alter the conditions under which a sentence is true , but do not affect the basic meaning of the sentence .", "label": "", "metadata": {}, "score": "68.10136"}
{"text": "The numbers 0 , 1 , and 2 indicate the nodes represented in the phrase structure rule . 0 is the node to the left of the arrow , the NP node .1 is the node immediately to the right of the arrow , the det node .", "label": "", "metadata": {}, "score": "68.199356"}
{"text": "The fourth advantage is that the interface will be bug free if the portable spec is well - formed syntactically and semantically .If specified relations really are tables in the database and numeric attributes really name attributes with numeric domains , etc , hen the spec refers to a real database and the grammar and lexicon resulting from the MAKE - PORTABLE - SPEC function will define a bug - free interface .", "label": "", "metadata": {}, "score": "68.23093"}
{"text": "Similar features will have similar paths through the tree .Referring to .FIG .5 , an example is illustrated .Node A is represented with the decimal number \" 1212 . \"Node B is represented with the decimal number \" 1220 .", "label": "", "metadata": {}, "score": "68.49786"}
{"text": "Sparse array techniques or other efficient data structures are necassary .5.5 YACC , A LALR(1 ) Bottom - up Parser Generator .This section describes YACC ,Yet Another Compiler - Compiler , written by Steve Johnson at Bell Telephone Laboratories in 1975 for the UNIX operating system .", "label": "", "metadata": {}, "score": "68.54132"}
{"text": "When we create the table , this item will be used to create the \" Accept \" entry .( In fact , looking at the table above , it can be seen that \" Accept \" is an entry for State 1 . )", "label": "", "metadata": {}, "score": "68.5896"}
{"text": "Domains correspond to DATA TYPES in programming languages .Some databases support only system - defined , syntactic domains like CHARACTER and INTEGER ; newer database systems support SEMANTIC DOMAINS ( like user defined data types in programming languages ) .Examples of semantic domains might be : . the set of all Congressmen 's names .", "label": "", "metadata": {}, "score": "68.61897"}
{"text": "It should be noted that even somewhat awkward locutions , when they appear in a menu for selection , will be clearer .Thus , for example , if a user has entered \" find pitchers \" and the menu of active items includes \" whose pitcher - ERA is \" , their relation is easily understood .", "label": "", "metadata": {}, "score": "68.83568"}
{"text": "Curly brackets indicate that exactly one of the elements within the brackets is to be inserted .Parentheses indicate that one or more ( or none ) of the elements in parentheses can be inserted .Ci - type variables are added merely to keep track of nested brackets and parentheses although this function is easily accomplished in the Lisp implementation ) .", "label": "", "metadata": {}, "score": "68.890816"}
{"text": "The pragmatic grammar differs from a semantic grammar in that it contains slots ( variable or procedures ) that the information in the data structure fills .His stated intent is to use Jane Robinson 's large grammar DIAGRAM ( Robinson , 1982 ) for his pragmatic grammar .", "label": "", "metadata": {}, "score": "68.95593"}
{"text": "The first LA stands for L ookahead token is added to the item .It is important to note that the same driver is used to parse .It is the table generation that is different .5.2.5 LR - Family : LR(1 ) Table Generation .", "label": "", "metadata": {}, "score": "68.9737"}
{"text": "In pseudo code , the entire function is described as follows : .PORTABLE SPEC 'S .How that information is elicited does not concern this section .The BUILD interfaces section of the patent describes extensions to the spec which are documented in the attached program code .", "label": "", "metadata": {}, "score": "69.07756"}
{"text": "It must , however , contain the necessary export declarations .The default is indicated by \" \" .Causes errors to be printed as they occur .Default is true .Causes warnings to be printed as they occur .Default is true .", "label": "", "metadata": {}, "score": "69.173"}
{"text": "numeric - attributes -- for each relation , the attributes to be included in the interface that come numeric domain and that are avergeable , totalable , . . . .identifying - attributes -- for each relation , the attributes that can be used by the user to identify the rows .", "label": "", "metadata": {}, "score": "69.21175"}
{"text": "Thus , for example , the node to Node A 's immediate left , is represented by \" 1211 .\" When the difference comparison is made , it works out to be \" 0001 , \" which implies a correspondingly close ontological relationship between the two concepts .", "label": "", "metadata": {}, "score": "69.40614"}
{"text": "Each production may have an action associated with it .5.5.1 YACC Metalanguage .The YACC metalanguage has a form similar to that for LEX : .The Definitions section can contain the typical things found at the top of a C program : constant definitions , structure declarations , include statements , and user variable definitions .", "label": "", "metadata": {}, "score": "69.58557"}
{"text": "ML ID : 107 .The development of natural language interfaces ( NLI 's ) for databases has been a challenging problem in natural language processing ( NLP ) since the 1970 's .The need for NLI 's has become more pronounced due to the widespread access to complex databases now available through the Internet .", "label": "", "metadata": {}, "score": "69.60273"}
{"text": "4 .Each arrowhead in .FIG .4 represents a concept node .The deeper into the tree ( i.e. , the higher the numbered level of the concept node ) , the more specific the concept is .Consider one path through FIG .", "label": "", "metadata": {}, "score": "69.62987"}
{"text": "Instead all of the constraints are in the experts . ) it provides a way to modify an interface ( to correct errors or add new tables ) .it provides a way for a user who owns an interface to edit the menu items by pointing to them in \" edit item mode \" and type in replacements .", "label": "", "metadata": {}, "score": "69.732834"}
{"text": "Reduce actions cause the parser to finish the current production and replace the assembled symbols with the symbol that replaces them ; .Accepts cause the parser to finish assembling a complete parse tree and halt ; .Errors cause the parser to give up because no grammar rule is available to reconcile what has already been parsed with what remains in the input stream .", "label": "", "metadata": {}, "score": "69.8282"}
{"text": "The rows of a relation of degree Ns are called N - TUPLES .So ( 111 - 22 - 3333 , # 331 , no ) is a 3-tuple from the votes relation .A relation of degree 2 is often termed a binary relation , degree 3 ternary , . . . . .", "label": "", "metadata": {}, "score": "69.97348"}
{"text": "The penalty for a recognition failure is often small : if two con- figurations are confused , they are often similar to each other , and the illusion works well enough , for instance , to drive a graphics animation of the moving hand .", "label": "", "metadata": {}, "score": "70.20108"}
{"text": "The Rendezvous prototype natural language interface to a database uses much the same kind of information as the SRI and TI systems .The information about database structure is stored in data structures that describe both database structural information and linguistic information .", "label": "", "metadata": {}, "score": "70.70843"}
{"text": "That is , they will just say Jill busy .Connection to logical representations : If you were to translate these sentences into a simple predicate logic form , you would presumably use busy(jill ) and teacher(jill ) .The treatment of the adjective or noun as the predicate in a predicate logic form parallels what we do in our grammatical relations representation .", "label": "", "metadata": {}, "score": "70.9636"}
{"text": "This is a simple problem to fix by applying a rule known as Left - Factoring , very similar to how you would factor an algebra problem .All you have to do is create a new non - terminal symbol S ' ( S - prime ) whose right hand side will hold the pieces of the productions that are n't common , so your S productions no becomes : .", "label": "", "metadata": {}, "score": "71.00761"}
{"text": "What I see next will make decisions as to what nonterminal I 'm in .Your grammar -- by the way -- exhibits a very common ambiguity called the \" dangling else , \" which has been around since the Algol days .", "label": "", "metadata": {}, "score": "71.13768"}
{"text": "it guarantees that the user can only construct interfaces with tables he owns or has been granted access to .it provides a means for sharing interfaces between users using GRANT or REVOKE .Both the MODE OF OPERATION of this interface ( highly interactive , window and menu oriented , nlmenu compatible so that it uses the same nlmenu driver as do the nlmenu natural langauge interfaces ) AND the FUNCTIONALITY of this interface are NOVEL .", "label": "", "metadata": {}, "score": "71.2342"}
{"text": "Despite such an improvement over a decimal representation , the branching factor of only 16 is still unacceptably small .A solution to this is to use a modified hexadecimal representation .Since it is unlikely that a reasonable , specialized ontology will need more than eight levels of general concept representation , a 16-digit hexadecimal number can be interpreted slightly differently , as an octet of hexadecimal pairs : .", "label": "", "metadata": {}, "score": "71.26599"}
{"text": "If the associated code is empty , the separating colon ' : ' is also omitted .A final dot marks the end of the rule ., etc . , have to be enclosed in single quotes when used as terminal or non - terminal symbols in grammar rules .", "label": "", "metadata": {}, "score": "71.64265"}
{"text": "By allowing both approaches to induce program clauses and choosing the best combination of their results , Cocktail learns more effective parsers .Experimental results on learning natural - language interfaces for two databases demonstrate that it learns more accurate parsers than Chillin , the previous best method for this task .", "label": "", "metadata": {}, "score": "71.781555"}
{"text": "For example , an attribute such as a batter 's hitting average can be computed from his at - bats and hits , and therefore need not be stored separately .It should also be noted that the expert for attribute classification will pop up a list of all possible attributes for each classification , and the user will typically desire not to include some of these attributes in the interface .", "label": "", "metadata": {}, "score": "71.823074"}
{"text": "Behavior Control : Finally we show how all these elements can be incorporated into a goal keeping robot .We develop simple behaviors that can be used in a layered architecture and enable the robot to block most balls that are being shot at the goal .", "label": "", "metadata": {}, "score": "71.874985"}
{"text": "PTBEscapingProcessor .If calling the parser within your own program , the main parse methods take a List of words which should already be correctly tokenized and escaped before calling the parser .You do n't need to and can not give the -tokenized option .", "label": "", "metadata": {}, "score": "71.98311"}
{"text": "At this point the \" using \" command is used to introduce the \" ( cover table ) \" expert .This first critically important operation lets the user specify which of the tables in the available database are to be used .", "label": "", "metadata": {}, "score": "72.153015"}
{"text": "Ball Tracking :The reliable tracking of the ball is vital in robot soccer .Therefore a Kalman - filter based system for estimating the ball position and velocity in the presence of occlusions is developped . -Sensor Fusion : The robot perceives its environment through several independent sensors ( camera , odometer , etc . ) , which have different delays .", "label": "", "metadata": {}, "score": "72.20297"}
{"text": "A KEY is some subset of the attributes of the relation and is treated as uniquely identifying the rows ( as Bill # in the bill relation ) .A user can uniquely refer to a row of any table by specifying the table name and the values of the key attributes .", "label": "", "metadata": {}, "score": "72.53938"}
{"text": "MODULE .MODULE SUMMARY .LALR-1 Parser Generator .DESCRIPTION .An LALR-1 parser generator for Erlang , similar to yacc .Takes a BNF grammar definition as input , and produces Erlang code for a parser .To understand this text , you also have to look at the yacc documentation in the UNIX(TM ) manual .", "label": "", "metadata": {}, "score": "72.65318"}
{"text": "Similar to the lexer filters 150 , the parser filters 250 may be chained together to form a list of filters to be applied to each candidate parse tree .Each parser filter 250 will keep track of the filter that should be applied immediately before it , and will submit candidate parse trees to that filter before performing a filtering function .", "label": "", "metadata": {}, "score": "72.66965"}
{"text": "A common difficulty with well - used databases is that they accumulate a huge number of unrelated data tables , and a process which in effect permits selection of a subset of related tables from the whole database provides substantial processing economies .", "label": "", "metadata": {}, "score": "73.08516"}
{"text": "This would add 8 bytes of total storage to each node in the tree .For a 10,000-concept tree , this is only 80 KB .For a 100,000-concept tree , it is 800 KB .And for a 1,000,000-concept tree , it is 8 MB .", "label": "", "metadata": {}, "score": "73.18669"}
{"text": "Reduce : .Reduce is indicated by \" R # \" where # is the number of a production .The top of the stack contains the right - hand side of a production , the handle .Reduce by the indicated production , consult the GOTO part of the table to see the next state , and push the left - hand side of the production onto the stack followed by the new state .", "label": "", "metadata": {}, "score": "73.2366"}
{"text": "The standard LALR parser generator algorithm fails when the grammar does not provide the parser generator enough information to decide whether the correction to perform given a certain current state and input symbol is to shift or to reduce .The generator algorithm also fails when the grammar does not provide the parser generator enough information to decide which of two or more rules should be reduced .", "label": "", "metadata": {}, "score": "73.41664"}
{"text": "That is , sentences like Jill is busy or Jill is a teacher .We continue to regard the adjective or noun as the predicate of which the subject is the argument , rather than changing and now regarding the copular verb is as the head and busy / teacher as a complement .", "label": "", "metadata": {}, "score": "74.04599"}
{"text": "ILP , which investigates the learning of relational ( first - order ) rules , provides an empirical method for acquiring knowledge within traditional , symbolic parsing frameworks .This dissertation details the architecture , implementation and evaluation of CHILL a computer system for acquiring natural language parsers by training over corpora of parsed text .", "label": "", "metadata": {}, "score": "74.28299"}
{"text": "Adjective : lazy , red .Noun : cat , book .Verb : ate , saw .Adverb : slowly , greedily .Nonterminal symbols are those symbols which are not terminal symbols .The Bn 's are either terminal or nonterminal symbols .", "label": "", "metadata": {}, "score": "74.31979"}
{"text": "In the area of program optimization , a prototype system , DOLPHIN , is able to transform some intractable specifications into polynomial - time algorithms , and outperforms competing approaches in several benchmark speedup domains .A prototype language acquisition system , CHILL , is also described .", "label": "", "metadata": {}, "score": "74.73337"}
{"text": "A predicate structure built from \" eat \" might thus require that the object of the predicate have a code beginning with \" 112 .\" As can be seen from the tree shown , it is clear that all the foods listed inherit the \" 112 \" prefix .", "label": "", "metadata": {}, "score": "75.26828"}
{"text": "INSERTIONS TABLES -- these four specifications list the access .DELETION TABLES -- rights that are reflected in the interface .MODIFICATION TABLES-- .NON - NUMERIC ATTRIBUTES -- for each relation , the attributes to be included in the interface that come from non - numeric domains .", "label": "", "metadata": {}, "score": "75.3702"}
{"text": "For example : .Header \" % % Copyright ( C ) \" \" % % @private \" \" % % @Author John \" .Next comes a declaration of the nonterminal categories to be used in the rules .For example : .", "label": "", "metadata": {}, "score": "75.46445"}
{"text": "RELATIONAL DATABASE :A collection of 0 or more relations .Formally , a relational database is a time varying collection of normalized relations of assorted degrees .RELATION : A two dimensional named table ( or FLAT FILE in older terminology ) .", "label": "", "metadata": {}, "score": "75.58444"}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( loop for ( rel .", "label": "", "metadata": {}, "score": "76.66237"}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( supplier - n \" ( specific supplier ) \" NOUNS(EXPERT ( list ( setq phrase ( get - type - in \" type a suppliername\"))(list ' quote phrase)))\"Suppliers have name , address , and status attributes .", "label": "", "metadata": {}, "score": "76.86221"}
{"text": "The / DT quick / JJ brown / JJ fox / NN jumped / VBD over / IN the / DT lazy / JJ dog / NN .with the command : . ser.gz fox.txt .Partially - tagged input ( only indicating the POS of some words ) is also OK .", "label": "", "metadata": {}, "score": "76.93917"}
{"text": "To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance .ML ID : 121 .", "label": "", "metadata": {}, "score": "77.3403"}
{"text": "Efforts taking from 10 to 30 man - years per application are not uncommon .Thus , only applications that can justify such large expenditure of manpower are candidate for possible applications .However , given the quality of the system that results , the effort has not proven to be worthwhile .", "label": "", "metadata": {}, "score": "77.96739"}
{"text": "claim 22 , wherein said parser filters include a selectional restriction filter and a parse probability filter .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 23 , wherein said selectional restriction filter vetoes parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .", "label": "", "metadata": {}, "score": "78.02906"}
{"text": "Following that , it would be passed to the lexer 120 , which would access the ontology 140 , and return the sequence : .The - det octopus - noun have - verb a - det heart - noun .Here , det stands for determiner , which is a word with a purely grammatical function , namely specifying a noun phrase .", "label": "", "metadata": {}, "score": "78.91414"}
{"text": "The ordering of the rows and columns in a relation is not usually considered to be significant .The number of rows in a relation is the CARDINALITY of the relation .The number of columns is the DEGREE of the relation .", "label": "", "metadata": {}, "score": "79.00726"}
{"text": "COMBINE INTERFACES existing - interfaces - with - specs - expert GIVING new - interface - expert .SHOW SPECS exisging - interfaces - with - specs - expert .GRANT INTERFACES existing - owned - interfaces - expert TO users - expert .", "label": "", "metadata": {}, "score": "79.4756"}
{"text": "Computers fail to track these in fast video , but sleight of hand fools humans as well : what happens too quickly we just can not see .We show a 3D tracker for these types of motions that relies on the recognition of familiar configurations in 2D images ( classification ) , and fills the gaps in - between ( interpolation ) .", "label": "", "metadata": {}, "score": "79.84378"}
{"text": "The meaning of the entire tree is the meaning of the VP , via the function \" lambda y ( hit y Mary \" ) , applied to the meaning of the NP , John .This function applied to this argument produces \" ( hit John Mary ) \" .", "label": "", "metadata": {}, "score": "80.015045"}
{"text": "Add extensible support for units like fee , pounds , . . .including support for unit conversion .Add extensible support for Attribute Groups like names ( composed of first and last names , dates , addresses , . . . .", "label": "", "metadata": {}, "score": "80.226456"}
{"text": "For example , the identifying attributes of a pitcher would include his team , ERA , etc .A key identifying attribute of a pitcher would be his name .A next critical step is arbitrating the access of various users to the interface being constructed .", "label": "", "metadata": {}, "score": "80.70392"}
{"text": "YACC and Bison are your friends I agree .When I was learning this stuff we encountered that same problem with parsing arithmetic as you mention above , our professor created a really elegant solution using the Visitor pattern .-Hunter McMillen Mar 22 ' 12 at 1:07 .", "label": "", "metadata": {}, "score": "81.46188"}
{"text": "In this paper , we address two issues that are related to domain adaptation .The first question is how much genre variation will affect NLP systems ' per ... \" .Domain adaptation is an important task in order for NLP systems to work well in real applications .", "label": "", "metadata": {}, "score": "81.842545"}
{"text": "We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .ML ID : 187 .", "label": "", "metadata": {}, "score": "82.75651"}
{"text": "For example , in a parts database , if every part has a weight less than five pounds , an expert for part weight can be used which constrains the numerical part weight input to be less than five pounds .Thus , the expert if effect permits sub - queries to the database to be transacted in the midst of formulating a larger query , and thus same much time .", "label": "", "metadata": {}, "score": "83.58533"}
{"text": "Description .Applicants hereby incorporate by reference co - pending application Ser .No .09/627,295 filed in the U.S. Patent and Trademark Office on Jul. 27 , 2000 , entitled \" Concept - Based Search and Retrieval System . \" BACKGROUND OF THE INVENTION .", "label": "", "metadata": {}, "score": "83.927986"}
{"text": "RENAME INTERFACE -- rename an existing interface the user owns .COMBINE INTERFACE -- combine interfaces .DROP INTERFACE(S)--drop interfaces the user owns or has been granted .GRANT INTERFACE(S)--grant interfaces to other users .REVOKE INTERFACE -- revoke a granted interface .", "label": "", "metadata": {}, "score": "84.92858"}
{"text": "A selectional restriction filter vetoes any parse tree where there are conflicts between the selectional features of the concepts serving as arguments to another concept and the restrictions of that concept .Selectional restrictions are imposed on the argument positions of predicate structures .", "label": "", "metadata": {}, "score": "86.363815"}
{"text": "TUTORIAL .LIST INTERFACES .CREATE INTERFACE new - interface - expert USING spec - initial .MODIFY INTERFACE existing - owned - interface - with - specs - expert BY CHANGING speclist GIVING new - interface - expert .DROP INTERFACES existing - dropable - interfaces - expert .", "label": "", "metadata": {}, "score": "86.84158"}
{"text": "COMMIT . where .spec - initial -- COVERED - TABLES ( speclist ) . speclist -- spec ( speclist ) .spec -- COVERED - TABLES . spec -- ACCESS - RIGHTS . spec -- CLASSIFY - ATTRIBUTES .spec -- IDENTIFYING - ATTRIBUTES .", "label": "", "metadata": {}, "score": "87.15152"}
{"text": "Continuing , the following states are created .State 2 State 3 State 4 State 5 State 6 .E T \u00b7 T F \u00b7 F ( \u00b7 E )F I d \u00b7 E E + \u00b7 T .E \u00b7 T T \u00b7 F .", "label": "", "metadata": {}, "score": "87.69034"}
{"text": "The rabbit snare exists because of the rabbit .Once you 've gotten the rabbit , you can forget the snare .Words exist because of meaning .Once you 've gotten the meaning , you can forget the words .", "label": "", "metadata": {}, "score": "88.33084"}
{"text": "This Master 's thesis describes parts of the control software used by the soccer robots of the Free University of Berlin , the so called FU - Fighters .The FU - Fighters compete in the Middle Sized League of RoboCup and reached the semi - finals during the 2004 RoboCup World Cup in Lisbon , Portugal .", "label": "", "metadata": {}, "score": "89.513176"}
{"text": "PART ( part # name city color weight ) .SHIPMENT ( supplier # part # quantity ) .which are suppliedby \" ) part # ) ( supplier supplier # ) ( part part#)))(((shipment supplier#)(\"which were shipped by \" .\" whicha were shipments of\")(supplier supplier#)))((other specificaitons to be added later ) ) ) ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "90.59752"}
{"text": "Parsing file : - i ca n't believe @mistamau does n't know who channing tatum is ... # loser Parsing [ sent .1 len .Parsed 14 words in 1 sentences ( 4.29 wds / sec ; 0.31 sents / sec ) .", "label": "", "metadata": {}, "score": "94.65813"}
{"text": "Suppose that a user of a search engine which makes use of this parser asks the question : .Do octopuses have hearts ?The sentence lexer 100 will read the question , and a sentence made of ontological entities is produced .", "label": "", "metadata": {}, "score": "95.19176"}
{"text": "A column of a relation is a subset of a domain , so the congressman.ssn column and the votes.conman column both come from the same domain , the domain of social security numbers .Only data elements from that domain should ever go in those columns .", "label": "", "metadata": {}, "score": "95.68057"}
{"text": "In the parser 220 , the tree shown in .FIG .6 is produced .The parse tree converter 230 then converts this tree into a predicate , where octopus is the subject of have , and heart is the object .", "label": "", "metadata": {}, "score": "95.86818"}
{"text": "Thus , when the sentence passes through the lexer filters 150 as discussed in the previous example embodiment , the stop word filter removes \" a \" and \" the , \" leaving : . octopus - noun have - verb heart - noun .", "label": "", "metadata": {}, "score": "96.405685"}
{"text": "Do - verb octopus - noun have - verb heart - noun .In the preferred embodiment 's lexer filters , the pseudo predicate filter removes the first verb \" do , \" because it is not the main verb of the sentence . \"", "label": "", "metadata": {}, "score": "97.07578"}
{"text": "The example sentence is : .The octopus has a heart .First , the sentence lexer 100 would process this sentence .The first component of the sentence lexer 100 , the document iterator 110 , would extract this sentence from the document it was contained in .", "label": "", "metadata": {}, "score": "104.872696"}
