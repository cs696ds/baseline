{"text": "Tokuume et al . , U.S. Pat .No .5,101,349 , discloses a natural language processing system that makes provisions for validating grammar from the standpoint of syntactic well - formedness , but does not provide facilities for validating the semantic well - formedness of feature structures .", "label": "", "metadata": {}, "score": "31.898224"}
{"text": "This technique narrows the task - independent corpus , but can identify yet more examples of task specific sentences , phrases , etc . .FIG .7 illustrates a method 200 for creating a language model for a selected application from a task - independent corpus in the manner discussed above .", "label": "", "metadata": {}, "score": "32.993256"}
{"text": "Examples of quite sophisticated patterns have been illustrated .The approach is validated by an evaluation based on the GENIA corpus .The parser described in this paper , the relation mining system , and the evaluation dataset , can be obtained by contacting the authors .", "label": "", "metadata": {}, "score": "35.09498"}
{"text": "As an alternative to the shortest path approach , [ 14 ] suggested the all - dependency - paths kernel to identify protein / gene interactions .In order to extract correct interactions , they represented a parse tree of a sentence with a dependency graph and considered dependencies outside the shortest path connecting two entities as well as dependencies on the shortest path .", "label": "", "metadata": {}, "score": "35.643456"}
{"text": "Furthermore , we distinguish the significances of parameters such as syntactic locality , semantic roles , and lexical features by varying their weights .Conclusions .We addressed the genic interaction problem with various dependency kernels and suggested various structural kernel scenarios based on the directed shortest dependency path connecting two entities .", "label": "", "metadata": {}, "score": "35.644928"}
{"text": "Wang T , Li Y , Bontcheva K , Cunningham H , Wang J : Automatic Extraction of Hierarchical Relations from Text .The Semantic Web : Research and Applications .3rd European Semantic Web Conference , ESWC 2006 no .4011 in Lecture Notes in Computer Science , Springer 2006 , 215 - 229 .", "label": "", "metadata": {}, "score": "35.74064"}
{"text": "Riedel S , Klein E : Genic Interaction Extraction with Semantic and Syntactic Chains .Proceedings of LLL , Born , Germany 2005 , 69 - 74 .Lodhi H , Saunders C , Shawe - Taylor J , Cristianini N , Watkins C : Text Classification using String Kernels .", "label": "", "metadata": {}, "score": "36.05442"}
{"text": "We study the problem of combining the outcomes of several different classifiers in a way that provides a coherent inference that satisfies some constraints .In particular , we develop two general approaches for an important subproblem - identifying phrase structure .", "label": "", "metadata": {}, "score": "36.290154"}
{"text": "Zhou G , Su J , Zhang J , Zhang M : Exploring Various Knowledge in Relation Extraction .Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics , Ann Arbor , MI , USA 2005 , 427 - 434 .", "label": "", "metadata": {}, "score": "36.30656"}
{"text": "Among them , the pairs , whose interactions were not stated as genic interactions , were used as negative examples because LLL provides only interactive pairs .Both the perfectly parsed and third party auto - parsed data sets are analyzed into typed dependency forms .", "label": "", "metadata": {}, "score": "37.260147"}
{"text": "For application developers , a CFG is also often highly labor - intensive to create .A second form of a language model is an N - gram model .Because the N - gram can be trained with a large amount of data , the n - word dependency can often accommodate both syntactic and semantic shallow structure seamlessly .", "label": "", "metadata": {}, "score": "37.43162"}
{"text": "No .5,386,406 to Hedin et al . discloses a system for converting natural - language expressions into a language - independent conceptual schema .The output of the Hedin et al . system is not suitable for use in a wide variety of applications ( e.g. machine translation , document summarization , categorization ) .", "label": "", "metadata": {}, "score": "37.524757"}
{"text": "We study the problem of combining the outcomes of several different classifiers in a way that provides a coherent inference that satisfies some constraints .In particular , we develop two general approaches for an important subproblem- identifying phrase structure .The first is a Markovian approach t ... \" .", "label": "", "metadata": {}, "score": "37.699894"}
{"text": "At step 164 , the task - independent corpus is parsed with the plurality of context - free grammars obtained in step 162 in order to identify word occurrences in the task - independent corpus of each of the semantic or syntactic concepts .", "label": "", "metadata": {}, "score": "37.853313"}
{"text": "The patterns encode the possible relationships between entities , allowing both entities and the relationships between them to be directly matched in the text .Other systems have incorporated large - scale domain - specific knowledge bases .MEDSYN D IKATE [ 13 ] employed a rich discourse model of entities and their relationships , built using a dependency parse of texts and a description logic knowledge base re - engineered from existing terminologies .", "label": "", "metadata": {}, "score": "38.35086"}
{"text": "Given this grammar , an LALR parser generator would fail to produce a parser because of a shift / reduce conflict .The modified LALR parser generator algorithm that the ontological parser of the present invention uses must be aware of the possibility of more than one possible course of action , and should recursively try both actions .", "label": "", "metadata": {}, "score": "38.38435"}
{"text": "The method is oriented for learning to parse any selected subset of target syntactic structures .It is local , yet can handle also compositional structures .In this paper , a memory - based parsing method is extended for handling compositional structures .", "label": "", "metadata": {}, "score": "38.51555"}
{"text": "They did not exploit any structural information .On the other hand , the work of [ 11 ] using both syntactic and word context information showed a bit low recall as compared to its precision .[14 ] applied syntactic information to a graph kernel by considering dependencies outside of the path as well as dependencies on the shortest path between two entities .", "label": "", "metadata": {}, "score": "38.619553"}
{"text": "By extrapolation we get the approximative recall results in table 3 .Related work .The task of relation extraction can be performed at different levels of complexity .The systems that deal with this task can be broadly classified in three categories , according to the amount of linguistic information brought to bear on the problem .", "label": "", "metadata": {}, "score": "38.65925"}
{"text": "In other cases , syntactic ambiguity will result in multiple possible parses .The parser should not generate any output trees for a sentence that does not reduce according to the rules ; rather it should generate a tree for every possible parse of an ambiguous sentence .", "label": "", "metadata": {}, "score": "38.666077"}
{"text": "This paper focusses instead on relationship extraction in the CLEF IE system .Our approach uses Support Vector Machine ( SVM ) classifiers to learn these relationships .The classifiers are trained and evaluated using novel data : a gold standard corpus of oncology narratives , hand - annotated with semantic entities and relationships .", "label": "", "metadata": {}, "score": "38.808987"}
{"text": "At the time of MUC-7 the approach adopted by most researchers was to analyse training examples by hand and author patterns to match contexts which expressed the relevant relation .Since the MUC evaluations there has been increasing work on relation extraction , far more than can be reviewed here .", "label": "", "metadata": {}, "score": "39.29573"}
{"text": "No .4,887,212 to Zamora et al . discloses a parser for syntactic analysis of text using a fast and compact technique .After part - of - speech tagging and disambiguation , syntactic analysis occurs in four steps .The grammar of Zamora et al . operates by making multiple passes to guess at noun phrases and verb phrases and then attempts to reconcile the results .", "label": "", "metadata": {}, "score": "39.532097"}
{"text": "Typically such systems make use of external resources , such as domain Ontologies , in order to detect the most likely combination of the constituents of the sentences , based on their semantic types .Some examples are [ 23 - 26 ] .", "label": "", "metadata": {}, "score": "39.759716"}
{"text": "Additionally , semantic feature compatibility checking is not possible with Jensen 's system .U.S. Pat .No .5,721,938 to Stuckey discloses a parsing technique , which organizes natural language into symbolic complexes , which treat all words as either nouns or verbs .", "label": "", "metadata": {}, "score": "39.87548"}
{"text": "Typical approaches to relationship extraction in this domain have used full parses , domain - specific grammars , and large knowledge bases encoding domain knowledge .In other areas of biomedical NLP , statistical machine learning ( ML ) approaches are now routinely applied to relationship extraction .", "label": "", "metadata": {}, "score": "39.94536"}
{"text": "One way to reduce these can be efficient sentence splitting .Our system still failed to identify some interactive pairs that occur with negation expressions .Further studies should be performed in this negation processing .Finally , some cases need information other than a sentence , as shown in Figure 6c .", "label": "", "metadata": {}, "score": "40.048462"}
{"text": "These terms , together with a number of token - level features , are then used to train SVM classifiers : one for each entity type .This approach has been evaluated using ten fold cross validation over the C77 corpus ( described above ) , achieving an overall F 1 for entity recognition of 71 % , macro - averaged across folds ( full results are given in [ 2 ] ) .", "label": "", "metadata": {}, "score": "40.053078"}
{"text": "Two instantiations of this approach are studied and experimental results for Noun - Phrase ... \" .A SNoW based learning approach to shallow parsing tasks is presented and studied experimentally .The approach learns to identify syntactic patterns by combining simple predictors to produce a coherent inference .", "label": "", "metadata": {}, "score": "40.053844"}
{"text": "The first group of experiments reported looks at the performance of relation extraction with non - parse feature sets .We followed an additive strategy for feature selection : starting with basic features , we added further features one set at a time .", "label": "", "metadata": {}, "score": "40.064407"}
{"text": "All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .The present system imposes a logical structure on text , and a semantic representation is the form used for storage .", "label": "", "metadata": {}, "score": "40.261566"}
{"text": "At this point , it should be noted that the method illustrated in .FIG .7 is not limited to a unified language model , or even an N - gram language model , but rather , can be helpful in forming language models of any type used in a language processing system where the model is based on a task - independent corpus .", "label": "", "metadata": {}, "score": "40.32402"}
{"text": "Thus , some works suggested more generalized pattern learning methods to align relevant sentences [ 7 - 9 ] .As an alternative , various kernel methods have been employed to this relation extraction problem .Such methods have , in particular , provided appealing solutions for learning rich structural data such as syntactic parse trees and dependency structures , which can not be easily expressed via the flat features .", "label": "", "metadata": {}, "score": "40.344383"}
{"text": "This corpus - based approach has since been augmented in two dimensions .[ 4 ] At the same time , researchers are also subjecting their corpora to more complex automatic processes to extract more knowledge from them .While word frequency and collocation analysis is fundamentally a task of simple counting , projects such as Kilgarriff 's Sketch Engine [ Kilgarriff et al .", "label": "", "metadata": {}, "score": "40.46667"}
{"text": "This is identical to the sentence produced above , and results in the same parse tree , and the same predicate structure .Thus , when the ontological parser in this example embodiment receives this question , it generates a predicate identical to that from a declarative sentence , and they can be matched .", "label": "", "metadata": {}, "score": "40.623363"}
{"text": "Proceedings of LBM , Singapore 2007 , 6.1 - 6.14 .Zhou G , Zhang M , Ji DH , Zhu Q : Tree Kernel - based Relation Extraction with Context - Sensitive Structured Parse Tree Information .In Proceedings of EMNLP and CNLL .", "label": "", "metadata": {}, "score": "40.641365"}
{"text": "Our approach , however , does have two clear advantages which complement those of traditional lexica : first , this method allows us to include statistics about actual word usage in the corpus we derive it from .And since we can run our word alignment at any time , we are always in a position to update the lexicon with the addition of new texts .", "label": "", "metadata": {}, "score": "40.658607"}
{"text": "Given the complexity of the task , typically only a few semantic relations are output , for which the confidence is very high , based on the analysis of large quantities of documents .Our aim is to show how a deep - linguistic approach can be used in a Text Mining application , offering high - precision relation extraction , while at the same time retaining a high recall .", "label": "", "metadata": {}, "score": "40.847275"}
{"text": "In addition to pairing entities according to the above constraints , this component also assigns features to each pair that characterise its lexical and syntactic qualities ( described further in the following section ) .The classifier training and test instances consist of entity pairs .", "label": "", "metadata": {}, "score": "40.85736"}
{"text": "In step 3 , we then align these 1 - 1 sentences using GIZA++ [ Och and Ney 2003 ] .This word alignment is performed in both directions in order to discover multi - word expressions ( MWEs ) in the source language .", "label": "", "metadata": {}, "score": "40.873688"}
{"text": "On the second level we combine various patterns into a single semantic rule , which normalizes many possible syntactic variants ( e.g. active , passive , nominalizations ) .On the third level we combine semantic rules with lexical and ontological constraints to obtain very specialized queries that can detect a given domain - specific relation , as specified by the user .", "label": "", "metadata": {}, "score": "41.00528"}
{"text": "This will enable us to include these later texts in our statistics on a word 's usage , and link these passages to the definition as well .Parsing .Two of the features we would like to incorporate into a dynamic lexicon are based on a word 's role in syntax : subcategorization and selectional preference .", "label": "", "metadata": {}, "score": "41.030945"}
{"text": "Syntactic features are as described in Table 3 .Variation in performance , by number of sentence boundaries ( n ) crossed by a relationship .For all cases , the cumulative feature set + event of Table 4 was used .", "label": "", "metadata": {}, "score": "41.056458"}
{"text": "This distinction may have some psychological validity , but it is not computationally attractive to maintain this distinction in separate array elements .A compromise approach is to attempt to make judgments about redundancy , and write software to merge branches as specified by the judgments of a knowledge engineer .", "label": "", "metadata": {}, "score": "41.174603"}
{"text": "This move is useful in allowing us to isolate the complexities of relation extraction from the vagaries of imperfect entity recognition when the method for performing the former task is under development .In operational use of the IE system , however , the limitations of entity recognition will impact the performance of relation extraction .", "label": "", "metadata": {}, "score": "41.380085"}
{"text": "In order to represent an interaction instance with the shortest traversal path between two entities on the parse graph , we used Dijkstra 's algorithm [ 23 ] .We first transformed the dependency graph to an undirected graph which allows the edges to be traversed in any direction because every syntactic relation is toward the syntactic head .", "label": "", "metadata": {}, "score": "41.62246"}
{"text": "In fact , this is a main drawback of the converted data , which causes erroneous results .It requires an additional pre - processing to eliminate or join unnecessary syntactic relations connected to NE words .That is , NE words are grouped again from the converted results and dependency relations relating NE words are readjusted .", "label": "", "metadata": {}, "score": "41.708298"}
{"text": "If the word alignment process maps the source word be to both of these lemmas in a given sentence ( as in Figure 3 ) , the translation probability is divided evenly between them .The weighted list of translation equivalents we identify using this technique can provide the foundation for our further lexical work .", "label": "", "metadata": {}, "score": "41.717854"}
{"text": "As mentioned before , there were various difficulties including the converted data in experiments .The difficulties are summarized in Table 2 .Thus , the performance can be enhanced by using other syntactic parser which is well adapted for this domain .", "label": "", "metadata": {}, "score": "41.77184"}
{"text": "Nevertheless , while the CFG provides us with a deeper structure , it is still inappropriate for robust spoken language processing since the grammar is almost always incomplete .A CFG - based system is only good when you know what sentences to speak , which diminishes the value and usability of the system .", "label": "", "metadata": {}, "score": "41.801453"}
{"text": "In order to accomplish this , we need to consider the role that automatic methods can play within our emerging cyberinfrastructure .[ 7 ] We need to provide traditional scholars with the apparatus necessary to facilitate their own textual research .", "label": "", "metadata": {}, "score": "41.81502"}
{"text": "While there has been substantial progress in biomedical named entity recognition , relation / interaction extraction is still challenging since biomedical texts often contain complex sentences with long - range relations , as shown in Figure 1a .Substructures for kernels .", "label": "", "metadata": {}, "score": "41.9274"}
{"text": "To investigate this question , we trained classifiers for the subset of relationships found under a number of different distance conditions , in all cases using the cumulative feature set + event from Table 4 , producing the results shown in Table 6 .", "label": "", "metadata": {}, "score": "41.947803"}
{"text": "In a first aspect , a task dependent unified language model for a selected application is created from a task - independent corpus .The task dependent unified language model includes embedded context - free grammar non - terminal tokens in a N - gram model .", "label": "", "metadata": {}, "score": "42.05994"}
{"text": "We can contrast this computer - assisted lexicography with a new variety - which we might more properly call \" computational lexicography \" - that has emerged with the COBUILD project [ Sinclair 1987 ] of the late 1980s .This corpus evidence allows lexicographers to include frequency information as part of a word 's entry ( helping learners concentrate on common words ) and also to include sentences from the corpus that demonstrate a word 's common collocations - the words and phrases that it frequently appears with .", "label": "", "metadata": {}, "score": "42.101818"}
{"text": "The relationships extracted are considered to be of interest for clinical and research applications downstream of IE , such as querying to support clinical research .The approach taken by the CLEF IE system is one that combines the use of existing terminology resources with supervised Machine Learning ( ML ) methods .", "label": "", "metadata": {}, "score": "42.233498"}
{"text": "has a complicated analysis , and can not afford semantic status to each word relative to all the other words within the dictionary .The Kucera et al . system uses three parsing stages , each of which needs more than one pass through the sentence to complete its analysis .", "label": "", "metadata": {}, "score": "42.243294"}
{"text": "While all researchers use orthographic and lexical features , the utility of syntactic information remains a topic of debate and one to which the current study contributes .Methods .Relationship schema .The CLEF IE system extracts entities , relationships and modifiers from text .", "label": "", "metadata": {}, "score": "42.30732"}
{"text": "Instead , they must traverse the list of links and compare structures on a node - by - node basis to guarantee identity .Complicating this procedure is the fact that concepts may be cross - linked across multiple branches of a tree , sharing multiple structures .", "label": "", "metadata": {}, "score": "42.31076"}
{"text": "There is tons of literature on dependency parsing you can read .This book and these lecture notes are good starting points to introduce the conventional methods .The Link Grammar Parser which is sorta like dependency parsing uses Sleator and Temperley 's Link Grammar syntax for producing word - word linkages .", "label": "", "metadata": {}, "score": "42.320175"}
{"text": "The previous techniques of natural language processing are often limited to the performance of a particular purpose and can not be used for other purposes .Conventional parsing techniques may be designed to function as part of a grammar checking system , but can not function as part of a search engine , summarization application , or categorization application .", "label": "", "metadata": {}, "score": "42.323128"}
{"text": "We train classifiers using a number of different features sets , and investigate their contribution to system performance .These sets include some comparatively simple text - based features , and others based on a linguistic analysis , including some derived from a full syntactic analysis of sentences .", "label": "", "metadata": {}, "score": "42.33118"}
{"text": "With clustering techniques , we can establish the semantic similarity between two words based on their appearance in similar contexts .In creating a lexicon with these features , we are exploring two strengths of automated methods : they can analyze not only very large bodies of data but also provide customized analysis for particular texts or collections .", "label": "", "metadata": {}, "score": "42.339622"}
{"text": "Mostly , the similarities between structures can be efficiently computed in a recursive manner without explicitly enumerating with feature vectors , which enables us to avoid complex feature construction and selection processes [ 9 - 14 ] .Motivation .This work expands on our previous kernel approaches [ 13 ] .", "label": "", "metadata": {}, "score": "42.387974"}
{"text": "Rindflesch T , Fiszman M , Libbus B : Semantic Interpretation for the Biomedical Literature .Medical Informatics : Advances in Knowledge Management and Data Mining in Biomedicine ( Edited by : Chen H , Fuller WHS , Friedman C ) .", "label": "", "metadata": {}, "score": "42.41703"}
{"text": "This structural property was incorporated as prior knowledge in the extended dependency kernel .In addition , the kernel was modified to consider more extensive structural comparisons by allowing partial dependency path matches and counting the matches differently according to their types .", "label": "", "metadata": {}, "score": "42.645004"}
{"text": "We have designed the search algorithm so that a few basic syntactic patterns are expanded by default .This includes for example the case of conjunctions , as it can be seen in one of the examples shown in figure 2 .", "label": "", "metadata": {}, "score": "42.668068"}
{"text": "The design of the ontology - based parser is based on the premise that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .", "label": "", "metadata": {}, "score": "42.67576"}
{"text": "Table 1 .Evaluation on Carroll 's test suite on subj , obj , PP - attachment and subordinate clause relations .We have observed that verbs and prepositions , which are especially important for the lexicalized disambiguation , vary far less between general text and the biomedical domain than nouns .", "label": "", "metadata": {}, "score": "42.816505"}
{"text": "The experimental results show that the model combining general and specific features alleviates the sparse data problem .In addition , the weighted probabilistic model based on information gain ratio outperforms the non - weighted model . ... distinctions that have to be taken intosaccount .", "label": "", "metadata": {}, "score": "42.84497"}
{"text": "The ontology - based parser is designed around the idea that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .", "label": "", "metadata": {}, "score": "42.903305"}
{"text": "Note that all these approaches are knowledge - engineering approaches , based on manually authored grammars , lexicons and ontologies .While supervised machine learning has also been applied to clinical text , its use has generally been limited to entity recognition .", "label": "", "metadata": {}, "score": "42.94056"}
{"text": "It is local , yet can handle also compositional structures . ... full parse of free - text sentences ( e.g. , Bod ( 1992 ) , Magerman ( 1995 ) , Collins ( 1997 ) , Ratnaparkhi ( 1997 ) , and Sekine ( 1998 ) ) .", "label": "", "metadata": {}, "score": "42.98209"}
{"text": "Tools . \" ...We study the problem of combining the outcomes of several different classifiers in a way that provides a coherent inference that satisfies some constraints .In particular , we develop two general approaches for an important subproblem - identifying phrase structure .", "label": "", "metadata": {}, "score": "43.001404"}
{"text": "This is in contrast to others ( for example [ 32 ] ) , who identify negated diseases and findings as complete expressions .The entities , modifiers , and relationships are described by both a formal XML schema , and a set of detailed definitions .", "label": "", "metadata": {}, "score": "43.087708"}
{"text": "This approach can produce results that may at first sight seem anomalous , e.g. cases where the F 1 score for a given relation does not fall between the P and R scores .Overall scores for relation recognition are produced by first micro - averaging scores for the different relation types within the fold , i.e. simply adding their counts for true - positives , false - negatives and false - positives , and using these summed values to compute P and R values directly .", "label": "", "metadata": {}, "score": "43.11077"}
{"text": "The ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}, "score": "43.142105"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 20 , wherein said parser filters remove parse trees that violate one of statistical and ontological criteria for well - formedness .", "label": "", "metadata": {}, "score": "43.151108"}
{"text": "0085 ] .As illustrated at 410 , the expanded terms are combined to form all possible triples .Then , as illustrated at 415 , all of the possible triples are checked against the dependency triple database 360 shown in FIGS .", "label": "", "metadata": {}, "score": "43.258125"}
{"text": "The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .Ontological parsing is a grammatical analysis technique built on the proposition that the most useful information that can be extracted from a sentence is the set of concepts within it , as well as their formal relations to each other .", "label": "", "metadata": {}, "score": "43.27137"}
{"text": "Likewise , the method for the pairs , including nested entities and negation expressions , should be enhanced .So far , we restricted the research to focus on structural kernels by using dependency information on the shortest path .However , the combination with the bag - of - words kernel can be a backup to compensate for the imperfect syntactic analyses derived from automated systems in the real world and insufficient information of the shortest path representation by including the neighboring words .", "label": "", "metadata": {}, "score": "43.309708"}
{"text": "Such a representation scheme gives each node in the tree a unique identifier that completely determines the relative place of that node in the tree structure .It also provides a simple way to compare relative positions of two discovered node instances .", "label": "", "metadata": {}, "score": "43.37876"}
{"text": "Rather than a full dependency structure for each sentence , it might be that you only care for the dependency triples ( two words , and the name of the dependency relation ) .For this , you might try : .", "label": "", "metadata": {}, "score": "43.535305"}
{"text": "All this information is represented as a set of predicates and stored into the KB of the system , which can then be queried using the methodology described in section \" Relation Mining \" .Example of Dependency Tree .Tree of dependencies for a GENIA sentence , along with other linguistic annotations .", "label": "", "metadata": {}, "score": "43.595894"}
{"text": "It is useful and usual to fix entity recognition in this way , to allow tuning specific to relationship extraction , and to allow the isolation of relation - specific problems .Ultimately , however , relation extraction does depend on the quality of entity recognition .", "label": "", "metadata": {}, "score": "43.64548"}
{"text": "The LLL basically used the Link Grammar Parser [ 24 ] for syntactic analysis and the parsed results were manually corrected .Thus , it is a clean data set .The dependency analysis produced by the parser was simplified to 27 grammatical relations .", "label": "", "metadata": {}, "score": "43.64943"}
{"text": "PubMed View Article .Fundel K , K\u00fcffer R , Zimmer R : RelEx - Relation extraction using dependency parse trees .Bioinformatics 2006 , 23 ( 3 ) : 365 - 371 .PubMed View Article .Huang M , Zhu X , Hao Y , Payan DG , Qu K , Li M : Discovering patterns to extract protein - protein interactions from full texts .", "label": "", "metadata": {}, "score": "43.650085"}
{"text": "We also examine the influence of training corpus size on performance , as hand annotation of training data is the major expense in supervised machine learning .Finally , we investigate the impact of imperfect entity recognition on relation extraction performance , by comparing relation extraction done over perfect gold - standard entities to that done over imperfect recognised entities .", "label": "", "metadata": {}, "score": "43.743004"}
{"text": "LNAI 3581 .Huang M , Zhu X , Payan DG , Qu K , Li M : Discovering Patterns to Extract Protein - Protein Interactions from Full Texts .OUP Bioinformatics 2004 , 20 ( 18 ) : 3604 - 3612 .", "label": "", "metadata": {}, "score": "43.751152"}
{"text": "The result is that the time complexity of structure - comparison algorithms attains the polynomial order of the number of features ( or nodes ) being compared .This fact makes the use of ontologies inefficient for high - performance computing applications , such as searching terabyte - sized databases with wide - ranging conceptual content .", "label": "", "metadata": {}, "score": "43.78331"}
{"text": "Feature selection .We next report experiments regarding the features most useful for relation extraction , using the features sets described in Table 3 .We divide the discussion between the case of features sets that do not use syntactic parse information and those that do .", "label": "", "metadata": {}, "score": "43.793427"}
{"text": "However , the use of a whole sentential structure can generate noise in learning since all constituents in a sentence actually do not concern an interaction between two entities .Thus , we need to restrict the structure for interaction learning to directly or indirectly relevant ones to two entities .", "label": "", "metadata": {}, "score": "43.824715"}
{"text": "After all , a more elaborate strategy for path extension with respects to single dependency path and coordination handling is required as future work .The path links that have no predicate should be reconsidered .Third , some interactions are undetected due to parsing errors .", "label": "", "metadata": {}, "score": "43.829453"}
{"text": "The search engine then combines the expanded terms to form dependency triples from the expanded terms .From the formed dependency triples , dependency triples which are not found in a dependency triples database are discarded to obtain remaining dependency triples from the expanded terms .", "label": "", "metadata": {}, "score": "43.834892"}
{"text": "This limits the versatility of the techniques .U.S. Pat .No .4,864,502 to Kucera et al . discloses a device that tags and parses natural - language sentences , and provides interactive facilities for grammar correction by an end user .", "label": "", "metadata": {}, "score": "43.91333"}
{"text": "In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .The output predicate structures contain numeric tags that represent the location of each concept within the ontology .", "label": "", "metadata": {}, "score": "43.923096"}
{"text": "In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .The output predicate structures contain numeric tags that represent the location of each concept within the ontology .", "label": "", "metadata": {}, "score": "43.923096"}
{"text": "Thomas J , Milward D , Ouzounis C , Pulman S , Carroll M : Automatic Extraction of Protein Interactions from Scientific Abstracts .Pac Symp Biocomput 2000 , 541 - 552 .Pustejovsky J , Castano J , Zhang J , Kotecki M , Cochran B : Robust Relational Parsing Over Biomedical Literature : Extracting Inhibit Relations .", "label": "", "metadata": {}, "score": "43.969566"}
{"text": "Each of the context - free grammars include words or terminals present in the task - independent corpus to form the semantic or syntactic concepts .The task - independent corpus with the plurality of context - free grammars is parsed to identify word occurrences of each of the semantic or syntactic concepts and phrases .", "label": "", "metadata": {}, "score": "43.969837"}
{"text": "No .5,146,496 to Jensen discloses a technique for identifying predicate - argument relationships in natural language text .The Jensen system must create intermediate feature structures to store semantic roles , which are then used to fill in predicates whose deep structures have missing arguments .", "label": "", "metadata": {}, "score": "44.028625"}
{"text": "0105 ] .In single triple translation , P(e ) can be estimated using MLE ( Maximum Likelihood Estimation ) , which can be rewritten as : .P .MLE .w .E1 .rel .E . w .", "label": "", "metadata": {}, "score": "44.035446"}
{"text": "The remaining feature selection experiments look at the impact of using features derived from a dependency parse analysis of the clinical texts made using the Stanford parser [ 39 ] , which is a dependency parser that has been developed principally in relation to newswire texts .", "label": "", "metadata": {}, "score": "44.048195"}
{"text": "In particular , we develop two general approaches for an important subproblem- identifying phrase structure .The first is a Markovian approach that extends standard HMMs to allow the use of a rich observation structure and of general classifiers to model state - observation dependencies .", "label": "", "metadata": {}, "score": "44.053032"}
{"text": "The proposed model exploits context features around the focus word .And to alleviate the sparse data problem , it integrates general features with specific feat ... \" .In this paper , we define the chunking problem as a classification of words and present a weighted probabilistic model for a text chunking .", "label": "", "metadata": {}, "score": "44.068863"}
{"text": "In the similar way , C p ( p 1 , p 2 ) is applied for common POS dependency subgraphs rooted at POS p 1 and p 2 .However , in case of syntactic dependency path , the subcategorization information is excluded as follows : .", "label": "", "metadata": {}, "score": "44.13531"}
{"text": "Traditionally such approaches have been limited by the brittleness of the existing parsers .However , recent advances in probabilistic - based parsing allow to overcome such limitations and render such approaches competitive .We discuss below a few systems that make use of full parsing approaches for the analysis of biomedical literature .", "label": "", "metadata": {}, "score": "44.166885"}
{"text": "This study starts from the drawbacks of our previous dependency kernel .It showed difficulties in handling the following aspects : ( 1 ) e - walks , ( 2 ) partial match , and ( 3 ) non - contiguous paths , and ( 4 ) different significance of substructures .", "label": "", "metadata": {}, "score": "44.18472"}
{"text": "They used the predicate argument structures obtained by a head - driven phrase structure grammar ( HPSG ) parser and a dependency parser , and word context features related to words before , between , and after two interacting NEs .On the other hand , some works considered only shallow linguistic information concerning word context features without using structural information by parsing .", "label": "", "metadata": {}, "score": "44.230984"}
{"text": "An ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}, "score": "44.237106"}
{"text": "Therefore for this experiment we use an existing manually annotated corpus .However , in [ 2 ] we describe how our system can cope with an automatically annotated corpus using an external tool for the detection of the domain entities and terminology .", "label": "", "metadata": {}, "score": "44.25634"}
{"text": "The second method is to perform research from the ground up in defining an ontology , assigning elements on an as - needed basis .Since minimal representation size is a main goal of parameterizing the ontology , one would want to eliminate many of the redundancies found in general - purpose ontologies such as WordNet .", "label": "", "metadata": {}, "score": "44.36355"}
{"text": "Bunescu R , Mooney R : Subsequence kernels for relation extraction .Proceedings of the 19th conference on Neural Information Processing Systems .Vancouver , Canada 2005 .Culotta A , Sorensen J : Dependency Tree Kernels for Relation Extraction .Proceedings of ACL Barcelona , Spain 2004 , 423 - 429 .", "label": "", "metadata": {}, "score": "44.381184"}
{"text": "Parsing the corpus .We use a robust , deep - syntactic , broad - coverage probabilistic Dependency Parser [ 11 ] , which identifies grammatical relations between the heads of chunks , chunk - internal dependencies , and the majority of long - distance dependencies [ 12 ] .", "label": "", "metadata": {}, "score": "44.441093"}
{"text": "Sinclair 1987 Sinclair , John M. ( ed . )Looking Up : an account of the COBUILD project in lexical computing .Collins , 1987 .Singh and Husain 2005 Singh , Anil Kumar and Samar Husain .\" Comparison , Selection and Use of Sentence Alignment Algorithms for New Language Pairs \" , Proceedings of the ACL Workshop on Building and Using Parallel Texts ( 2005 ) .", "label": "", "metadata": {}, "score": "44.449753"}
{"text": "Miller et al .1993 Miller , George , Claudia Leacock , Randee Tengi , and Ross Bunker . \"A Semantic Concordance \" , Proceedings of the ARPA Workshop on Human Language Technology ( 1993 ) .Moore 2002 Moore , Robert C. \" Fast and Accurate Sentence Alignment of Bilingual Corpora \" , AMTA ' 02 : Proceedings of the 5th Conference of the Association for Machine Translation in the Americas on Machine Translation ( 2002 ) .", "label": "", "metadata": {}, "score": "44.72586"}
{"text": "They generally use a syntactic parse with domain - specific grammar rules .The Linguistic String project [ 10 ] used a full syntactic and clinical sub - language parse to fill template data structures corresponding to medical statements .These were mapped to a database model incorporating medical facts and the relationships between them .", "label": "", "metadata": {}, "score": "44.748028"}
{"text": "Annotators were further told that relationships could span multiple sentences , and that it was acceptable to use clinical knowledge to infer when a relationship existed .Counts of all relationships annotated in C77 are shown in Table 2 , sub - divided by the number of sentence boundaries spanned .", "label": "", "metadata": {}, "score": "44.767235"}
{"text": "Each of these co - referring expressions is a mention of the entity .The schema includes encoding of co - reference between different textual mentions of the same entity .For the work reported in this paper , however , co - reference is ignored , and each entity mention is treated as a different entity .", "label": "", "metadata": {}, "score": "44.848686"}
{"text": "Consequently , the weighting scheme helps emphasize the dependencies on the shortest path without excluding dependencies other than the shortest path .Thus , potentially relevant words outside of the shortest path can be included in the kernel .However , [ 12 ] reported that subtrees enclosed by the shortest path between two entities still describe their relation better than other subtrees , even though the representation can miss important words outside the shortest path in some cases , as pointed by [ 14 ] .", "label": "", "metadata": {}, "score": "44.865536"}
{"text": "Corney DPA , Buxton BF , Langdon WB , Jones D :BioRAT : Extracting Biological Information from Full - Length Papers .Bioinformatics 2004 , 20 ( 17 ) : 3206 - 13 .View Article PubMed .Leroy G , Chen H , Martinez JD : A Shallow Parser Based on Closed - Class Words to Capture Relations in Biomedical Text .", "label": "", "metadata": {}, "score": "44.887794"}
{"text": "For each sentence read from standard input , an xml file will be created in the directory $ HOME / tmp containing the dependency structure .For browsing and querying such xml files , check out the scripts that come with the Alpino Treebank .", "label": "", "metadata": {}, "score": "44.90941"}
{"text": "This iterative process can be repeated as necessary until the errors are corrected and a suitable N - gram model has been obtained .As discussed above , the task - independent corpus is a general corpus and in fact it is likely that most of the corpus is unrelated to the task or application that the developer is interested in .", "label": "", "metadata": {}, "score": "45.12906"}
{"text": "For a query sentence , all of the words are replaced with their similar or related words , for example synonyms from a thesaurus .Then , a dependency triple database is used to filter illegal collocations in order to remove possible noisy expansions .", "label": "", "metadata": {}, "score": "45.15589"}
{"text": "We believe that this work has implications for clinical text mining more generally , given the success of our approach and its adaptability for other clinical domains , though further work to confirm our encouraging results should be carried out on a larger sample of narratives and relationship types .", "label": "", "metadata": {}, "score": "45.183453"}
{"text": "First , entities that are paired must be within n sentences of each other .Second , we constrain the entity pairs created by argument type [ 36 ] .For example , there is little point in creating an entity pair between a Drug or device entity and a Result entity , as no relationships exist between entities of these types , as specified by the schema .", "label": "", "metadata": {}, "score": "45.217525"}
{"text": "system checks only for syntactic correctness .U.S. Pat .No .4,914,590 to Loatman et al . discloses a natural language understanding system .The goal of the Loatman et al . system is to provide a formal representation of the context of a sentence , not merely the sentence itself .", "label": "", "metadata": {}, "score": "45.240685"}
{"text": "6 illustrates a method 180 for creating a unified language model for a selected application from a task - independent corpus that includes a large number of phrases that may be of different context .Simple parsing of the task - independent corpus with context - free grammars for the task - dependent application may cause errors , which will then propagate to the N - gram model upon application of an N - gram algorithm .", "label": "", "metadata": {}, "score": "45.358963"}
{"text": "The entity recognition approach is as described in [ 2 ] , using a combination of lexical lookup and supervised ML .Lexical lookup uses the Termino terminology resource [ 40 ] .A Termino database is loaded with terms from the UMLS Metathesaurus [ 33 ] .", "label": "", "metadata": {}, "score": "45.36937"}
{"text": "The paper presents experimental results for recognizing noun phrase , subject - verb and verb - object patterns in l ! ]n - glish .Since the learning approach enables easy port - ing to new domains , we plan to apply it to syntac - tic patterns in other languages and to sub - language patterns for information extraction . ... full parsing and instead to rely only on local information .", "label": "", "metadata": {}, "score": "45.372795"}
{"text": "To realize this system , several technologies are proposed .For example , a first is related to improved example sentence recommendation methods .A second is related to improved cross - lingual information retrieval methods and technology which facilitate searching in the user 's native language others are also proposed .", "label": "", "metadata": {}, "score": "45.396835"}
{"text": "A side benefit from this algorithm is that it provides an intuitive , natural ranking algorithm .Larger values from the subtraction operation mean further distance apart in the tree , so even when two concepts are in the same branch , the representation provides a convenient metric of conceptual distance .", "label": "", "metadata": {}, "score": "45.45076"}
{"text": "We develop efficient combination algorithms under both models and study them experimentally in the context of shallow parsing . ... algorithms that use general classifiers to yield the inference .Working within a concrete task allows us to compare ... . by Young - Sook Hwang , So - Young Park , Hoo - Jung Chung , Yong - Jae Kwak , Hae - Chang Rim , 2001 . \" ...", "label": "", "metadata": {}, "score": "45.58277"}
{"text": "In the feature - based kernels , the syntactic substructures of relation instances were mapped to flat features .For example , the walk kernel learned interactions through v -walk and e -walk features on the shortest dependency paths .On the contrary , the structure - based kernel was represented by structural similarities between relation instances ( See Equation ( 3 ) , ( 4 ) ) , instead of explicit feature enumerations .", "label": "", "metadata": {}, "score": "45.583122"}
{"text": "The comparisons with other systems , which were accessed by LLL task 's external evaluation , are shown .Table 7 shows performance comparisons over AIMed with other systems .In the table , all systems except [ 9 ] used syntactic information by automated parsers .", "label": "", "metadata": {}, "score": "45.64517"}
{"text": "Lindberg D , Humphreys B , McCray A : The Unified Medical Language System .Methods Inf Med 1993 , 32 ( 4 ) : 281 - 291 .PubMed .Roberts A , Gaizauskas R , Hepple M , Demetriou G , Guo Y , Setzer A , Roberts I : Semantic Annotation of Clinical Text : The CLEF Corpus .", "label": "", "metadata": {}, "score": "45.752586"}
{"text": "28 ] applied sequence alignment and finite state automata to generate syntactic patterns for identifying genic interactions .[29 ] proposed the Markov Logic model to create a set of weighted clauses on the discourse representation structure which can classify pairs of interactive NEs .", "label": "", "metadata": {}, "score": "45.794556"}
{"text": "Dependency parsers are the way to go here probably . - ealdent Mar 9 ' 10 at 15:10 Affiliated with .Affiliated with .Affiliated with .Abstract .Background .The Clinical E - Science Framework ( CLEF ) project has built a system to extract clinically significant information from the textual component of medical records in order to support clinical research , evidence - based healthcare and genotype - meets - phenotype informatics .", "label": "", "metadata": {}, "score": "45.86196"}
{"text": "The following is an example of a sentence and demonstrates both how it is parsed as a sentence within a document , and how a question to an information retrieval system would produce matching predicates to retrieve the document containing this sentence .", "label": "", "metadata": {}, "score": "45.90795"}
{"text": "High - quality domain entity recognition is therefore key to successful parsing in the biomedical domain , as we show in [ 20 ] .Methods : Relation mining .Our approach to relation mining is based on 3 levels of rules .", "label": "", "metadata": {}, "score": "45.93772"}
{"text": "Discussion and future work .A more detailed investigation of other dependency parsers applied in PPI studies [ 11 , 16 , 19 ] should be performed in our future research .The critical point in biomedical text parsing is how well a parser handles coordination , apposition , and relative clauses which often cause erroneous results in PPI learning .", "label": "", "metadata": {}, "score": "46.012733"}
{"text": "It does not always deliver a parse spanning the entire sentence , however it never fails completely , always delivering at least partial structures .Table 1 shows a comparison of two evaluations performed using the parser .For the first result , we apply the standard 500 sentence test set for dependency parsers , GREVAL [", "label": "", "metadata": {}, "score": "46.05532"}
{"text": "If desired , the second language model can be weighted based on whether the identified text is believed to be accurate .The weighting can be based on the amount of text identified in the task - independent corpus , the number of queries used , etc . .", "label": "", "metadata": {}, "score": "46.151527"}
{"text": "We have implemented patterns and rules that can cope with these cases , but they have not been evaluated yet , and therefore for the present study they are not further considered .Ontology - based queries .If a domain Ontology is available , our system can make use of it in the query process , by using the types as restrictions for the arguments .", "label": "", "metadata": {}, "score": "46.151703"}
{"text": "The system and method of the present invention isolates predicate - argument relationships into a consistent format regardless of text types .The predicate - argument relationships can be used in search , grammar - checking , summarization , and categorization applications , among others .", "label": "", "metadata": {}, "score": "46.16652"}
{"text": "Similarity between the query and segments of the task - independent corpus can be computed using cosine similarity measure .These are generally well - known techniques in the field of information retrieval .Alternatively , the query can include Boolean logic ( \" and \" , \" or \" , etc . ) as may be desired to combine word phrases .", "label": "", "metadata": {}, "score": "46.2081"}
{"text": "From the formed dependency triples , dependency triples which are not found in a dependency triples database are discarded to obtain remaining dependency triples from the expanded terms .The search engine then searches the sentence database using the remaining dependency triples as search parameters .", "label": "", "metadata": {}, "score": "46.233444"}
{"text": "Variation in performance by training corpus size .The \" Count \" row gives the number of training instances of a relation type , for the given corpus .The cumulative feature set + event of Table 4 was used .Extracting relations over extracted entities .", "label": "", "metadata": {}, "score": "46.254883"}
{"text": "Since a key component of semantic relation determination is to identify the semantic arguments filling the roles of predicates , such predicate markers can be an informative feature on predicate argument structures for a given sentence .Figure 2b visualizes the shortest dependency path linking \" ywhE \" and \" sigF \" .", "label": "", "metadata": {}, "score": "46.335106"}
{"text": "For example , in a search engine application , it may be useful to check whether or not a particular noun can serve as an argument of a predicate .The features of the noun should be more specific than the features of the argument position it is attached to .", "label": "", "metadata": {}, "score": "46.347378"}
{"text": "Such patterns can be manually written , or , more frequently , automatically induced from a manually annotated corpus .An example of this approach is given by [ 22 ] .While surface patterns are easy to learn and computationally efficient , they fail to generalize on even the most obvious linguistic variations .", "label": "", "metadata": {}, "score": "46.351364"}
{"text": "Classification .We treat clinical relationship extraction as a classification task , training classifiers to assign a relationship type to an entity pair .An entity pair is a pairing of entities that may or may not be the arguments of a relation .", "label": "", "metadata": {}, "score": "46.439095"}
{"text": "[ 0013]FIG .3 is a block diagram illustrating a system and method of the present invention which aid a user in constructing and polishing English sentences .[ 0014 ] .FIGS .4 - 1 and 4 - 2 are examples of dependency triples for an English language query and a Chinese language query , respectively .", "label": "", "metadata": {}, "score": "46.44182"}
{"text": "They all performed 10-fold cross - validation on the LLL training set for evaluation and performances were assessed in terms of undirected interaction extraction .Our walk - weighted subsequence kernel was compared with other recent systems which were evaluated on 5 PPI corpora .", "label": "", "metadata": {}, "score": "46.45397"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a non - negative number indicates agreement .", "label": "", "metadata": {}, "score": "46.536777"}
{"text": "Performance does , however , remain close to IAA ( Table 9 ) , which measures an analogous human task in which annotators must find both entities and relations .Clearly , good relation extraction depends on good entity recognition .Performance of relation extraction over automatically extracted entities , compared to relation extraction using perfect gold standard entities .", "label": "", "metadata": {}, "score": "46.701546"}
{"text": "[ 0015]FIG .5- 1 is a block diagram illustrating a method of creating a dependency triples database .[ 0016 ] .[ 0016]FIG .5- 2 is a block diagram illustrating a query expansion method which provides alternative expressions for use in searching a sentence database .", "label": "", "metadata": {}, "score": "46.726543"}
{"text": "Such complex rules can be designed by listing all the syntactic and lexical constraints , or alternatively can be constructed combining syntactic and semantic rules , as in the example below : .We refer to relations defined at this level as domain relations as they rely on lexical constraints which are typical of a given domain .", "label": "", "metadata": {}, "score": "46.793922"}
{"text": "[ 9 ] These are syntactic qualities since each of these arguments bears a direct syntactic relation to their head as much as they hold a semantic place within the underlying argument structure .In order to extract this kind of subcategorization and selectional information from unstructured text , we first need to impose syntactic order on it .", "label": "", "metadata": {}, "score": "46.81465"}
{"text": "Our treebank is still too small to achieve state - of - the - art results in parsing but we can still induce valuable lexical information from its output by using a large corpus and simple hypothesis testing techniques to outweigh the noise of the occasional error [ Bamman and Crane 2008 ] .", "label": "", "metadata": {}, "score": "46.833447"}
{"text": "The results obtained are comparable to other parsers [ 16 - 18 ] .For the second result , we use a random set from the GENIA corpus in order to assess its performance on the biomedical domain .We have randomly selected 100 sentences from the GENIA corpus , which we have manually annotated for the syntactic relations that the parser can detect .", "label": "", "metadata": {}, "score": "46.867043"}
{"text": "We constrict an essential structure for modeling of a relationship between two entities to the directed shortest dependency path that connects them on the sentential graphs .However , to cover some limitations of the shortest path representation as pointed in [ 12 ] and [ 14 ] , single paths that consist of two NEs and a single direct syntactic dependency of a coordinating conjunction between them are extended .", "label": "", "metadata": {}, "score": "46.87492"}
{"text": "The human - created annotations of the gold standard documents capture examples of the specific content that the IE system is required to extract , providing the system with focussed knowledge of the task domain , alongside the broader domain knowledge provided by more general terminology resources .", "label": "", "metadata": {}, "score": "46.88009"}
{"text": "The latter shows that even inclusion of relationships in adjacent sentences produces a 6 % drop in overall F 1 as compared to the purely intra - sentential case .Performance continues to drop as more inter - sentential relationships are included , as the remaining columns show .", "label": "", "metadata": {}, "score": "46.95347"}
{"text": "[ 0057 ] .Dependency Triple Database .[0058 ] .A dependency triple consists of a head , a dependent , and a dependency relation between the head and the dependent .Using a dependency parser , a sentence is analyzed into a set of dependency triples trp in a form such as illustrated in Equation 5 : .", "label": "", "metadata": {}, "score": "47.03843"}
{"text": "However , it is clear from the tree above that not all differences are equally meaningful .In order for the magnitude of the difference to be relevant , it must first be the case that one of the concepts inherits all the properties of the others .", "label": "", "metadata": {}, "score": "47.064957"}
{"text": "Here , we suggest two kinds of kernel methods for genic interaction extraction , considering the structural aspects of sentences .First , we improve our prior dependency kernel by modifying the kernel function so that it can involve various substructures in terms of ( 1 ) e - walks , ( 2 ) partial match , ( 3 ) non - contiguous paths , and ( 4 ) different significance of substructures .", "label": "", "metadata": {}, "score": "47.13791"}
{"text": "As our results will show , it is clear that it is difficult for annotators to reach agreement on relationships , some more so than others .Further , lower values for IAA than for CIAA show this difficulty is compounded massively by lack of agreement on entities .", "label": "", "metadata": {}, "score": "47.164955"}
{"text": "The system is the current state - of - the - art PPI extraction system on various PPI corpora .They also boosted system performance by adopting the corpus weighting concept ( SVM - CW ) [ 21 ] .Recently , the BioNLP 2009 shared task considered more detailed behaviours of bio - molecules [ 22 ] as compared to previous PPI researches .", "label": "", "metadata": {}, "score": "47.17021"}
{"text": "The modular design of the ontological parser permits the use of any part - of - speech - tagged ontology , with only minimal rewriting of the lexer and parser to accommodate format - specific issues .However , maximum benefits are recognized through the use of a parameterized ontology , an innovation heretofore unavailable in any parser or information retrieval system .", "label": "", "metadata": {}, "score": "47.191223"}
{"text": "The lexical walk consists of lexical words and their dependency relations on a lexical dependency path like Figure 2c , and the syntactic walk , of POS and their dependency relations , on a syntactic dependency path , respectively .With this walk information , we can capture structural context information .", "label": "", "metadata": {}, "score": "47.20449"}
{"text": "Gale et al .1992a Gale , William , Kenneth W. Church and David Yarowsky . \"Using bilingual materials to develop word sense disambiguation methods \" , Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation ( 1992 ) .", "label": "", "metadata": {}, "score": "47.252182"}
{"text": "Inside each context - free grammar , the standard probabilistic context - free grammar can be used .However , without real data pertaining to the specific task or application , an estimate for each of the terminal probabilities can not be easily determined .", "label": "", "metadata": {}, "score": "47.26903"}
{"text": "They apply a pattern extraction algorithm to induce rules from a development corpus that are then applied to a test corpus .The results are relatively good ( 33 % F - Measure ) for an approach which aims at avoiding manual construction of rules .", "label": "", "metadata": {}, "score": "47.28756"}
{"text": "McDonald et al .2005 McDonald , Ryan , Fernando Pereira , Kiril Ribarov , and Jan Haji\u010d .\" Non - projective Dependency Parsing using Spanning Tree Algorithms \" , Proceedings of HLT / EMNLP ( 2005 ) .Mel'\u010duk 1988 Mel'\u010duk , Igor A. Dependency Syntax : Theory and Practice .", "label": "", "metadata": {}, "score": "47.34606"}
{"text": "The resultant class assignments by multiple binary classifiers must be post - processed to deal with ambiguity .In application to unseen text , it is possible that several classifiers assign different classes to an entity pair ( test instance ) .", "label": "", "metadata": {}, "score": "47.36519"}
{"text": "To improve query translation in search engine 315 ( or in component 310 ) a new dependency triple based translation model is employed .First , the main dependency triples are extracted from the query , then translation based on those triples is performed .", "label": "", "metadata": {}, "score": "47.38027"}
{"text": "We adopt the same data splitting and evaluation strategy as the study .Also , if the same protein name occurs multiple times in a sentence , the interactions are identified over each occurrence .However , self interactions that a single protein interacts with itself are regarded as negative , whereas in many other works , self interactions are not considered as candidates and removed prior to evaluation .", "label": "", "metadata": {}, "score": "47.382065"}
{"text": "Training examples are typically relation instances expressed as a relation type associated with a linked pair of typed entity mentions tagged in a text .The result is a relation classifier capable of recognising relations in entity - tagged text .Approaches differ chie fly according to the ML algorithms and the features employed .", "label": "", "metadata": {}, "score": "47.382248"}
{"text": "This section describes the approach taken in analyzing the input corpus .The tools that we use for such processing steps are organized into a Natural Language Processing pipeline including a fast , deep - linguistic statistical dependency parser .The pipeline and the parser are described separately below .", "label": "", "metadata": {}, "score": "47.478363"}
{"text": "That is , the further apart the beginning and the end in a substring are , the more it is penalized .Contiguous substring matches are assumed to be coherent and affect more the overall meaning of shortest path string .The feature coordination function is changed into a weighted count of subsequence occurrences as follows : .", "label": "", "metadata": {}, "score": "47.493557"}
{"text": "Re- casting the multi - class relation problem as a number of binary problems , and post - processing to resolve ambiguities , is handled by the GATE Learning API .Features for classification .The SVM classification model is built from lexical and syntactic features assigned to tokens and entity pairs prior to classification .", "label": "", "metadata": {}, "score": "47.51601"}
{"text": "We describe and evaluate an environment supporting the extraction of domain - specific relations , such as protein - protein interactions , from a richly - annotated corpus .We use full , deep - linguistic parsing and manually created , versatile patterns , expressing a large set of syntactic alternations , plus semantic ontology information .", "label": "", "metadata": {}, "score": "47.524574"}
{"text": "Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing 2005 , 724 - 731 .Katrenko S , Adriaans P : Learning Relations from Biomedical Corpora Using Dependency Trees .Knowledge Discovery and Emergent Complexity in Bioinformatics no .", "label": "", "metadata": {}, "score": "47.557487"}
{"text": "Feature sets used for learning relationships .The table is split into non - syntactic features , combined non - syntactic features , and syntactic features .The size of a set is the number of features in that set .The tokN features are POS and surface string taken from a window of N tokens on each side of both paired entities .", "label": "", "metadata": {}, "score": "47.622974"}
{"text": "Thus , we additionally consider fragment structures in the learning framework , which are incomplete graphs like in Figure 1e .This is referred to as partial path match .Third , the kernel considered internally contiguous dependency substructures on the shortest path .", "label": "", "metadata": {}, "score": "47.668243"}
{"text": "Related works .In general , a deeper linguistic representation is known to support information extraction well if its accuracy is guaranteed .Thus , many researches related to relation extraction have used shallow or full syntactic analysis .In particular , words between two entities are considered to carry important information regarding relationships between the entities .", "label": "", "metadata": {}, "score": "47.7312"}
{"text": "Munich : K. G. Saur , 2006 .Tufis et al .2004 Tufis , Dan , Radu Ion , and Nancy Ide . \" Fine - Grained Word Sense Disambiguation Based on Parallel Corpora , Word Alignment , Word Clustering and Aligned Wordnets \" , Proceedings of the 20th International Conference on Computational Linguistics ( 2004 ) .", "label": "", "metadata": {}, "score": "47.747326"}
{"text": "Additionally , studies on string kernels are possible because there can be a wide variety of string kernels depending on how the subsequences are defined .Conclusions .We presented kernel methods defined on the shortest dependency path for genic relation extraction .", "label": "", "metadata": {}, "score": "47.806984"}
{"text": "Errors in POS tagging can not be dismissed , and could be the cause of this .The existence of intervening entities , as coded in feature set inter , provides a small benefit .The inclusion of information about events , in the event feature set , is less clear - cut .", "label": "", "metadata": {}, "score": "47.81826"}
{"text": "The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}, "score": "47.82184"}
{"text": "The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}, "score": "47.82184"}
{"text": "Preferably , assigning probabilities to terminals of the context - free grammars includes normalizing the probabilities of the terminals from the N - gram language model in each of the context - free grammars as a function of the terminals in the corresponding context - free grammar .", "label": "", "metadata": {}, "score": "47.84786"}
{"text": "Schneider G , Rinaldi F , Dowdall J : Fast , Deep - Linguistic Statistical Minimalist Dependency Parsing .COLING-2004 workshop on Recent Advances in Dependency Grammars , August 2004 , Geneva , Switzerland 2004 .Schneider G : Extracting and Using Trace - Free Functional Dependencies from the Penn Treebank to Reduce Parsing Complexity .", "label": "", "metadata": {}, "score": "47.867916"}
{"text": "On the task of extracting human protein interactions they report 91 % precision and 21 % recall .GENIES [29 ] is a system , based on a DCG grammar , which processes biomedical literature in order to detect information about cellular pathways .", "label": "", "metadata": {}, "score": "47.958885"}
{"text": "In this way it is immediately obvious to the user whether the tools have done a proper job , or a mistake has been introduced at some stage of processing ( see figure 2 ) .When the coverage is satisfactory , it is possible to proceed to an evaluation , like the one described in this section , which however refers to a particular ' snapshot ' of the system at a given point in time .", "label": "", "metadata": {}, "score": "47.971237"}
{"text": "As described above , commonly the context - free grammars are written by a developer having at least some knowledge of what phrases may be used in the selected application for each of the semantic or syntactic concepts , but the extent of knowledge about such phrases is not complete .", "label": "", "metadata": {}, "score": "47.99266"}
{"text": "Each of the identified word occurrences is replaced with corresponding non - terminal tokens .A N - gram model is then built having the non - terminal tokens .A third aspect is a method for creating a language model for a selected application from a task - independent corpus .", "label": "", "metadata": {}, "score": "48.0202"}
{"text": "These trees are implemented via a variety of techniques , which are generally equivalent to doubly - linked lists .Doubly - linked lists must be created with head and tail nodes , which terminate the list and are designed to keep traversals of the list in bounds .", "label": "", "metadata": {}, "score": "48.037247"}
{"text": "As different applications are developed for language processing , task - dependent ( domain dependent ) language models may be more appropriate , due to their increased specificity , which can also make the language models more accurate than a larger , general purpose language model .", "label": "", "metadata": {}, "score": "48.06028"}
{"text": "Among the systems that participated , the experience of [ 30 ] shows that an approach based on syntactic information can deliver very good results .A different approach , based on learning simple surface patterns ( which encode only lexical information , word order and PoS tags ) is followed by [ 31 ] .", "label": "", "metadata": {}, "score": "48.12681"}
{"text": "The results of this automatic processing go far beyond the construction of a single lexicon .I noted earlier that all scholarly dictionaries include a list of citations illustrating a word 's exemplary use .As Figure 1 shows , each entry in this new , dynamic lexicon ultimately ends with a list of canonical citations to fixed passages in the text .", "label": "", "metadata": {}, "score": "48.127796"}
{"text": "0007 ] .A second challenge is determining how to retrieve hint sentences .Hint sentences are used to provide expanded expressions .In other words , hint sentences should be similar in meaning to the user 's input query sentence , and are used to provide the user with alternate ways to express a particular idea .", "label": "", "metadata": {}, "score": "48.141125"}
{"text": "It kind of sounds like you 're looking for a dependency parser .Such a parser will give you the relationship between any word in a sentence and its semantic or syntactic head .The MSTParser uses an online max - margin technique known as MIRA to classify the relationships between words .", "label": "", "metadata": {}, "score": "48.239365"}
{"text": "As a result , it 's too confusing and time - consuming for users to get any solution .[ 0005 ] .Generally , writers find , it very helpful to have good example sentences available while writing for reference in polishing sentences .", "label": "", "metadata": {}, "score": "48.256847"}
{"text": "Each kernel captured structural information in a different way to find the relationships between genes / proteins in a sentence .The kernels are based on the shortest path connecting two entities on the syntactic parse trees ( dependency graph ) .", "label": "", "metadata": {}, "score": "48.335033"}
{"text": "Figure 1 presents a mock - up of what a dictionary entry could look like in such a dynamic reference work .The first section ( \" Translation equivalents \" ) presents items 1 and 2 from the list , and is reminiscent of traditional lexica for classical languages : a list of possible definitions is provided along with examples of use .", "label": "", "metadata": {}, "score": "48.430653"}
{"text": "Grover C , Haddow B , Klein E , Matthews M , Nielsen L , Tobin R , Wang X : Adapting a Relation Extraction Pipeline for the BioCreAtIvE II Task .Proceedings of the BioCreAtIvE II Workshop Madrid , Spain 2007 .", "label": "", "metadata": {}, "score": "48.489845"}
{"text": "The effect is , that lexical assignments that do not respect this bracketing are removed .In case there is no lexical assignment for the words marked @mwu , then it is assumed that this sequence should be analysed as a name .", "label": "", "metadata": {}, "score": "48.506393"}
{"text": "In their ability to include statistical information about a word 's actual use , these contemporary projects are exploiting advances in computational linguistics that have been made over the past thirty years .Before turning , however , to how we can adapt these technologies in the creation of a new and complementary reference work , we must first address the use of such lexica .", "label": "", "metadata": {}, "score": "48.55908"}
{"text": "That is , lexical subgraphs and morpho - syntactic subgraphs , e - walk and v - walk , and contiguous and non - contiguous dependencies are all differently handled by this kernel .In the experiments , we evaluated our kernels on the 5 PPI corpora by [ 18 ] .", "label": "", "metadata": {}, "score": "48.566277"}
{"text": "The parser uses a hand - written grammar expressing linguistic competence and a statistical language model that calculates lexicalized attachment probabilities , thus expressing linguistic performance .The parser expresses distinctions that are especially important for a predicate - argument based deep syntactic representation , as far as they are expressed in the Penn Treebank training data [ 15 ] .", "label": "", "metadata": {}, "score": "48.567055"}
{"text": "However , the intended output of the parser is the set of predicate structures that it builds for each sentence , and so the preferred parse tree receiver is a software module called a parse tree converter , which extracts predicate structures from the parse trees .", "label": "", "metadata": {}, "score": "48.57551"}
{"text": "To the best of our knowledge , statistical methods have not been previously applied to extraction of relationships from clinical text .By contrast there has been extensive work on relation extraction from biomedical journal papers and abstracts .Much early work in this area and some recent work as well has been done within the hand - written rule base / knowledge engineering paradigm .", "label": "", "metadata": {}, "score": "48.589455"}
{"text": "Comparisons with other systems .Table 6 shows comparisons with other systems that were trained and tested on the perfectly parsed LLL dataset .The systems were all accessed by the LLL external evaluation server .In the experiment , our system outperformed other systems .", "label": "", "metadata": {}, "score": "48.6297"}
{"text": "A language model provides a method or means of specifying which sequences of words in the vocabulary are possible , or in general provides information about the likelihood of various word sequences .Speech recognition is often considered to be a form of top - down language processing .", "label": "", "metadata": {}, "score": "48.64956"}
{"text": "The advantages of the present system are the provision of a semantic representation of comparable utility with significantly reduced processing requirements , and no need to train the system to produce semantic representations of text content .The system and method for ontological parsing of natural language according to the present invention has a far simpler analysis process than conventional parsing techniques , and utilizes a dictionary containing tags with syntactic information .", "label": "", "metadata": {}, "score": "48.659817"}
{"text": "Conclusions and future work .In this paper we have presented an approach aimed at supporting the process of extraction of core relational information from scientific literature in the biomedical domain .We have based our experiments on an extended version of the manually - annotated GENIA corpus .", "label": "", "metadata": {}, "score": "48.66841"}
{"text": "The last two definitions recursively call C w with respect to their common dependency word pairs in the set sc w ( n 1 , n 2 ) but C w is weighted with a larger value if the two nodes share the same subcategorization information .", "label": "", "metadata": {}, "score": "48.724735"}
{"text": "Finally , all of the translations of the triples are used as the query terms by search engine 315 .[ 0102 ] .Using Bayes ' theorem , we can write : .P .e .c . )P .", "label": "", "metadata": {}, "score": "48.818375"}
{"text": "They utilized neighboring words and their word class sequences to discover the presence of a relation between entities .[17 ] extended [ 9 ] 's work .[16 ] proposed the composite kernel , which combines previously suggested kernels : the all - paths - dependency kernel of [ 14 ] , the bag - of - words kernel of [ 11 ] , and the subset tree kernel of [ 20 ] .", "label": "", "metadata": {}, "score": "48.8686"}
{"text": "The second is an extension of constraint satisfaction formalisms .We develop efficient combination algorithms under both models and study them experimentally in the context of shallow parsing . 1 Introduction In many situations it is necessary to make decisions that depend on the outcomes of several different classifiers in a way that provides a coherent inference that satisfies some constraints - the sequential nature of the data or other domain specific constraints .", "label": "", "metadata": {}, "score": "48.877686"}
{"text": "We have shown that it is possible to extract clinical relationships from text , using a supervised machine learning approach .IAA scores suggest that the task is difficult , but our system performs well , achieving an overall F 1 of 72 % , just 3 % below corrected IAA .", "label": "", "metadata": {}, "score": "48.93107"}
{"text": "[ 16 ] presented a composite kernel of previously suggested kernels .They combined the all - paths- dependency kernel by [ 14 ] , the bag - of - words kernel by [ 11 ] , and the subtree kernel by [ 20 ] .", "label": "", "metadata": {}, "score": "48.957916"}
{"text": "Often , the rules are applied ... . \" ...Signi ca nt amount of work has been devoted recently to develop learning techniques that can be used to generate partial ( shallow ) analysis of natural language sentences rather than a full parse .", "label": "", "metadata": {}, "score": "48.9919"}
{"text": "5- 1 illustrates a method of creating the dependency triples database 360 .FIG .8 described later illustrates the search engine coupled to the triples database 360 .[ 0061 ] .As shown in FIG .5- 1 , each sentence from a text corpus is parsed by a dependency parser 355 and a set of dependency triples is generated .", "label": "", "metadata": {}, "score": "49.03473"}
{"text": "The corpora were parsed with Charniak and Lease parser [ 25 ] and the parsed results were transformed into the collapsed Stanford dependency scheme .As shown in Figure 3 , they contain information regarding entities such as proteins / genes / RNA / chemicals , interaction pairs between entities , tokens , and syntactic dependencies between tokens in a unified format , which enable all 5 corpora to be easily integrated into a system .", "label": "", "metadata": {}, "score": "49.079876"}
{"text": "Working within a concrete task allows us to compare ... . by Marcia Mu\u00f1oz , Vasin Punyakanok , Dan Roth , Day Zimak - IN PROCEEDINGS OF EMNLP - WVLC&apos;99 .ASSOCIATION FOR COMPUTATIONAL LINGUISTICS , 1999 . \" ...A SNoW based learning approach to shallow parsing tasks is presented and studied experimentally .", "label": "", "metadata": {}, "score": "49.0815"}
{"text": "Thus , we properly classify the substructures that the directed shortest path encloses and distinctively incorporated them into kernels according to the types of dependency substructures .This point differs from other recent kernel approaches that address the PPI extraction [ 9 , 11 , 14 , 16 , 17 ] .", "label": "", "metadata": {}, "score": "49.146675"}
{"text": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics , interactive poster and demonstration sessions , Ann Arbor , MI , USA 2005 , 25 - 28 .Blaschke C , Andrade MA , Ouzonis C , Valencia A : Automatic extraction of biological information from scientific text : protein - protein interactions .", "label": "", "metadata": {}, "score": "49.185307"}
{"text": "The results are compared using automatically parsed third party protein - protein interaction ( PPI ) data as well as perfectly syntactic labeled PPI data .Background .Introduction .In recent years , biomedical research has been accelerated by technological advances in biomedical science and a surge of genomic data from the Human Genome Project and a huge amount of new information has been coming from the related research .", "label": "", "metadata": {}, "score": "49.186275"}
{"text": "For instance , by way of example , one set of context - free grammars of a larger plurality of context - free grammars for a software application or task concerning scheduling meetings or sending electronic mail may comprise : . etc . .", "label": "", "metadata": {}, "score": "49.217934"}
{"text": "In addition , some named entities are embedded in other named entities .Embedded ( nested ) named entities refer to the cases in which one entity contains another .In such cases , two entities share the same dependency structure but the interaction results should be different because one of them participates in an actual interaction .", "label": "", "metadata": {}, "score": "49.21803"}
{"text": "The training data are stored as - is , in efficient suttix - tree data structures .Generalization is performed on - line at recognition time by compar - ing subsequences of the new text to positive and negative evidence in the corIms .", "label": "", "metadata": {}, "score": "49.221443"}
{"text": "Crucially , a limitation of this assumption is that substantially more effort must be applied in crafting the ontology , since re - indexing large volumes of text becomes extraordinarily expensive as the text grows .The designers of a parameterized ontology must be certain that their coverage is adequate before making a decision to freeze the structure .", "label": "", "metadata": {}, "score": "49.243725"}
{"text": "In this work , a genic relation pair for kernel functions is represented by the shortest dependency path between two NEs on the syntactic graph .Thus , the proposed kernels compute structural similarities in various ways according to the substructures that two dependency paths contain .", "label": "", "metadata": {}, "score": "49.316692"}
{"text": "Proceedings of IJCNLP Jeju , Korea 2005 , 58 - 69 .Shawe - Taylor J , Cristianini N : Support Vector Machines and Other Kernel - based Methods .Volume Chapter 11 .Cambridge University Press ; 2000 .Harabagiu SM , Bejan CA , Morarescu P : Shallow Semantics for Relation Extraction .", "label": "", "metadata": {}, "score": "49.355396"}
{"text": "In this manner , the size of the task - independent corpus is reduced prior to parsing so that method 180 may execute more quickly .Appropriate context - free grammars can then be determined and included in the plurality of context - free grammars at step 182 .", "label": "", "metadata": {}, "score": "49.392723"}
{"text": "The phrases associated with these grammars would not normally be spoken in the selected application .Thus , the extent or size of the plurality of context - free grammars is less during speech recognition , corresponding to less required storage space in the computer 50 than was used for parsing the task - independent corpus .", "label": "", "metadata": {}, "score": "49.414127"}
{"text": "The sentence receiver is a software abstraction that may be realized through any number of techniques .The parser 230 takes a sequence of instances from an ontology , in the form of a sentence , and converts them into a collection of parse trees .", "label": "", "metadata": {}, "score": "49.41705"}
{"text": "The results illustrate that the SVM classifiers can exploit the more abstract information of underlying dependency relations , to generalise beyond the surface information of token strings and distances .Variation in performance by feature set , syntactic features .The first column shows the cumulative + event system from Table 4 .", "label": "", "metadata": {}, "score": "49.449646"}
{"text": "There are several techniques available for deciding which sense is most appropriate given the context , and several different measures for what definition of \" context \" is most appropriate itself .One technique that we have experimented with is a naive Bayesian classifier ( following Gale et al .", "label": "", "metadata": {}, "score": "49.46611"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format comprising : . a sentence lexer for converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and .", "label": "", "metadata": {}, "score": "49.46674"}
{"text": "Columbus , USA 2008 , 1 - 9 .Aubin S : Challenge LLL Syntactic Analysis Guidelines .Technical reports , Universit\u00e9 Paris Nord 2005 .Miwa M , S\u00e6tre R , Miyao Y , Ohta T , Tsujii J : Protein - protein interaction extraction by leveraging multiple kernels and parsers .", "label": "", "metadata": {}, "score": "49.46876"}
{"text": "The parser of the Stuckey system is only suitable for grammar - checking applications .U.S. Pat .No .5,960,384 to Brash discloses a parsing method and apparatus for symbolic expressions of thought such as English - language sentences .The parser of the Brash system assumes a strict compositional semantics , where a sentence 's interpretation is the sum of the lexical meanings of nearby constituents .", "label": "", "metadata": {}, "score": "49.52971"}
{"text": "The dependency kernel directly computed the structural similarity between two graphs by counting common subgraphs .However , our previous dependency kernel rigorously focused on v - walk , so the direct dependencies between pairs of nodes and e - walk style structural information was excluded .", "label": "", "metadata": {}, "score": "49.590057"}
{"text": "One major approach to this issue is to adopt specific types of matching rules or patterns as the core relation discovery operation .The patterns are mainly represented in the form of sequences of words , parts - of - speech ( POS ) , or syntactic constituents [ 5 , 6 ] .", "label": "", "metadata": {}, "score": "49.601288"}
{"text": "After pre - processing , mentions of entities within the text are annotated .In the experiments reported , unless otherwise stated , we assume perfect entity recognition , as given by the entities in the human annotated gold standard described above .", "label": "", "metadata": {}, "score": "49.625336"}
{"text": "Results and discussion .Train and test data .We performed experiments on extracting gene and protein interactions from two different data sets , automatically parsed and perfectly parsed data sets .First of all , we used the LLL 05 shared task data for individual evaluation of the kernels that we proposed in this work .", "label": "", "metadata": {}, "score": "49.704605"}
{"text": "They participated fully in the conceptual design of the CLEF IE approach and system , and of the reported experimental work , and contributed to the writing of the manuscript .YG implemented and evaluated the system augmentations for using syntactic features , and drafted the relevant manuscript sections .", "label": "", "metadata": {}, "score": "49.707504"}
{"text": "Similarly , for information retrieval purposes , an embodiment of the ontological parser optimized for queries may make use of all these filters , but add a pseudo - predicate filter and a pseudo - concept filter .The stop word filter removes stop words from sentences .", "label": "", "metadata": {}, "score": "49.7554"}
{"text": "Task - dependent corpora , on the other hand , are typically not available .These corpora must be laboriously compiled , and even then , may not be very complete .A broad aspect of the invention includes a method for creating a task or domain dependent unified language model for a selected application from a task - independent corpus .", "label": "", "metadata": {}, "score": "49.763298"}
{"text": "The unified language model has the potential of overcoming the weaknesses of both the word N - gram & CFG language models .However , there is no clear way to leverage domain - independent training corpus or domain - independent language models , including the unified language models , for domain specific applications .", "label": "", "metadata": {}, "score": "49.77568"}
{"text": "In doing that , we compare two ways of modeling the problem of learning to recognize patterns and suggest that shallow parsing patterns are bet- ter learned using open / close predictors than using inside / outside predictors . ... to full - sentence parsers .", "label": "", "metadata": {}, "score": "49.778976"}
{"text": "The lexicalized dependency path string consists of words and their dependency relations .We also consider the syntactic dependency path string , which consists of POS and their dependency relations , incorporating direction and predicate information .Likewise , a POS dependency list contains pairs of POS and the syntactic relations between the POS and their direct child nodes ' POS .", "label": "", "metadata": {}, "score": "49.873146"}
{"text": "The identified text of the task - independent corpus is more relevant to the selected task or application ; therefore , a language model derived from the identified text may be more specific than a language model based on the complete task - independent corpus .", "label": "", "metadata": {}, "score": "49.887"}
{"text": "In the sentence , the system detected all pairs as interactive pairs , but some pairs should have been filtered out .Our negation processing method could not cover the context of \" but not with \" .Figure 7c shows the interactions that are not detected with information on the shortest path alone .", "label": "", "metadata": {}, "score": "49.97258"}
{"text": "Often numerous passes through the input sentence(s ) are required to fully parse the input , thereby adding to the time required to parse the input .Often the previous techniques do not have very robust feature checking capabilities .In particular , the techniques do not check for both syntactic and semantic compatibility .", "label": "", "metadata": {}, "score": "50.054554"}
{"text": "BMC Bioinformatics 2008 , 9 ( Suppl 3 ) : S6 .PubMed View Article .Miyao Y , Sagae K , S\u00e6tre R , Matsuzaki T , Tsujii J : Evaluating Contributions of Natural Language Parsers to Protein - protein Interaction Extraction .", "label": "", "metadata": {}, "score": "50.17441"}
{"text": "Notable is that the average precision of our system was higher than that in the other PPI extraction systems with a similar setting ( i.e. the best F - value ) .The average recalls , precisions and F - scores of the systems shown in Table 8 were computed with respect to all the 5 PPI corpora .", "label": "", "metadata": {}, "score": "50.180206"}
{"text": "This is a powerful resource that can give us much more information about a text than simple search engines currently allow .Conclusion .In this a dynamic lexicon fills a gap left by traditional reference works .By creating a lexicon directly from a corpus of texts and then situating it within that corpus itself , we can let the two interact in ways that traditional lexica can not .", "label": "", "metadata": {}, "score": "50.221436"}
{"text": "The former gives features from a window around each argument .The latter two provide more positional information .Do these two provide enough information on their own , without the windowed features ?To test this , we removed the tokN features from the full cumulative feature set , corresponding to column + event of Table 4 .", "label": "", "metadata": {}, "score": "50.228004"}
{"text": "Other functions can also be used .For example , other exponential length functions can be used .Furthermore , in other embodiments , the length factor can be chosen such that longer confirming sentences are ranked higher , if doing so was deemed advantageous .", "label": "", "metadata": {}, "score": "50.28677"}
{"text": "The above data structure naturally lends itself to one particular algorithm for comparing the identity or subsumption of ontological features .The algorithm relies on the implementation of the tree by associating with each node in the tree an integer value that represents the position of that node within the hierarchical structure .", "label": "", "metadata": {}, "score": "50.291283"}
{"text": "Each line is then parsed , and various output is produced ( the actual output depends on the various options that are set ) .For those with less experience with Unix , this form allows you to parse larger collections of sentences using input redirection : .", "label": "", "metadata": {}, "score": "50.31361"}
{"text": "We used the dependency parsed corpora by [ 18 ] for dependency information .Consequently , the proposed kernel showed a bit low recall as compared to its precision on the automatic parsed datasets .In particular , recall rates were much lower over the AIMed and BioInfer .", "label": "", "metadata": {}, "score": "50.37431"}
{"text": "FIG .5 illustrates a first method 160 for creating or building a language model .The method 160 includes a step 162 for obtaining a plurality of context - free grammars comprising non - terminal tokens representing semantic or syntactic concepts .", "label": "", "metadata": {}, "score": "50.488335"}
{"text": "The feature set dep consists of 16 features derived from the parse , which are only computed when the entities appear in the same sentence ( and otherwise take value null ) .The features encode characteristics of the dependency path connecting the paired entities , of the immediate left context in the dependency analysis of the leftmost entity , and of the corresponding right context of the rightmost entity .", "label": "", "metadata": {}, "score": "50.509293"}
{"text": "BMC Bioinformatics 2008 ., 9 ( 207 ) : .Bunescu R , Ge R , Kate R , Marcotte E , Mooney R , Ramani A , Wong Y : Comparative experiments on learning information extractors for proteins and their interactions .", "label": "", "metadata": {}, "score": "50.528954"}
{"text": "As discussed above , the task - independent corpus is a compilation of sentences , phrases , etc . that is not directed at any one particular application , but rather , generally shows , through a wide variety of examples , how words are ordered in a language .", "label": "", "metadata": {}, "score": "50.582863"}
{"text": "Query translation module or component 715 uses , for example , the query translation method described above with reference to FIG .7 and Equations 10 - 14 .[0114 ] .In embodiments in which the user is writing in English , the parser is an English parser such as NLPWin developed by Microsoft Research Redmond , though other known parsers can be used as well .", "label": "", "metadata": {}, "score": "50.607162"}
{"text": "It should be readily apparent that the ordering of elements of the code can be arbitrary , but must be used consistently in order to compare features .There are two ways to construct a parameterized ontology .The first method is to simply freeze an existing ontology , write a program to find the maximum tree depths and number of branches , and then write another program to recode the pointer information into array elements and depths .", "label": "", "metadata": {}, "score": "50.625687"}
{"text": "As long as grammatical roles can be identified , the present system and method can be easily adapted to any language .For example , certain case - marked languages , such as Japanese or German , can be parsed through a grammar which simply records the grammatical relationships encoded by particular markers , and the resulting output is still compatible with the parsing results achieved for other languages .", "label": "", "metadata": {}, "score": "50.62626"}
{"text": "Chapman W , Bridewell W , Hanbury P , Cooper G , Buchanan B : A simple algorithm for identifying negated findings and diseases in discharge summaries .J Biomed Inform 2001 , 34 ( 5 ) : 301 - 310 .", "label": "", "metadata": {}, "score": "50.76864"}
{"text": "Finally , the dependency kernel evaluates the similarity of two graphs by the composition of syntactic dependencies and lexical dependencies as follows : .The formula ( 6 ) enumerates all matching nodes of two graphs , d 1 and d 2 .", "label": "", "metadata": {}, "score": "50.80738"}
{"text": "Mihalcea and Edmonds 2004 Mihalcea , Rada and Philip Edmonds ( eds . )Proceedings of Senseval-3 : Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text ( 2004 ) .Miller 1995 Miller , George .", "label": "", "metadata": {}, "score": "50.863655"}
{"text": "PubMed View Article .Hakenberg J , Plake C , Leser U , Kirsch H , Rebholz - Schuhmann D : LLL05 Challenge : Genic Interaction Extraction - Identification of Language Patterns Based on Alignment and Finite State Automata .Proceedings of LLL .", "label": "", "metadata": {}, "score": "50.926506"}
{"text": "Relationship extraction .Our system is built using the GATE NLP toolkit , which is an architecture allowing language processing applications to be constructed as a pipeline of processing components [ 35 ] .Documents are passed down this pipeline , being analysed by each component in turn , with the results of this analysis being available to later components .", "label": "", "metadata": {}, "score": "51.005352"}
{"text": "The basic idea is to compare text documents by means of substrings they contain : the more substrings in common , the more similar they are .A string is defined as any finite sequence of symbols drawn from a finite alphabet and string kernels concern occurrences of subsequences or substrings in strings .", "label": "", "metadata": {}, "score": "51.064823"}
{"text": "Specifically , relation extraction emerged as a stand - alone task in MUC-7 [ 5 ] , i.e. requiring participants to extract instances of the employee_of , product_of , and location_of relations , holding between organisations and persons , artefacts and locations respectively , from newswire text .", "label": "", "metadata": {}, "score": "51.080853"}
{"text": "The experiments show that our approach described is capable of delivering high - precision results , while maintaining sufficient levels of recall .The high level of abstraction of the rules used by the system , which are considerably more powerful and versatile than finite - state approaches , allows speedy interactive development and validation .", "label": "", "metadata": {}, "score": "51.0858"}
{"text": "View Article PubMed .Zweigenbaum P , Bachimont B , Bouaud J , Charlet J , Boisvieux JF : A multi - lingual architecture for building a normalised conceptual representation from medical language .Proc Annu Symp Comput Appl Med Care 1995 , 357 - 361 .", "label": "", "metadata": {}, "score": "51.117245"}
{"text": "This is a format which is well suited for storage in a relational DB or for analysis with Data Mining algorithms .The dependency relations , together with intermediate results of the pipeline ( tokens , terms , chunks , sentences ) are stored in a Knowledge Base ( KB ) , which can then be queried by a separate module , described later in section \" Relation Mining \" .", "label": "", "metadata": {}, "score": "51.132088"}
{"text": "However , precisions of the proposed kernel were quite competitive in both clean dataset , and automated third - party datasets .As shown in the experiments , our approach worked better than other system under the same syntactic information environment or when accurate syntactic features were provided .", "label": "", "metadata": {}, "score": "51.153442"}
{"text": "They are syntactically marked because they can have several PP arguments .Biomedical relational nouns like overexpression or transcription are absent from the Penn Treebank or rare .We use an unsupervised approach based on [ 19 ] to learn relational nouns from Medline .", "label": "", "metadata": {}, "score": "51.161743"}
{"text": "Word phrases are generated from the plurality of context - free grammars .The context - free grammars are used for formulating an information retrieval query from at least one of the word phrases .The task - independent corpus is queried based on the query formulated and text in the task - independent corpus is identified based on the query .", "label": "", "metadata": {}, "score": "51.18815"}
{"text": "In this work , we fixed the order of spectrum as 3 and summed K s of lexical dependency path string and K s of syntactic dependency path string for the common substring counting .With this kernel , we can consider the substructure as shown in Figure 1f .", "label": "", "metadata": {}, "score": "51.20857"}
{"text": "To realize a precise translation , query understanding and translation selection are two big technical obstacles .[0008 ] .In light of these problems , or others not discussed , a system or method which aids non - native speakers in writing in English or other non - native languages by providing relevant confirming and/or hint sentences would be a significant improvement in the art .", "label": "", "metadata": {}, "score": "51.308678"}
{"text": "First and second N - gram language models are built from the word phrases and the task - independent corpus , respectively .The first N - gram language model and the second N - gram language model are combined to form a third N - gram language model .", "label": "", "metadata": {}, "score": "51.30993"}
{"text": "Consequently , a parser that handles both of these conditions is needed .The parser 230 must pursue all possible parse trees , in effect branching and pursuing more than one path at every ambiguity .The standard LALR parser is a finite state machine designed to build a parse tree from the set of grammar rules ( called productions ) one input symbol at a time .", "label": "", "metadata": {}, "score": "51.36626"}
{"text": "Knowledge bases contain instances of real data , which represent a location somewhere within the ontology .Validating the equivalence of an instance with a concept in an ontology entails comparing the features of an instance with the features of a concept .", "label": "", "metadata": {}, "score": "51.377445"}
{"text": "Research goal and differences from other recent similar work .The first three substructures mentioned above can be covered by general graph kernels [ 14 , 16 ] .However , none of related studies treated the fourth issue from a syntactic structure perspective .", "label": "", "metadata": {}, "score": "51.412277"}
{"text": "At step 208 , the task - independent corpus is queried based on the query formulated .The particular information retrieval technique used to generate and execute the query against the task - independent corpus is not critical to this feature of the present invention .", "label": "", "metadata": {}, "score": "51.421783"}
{"text": "It would certainly be possible to compute these dynamically , since any tree - search algorithm must keep track of which branches it traverses in trying to locate a particular node .However , as the search backtracks and corrects its path a fair number of adjustments and recalculations of the current node value would likely result .", "label": "", "metadata": {}, "score": "51.462246"}
{"text": "Proceedings of the Seventh Message Understanding Conference ( MUC-7 ) , Fairfax , VA , USA 1998 .Miller S , Crystal M , Fox H , Ramshaw L , Schwartz R , Stone R , Weischedel R : Algorithms that learn to extract information : BBN : Description of the SIFT system as used for MUC-7 .", "label": "", "metadata": {}, "score": "51.60392"}
{"text": "Nat .6.90 , etc .For a more comprehensive ( but not exhaustive ) comparison , I can consult the TLL .This is what we might consider a manual form of \" lemmatized searching .\" The search results are thus significantly diluted by a large number of false positives .", "label": "", "metadata": {}, "score": "51.67498"}
{"text": "This structure guarantees that an arbitrary number of nodes may be inserted into the list without losing track of the locations of existing nodes , as well as enabling the list to be searched from either the top or bottom .However , the great flexibility of tree data structures , which may encompass trees of arbitrary depth , also imposes a significant cost in computability .", "label": "", "metadata": {}, "score": "51.81978"}
{"text": "7 wherein the same reference numerals have been used to identify similar steps .However , method 220 can be used to create an N - gram language model having the non - terminal tokens of the context - free grammars .", "label": "", "metadata": {}, "score": "51.86157"}
{"text": "A second basis for evaluating system performance is comparison against baseline scores for the given task , which are scores that can be achieved using some quite simplistic method .Baseline scores can be viewed as providing a ( reasonable ) lower bound for performance , and the improvement over the baseline is a measure of the benefit achieved by using a more complex approach .", "label": "", "metadata": {}, "score": "51.894"}
{"text": "xml_format_frame .Boolean flag that indicates whether the system should produce verbose xml output ( containing various detailed lexical features ) .Examples with end_hook . xml .Suppose you want to save the dependency structure of the best parse of each sentence as xml .", "label": "", "metadata": {}, "score": "51.90946"}
{"text": "Automatic parsing generally requires the presence of a treebank - a large collection of manually annotated sentences - and a treebank 's size directly correlates with parsing accuracy : the larger the treebank , the better the automatic analysis .We are currently in the process of creating a treebank for Latin , and have just begun work on a one - million - word treebank of Ancient Greek .", "label": "", "metadata": {}, "score": "52.033676"}
{"text": "It should simply be noted that the language model created from the identified text according to the present technique works better with information retrieval techniques that identify more relevant text of the task - independent corpus .The text identified in the task - independent corpus based on the query is indicated at step 210 .", "label": "", "metadata": {}, "score": "52.04244"}
{"text": "The ontological parser has two major functional elements , a sentence lexer and a parser .The sentence lexer takes a sentence and converts it into a sequence of ontological entities that are tagged with part - of - speech information .", "label": "", "metadata": {}, "score": "52.05397"}
{"text": "In the predicate representation scheme of the present invention , there are only a few distinct frames for predicate structures , as many as needed to cover the different numbers of arguments taken by different verbs .Predicates may be enhanced with selectional restriction information , which can be coded automatically for entire semantic classes of words , rather than on an individual basis , because of the ontological scheme .", "label": "", "metadata": {}, "score": "52.089222"}
{"text": "Typical output then looks like : . syntactic structure .Perhaps your interest lies in the syntactic structure assigned by Alpino .The following writes out the syntactic structure for each parse that Alpino finds : .Each parse is written as a bracketed string , where each opening bracket is followed by the category ( preceded by the ampersand ) .", "label": "", "metadata": {}, "score": "52.13581"}
{"text": "Here , we first evaluate the effectiveness of different dependency subpaths and revise the dependency kernel so as to overcome the problems of complete subgraphs and equal counting for all subgraphs .In order to treat non - contiguous path substructures , we next introduce string kernels that compare two instances ( paths ) in terms of substrings they contain .", "label": "", "metadata": {}, "score": "52.152443"}
{"text": "SHK and JTY carried out PPI studies and suggested overall idea of this manuscript , and the system design .They performed the experiments and analyzed the results .JHY and SP participated in the system design and helped to draft the manuscript .", "label": "", "metadata": {}, "score": "52.156036"}
{"text": "In fact , nested named entities are commonly encountered in biomedical text .For example , they account for 16.7 % of all named entities of GENIA corpus .Currently , we allow all entities on nested entities .For instance , \" IFN - gamma \" and \" IFN - gamma SCI \" in Figure 5a are both considered .", "label": "", "metadata": {}, "score": "52.168774"}
{"text": "[ 0088 ] .Triples in triple database : accept\u02dcDobj\u02dcjob , .[ 0090 ] .Remaining Expanded Terms : accept\u02dcDobj\u02dcjob .[ 0091 ] .Confusion Method of Hint Sentence Retrieval .[ 0092 ] .Sometimes , a user may input a query using a mix of words from a first language and grammatical structure from a second language .", "label": "", "metadata": {}, "score": "52.19437"}
{"text": "Besides , there might be a significant time lag between the publication of a result and its introduction into such databases .Relevant articles have to be selected and accurately read by human experts looking for the core information .This process is usually referred to as curation of the article .", "label": "", "metadata": {}, "score": "52.19586"}
{"text": "To create a general purpose language model , such as an N - gram language model , a task - independent corpus of training data can be used and applied as discussed above to an N - gram algorithm .Task - independent corpora are readily available and can comprise compilations of magazines , newspapers , etc . , to name just a few .", "label": "", "metadata": {}, "score": "52.32215"}
{"text": "In the definition , if the set of common dependency child word pairs is empty but the two nodes have the same sub - categorization value , then the matching function returns 3.0 .If there is no child of n 1 or n 2 but two nodes are the same words , then C w ( n 1 , n 2 ) returns 1.0 .", "label": "", "metadata": {}, "score": "52.42884"}
{"text": "A N - gram model is built having the non - terminal tokens .A second plurality of context - free grammars is obtained for at least some of the same non - terminals representing the same semantic or syntactic concepts .", "label": "", "metadata": {}, "score": "52.45147"}
{"text": "J Biomed Inform 2003 , 36 ( 6 ) : 462 - 477 .View Article PubMed .Li Y , Bontcheva K , Cunningham H : SVM Based Learning System for Information Extraction .Deterministic and statistical methods in machine learning : first international workshop no .", "label": "", "metadata": {}, "score": "52.478615"}
{"text": "Kim J , Ohta T , Pyysalo S , Kano Y , Tsujii J : Overview of BioNLP'09 Shared Task on Event Extraction .Proceedings of the BioNLP Workshop , Boulder , USA 2009 , 1 - 9 .View Article .", "label": "", "metadata": {}, "score": "52.66635"}
{"text": "All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .Background of the Invention .Numerous techniques have been developed to process natural language input .", "label": "", "metadata": {}, "score": "52.678917"}
{"text": "l . .]P .s .u . t .i ._ . )Here represents the special end - of - sentence word .Three different methods are used to calculate the likelihood of a word given history inside a context - free grammar non - terminal .", "label": "", "metadata": {}, "score": "52.689064"}
{"text": "However , the e -walk style structural information is excluded in the previous dependency kernel , which is one of the reasons for the low performance .Therefore , such information should be considered as prior knowledge , and be regarded as more significant structures , among the subpaths .", "label": "", "metadata": {}, "score": "52.69612"}
{"text": "The computer applications used in biomedical research therefore need to support genotype - meets - phenotype informatics and the move towards translational biology .This will undoubtedly include linkage to the information held in individual medical records : in both its structured and unstructured ( textual ) portions .", "label": "", "metadata": {}, "score": "52.70221"}
{"text": "Other baselines were tried where only one of the latter two criteria , or neither , was used , but these showed much worse performance .The baseline scores were produced directly over the gold standard , i.e. with the set of possibly - related entity pairs being computed from the gold standard entities .", "label": "", "metadata": {}, "score": "52.736607"}
{"text": "A second aspect is a method for creating a task dependent unified language model for a selected application from a task - independent corpus .The task dependent unified language model includes embedded context - free grammar non - terminal tokens in a N - gram model .", "label": "", "metadata": {}, "score": "52.76762"}
{"text": "Thus , we evaluated each walk type 's contribution to the interaction extraction .For this , we conducted the experiment by restricting the walk kernel to operate with a single walk type .As shown in Table 3 , we could achieve a quite competing result only with e -walk information .", "label": "", "metadata": {}, "score": "52.8075"}
{"text": "Generally , another aspect of the present invention includes using the context - free grammars for the task - dependent application to form phrases , sentences or sentence fragments that can then be used as queries in an information retrieval system .", "label": "", "metadata": {}, "score": "52.841766"}
{"text": "Query Translation .[ 0101 ] .Search engine 315 also uses query translation to improve the retrieval of sentences as shown in FIG .7 .Given a user 's query ( shown at 655 ) , the key dependency triples are extracted with a robust parser as shown at 660 .", "label": "", "metadata": {}, "score": "52.849403"}
{"text": "If the most common class is null , then all the entity pairs will be treated as unrelated .More complicated baseline methods might use further criteria for subdividing the possible entity pairs into subsets for which most common classes are computed .", "label": "", "metadata": {}, "score": "52.857346"}
{"text": "Treebanks : Building and Using Parsed Corpora ( Edited by : Abeill\u00e9 A ) .Dordrecht : Kluwer 2003 , 299 - 316 .Lin D : Dependency - based Evaluation of MINIPAR .Workshop on the Evaluation of Parsing Systems , Granada , Spain 1998 .", "label": "", "metadata": {}, "score": "52.86268"}
{"text": "In this case , the word naa in the input will be treated in lexical lookup as if the word naar was given .Similarly , the lexical categories associated with gooooooeeeeed are those of the word goed .A further meta - label for lexical assignment is the @mwu label .", "label": "", "metadata": {}, "score": "52.9293"}
{"text": "Rinaldi F , Schneider G , Kaljurand K , Hess M , Andronis C , Konstanti O , Persidis A : Mining of Functional Relations between Genes and Proteins over Biomedical Scientific Literature using a Deep - Linguistic Approach .Journal of Artificial Intelligence in Medicine 2006 , in press .", "label": "", "metadata": {}, "score": "52.980747"}
{"text": "In particular , at step 182 , a plurality of context - free grammars is obtained .For example , a task - dependent application may require modeling the day of the week as a semantic concept in the N - gram model .", "label": "", "metadata": {}, "score": "53.045967"}
{"text": "a parse tree converter that receives the output of said parser component and converts said parse trees into predicates .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 19 , wherein said parser component further comprises : . parser filters operating on said predicates to remove erroneous predicates .", "label": "", "metadata": {}, "score": "53.094185"}
{"text": "Hakenberg J , Plake C , Leser U , Kirsch H , Rebholz - Schuhmann D : LLL'05 Challenge : Genie Interaction Extraction - Identification of Language Patterns Based on Alignment and Finite State Automata .Romacker M , Grandjean N , Parisot P , Kreim O , Cronenberger D , Vachon T , Peitsch M : The UltraLink : An Expert System for Contextual Hyperlinking in Knowledge Management .", "label": "", "metadata": {}, "score": "53.127213"}
{"text": "The proposed kernels were experimented on the LLL shared task data and 5 PPI corpora .We achieved good performances only with substructures represented on the shortest path between entities .Methods .In the modified version , we treat each type of substructures with different importance .", "label": "", "metadata": {}, "score": "53.29696"}
{"text": "1 is a block diagram of the sentence lexer according to the present invention ; .FIG .2 is a block diagram of the parser according to the present invention ; .FIG .3 is a diagram showing two complete parse trees produced according to the present invention ; .", "label": "", "metadata": {}, "score": "53.319622"}
{"text": "Lussier Y , Borlawsky T , Rappaport D , Liu Y , Friedman C : PhenoGO : assigning phenotypic context to gene ontology annotations with natural language processing .Pac Symp Biocomput 2006 , 64 - 75 .Hahn U , Romacker M , Schulz S : medsynDikate - a natural language system for the extraction of medical information from findings reports .", "label": "", "metadata": {}, "score": "53.33209"}
{"text": "View Article PubMed .Goadrich M , Oliphant L , Shavlik J : Learning to Extract Genic Interactions Using Gleaner .Proceedings of the ICML05 workshop : Learning Language in Logic ( LLL05 ) , Bonn , Germany 2005 , 62 - 68 .", "label": "", "metadata": {}, "score": "53.377533"}
{"text": "To enhance the retrieval precision , system 300 utilizes , alone or in combination , two extended indexing unit methods .First , to reflect the linguistic significance in constituting a sentence , different types of indexing units are assigned different weights .", "label": "", "metadata": {}, "score": "53.43009"}
{"text": "Beyond the lexicon .These technologies , borrowed from computational linguistics , will give us the grounding to create a new kind of lexicon , one that presents information about a word 's actual usage .This lexicon resembles its more traditional print counterparts in that it is a work designed to be browsed : one looks up an individual headword and then reads its lexical entry .", "label": "", "metadata": {}, "score": "53.482075"}
{"text": "The relationship extraction system .The relationship extraction system , as a GATE pipeline .Narratives are first pre - processed using standard GATE modules .Narratives were tokenised , sentences found with a regular expression - based sentence splitter , part - of - speech ( POS ) tagged , and morphological roots found for word tokens .", "label": "", "metadata": {}, "score": "53.515915"}
{"text": "There has been little work on relation extraction from clinical texts , presumably because of the difficulty in getting access to texts of this type .In the work carried out to date , extraction of relationships from clinical text is usually carried out as part of a full clinical IE system .", "label": "", "metadata": {}, "score": "53.520996"}
{"text": "Similarly , the filter would need to check twice to determine that \" car \" is in agreement with \" transportation , \" and once for \" vehicle . \"In contrast , a parameterized ontology assigns numbers to these concepts , such that each level is a larger number than the previous level .", "label": "", "metadata": {}, "score": "53.545776"}
{"text": "Although the annotators marked co - reference between mentions of the same entity , they were asked to ignore this for relationship annotation .Both the annotation tool and the annotation guidelines enforced the creation of relationships between mentions , not entities .", "label": "", "metadata": {}, "score": "53.588104"}
{"text": "For confirming sentence retrieval , retrieval of the sentences includes retrieval using the expanded indexing terms method described above .The retrieved sentences are then ranked using a ranking component or step 740 , for example using the ranking method described with reference to Equations 6 - 8 , and provided as examples at 745 This process realizes the confirming sentence retrieval .", "label": "", "metadata": {}, "score": "53.72892"}
{"text": "This option uses a set of options to improve the speed of the parser .In this mode , the parser only delivers the first ( best ) analysis .The part - of - speech pre - processor is applied .", "label": "", "metadata": {}, "score": "53.77108"}
{"text": "The first question is that if the user 's sentence is too long and complex , which part should be taken as the user 's focus ?The second question is that if a large number of sentences are matched , how can or should they be ranked precisely and efficiently in order to maximize their usefulness to the writer ?", "label": "", "metadata": {}, "score": "53.772995"}
{"text": "A key to intelligent design is leaving room for expansion .As long as the maximum depth of trees is not reached , adding additional levels is transparent .The trade - off in a parameterized ontology is selecting the size of a data structure so that it is no larger than it needs to be , but with adequate room for correcting mistakes or expanding coverage later on .", "label": "", "metadata": {}, "score": "53.79224"}
{"text": "Going too far along this route , however , can lead to more complicated methods that do not obviously deserve the title ' baseline ' , and can involve the work that is most naturally done by machine learning methods being laboriously reproduced as a manual feature engineering task .", "label": "", "metadata": {}, "score": "53.808178"}
{"text": "Those other concepts are the arguments of the predicate , and are generally nouns , because predicate relationships are usually between entities .As stated previously , the ontological parser has two major components , a sentence lexer 100 and a parser 200 .", "label": "", "metadata": {}, "score": "53.837666"}
{"text": "Their evaluation environment was not specifically described in the paper but they conducted the \" RelEx \" system on the same parsed corpora as that used in our system .Except HPRD50 domain , our kernel worked better than the system under the same syntactic information .", "label": "", "metadata": {}, "score": "53.846893"}
{"text": "However , each of the context - free grammars of the second plurality is more appropriate for the selected application .Referring back to the proper name example provided above , the second plurality of context - free grammars could include a CFG : .", "label": "", "metadata": {}, "score": "53.8861"}
{"text": "wm ) is represented as follows : .The .P .w . wm . )i . m .P .w .i .H .i . )N - gram model is obtained by applying an N - gram algorithm to a corpus ( a collection of phrases , sentences , sentence fragments , paragraphs , etc ) of textual training data .", "label": "", "metadata": {}, "score": "53.88662"}
{"text": "In this work , we also project the shortest path string like Figure 2c to a string itself and directly compare the strings .On the basis of our data representation , nodes and edges of a shortest path string correspond to alphabets of a string .", "label": "", "metadata": {}, "score": "53.92807"}
{"text": "New rules can make use of rules defined at lower levels , some of which remain stable across different applications .In order to simplify the process of evaluation and shorten the development cycle , we have created visualization tools ( based on XML , CSS and CGI scripts ) , that can display the results in a browser .", "label": "", "metadata": {}, "score": "53.99974"}
{"text": "The LALR parser is widely used and is better known as the approach used by parser generators such as yacc and bison .While the description is a preferred embodiment , it will be understood that any implementation of a context - free grammar within a similar architecture , including such variants as an LALR-2 parser ( which looks ahead by two words ) , are within the scope of the present invention .", "label": "", "metadata": {}, "score": "54.006916"}
{"text": "The CLEF IE system analyses the textual records to extract entities , events and the relationships between them .These relationships give information that is often not available in the structured record .Why was a drug given ?What were the results of a physical examination ?", "label": "", "metadata": {}, "score": "54.011818"}
{"text": "System best performance figures ( from Tables 4 and 5 ) , and comparison to baseline performance and to inter - annotator agreement scores .The relation models used in this evaluation were trained over texts containing gold standard entities .For relation extraction over test data containing imperfect recognised entities , however , it may be that better performance would result with models also trained over data containing imperfect entities , but this issue can only be answered empirically .", "label": "", "metadata": {}, "score": "54.026276"}
{"text": "Consider two strings , s and t to be compared that have the same length p , where the feature space is generated by all subsequences of length p derived from shortest path strings to be classified .Then , the overall inner product between them can be expressed as follows : .", "label": "", "metadata": {}, "score": "54.041634"}
{"text": "Thus , two subgraphs matched only when two root nodes and their direct child nodes were the same and the dependency relationships between them were the same .Such a match is referred to as a complete path match .It consists of a connected sub - graph with at least two words .", "label": "", "metadata": {}, "score": "54.05876"}
{"text": "0081 ] .In other words , similarity ranking algorithms Sim ( Di , Qj ) such as those shown in Equations 7 and 8 can be used instead .Sim .D .i .Q .j . ) k .", "label": "", "metadata": {}, "score": "54.103733"}
{"text": "The table also shows the counts of the training instances for each relation type in the different corpora .Overall , performance improves as training corpus size increases ( F 1 rising from 63 % to 69 % ) , as expected .", "label": "", "metadata": {}, "score": "54.14511"}
{"text": "The decision - making process occurs at intermediate parsing stages , and parse probabilities are considered before all parse paths have been pursued .Intermediate parse probability calculations have to be stored , and the system has to check for intermediate feature clashes .", "label": "", "metadata": {}, "score": "54.14807"}
{"text": "MedScan [ 28 ] makes use of a syntactic parser ( which typically yields a large number of analyses for each sentence ) and a semantic processor which transforms each syntactic tree into a corresponding semantic tree .Information extraction rules are then used to prune the large number of trees and extract from them the information of interest .", "label": "", "metadata": {}, "score": "54.289246"}
{"text": "Conclusion .We have shown that it is possible to extract important clinical relationships from text , using supervised statistical ML techniques , at levels of accuracy approaching those of human annotators .Background .Natural Language Processing ( NLP ) has been widely applied in biomedicine , particularly to improve access to the ever - burgeoning research literature .", "label": "", "metadata": {}, "score": "54.325233"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said sentence lexer comprises : . a document iterator that receives text input and outputs individual sentences ; . a lexer that receives said individual sentences from said document iterator and outputs individual words ; and . an ontology that receives said individual words from said lexer and returns ontological entities or words tagged with default assumptions about an ontological status of said individual words to said lexer .", "label": "", "metadata": {}, "score": "54.421623"}
{"text": "Fundel K , K\u00fcffner R , Zimmer R : RelEx - relation extraction using dependency parse trees .Bioinformatics 2007 , 23 ( 3 ) : 365 - 71 .View Article PubMed .Gaizauskas R , Demetriou G , Artymiuk P , Willett P : Protein Structures and Information Extraction from Biological Texts : The PASTA System .", "label": "", "metadata": {}, "score": "54.434578"}
{"text": "Confirming sentences are used to confirm or guide the user 's sentence structure , while the hint sentences are used to provide expanded expressions .Confirming sentences should be close in sentence structure or form to the user 's input query or intended input query in order to serve as a grammatical example .", "label": "", "metadata": {}, "score": "54.447906"}
{"text": "Proc of EACL 03 , Budapest , Hungary 2003 , 291 - 296 .Rinaldi F , Schneider G , Kaljurand K , Hess M , Andronis C , Persidis A , Konstanti O : Relation Mining over a Corpus of Scientific Literature .", "label": "", "metadata": {}, "score": "54.5599"}
{"text": "Both forms of language processing can benefit from a language model .One common technique of classifying is to use a formal grammar .The formal grammar defines the sequence of words that the application will allow .One particular type of grammar is known as a \" context - free grammar \" ( CFG ) , which allows a language to be specified based on language structure or semantically .", "label": "", "metadata": {}, "score": "54.65013"}
{"text": "And to alleviate the sparse data problem , it integrates general features with specific features .In the training stage , we select useful features after measuring information gain ratio of each features and assign higher weight to more informative feature by adopting the information gain ratio .", "label": "", "metadata": {}, "score": "54.6979"}
{"text": "The word phrases can include some or all of the various combinations and permutations defined by the associated context - free grammars where the non - terminal tokens include multiple words .At step 206 , at least one query is formulated for an information retrieval system using at least one of the generated word phrases .", "label": "", "metadata": {}, "score": "54.712254"}
{"text": "The uniform model does not capture the empirical word distribution underneath a context - free grammar non - terminal .A better alternative is to inherit existing domain - independent word tri - gram probabilities .These probabilities need to be appropriately normalized in the same probability space .", "label": "", "metadata": {}, "score": "54.744797"}
{"text": "Minnen G , Carroll J , Pearce D : Applied morphological processing of English .Natural Language Engineering 2001 , 7 ( 3 ) : 207 - 223 .View Article .Mikheev A : Automatic rule induction for unknown word guessing .", "label": "", "metadata": {}, "score": "54.77531"}
{"text": "The pseudo - concept filter operates in one embodiment , a query ontological parser .It removes concepts from queries , which are not likely to be the actual concept the user intends .Pseudo - concepts are largely nouns , and can be captured by a stop word list .", "label": "", "metadata": {}, "score": "54.79426"}
{"text": "A ] cases can be considered almost correct , as it easy ( by simply examining the highlighted arguments ) to detect the correct boundaries of the argument , should that be required .Unresolved pronouns [ P ] need a reader to deal with a substantially larger context ( e.g. \" this protein \" , referring to a protein mentioned in the previous sentence ) .", "label": "", "metadata": {}, "score": "54.79917"}
{"text": "The Brash system makes no provisions for the possibility that immediate relationships are not in fact the correct expression of sentence - level concepts , because it assumes that syntactic constituency is always defined by immediate relationships .The Brash system does not incorporate ontologies as the basis for its lexical resource , and therefore does not permit the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}, "score": "54.92232"}
{"text": "Size of training corpus .The provision of sufficient training data for supervised learning algorithms is a limitation on their use .We examined the effect of training corpus size on relationship extraction .We selected subsets consisting of 25 and 50 documents from the C77 corpus , itself comprising 77 narratives , to produce sub - corpora that we refer to as C25 and C50 , respectively .", "label": "", "metadata": {}, "score": "54.923485"}
{"text": "This operation may be accomplished in several ways : .If the ontology used by the parser only contains string labels for the nodes in a tree structure , the tree leading to the restriction must be established as a sub - tree of the selectional features of the argument .", "label": "", "metadata": {}, "score": "54.925663"}
{"text": "The system performance was improved by 5 % with the walk - weighted subsequence kernel over the original LLL data , as compared to the previous walk - based kernel ( Table 3 ) .According to the results by the LLL evaluation server , action - type interactions and negative interactions were recognized better in the walk - weighed subsequence kernel than in the previous walk - based kernel .", "label": "", "metadata": {}, "score": "54.9497"}
{"text": "However , there was still low since the kernel counts only the matches that preserve direct dependencies .Thus , we newly introduced string kernels , which could handle non - contiguous dependencies .From the spectrum kernel to the walk - weighted subsequence kernel , substructure types to be considered are incrementally augmented and the kernels gradually perform more comprehensive comparison of substructures enclosed by two shortest dependency strings .", "label": "", "metadata": {}, "score": "55.110847"}
{"text": "The problem for N - gram models is that a lot of data is needed and the model may not be specific enough for the desired application .Since a word - based N - gram model is limited to n - word dependency , it can not include longer - distance constraints in the language whereas CFG can .", "label": "", "metadata": {}, "score": "55.180115"}
{"text": "E1 .w . E2 .P .e . )P .w .C1 .w .E1 . )P .w .C2 .w .E2 . )Equations ._ .Therefore , given a Chinese triple , the English translation can be obtained with this statistical approach .", "label": "", "metadata": {}, "score": "55.187035"}
{"text": "We therefore must concentrate on two problems .First , how much can we automatically learn from a large textual collection using machine learning techniques that thrive on large corpora ?And second , how can the vast labor already invested in handcrafted lexica help those techniques to learn ?", "label": "", "metadata": {}, "score": "55.2458"}
{"text": "Cunningham H , Maynard D , Bontcheva K , Tablan V : GATE :A Framework and Graphical Development Environment for Robust NLP Tools and Applications .Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics , Philadelphia , PA , USA 2002 , 168 - 175 .", "label": "", "metadata": {}, "score": "55.267403"}
{"text": "Abstract .A method for creating a language model from a task - independent corpus is provided .In one embodiment , a task dependent unified language model is created .The unified language model includes a plurality of context - free grammars having non - terminals and a hybrid N - gram model having at least some of the same non - terminals embedded therein .", "label": "", "metadata": {}, "score": "55.348568"}
{"text": "Method 450 may create too much noise if the translation quality is poor .Therefore , the method 500 illustrated in FIG .6- 2 can be used instead .[ 0095 ] .A second method , which is referred to herein as \" the confusion method , \" expands word pairs in the users query using a confusion set database .", "label": "", "metadata": {}, "score": "55.35038"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said pseudo - concept filter removes concepts from queries .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "55.351936"}
{"text": "The ontological parser is designed to be modular , so that improvements and language - specific changes can be made to individual components without reengineering the other components .The components are discussed in detail below .The ontological parser has two major functional elements , a sentence lexer and a parser .", "label": "", "metadata": {}, "score": "55.386196"}
{"text": "The raw IAA score does not take this into account : if an annotator fails to find an entity , they will also be penalised for all relationships with that entity .We therefore give a Corrected IAA ( CIAA ) in which annotators are only compared on those relations for which they have both found the entities involved .", "label": "", "metadata": {}, "score": "55.455643"}
{"text": "As is also common in TF - IDF weighting schemes , the query Q , which is the user 's input sentence , is indexed in a similar way , and a vector is also obtained for a query as shown in Equation 3 : . [ 0053 ] .", "label": "", "metadata": {}, "score": "55.47576"}
{"text": "If an instantiation of a triple has already existed in the triple database 360 , the frequency of this triple increases .After all the sentences are parsed , a triples database including thousands of triples has been created .Since the parser may not be 100 % correct , some parsing mistakes can be introduced at the same time .", "label": "", "metadata": {}, "score": "55.493088"}
{"text": "Doddington G , Mitchell A , Przybocki M , Ramshaw L , Strassel S , Weischedel R : The Automatic Content Extraction ( ACE ) Program - Tasks , Data , & Evaluation .Proceedings of the 4th International Conference on Language Resources and Evaluation ( LREC 2004 ) , Lisbon , Portugal 2004 , 837 - 840 .", "label": "", "metadata": {}, "score": "55.540863"}
{"text": "Having described several embodiments of the concept - based indexing and search system in accordance with the present invention , it is believed that other modifications , variations and changes will be suggested to those skilled in the art in view of the description set forth above .", "label": "", "metadata": {}, "score": "55.55999"}
{"text": "Not all the attention has been on protein - protein interactions : [ 21 ] discusses such an approach for extracting causal relations between genetic phenomena and diseases and [ 22 ] discusses an extension of this approach to a broad range of relations in pharmacogenetics .", "label": "", "metadata": {}, "score": "55.615227"}
{"text": "In addition , the converted corpora have much more dependency types than LLL and some typed dependencies on the corpora are redundant .For example , there is no clear - cut distinction between the pronominal relation types , \" amod \" ( adjectival modifier ) , \" nn \" ( nominal modifier ) and \" dep \" ( dependent ) .", "label": "", "metadata": {}, "score": "55.629383"}
{"text": "Bioinformatics 2005 , 22 ( 6 ) : 645 - 650 .View Article PubMed .Daraselia N , Egorov S , Yazhuk A , Novichkova S , Yuryev A , Mazo I : Extracting Protein Function Information from MEDLINE Using a Full - Sentence Parser .", "label": "", "metadata": {}, "score": "55.638184"}
{"text": "For each of the ten testing folds , the corresponding nine folds of gold standard data were used to train both an entity recognition model and a relation recognition model , the latter again using the + event feature set .The relation results are then scored against the gold standard version of the test fold , with overall scores being macro - averaged across folds , as reported in Table 8 .", "label": "", "metadata": {}, "score": "55.697716"}
{"text": "Since the XML files of both the source text and its translations are marked up with the same reference points , \" chapter 1 , section 1 \" of Tacitus ' Annales is automatically aligned with its English translation ( step 1 ) .", "label": "", "metadata": {}, "score": "55.70052"}
{"text": "This representation is different from those in recently published other works that encode relations with the shortest path descriptions between entities [ 9 , 12 ] .It can be efficient and informative for learning .Data Representations .The shortest path representation between NE pairs and the shortest path string are visualized .", "label": "", "metadata": {}, "score": "55.714172"}
{"text": "The single dependency shortest path implies one that is composed of two entities and a direct dependency between them , such as \" NE_conj_and_NE \" or \" NE_conj_or_NE \" .In this case , we need further information other than the paths to retrieve correct interactions .", "label": "", "metadata": {}, "score": "55.761806"}
{"text": "0115 ] .To retrieve hint sentences , the terms list is expanded using an expansion component or step 750 .Term expansion is carried out using either of two resources , a thesaurus 755 ( as discussed above with reference to FIG .", "label": "", "metadata": {}, "score": "55.825134"}
{"text": "claim 28 , wherein the step of parsing comprises the step of looking ahead one word , scanning input from left - to - right , and constructing said parse tree .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "55.942196"}
{"text": "PubMed View Article .Bairoch A , Apweiler R , Wu CH : The Universal Protein Resource ( UniProt ) .Nucleic Acids Res 2005 , 33 : D154 - 9 .PubMed View Article .Ono T , Hishigaki H , Takagi T : Automated Extraction of Information on Protein - protein Interactions from the Biological Literature .", "label": "", "metadata": {}, "score": "56.008553"}
{"text": "Based predominantly on the guidelines used for the Prague Dependency Treebank , our annotation style is also influenced by the Latin grammar of Pinkster ( 1990 ) , and is founded on the principles of dependency grammar [ Mel'\u010duk 1988 ] .", "label": "", "metadata": {}, "score": "56.05056"}
{"text": "The example size of each corpus is shown in Table 1 .Meanwhile , in case of original LLL data , 464 NE pairs on the training set are used to train the kernels and 330 NE pairs on the test set are classified .", "label": "", "metadata": {}, "score": "56.1045"}
{"text": "Kim SH , Yoon JT , Yang JH : Kernel approaches for Genic Interaction Extraction .Bioinformatics 2008 , 24 ( 1 ) : 118 - 126 .PubMed View Article .Airola A , Pyysalo S , Bj\u00f6ne J , Pahikkala T , Ginter F , Salakoski T : A Graph Kernel for Protein - Protein Interaction Extraction .", "label": "", "metadata": {}, "score": "56.111786"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 6 , wherein a first digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .", "label": "", "metadata": {}, "score": "56.145676"}
{"text": "TABLE 1 .Lemma . scientist , preside , over , .workshop .[0067 ] .Using the extended indexing method of the present invention , for the same example sentence , the indexing terms illustrated in Table 2 are also employed in the database search by search engine 315 : .", "label": "", "metadata": {}, "score": "56.15087"}
{"text": "Extraction performances are evaluated by the F - score .As mentioned before , we can check the performance over the LLL test data through an external evaluation .On the contrary , separate test sets and external evaluation schemes are not provided to the other 4 corpora .", "label": "", "metadata": {}, "score": "56.235558"}
{"text": "Without benchmark test dataset and external evaluation , it is difficult to directly compare performances between approaches since there are substantial differences according to the data set used for training and testing , whether to include self interactions , preprocessing , or the data splitting strategy used in cross - validation .", "label": "", "metadata": {}, "score": "56.241955"}
{"text": "In the latter case , a subset of the lexical categories assigned by Alpino is allowed ( this subset can be empty ) .The @add_lex meta annotation can be used to tell the parser to treat a given word in the input with the lexical categories associated with another word .", "label": "", "metadata": {}, "score": "56.243973"}
{"text": "PubMed View Article .Moschitti A : Making Tree Kernels practical for Natural Language Learning .Proceedings of the Eleventh International Conference on European Association for Computational Linguistics ( EACL )Trento , Italy 2006 , 113 - 120 .Miwa M , Saetre R , Miyao Y , Tsujii J : A Rich Feature Vector for Protein - Protein Extraction from Multiple Corpora .", "label": "", "metadata": {}, "score": "56.26987"}
{"text": "0093 ] .A first method 450 of detecting the user 's intention is illustrated in FIG .6- 1 with an example .This is known as the translation method .Using this method , the user 's query is received as shown at 455 , and is translated from the first language ( with second language grammar , structure , collocation , etc . ) into the second language as shown at 460 .", "label": "", "metadata": {}, "score": "56.307186"}
{"text": "That is , words representing the interactions did not exist on the shortest path .Likewise , the interaction in Figure 7d should be filtered out .It requires a broad context such as \" interaction with 14 - 3 - 3 proteins \" .", "label": "", "metadata": {}, "score": "56.36006"}
{"text": "Step 190 is similar to Step 170 and includes obtaining a second set of context - free grammars suited for the selected application .Used during language processing such as speech recognition , the N - gram model having the non - terminal tokens and the plurality of context - free grammars associated with the task - dependent application is stored on a computer readable medium accessible by the speech recognition module 100 .", "label": "", "metadata": {}, "score": "56.452114"}
{"text": "D i in the collection of documents and the query sentence Q j can be calculated as the inner product of their vectors , as shown in Equation 4 : .Sim .D .i .Q .j . ) k .", "label": "", "metadata": {}, "score": "56.517887"}
{"text": "Therefore , probabilities of the terminals from the N - gram language model need to be appropriately normalized in the same probability space as the terminals present in the corresponding context - free grammar .i in W. The likelihood of W under the segmentation T is therefore .", "label": "", "metadata": {}, "score": "56.625027"}
{"text": "The first step is the identification of all biological relevant entities ( genes , proteins , diseases , etc . ) .The task is made particularly difficult by the high ambiguity of the entity names in this domain : in addition to a high degree of polysemy and synonymy , very common words can be used as names of entities [ 1 ] .", "label": "", "metadata": {}, "score": "56.63133"}
{"text": "Step 162 represents obtaining context - free grammars having non - terminal tokens to represent the semantic or syntactic concepts in the task - independent corpus , the non - terminal tokens having terminals present in the task - independent corpus .", "label": "", "metadata": {}, "score": "56.666557"}
{"text": "We performed the walk - weighted subsequence kernel over the converted LLL data to figure out how the use of automatic parsed data affects the performance of the kernel in comparison with the clean dataset .Finally , the walk - weighted subsequence kernel was evaluated over the 5 converted PPI corpora .", "label": "", "metadata": {}, "score": "56.70473"}
{"text": "[ 0066 ] .For instance , consider an input query sentence : \" The scientist presided over the workshop . \"Using a conventional IR indexing method , as in the baseline system defined above , only the lemmas are used as indexing units ( i.e. , the function words are removed as stop words ) .", "label": "", "metadata": {}, "score": "56.82521"}
{"text": "Figure 5 and 6 show some false negative interactions to be recognized .Types of False Positive Examples .Some false positive interactions to be filtered out are shown .The error types can be classified into a ) and d ) need more context , b ) negation , and c ) related words are not found on the shortest path .", "label": "", "metadata": {}, "score": "56.82835"}
{"text": "For example , in figure 2 it can be seen that each result bears the name of the rule that generated it ( last argument of the third column ) .This allows immediate detection of problems and their quick correction .", "label": "", "metadata": {}, "score": "56.858273"}
{"text": "After briefly introducing the GENIA corpus in section \" Corpus Analysis \" , we detail the processing steps that have been adopted in order to extract a rich set of linguistic and domain - specific information .Section \" Relation Mining \" shows in particular how the intermediate results of data analysis are used in the Relation Mining task .", "label": "", "metadata": {}, "score": "56.86792"}
{"text": "The full CLEF IE system , including automatic entity recognition , is able to process a document in sub - second time on a commodity workstation .We have used the system to extract 6 million relations from over half a million patient documents , for use in downstream CLEF applications .", "label": "", "metadata": {}, "score": "56.92198"}
{"text": "An N - gram model is then built at step 168 using an N - gram algorithm , the N - gram model having the non - terminal tokens embedded therein .At step 170 , a second plurality of context - free grammars is obtained suitable for the selected application .", "label": "", "metadata": {}, "score": "56.95781"}
{"text": "The interaction with researchers who work on pharmaceutical topics will clearly provide very valuable feedback .This will help us to better customize our rules and to evaluate the quality of our approach in an iterative manner .A long - term goal is the combination of the results into complex pathway networks , which can then be presented graphically to the users .", "label": "", "metadata": {}, "score": "56.959675"}
{"text": "Also , the search engine 114 accesses the language model 16 .The language model 16 is a unified language model or a word N - gram or a context - free grammar that is used in identifying the most likely word represented by the input speech .", "label": "", "metadata": {}, "score": "56.980957"}
{"text": "Sentences spanned .Table 2 shows that although intra - sentential relations account for a clear majority ( 77 % ) of relationships , 23 % are inter - sentential , with 10 % of all relationships holding between entities in adjacent sentences .", "label": "", "metadata": {}, "score": "57.03544"}
{"text": "A fourth aspect is a method for creating a language model for a selected application from a task - independent corpus .The method includes obtaining a plurality of context - free grammars comprising non - terminal tokens representing semantic or syntactic concepts of the selected application .", "label": "", "metadata": {}, "score": "57.061974"}
{"text": "Both systems are trainable and provide similar classification and attachment performance , see table 1 here .I 'd add the Stanford Parser , which does normal phrase structure parsing , but also will output dependency parses .Easy to use , open source , java , fast , etc . - ealdent Mar 9 ' 10 at 15:11 .", "label": "", "metadata": {}, "score": "57.080704"}
{"text": "If desired , the identified text can be extracted , copied or otherwise stored separate from the task - independent corpus as an aid in isolating relevant text and providing easier processing .FIG .9 is a block diagram illustrating another aspect of the present invention .", "label": "", "metadata": {}, "score": "57.11299"}
{"text": "Instead the system and method of the present invention incorporates a sophisticated syntactic analysis component , which allows facts about parts - of - speech to determine the correct syntactic analysis .Additionally , by incorporating ontologies as the basis for the lexical resource , the present invention permits the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}, "score": "57.22252"}
{"text": "Authors ' Affiliations .Department of Computer Science , Sogang University .Daumsoft Inc , Se - Ah Venture Tower .References .Boeckmann B , Bairoch A , Apweiler R : The SWISS - PROT protein knowledgebase and its supplement TrEMBL in 2003 .", "label": "", "metadata": {}, "score": "57.2453"}
{"text": "Table 2 summarizes the numbers of multiple relations , self cycle relations , operations needed for grouping NE words , and sentences including nested NEs with respect to 5 corpora .For example , the converted AIMed includes 104 multiple relations and 309 self - cycle dependencies to be removed .", "label": "", "metadata": {}, "score": "57.25833"}
{"text": "The method includes obtaining a plurality of context - free grammars comprising non - terminal tokens representing semantic or syntactic concepts of the selected application .A word language model is built from the corpus .Probabilities of terminals of at least some of the context - free grammars are normalized and assigned as a function of corresponding probabilities obtained for the same terminals from the word language model .", "label": "", "metadata": {}, "score": "57.324684"}
{"text": "For example in the case of a sentence such as \" The yellow sun \" there is a relationship between yellow and sun .THe machine learning techniques I have considered so far are Baynesian Statistics , Rough Sets , Fuzzy Logic , Hidden markov model and Artificial Neural Networks .", "label": "", "metadata": {}, "score": "57.410618"}
{"text": "Since , the two corpora include nested entities ( Table 2 ) and their distributions of negative and positive examples are very unbalanced ( Table 1 ) , the performances were comparatively low although the two are large sized corpora in contrast to other corpora .", "label": "", "metadata": {}, "score": "57.424046"}
{"text": "The indexing result for a document ( which contains only one sentence ) with a conventional IR indexing approach can be represented as a vector of weights as shown in Equation 1 : .[ 0050 ] .In an example embodiment , terms are English words .", "label": "", "metadata": {}, "score": "57.45298"}
{"text": "View Article PubMed .Rindflesch TC , Libbus B , Hristovski D , Aronson A , Kilicoglu H : Semantic relations asserting the etiology of genetic diseases .AMIA Annu Symp Proc 2003 , 554 - 558 .Ahlers CB , Fiszman M , Demner - Fushman D , Lang FM , Rindflesch TC : Extracting Semantic Predications from Medline Citations for Pharmacogenomics .", "label": "", "metadata": {}, "score": "57.506454"}
{"text": "Generally , it is assumed that users who need to write in English from time to time must have basic knowledge of English vocabulary and grammar .In other words , the users have some ability to discern good sentences from bad sentences , given a choice .", "label": "", "metadata": {}, "score": "57.51284"}
{"text": "Thus , we extend the kernel by allowing the possibility of partial matches besides e -walk with an extra factor ensuring that the partial matches have lower weights than complete path matches .In the extended dependency kernel , partial matches such as single word / POS matches and node - edge or edge - node matches are counted , as well as v -walks .", "label": "", "metadata": {}, "score": "57.566284"}
{"text": "Confirming sentences should be close in sentence structure or form to the user 's input query or intended input query .Given a limited example base , it is hard to retrieve totally similar sentences , so it is typically only possible to retrieve sentences containing some similar parts to the sentence being written ( the query sentence ) .", "label": "", "metadata": {}, "score": "57.58754"}
{"text": "storing the N - gram model and a second plurality of context - free grammars comprising at least some of the same non - terminals representing the same semantic or syntactic concepts in the memo , each of the context - free grammars of the second plurality being more appropriate for use in the selected application .", "label": "", "metadata": {}, "score": "57.610916"}
{"text": "Results .We have designed and implemented an ML - based system for relation extraction , using support vector machines , and trained and tested it on a corpus of oncology narratives hand - annotated with clinically important relationships .Over a class of seven relation types , the system achieves an average F1 score of 72 % , only slightly behind an indicative measure of human inter annotator agreement on the same task .", "label": "", "metadata": {}, "score": "57.63803"}
{"text": "SVMs have been used for relation extraction , but not extensively in biomedical applications ( though see [ 27 ] ) ; examples include [ 28 - 30 ] .We use SVMs due to their generally high performance at classification tasks , as it is in these terms that we have recast relation extraction .", "label": "", "metadata": {}, "score": "57.646683"}
{"text": "This metric , known as F 1 , as also defined below .We used a standard ten - fold cross validation methodology in our experiments .Various tables given later report the results of these experiments , showing recognition scores for the different relation types and for relation recognition overall .", "label": "", "metadata": {}, "score": "57.702896"}
{"text": "If an instance holds such dependency structure with respect to the predicate of \" control \" , it is very likely that two NEs in the structure have a genic relation .The semantic relations among predicates and their modifiers are clearly helpful for relation extraction .", "label": "", "metadata": {}, "score": "57.731903"}
{"text": "Example 2 : identifiers .Often it is desirable to have identifiers which indicate the paragraph number and the sentence number in that paragraph .For this purpose , we need the two scripts ./add_key and ./number_sents .Each line is now prefixed with an identifier X - Y where X is the paragraph number and Y is the sentence number .", "label": "", "metadata": {}, "score": "57.735085"}
{"text": "SUMMARY OF THE INVENTION .The foregoing and other deficiencies are addressed by the present invention , which is directed to an ontology - based parser for natural language processing .More particularly , the present invention relates to a system that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}, "score": "57.770866"}
{"text": "The system and method of the present invention also provides a robust feature - checking system that accounts for semantic compatibility as well as syntactic compatibility .The ontology of the present invention converts all inflected words to their canonical forms .", "label": "", "metadata": {}, "score": "57.82743"}
{"text": "Currently , extra pre - processing such as tag fixing and sentence splitting used in other works [ 14 , 16 ] was not performed in this study .The numbers of multiple relations , self cycle relations , operations ( eliminate / join relations ) for grouping NE words , and sentences including nested NEs , which need a pre - processing , are summarized with respect to 5 corpora .", "label": "", "metadata": {}, "score": "57.88463"}
{"text": "7 is another example parse tree incorporating real words according to the present invention .DETAILED DESCRIPTION OF THE INVENTION .In the following detailed discussion of the present invention , numerous terms , specific to the subject matter of a system and method for concept - based searching , are used .", "label": "", "metadata": {}, "score": "57.90469"}
{"text": "In fact , most cases have no interactions except some cases that co - occur with binding , association , recombinant , or interaction contexts .In addition , we add the negation mark before a predicate on the path when a negation expression occurs around the predicate .", "label": "", "metadata": {}, "score": "57.963814"}
{"text": "For the relation learning , we basically adopt a kernel approach .Kernel means a similarity function that maps a pair of instances to their similarity score .Thus , objects of kernel methods are expressed by a similarity matrix .In general , a kernel can be easily computed using inner products between objects without explicit feature handling .", "label": "", "metadata": {}, "score": "58.098198"}
{"text": "View Article PubMed .Yakushiji A , Miyao Y , Tateisi Y , Tsujii J : Biomedical Information Extraction with Predicate - Argument Structure Patterns .Proceedings of the First International Symposium on Semantic Mining in Biomedicine 2005 , 60 - 69 .", "label": "", "metadata": {}, "score": "58.117683"}
{"text": "Head - Driven Statistical Models for Natural Language Parsing \" , Ph.D. thesis .Philadelphia : University of Pennsylvania , 1999 .Freund 1840 Freund , Wilhelm ( ed . )W\u00f6rterbuch der lateinischen Sprache : nach historisch - genetischen Principien , mit steter Ber\u00fccksichtigung der Grammatik , Synonymik und Alterthumskunde .", "label": "", "metadata": {}, "score": "58.11789"}
{"text": "The system of the present invention maintains arguments as variables during the parsing process , and automatically fills in long - distance dependencies as part of the parsing process .No post - parsing analysis is needed to obtain this benefit , and the parsing time is not impacted by the maintenance of these variables , thus resulting in faster parsing execution .", "label": "", "metadata": {}, "score": "58.124588"}
{"text": "The pipeline [ 6 ] performs a sequence of processing tasks , described below .In the case of GENIA , some of these steps ( e.g. tagging , terminology detection ) are not necessary - and are automatically skipped - because the relevant information is already provided in the Corpus .", "label": "", "metadata": {}, "score": "58.15776"}
{"text": "FIG .3 , for the input string ' ab . 'An example of a context - free grammar that would be used in implementing the parser is as follows : .The modified LALR parser generator , grammar , and modified LALR parsing engine discussed previously should generate a non - deterministic recursive parser .", "label": "", "metadata": {}, "score": "58.194466"}
{"text": "The approach used with embodiments of the invention is to provide appropriate sentences to the user , whenever and whatever he or she is writing .The scenario is very simple : Whenever a user writes a sentence , the system detects his or her intention , and provides some example sentences .", "label": "", "metadata": {}, "score": "58.21178"}
{"text": "Next , in order to compare the above result with ones on the data set made in an automatic way , we performed the same experiment over the converted LLL data using the walk - weighted subsequence kernel .For this , the kernel was trained on automatic - parsed LLL training data and then tested on automatic - parsed LLL test data .", "label": "", "metadata": {}, "score": "58.238495"}
{"text": "The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network .In a distributed computing environment , program modules may be located in both local and remote computer storage media including memory storage devices .", "label": "", "metadata": {}, "score": "58.25232"}
{"text": "Learning and evaluation method .Each kernel is combined with SVM .The LIBSVM 2.84 package [ 26 ] , which allows multi - class classifications and user - defined kernels , is used for SVM learning .In this study , we define our own kernels and set the C value as 1,000 for the best F - value .", "label": "", "metadata": {}, "score": "58.266663"}
{"text": "The similarity is recursively computed over their common dependency child word pairs in the set sc w ( n 1 , n 2 ) , starting from root nodes .As a result , we can calculate C w as follows : .", "label": "", "metadata": {}, "score": "58.289406"}
{"text": "5- 2 .The query expansion method provides alternative expressions for use in searching the sentence database 320 .[ 0084 ] .The expansion procedure is as follows : First , as illustrated at 405 , we expand the terms in the query using synonyms defined in a machine readable thesaurus , for example such as WordNet .", "label": "", "metadata": {}, "score": "58.29622"}
{"text": "Authors ' Affiliations .Department of Computer Science , University of Sheffield .References .Rector A , Rogers J , Taweel A , Ingram D , Kalra D , Milan J , Singleton P , Gaizauskas R , Hepple M , Scott D , Power R : CLEF - joining up healthcare with clinical and post - genomic research .", "label": "", "metadata": {}, "score": "58.31391"}
{"text": "this writes out : .Each line is a single dependency triple .The first field is the head word , the second field is the dependency name , the third field is the dependent word , and the fourth field is the sentence number .", "label": "", "metadata": {}, "score": "58.32128"}
{"text": "Bayesian classification is most commonly found in spam filtering .By counting each word and the class ( spam / not spam ) it appears in , we can assign it a probability that it falls into one class or the other .", "label": "", "metadata": {}, "score": "58.34015"}
{"text": "Different properties of two walks .In this work , we focus on different structural properties of v -walk and e -walk .The v -walk shows a labeled relationship from a head to its modifier .Thus , it is related to a direct dependency relationship between two words or POS .", "label": "", "metadata": {}, "score": "58.402428"}
{"text": "The term concept as used herein means an abstract formal representation of meaning , which corresponds to multiple generic or specific words in multiple languages .Concepts may represent the meanings of individual words or phrases , or the meanings of entire sentences .", "label": "", "metadata": {}, "score": "58.40901"}
{"text": "If the word exists within the ontology 140 , it is returned as an ontological entity ; if not , it is returned as a word tagged with default assumptions about its ontological status .In one embodiment , words are automatically assumed to be nouns ; however , the words may be other parts of speech .", "label": "", "metadata": {}, "score": "58.422436"}
{"text": "However , appropriate probabilities for each rule can only be determined by experimentation .In the initial version , probabilities will be assigned by linguistic intuition ; as iterations of the design progress , probabilities will be determined through experimentation .Since sentence probabilities are generally very small numbers , the parse probability filter should pass any parse tree with a probability of at least 30 % of the highest probability parse .", "label": "", "metadata": {}, "score": "58.42391"}
{"text": "Roberts A , Gaizauskas R , Hepple M , Guo Y : Combining terminology resources and statistical methods for entity recognition : an evaluation .Proceedings of the Sixth International Conference on Language Resources and Evaluation , LREC 2008 , Marrakech , Morocco 2008 .", "label": "", "metadata": {}, "score": "58.435677"}
{"text": "Approval to use this corpus for research purposes within CLEF was obtained from the Thames Valley Multi - centre Research Ethics Committee ( MREC ) .The corpus comprises 77 narratives , which were carefully selected and annotated according to a best practice methodology , as described in [ 34 ] .", "label": "", "metadata": {}, "score": "58.57312"}
{"text": "Overall , there is a 1 % improvement in F 1 .It appears that the bulk of performance is attained through entity type and distance features , with some contribution from positional surface string information .Performance is between 1 % and 9 % lower than CIAA for each relationship , with a best overall F 1 of 70 % , compared to a CIAA of 75 % .", "label": "", "metadata": {}, "score": "58.57891"}
{"text": "The hint sentences can be ranked at 740 in the same manner as the confirming sentences .In an interactive search mode , if the retrieved sentences are not satisfactory , the user can highlight the words he or she wishes to focus on , and searches again .", "label": "", "metadata": {}, "score": "58.599503"}
{"text": "These probability values collectively form the N - gram language model .Some aspects of the invention described below can be applied to building a standard statistical N - gram model .As is also well known in the art , a language model can also comprise a context - free grammar .", "label": "", "metadata": {}, "score": "58.62095"}
{"text": "Because \" amino_acid \" is a supertype of \" protein_molecule \" , according to the given ontology ( although this might appear incorrect to a domain expert ) , the results of the latter include ( and expand ) the results of the former .", "label": "", "metadata": {}, "score": "58.66534"}
{"text": "This substructure is called non - contiguous path .Finally , the kernel counted all common subgraphs equally regardless of their importance , even though some subgraphs have more useful properties for learning than others .The kernel made no distinction between the significances of structures .", "label": "", "metadata": {}, "score": "58.6929"}
{"text": "For example , a bi - gram ( or 2-gram ) language model considers the previous word as having an influence on the next word .where w is a word of interest : .Also , the probability of a word sequence is determined based on the multiplication of the probability of each word given its history .", "label": "", "metadata": {}, "score": "58.695557"}
{"text": "claim 23 , wherein said parse probability filter vetoes parse trees that fall below a minimum probability for semantic interpretation .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said system is modular to permit the use of any part - of - speech - tagged ontology .", "label": "", "metadata": {}, "score": "58.749573"}
{"text": "The parser is a tool for analyzing syntactic relationships between entities .Referring to .FIG .1 , the sentence lexer 100 is shown .Document iterator 120 receives documents or text input 110 , and outputs individual sentences to the lexer 130 .", "label": "", "metadata": {}, "score": "58.800457"}
{"text": "etc .This type of grammar does not require an in - depth knowledge of formal sentence structure or linguistics , but rather , a knowledge of what words , phrases , sentences or sentence fragments are used in a particular application or task .", "label": "", "metadata": {}, "score": "58.85371"}
{"text": "Overall , however , the baseline method performs much worse than the best system , giving a macro - averaged F 1 of 41 % against a best system F 1 of 72 % and a CIAA of 75 % .The simplest baseline , using only the types of the two entities , was found to score 0 % for all measures ( which followed from it having a null default for all cases ) .", "label": "", "metadata": {}, "score": "58.9325"}
{"text": "In a labeled dependency grammar , we can express a verb 's subcategorization as a combination of syntactic roles ( e.g. , OBJ OBJ ) .A predicate 's selectional preference specifies the type of argument it generally appears with .The verb to eat , for example , typically requires its object to be a thing that can be eaten and its subject to have animacy , unless used metaphorically .", "label": "", "metadata": {}, "score": "58.939426"}
{"text": "Error analyses .In this section , we discuss the types of interactions that remain to be recognized and filtered out and how to improve the performance of the proposed walk - weighted subsequence kernel by analyzing errors .For convenience , we assumed the interactions to be undirected .", "label": "", "metadata": {}, "score": "58.959892"}
{"text": "Still another object of the present invention is to provide a system and method for parsing natural language input that transforms data using a syntactic parser and ontology , where the ontology is used as a lexical resource .Yet another object of the present invention is to provide a system and method for parsing natural language input that provides ontological entities as output that are predicate - argument structures .", "label": "", "metadata": {}, "score": "58.98289"}
{"text": "This assumption is that the number of branches in an ontological hierarchy , and their depth , can be determined by designing it to fixed parameters at the time of creation , and by selecting maximum values for the branches and the depths .", "label": "", "metadata": {}, "score": "59.003647"}
{"text": "pass on identifier of words .Warning : bracketed input is not supported in case Alpino tokenizes the input sentences on the fly .A large part of the computational time is spent on finding the correct constituents .The ability to indicate syntactic structure is a nice feature especially for attaching modifiers at the correct location , enumerations and complex nestings .", "label": "", "metadata": {}, "score": "59.097576"}
{"text": "In general , a direct computation of all subsequences becomes inefficient even if we use a small value of p .For an efficient computation , the dynamic programming algorithm by [ 30 ] was used .In this paper , we will not explain the details about the efficient recursive kernel computation method .", "label": "", "metadata": {}, "score": "59.13711"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees that fall below a minimum probability for semantic interpretation .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "59.160088"}
{"text": "Then , the feature coordination function \u03d5 u ( s ) is used to denote the count of how many times substring u occurs as a contiguous and non - substring in the input string s. I p is the index sequences set of length p .", "label": "", "metadata": {}, "score": "59.173138"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said noun filter groups proper nouns into single lexical nouns .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "59.21903"}
{"text": "Mediae Latinitatis Lexicon Minus .Leiden : Brill , 1976 .Nivre et al .2006 Nivre , Joakim , Johan Hall , and Jens Nilsson . \"MaltParser : A Data - Driven Parser - Generator for Dependency Parsing \" , Proceedings of the Fifth International Conference on Language Resources and Evaluation ( 2006 ) .", "label": "", "metadata": {}, "score": "59.23293"}
{"text": "Ik wil [ @skip ? ? ? ] naar huis Ten opzichte [ @skip echter ] van deze bezwaren willen wij .... .A related trick that is useful in particular cases , is to add a word to the sentence in order to ensure that the parse can succeed , but instruct Alpino that this word should not be part of the resulting dependency structures .", "label": "", "metadata": {}, "score": "59.300316"}
{"text": "All kernels were trained and tested over clean data set ( LLL training and test ) and accessed by LLL external evaluation server .As indicated in Table 3 , even the spectrum kernel , which is the simplest string kernel , showed a better result than the dependency kernel .", "label": "", "metadata": {}, "score": "59.31961"}
{"text": "The significance values can take into account the types of substructures and we experimentally set the significance values for the best F - value .As a result , this kernel showed the best performance ( F - score 82.1 ) for the extraction of genic relation on the LLL data .", "label": "", "metadata": {}, "score": "59.422318"}
{"text": "In this sample embodiment , this predicate is then passed through the parser filters , where it successfully passes the parse probability and selectional feature compatibility tests .In the foregoing example , \" have \" is a verb unlikely to have any selectional restrictions on arguments .", "label": "", "metadata": {}, "score": "59.48956"}
{"text": "Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics ( EACL06 ) , Trento , Italy 2006 , 401 - 408 .Zelenko D , Aone C , Richardella A : Kernel Methods for Relation Extraction .", "label": "", "metadata": {}, "score": "59.494705"}
{"text": "This technology is called \" intelligent recommendation of example sentences \" .[ 0041 ] .[ 0041]FIG .3 is the block diagram illustrating a system and method of the present invention which aid a user in constructing and polishing English sentences .", "label": "", "metadata": {}, "score": "59.523907"}
{"text": "The difference is simply a digit - by - digit comparison that starts with the most significant bit and continues until the first decimal digit difference is located .Importantly , though , the differences due to inheritance along incompatible sub - trees do not correspond to elements of natural - language meaning .", "label": "", "metadata": {}, "score": "59.611183"}
{"text": "claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a negative number indicates feature incompatibility .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "59.629242"}
{"text": "In the embodiment illustrated in .FIG .9 , block 240 represents the context - free grammars obtained ( for example , authored by the developer ) for the selected task or application .The context - free grammars are used to generate synthetic data or word phrases 242 in a manner similar to step 204 of methods 200 and 220 .", "label": "", "metadata": {}, "score": "59.6542"}
{"text": "As mentioned in the Background section , the application developer should be provided with an efficient method in which an appropriate language model 16 can be created for the selected application .In some applications , a standard N - gram language model will work and any improvements in developing such a model will be valuable .", "label": "", "metadata": {}, "score": "59.755703"}
{"text": "A predicate structure is a data type that includes a predicate and multiple additional concepts ; as a grouping of concepts , it is itself a concept .An ontology is a hierarchically organized complex data structure that provides a context for the lexical meaning of concepts .", "label": "", "metadata": {}, "score": "59.78208"}
{"text": "During the sentence lexer stage , words are labeled with information from the ontology , including these numerical codes .The argument position for each predicate structure may be tagged with codes from any level of the ontology .The parser will only output predicate structures where the noun inherits at least those features specified by the code .", "label": "", "metadata": {}, "score": "59.79731"}
{"text": "For example , in an information retrieval application , it is capable of pulling out stopwords and unintended query words ( as in the pseudo - concept and pseudo - predicate filters ) .In the embodiment discussed above , the grammar violation checking of the system and method of the present invention filters both by the probability of a syntactically successful parse and the compatibility of the lexical semantics of words in the ontology .", "label": "", "metadata": {}, "score": "59.842987"}
{"text": "For example , another possible encoding of the ontology tree might involve a 40-digit decimal number .In such a case , 4 digits could be assigned to each node of the tree , implying that the tree could have up to 10 levels of depth .", "label": "", "metadata": {}, "score": "59.86931"}
{"text": "Essentially , the N - gram language model 142 ( also known as a hybrid N - gram model ) of the unified language model 140 includes an augmented vocabulary having words and at least some of the non - terminals .", "label": "", "metadata": {}, "score": "59.883957"}
{"text": "Generally , the word pairs will be in the same language , but can be annotated to a translation word if desired .[ 0096 ] .Referring first to FIG .6- 2 , shown is a method 500 of constructing a confusion set database 505 for use by search engine 315 in detecting the user 's intentions .", "label": "", "metadata": {}, "score": "59.972557"}
{"text": "Those were evaluated in terms of directed interactions .Consequently , the performance dropped to 68.5 , which represents a 13.6 % decrease in F - score , as compared to the use of perfectly parsed data .Our walk - weighted subsequence kernel was trained on automatic - parsed LLL training data and then tested on automatic - parsed LLL test data .", "label": "", "metadata": {}, "score": "60.018696"}
{"text": "However , since a majority of databases still rely on human curators , substantial manual efforts are required to cope with enormous collections on biomedical research and publications .Thus , the development of high - quality information extraction tools that allow scientists and curators to quickly access new discoveries is an important issue in bioinformatics .", "label": "", "metadata": {}, "score": "60.037483"}
{"text": "Since algorithm design and implementation are distinct and separable issues , an embodiment of a parameterized ontology 's data structures has not yet been discussed .The following is a suggested implementation .The proposed data structure includes an integer value , where each digit of the integer corresponds to a specific branch taken at the corresponding level in the tree .", "label": "", "metadata": {}, "score": "60.09072"}
{"text": "PubMed .Friedman C , Alderson P , Austin J , Cimino J , Johnson S : A General Natural - language Text Processor for Clinical Radiology .J Am Med Inform Assoc 1994 , 1 ( 2 ) : 161 - 174 .", "label": "", "metadata": {}, "score": "60.105587"}
{"text": "The A / D converter 104 converts the analog speech signal into a sequence of digital signals , which is provided to the feature extraction module 106 .In one embodiment , the feature extraction module 106 is a conventional array processor that performs spectral analysis on the digital signals and computes a magnitude value for each frequency band of a frequency spectrum .", "label": "", "metadata": {}, "score": "60.132187"}
{"text": "Bioinformatics 2003 , 19 ( 13 ) : 1699 - 1706 .View Article PubMed .Friedman C , Kra P , Krauthammer MH , Rzhetsky A : GENIES : a Natural - Language Processing System for the Extraction of Molecular Pathways from Journal Articles .", "label": "", "metadata": {}, "score": "60.13344"}
{"text": "The metrics do not say how hard relationship extraction is .We therefore also provide Inter Annotator Agreement ( IAA ) scores from the creation of the gold standard .The IAA measures the level of agreement between the two annotators who independently annotated each text to produce its double annotation .", "label": "", "metadata": {}, "score": "60.140614"}
{"text": "The method of .claim 1 , wherein combining the expanded terms to form the plurality of dependency triples further comprises combining the expanded terms to form all possible dependency triples from the expanded terms .The method of .claim 1 , wherein expanding the query by including synonyms of the terms to obtain expanded terms further comprises adding synonyms of at least some of the terms of the query .", "label": "", "metadata": {}, "score": "60.25326"}
{"text": "Alone however , this method suffers from the problem of noisy expansions .To avoid the problem of noisy expansions , method 400 used by search engine 315 implements additional steps 410 and 415 before searching the sentence database for hint sentences .", "label": "", "metadata": {}, "score": "60.26944"}
{"text": "Adverbs detail the meaning of the verbs they accompany , but do not change them .Since the meaning of the sentence remains the same , adverbs can be removed to simplify parsing .The pseudo - predicate filter operates in one embodiment , as a query ontological parser .", "label": "", "metadata": {}, "score": "60.337547"}
{"text": "Institute of Computational Linguistics , IFI , University of Zurich .Novartis Pharma AG .References .Jensen LJ , Saric J , Bork P : Literature mining for the biologist : from information retrieval to biological discovery .Nature Reviews Genetics 2006 , 7 : 119 - 129 .", "label": "", "metadata": {}, "score": "60.46669"}
{"text": "Additionally , the Computational Knowledge Management and Text Mining unit at Novartis supports a number of custom tailored text mining solutions for disease areas and pipelines .One of the core components is an annotator that we intend to apply for the entity recognition task .", "label": "", "metadata": {}, "score": "60.51367"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .", "label": "", "metadata": {}, "score": "60.636932"}
{"text": "claim 7 and having instructions further comprising : . building a second N - gram language model from the word phases from the plurality of context - free grammars ; and .combining the first - mentioned N - gram language model and the second N - gram language model to form a third N - gram language model .", "label": "", "metadata": {}, "score": "60.719604"}
{"text": "claim 38 , further comprising the step of representing said parse trees by modified hexadecimal numbers that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "60.73732"}
{"text": "claim 6 , wherein said parse trees is represented by modified hexadecimal digits that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format comprising the steps of : . converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and . converting said sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the natural language sentence and binds arguments into predicates .", "label": "", "metadata": {}, "score": "60.781776"}
{"text": "The equivalence rules expressed above allow the user to formulate powerful queries which capture all the defined variants of the given configuration .For example , the query below returns all the sentences containing a control relation , where A and B are instantiated respectively by the agent and the target of the relation : . applyRel(xrel(['control ' , A , B ] ) ) .", "label": "", "metadata": {}, "score": "60.84203"}
{"text": "Such bag- of - characters representation is the most widely used in natural language processing .However , the major shortcoming is the structural simplicity that all features represent only local information .In Equation ( 7 ) , K s ( s 1 , s 2 ) denotes the number of common p -substrings between two shortest path strings , s 1 and s 2 .", "label": "", "metadata": {}, "score": "60.843983"}
{"text": "We are currently setting up a framework for an intensive collaboration , which will allow us to apply the approach described in this paper to non - annotated corpora , using term recognition tools at Novartis .Since 2001 , Novartis has information extraction and text mining applications in place that are used by hundreds of associates [ 32 ] .", "label": "", "metadata": {}, "score": "60.858917"}
{"text": "It was compared with the result over clean LLL training / test set .The walk - weighted subsequence kernel was also evaluated over the other 4 converted PPI corpora as shown in Table 5 .It achieved an average F - score of about 67.46 .", "label": "", "metadata": {}, "score": "60.891052"}
{"text": "As the set of rules is gradually enriched , so are the possible lexico - syntactic variants that can be captured .For example in figure 2 , the last of the examples shown is a case of a complex rule designed to capture the pattern \" A triggers the H of B \" , where H represent a nominalized verb ( activation , regulation , etc . ) .", "label": "", "metadata": {}, "score": "60.892403"}
{"text": "In some embodiments , the search engine 315 of the present invention utilizes a dependency triples database 360 to expand the search terms of the main dependency triples extracted from the query .Thus , the dependency triples database can be included in , or coupled to , either of query processing component 310 and search engine 315 .", "label": "", "metadata": {}, "score": "60.905167"}
{"text": "For the event feature set , entities were divided into events ( Investigation and Intervention ) and non - events ( all others ) .Features record whether an entity pair consists of two events , two non - events , or one of each , and whether there are any intervening events or non - events .", "label": "", "metadata": {}, "score": "60.941147"}
{"text": "Therefore , the linguistic weights can be assigned to retrieve confirming example sentences having the particular type of term , sentence component or POS relation deemed to be most important for a typical user .[ 0080 ] .The second feature added to the similarity function is the sentence length factor or function \u0192(L i ) .", "label": "", "metadata": {}, "score": "60.95024"}
{"text": "Table 5 reiterates the + event column of Table 4 , corresponding to the accumulation of all non - syntactic feature sets , and gives results for augmenting this set with the syntactic features of dep and then also syndist .The syntactic features contribute mainly to finding the has_indication and negation_modifier relations , with an improved F 1 of around 4 % for each , while retaining performance for other relations .", "label": "", "metadata": {}, "score": "60.9663"}
{"text": "In other words , they are replaced with the correct translation word pair .A sentence retrieval component of the search engine 315 then searches the sentence database 320 using the new query created using the confusion set database .Again , while the confusion set methods have been discussed with reference to English word pairs written by a native Chinese speaking person , these methods are language independent and can be applied to other language combinations as well .", "label": "", "metadata": {}, "score": "61.299232"}
{"text": "Affiliated with .Abstract .Background .The construction of interaction networks between proteins is central to understanding the underlying biological processes .However , since many useful relations are excluded in databases and remain hidden in raw text , a study on automatic interaction extraction from text is important in bioinformatics field .", "label": "", "metadata": {}, "score": "61.313908"}
{"text": "FIGS .5 - 8 are flow charts for different aspects of the present invention .FIG .9 is a block diagram of another aspect of the present invention .DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS .FIG .1 generally illustrates a language processing system 10 that receives a language input 12 and processes the language input 12 to provide a language output 14 .", "label": "", "metadata": {}, "score": "61.319595"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 39 , wherein a most significant digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .", "label": "", "metadata": {}, "score": "61.34644"}
{"text": "Semantic queries .The next step is then to combine different syntactic patterns to yield a semantic rule .A generic relation between two arguments ( A and B ) , mediated by a verb or an equivalent relational noun ( H ) , is most commonly expressed by one of the following patterns : . semRel(xrel([H , A , B ] ) , active([A , H , B ] ) ) . semRel(xrel([H , A , B ] ) , passive([B , H , A ] ) ) . semRel(xrel([H , A , B ] ) , nominalization([H , B , A ] ) ) .", "label": "", "metadata": {}, "score": "61.373516"}
{"text": "[ 0019]FIG .6- 3 is a block diagram illustrating a confusion set method of detecting a user 's input query intentions .[ 0020 ] .[ 0020]FIG .7 is a block diagram illustrating a query translation method of improving the retrieval of sentences .", "label": "", "metadata": {}, "score": "61.439346"}
{"text": "In one embodiment , the acoustic model 112 includes a senone tree associated with each Markov state in a Hidden Markov Model .The Hidden Markov models represent , in one illustrative embodiment , phonemes .The tree search engine 114 also accesses the lexicon stored in module 110 .", "label": "", "metadata": {}, "score": "61.472733"}
{"text": "The similarity value between two subsequences are decreased by the factor of l ( i ) and l ( j ) , reflecting how spread out the subsequences are .The inner product between two strings s and t over A p is a sum over all common fixed - length subsequences that are weighted according to their frequency of occurrence and lengths .", "label": "", "metadata": {}, "score": "61.48769"}
{"text": "This flag determines the number of analyses that is passed on by the robustness / disambiguation component .If the value is 0 , then the system simply finds all solutions .parse_candidates_beam .Integer which determines during parsing ( first phase ) how many sub - parses are produced for any given sub - goal .", "label": "", "metadata": {}, "score": "61.491745"}
{"text": "claim 6 , wherein said predicates and arguments are represented by encodings comprising at least one digit separated into multiple groups to provide multiple ontological levels and a branching factor at each node .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 2 , further comprising lexer filters for modifying said individual sentences based on word meanings .", "label": "", "metadata": {}, "score": "61.570866"}
{"text": "6 - 2 and 6 - 3 ) .Then , the expanded terms are filtered using a filtering component or step 760 with triple database 360 as described above , for example with reference to FIG .5- 2 .The result is a set of expanded terms 765 which also exist in the triples database .", "label": "", "metadata": {}, "score": "61.654537"}
{"text": "Results are shown in Table 4 .The initial classifier used a tok6+atype feature set .Addition of both dir and dist features give significant improvements in all metrics , of around 10 % F 1 overall , in each case .", "label": "", "metadata": {}, "score": "61.71821"}
{"text": "Parse tree converter 240 receives the output of the parser 230 , and converts the parse trees into predicates .Following the Parse tree converter , parser filters 250 operate or the predicates to remove erroneously generated predicates based on rules about the probability of syntactic analyses , as well as rules about the compatibility of concepts with each other .", "label": "", "metadata": {}, "score": "61.76646"}
{"text": "claim 28 , further comprising the step of modifying said natural language sentence based on word meanings .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the steps of : . receiving sentences including ontological entities ; . parsing said sentences including ontological entities into parse trees representing concepts in the corresponding sentence including ontological entities ; and . converting said parse trees into predicates .", "label": "", "metadata": {}, "score": "61.82861"}
{"text": "We can then subtract numbers to see if the features are in agreement , and a non - negative result suffices to prove this .Since 1 is nonnegative , we know that the features are in agreement .If concepts are identical , they will subtract to zero , which is equivalent to passing the filter by having two identical strings .", "label": "", "metadata": {}, "score": "61.850906"}
{"text": "A system , comprising : . memory ; . a processor adapted to access the memory ; . instructions stored on the memory and executable by the processor which , when implemented , execute a method to build a language model , the method comprising : . accessing a plurality of context - free grammars comprising non - terminal tokens representing semantic or syntactic concepts of the selected application ; . generating word phases from the plurality of context - free grammars ; . formulating an information retrieval query from at least one of the word phases ; . querying a task independent corpus based on the query formulated ; . identifying associated text in the task independent corpus based on the query ; and .", "label": "", "metadata": {}, "score": "61.860104"}
{"text": "Since the parser is both probabilistic and operating on multiple streams of possible ontological entities , it is necessary to prune out spurious parse trees generated by the parser 230 .Parser filters 250 are designed to prune out spurious parse trees generated by the parser 230 , by removing trees that violate either statistical or ontological criteria for well - formed - ness .", "label": "", "metadata": {}, "score": "61.86605"}
{"text": "The alternative to the veryfast -option .The system will find all possible parses for the input .No part - of - speech pre - processor is applied .No beams are used in search .The parser does not enforce the \" guides \" technique .", "label": "", "metadata": {}, "score": "61.946213"}
{"text": "\" It is worth noting that once the first digit difference is detected , there is no further need to compute remaining digits .They diverge at level 3 , the third digit in the representation , and thereafter lie along completely different sub - trees that do not intersect .", "label": "", "metadata": {}, "score": "61.953743"}
{"text": "To provide solutions to one or more of the previously discussed challenges , system 300 and the methods it implements utilize a natural language processing - enabled ( NLP - enabled ) cross language information retrieval design .It uses a conventional information retrieval ( TR ) model as a baseline , and applies NLP technology to improve retrieval precision .", "label": "", "metadata": {}, "score": "61.966"}
{"text": "Signi ca nt amount of work has been devoted recently to develop learning techniques that can be used to generate partial ( shallow ) analysis of natural language sentences rather than a full parse .We conclude that directly learning to perform these tasks as shallow parsers do is advantageous over full parsers both in terms of performance and robustness to new and lower quality texts . \" ...", "label": "", "metadata": {}, "score": "62.005154"}
{"text": "Reynar JC , Ratnaparkhi A : A Maximum Entropy Approach to Identifying Sentence Boundaries .Proceedings of the Fifth Conference on Applied Natural Language Processing Washington , D.C. : University of Pennsylvania 1997 .Ratnaparkhi A : A Maximum Entropy Part - Of - Speech Tagger .", "label": "", "metadata": {}, "score": "62.00611"}
{"text": "Sim .D .i .Q .j . ) k .d . ik . q . jk .W . jk . )f .Li . )Equation ._ .Di is the vector weight representation of the i th confirming sentence ( see Equation 1 above ) .", "label": "", "metadata": {}, "score": "62.06903"}
{"text": "Entity types are manually mapped to types from the Unified Medical Language System ( UMLS ) semantic network [ 33 ] , each CLEF entity type being mapped to several UMLS types .Relationship types are those felt necessary to capture the essential clinical dependencies between entities referred to in patient documents , and to support CLEF end user applications .", "label": "", "metadata": {}, "score": "62.09398"}
{"text": "Narratives were annotated by two independent , clinically trained , annotators , and then a consensus annotation created by a third .We refer to the corpus as C77 .Corpora of this small size are not unusual in supervised machine learning , and reflect the expense of hand annotation .", "label": "", "metadata": {}, "score": "62.096157"}
{"text": "For example , the ranked confirming sentences can be displayed as a numbered list , as shown by way of example in FIG .3 .[ 0071 ] .In accordance with embodiments of the present invention , a ranking algorithm ranks the confirming sentences based upon their respective similarities Sim ( Di , Qj ) with the input query .", "label": "", "metadata": {}, "score": "62.105736"}
{"text": "We return to this issue below .Gold standard corpus .The schema and definitions were used to hand - annotate the entities and relationships in oncology narratives , to provide a gold standard for system training and evaluation .By \" narrative \" we mean letters , notes , and summaries written by the oncologist , describing the patient 's care .", "label": "", "metadata": {}, "score": "62.11934"}
{"text": "At every cycle , a new character is read from the input stream and the character and current state are used to look up , in the action table , which action to perform .The actions are in one of the following forms : .", "label": "", "metadata": {}, "score": "62.16152"}
{"text": "The system showed the current state - of - the - art results over other corpora as well as AIMed .Surprisingly , the recalls of the system were very high even in tricky corpora such as AIMed and BioInfer .Table 8 shows comparison with other systems over the 5 PPI corpora .", "label": "", "metadata": {}, "score": "62.20478"}
{"text": "Features sets are abbreviated as in Table 3 .For the first seven columns , features were added cumulatively to each other .The next two columns , allgen and notok , are as described in Table 3 .We were interested to see if generalising features could improve performance , as this had benefited our previous work in entity extraction .", "label": "", "metadata": {}, "score": "62.221806"}
{"text": "The standard LALR parser generator algorithm fails when the grammar does not provide the parser generator enough information to decide whether the correction to perform given a certain current state and input symbol is to shift or to reduce .The generator algorithm also fails when the grammar does not provide the parser generator enough information to decide which of two or more rules should be reduced .", "label": "", "metadata": {}, "score": "62.261864"}
{"text": "In this form , the input sentence is given as a sequence of tokens W1 .Wn on the command line .Options .There are a whole bunch of options which affect the way in which the system runs .For most options , there is documentation available from the graphical user interface .", "label": "", "metadata": {}, "score": "62.363792"}
{"text": "The software described is open source and can be downloaded as part of GATE [ 41 ] , except for the entity pairing component , which will be released shortly .We are currently preparing a UK research ethics committee application , for permission to release our annotated corpus .", "label": "", "metadata": {}, "score": "62.378723"}
{"text": "Converted corpora \" is short for the dependency - parsed 5 corpora by [ 18 ] .Preprocessing for the third party automated inputs .Self cycle here means that an edge ( x , y ) and its inverted edge ( y , x ) coexist between two nodes , x and y. .", "label": "", "metadata": {}, "score": "62.37932"}
{"text": "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics Morristown , NJ , USA : Association for Computational Linguistics 2003 , 423 - 430 .Harkema H , Gaizauskas R , Hepple M , Roberts A , Roberts I , Davis N , Guo Y : A Large Scale Terminology Resource for Biomedical Text Processing .", "label": "", "metadata": {}, "score": "62.448006"}
{"text": "de leuke en vervelende kinderen .POS - tags .If you only care for the part - of - speech tags that Alpino used to derive the best parse , then you can use the following command : .In that case , the system prints lines like the following to standard error ( ! )", "label": "", "metadata": {}, "score": "62.497803"}
{"text": "The classifier builds a model of these entity pair training instances , from their features .In classifier application , entity pairs are created from unseen text , under the above constraints .The classifier assigns one of our seven relationship types , or null , to each entity pair .", "label": "", "metadata": {}, "score": "62.56171"}
{"text": "The system of . claim 2 having instructions further comprising : . storing the N - gram model having the non - terminal tokens and the set of context - free grammars having non - terminal tokens representing task dependent semantic or syntactic concepts on the memory .", "label": "", "metadata": {}, "score": "62.607483"}
{"text": "In a network environment , program modules depicted relative to the personal computer 50 , or portions thereof , can be stored in the remote memory storage devices .As appreciated by those skilled in the art , the network connections shown are exemplary and other means of establishing a communications link between the computers can be used .", "label": "", "metadata": {}, "score": "62.6575"}
{"text": "Thus , we introduce string kernels to handle such non - contiguous subpaths .String kernels .In this section , we will look at the string kernels from various structural perspectives .First of all , we will briefly introduce concepts and notations for string kernels .", "label": "", "metadata": {}, "score": "62.72882"}
{"text": "In the embodiment illustrated , the language model 16 can be an N - gram language model or a unified language model comprising a context - free grammar specifying semantic or syntactic concepts with non - terminals and a hybrid N - gram model having non - terminals embedded therein .", "label": "", "metadata": {}, "score": "62.798992"}
{"text": "On the other hand , for the rest of fully automatically parsed corpora , we could not show significant improvements in F - score over other systems .As in many other researches , the extraction performances on AIMed and BioInfer , were worse than those on the other 3 corpora .", "label": "", "metadata": {}, "score": "62.810387"}
{"text": "There are multiple methods of calculating and defining the weight d ik of a term .Here , by way of example , we use the relationship shown in Equation 2 : . d . ik .[ . log .f . ik . ) 1.0 . ] log .", "label": "", "metadata": {}, "score": "62.85215"}
{"text": "There are several ways in which a multi - class problem can be recast as binary problems .The commonest are one - against - one in which one classifier is trained for every possible pair of classes , and one - against - all in which a classifier is trained for a binary decision between each class and all other classes , including null , combined .", "label": "", "metadata": {}, "score": "62.858093"}
{"text": "Brants and Franz 2006 Brants , Thorsten and Alex Franz .Web 1 T 5-gram Version 1 .Philadelphia : Linguistic Data Consortium , 2006 .Brown et al .1991c Brown , Peter F. , Stephen A. Della Pietra , Vincent J. Della Pietra and Robert L. Mercer .", "label": "", "metadata": {}, "score": "62.9535"}
{"text": "0075 ] .[ 0077 ] .W jk is the linguistic weight of term q jk .The linguistic weights for different parts of speech in one example embodiment are provided in the second column of Table 3 .The present invention is not limited , however , to any specific weighting .", "label": "", "metadata": {}, "score": "63.00558"}
{"text": "Schneider G : A broad - coverage , representationally minimal LFG Parser : chunks and F - structures are sufficient .The 10th international LFG Conference ( LFG 2005 ) ( Edited by : Butt M , King TH ) .Bergen , Norway : CSLI 2005 .", "label": "", "metadata": {}, "score": "63.184135"}
{"text": "Adj / Adv .Noun .Others .[ 0078 ] .One is the linguistic weight , W jk of terms in the query Q j .[0079 ] .It is believed that users pay more attention to issues reflecting sentence structure and word combinations .", "label": "", "metadata": {}, "score": "63.292442"}
{"text": "Similarly , this kernel also considers subsequences of length 3 .The formula ( 11 ) means that the kernel assigns 3.0 for common contiguous e -walk substrings , 2.0 for common contiguous v -walk substrings .For non - contiguous subsequences , they can be penalized by gap - weights , but the performance was the best when we set the lambda to 1.0 .", "label": "", "metadata": {}, "score": "63.379955"}
{"text": "In other words , v - walks ( Figure 1b ) were compared , but e - walks ( Figure 1c ) , one of the features in the walk kernel , were not .However , according to our experiments , the e - walk feature practically plays a more important role in determining the relation than v - walk .", "label": "", "metadata": {}, "score": "63.390774"}
{"text": "If your input is not like that , cf the script paragraph_per_line .Example 1 .For an example text , cf the text file t1.txt which contains the following : .Het PIONIER project Algorithms for Linguistic Processing van Gertjan van Noord is een onderzoeksproject op het gebied van de computationele taalkunde .", "label": "", "metadata": {}, "score": "63.4608"}
{"text": "] There also is the @id meta - notation .This notation can be used to add a wordid attribute in the XML output of a particular word .In order that this meta - notation can be used in combination with other , the notation precedes the word for which it is meant .", "label": "", "metadata": {}, "score": "63.47704"}
{"text": "For instance , the first pair , \" FGF-2 \" and \" FGFR1 \" ( 18 , 22 ) in the sentence of Figure 6a was not found due to incorrect dependency analysis in the form of \" nn(FGFR4 - 32 , FGFR1 - 27 ) \" .", "label": "", "metadata": {}, "score": "63.48177"}
{"text": "But , if speed is a big concern , the Stanford Parser is actually not that fast .The abstract I linked to above ( i.e. , see table 1 -here- ) , discusses faster ways of generating the Stanford Dependencies using other parsers like MST , Malt , and Charniak . - dmcer Mar 9 ' 10 at 23:15 .", "label": "", "metadata": {}, "score": "63.487984"}
{"text": "Normal syntactic symbols can be used here as @np , @pp etc .Examples : .Hij fietst [ @pp op zijn gemakje ] [ door de straten van De Baarsjes ] .FNB zet teksten van [ [ kranten en tijdschriften ] , boeken , [ studie- en vaklectuur ] , bladmuziek , folders , brochures ] om in gesproken vorm .", "label": "", "metadata": {}, "score": "63.59675"}
{"text": "The parse probability filter vetoes parse trees that fall below a minimum probability for valid semantic interpretation .The parse probability filter will calculate the probability of a sentence parse by taking the product of the probabilities of the syntactic rules used to generate a given parse tree .", "label": "", "metadata": {}, "score": "63.621635"}
{"text": "At step 186 , each of the identified word occurrences for non - terminals representing concepts which are of interest to the target application is replaced with the corresponding non - terminal token as defined by the corresponding context - free grammar .", "label": "", "metadata": {}, "score": "63.7013"}
{"text": "Warning : the resulting dependency structure is most likely not well - formed and often needs manual editing .The @folia meta - notation can be used to inform Alpino about the lemma and postag of the given word .Examples : .", "label": "", "metadata": {}, "score": "63.709873"}
{"text": "When the third N - gram language model 252 is built having non - terminals , the word phrases or synthetic data at block 242 typically will also include the non - terminals as well .When the context - free grammars are used to generate synthetic data , probabilities for the word phrases formed with the non - terminals and the terminals of the non - terminals can be chosen as desired ; for instance , each can be assigned equal probability .", "label": "", "metadata": {}, "score": "63.75831"}
{"text": "Only those triples which have ever appeared in the triple database are selected as expanded query terms .Those expanded triples which are not found in the triple database are discarded .Then , the sentence database is searched for hint sentences using the remaining expanded terms as shown at 420 .", "label": "", "metadata": {}, "score": "63.7676"}
{"text": "Each line represents the information of a word .The fileds represent from left to right : the word , the part - of - speech tag , the sentence number , the begin position of the word , the end position of the word , and two further fields that you probably want to ignore .", "label": "", "metadata": {}, "score": "63.788456"}
{"text": "In the -flag Flag Value syntax , on the other hand , the Value is parsed as a Prolog atom .In many cases this does not make a difference .Remember : for path names , you need the second format . -tk .", "label": "", "metadata": {}, "score": "63.813087"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said adverb filter removes lexemes containing adverb concepts from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "63.859776"}
{"text": "For subcategorization information , subcat w ( x ) is used to refer to the sub - categorization pair of a word x which is composed of the left and right edge of it .That is the same information with e -walk .", "label": "", "metadata": {}, "score": "63.868473"}
{"text": "Q .h . )P . word .w .u . t .i .l .u . t .i .l .The normalization is performed the same as in Equation ( 7 ) .Multiple segmentations may be available for W due to the ambiguity of natural language .", "label": "", "metadata": {}, "score": "64.03657"}
{"text": "claim 30 , further comprising the step of assigning numbers to said concepts .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 34 , further comprising the step of subtracting said numbers to determine if features are in agreement , wherein a negative number indicates feature incompatibility .", "label": "", "metadata": {}, "score": "64.066605"}
{"text": "However , it assigns the weights of subsequences not by the lengths of gaps , but by their type .We set more weights to contiguous subsequences than to non - contiguous subsequences since they are coherent and can affect more the overall meaning of shortest path string .", "label": "", "metadata": {}, "score": "64.069855"}
{"text": "A system , comprising : . memory ; . a processor adapted to access the memory ; . instructions stored on the memory and executable by the processor which , when implemented , execute a method to build a unified language model for a selected application , the method comprising : . accessing a plurality of context - free grammars comprising non - terminal tokens representing semantic or syntactic concepts of the selected application ; . building a word language model from a corpus ; and .", "label": "", "metadata": {}, "score": "64.07953"}
{"text": "Table 2 shows the results obtained on a subset of the relations extracted by the system .We asked the domain experts to evaluate each relation and each argument of the relation , and mark them according to the following guidelines : .", "label": "", "metadata": {}, "score": "64.08982"}
{"text": "The output of Alpino uses identifiers .The sentence identifier is either defined explicitly as part of the input sentence , or it is set implicitly by Alpino ( simply counting the sentences of a specific session starting from 1 ) .", "label": "", "metadata": {}, "score": "64.11932"}
{"text": "In this case , only the functor of the POS - tag is given , and Alpino will allow any lexical assignments which have the same functor .Example : . ik wil [ @posflt preposition naar ] huis ik voel me [ @posflt adjective naar ] .", "label": "", "metadata": {}, "score": "64.15451"}
{"text": "We start the kernel modification with the re - consideration of walks properties .In the walk kernel , the structural information is encoded with walks of graphs .It begins with a vertex and ends with a vertex , where V and E are a set of vertices ( nodes ) and edges ( relations ) , respectively .", "label": "", "metadata": {}, "score": "64.16085"}
{"text": "Walk - weighted fixed length subsequence kernel .In order to improve the gap - weighted subsequence kernel , we devise the walk - weighted subsequence kernel which can handle structural properties differently in addition to the consideration of contiguous and non - contiguous substring .", "label": "", "metadata": {}, "score": "64.181366"}
{"text": "The modal verb filter will contain a set of modal verbs similar to the stop word list contained in stop word filter .Any Lexeme whose text is in that set and whose concept is a verb is identified as a modal verb , and will be removed .", "label": "", "metadata": {}, "score": "64.30541"}
{"text": "Although the present invention has been described with reference to particular embodiments , workers skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention .For example , examples described with reference to English language writing by a Chinese speaking person are applicable in concept to writing in a first language by a person whose native language is a second language which is different from the first language .", "label": "", "metadata": {}, "score": "64.30618"}
{"text": "If a noun is found and it satisfies the restrictions of the adjective , the adjective filter will apply the selectional features of the adjective to the noun by adding all of the adjective 's selectional features to the noun 's set of selectional features .", "label": "", "metadata": {}, "score": "64.32367"}
{"text": "This gave the results shown in column allgen .Results are not clear cut , in some cases better and in some worse than the previous best .Overall , there is no difference in F 1 .There is a slight increase in overall recall , and a corresponding drop in precision - as might be expected .", "label": "", "metadata": {}, "score": "64.331436"}
{"text": "claim 7 , wherein combining the expanded terms to form the plurality of dependency triples further comprises combining the expanded terms to form all possible dependency triples from the expanded terms .The computer - readable medium of .claim 7 , wherein expanding the query by including synonyms of the terms to obtain expanded terms further comprises adding synonyms of at least some of the terms of the query .", "label": "", "metadata": {}, "score": "64.41319"}
{"text": "The present invention relates to an ontological parser for natural language processing .More particularly , the present invention relates to a system and method for ontological parsing of natural language that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}, "score": "64.41894"}
{"text": "In addition , sc w ( n 1 , n 2 ) and sc p ( p 1 , p 2 ) denote the set of common dependencies between two subgraphs rooted at n 1 and n 2 , and POS p 1 and p 2 , respectively .", "label": "", "metadata": {}, "score": "64.58058"}
{"text": "claim 3 , wherein adding synonyms of at least some of the terms of the query further comprises adding the synonyms to the terms of the query such that the expanded terms include the synonyms and the terms of the query .", "label": "", "metadata": {}, "score": "64.68915"}
{"text": "f .w .E1 .rel .E . w .E2 . )f .Equation ._ .[ 0107 ] .But this can be simplified as : .Furthermore , we suppose that the selection of a word in translation is independent of the type of dependency relation , therefore we can assume that w C1 is only related to w E1 , and that w C2 is only related to w E2 .", "label": "", "metadata": {}, "score": "64.72181"}
{"text": "Spelling check and grammar check are helpful only when the user misspells a word or makes an obvious grammar mistake .These checking programs can not be depended on for help in polishing sentences .A dictionary can be helpful as well , but mostly only for resolving reading and translation issues .", "label": "", "metadata": {}, "score": "64.748955"}
{"text": "Step 224 then includes replacing each of the identified word occurrences with corresponding non - terminal tokens for selected non - terminals ( i.e. excluding the non - terminals which may have been introduced to prevent mistakes during parsing ) .Step 212 would then include building an N - gram model having non - terminal tokens .", "label": "", "metadata": {}, "score": "64.76108"}
{"text": "Before we explain the matching function , we will introduce some notations .For each node x , word ( x ) is the word at a certain node and POS ( x ) is the POS of the node . children w ( n ) denotes word dependency list of word n and children p ( p ) refers to POS dependency list of POS p. children w ( n ) is the set of ( relation , word ) pairs which are direct modifiers of n .", "label": "", "metadata": {}, "score": "64.76116"}
{"text": "Prior to a detailed discussion of the present invention , an overview of an operating environment may be helpful .FIG .2 and the related discussion provide a brief , general description of a suitable computing environment in which the invention can be implemented .", "label": "", "metadata": {}, "score": "64.857956"}
{"text": "The system of . claim 8 and having instructions further comprising : . storing the N - gram model having the non - terminal tokens and the plurality of context - free grammars having non - terminal tokens representing task dependent semantic or syntactic concepts on the memory .", "label": "", "metadata": {}, "score": "65.08664"}
{"text": "FIG .2 and accessible by the processing unit 51 or another suitable processor .In addition , the lexicon storage module 110 , the acoustic model 112 , and the language model 16 are also preferably stored in any of the memory devices shown in .", "label": "", "metadata": {}, "score": "65.115265"}
{"text": "It uses \" tok \" , which is a C program created by the FSA Utilities that does most of the tokenization .This is much more efficient than an equivalent Perl script using regular expressions .In addition there are a number of scripts that do some more difficult stuff that requires more global information ( for which no sequential transducer can be defined ) .", "label": "", "metadata": {}, "score": "65.198166"}
{"text": "n . k . ) j .[ . log .f .jk . ) log .N .n . k . ) . ]Equation ._ . where f ik is the occurrence frequency of the term t k in the document D i , N is the total number of documents in the collection , and n k is the number of documents that contain the term t k .", "label": "", "metadata": {}, "score": "65.20171"}
{"text": "In the absence of a gold standard , only approximative recall values can be reported .In [ 2 ] we report a value of 40 % for a measure that we call \" worst - case recall \" , which basically implies that our actual recall is at least as good as this value .", "label": "", "metadata": {}, "score": "65.304855"}
{"text": "IAA scores are not directly comparable here to system extraction scores , as relationship annotation is a slightly different task for the human annotators .The relationship extraction system is given entities , and finds relationships between them .Human annotators must find both the entities and the relationships .", "label": "", "metadata": {}, "score": "65.3098"}
{"text": "Integer which determines during parsing how many parses are produced for any given maximal projection .From these , only the best are kept for further processing later ( using the disambiguation_beam flag ) .This flag can be used to limit the number of parses that are computed in the first place .", "label": "", "metadata": {}, "score": "65.32791"}
{"text": "In this paper , we proposed 5 different kernels .We first investigated structural significances depending on substructure types with our previous walk kernel .Then , for accurate assessments , each kernel 's performance was evaluated with the clean dataset , LLL .", "label": "", "metadata": {}, "score": "65.35069"}
{"text": "Wiley 2006 , in press .Copyright .\u00a9 Rinaldi et al .2006 .This article is published under license to BioMed Central Ltd.A method , computer readable medium and system are provided which retrieve hint sentences from a sentence database in response to a query .", "label": "", "metadata": {}, "score": "65.391205"}
{"text": "The discounting by distance gap was not effective .Similarly , gap weighting for non - contiguous subsequences was not good as with the walk - weighted subsequence kernel .The best result was obtained with the walk - weighted subsequence kernel where their substructures were differently weighted according to their significance levels for learning .", "label": "", "metadata": {}, "score": "65.4107"}
{"text": "Predicate structures are representations of logical relationships between the words in a sentence .Every predicate structure contains a predicate , which is either a verb or a preposition , and a set of arguments , which may be any part of speech .", "label": "", "metadata": {}, "score": "65.43593"}
{"text": "Furthermore , the shortest path string is defined as a sequence of words or parts - of - speech ( POS ) connected by directed dependency relations , as shown in Figure 2b .The presence of the \" PRED \" label for a word on the path indicates that the directions of the left or right edges connected to the word are changed .", "label": "", "metadata": {}, "score": "65.45575"}
{"text": "The ability to search a Latin or Greek text by an English translation equivalent is a close approximation to real cross - language information retrieval .By searching for word sense , however , a scholar can simply search for slave and automatically be presented with all of the passages for which this translation equivalent applies .", "label": "", "metadata": {}, "score": "65.5227"}
{"text": "Generally , program modules include routine programs , objects , components , data structures , etc . that perform particular tasks or implement particular abstract data types .Tasks performed by the programs and modules are described below and with the aid of block diagrams and flow charts .", "label": "", "metadata": {}, "score": "65.599"}
{"text": "Copyright .\u00a9 Kim et al .2010 .This article is published under license to BioMed Central Ltd.A method for creating a language model from a task - independent corpus is provided .In one embodiment , a task dependent unified language model is created .", "label": "", "metadata": {}, "score": "65.617325"}
{"text": "Ranking Algorithm .[0070 ] .After search engine 315 retrieves a number of confirming sentences from the database , for example using the extended indexing units method described above or other methods , the confirming sentences are ranked to determine the sentences which are the most grammatically or structurally similar to the input query .", "label": "", "metadata": {}, "score": "65.67873"}
{"text": "These grammar rules , called productions , specify language that the target parser is supposed to recognize .Each production indicates that a specific combination of input symbols , called terminals , and assembled groups of terminals , called non - terminals , can be assembled into a new non - terminal .", "label": "", "metadata": {}, "score": "65.68931"}
{"text": "If the ontological tree structure is carefully crafted , proximity within the tree should , in some measure , correspond to ontological proximity .Therefore , detecting the first digit difference , as above , gives a reasonable measure of the degree of ontological proximity of the two concepts .", "label": "", "metadata": {}, "score": "65.70497"}
{"text": "If you have square brackets in your input , you need to escape these using the backslash .Bracketed input .@postag .@posflt .@add_lex .@mwu . @folia .requirement to skip words . @skip .include phantom words .", "label": "", "metadata": {}, "score": "65.71056"}
{"text": "The language processing system 10 processes the spoken language and provides as an output , recognized words typically in the form of a textual output .During processing , the speech recognition system or module 10 can access a language model 16 in order to determine which words have been spoken .", "label": "", "metadata": {}, "score": "65.73114"}
{"text": "You can also force a lexical assingment to a token or a series of tokens , if the Alpino lexicon does not contain the proper assignment .A @postag followed by an Alpino lexical category will force the assignment of the corresonding lexical category to the words contained in the brackets .", "label": "", "metadata": {}, "score": "65.73782"}
{"text": "0017 ] .[ 0017]FIG .6- 1 is a block diagram illustrating a translation method of detecting a user 's input query intentions .[ 0018 ] .[ 0018]FIG .6- 2 is a block diagram illustrating a method of constructing a confusion set database .", "label": "", "metadata": {}, "score": "65.74538"}
{"text": "In spite of its structural simplicity , the result was quite promising .It was better than the performance of the extended dependency kernel .We could obtain a reasonable performance only with contiguous dependencies on the shortest path string .Fixed - length subsequence kernel .", "label": "", "metadata": {}, "score": "65.821335"}
{"text": "PubMed View Article .Giuliano C , Lavelli A , Romano L : Exploiting Shallow Linguistic Information for Relation Extraction from Biomedical Literature .Proceedings of the 11th Conference of European Chapter of the Association for Computational Linguistics , Trento , Italy 2006 , 401 - 408 .", "label": "", "metadata": {}, "score": "65.853485"}
{"text": "In order to tokenize your text , you would first ensure that each line contains a paragraph of text with the paragraph_per_line script ( this essentially removes single newlines from the input ) , and then pipe the result to the tokenizer : . /tokenize.sh .", "label": "", "metadata": {}, "score": "65.89003"}
{"text": "We use an SVM implementation developed within our own group , and provided as part of the GATE toolkit .This is a variant on the original SVM algorithm , SVM with uneven margins , in which classification may be biased towards positive training examples .", "label": "", "metadata": {}, "score": "66.02646"}
{"text": "A response relation is a true positive if a relation of the same type , and with the exact same arguments , exists in the key .Corresponding definitions apply for false positive and false negative .Counts of these matches are used to calculate Recall ( R ) and Precision ( P ) scores , as defined below .", "label": "", "metadata": {}, "score": "66.048874"}
{"text": "Unlike the spectrum kernel , the subsequence kernel allows gaps between characters .That is , some characters can intervene between two matching subsequences .Thus , this kernel can explain the substructures like Figure 1 g .The advantage of the kernel is that we can exploit long - range dependencies existing on strings .", "label": "", "metadata": {}, "score": "66.2042"}
{"text": "Acknowledgements .We are indebted to the creators of the GENIA corpus for providing such a valuable resource .Special thanks to Manfred Klenner for very important comments and suggestions .This article has been published as part of BMC Bioinformatics Volume 7 , Supplement 3 , 2006 : Second International Symposium on Semantic Mining in Biomedicine .", "label": "", "metadata": {}, "score": "66.21118"}
{"text": "Abstract .Manual lexicography has produced extraordinary results for Greek and Latin , but it can not in the immediate future provide for all texts the same level of coverage available for the most heavily studied materials .As we build a cyberinfrastructure for Classics in the future , we must explore the role that automatic methods can play within it .", "label": "", "metadata": {}, "score": "66.23764"}
{"text": "In addition , up to now , no effective software has existed that supports English polish , and it is believed that few researchers have ever worked on this area .[ 0006 ] .There are numerous challenges to realizing a system capable of aiding users in polishing English sentences .", "label": "", "metadata": {}, "score": "66.262314"}
{"text": "For both arguments the exact results [ Y ] are above 50 % .When we slightly relax the precision criteria and include the cases [ A ] where the argument has been correctly identified , but incorrectly expanded , precision jumps to about 90 % .", "label": "", "metadata": {}, "score": "66.263245"}
{"text": "Busa 2004 Busa , Roberto .\" Foreword : Perspectives on the Digital Humanities \" , Blackwell Companion to Digital Humanities .Oxford : Blackwell , 2004 .Charniak 2000 Charniak , Eugene .\" A Maximum - Entropy - Inspired Parser \" , Proceedings of NAACL ( 2000 ) .", "label": "", "metadata": {}, "score": "66.34533"}
{"text": "Commonly , a plurality of context - free grammars comprising non - terminal tokens representing various semantic or syntactic concepts are used .For instance , other semantic or syntactic concepts include geographical places , regions , titles , dates , times , currency amounts , and percentage amounts to name a few .", "label": "", "metadata": {}, "score": "66.3747"}
{"text": "[ 0043 ] .The database 320 contains a large number of example sentences extracted from standard English documents .The search engine 315 retrieves user - intended example sentences from the database .The example sentences are ranked by the search engine 315 , and are provided at a sentence output component 325 for reference by the user in polishing his or her written sentences .", "label": "", "metadata": {}, "score": "66.44414"}
{"text": "Searching by word sense also allows us to investigate problems of changing orthography - both across authors and time : as Latin passes through the Middle Ages , for instance , the spelling of words changes dramatically even while meaning remains the same .", "label": "", "metadata": {}, "score": "66.480095"}
{"text": "These features are split into 15 sets , as described in Table 3 .All above features in root and generalised POS forms , i.e. gen - tok6+atype+dir+dist+root+genpos+inter+event .notok .All above except tokN features , others in string and POS forms , i.e. atype+dir+dist+str+pos+inter+event . dep .", "label": "", "metadata": {}, "score": "66.485825"}
{"text": "The configuration of the parser 200 is shown in FIG .2 .First , the sentence receiver 220 obtains sentences 210 consisting of ontological entities produced by the sentence lexer 100 .These sentences are parsed by the parser 230 , which is designed to use a context - free grammar , although other grammatical models may be used without departing from the scope and spirit of the invention .", "label": "", "metadata": {}, "score": "66.51018"}
{"text": "pos_tagger .Boolean flag to determine whether to use a POS - tagger to filter the result of lexical lookup .The POS - tagger is based on unigram , bigram and trigram frequencies .This filter can be made more or less strict using the pos_tagger_n flag . pos_tagger_n , pos_tagger_p , pos_tagger_m .", "label": "", "metadata": {}, "score": "66.68791"}
{"text": "0062 ] .Improve Retrieval Precision with NLP Technologies .[ 0063 ] .In accordance with the present invention , search engine 315 utilizes one or both of two methods to improve the \" confirming sentence \" retrieval results .One method utilizes extended indexing terms .", "label": "", "metadata": {}, "score": "66.69855"}
{"text": "Skips .If the annotator can predict that a certain token or series of tokens will make the annotation a mess , it can be skipped by @skip .In such a case , the sentence is parsed as if the word(s ) that are marked with skip where not there , except that the numbering of the words in the resulting dependency structure is still correct .", "label": "", "metadata": {}, "score": "66.718376"}
{"text": "scientist_noun , .POS .workshop noun , preside verb .Phrasal verb .preside\u02dcover .Dependency .preside\u02dcDobj\u02dcworkshop . triples .[0068 ] .The confirming sentences retrieved from sentence database 320 by search engine 315 using the extended indexing units for the particular input query are then ranked using a new ranking algorithm .", "label": "", "metadata": {}, "score": "66.785645"}
{"text": "For instance , the shortest path between \" BMP-2 \" and \" BMPR-1A \" in Figure 5b represented as \" NE / NE_prep_for(DN)_NE / NE \" requires contextual information outside the path such as \" binding \" to identify their interaction .", "label": "", "metadata": {}, "score": "66.8745"}
{"text": "Minute research in manuscript authorities has largely restored the texts of the classical writers , and even their orthography .Philology has traced the growth and history of thousands of words , and revealed meanings and shades of meaning which were long unknown .", "label": "", "metadata": {}, "score": "66.94147"}
{"text": "These probability distributions are later used in executing a Viterbi or similar type of processing technique .Upon receiving the code words from the feature extraction module 106 , the tree search engine 114 accesses information stored in the acoustic model 112 .", "label": "", "metadata": {}, "score": "66.951035"}
{"text": "Syntactic queries .We have written a set of syntactic rules that capture some of the most important syntactic phenomena , as in the example below , which encodes the passive case : .synRel(passive , [ X1 , X2 , X3 ] , .", "label": "", "metadata": {}, "score": "66.96443"}
{"text": "This kernel is defined via the feature map from the space of all finite sequences drawn from to the vector space indexed by the set of p -length subsequences derived from A. We will define A p as the set of all subsequences of length p .", "label": "", "metadata": {}, "score": "67.051865"}
{"text": "In addition , those skilled in the art will appreciate that the invention can be practiced with other computer system configurations , including hand - held devices , multiprocessor systems , microprocessor - based or programmable consumer electronics , network PCs , minicomputers , mainframe computers , and the like .", "label": "", "metadata": {}, "score": "67.08421"}
{"text": "Since the Perseus Digital Library contains two large monolingual corpora ( the canon of Greek and Latin classical texts ) and sizable parallel corpora as well , we have investigated using parallel texts for word sense disambiguation .This method uses the same techniques we used to create a sense inventory to disambiguate words in context .", "label": "", "metadata": {}, "score": "67.13893"}
{"text": "Andrews 1850 Andrews , E. A. ( ed . )A Copious and Critical Latin - English Lexicon , Founded on the Larger Latin - German Lexicon of Dr. William Freund ; With Additions and Corrections from the Lexicons of Gesner , Facciolati , Scheller , Georges , etc . .", "label": "", "metadata": {}, "score": "67.18262"}
{"text": "[ 0009 ] .The methods , computer readable medium and systems of the present invention aid users in retrieving hint sentences from a sentence database in response to a query .[0010 ] .An input component receives the query having terms .", "label": "", "metadata": {}, "score": "67.187294"}
{"text": "Bamman and Crane 2007 Bamman , David and Gregory Crane . \"The Latin Dependency Treebank in a Cultural Heritage Digital Library \" , Proceedings of the ACL Workshop on Language Technology for Cultural Heritage Data ( 2007 ) .Bamman and Crane 2008 Bamman , David and Gregory Crane .", "label": "", "metadata": {}, "score": "67.22429"}
{"text": "Languages such as Japanese or Russian , which permit free ordering of words , but mark intended usage by morphological changes , would be difficult to parse using the Brash system .The patent to Hemphill et al .( U.S. Pat .", "label": "", "metadata": {}, "score": "67.24119"}
{"text": "Results : Evaluation .The approach followed for creating rules starts from a set of relations that are of particular interest in this domain , such as : activate , bind , block , regulate , control , express .The rule developer is offered a view over all the sentences that might include one of the selected relations ( detected using as keywords the verbs that express such relation and all their grammatical inflections ) .", "label": "", "metadata": {}, "score": "67.24867"}
{"text": "Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing Columbus , OH , USA : Association for Computational Linguistics 2008 , 10 - 18 .Defense Advanced Research Projects Agency : Proceedings of the Seventh Message Understanding Conference ( MUC-7 ) Fairfax , VA , USA : National Institute of Standards and Technology 1998 .", "label": "", "metadata": {}, "score": "67.25534"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said stop word filter removes stop words from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "67.29511"}
{"text": "Full details of the classifier are given in [ 37 ] .We used the implementation \" out of the box \" , with default parameters as determined in experiments with other data sets .The SVM with uneven margins algorithm is a binary classifier .", "label": "", "metadata": {}, "score": "67.307556"}
{"text": "Searching by selectional preference .The ability to search by a predicate 's selectional preference is also a step toward semantic searching - the ability to search a text based on what it \" means . \"In building the lexicon , we automatically assign an argument structure to all of the verbs .", "label": "", "metadata": {}, "score": "67.341736"}
{"text": "0044 ] .The user enters a query by writing something in a word processing program running on a computer or computing environment such as those shown in FIGS . 1 and 2 .For example , he or she may input one single word , or a phrase , or a whole sentence .", "label": "", "metadata": {}, "score": "67.390594"}
{"text": "The history of ancient nations , the private life of the citizens , the thoughts and beliefs of their writers have been closely scrutinized in the light of accumulating information .Thus the student of to - day may justly demand of his Dictionary far more than the scholarship of thirty years ago could furnish .", "label": "", "metadata": {}, "score": "67.41385"}
{"text": "The system of .claim 6 wherein the language model is an N - gram language model .The system of .claim 7 and having instructions further comprising : . parsing the identified text of the task independent corpus with the plurality of context - free grammars to identify word occurrences for each of the semantic or syntactic concepts ; . replacing each of the identified word occurrences with corresponding non - terminal tokens ; and . wherein building the N - gram language model comprises building a N - gram model having the non - terminal tokens .", "label": "", "metadata": {}, "score": "67.57541"}
{"text": "Arguments are underlined and preceded by their argument number .The relationship schema .The relationship schema , showing entities ( rectangles ) , modifiers ( ovals ) , and relationships ( arrows ) .Some of the relationships considered important by the clinical experts were not obvious without domain knowledge .", "label": "", "metadata": {}, "score": "67.66226"}
{"text": "[ 1 ] The Biblioteca Teubneriana BTL-1 collection , for instance , contains 6.6 million words , covering Latin literature up to the second century CE .For a recent overview of the Index Thomisticus , including the corpus size and composition , see Busa ( 2004 ) .", "label": "", "metadata": {}, "score": "67.702774"}
{"text": "Typing in sentences through the parse widget works without any problems though .Typing in sentences through the command interpreter also works without any problems if you did not start the graphical user interface .This is the feedback from SICS : .", "label": "", "metadata": {}, "score": "67.71711"}
{"text": "First , we performed string comparisons with a simple string kernel .One of the ways to compare two strings is to count how many p -length contiguous substrings they have in common .It is called the spectrum kernel of order p or p -spectrum kernel .", "label": "", "metadata": {}, "score": "67.798355"}
{"text": "In the first case , the input is a string which may need to be tokenized ( see discussion above ) .In the second case , Tokens is a list of atoms where each atom is a token ( word , punctuation mark ) of the sentence .", "label": "", "metadata": {}, "score": "67.8363"}
{"text": "Another object of the present invention is to provide a system and method for parsing natural language input that realizes enormous speed benefits from the parameterized ontology that the parser utilizes .BRIEF DESCRIPTION OF THE DRAWINGS .These and other attributes of the present invention will be described with respect to the following drawings in which : .", "label": "", "metadata": {}, "score": "67.90318"}
{"text": "Thus , the feature extraction module 106 provides , at its output the feature vectors ( or code words ) for each spoken utterance .The feature extraction module 106 provides the feature vectors ( or code words ) at a rate of one feature vector or ( code word ) approximately every 10 milliseconds .", "label": "", "metadata": {}, "score": "68.01528"}
{"text": "P .c .e . )P .c . )Equation ._ .Here , the P(e ) factor is a measure of the likelihood of the occurrence of a dependency triple e in the English language .It makes the output of e natural and grammatical .", "label": "", "metadata": {}, "score": "68.081696"}
{"text": "The gentokN features generalise tokN to use morphological root and generalised POS .The pos , root , and genpos feature sets are similarly constructed from the POS tags , roots , and generalised POS tags of the entity mentions and their surrounding tokens .", "label": "", "metadata": {}, "score": "68.15943"}
{"text": "R\u00e9sum\u00e9 .A method , computer readable medium and system are provided which retrieve hint sentences from a sentence database in response to a query .An input component receives the query having terms .A search engine expands the query by including synonyms of the terms to obtain expanded terms .", "label": "", "metadata": {}, "score": "68.21716"}
{"text": "In Dijkstra 's algorithm .Second edition .MIT Press and McGraw - Hill ; 2001:595 - 601 .Sleator D , Temperly D : Parsing English with a Link Grammar .Proceedings of IWPT , Tilburg , The Netherlands 1993 , 277 - 291 .", "label": "", "metadata": {}, "score": "68.3192"}
{"text": "Proceedings of the ICML05 workshop : Learning Language in Logic ( LLL05 ) , Bonn , Germany 2005 , 31 - 37 .Sager N , Lyman M , Bucknall C , Nhan N , Tick L : Natural language processing and the representation of clinical data .", "label": "", "metadata": {}, "score": "68.323975"}
{"text": "FIG .1 is a block diagram of a language processing system .FIG .2 is a block diagram of an exemplary computing environment .FIG .3 is a block diagram of an exemplary speech recognition system .FIG .", "label": "", "metadata": {}, "score": "68.37486"}
{"text": "Using the Alpino server to parse a sentence is much faster than initializing a separate Alpino process for that purpose .Implementing an Alpino client is straightforward in most programming languages .For instance , the following defines a simple Alpino client in Python : .", "label": "", "metadata": {}, "score": "68.488815"}
{"text": "[ 0098 ] .Those sets for which the English translation is not the same as the English original remain in the confusion set database 505 .The confusion set can also be expanded by adding some typical confusion word pairs as defined in a text book 525 or existing in a personal collection 530 of confusing words .", "label": "", "metadata": {}, "score": "68.50041"}
{"text": "In the subsequence kernel , all substructures are equally counted .It does not matter whether the subsequence is continuous , non - continuous or how spread out the occurrences of subsequences are .Thus , the gap - weighted subsequence kernel is tested so as to reflect degree of the contiguity of the subsequence to the subsequence kernel .", "label": "", "metadata": {}, "score": "68.50706"}
{"text": "claim 6 and having instructions further comprising : . storing the identified text of the task independent corpus separate from the task independent corpus .The system of .claim 9 wherein building the second N - gram language model includes using only the identified text .", "label": "", "metadata": {}, "score": "68.51967"}
{"text": "0099 ] .[ 0099]FIG .6- 3 illustrates a method 600 of determining the user 's intentions by expands word pairs in the user 's query using the confusion set database 505 .As illustrated at 605 , the user 's query is received at an input component .", "label": "", "metadata": {}, "score": "68.53105"}
{"text": "claim 1 wherein the plurality of context - free grammars include at least one context - free grammar having a non - terminal token for a phrase that can be mistaken for one of the desired task dependent semantic or syntactic concepts .", "label": "", "metadata": {}, "score": "68.64258"}
{"text": "Consider a sample path through an ontology : .In this example , if the argument position of a predicate must be an example of transportation , then any of the three more - specific words will be an acceptable argument for the predicate .", "label": "", "metadata": {}, "score": "68.83543"}
{"text": "This representation also provides optimized execution of the difference comparison , since using hexadecimals instead of decimals optimizes the logical digit - by - digit comparison to a computer - efficient byte - by - byte comparison .It should also be noted that the above examples of decimal , hexadecimal , or multi - digit hexadecimal are typical parameter choices for the node encoding included in the present invention .", "label": "", "metadata": {}, "score": "68.96156"}
{"text": "Oxford Latin Dictionary .Oxford : Oxford University Press , 1968 - 1982 .Grozea 2004 Grozea , Christian .\" Finding Optimal Parameter Settings for High Performance Word Sense Disambiguation \" , Proceedings of Senseval-3 : Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text ( 2004 ) .", "label": "", "metadata": {}, "score": "69.0464"}
{"text": "Dunja Mladinic , Turning Yahoo into an Automatic Web Page Classifier , ECAI 98:13th European Conference on Artificial Intelligence , Brighton , UK , Aug. 23 to Aug. 28 , 1998 , pp .473 - 474 , John Wiley & Sons , Ltd. .", "label": "", "metadata": {}, "score": "69.0502"}
{"text": "Top - down language processing begins with the largest unit of language to be recognized , such as a sentence , and processes it by classifying it into smaller units , such as phrases , which in turn , are classified into yet smaller units , such as words .", "label": "", "metadata": {}, "score": "69.0518"}
{"text": "The values can also be changed in interactive mode using either the command interpreter or the graphical user interface .In the graphical user interface , documentation for each option is provided .Boolean flags have one of the values \" on \" or \" off \" .", "label": "", "metadata": {}, "score": "69.07477"}
{"text": "Similar features will have similar paths through the tree .Referring to .FIG .5 , an example is illustrated .Node A is represented with the decimal number \" 1212 . \"Node B is represented with the decimal number \" 1220 .", "label": "", "metadata": {}, "score": "69.08192"}
{"text": "claim 7 , wherein discarding dependency triples , from the plurality of dependency triples , which are not found in a dependency triples database to obtain the remaining dependency triples from the expanded terms further comprises : . searching the dependency triples database for matches with each of the plurality of dependency triples ; . determining which of the dependency triples do not have a match in the dependency triples database ; and . discarding dependency triples , from the plurality of dependency triples , which do not have a match in the dependency triples database .", "label": "", "metadata": {}, "score": "69.0954"}
{"text": "Preferably , the N - gram model having the non - terminal tokens and the second plurality of context - free grammars having non - terminal tokens representing task dependent semantic or syntactic concepts are stored on a computer readable medium accessible by the speech recognizer 100 .", "label": "", "metadata": {}, "score": "69.12804"}
{"text": "A proper noun is any word or phrase representing a non - generic noun concept .Although a number of proper nouns are already present in the lexicon , they are already properly treated as regular lexical items .Since proper nouns behave syntactically as regular nouns , there is no need to distinguish proper nouns and nouns already in the lexicon .", "label": "", "metadata": {}, "score": "69.25409"}
{"text": "4 is an example parse tree according to the present invention ; .FIG .5 is another example parse tree according to the present invention ; .FIG .6 is another example parse tree according to the present invention ; and .", "label": "", "metadata": {}, "score": "69.25781"}
{"text": "A if the relation is correct and biologically significant , but includes too much or too little information ( for example because an informative PP is not highlighted or a non informative PP is highlighted ) , treat as correct .P if the relation appears correct , but an anaphora needs to be resolved , treat as incorrect .", "label": "", "metadata": {}, "score": "69.25987"}
{"text": "The stop word filter will contain a set of words accepted as stop words ; any lexeme whose text is in that set is considered to be a stop word .An adjective filter serves to remove lexemes representing adjective concepts from sentences .", "label": "", "metadata": {}, "score": "69.27829"}
{"text": "Each relationship type is constrained to hold only between pairs of specific entity types , e.g. the has_location relation can hold only between a Condition and a Locus .Some relationships can hold between multiple type pairs .The full set of relationships and their argument types are shown in Table 1 , with a description and examples of each .", "label": "", "metadata": {}, "score": "69.380424"}
{"text": "As mentioned earlier , since nested entities have the same structural and contextual information but prediction results need to be different , they prevent a proper learning .This can be one reason for the low performance .Thus , we need to restrict either the longest NE or the shortest NE for performance improvement .", "label": "", "metadata": {}, "score": "69.44681"}
{"text": "claim 7 , wherein searching the sentence database using the remaining dependency triples as search parameters further comprises retrieving hint sentences from the sentence database using the remaining dependency triples as search parameters .A system for retrieving sentences from a sentence database in response to a query having terms , the system comprising : . an input component which receives the query as an input ; . a dependency triples database ; and .", "label": "", "metadata": {}, "score": "69.46273"}
{"text": "2006 Klosa , Annette , Ulrich Schn\u00f6rch , and Petra Storjohann .\" ELEXIKO - A Lexical and Lexicological , Corpus - based Hypertext Information System at the Institut f\u00fcr deutsche Sprache , Mannheim \" , Proceedings of the 12th Euralex International Congress ( 2006 ) .", "label": "", "metadata": {}, "score": "69.48632"}
{"text": "1993 Marcus , Mitchell P. , Beatrice Santorini , and Mary Ann Marcinkiewicz .\" Building a Large Annotated Corpus of English : The Penn Treebank \" , Computational Linguistics 19.2 ( 1993 ) .McCarthy et al .2004 McCarthy , Diana , Rob Koeling , Julie Weeds and John Carroll .", "label": "", "metadata": {}, "score": "69.52133"}
{"text": "A 10-digit decimal number allows 10 10 , or 10 billion possible concepts to be stored in the tree .That is a sufficient number of total concepts , but the branching factor is too small .There can be a maximum of ten possible branches out of each node to the next level .", "label": "", "metadata": {}, "score": "69.653694"}
{"text": "[ 0024 ] .The invention is operational with numerous other general purpose or special purpose computing system environments or configurations .[ 0025 ] .The invention may be described in the general context of computer - executable instructions , such as program modules , being executed by a computer .", "label": "", "metadata": {}, "score": "69.68876"}
{"text": "claim 1 , wherein discarding dependency triples , from the plurality of dependency triples , which are not found in a dependency triples database to obtain the remaining dependency triples from the expanded terms further comprises : . searching the dependency triples database for matches with each of the plurality of dependency triples ; . determining which of the dependency triples do not have a match in the dependency triples database ; and . discarding dependency triples , from the plurality of dependency triples , which do not have a match in the dependency triples database .", "label": "", "metadata": {}, "score": "69.69461"}
{"text": "You have an UTF-8 locale ( invoke the locale command to verify this ) .Inititializing Tcl / Tk will change the process locale from the default \" C \" locale to whatever locale is inherited from the environment .I.e. when Tcl / Tk is initialized the process locale becomes the UTF-8 locale in ( 1 ) .", "label": "", "metadata": {}, "score": "69.702805"}
{"text": "The kernels consider both lexical shortest path string and syntactic shortest path string .We gradually enlarge the kernels to perform a more comprehensive comparison between the two shortest path strings , from the spectrum kernel to the weighted subsequence kernel .", "label": "", "metadata": {}, "score": "69.81389"}
{"text": "Alpino supports the UTF-8 encoding .Here are some properly tokenized sentences : .Dat is nog niet duidelijk . 'We zien hier niet het breken van tandenstokers .Dodelijke wapens worden gesloopt . 'Slechts enkele nieuwe documenten zijn aan het licht gekomen . '", "label": "", "metadata": {}, "score": "69.86789"}
{"text": "Aspects of the present invention are implemented in the search engine component 315 as is described below .However , certain aspects of the present invention can be implemented in query processing component 310 in other embodiments .Notice that although the invention is described in the context of Chinese and English , the invention is language independent and can be extended easily to other languages .", "label": "", "metadata": {}, "score": "69.903625"}
{"text": "If a node is a predicate , then it has a close connection with the sub - categorization information which is important in semantic role labeling task for discovering the predicate - argument structure for a given sentence .In Figure 2c , the e -walk of \" sub(UP)-control - comp_by ( DN ) \" shows the argument structure of the predicate verb , \" control \" .", "label": "", "metadata": {}, "score": "69.93842"}
{"text": "If this does n't help , send a bug - report to the author .Please .Tokenization .The sentences that you give to Alpino are assumed to be already tokenized : a single sentence on a line , and each token ( word ) separated by a single space .", "label": "", "metadata": {}, "score": "69.97096"}
{"text": "Details about the corpora and their characteristics can be found in [ 18 ] .Examples of Typed Dependencies .The dependency information considered in the converted corpora by [ 18 ] is shown .The entity , \" calcium - sensing receptor \" forms separate tokens .", "label": "", "metadata": {}, "score": "70.04645"}
{"text": "In the example used herein , corpus 510 is an English - Chinese bilingual corpus .This alignment is possible because the correct translations were readily available in the original bilingual corpus .At this point , sets of word pairs are defined which correlate , for a particular Chinese word pair , the English translation to the English original word pair(correct translation word pair as defined by its alignment in the bilingual corpus ) : . [", "label": "", "metadata": {}, "score": "70.09326"}
{"text": "The N - gram language model 142 will be used to first predict words and non - terminals .Then , if a non - terminal has been predicted , the plurality of context - free grammars 144 is used to predict terminals as a function of the non - terminals .", "label": "", "metadata": {}, "score": "70.14417"}
{"text": "Table 9 provides a summary of the key performance figures for the overall system , showing results for the best system configuration using only non - syntactic features ( notok ) and for the best one using syntactic features ( + syndist ) .", "label": "", "metadata": {}, "score": "70.23839"}
{"text": "Equation ._ .In addition to , or instead of , using a baseline approach to sentence retrieval such as the one described above , search engine 315 builds upon that approach by using an NLP - enabled cross language information retrieval method or approach .", "label": "", "metadata": {}, "score": "70.278725"}
{"text": "Information overload is one of the most widely felt problems in our modern society .Individuals have access to a previously unimaginable flood of new information and professionals are confronted in their daily activities with a cornucopia of relevant results .Especially for biomedical scientific literature , there is a pressing need for an efficient approach to access and extract information , in a format that can be easily assimilated by humans or further processed by other automated tools .", "label": "", "metadata": {}, "score": "70.35927"}
{"text": "Referring to .FIG .4 , a unified language model 140 includes a combination of an N - gram language model 142 and a plurality of context - free grammars 144 .Specifically , the N - gram language model 142 includes at least some of the same non - terminals of the plurality of context - free grammars 144 embedded therein such that in addition to predicting words , the N - gram language model 142 also can predict non - terminals . where ( h 1 , h 2 , . . .", "label": "", "metadata": {}, "score": "70.41924"}
{"text": "Figure 4 shows some interaction examples containing embedded entities .In Figure 4a , the longest entity is the interactive entity .On the contrary , in Figure 4b , the embedded ( shortest ) entity is involved in the interaction .", "label": "", "metadata": {}, "score": "70.43393"}
{"text": "The table also provides scores for a baseline approach ( to be detailed shortly ) and for inter - annotator agreement , in both IAA and CIAA variants .In contrast , CIAA scores are fairly close to , and mostly above , the system scores ( the sole exception being a + syndist system score for has_target that is 1 % above CIAA ) .", "label": "", "metadata": {}, "score": "70.440735"}
{"text": "Section \" Related Work \" surveys related work .We conclude by describing plans for future work in section \" Conclusions and Future Work \" .Methods : Corpus analysis .The base abstracts were selected from Medline using the keywords \" Human \" , \" Blood Cells \" , and \" Transcription Factors \" .", "label": "", "metadata": {}, "score": "70.4627"}
{"text": "i 2 . . .u t .A CFG state constrains the possible words that can follow the history .u t .i 1 u t .i 2 . . .u t .The likelihood of observing u t .", "label": "", "metadata": {}, "score": "70.50304"}
{"text": "As appreciated by those skilled in the art , the language model 16 can be used in other language processing systems besides the speech recognition system discussed above .For instance , language models of the type described above can be used in handwriting recognition , Optical Character Recognition ( OCR ) , spell - checkers , language translation , input of Chinese or Japanese characters using standard PC keyboard , or input of English words using a telephone keypad .", "label": "", "metadata": {}, "score": "70.77087"}
{"text": "The noun must follow either immediately after the adjective , or have only adjective and conjunction words appearing between the noun and the adjective .If no such noun or conjunction is found , the adjective filter will veto the sentence .", "label": "", "metadata": {}, "score": "70.8316"}
{"text": "In this case the U+2018 and U+2019 characters are just treated as any other lower case characters and they are parsed as part of the longer atoms .So , the SICStus bug is that character classification is affected by the process locale .", "label": "", "metadata": {}, "score": "70.90433"}
{"text": "Although described herein where the speech recognition system 100 uses HMM modeling and senone trees , it should be understood that this is but one illustrative embodiment .As appreciated by those skilled in the art , the speech recognition system 100 can take many forms and all that is required is that it uses the language model 16 and provides as an output the text spoken by the user .", "label": "", "metadata": {}, "score": "70.94258"}
{"text": "BACKGROUND OF THE INVENTION .[0002 ] .The present invention relates to machine aided writing systems and methods .In particular , the present invention relates to systems and methods for aiding users in writing in non - native languages .", "label": "", "metadata": {}, "score": "71.004974"}
{"text": "Consequently , ten is too small to constrain the branching factor for each level .The use of a hexadecimal representation would improve this some by increasing the branching factor to 16 .Thus , using a 16-digit ( i.e. , a 64-bit ) hexadecimal number gives 16 branches at each node for 16 levels : 16 16 possible concepts .", "label": "", "metadata": {}, "score": "71.05048"}
{"text": "Digital methods also let us deal well with scale .For instance , while the OLD focused on a canon of Classical authors that ends around the second century CE , Latin continued to be a productive language for the ensuing two millennia , with prolific writers in the Middle Ages , Renaissance and beyond .", "label": "", "metadata": {}, "score": "71.051254"}
{"text": "Studies in Honour of Jarmila Panevov\u00e1 .Prague : Charles University Press , 1999 .Kilgarriff et al .2004 Kilgarriff , Adam , Pavel Rychly , Pavel Smrz , and David Tugwell . \"The Sketch Engine \" , Proceedings of EURALEX ( 2004 ) .", "label": "", "metadata": {}, "score": "71.0975"}
{"text": "4 .Each arrowhead in .FIG .4 represents a concept node .The deeper into the tree ( i.e. , the higher the numbered level of the concept node ) , the more specific the concept is .Consider one path through FIG .", "label": "", "metadata": {}, "score": "71.13508"}
{"text": "By way of example , steps 460 and 465 are shown with respect to the Chinese and English languages .However , it must be noted that these steps are not limited to any particular first and second languages .[ 0094 ] .", "label": "", "metadata": {}, "score": "71.24241"}
{"text": "In that case , the kernel is equivalent to the fixed length subsequence kernel that identically counts all common subsequences as 1 .As a result , the F - score ( 70.2 ) was lower than the subsequence kernel even though this kernel can offer a more comprehensive weighting scheme depending on the dependency distance of each subsequence .", "label": "", "metadata": {}, "score": "71.25778"}
{"text": "[ 0112]FIG .8 is a block diagram illustrating an embodiment 315 - 1 of search engine 315 which includes the various confirming and hint sentence retrieval concepts disclosed herein .Therefore , the search engine of the present invention must be understood to include every combination of the above - described features .", "label": "", "metadata": {}, "score": "71.49295"}
{"text": "PhD thesis University of Pennsylvania , Philadelphia , USA 1999 .Marcus M , Santorini B , Marcinkiewicz M : Building a Large Annotated Corpus of English : the Penn Treebank .Computational Linguistics 1993 , 19 : 313 - 330 .", "label": "", "metadata": {}, "score": "71.60432"}
{"text": "In a nominalization ( e.g. \" The inhibition of B by A \" ) the relation is expressed by a relational noun , while the two arguments are expressed by prepositional - phrase attachments .The argument A will be referred to as the agent , B as the target , adopting the terminology used in [ 21 ] .", "label": "", "metadata": {}, "score": "71.64258"}
{"text": "2 .Furthermore , the tree search engine 114 is implemented in processing unit 51 ( which can include one or more processors ) or can be performed by a dedicated speech recognition processor employed by the personal computer 50 .In the embodiment illustrated , during speech recognition , speech is provided as an input into the system 100 in the form of an audible voice signal by the user to the microphone 92 .", "label": "", "metadata": {}, "score": "71.90202"}
{"text": "alpino_end_hook(Key , Sentence , Status , NumberOfSolutions ) .is called after the parser has found all solutions .NumberOfSolutions is an integer indicating the number of solutions .Status is an atom indicating whether parsing was successful , or not .", "label": "", "metadata": {}, "score": "71.94176"}
{"text": "P .w . )T .S .W . )P .W .T . )Although the present invention has been described with reference to preferred embodiments , workers skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention .", "label": "", "metadata": {}, "score": "71.95925"}
{"text": "6- 3 , while a method of constructing the confusion set database is illustrated in FIG .6- 2 .A confusion set is a database containing word pairs that are confusing , such as \" open / turn on \" .", "label": "", "metadata": {}, "score": "72.05443"}
{"text": "dep(prep , X3 , By ) , pos(X2 , ' VBN ' ) , .lemma(By , [ ' by ' , ' through ' , ' via ' ] ) ] ) .Syntactic rules capture general linguistic phenomena and as such are highly reusable across different domains .", "label": "", "metadata": {}, "score": "72.13501"}
{"text": "[ 0021]FIG .8 is a block diagram illustrating one embodiment of the search engine shown in FIG .3 . DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS .[ 0022 ] .The present invention provides an effective system which helps users write in a non - native language and polish their sentences by referring to suggestive sentences .", "label": "", "metadata": {}, "score": "72.19174"}
{"text": "claim 15 wherein the word language model comprises an N - gram language model and wherein the corpus comprises a task independent corpus .The system of .claim 16 and having instructions further comprising : . generating word phrases from the plurality of context - free grammars ; . formulating an information retrieval query from at least one of the word phrases ; . querying the task independent corpus based on the query formulated ; . identifying associated text in the task independent corpus based on the query ; and . wherein building a N - gram language model includes using the identified text .", "label": "", "metadata": {}, "score": "72.23537"}
{"text": "As a result , the F - score was improved from 60.4 to 69.4 on LLL dataset ( Table 3 ) , compared with the previous dependency kernel .The uses of partial path match and subcategorization information were helpful but the result is still worse than that by the walk kernel .", "label": "", "metadata": {}, "score": "72.308014"}
{"text": "We called it v -walk .Likewise , we defined e -walk which starts and ends with an edge , e i , i+1 , v i+1 , e i+1 , i+2 .It is actually not a walk defined in the graph theory , but we take e -walk to capture contextual syntactic structures as well .", "label": "", "metadata": {}, "score": "72.478935"}
{"text": "Classics has arguably the most well - curated collection of texts in the world , and the uses its scholars demand from that collection are unique .In the following I will document the technologies available to us in creating a new kind of reference work for the future - one that complements the traditional lexicography exemplified by the OLD and the TLL and lets scholars interact with their texts in new and exciting ways .", "label": "", "metadata": {}, "score": "72.586975"}
{"text": "Declarations .Acknowledgements .This work is supported by the BK21 program of the Ministry of Education and Basic Science Research Program through the National Research Foundation of Korea ( NRF ) funded by the Ministry of Education , Science and Technology ( 2009 - 0070211 ) .", "label": "", "metadata": {}, "score": "72.60033"}
{"text": "With the rapid development of global communications , the ability to write in English and other non - native languages is becoming more important .However , non - native speakers ( for example , people who speak Chinese , Japanese , Korean or other non - English languages ) often find it very difficult to write in English .", "label": "", "metadata": {}, "score": "72.60865"}
{"text": "How do we get there ?We have already begun work on a dynamic lexicon like that shown in Figure 1 [ Bamman and Crane 2008 ] .Our approach is to use already established methods in natural language processing ; as such , our methodology involves the application of three core technologies : . identifying word senses from parallel texts ; . locating the correct sense for a word using contextual information ; and .", "label": "", "metadata": {}, "score": "72.658844"}
{"text": "f .Li . )Equation ._ .Sim .D .i .Q .j . ) k .d . ik . q . jk . )W . jk .Equation ._ .In system 300 , search engine 315 improves hint sentence retrieval using a query expansion method of the present invention .", "label": "", "metadata": {}, "score": "72.714935"}
{"text": "Classics , however , is only one field among many concerned with the technologies underlying lexicography , and by relying on the techniques of other disciplines like computational linguistics and computer science , we can count on the future progress of disciplines far outside our own .", "label": "", "metadata": {}, "score": "72.807884"}
{"text": "Addition of the str features also give good improvement in most metrics , again 10 % F 1 overall .Addition of part - of - speech information , in the form of pos features , however , leads to a drop in some metrics , overall F 1 dropping by 1 % .", "label": "", "metadata": {}, "score": "72.880325"}
{"text": "Competing interests .The authors declare that they have no competing interests .Authors ' contributions .AR designed and built the system using the GATE framework , wrote most of the new components , prepared the data , contributed to evaluation tests , and drafted the manuscript .", "label": "", "metadata": {}, "score": "72.974335"}
{"text": "Banerjee and Pedersen 2002 Banerjee , Sid and Ted Pedersen . \"An Adapted Lesk Algorithm for Word Sense Disambiguation Using WordNet \" , Proceedings of the Conference on Computational Linguistics and Intelligent Text Processing ( 2002 ) .Bourne 1916 Bourne , Ella . \"", "label": "", "metadata": {}, "score": "73.00194"}
{"text": "This query returns all the relations where \" NF - kappa B \" is involved as a target ( e.g. \" In T cells , NF - kappa B is activated upon cellular treatment by phorbol esters and the cytokine tumor necrosis factor alpha . \" )", "label": "", "metadata": {}, "score": "73.027695"}
{"text": "In some embodiments of the present invention , search engine 315 is designed to detect the user 's intention before searching the sentence database for hint sentences .The search engine can detect the user 's intention using either or both of two methods .", "label": "", "metadata": {}, "score": "73.12565"}
{"text": "Het model ( grammatica ) beschrijft bijvoorbeeld de mogelijke uitingen van het Nederlands en hun bijbehorende betekenis . Zo'n model beschrijft dus ( onder andere ) de relatie tussen vorm en betekenis .Een belangrijke vraag in de computationele taalkunde is vervolgens hoe je deze relatie algoritmisch kunt bepalen .", "label": "", "metadata": {}, "score": "73.13967"}
{"text": "As technology advances and speech and handwriting recognition is provided in more applications , the application developer must be provided with an efficient method in which an appropriate language model can be created for the selected application .SUMMARY OF THE INVENTION .", "label": "", "metadata": {}, "score": "73.292244"}
{"text": "A Systematic Comparison of Various Statistical Alignment Models \" , Computational Linguistics 29.1 ( 2003 ) .Pinkster 1990 Pinkster , Harm .Latin Syntax and Semantics .London : Routledge , 1990 .Sch\u00fctz 1895 Sch\u00fctz , Ludwig .Thomas - Lexikon .", "label": "", "metadata": {}, "score": "73.448074"}
{"text": "Busa 1974 - 1980 Busa , Roberto .Index Thomisticus : sancti Thomae Aquinatis operum omnium indices et concordantiae , in quibus verborum omnium et singulorum formae et lemmata cum suis frequentiis et contextibus variis modis referuntur quaeque / consociata plurium opera atque electronico IBM automato usus digessit Robertus Busa SI .", "label": "", "metadata": {}, "score": "73.46298"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .[ 0011 ] .[ 0011]FIG .1 is a block diagram of one computing environment in which the present invention may be practiced .[ 0012 ] .[ 0012]FIG .2 is a block diagram of an alternative computing environment in which the present invention may be practiced .", "label": "", "metadata": {}, "score": "73.61201"}
{"text": "Modifiers are words that qualify an entity in some way , referring e.g. to the laterality of an anatomical locus , or the negation of a condition ( \" no sign of in ammation \" ) .Entities are connected to each other and to modifiers by relationships : e.g. linking a drug entity to the condition entity for which it is indicated , linking an investigation to its results , or a negating phrase to a condition .", "label": "", "metadata": {}, "score": "73.62091"}
{"text": "Automatic Sense Disambiguation Using Machine Readable Dictionaries : How to Tell a Pine Cone from an Ice Cream Cone \" , Proceedings of the ACM - SIGDOC Conference ( 1986 ) .Lewis and Short 1879 Lewis , Charles T. and Charles Short ( eds . )", "label": "", "metadata": {}, "score": "73.69972"}
{"text": "Integer which determines during unpacking the how many best analyses are kept for each ' maximal projection ' .A larger value will imply slower and more accurate processing .The value 0 is special : in that case the system performs a full search ( hence maximal accuracy and minimal speed ) .", "label": "", "metadata": {}, "score": "73.706085"}
{"text": "Relates a bodily locus or intervention to its sidedness : right , left , bilateral .Relates a bodily locus to other information about the location : upper , lower , extra , etc . .Relationship types , their argument type constraints , a description and examples .", "label": "", "metadata": {}, "score": "73.73824"}
{"text": "Tile common practice for approaching this task is by tedious manual definition of possible pat - tern structures , often in the h)rm of re ... \" .Tile common practice for approaching this task is by tedious manual definition of possible pat - tern structures , often in the h)rm of regular expres - sions or finite automata .", "label": "", "metadata": {}, "score": "73.74141"}
{"text": "In addition , other input / output devices may be attached to or found with mobile device 200 within the scope of the present invention .[ 0039 ] .In accordance with various aspects of the present invention , proposed are methods and systems which provide practical tools for assisting English writing for non - natives .", "label": "", "metadata": {}, "score": "73.90504"}
{"text": "Despite such an improvement over a decimal representation , the branching factor of only 16 is still unacceptably small .A solution to this is to use a modified hexadecimal representation .Since it is unlikely that a reasonable , specialized ontology will need more than eight levels of general concept representation , a 16-digit hexadecimal number can be interpreted slightly differently , as an octet of hexadecimal pairs : .", "label": "", "metadata": {}, "score": "74.028366"}
{"text": "The user 's input will be handled as a query to the search engine 315 .The search engine searches the sentence base 320 to find relevant sentences .The relevant sentences are categorized into two classes : confirming sentences and hint sentences .", "label": "", "metadata": {}, "score": "74.04783"}
{"text": "claim 9 , wherein adding synonyms of at least some of the terms of the query further comprises adding the synonyms to the terms of the query such that the expanded terms include the synonyms and the terms of the query .", "label": "", "metadata": {}, "score": "74.19667"}
{"text": "We included all embedded entities in the training and test data for comparisons with other systems .Embedded Entities .Some interaction examples are given regarding embedded entities .a ) the longest entity is the interactive entity , b ) the embedded entity is involved in the interaction .", "label": "", "metadata": {}, "score": "74.243866"}
{"text": "In the case of an N - gram language model or a hybrid N - gram language model , step 212 will commonly require use of an N - gram algorithm .FIG .8 illustrates a method 220 similar to the method 200 of .", "label": "", "metadata": {}, "score": "74.33438"}
{"text": "1 include a local area network ( LAN ) 171 and a wide area network ( WAN ) 173 , but may also include other networks .Such networking environments are commonplace in offices , enterprise - wide computer networks , intranets and the Internet .", "label": "", "metadata": {}, "score": "74.40207"}
{"text": "Default values should give good performance .user_max .This flag takes a numberical value which is then used as the maximum number of milliseconds that the system is given for each sentence .So , if the value is set to 60000 , then if a parse for a given sentence requires more than a minute of CPU - time , that parse is aborted .", "label": "", "metadata": {}, "score": "74.41761"}
{"text": "In the past thirty years , computers have allowed this process to be significantly expedited , even in such simple ways as textual searching .This approach has been exploited most recently by the Greek Lexicon Project [ 2 ] at the University of Cambridge , which has been developing a New Greek Lexicon since 1998 using a large database of electronically compiled slips ( with a target completion date of 2010 ) .", "label": "", "metadata": {}, "score": "74.65631"}
{"text": "The \" scholarship of thirty years ago \" that Lewis and Short here distance themselves from is Andrews ' 1850 Latin - English lexicon , itself largely a translation of Freund 's German W\u00f6rterbuch published only a decade before .Founded on the same lexicographic principles that produced the juggernaut Oxford English Dictionary , the OLD is a testament to the extraordinary results that rigorous manual labor can provide .", "label": "", "metadata": {}, "score": "74.72752"}
{"text": "As shown at 475 and corresponding to step 460 , the Chinese - like English query is translated into the Chinese query \" .Then , as shown at 480 corresponding to step 465 , the Chinese query is translated back into the English language query \" Turn on the light , \" which does not contain the collocation mistake of the original query .", "label": "", "metadata": {}, "score": "74.74626"}
{"text": "Figure 7 shows some types of false positive interactions that remain to be filtered out .In Figure 7a , the pair of \" phosphatidylinositol ( PI ) 3-kinase \" and \" CD5 \" actually has no relation but our system recognized it as an interaction pair because of the substructure of \" interacts / VBZ_PRED prep_with(DN ) \" .", "label": "", "metadata": {}, "score": "74.74709"}
{"text": "A search engine expands the query by including synonyms of the terms to obtain expanded terms .10247684 , 247684 , US 2004/0059564 A1 , US 2004/059564 A1 , US 20040059564 A1 , US 20040059564A1 , US 2004059564 A1 , US 2004059564A1 , US - A1 - 20040059564 , US - A1 - 2004059564 , US2004/0059564A1 , US2004/059564A1 , US20040059564 A1 , US20040059564A1 , US2004059564 A1 , US2004059564A1 .", "label": "", "metadata": {}, "score": "74.78935"}
{"text": "Description .CROSS - REFERENCE TO RELATED APPLICATIONS .[ 0001 ] .Reference is hereby made to the following co - pending and commonly assigned patent applications filed on even date herewith : U.S. application Ser .No . _ _ _ _ _ _ entitled \" METHOD AND SYSTEM FOR DETECTING USER INTENTIONS IN RETRIEVAL OF HINT SENTENCES \" for inventor Ming Zhou and U.S. application Ser .", "label": "", "metadata": {}, "score": "74.86624"}
{"text": "CROSS - REFERENCE TO RELATED APPLICATION .The present application is a continuation of and claims priority of U.S. patent application Ser .No .09/585,298 , filed Jun. 1 , 2000 , the content of which is hereby incorporated by reference in its entirety .", "label": "", "metadata": {}, "score": "74.92069"}
{"text": "For example , consider a tree shown in FIG .7 .It is clear that in some cases , it is useful to know the distance between words , but that it is not equally useful in all cases .However , since neither of these terms shares any properties beyond \" organic \" with \" amino acid , \" it is not helpful to know the distance between \" bread \" and \" amino acid , \" even though they are only one level apart .", "label": "", "metadata": {}, "score": "75.19278"}
{"text": "The path starts at the root node ( Level 1 ) and takes the 2nd branch to level 2 , then takes the 3rd branch from that node to get to level 3 .The final \" 0 \" is a terminator , indicating that this particular node of the tree is not at the lowest possible level of the tree ; it does not necessarily indicate that no nodes branch from this level .", "label": "", "metadata": {}, "score": "75.22148"}
{"text": "The Perseus Digital Library contains at least one English translation for most of its Latin and Greek prose and poetry source texts .Many of these translations are encoded under the same canonical citation scheme as their source , but must further be aligned at the sentence and word level before individual word translation probabilities can be calculated .", "label": "", "metadata": {}, "score": "75.2829"}
{"text": "The feature extraction module 106 divides the digital signal received from the A / D converter 104 into frames that include a plurality of digital samples .Each frame is approximately 10 milliseconds in duration .The frames are then encoded by the feature extraction module 106 into a feature vector reflecting the spectral characteristics for a plurality of frequency bands .", "label": "", "metadata": {}, "score": "75.33468"}
{"text": "One of the advantages of the Novartis annotator is that it is built on a huge terminology with more than 1 Million terms .The terms contain gene names , targets , modes of action , diseases , geographic locations , products and companies .", "label": "", "metadata": {}, "score": "75.456665"}
{"text": "Next , we treat the shortest path strings as strings and introduce some string kernels such as the spectrum kernel , subsequence kernel and gap weighted kernel .Finally , we suggest the walk weighted subsequence kernel , which can model not only the previous problems , but also non - contiguous structures and structural importance not covered by the previous kernels .", "label": "", "metadata": {}, "score": "75.583405"}
{"text": "claim 9 and having instructions further comprising : . parsing the identified text of the task independent corpus with the plurality of context - free grammars to identify word occurrences for each of the semantic or syntactic concepts ; . replacing each of the identified word occurrences with corresponding non - terminal tokens ; and .", "label": "", "metadata": {}, "score": "75.73981"}
{"text": "Pisa , Italy : ECML / PKDD 2004 , 11 - 18 .Kaljurand K , Rinaldi F , Schneider G : Prolog - based query interface to syntactic dependencies extracted from biomedical literature .Tech rep IFI , University of Zurich 2006 .", "label": "", "metadata": {}, "score": "75.94374"}
{"text": "The present invention relates to language modeling .More particularly , the present invention relates to creating a language model for a language processing system .Accurate speech recognition requires more than just an acoustic model to select the correct word spoken by the user .", "label": "", "metadata": {}, "score": "75.98192"}
{"text": "Known Issues .Alpino assumes that your input is in UTF8 .There is a problem if you run Alpino with the graphical user interface , and you attempt to parse sentences through the command interpreter ( either the Hdrug / Alpino command interpreter , or the standard Prolog command interpreter ) .", "label": "", "metadata": {}, "score": "76.024124"}
{"text": "The feature sets allgen and notok are combinations of the above feature sets , as specified by the descriptions in Table 3 .For the final two feature sets shown in Table 3 , we used the Stanford Parser [ 39 ] to parse the C77 corpus .", "label": "", "metadata": {}, "score": "76.12485"}
{"text": "end_hook .Perhaps the most important flag is the end_hook flag which determines what the system should do with a parse that it has found .Typically this involves printing certain information concerning the parse to standard error , standard output or a file .", "label": "", "metadata": {}, "score": "76.13391"}
{"text": "Typed dependencies det(sun-3 , The-1 ) amod(sun-3 , yellow-2 )Typed dependencies , collapsed det(sun-3 , The-1 ) amod(sun-3 , yellow-2 ) .From your question it sounds like you 're interested in the typed dependencies .Well , Chomsky has done stuff with theory of computation , esp with classifying types of languages ( regular , context - free , etc ) , and he revolutionized NLP back in the 60 's , I would n't really recommend him as a starting point for this task .", "label": "", "metadata": {}, "score": "76.16527"}
{"text": "claim 22 , wherein said parser filters include a selectional restriction filter and a parse probability filter .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 23 , wherein said selectional restriction filter vetoes parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .", "label": "", "metadata": {}, "score": "76.177734"}
{"text": "The binary file depends on the Tcl / Tk libraries as well as a number of system libraries .The specific dependencies of the current release are as follows ( subject to change ) : . linux - vdso . so.1 libstdc++ .", "label": "", "metadata": {}, "score": "76.287506"}
{"text": "Reduce actions cause the parser to finish the current production and replace the assembled symbols with the symbol that replaces them ; .Accepts cause the parser to finish assembling a complete parse tree and halt ; .Errors cause the parser to give up because no grammar rule is available to reconcile what has already been parsed with what remains in the input stream .", "label": "", "metadata": {}, "score": "76.41722"}
{"text": "Several heuristics apply to limit the search space .Flags ( global variables ) .There are ( way too ) many global variables ( called flags ) which will alter the behavior of Alpino .These flags typically already have a default value .", "label": "", "metadata": {}, "score": "76.42404"}
{"text": "Such identifiers are set using the current_ref Hdrug flag .The hook predicate .alpino_result_hook(Key , Sentence , No , Result ) .is called for each parse .Key and Sentence are as before , No is an integer indicating the number of the parse ( parses for a given sentence are numbered from 1 to n ) , and Result is an internal representation of the full parse itself .", "label": "", "metadata": {}, "score": "76.443245"}
{"text": "Affiliated with .Affiliated with .Affiliated with .Abstract .Background .The biomedical domain is witnessing a rapid growth of the amount of published scientific results , which makes it increasingly difficult to filter the core information .There is a real need for support tools that ' digest ' the published results and extract the most important information .", "label": "", "metadata": {}, "score": "76.69237"}
{"text": "This allows us to provide translation equivalents for idioms and common phrases such as res publica ( republic ) or gratias ago ( to give thanks ) .Corpus methods ( especially supervised methods ) generally perform best in the SENSEVAL competitions - at SENSEVAL-3 , the best system achieved an accuracy of 72.9 % in the English lexical sample task and 65.1 % in the English all - words task .", "label": "", "metadata": {}, "score": "76.83329"}
{"text": "Two rules are included in this example of a pseudo - concept filter implementation .The first rule is that any word relating to the user , or his current situation , such as \" I \" or \" me \" is always deleted .", "label": "", "metadata": {}, "score": "76.918945"}
{"text": "The 8 event categories such as gene expression , transcription , protein catablolism , phoshorylation , localization , binding , and regulation were considered and the best result in the task was 51.59 % ( F - score ) .Data representation .", "label": "", "metadata": {}, "score": "77.075516"}
{"text": "Similar to the lexer filters 150 , the parser filters 250 may be chained together to form a list of filters to be applied to each candidate parse tree .Each parser filter 250 will keep track of the filter that should be applied immediately before it , and will submit candidate parse trees to that filter before performing a filtering function .", "label": "", "metadata": {}, "score": "77.13562"}
{"text": "claim 1 , wherein searching the sentence database using the remaining dependency triples as search parameters further comprises retrieving hint sentences from the sentence database using the remaining dependency triples as search parameters .A computer - readable medium having computer - executable instructions for performing steps comprising : . receiving the query having terms ; . expanding the query by including synonyms of the terms to obtain expanded terms ; . combining the expanded terms to form a plurality of dependency triples from the expanded terms ; . discarding dependency triples , from the plurality of dependency triples , which are not found in a dependency triples database to obtain remaining dependency triples from the expanded terms ; and . searching the sentence database using the remaining dependency triples as search parameters .", "label": "", "metadata": {}, "score": "77.20095"}
{"text": "Integer ( typically 0 , 1 or 2 ) which determines the number and detail of debug and continuation messages .demo .Boolean flag which determines if a visual impression of the parse is produced ( either to standard output , or the graphical interface if it is running ) .", "label": "", "metadata": {}, "score": "77.28104"}
{"text": "For instance : .It follows that the vertical bar is a special character that is supposed to be not part of the sentence in case there is not an identifier .Lines which start with a percentage sign are ignored : the percentage sign is used to introduce comments : .", "label": "", "metadata": {}, "score": "77.81203"}
{"text": "Het PIONIER onderzoek richt zich hierbij op twee fundamentele problemen : ambiguiteit en efficientie .Het tweede probleem behelst de efficientie van de verwerking .Voor de modellen die tot nu toe worden opgesteld kan worden aangetoond dat de verwerkingstijd polynomiaal ( soms zelfs exponentieel ) zou moeten toenemen bij het toenemen van de lengte van de uiting .", "label": "", "metadata": {}, "score": "77.91145"}
{"text": "[ 0064 ] .Extended Indexing Terms .[0065 ] .Using conventional IR approaches , the search engine 315 would search sentence base 320 using only the lemma of the input query to define indexing units for the search .", "label": "", "metadata": {}, "score": "78.178116"}
{"text": "Lexer filters 150 are modular plug - ins , which modify sentences based on knowledge about word meanings .The preferred embodiment contains several filters 150 , although more may be developed , and existing filters may be removed from future versions , without altering the scope of the invention .", "label": "", "metadata": {}, "score": "78.19568"}
{"text": "Even within a given time frame , spelling can vary , especially from poetry to prose .By allowing users to search for a sense rather than a specific word form , we can return all passages containing saeculum , saeclum , seculum and seclum - all valid forms for era .", "label": "", "metadata": {}, "score": "78.40704"}
{"text": "Thus , for example , the node to Node A 's immediate left , is represented by \" 1211 .\" When the difference comparison is made , it works out to be \" 0001 , \" which implies a correspondingly close ontological relationship between the two concepts .", "label": "", "metadata": {}, "score": "78.59036"}
{"text": "Despite the positive aspect of the subsequence that it considers non - contiguous subsequences as well as contiguous substrings , the performance was not satisfactory .It has improved over the spectrum kernel to some extent , but it was the same value with the walk kernel as F - score 77.5 on LLL which showed the best result in our previous study .", "label": "", "metadata": {}, "score": "78.68727"}
{"text": "Example : .This yields : .Special symbols in the input .The following symbols which might occur in input lines are special for Alpino : .Only the first occurrence of a vertical bar on a given line is special .", "label": "", "metadata": {}, "score": "78.77126"}
{"text": "Other input devices ( not shown ) can include a joystick , game pad , satellite dish , scanner , or the like .A monitor 77 or other type of display device is also connected to the system bus 53 via an interface , such as a video adapter 78 .", "label": "", "metadata": {}, "score": "78.90759"}
{"text": "Only makes sense for interactive operation .-notk .Do not use the graphical user interface .-cmd Goal .Evaluates Prolog Goal ; Goal is parsed as Prolog term . -l File .Loads the Prolog file , using the Prolog goal use_module(File ) .", "label": "", "metadata": {}, "score": "79.03412"}
{"text": "The labels of all NE pair instances are represented in word order with \" TA \" ( target - agent ) , \" AT \" ( agent - target ) and \" O \" ( no interaction ) .Figure 2e shows some instances derived from the sentence Figure 2a .", "label": "", "metadata": {}, "score": "79.41874"}
{"text": "Typically you need a recent version ;-) .tcl / tk .libxml2 . libxslt .python2 .python2 library libxml2 .python2 library libxslt . dictzip ( sometimes packaged with dictd ) .libpopt . libz .Running Alpino .In other that you can use Alpino and the related tools , you need to define your ALPINO_HOME environment variable .", "label": "", "metadata": {}, "score": "79.45079"}
{"text": "Typing \" halt .\" to the Prolog command - line reader will return to the state before control - P was typed .If you need to parse a line starting with a % -sign , then the easiest solution is to use a key ( for interactive usage , perhaps use the empty key ) : .", "label": "", "metadata": {}, "score": "79.66701"}
{"text": "Alpino Hooks .Note that Alpino currently is not really implemented as a Prolog library .Yet , you might find it useful to know that you can call the Alpino parser from Prolog using the following two predicates : .alpino_parse_line(Ref , String ) alpino_parse_tokens(Ref , Tokens ) .", "label": "", "metadata": {}, "score": "79.67471"}
{"text": "This would add 8 bytes of total storage to each node in the tree .For a 10,000-concept tree , this is only 80 KB .For a 100,000-concept tree , it is 800 KB .And for a 1,000,000-concept tree , it is 8 MB .", "label": "", "metadata": {}, "score": "79.86969"}
{"text": "This is described below .The percentage sign is only special if it is the first character of a line .In that case the line is treated as a comment , and is ignored .A line only consisting of ^P ( control - P ) is treated as an instruction to escape to the Prolog command - line interface .", "label": "", "metadata": {}, "score": "80.0777"}
{"text": "Of course , the resulting dependency structure may need adjusting with the editor afterwards .Hij heeft een beetje [ @postag adjective(both(nonadv ) ) curly ] haar .Op een [ @postag adjective(e ) mgooie ] dag gingen ze fietsen .Mijn [ @postag proper_name(sg,'MISC ' ) body mass index ] laat te wensen over .", "label": "", "metadata": {}, "score": "80.08046"}
{"text": "Of necessity , these citations are usually only exemplary selections , though the TLL provides comprehensive listings by Classical authors for many of its lemmata .These citations essentially function as an index into the textual collection .If I am interested in the places in Classical literature where the verb libero means to acquit , I can consult the OLD and then turn to the source texts it cites : Cic .", "label": "", "metadata": {}, "score": "80.10134"}
{"text": "Pseudo - predicate verbs include \" give \" , \" show \" , and \" find \" .Not all instances of these verbs are pseudo - predicates ; however , the first instance of them in a query often is .", "label": "", "metadata": {}, "score": "80.42934"}
{"text": "Ik aanbad [ @phantom hem ] dagelijks in de kerk Ik kocht boeken en Piet [ @phantom kocht ] platen Ik heb [ @phantom meer ] boeken gezien dan hem .Limitations : a phantom bracketed string can only contain a single word .", "label": "", "metadata": {}, "score": "80.58757"}
{"text": "The modal verb filter removes modal verbs from sentence objects .Modal verbs are verbs such as \" should \" , \" could \" , and \" would \" .Such verbs alter the conditions under which a sentence is true , but do not affect the basic meaning of the sentence .", "label": "", "metadata": {}, "score": "81.0134"}
{"text": "For example , for an English sentence \" I have a brown dog \" , a dependency parser can get a set of triples as is illustrated in FIG .4- 1 .The standard expression of the dependency parsing result is : ( have , sub , I ) , ( have , obj , dog ) , ( dog , adj , brown ) , ( dog , det , a ) .", "label": "", "metadata": {}, "score": "81.27246"}
{"text": "This is an especially appropriate manner of representation for languages with a free word order ( such as Latin and Czech ) , where the linear order of constituents is broken up with elements of other constituents .A dependency grammar representation , for example , of ista meam norit gloria canitiem Propertius I.8.46 - \" that glory would know my old age \" - would look like the following : .", "label": "", "metadata": {}, "score": "81.410706"}
{"text": "The proposed kernels are also evaluated using the 5 PPI corpora which put together by [ 18 ] for comparative evaluations on diverse corpora .Many recent studies that addressed PPI task used the corpora as default benchmarks .The corpora consist of AIMed , BioInfer , IEPA , HRPD50 , and LLL 05 .", "label": "", "metadata": {}, "score": "81.49533"}
{"text": "By way of example , and not limitation , FIG .1 illustrates operating system 134 , application programs 135 , other program modules 136 , and program data 137 .[ 0029 ] .The computer 110 may also include other removable / non - removable volatile / nonvolatile computer storage media .", "label": "", "metadata": {}, "score": "81.5645"}
{"text": "This option is illustrated in dashed lines for block 264 and arrows 266 and 268 .Of course , if this option is chosen the identified text 210 would not be provided directly to the N - gram algorithm 248 , but rather to block 264 .", "label": "", "metadata": {}, "score": "81.566444"}
{"text": "0109 ] .Then we have : .e . max . argmax .e .P .e . )P .c .e . ) argmax .e .P .e . )P .c .e . ) argmax .", "label": "", "metadata": {}, "score": "81.58193"}
{"text": "Computer storage media includes both volatile and nonvolatile , removable and non - removable media implemented in any method or technology for storage of information such as computer readable instructions , data structures , program modules or other data .Communication media typically embodies computer readable instructions , data structures , program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media .", "label": "", "metadata": {}, "score": "81.74497"}
{"text": "By way of example , and not limitation , communication media includes wired media such as a wired network or direct - wired connection , and wireless media such as acoustic , RF , infrared and other wireless media .Combinations of any of the above should also be included within the scope of computer readable media .", "label": "", "metadata": {}, "score": "81.74542"}
{"text": "[ 0027 ] .Computer 110 typically includes a variety of computer readable media .Computer readable media can be any available media that can be accessed by computer 110 and includes both volatile and nonvolatile media , removable and non - removable media .", "label": "", "metadata": {}, "score": "81.99156"}
{"text": "The TLL , however , is impeccable in precision , while the Perseus and TLG results are dirty .What we need is a resource to combine the best of both .Where do we want to be ?The OLD and TLL are not likely to become obsolete anytime soon ; as the products of highly skilled editors and over a century of labor , the sense distinctions within them are highly precise and well substantiated .", "label": "", "metadata": {}, "score": "82.16316"}
{"text": "In the following I will detail how we can leverage them all to uncover large - scale usage patterns in a text .Word Sense Induction .So , for example , the Greek word arch\u00ea may be translated in one context as beginning and in another as empire , corresponding respectively to LSJ definitions I.1 and II.2 .", "label": "", "metadata": {}, "score": "82.31675"}
{"text": "Therefore , the biggest problem for these non - natives while writing in English is determining how to polish sentences .While this can be true regarding the process of writing in any non - native language , the problem is described primarily with reference to English writing .", "label": "", "metadata": {}, "score": "82.49628"}
{"text": "The computer 110 may operate in a networked environment using logical connections to one or more remote computers , such as a remote computer 180 .The remote computer 180 may be a personal computer , a hand - held device , a server , a router , a network PC , a peer device or other common network node , and typically includes many or all of the elements described above relative to the computer 110 .", "label": "", "metadata": {}, "score": "82.998"}
{"text": "u t .i 1 u t .i 2 . . .u t .i k ] from the context - free grammar non - terminal t i .In the case when t i itself is a word ( \u016b t .", "label": "", "metadata": {}, "score": "83.16577"}
{"text": "For an unconventional approach to dependency parsing , you can read this paper that models word - word relationships analogous to subatomic particle interactions in chemistry / physics .Your sentence The yellow sun .Tagging The / DT yellow / JJ sun / NN .", "label": "", "metadata": {}, "score": "83.225266"}
{"text": "[ 0023]FIG .1 illustrates an example of a suitable computing system environment 100 on which the invention may be implemented .The computing system environment 100 is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention .", "label": "", "metadata": {}, "score": "83.24858"}
{"text": "first_line_no .Integer which you can use to enforce that Alpino first ignores a number of lines , and then starts parsing after that many lines .Normally , the value of this flag will be 0 ( parse all lines ) , but in some cases it is useful to ignore the first part of an input file ( because perhaps those lines already were parsed in an earlier session ) .", "label": "", "metadata": {}, "score": "83.394196"}
{"text": "Block 248 illustrates application of an N - gram algorithm to obtain the second N - gram language model 250 .A third N - gram language model 252 is formed by combining the first N - gram language model 246 and the second N - gram language model 250 .", "label": "", "metadata": {}, "score": "83.61511"}
{"text": "He is suffering from nausea and severe headaches .Dolasteron was prescribed .domain knowledge is needed to identify the has_indication relation between the drug \" Dolasteron \" and the \" nausea \" condition .As in this example , many such relationships are inter - sentential .", "label": "", "metadata": {}, "score": "83.695465"}
{"text": "The project 's data resource is a repository of the full clinical records for over 20000 cancer patients from the Royal Marsden Hospital , Europe 's largest oncology centre .These records combine structured information , clinical narratives , and free text investigation reports .", "label": "", "metadata": {}, "score": "83.8777"}
{"text": "A selectional restriction filter vetoes any parse tree where there are conflicts between the selectional features of the concepts serving as arguments to another concept and the restrictions of that concept .Selectional restrictions are imposed on the argument positions of predicate structures .", "label": "", "metadata": {}, "score": "83.9828"}
{"text": "A predicate structure built from \" eat \" might thus require that the object of the predicate have a code beginning with \" 112 .\" As can be seen from the tree shown , it is clear that all the foods listed inherit the \" 112 \" prefix .", "label": "", "metadata": {}, "score": "84.068665"}
{"text": "The SICStus tokenizer classifies non - Latin1 characters using locale sensitive functions ( iswpunct ( ) , ... ) .So when the process locale is UTF-8 the U+2018 and U+2019 in l.pl are classified as symbol characters which , rightfully , gives a syntax error .", "label": "", "metadata": {}, "score": "84.95699"}
{"text": "As shown n FIG .8 at 705 , an input query is received by search engine 315 - 1 .As shown at 710 , search engine 315 - 1 includes a language determining component which determines whether the query is in English ( or more generally in the first language ) .", "label": "", "metadata": {}, "score": "85.340256"}
{"text": "This takes advantage of the Penn Treebank tagset used by GATE 's POS tagger , in which related POS tags share the first two characters .For example , all six verb POS tags start with the letters \" VB \" .", "label": "", "metadata": {}, "score": "85.40334"}
{"text": "Acknowledgements .CLEF is funded by the UK Medical Research Council , grant reference GO300607 .We would like to thank the Royal Marsden Hospital for providing the corpus , and our clinical partners in CLEF for assistance in developing the schema , and for gold standard annotation .", "label": "", "metadata": {}, "score": "85.43475"}
{"text": "With reference to FIG .1 , an exemplary system for implementing the invention includes a general - purpose computing device in the form of a computer 110 .Components of computer 110 may include , but are not limited to , a processing unit 120 , a system memory 130 , and a system bus 121 that couples various system components including the system memory to the processing unit 120 .", "label": "", "metadata": {}, "score": "85.98081"}
{"text": "so.0 libtcl8.4 .so.0 libSM.so.6 libICE.so.6 libX11.so.6 libdl.so.2 libm.so.6 libpthread.so.0 libgcc_s . so.1 libc.so.6 /lib64/ld - linux - x86 - 64 . so.2 libuuid.so.1 libxcb.so.1 libXau.so.6 libXdmcp.so.6 .In addition , some of the tools and programs that are shipped with Alpino require additional packages .", "label": "", "metadata": {}, "score": "85.982765"}
{"text": "For example , the following restrictions can be used in a query in order to limit the type of the agent to be \" protein_molecule \" : . applyRel(xrel(['control ' , type : ' G#protein_molecule ' , _ ] ) ) .", "label": "", "metadata": {}, "score": "86.061714"}
{"text": "The various usages of Alpino can be summarized as follows : .Alpino [ Options ] Alpino [ Options ] -parse Alpino [ Options ] -parse W1 .Wn .In the first form , the system will work in interactive mode .", "label": "", "metadata": {}, "score": "86.34052"}
{"text": "Alpino .Some frequently used options are given here .Assigns Value to global variable Flag .See below for a list of flags with suggested values .The remaining options all start with a dash : . -flag Flag Value .", "label": "", "metadata": {}, "score": "87.31517"}
{"text": "-alpino_parse_tokens(s2324,[ik , besta ] ) .If you want to extend the functionality of Alpino , you may be interested to learn about the following ( Prolog- ) hooks .The hook predicate .alpino_start_hook(Key , Sentence ) .is called before the parse of each sentence .", "label": "", "metadata": {}, "score": "87.44696"}
{"text": "A number of program modules can be stored on the hard disk , magnetic disk 59 , optical disk 61 , ROM 54 or RAM 55 , including an operating system 65 , one or more application programs 66 , other program modules 67 , and program data 68 .", "label": "", "metadata": {}, "score": "87.638016"}
{"text": "For instance , the task - independent corpus includes various instances of how proper names are used .For example , the task - independent corpus could have sentences like : \" Bill Clinton was present at the meeting \" and \" John Smith went to lunch at the conference \" .", "label": "", "metadata": {}, "score": "87.69759"}
{"text": "PubMed View Article .Bader GD , Betel D , Hogue CWV : BIND : the Biomolecular Interaction Network Database .Nucleic Acids Res 2003 , 31 ( 1 ) : 248 - 250 .PubMed View Article .Zanzoni A , Montecchi - Palazzi L , Quondam M , Ausiello G , Helmer - Citterich M , Cesareni G : MINT : A Molecular INTeraction Database .", "label": "", "metadata": {}, "score": "87.948616"}
{"text": "In a distributed computing environment , program modules can be located in both local and remote memory storage devices .With reference to .The system bus 53 can be any of several types of bus structures including a memory bus or memory controller , a peripheral bus , and a local bus using any of a variety of bus architectures .", "label": "", "metadata": {}, "score": "88.00797"}
{"text": "Integer which determines minimum sentence length .Sentences with less words are ignored .This flag is undefined by default .max_sentence_length .Integer which determines maximum sentence length .Sentences with more words are ignored .This flag is undefined by default .", "label": "", "metadata": {}, "score": "88.45664"}
{"text": "Tools for Error Mining .TODO .Running Alpino as a Server .As of march 2011 , there is experimental support for running Alpino as a server program .The server is started using the Prolog command .alpino_server .Communication with a client proceeds through the use of internet sockets .", "label": "", "metadata": {}, "score": "89.400154"}
{"text": "Following that , it would be passed to the lexer 120 , which would access the ontology 140 , and return the sequence : .The - det octopus - noun have - verb a - det heart - noun .Here , det stands for determiner , which is a word with a purely grammatical function , namely specifying a noun phrase .", "label": "", "metadata": {}, "score": "89.581215"}
{"text": "Description .Applicants hereby incorporate by reference co - pending application Ser .No .09/627,295 filed in the U.S. Patent and Trademark Office on Jul. 27 , 2000 , entitled \" Concept - Based Search and Retrieval System . \" BACKGROUND OF THE INVENTION .", "label": "", "metadata": {}, "score": "89.704735"}
{"text": "Use the options -tk or -notk to enable / disable the gui explicitly .In interactive mode , you are in effect using the Hdrug command interpreter and ( optionally ) the Hdrug graphical user interface .Refer to the Hdrug documentation for more information .", "label": "", "metadata": {}, "score": "89.74237"}
{"text": "In a networked environment , program modules depicted relative to the computer 110 , or portions thereof , may be stored in the remote memory storage device .By way of example , and not limitation , FIG .1 illustrates remote application programs 185 as residing on remote computer 180 .", "label": "", "metadata": {}, "score": "90.07263"}
{"text": "Please contact the author if you have specific requests .If something goes wrong .If for some reason Alpino does not work , the first thing you should try is to alter in the Alpino initialization script the line . into .", "label": "", "metadata": {}, "score": "90.13931"}
{"text": "Other values describe more exotic possibilities , please consult the hdrug_status flag in Hdrug for further details .Alpino Tokenizer .The Alpino distribution contains a directory Tokenization with various tools that you can use to tokenize your input into the required format for Alpino .", "label": "", "metadata": {}, "score": "91.02609"}
{"text": "The original , pre - lemmatized Latin is salvum tu me esse cupisti ( Cicero , Pro Plancio , chapter 33 ) .The original English is you wished me to be safe .As a result of the lemmatization process , many source words are mapped to multiple words in the target - most often to lemmas which share a common inflection .", "label": "", "metadata": {}, "score": "91.87668"}
{"text": "Just as a spam filter is trained by a user explicitly labeling a message as spam , this classifier can be trained simply by the presence of an aligned translation .For instance , the Latin word spiritus has several senses , including spirit and wind .", "label": "", "metadata": {}, "score": "92.0437"}
{"text": "A typical way tot do this , is to add the following lines to the file .bashrc in your home directory , assuming you use bash , and assuming you extracted the Alpino stuff in a directory called Alpino in your home directory : .", "label": "", "metadata": {}, "score": "92.07706"}
{"text": "Boston , MA , USA : ACL 2004 , 53 - 60 .Copyright .\u00a9 Roberts et al .2008 .This article is published under license to BioMed Central Ltd.", "label": "", "metadata": {}, "score": "92.58896"}
{"text": "The objects in object store 216 are maintained by applications 214 and operating system 212 , at least partially in response to calls to the exposed application programming interfaces and methods .[ 0037 ] .Communication interface 208 represents numerous devices and technologies that allow mobile device 200 to send and receive information .", "label": "", "metadata": {}, "score": "93.746254"}
{"text": "FIG .3 .It should be noted that the entire system 100 , or part of speech recognition system 100 , can be implemented in the environment illustrated in .FIG .2 .For example , microphone 92 can preferably be provided as an input device to the computer 50 , through an appropriate interface , and through the A / D converter 104 .", "label": "", "metadata": {}, "score": "94.18227"}
{"text": "In deciding how we want to design a cyberinfrastructure for Classics over the next ten years , there is an important question that lurks between \" where are we now ? \" and \" where do we want to be ?\" : where are our colleagues already ?", "label": "", "metadata": {}, "score": "94.24742"}
{"text": "The personal computer 50 can operate in a networked environment using logic connections to one or more remote computers , such as a remote computer 79 .FIG .2 .The logic connections depicted in .FIG .2 include a local area network ( LAN ) 81 and a wide area network ( WAN ) 82 .", "label": "", "metadata": {}, "score": "94.269165"}
{"text": "A basic input / output system 56 ( BIOS ) , containing the basic routine that helps to transfer information between elements within the personal computer 50 , such as during start - up , is stored in ROM 54 .The hard disk drive 57 , magnetic disk drive 58 , and optical disk drive 60 are connected to the system bus 53 by a hard disk drive interface 62 , magnetic disk drive interface 63 , and an optical drive interface 64 , respectively .", "label": "", "metadata": {}, "score": "94.662766"}
{"text": "A monitor 191 or other type of display device is also connected to the system bus 121 via an interface , such as a video interface 190 .In addition to the monitor , computers may also include other peripheral output devices such as speakers 197 and printer 196 , which may be connected through an output peripheral interface 190 .", "label": "", "metadata": {}, "score": "95.180374"}
{"text": "Input / output components 206 include a variety of input devices such as a touch - sensitive screen , buttons , rollers , and a microphone as well as a variety of output devices including an audio generator , a vibrating device , and a display .", "label": "", "metadata": {}, "score": "95.44135"}
{"text": "However , the task - independent corpus might contain references to a person called \" Joe Friday \" .In this manner , during parsing of the task - independent corpus , instances of days of the week will be identified separate from instances where \" Friday \" is the last name of an individual .", "label": "", "metadata": {}, "score": "95.61578"}
{"text": "W .T . )i . m .P .t .i .t .i .t .i .i . m .P .u . t .i ._ .t .i . )", "label": "", "metadata": {}, "score": "96.63511"}
{"text": "[ 0035 ] .Memory 204 is implemented as non - volatile electronic memory such as random access memory ( RAM ) with a battery back - up module ( not shown ) such that information stored in memory 204 is not lost when the general power to mobile device 200 is shut down .", "label": "", "metadata": {}, "score": "96.8568"}
{"text": "Mobile device 200 can also be directly connected to a computer to exchange data therewith .In such cases , communication interface 208 can be an infrared transceiver or a serial or parallel communication connection , all of which are capable of transmitting streaming information .", "label": "", "metadata": {}, "score": "97.801445"}
{"text": "P .u . t .i ._ .t .i . )[ .l .u ._ .t .i .P .u . t .l .u . t .i . u . t .", "label": "", "metadata": {}, "score": "98.01092"}
{"text": "There is a makefile Makefile.start_server which can be used to simplify starting up an Alpino server .For every request that the server receives , a new client process is started which takes care of that request .An Alpino server only runs under Linux .", "label": "", "metadata": {}, "score": "98.098526"}
{"text": "The Baseline System .[0048 ] .The baseline system upon which search engine 315 improves is an approach used widely in traditional IR systems .A general description of one embodiment of this approach is as follows .[ 0049 ] .", "label": "", "metadata": {}, "score": "98.33859"}
{"text": "The drives and their associated computer storage media discussed above and illustrated in FIG .1 , provide storage of computer readable instructions , data structures , program modules and other data for the computer 110 .In FIG .1 , for example , hard disk drive 141 is illustrated as storing operating system 144 , application programs 145 , other program modules 146 , and program data 147 .", "label": "", "metadata": {}, "score": "98.76282"}
{"text": "Use the flag assume_input_is_tokenized for this purpose .If the value is on , then Alpino wo n't try to tokenize the input .If the value is off , it will tokenize the input .It will not do any sentence splitting .", "label": "", "metadata": {}, "score": "99.39932"}
{"text": "The system 300 includes an input 305 which is used to receive or enter an input query into the system .[ 0042 ] .A query processing component 310 provides the query , either in whole or in related component parts , to search engine 315 .", "label": "", "metadata": {}, "score": "101.73859"}
{"text": "P .u . t .i .l .h . )P . word .u . t .i .l .u . t .i .l .u . t .i .l .w .", "label": "", "metadata": {}, "score": "101.863464"}
{"text": "[ 0034 ] .[ 0034]FIG .2 is a block diagram of a mobile device 200 , which is an exemplary computing environment .Mobile device 200 includes a microprocessor 202 , memory 204 , input / output ( I / O ) components 206 , and a communication interface 208 for communicating with remote computers or other mobile devices .", "label": "", "metadata": {}, "score": "102.12491"}
{"text": "When used in a LAN networking environment , the computer 110 is connected to the LAN 171 through a network interface or adapter 170 .When used in a WAN networking environment , the computer 110 typically includes a modem 172 or other means for establishing communications over the WAN 173 , such as the Internet .", "label": "", "metadata": {}, "score": "102.54503"}
{"text": "In the parser 220 , the tree shown in .FIG .6 is produced .The parse tree converter 230 then converts this tree into a predicate , where octopus is the subject of have , and heart is the object .", "label": "", "metadata": {}, "score": "103.56006"}
{"text": "When it is translated as spirit , its context has ( more naturally ) a religious tone , including words such as sanctus ( holy ) and omnipotens ( all - powerful ) .If we are confronted with an instance of spiritus in a sentence for which we have no translation , we can disambiguate it as either spirit or wind by looking at its context in the original Latin .", "label": "", "metadata": {}, "score": "103.85602"}
{"text": "The system memory 130 includes computer storage media in the form of volatile and/or nonvolatile memory such as read only memory ( ROM ) 131 and random access memory ( RAM ) 132 .A basic input / output system 133 ( BIOS ) , containing the basic routines that help to transfer information between elements within computer 110 , such as during start - up , is typically stored in ROM 131 .", "label": "", "metadata": {}, "score": "104.4924"}
{"text": "Suppose that a user of a search engine which makes use of this parser asks the question : .Do octopuses have hearts ?The sentence lexer 100 will read the question , and a sentence made of ontological entities is produced .", "label": "", "metadata": {}, "score": "104.73412"}
{"text": "When used in a LAN networking environment , the personal computer 50 is connected to the local area network 81 through a network interface or adapter 83 .When used in a WAN networking environment , the personal computer 50 typically includes a modem 84 or other means for establishing communications over the wide area network 82 , such as the Internet .", "label": "", "metadata": {}, "score": "104.9548"}
{"text": "Thus , when the sentence passes through the lexer filters 150 as discussed in the previous example embodiment , the stop word filter removes \" a \" and \" the , \" leaving : . octopus - noun have - verb heart - noun .", "label": "", "metadata": {}, "score": "106.985405"}
{"text": "Operating system 144 , application programs 145 , other program modules 146 , and program data 147 are given different numbers here to illustrate that , at a minimum , they are different copies .[ 0031 ] .A user may enter commands and information into the computer 110 through input devices such as a keyboard 162 , a microphone 163 , and a pointing device 161 , such as a mouse , trackball or touch pad .", "label": "", "metadata": {}, "score": "107.837296"}
{"text": "[ 0036 ] .Memory 204 includes an operating system 212 , application programs 214 as well as an object store 216 .During operation , operating system 212 is preferably executed by processor 202 from memory 204 .Operating system 212 , in one preferred embodiment , is a WINDOWS \u00ae CE brand operating system commercially available from Microsoft Corporation .", "label": "", "metadata": {}, "score": "107.974945"}
{"text": "In embodiments in which the entire input query is provided to search engine 315 for processing and searching , query processing component 310 can be combined with input 305 .However , in some embodiments , query processing component 310 can perform some processing functions on the query , for example extracting terms from the query and passing the terms to search engine 315 .", "label": "", "metadata": {}, "score": "107.9832"}
{"text": "Do - verb octopus - noun have - verb heart - noun .In the preferred embodiment 's lexer filters , the pseudo predicate filter removes the first verb \" do , \" because it is not the main verb of the sentence . \"", "label": "", "metadata": {}, "score": "108.93051"}
{"text": "Oxford : Clarendon Press , 1879 .Liddell and Scott 1940 Liddell , Henry George and Robert Scott ( eds . )A Greek - English Lexicon , revised and augmented throughout by Sir Henry Stuart Jones .Oxford : Clarendon Press , 1940 .", "label": "", "metadata": {}, "score": "109.003586"}
{"text": "The example sentence is : .The octopus has a heart .First , the sentence lexer 100 would process this sentence .The first component of the sentence lexer 100 , the document iterator 110 , would extract this sentence from the document it was contained in .", "label": "", "metadata": {}, "score": "111.70511"}
