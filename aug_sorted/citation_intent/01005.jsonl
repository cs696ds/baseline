{"text": "The second question is how one can estimate NLP systems ' performance when gold standard on the test data does not exist .To answer the question , we extend the parsing prediction model in ( Ravi et al . , 2008 ) to provide prediction for word segmentation and POS tagging as well .", "label": "", "metadata": {}, "score": "31.437634"}
{"text": "In some such cases with one variance component essentially zero relative to the others or the models are not properly nested , Pinheiro and Bates showed that the true distribution of this likelihood ratio chi - square statistic could be substantially different from the naive , often dramatically so .", "label": "", "metadata": {}, "score": "32.210327"}
{"text": "Here is an example of use .Certain assumptions [ 3 ] must be met for the statistic to follow a chi - squared distribution , and often empirical p -values are computed .The likelihood - ratio test requires nested models , i.e. models in which the more complex one can be transformed into the simpler model by imposing a set of constraints on the parameters .", "label": "", "metadata": {}, "score": "33.19873"}
{"text": "Kilgarriff A : Comparing corpora .International Journal of Corpus Linguistics 2001 , 6 : 97 - 133 .View Article .Teh YW , Jordan MI , Beal MJ , Blei DM : Hierarchical Dirichlet processes .Journal of the American Statistical Association 2006 , 101 ( 476 ) : 1566 - 1581 .", "label": "", "metadata": {}, "score": "35.01945"}
{"text": ".. our corpus .The second question is how one can estimate NLP systems ' performance when gold standard on the test data does not exist .Our experiments show that the predicted scores are close to the real scores when tested on the CTB data .", "label": "", "metadata": {}, "score": "35.757698"}
{"text": "Similarly , the result of Bayesian inference applied to a choice of single multinomial distribution for all rows of the contingency table taken together versus the more general alternative of a separate multinomial per row produces results very similar to the G statistic .", "label": "", "metadata": {}, "score": "36.065536"}
{"text": "To find natural groupings of the subdomains , we perform K - means clustering directly on the distributions , using the Gap statistic [ 52 ] to choose the value for K .The Gap statistic uses within - cluster error and random sampling to find optimal parameters tailored to the data set .", "label": "", "metadata": {}, "score": "36.2658"}
{"text": "We expect that the lower the similarity threshold , the lower the actual redundancy level of the resulting corpus ( in other words , we verify that our fingerprinting redundancy reduction algorithm effectively reduces redundancy ) .Descriptive statistics of reduced corpora .", "label": "", "metadata": {}, "score": "36.826366"}
{"text": ", 2009 ; Biber & Gray , 2010 ) , but the most interesting usages apply the divergence to a machine learning system .Despite the fact that authors have shown that a divergence ( Van Asch & Daelemans , 2010 ; Plank , 2011 ) or a linear combination of divergences ( McClosky , 2010 ) can be successfully used to link the sim ... . \" ...", "label": "", "metadata": {}, "score": "36.89457"}
{"text": "For the general contingency table , we can write the log - likelihood ratio statistic as .Casella , George ; Berger , Roger L. ( 2001 ) .Statistical Inference ( Second ed . )ISBN 0 - 534 - 24312 - 6 .", "label": "", "metadata": {}, "score": "36.90685"}
{"text": "However , most ... \" .It is well known that parsing accuracy suffers when a model is applied to out - of - domain data .It is also known that the most beneficial data to parse a given domain is data that matches the domain ( Sekine , 1997 ; Gildea , 2001 ) .", "label": "", "metadata": {}, "score": "37.101738"}
{"text": "This approach makes two hypothesis , and compares the likelihood of the two hypothesis .The hypothesis are as follows : .We first calculate the actual probabilities for the independent and dependent cases from the occurrence counts of the words in the corpus , like so : . where : .", "label": "", "metadata": {}, "score": "37.292183"}
{"text": "It is well known that parsing accuracy suffers when a model is applied to out - of - domain data .It is also known that the most beneficial data to parse a given domain is data that matches the domain ( Sekine , 1997 ; Gildea , 2001 ) .", "label": "", "metadata": {}, "score": "37.72141"}
{"text": "Recent years have seen an increased research interest in the effect of domain variation on the effectiveness of Natural Language Processing ( NLP ) technology .A fundamental assumption of statistical methods is that the data used to train a system has the same distribution as the data that will be used when applying or evaluating the system .", "label": "", "metadata": {}, "score": "38.07618"}
{"text": "For samples of a reasonable size , the G -test and the chi - squared test will lead to the same conclusions .For very small samples the multinomial test for goodness of fit , and Fisher 's exact test for contingency tables , or even Bayesian hypothesis selection are preferable to either the chi - squared test or the G -test .", "label": "", "metadata": {}, "score": "38.13034"}
{"text": "It introduces basic and intermediate - level statistical techniques that can be used by linguists , especially in the domains of applied and corpus linguistics .The techniques range from basic parametric and non - parametric tests , such as the chi - squared test , to more advanced multivariate techniques , such as factor analysis and multiple linear regression .", "label": "", "metadata": {}, "score": "38.288086"}
{"text": "In this paper , we ask three research questions : ( i ) How can redundancy be quantified in large - scale text corpora ?( ii )Conventional wisdom is that larger corpora yield better results in text mining .But how does the observed EHR redundancy affect text mining ?", "label": "", "metadata": {}, "score": "38.416725"}
{"text": "We observe that the log - likelihood graphs for them have the same shape , with the larger corpora achieving higher log - likelihood , and the best fits obtained with topic numbers between 100 and 200 ( Figure 4 a ) .", "label": "", "metadata": {}, "score": "38.800716"}
{"text": "This is similar to the approach used by Arnold et al .( 2010 ) [ 28 ] and is accepted as a method for comparing LDA performance [ 54 ] .The topic models were learned using the Collapsed Gibbs Sampler provided in Mallet [ 55 ] with the recommended parameters and with hyper - parameter optimization as described in Wallach et al .", "label": "", "metadata": {}, "score": "39.53209"}
{"text": "If the distribution of the likelihood ratio corresponding to a particular null and alternative hypothesis can be explicitly determined then it can directly be used to form decision regions ( to accept / reject the null hypothesis ) .In most cases , however , the exact distribution of the likelihood ratio corresponding to specific hypotheses is very difficult to determine .", "label": "", "metadata": {}, "score": "39.727604"}
{"text": "The book can thus be used as a supplement to more practically oriented textbooks , e.g. , Baayen ( 2008 ) and Gries ( 2009 , 2013 ) .Another strong point is the systematic discussion and comparison of parametric and non - parametric methods offered in Chapter 3 .", "label": "", "metadata": {}, "score": "39.97542"}
{"text": "A similar pattern is observed at the bi - gram level ( a Zipfian distribution for the non - redundant corpus and a non - Zipfian distribution for the redundant corpus ) .Impact of redundancy on text mining .We have observed that redundant corpora exhibit different statistical profiles than non - redundant ones , according to their word occurrence distributions .", "label": "", "metadata": {}, "score": "40.115395"}
{"text": "Cohen et al .[ 11 ] carry out a detailed analysis of argument realisation with respect to verbs and nominalisations , using the GENIA and PennBioIE corpora .Nguyen and Kim improve the performance of a pronoun resolver by incorporating their observations , thus demonstrating the importance of capturing domain - specific phenomena .", "label": "", "metadata": {}, "score": "40.36843"}
{"text": "Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?( iii )How can one mitigate the impact of redundancy on text mining ?Results .We analyze a large - scale EHR corpus and quantify redundancy both in terms of word and semantic concept repetition .", "label": "", "metadata": {}, "score": "40.63555"}
{"text": "Essentially , we compute the \u03a7 2 statistic from the observed and expected probabilities ( based on marginal probabilities of the observations ) , and compare it with the critical value at a 0.05 level of significance .If the result is positive , the observed value lies outside the 95 % range of expected values based on a \" fair \" distribution , ie one where the words are independent and equally likely , and hence can be considered to be a phrase .", "label": "", "metadata": {}, "score": "40.662975"}
{"text": "Log - Likelihood Ratio Test for VAD .The VAD method for the present invention is similar to the threshold - comparison in that it employs measured quantities for decision - making .The present invention advantageously employs log - likelihood ratio and pitch .", "label": "", "metadata": {}, "score": "40.73053"}
{"text": "View Article .Tibshirani R , Walther G , Hastie T : Estimating the number of clusters in a data set via the gap statistic .Journal of the Royal Statistical Society B 2001 , 63 ( 2 ) : 411 - 423 .", "label": "", "metadata": {}, "score": "40.773212"}
{"text": "The number of topics is a free parameter of LDA - given two LDA models with the same log - likelihood on withheld data , the one with the lower number of topics has better explanatory power ( fewer latent variables or topics are needed to explain the data ) .", "label": "", "metadata": {}, "score": "40.9642"}
{"text": "Theoretical Statistics .Chapman and Hall .ISBN 0 - 412 - 12420 - 3 .Huelsenbeck , J. P. ; Crandall , K. A. ( 1997 ) .\" Phylogeny Estimation and Hypothesis Testing Using Maximum Likelihood \" .Annual Review of Ecology and Systematics 28 : 437 - 466 .", "label": "", "metadata": {}, "score": "41.047638"}
{"text": "The redundant corpus , though 6.9 times larger , produces the same fit as the non - redundant corpus ( Last Informative Note ) .When applied to the synthetic WSJ corpora , we get a finer picture of the behavior of LDA under various corpora sizes and redundancy levels ( Figure 4 ) .", "label": "", "metadata": {}, "score": "41.078423"}
{"text": "Proceedings of HLT - NAACL-09 , Boulder , CO 2009 .Rimell L , Clark S : Porting a lexicalized - grammar parser to the biomedical domain .Journal of Biomedical Informatics 2009 , 42 ( 5 ) : 852 - 865 .", "label": "", "metadata": {}, "score": "41.213375"}
{"text": "They conclude that for testing fixed effects , it 's wise to use simulation .( And they provided a \" simulate.lme \" function in their \" nlme \" package for S - PLUS and R to support doing that . )", "label": "", "metadata": {}, "score": "41.234295"}
{"text": "In this paper , we ask three research questions : ( i ) how can redundancy be quantified in large - scale text corpora ?( ii )Conventional wisdom is that larger corpora yield better results in text mining .But how does the observed text redundancy in EHR affect text mining ?", "label": "", "metadata": {}, "score": "41.267452"}
{"text": "[ 3 ] This means that for a great variety of hypotheses , a practitioner can compute the likelihood ratio for the data and compare to the value corresponding to a desired statistical significance as an approximate statistical test .Wilk 's theorem assumes that the true but unknown values of the estimated parameters are in the interior of the parameter space .", "label": "", "metadata": {}, "score": "41.284992"}
{"text": "proposed an ensemble method ( Reichart and Rappoport , 2007 ) .They regarded parses as being of high quality if 20 different parsers agreed .They used an SVM regression approach on the basis of text - based and parse - based features .", "label": "", "metadata": {}, "score": "41.308437"}
{"text": "We measure the impact of redundancy on two standard text - mining applications : collocation identification and topic modeling .We compare the results of these methods on synthetic data with controlled levels of redundancy and observe significant performance variation .Finally , we compare two mitigation strategies to avoid redundancy - induced bias : ( i ) a baseline strategy , keeping only the last note for each patient in the corpus ; ( ii ) removing redundant notes with an efficient fingerprinting - based algorithm .", "label": "", "metadata": {}, "score": "41.408714"}
{"text": "Writing for the best values for under the hypothesis , the maximum likelihood estimate is given by .The hypothesis and null hypothesis can be rewritten slightly so that they satisfy the constraints for the logarithm of the likelihood ratio to have the desired nice distribution .", "label": "", "metadata": {}, "score": "41.596725"}
{"text": "G -tests are coming into increasing use , particularly since they were recommended in the 1994 edition of the popular statistics text book by Sokal and Rohlf [ 1 ] .Dunning introduced the test to the computational linguistics community where it is now widely used .", "label": "", "metadata": {}, "score": "41.65648"}
{"text": "The dimensions of variation that directly affect a given statistical tool will depend on the application and methodology involved .For example , a document classifier using a bag - of - words representation will be sensitive to lexical variation but not to syntactic variation , while a lexicalised parser will be sensitive to both .", "label": "", "metadata": {}, "score": "41.974438"}
{"text": "Conclusions .We find that while patterns of inter - subdomain variation differ somewhat from one feature set to another , robust clusters can be identified that correspond to intuitive distinctions such as that between clinical and laboratory subjects .In particular , subdomains relating to genetics and molecular biology , which are the most common sources of material for training and evaluating biomedical NLP tools , are not representative of all biomedical subdomains .", "label": "", "metadata": {}, "score": "42.51754"}
{"text": "Chi - Square Approach .With the Chi - Square Approach , we assume the independence hypothesis H 0 , and then attempt to prove or disprove it .This is apparently a popular technique applicable in other fields as well .", "label": "", "metadata": {}, "score": "42.60544"}
{"text": "Conclusions .In this paper we have identified the phenomenon of subdomain variation and studied how it manifests itself in the domain of biomedical language .As far as we are aware , this is the first time that subdomain analysis has been applied to a corpus spanning an entire scientific domain and the first time that it has been performed with a focus on implications for natural language processing applications .", "label": "", "metadata": {}, "score": "42.677185"}
{"text": "One may ask , however , whether the fact that the sentences are repeated in EHR corpora reflects on their semantic importance from a clinical standpoint , and therefore , whether the collocations extracted from the full EHR corpus contain more clinically relevant collocations .", "label": "", "metadata": {}, "score": "42.795547"}
{"text": "Downey D , Etzioni O , Soderland S : Analysis of a probabilistic model of redundancy in unsupervised information extraction .Artif Intell 2010 , 174 ( 11 ) : 726 - 748 .View Article .Altschul SF , Madden TL , Sch\u00e4ffer AA , Zhang J , Zhang Z , Miller W , Lipman DJ : Gapped BLAST and PSI - BLAST : a new generation of protein database search programs .", "label": "", "metadata": {}, "score": "42.867607"}
{"text": "Current statistical parsers tend to perform well only on their training domain and nearby genres .While strong performance on a few related domains is sufficient for many situations , it is advantageous for parsers to be able to generalize to a wide variety of domains .", "label": "", "metadata": {}, "score": "42.907158"}
{"text": "Current statistical parsers tend to perform well only on their training domain and nearby genres .While strong performance on a few related domains is sufficient for many situations , it is advantageous for parsers to be able to generalize to a wide variety of domains .", "label": "", "metadata": {}, "score": "42.907158"}
{"text": "This phenomenon also hampers the use of machine learning methods by preventing a good division of the data to non - overlapping test and train sets .Results and discussion .Quantifying redundancy in a large - scale EHR corpus .Word sequence redundancy at the patient level .", "label": "", "metadata": {}, "score": "42.93948"}
{"text": "Pyysalo S , Ginter F , Heimonen J , Bj\u00f6rne J , Boberg J , J\u00e4rvinen J , Salakoski T : BioInfer : A corpus for information extraction in the biomedical domain .BMC Bioinformatics 2007 , 8 : 50 .PubMed View Article .", "label": "", "metadata": {}, "score": "43.017807"}
{"text": "We observe that the lists of extracted collocations on these two corpora differ markedly ( collocations were extracted with a threshold of 0.001 and 0.01 for TMI and PMI respectively ) .The PMI algorithm identified 15,814 collocations in the All Informative Notes corpus , and 2,527 in the Last Informative Notes corpus .", "label": "", "metadata": {}, "score": "43.03854"}
{"text": "This assumption is erroneous .In fact , there exist perfectly legitimate solutions that enable one to incorporate categorical predictors ( e.g. dummy coding ) and non - linear relationships ( e.g. power transformation ) in a linear regression model ; ii .", "label": "", "metadata": {}, "score": "43.277725"}
{"text": "10 comments ( moderated to prevent spam ) : .Yuval said ... .Here is a survey of several methods for finding collocations from Manning and Schutze 's \" Foundations of Statistical Natural Language Processing \" .It includes the likelihood ratio and Chi - square methods , and adds some others : .", "label": "", "metadata": {}, "score": "43.27894"}
{"text": "Advances in informatics 2005 , LNCS 3746 : 382 - 392 .View Article .Smith TF , Waterman MS , Fitch WM : Comparative biosequence metrics .J Mol Evol 1981 , 18 ( 1 ) : 38 - 46 .", "label": "", "metadata": {}, "score": "43.494156"}
{"text": "b(n 12 ; n 2 , p 00 ) .b(n 12 ; n 2 , p 10 ) .The ratio of the likelihood tells us how much more likely the dependence assumption is compared to the independence assumption .We can cancel out the Binomial coefficients in this case .", "label": "", "metadata": {}, "score": "43.51615"}
{"text": "GR distributions will reflect characteristic syntactic preferences in a domain , such as the preference for modification observed by Biber and Gray [ 7 ] in scientific text .Variation in GR distributions across subdomains may be expected to degrade parsing performance and necessitate model adaptation .", "label": "", "metadata": {}, "score": "43.559322"}
{"text": "While these are without a doubt extremely valuable resources for application building , their limited coverage casts doubt on the assumption that a system that performs well on one will also perform well on biomedical text in general .One of the central questions addressed in the present paper is how representative a corpus restricted to a single subdomain of biomedical text can be of the overall biomedical domain .", "label": "", "metadata": {}, "score": "43.591755"}
{"text": "WSJx2 , WSJx3 , and WSJs5 are all larger in size than WSJ-1300 .We therefore would expect them to reach higher log - likelihood , but this does not occur .Instead , their log - likelihood graphs keep increasing as the number of topics increases , all the while remaining consistently inferior to the WSJ-1300 corpus , from which they are derived .", "label": "", "metadata": {}, "score": "43.697937"}
{"text": "In this scenario , we control for vocabulary : only word types that appear in the smaller corpus ( Last Informative Note ) are considered for collocations .To measure the impact of redundancy on the extracted collocations , for each collocation , we count the number of patients whose notes contain this collocation .", "label": "", "metadata": {}, "score": "43.713425"}
{"text": "E ij .Thus , 95 % of the hypothetical distribution lies behind the critical value .The ChiSquare approach is used by LingPipe for phrase extraction , according to the BSA book .ChiSquarePhraseFilter .The code for the ChiSquarePhraseFilter is shown below .", "label": "", "metadata": {}, "score": "43.742165"}
{"text": "The underlying basis of a threshold - comparison VAD scheme is that it extracts some selected features or quantities from the input signal and then compare these values with some thresholds .( See , e.g. , K. El - Maleh and P. Kabal , \" Comparison of Voice Activity Detection Algorithms for Wireless Personal Communications Systems \" , Proc .", "label": "", "metadata": {}, "score": "43.747425"}
{"text": "The comparison of recognition results for noisy data is shown in Table 4 .It reveals that the LLRT - based VAD method of the present invention is robust with respect to environmental variability by achieving similar performance improvement over the baseline system .", "label": "", "metadata": {}, "score": "43.938095"}
{"text": "Model fit as function of number of topics on the WSJ corpora .In ( a ) we compare the effect of size on LDA , bigger corpora yield better fit .In ( b ) we examine the effect of redundancy : the doubled / trebled corpora reduce fit slightly while the noisier WSJs5 performs almost as badly as training on the smaller WSJ-600 corpus .", "label": "", "metadata": {}, "score": "43.959915"}
{"text": "To understand this discrepancy , we examine the topics obtained on the redundant corpora qualitatively .Topics are generated by LDA as ranked lists of words .Once a topic model is applied on a document , we can compute the topic assignment for each word in the document .", "label": "", "metadata": {}, "score": "44.098083"}
{"text": "Kim JD , Ohta T , Tateisi Y , Tsujii J : GENIA corpus - a semantically annotated corpus for bio - textmining .Bioinformatics 2003 , 19 ( Suppl 1 ) : i180-i182 .PubMed View Article .Kulick S , Bies A , Liberman M , Mandel M , McDonald R , Palmer M , Schein A , Ungar L , Winters S , White P : Integrated annotation for biomedical information extraction .", "label": "", "metadata": {}, "score": "44.129723"}
{"text": "Banerjee S , Pedersen T : The design , implementation , and use of the ngram statistics package .[Computational Linguistics and Intelligent Text Processing ] .Wallach HM , Murray I , Salakhutdinov R , Mimno D : Evaluation methods for topic models .", "label": "", "metadata": {}, "score": "44.190693"}
{"text": "Computational linguistics 2003 , 29 ( 3 ) : 333 - 347 .View Article .Atterer M , Sch tze H : The effect of corpus size in combining supervised and unsupervised training for disambiguation .Association for Computational Linguistics ; 2006:25 - 32 .", "label": "", "metadata": {}, "score": "44.201378"}
{"text": "This likelihood ratio , or equivalently its logarithm , can then be used to compute a p -value , or compared to a critical value to decide whether to reject the null model in favour of the alternative model .When the logarithm of the likelihood ratio is used , the statistic is known as a log - likelihood ratio statistic , and the probability distribution of this test statistic , assuming that the null model is true , can be approximated using Wilks 's theorem .", "label": "", "metadata": {}, "score": "44.318855"}
{"text": "The algorithm also benefits from a speech recognition system when templates are to be built in the training phase .An example of a speech recognition which may be employed is disclosed in L. R. Bahl , et al . , \" Performance of the IBM Large Vocabulary Continuous Speech Recognition System on the ARPA Wall Street Journal Task , \" ICASSP-95 ; 1995 .", "label": "", "metadata": {}, "score": "44.408195"}
{"text": "We noted that they tend to define their clusters by over- or under - use of lemmas relative to the corpus average , with some favouring one extreme or the other .This may reflect differences in how lexical items vary : for nouns , over - use tends to be characteristic because the basic objects of enquiry are often disjoint between subdomains .", "label": "", "metadata": {}, "score": "44.455227"}
{"text": "Next , the author moves on to discuss type and token distribution in a corpus , as well as Zipf 's law .Finally , he describes how to measure dispersion of a word in a corpus by using Gries ' ( 2008 ) DP ( i.e. Deviation of Proportions ) measure .", "label": "", "metadata": {}, "score": "44.470566"}
{"text": "We show that this algorithm does not require the slower alignment stage of BLAST and that it accurately identifies instances of copy - paste operations .Text mining techniques .We review two established text - mining techniques : collocation identification and topic modeling .", "label": "", "metadata": {}, "score": "44.5889"}
{"text": "Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?( iii )How can one mitigate the impact of redundancy on text mining ?Before presenting results of our experiments and methods , we first review previous work in assessing redundancy in the EHR , two standard text - mining techniques of interest for data - driven disease modeling , and current work in how to mitigate presence of information redundancy .", "label": "", "metadata": {}, "score": "44.76722"}
{"text": "We see that the significantly smaller Last Informative Note performs as well as All Informative Notes ( 8,557 notes vs. 1,247 ) while Reduced Redundancy Informative Notes ( 3,970 notes ) outperforms both .As we showed in Figure 4 a , we would expect a larger corpus to yield a better fit on the model : All Informative Notes is more than 7 times larger than Last Informative , still it yields the same fit on held out data .", "label": "", "metadata": {}, "score": "45.090282"}
{"text": "Vincze V , Szarvas G , Farkas R , M\u00f3ra G , Csirik J : The BioScope corpus : Biomedical texts annotated for uncertainty , negation and their scopes .BMC Bioinformatics 2008 , 9 ( Suppl 11 ) : S9 .", "label": "", "metadata": {}, "score": "45.12067"}
{"text": "Intelligent Systems , IEEE 2009 , 24 ( 2 ) : 8 - 12 .View Article .Dredze M , Blitzer J , Talukdar PP , Ganchev K , Graca J , Pereira F : Frustratingly hard domain adaptation for dependency parsing .", "label": "", "metadata": {}, "score": "45.146378"}
{"text": "Methods for identifying redundancy in large string - based databases exist in both bioinformatics and plagiarism detection [ 40 - 42 ] .A similar problem has been addressed in the creation of sequence databases for bioinformatics : Holm and Sander [ 43 ] advocated the creation of non - redundant protein sequence databases and suggested that databases limit the level of redundancy .", "label": "", "metadata": {}, "score": "45.148582"}
{"text": "Results .Using the large OpenPMC text corpus , which spans the many subdomains of biomedicine , we investigate variation across a number of lexical , syntactic , semantic and discourse - related dimensions .These dimensions are chosen for their relevance to the performance of NLP systems .", "label": "", "metadata": {}, "score": "45.19671"}
{"text": "Properties of the feature sets .We now consider each feature set in terms of the significance of variation and clustering of subdomains .Over- and Under - use of lexical items .Before considering the lexical feature sets , we discuss a phenomenon noticed when examining the lemmas that most characterize each cluster .", "label": "", "metadata": {}, "score": "45.429165"}
{"text": "This lack of consistency explains the confusion and consequently low performance achieved by LDA on redundant corpora .Mitigation strategies for handling redundancy .Given a corpus with inherent redundancy , like the EHR corpus , the basic goal of redundancy mitigation is to choose the largest possible subset of the corpus with an upper bound on the amount of redundancy in that subset .", "label": "", "metadata": {}, "score": "45.47876"}
{"text": "View Article .Banko M , Brill E : Mitigating the paucity - of - data problem : Exploring the effect of training corpus size on classifier performance for natural language processing .Association for Computational Linguistics ; 2001:1 - 5 .", "label": "", "metadata": {}, "score": "45.527405"}
{"text": "Correction to \" Dispersions and adjusted frequencies in corpora \" .International Journal of Corpus Linguistics 17(1 ) .Manning , Chris & Hinrich Sch\u00fctze .Foundations of Statistical Natural Language Processing .Cambridge , MA : MIT Press .ABOUT THE REVIEWER : Natalia Levshina is a postdoctoral researcher at the Research Group ' Language Typology and Quantitative Linguistics ' at Philipps University of Marburg , Germany .", "label": "", "metadata": {}, "score": "45.529324"}
{"text": "PubMed .Manning CD , Schutze H : Foundations of statistical natural language processing .MIT Press , Cambridge MA ; 1999:151 - 190 .Joshi M , Pakhomov S , Pedersen T , Chute CG : A comparative study of supervised learning as applied to acronym expansion in clinical reports .", "label": "", "metadata": {}, "score": "45.56287"}
{"text": "Figure 2 shows the distribution of UMLS concepts ( CUI ) frequencies in the three corpora with expected decreasing levels of redundancy : the All Informative Notes corpus , the All Notes corpus , and the Last Informative Note Corpus .We observe that the profile in the non - redundant Last Informative Note corpus differs markedly from the ones of the redundant corpora ( All Notes and All Informative Notes ) .", "label": "", "metadata": {}, "score": "45.905117"}
{"text": "The GR features ( Figure 5 ) have similarities with the POS features , and overlapping interpretations : for example , both capture the over - usage of determiners by Biomedical Engineering and Medical Informatics .More unusual is that their cluster includes Ethics and Education , due to high usage of clausal modifiers .", "label": "", "metadata": {}, "score": "45.91818"}
{"text": "In this paper , we focused on intrinsic , quantitative evaluations to assess the impact of redundancy on two text - mining techniques .Qualitative analysis as well as task - based evaluations are needed to get a full understanding of the role of redundancy in clinical notes on text - mining methods .", "label": "", "metadata": {}, "score": "45.961166"}
{"text": "Comparison of extracted collocations on synthetic redundant corpora and non - redundant corpora ( WSJ - X words / Y distinct words ) .Collocations were extracted using using True Mutual Information and Pointwise Mutual Information ( with cutoffs of 0.001 and 0.01 respectively ) .", "label": "", "metadata": {}, "score": "46.057663"}
{"text": "We take two popular dependency parsers - one graph - based and one transition - based - and compare results for both .Results show that using semisupervised learning in the form of self - training and co - training yields only very modest improvements in parsing accuracy .", "label": "", "metadata": {}, "score": "46.22582"}
{"text": "We now describe the implementation details of our study : first , we present the OpenPMC corpus of biomedical text and its division into the subdomains that constituted our basic units of enquiry .Second , we enumerate the linguistic features we considered , and explain how we extracted them from the corpus .", "label": "", "metadata": {}, "score": "46.441284"}
{"text": "The code for the LikelihoodRatioPhraseFilter is shown below .The calculations are based on the formula for R(H 1 /H 0 ) developed in the last section .Rather than return a yes / no answer from the filters , the filter returns the logarithm of R. So the client should check to see if the logarithm has a value greater than 0 , ie , the likelihood of the dependence H 1 ( that the words are dependent on each other ) is higher than H 0 ( that the words are independent ) .", "label": "", "metadata": {}, "score": "46.516838"}
{"text": "We study this problem as a new task - multiple source parser adaptation .Our system trains on corpora from many different domains .It learns not only statistics of those domains but quantitative measures of domain differences and how those differences affect parsing accuracy .", "label": "", "metadata": {}, "score": "46.51902"}
{"text": "The LLRT statistic and pitch produce score tags on a frame - by - frame basis .The speech / non - speech classification based on this score tag may over - segment the utterances to make it unsuitable for the speech recognition purposes .", "label": "", "metadata": {}, "score": "46.57074"}
{"text": "For computational consideration and simplicity , a log - likelihood ratio test ( LLRT ) statistic or cepstrum is then defined as : .^ .t . )Reject .H .^ .t . )Reject .H .", "label": "", "metadata": {}, "score": "46.57238"}
{"text": "Friedman et al .[ 9 ] document the \" sublanguages \" associated with two biomedical domains : clinical reports and molecular biology articles .They set out restricted ontologies and frequent co - occurrence templates for the two domains and discuss the similarities and differences between them , but they do not perform any quantitative analysis .", "label": "", "metadata": {}, "score": "46.668846"}
{"text": "The similarities in cluster results to both the lexical and GR features demonstrates this further .Distributions over CCG categories extracted by the C&C parser trained on Genia .Clockwise from the top left : the heatmap shows the pairwise Jensen - Shannon Divergence ( top half ) and statistical significance ( bottom half ) , as well as the homogeneity ( diagonal ) .", "label": "", "metadata": {}, "score": "46.783386"}
{"text": "Unlike the conventional threshold - comparison VAD algorithms , they are robust to environmental variability and do not need to be dynamically updated .Experimental Setup and Results .Two sets of experiments were carried out by the inventors .The first one evaluated the effectiveness of extracted features for LLRT .", "label": "", "metadata": {}, "score": "46.79789"}
{"text": "Many studies have indeed shown that cross - domain learned corpora yield poor language models [ 35 ] .The field of domain adaptation attempts to compensate for the poor quality of cross - domain data , by adding carefully picked text from other domains [ 36 , 37 ] or other statistical mitigation techniques .", "label": "", "metadata": {}, "score": "46.811462"}
{"text": "In addition , the data in examples are often fictional or come from an unnamed source , especially in the first chapters of the book .Second , in the age of the statistical software boom , it is somewhat surprising to find no practical guidelines regarding how to perform statistical tests with the help of existing packages ( for instance , SPSS , which is extensively used by the author ) .", "label": "", "metadata": {}, "score": "46.861206"}
{"text": "Such lexicon compilation requires highly reliable predicate - argument structures to practically contribute to Natural Language Processing ( NLP ) applications , such as paraphrasing , text entailment , and machine translation .We first apply chunking to raw corpora and then extract reliable chunks to ensure that high - quality predicate - argument structures are obtained from the chunks .", "label": "", "metadata": {}, "score": "46.942047"}
{"text": "Additionally , the intra - subdomain JSD values can be used by themselves to indicate how homogeneous a subdomain is with respect to the given feature set .The choice of sample size is based on general guidelines for significant corpus sizes [ 51 ] , where million - word samples are considered sufficient for specialized language studies .", "label": "", "metadata": {}, "score": "47.008953"}
{"text": "In Proceedings of the 1st international workshop on Text mining in bioinformatics : 2006 .ACM ; 2006:7 - 14 .McInnes BT , Pedersen T , Pakhomov SV : Determining the syntactic structure of medical terms in clinical notes .In Proceedings of the Workshop on BioNLP 2007 : Biological , Translational , and Clinical Language Processing : 2007 .", "label": "", "metadata": {}, "score": "47.083263"}
{"text": "We present a method for acquiring reliable predicate - argument structures from raw corpora for automatic compilation of case frames .Such lexicon compilation requires highly reliable predicate - argument structures to practically contribute to Natural Language Processing ( NLP ) applications , such as par ... \" .", "label": "", "metadata": {}, "score": "47.155132"}
{"text": "We then calculate the Chi - Square statistic & Chi 2 and the degrees of freedom \u03bd from our sample .In our code we will just use the ChiSquare test statistic and pass in two arrays of observed and expected frequencies , but the formula below would be used if we were to do this by hand .", "label": "", "metadata": {}, "score": "47.163315"}
{"text": "It also discusses z - scores and t - scores , which can be used for data standardization .The author provides detailed explanations of how these measures can be computed .The chapter also offers a brief introduction to probability theory and gives examples of different types of distributions .", "label": "", "metadata": {}, "score": "47.20527"}
{"text": "The fact that redundancy never occurs across patients , but within same - patient notes only , seems to create unintended biases in the extracted collocations .The results on the WSJ and its synthetic variants confirm our results on the EHR corpora : collocations extracted on a redundant corpus differ significantly from those extracted on a corpus of similar size without redundancy .", "label": "", "metadata": {}, "score": "47.214638"}
{"text": "In the second submission , also a constituency parsing system , the n - best lists of various parsing models are combined using an approximate sentence - level product model .The third system , the highest ranked system in the dependency parsing track , uses voting over dependency arcs to combine the output of three constituency parsing systems which have been converted to dependency trees .", "label": "", "metadata": {}, "score": "47.274265"}
{"text": "More recently , Perotte et al .leveraged topic models in a supervised framework for the task of assigning ICD-9 codes to discharge summaries [ 29 ] .There , the input consisted of the words in the discharge summaries and the hierarchy of ICD-9 codes .", "label": "", "metadata": {}, "score": "47.300064"}
{"text": "The scatter plot is colored according to the best K - means clustering ( determined by the Gap statistic ) projected onto the first two principal components ( normalized ) .Distributions over noun lemmas as tagged by the C&C parser trained on Genia .", "label": "", "metadata": {}, "score": "47.301212"}
{"text": "Lexical features are fundamental to methods for text classification [ 30 ] , language modelling [ 31 ] and most modern parsing approaches [ 14 , 32 , 33 ] .These systems may therefore be affected by variations in lexical distributions , either as a result of misestimating frequencies or out - of - vocabulary effects .", "label": "", "metadata": {}, "score": "47.344"}
{"text": "Conclusions .Before applying text - mining techniques , one must pay careful attention to the structure of the analyzed corpora .While the importance of data cleaning has been known for low - level text characteristics ( e.g. , encoding and spelling ) , high - level and difficult - to - quantify corpus characteristics , such as naturally occurring redundancy , can also hurt text mining .", "label": "", "metadata": {}, "score": "47.386677"}
{"text": "Most calculations in this chapter are done by the author with the help of SPSS .Chapters 5 and 6 deal with some fundamental issues in corpus linguistics related to word frequency lists and collocation measures .Chapter 5 is probably the most heterogeneous one of the book .", "label": "", "metadata": {}, "score": "47.439796"}
{"text": "In the clinical domain , Arnold et al .[28 ] used LDA for comparing patient notes based on topics .A topic model was learned for different cohorts , with the number of topics derived experimentally based on log - likelihood fit of the created model to a test set .", "label": "", "metadata": {}, "score": "47.5214"}
{"text": "This has led to significant interest in the idea of contrasting domains and the concomitant problem of domain adaptation , as well as the production of manually annotated domain - specific corpora .In this paper we study the phenomenon of subdomain variation , i.e. , the ways in which language use differs in different subareas of a broad domain such as \" biomedicine \" .", "label": "", "metadata": {}, "score": "47.527336"}
{"text": "The Last Informative Note corpus is a subset of All Informative Notes , and contains only the most recent note for each patient .Synthetic WSJ redundant corpora .We construct synthetic corpora with a controllable level of redundancy to compare the behavior of the text mining methods on various levels of redundancy .", "label": "", "metadata": {}, "score": "47.560738"}
{"text": "Baldridge J , Morton T , Bierner G : The opennlp maximum entropy package .[ Technical report , SourceForge ] .Teufel S , Elhadad N : Collection and Linguistic Processing of a Large - scale Corpus of Medical Articles .", "label": "", "metadata": {}, "score": "47.577656"}
{"text": "Furthermore , the dimensions of variation that we identify cover a wide range of features that directly affect NLP applications ; these correspond to variation on the levels of lexicon , semantics , syntax and discourse .In the remainder of this section - before moving on to describe our methods and results - we motivate our work by summarising related prior research on corpus - based analysis of domain and subdomain variation and on the recognised problem of domain adaptation in natural language processing .", "label": "", "metadata": {}, "score": "47.66599"}
{"text": "Co- reference resolution is crucial to many information extraction applications where valuable information may be linked to a referent in this fashion .Nguyen and Kim [ 12 ] compare the use of pronouns in newswire and biomedical text , using the GENIA corpus as representative of the latter , and found significant differences .", "label": "", "metadata": {}, "score": "47.760544"}
{"text": "See Table 2 .The second type of error , loss of signal can also be observed .Another method for selecting the significant collocations is using a top - N cutoff instead of a PMI cutoff .Comparing the top 1,000 collocations with TMI for All Informative Notes and Last Informative Notes , we find a marked difference of 196 collocations .", "label": "", "metadata": {}, "score": "47.81372"}
{"text": "In general , to test random effects , they recommend using Restricted maximum likelihood ( REML ) .For fixed effects testing , they say , \" a likelihood ratio test for REML fits is not feasible , because \" changing the fixed effects specification changes the meaning of the mixed effects , and the restricted model is therefore not nested within the larger model .", "label": "", "metadata": {}, "score": "47.825882"}
{"text": "The results of high redundancy in patient notes are consistent with Wrenn et al .[14 ] observations on a similar EHR dataset .The contrast between same - patient and across - patient redundancy , however , is surprising given that the whole corpus is sampled from a population with at least one shared chronic condition .", "label": "", "metadata": {}, "score": "48.03865"}
{"text": "Smoothing Decision Window .The smoothing window serves two purposes .One is to integrate information from adjacent observations and the other to incorporate continuity constraint to manage the \" hangover \" periods for transition between speech and noise sections .Let c(t ) be the normalized cumulative count of the score tag from the LLRT statistic in a N - frame - long decision window ending at time frame t. It can be expressed as : . c . t . )", "label": "", "metadata": {}, "score": "48.219383"}
{"text": "However , this recognition - based operation may be too expensive for computation - sensitive applications , and therefore , it is mainly used for off - line applications with sufficient resources .Furthermore , it is language - specific and the quality highly depends on the availability of prior knowledge of text .", "label": "", "metadata": {}, "score": "48.34368"}
{"text": "Mutual information and topic modeling .Collocation identification was carried out on the different corpora using the Ngram Statistics Package [ 53 ] , which provides an implementation for collocation detection using True Mutual Information ( TMI ) and Pointwise Mutual Information ( PMI ) .", "label": "", "metadata": {}, "score": "48.35295"}
{"text": "Conventional wisdom is that larger corpora yield better results in text mining .In fact , it is well established empirically that larger datasets yield more accurate models of text processing ( see for example , [ 31 - 34 ] ) .", "label": "", "metadata": {}, "score": "48.418434"}
{"text": "This article needs attention from an expert in Statistics .Please add a reason or a talk parameter to this template to explain the issue with the article .WikiProject Statistics ( or its Portal ) may be able to help recruit an expert .", "label": "", "metadata": {}, "score": "48.432114"}
{"text": "The commonly used chi - squared tests for goodness of fit to a distribution and for independence in contingency tables are in fact approximations of the log - likelihood ratio on which the G - tests are based .This approximation was developed by Karl Pearson because at the time it was unduly laborious to calculate log - likelihood ratios .", "label": "", "metadata": {}, "score": "48.5064"}
{"text": "56 ] .The log - likelihood graphs were computed on withheld datasets .A non - redundant withheld dataset of 233 Informative notes was created for EHR corpus ( all the notes from the same patients were removed from the redundant corpora to prevent contamination between corpora and the withheld dataset ) .", "label": "", "metadata": {}, "score": "48.586117"}
{"text": "Haug P , Koehler S , Lau L , Wang P , Rocha R , Huff S : A natural language understanding system combining syntactic and semantic techniques .Proc Annu Symp Comput Appl Med Care 1994 , 247 - 251 .", "label": "", "metadata": {}, "score": "48.602676"}
{"text": "It discusses four association measures ( i.e. mutual information ( MI ) and its modified version , MI3 , z - score , and log - likelihood ) and compares them in a case study of a small list of collocates .", "label": "", "metadata": {}, "score": "48.649757"}
{"text": "Our method can produce corpora with different redundancy amounts quickly , without alignment of documents and without any prior knowledge of the documents .We confirmed that the parameter of our Selective Fingerprinting method is a good predictor of document alignment and can be used as the sole method for removing redundancy .", "label": "", "metadata": {}, "score": "48.66385"}
{"text": "Even more striking , when examining the behavior of WSJs5 ( with 3,300 documents sampled from 1,300 distinct documents ) up to 100 topics , we observe it reaches the same fit as WSJ-600 .We have seen that for the naturally occurring WSJ corpus training on more data produces better fit to held out data ( see Figure 4 a ) .", "label": "", "metadata": {}, "score": "48.712997"}
{"text": "Verspoor et al .[ 8 ] use measurements of lexical and structural variation to demonstrate that Open Access and subscription - based journal articles in a specific domain ( mouse genomics ) are sufficiently similar that research on the former can be taken as representative of the latter .", "label": "", "metadata": {}, "score": "48.727413"}
{"text": "These information - dense terms could prove useful for tasks like automatic curation of medical ontologies , as they imply relationships between their lexical components , the verbs they modify , and so forth .Distributions over verb lemmas as tagged by the C&C parser trained on Genia .", "label": "", "metadata": {}, "score": "48.769775"}
{"text": "Measuring divergence .Our goal is to illustrate the presence or absence of significant differences among the subdomains for each feature set .The feature sets ( with the exception of the sentential and discourse features ) are represented as probability distributions .", "label": "", "metadata": {}, "score": "48.912792"}
{"text": "As interest in biomedical applications of NLP continues and NLP systems are deployed in increasingly varied contexts , we expect the study of subdomain variation to become ever more important .One direction for future work is to directly measure the effect of subdomain variation on the performance of NLP systems for various tasks .", "label": "", "metadata": {}, "score": "48.94416"}
{"text": "No additional knowledge about the target domain is included .A more realistic approach assumes that only raw text from the target domain is available .This assumption lends itself well to semi - supervised learning methods since these utilize both labeled and unlabeled examples .", "label": "", "metadata": {}, "score": "48.986084"}
{"text": "View Article .Zhou G , Zhao J , Liu K , Cai L : Exploiting web - derived selectional preference to improve statistical dependency parsing .Proceedings of ACL : 2011 , 2011 : 1556 - 1565 .Chen HB , Huang HH , Tan CT , Tjiu J , Chen HH : A statistical medical summary translation system .", "label": "", "metadata": {}, "score": "49.047745"}
{"text": "As described in the previous section , the language of biomedical text differs from general language in many diverse ways , making an awareness of variation effects crucial .Two strategies are available to developers of tools for statistical biomedical text processing : creating a new annotated corpus of domain - specific data , and \" adapting \" a model trained on an existing out - of - domain data set to the domain of interest .", "label": "", "metadata": {}, "score": "49.108017"}
{"text": "That being said , there are a few concerns .First , I have some doubts that the book fully achieves its goal formulated in the preface , namely , to demonstrate how statistics can contribute to linguistic studies .Unfortunately , the examples and topics covered in the book are too limited from a theoretical point of view .", "label": "", "metadata": {}, "score": "49.159195"}
{"text": "To filter out pleonastic pronouns we used a combination of the C&C parser 's pleonasm tag and heuristics based on Lappin and Leass [ 43 ] .Semantic features .To facilitate a robust analysis of semantic differences , we induced a \" topic model \" using Latent Dirichlet Analysis ( LDA ) [ 44 ] .", "label": "", "metadata": {}, "score": "49.236458"}
{"text": "We experimented with filtering low - frequency items at various thresholds , to reduce noise and improve processing speed , and settled on filtering items that occur less than 150 times in the entire corpus .Sentential and discourse features .We measured average sentence , noun phrase and base nominal lengths ( in tokens ) for each subdomain , using the parsed output from C&C.", "label": "", "metadata": {}, "score": "49.242306"}
{"text": "We artificially introduce redundancy by randomly sampling documents and repeating them until a controlled level of redundancy is achieved .Collocation identification .We expect that in a redundant corpus , the word sequences ( n - grams ) which are copied often will be over - represented .", "label": "", "metadata": {}, "score": "49.260513"}
{"text": "As K increases , performance on both data sets improves , but should improve more dramatically on the actual data set as K approaches a natural choice for cluster count .K is selected as the value where the improvement in performance at K + 1 is not significantly more than the improvement in performance on the random data .", "label": "", "metadata": {}, "score": "49.34262"}
{"text": "Minnen G , Carroll J , Pearce D : Applied morphological processing of English .Natural Language Engineering 2001 , 7 ( 3 ) : 207 - 223 .View Article .Miller GA , Beckwith R , Fellbaum C , Gross D , Miller K : Introduction to WordNet :", "label": "", "metadata": {}, "score": "49.376938"}
{"text": "The hypotheses are defined for probability distribution of noise H 0 and for the probability distribution of speech H 1 .The probabilities for x(t ) , given it is a noise frame , and given it is a speech frame , can be written for P 0 t and P 1 t in Equation ( 1 ) .", "label": "", "metadata": {}, "score": "49.453773"}
{"text": "PubMed View Article .Pearson WR : [ 5 ] Rapid and sensitive sequence comparison with FASTP and FASTA .Academic Press ; 1990:63 - 98 .[Methods in Enzymology .vol .Volume 183 ] .HaCohen - Kerner Y , Tayeb A , Ben - Dror N : Detection of simple plagiarism in computer science papers .", "label": "", "metadata": {}, "score": "49.55185"}
{"text": "Gotti M : Investigating Specialized Discourse .Bern : Peter Lang ; 2005 .Curran J , Clark S , Bos J : Linguistically motivated large - scale NLP with C&C and Boxer .Proceedings of the ACL-07 Demo and Poster Sessions , Prague , Czech Republic 2007 .", "label": "", "metadata": {}, "score": "49.653946"}
{"text": "The program storage device as recited in . claim 10 , wherein the step of tagging the frames of the input data based on the log - likelihood ratio test statistic and pitch characteristics include the step of tagging the frames according to an equation : .", "label": "", "metadata": {}, "score": "49.696995"}
{"text": "The scatter plot is colored according to the best K - means clustering ( determined by the Gap statistic ) projected onto the first two principal components ( normalized ) .The relationship between some subdomains is stronger when considering one selectional preference versus another .", "label": "", "metadata": {}, "score": "49.726627"}
{"text": "Note that the cepstrum - based features are primarily chosen for the LLRT statistic in this invention with a major advantage that the efficiency can be maximized by using the same front - end .Speech Recognition .In this test , the speech decoder runs in a modeless fashion , in which both finite - state grammar and statistical language model are enabled .", "label": "", "metadata": {}, "score": "49.751873"}
{"text": "The average amount of redundancy in removed note pairs is sampled as well .Redundancy is computed in the same way as in Section 2.1.1 .We randomly sampled 2,000 same - patient pairs of notes and aligned them using Smith - Waterman alignment .", "label": "", "metadata": {}, "score": "49.81927"}
{"text": "Proceedings of the COLING - ACL-06 Interactive Presentation Sessions , Sydney , Australia 2006 .Lappin S , Leass HJ : An algorithm for pronominal anaphora resolution .Computational Linguistics 1994 , 20 ( 4 ) : 535 - 561 .Blei DM , Ng AY , Jordan MI , Lafferty J : Latent Dirichlet allocation .", "label": "", "metadata": {}, "score": "49.92755"}
{"text": "Otherwise , if the criteria for blocks 74 and 76 are not met , then the nature of the input signal is undecided and the status remains unchanged .In this invention , a novel voice activity detection system and method are disclosed with the use of log - likelihood ratio test .", "label": "", "metadata": {}, "score": "49.957264"}
{"text": "Therefore , a need exists for a system and method which overcomes the deficiencies of the prior art , for example , the lack of robustness in threshold estimation and adaptation , the lack of the ability to handle non - stationary and transient noises and language - dependency .", "label": "", "metadata": {}, "score": "49.97724"}
{"text": "Berlin : De Gruyter Mouton .Harrell , Frank E. Jr. 2001 .Regression Modeling Strategies .With Application to Linear Models , Logistic Regression , and Survival Analysis .New York : Springer .Lijffijt , Jefrey , & Stefan Th .", "label": "", "metadata": {}, "score": "49.9843"}
{"text": "Also , they can achieve good performance in high - SNR environments .However , all these arts rely on either empirically determined thresholds ( fixed or dynamically updated ) , the stationarity assumption of background noise , or the assumption of symmetry distribution process .", "label": "", "metadata": {}, "score": "49.995853"}
{"text": "WSJ data ( Petrov and Klein , 2007 ; Foster , 2010 ) .The parser uses the English signature list described in Attia et al ( 2010 ) to assign partof - speech tags to unknown words . \" ...Domain adaptation is an important task in order for NLP systems to work well in real applications .", "label": "", "metadata": {}, "score": "50.086937"}
{"text": "303 - 307 , 1995 . )These thresholds are usually estimated from noise - only periods and updated dynamically .Many early detection schemes used features like short - term energy , zero crossing , autocorrelation coefficients , pitch , and LPC coefficients ( See , e.g. , L. R. Rabiner , et al . as cited above ) .", "label": "", "metadata": {}, "score": "50.158386"}
{"text": "Whether it fits significantly better and should thus be preferred is determined by deriving the probability or p -value of the difference D .Where the null hypothesis represents a special case of the alternative hypothesis , the probability distribution of the test statistic is approximately a chi - squared distribution with degrees of freedom equal to .", "label": "", "metadata": {}, "score": "50.295803"}
{"text": "Blei DM , Ng AY , Jordan MI : Latent dirichlet allocation .J Mach Learn Res 2003 , 3 : 993 - 1022 .Arnold CW , El - Saden SM , Bui AAT , Taira R : Clinical Case - based Retrieval Using Latent Topic Analysis .", "label": "", "metadata": {}, "score": "50.387627"}
{"text": "However , exceptions to this ( e.g. Gastroenterology ) indicate the relationship is more complex , and requires more detailed analysis .The CCG categories ( Figure 9 ) show the same relationship with long sentence length as GRs .Ethics and Education are back to forming their own cluster .", "label": "", "metadata": {}, "score": "50.42595"}
{"text": "Proceedings of ICML-97 , Nashville , TN 1997 .Brown PF , deSouza PV , Mercer RL , Della Pietra VJ , Lai JC : Class - based n - gram models of natural language .Computational Linguistics 1992 , 18 ( 4 ) : 467 - 479 .", "label": "", "metadata": {}, "score": "50.4445"}
{"text": "For plagiarism detection , HaCohen - Kerner et al .[42 ] compare two fingerprinting methods : ( i ) Full fingerprinting - all substrings of length n of a string are used as fingerprints .This means that for a string of length m , m - n+1 fingerprints will be used ; and ( ii ) Selective Fingerprinting - non - overlapping substrings are chosen .", "label": "", "metadata": {}, "score": "50.501"}
{"text": "These data sets are often drawn from a single register or topical domain , news text being the most common due to its availability in large quantities .For example , syntactic parsers are usually trained and evaluated on the Wall Street Journal portion of the Penn Treebank , though it is known that this gives an overoptimistic view of parser accuracy [ 13 , 14 ] .", "label": "", "metadata": {}, "score": "50.676056"}
{"text": "Dispersions and adjusted frequencies in corpora .International Journal of Corpus Linguistics 13(4 ) .Gries , Stefan Th .Statistics for Linguistics with R. A practical introduction .Berlin : De Gruyter Mouton .Gries , Stefan Th .Statistics for Linguistics with R. A practical introduction .", "label": "", "metadata": {}, "score": "50.834488"}
{"text": "POS tagging is a first step in many NLP tasks , such as morphological analysis and production [ 34 ] and constructing lexical databases [ 35 ] .Syntactic features .Lexical categories that describe a word 's combinatorial properties are essential to the success of some classes of lexicalised statistical parser .", "label": "", "metadata": {}, "score": "50.844837"}
{"text": "The ' independent value ' ( 63 ) in regression modelling is normally called the ' intercept ' ; iv .Gries 's ( 2008 ) DP measure is not the ' Degree of Dispersion ' ( 183 ) , but rather the ' Deviation of Proportions ' ; v. Finally , a normalized version of DP ( Lijffijt & Gries 2012 ) might have been more appropriate to include .", "label": "", "metadata": {}, "score": "51.104942"}
{"text": "EHR corpora , however , exhibit specific characteristics when compared with corpora in the biomedical literature domain or the general English domain .This paper is concerned with the inherent characteristics of corpora composed of longitudinal records in particular and their impact on text - mining techniques .", "label": "", "metadata": {}, "score": "51.111427"}
{"text": "Table 3 compares the results for the MIXED task , in which the embedded command phrases are bounded by short pauses .It is shown that the LLRT - based VAD improves the overall word error rate to 26.6 % in contrast to 28.5 % when no VAD is used .", "label": "", "metadata": {}, "score": "51.132385"}
{"text": "However , most previous work on domain adaptation relied on the implicit assumption that domains are somehow given .As more and more data becomes available , automatic ways to select data that is beneficial for a new ( unknown ) target domain are becoming attractive .", "label": "", "metadata": {}, "score": "51.169052"}
{"text": "Background .Overview of biomedical natural language processing .Research in the field of NLP is concerned with the development of systems that take textual data ( e.g. , research articles or abstracts ) as input and/or output .Examples of these systems encompass \" core \" tasks that often provide components of larger systems , such as syntactic analysis or semantic disambiguation , as well as practical applications for tasks such as summarisation , information extraction and translation .", "label": "", "metadata": {}, "score": "51.175186"}
{"text": "Perotte A , Bartlett N , Elhadad N , Wood F : Hierarchically Supervised Latent Dirichlet Allocation .[ NIPS :2011 ] .Bisgin H , Liu Z , Fang H , Xu X , Tong W : Mining FDA drug labels using an unsupervised learning technique - topic modeling .", "label": "", "metadata": {}, "score": "51.222992"}
{"text": "The step of determining a second probability may include the step of comparing the given frame to a model of Gaussian mixtures for speech .The methods may be performed by a program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform the method steps .", "label": "", "metadata": {}, "score": "51.244385"}
{"text": "Semantic features capture what a text is \" about \" at a more general and interpretable level than individual lexical features .One approach we adopted , known as \" topic modelling \" , models each document of interest as a mixture of distributions over words or \" topics \" that have been induced automatically from the corpus .", "label": "", "metadata": {}, "score": "51.302025"}
{"text": "The All EHR corpus , which contains all notes of all types , fits between these two extremes , since we expect less redundancy across note types , even for a single patient .One standard way of characterizing large corpora is to plot the histogram of terms and their raw frequencies in the corpus .", "label": "", "metadata": {}, "score": "51.433784"}
{"text": "It is due to the artifact that preceding decoded context before each speech / noise transition is discarded such that the language model stifles on the dictation portions .LLRT VAD in Noisy Environments .To test the robustness of VAD , another set of noisy test data is collected from one male speaker by playing a pre - recorded cafeteria noise during recording , including the NOISY - C&C and NOISY - MIXED task .", "label": "", "metadata": {}, "score": "51.46456"}
{"text": "Figure 1 further details the full histogram of redundancy for pairs of same - patient informative notes .The redundancy ( percentage of aligned tokens ) was computed for the notes of a random sample of 100 patients .For instance , it indicates that 7.6 % of the same patient note pairs in the corpus have between 20 % and 30 % identity .", "label": "", "metadata": {}, "score": "51.50474"}
{"text": "Our results suggest that not only are these resources tuned for a handful of subdomains , but these subdomains exhibit a narrow range of linguistic behaviour , less representative of other biomedical subdomains .This is true for both lexical features ( e.g. nouns , Figure 4 ) and syntactic features ( e.g. GRs , Figure 5 ) .", "label": "", "metadata": {}, "score": "51.69761"}
{"text": "We focus on the All Informative Notes corpus .The metadata - based baseline produces the Last Informative Note corpus .The content - based mitigation strategy , which relies on fingerprinting , can produce corpora with varying levels of redundancy .", "label": "", "metadata": {}, "score": "51.724922"}
{"text": "[ 1 ] .Each of the two competing models , the null model and the alternative model , is separately fitted to the data and the log- likelihood recorded .The test statistic ( often denoted by D ) is twice the log of the likelihoods ratio , i.e. , it is twice the difference in the log - likelihoods : .", "label": "", "metadata": {}, "score": "51.775185"}
{"text": "Fingerprinting algorithm .Detecting redundancy within the notes of a single patient is feasible using standard alignment methods borrowed from bioinformatics such as : Smith - Waterman [ 52 ] , FastA [ 41 ] or Blast2seq [ 40 ] .However , some available EHR corpora are de - identified to protect patient privacy [ 57 ] and notes are not grouped by patients .", "label": "", "metadata": {}, "score": "51.8226"}
{"text": "The input , Full EHR corpus , is the largest .As expected , the Last Informative Note corpus obtained through our metadata - based baseline is the smallest corpus .While redundancy is reduced , its size is also drastically decreased from the original corpus .", "label": "", "metadata": {}, "score": "51.975143"}
{"text": "This is expected based on the definition of PMI , and we confirm this prediction on WSJx2 and WSJx3 which produce exactly the same list of collocations as WSJ-1300 ( WSJx2 is a corpus constructed by doubling every document in WSJ-1300 ) .", "label": "", "metadata": {}, "score": "52.099777"}
{"text": "Web - scale experiments show that the DMV , perhaps because it is unlexicalized , does not benefit from orders of magnitude more annotated but noisier data .Our model , trained on a single blog , generalizes to 53.3 % accuracy out - of - domain , against the Brown corpus - nearly 10 % higher than the previous published best .", "label": "", "metadata": {}, "score": "52.12404"}
{"text": "Secondly , academic writing places greater demands on the reader by omitting non - essential information , through the frequent use of passivisation , nominalisation and noun compounding .Biber and Gray also show that these tendencies towards \" less elaborate and less explicit \" language have become more pronounced in recent history .", "label": "", "metadata": {}, "score": "52.140724"}
{"text": "Semantic features .A reasonable first expectation is for the topic modelling results ( Figure 3 ) to be similar to the lexical features .This largely holds : 8/12 binary pairings of leaf subdomains in the noun dendrogram are also present in the topic modelling dendrogram , and the exceptions are generally displaced by one or two places and are attested in other vocabulary feature sets .", "label": "", "metadata": {}, "score": "52.20784"}
{"text": "PubMed View Article .Nguyen NL , Kim JD : Exploring domain differences for the design of a pronoun resolution system for biomedical text .Proceedings of COLING-08 , Manchester , UK 2008 .Gildea D : Corpus variation and parser performance .", "label": "", "metadata": {}, "score": "52.25954"}
{"text": "View Article .Carreras X , M\u00e0rquez L : Introduction to the CoNLL-2004 shared task : Semantic role labeling .Proceedings of CoNLL-04 , Boston , MA 2004 .Sarkar A , Xia F , Joshi A : Some experiments on indicators of parsing complexity for lexicalized grammars .", "label": "", "metadata": {}, "score": "52.277397"}
{"text": "The program storage device as recited in . claim 10 , wherein the step of providing a smoothing window of N frames includes the formula : . where w(t ) is the smoothing window , t is time , and \u03b1 is a decay constant .", "label": "", "metadata": {}, "score": "52.37648"}
{"text": "These two types of variation , the introduction of completely new nouns and the modified behaviour of common verbs , call for different adaptation techniques .For example , self - training can be used to re - estimate distributional properties of common verbs but may be less successful at handling the out - of - vocabulary effects caused by unseen nouns .", "label": "", "metadata": {}, "score": "52.401222"}
{"text": "Chapter 3 discusses univariate and bivariate parametric and non - parametric tests that can be used to compare two or more groups or investigate relationships between variables .The chapter begins with an overview of the most important statistics , where the author explains how to use the tests appropriately depending on specific research questions and characteristics of the available data .", "label": "", "metadata": {}, "score": "52.538567"}
{"text": "In the highly - redundant All Informative Notes corpus , the peak is the most pronounced , with more concepts occurring four to eight times in the corpus than once .Concept - distribution .Distribution of UMLS concept occurrences in corpora with different levels of redundancy .", "label": "", "metadata": {}, "score": "52.557846"}
{"text": "The non - distributional sentential and discourse features are directly reported as tables .The JSD values for the lexical and syntactic feature sets are presented in four figures per feature set : a heat map , a dendrogram , a distributional line plot , and a scatter plot .", "label": "", "metadata": {}, "score": "52.598427"}
{"text": "The likelihood ratio test statistic is [ 7 ] .A likelihood ratio test is any test with critical region ( or rejection region ) of the form where is any number satisfying .Many common test statistics such as the Z -test , the F -test , Pearson 's chi - squared test and the G -test are tests for nested models and can be phrased as log - likelihood ratios or approximations thereof .", "label": "", "metadata": {}, "score": "52.64563"}
{"text": "A system and method for voice activity detection , in accordance with the invention includes the steps of inputting data including frames of speech and noise , and deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic and pitch .", "label": "", "metadata": {}, "score": "52.76454"}
{"text": "Therefore , it is more robust with respect to the background noise environments than the conventional threshold - comparison approaches .Further , surprising improvements are gained when pith is considered along with LLRT to detect voice .Combined with a smoothing technique based on a running decision window , the present invention is capable of preserving continuity constraints and easily controlling the \" hangover \" periods to ensure proper segment length .", "label": "", "metadata": {}, "score": "52.804016"}
{"text": "Proceedings of NIPS-02 , Vancouver , BC 2002 .Nivre J , Hall J , Nilsson J , Chanev A , Eryi\u011fit G , K\u00fcbler S , Marinov S , Marsi E : MaltParser : A language - independent system for data - driven dependency parsing .", "label": "", "metadata": {}, "score": "52.842007"}
{"text": "Results and Discussion .General observations .The most striking general trend is the strong similarity between Biochemistry , Genetics and Molecular Biology .These subdomains form the most consistent cluster across feature sets , and are often one of the most closely - related triplets in the dendrograms ( e.g. adjectives , Figure 2 , topic modelling , Figure 3 ) .", "label": "", "metadata": {}, "score": "52.957047"}
{"text": "Topic modeling .The algorithm for topic modeling that we analyze , LDA , is a complex inference process which captures patterns of word co - occurrences within documents .To investigate the behavior of LDA on corpora with varying levels of redundancy , we rely on two standard evaluation criteria : log - likelihood fit on withheld data and the number of topics required in order to obtain the best fit on the withheld data .", "label": "", "metadata": {}, "score": "52.963257"}
{"text": "Less stringent metrics include : amount of shared words , amount of shared concepts or amount of overlapping bi - grams [ 16 ] .While these methods have been shown to identify semantic similarity of texts , they do not specifically capture instances of copy - paste operations , which reproduce whole paragraphs .", "label": "", "metadata": {}, "score": "53.129475"}
{"text": "1 , where the models output at blocks 22 and 28 provide the input for determining probabilities based on LLRT .Pitch is computed in block 65 for each input signal , x(t ) .Pitch may be computed by conventional means .", "label": "", "metadata": {}, "score": "53.163937"}
{"text": "All Informative , input corpus , the corpus obtained by the redundancy reduction baseline ( Last Informative Note ) , and the corpora produced by the fingerprinting redundancy reduction strategy at different level .Computation time for constructing a redundancy - reduced corpus at a given similarity threshold using the selective fingerprinting is 6 minutes ( with an Intel Xeon CPU X5570 2.93 GHz ) .", "label": "", "metadata": {}, "score": "53.18766"}
{"text": "The scatter plots project the optimal K - Means clustering onto the first two principal components of the data .The components are normalised , and points coloured according to cluster membership , with the subdomain written immediately above .The \" Newswire \" subdomain is not included in the plots : as an outlier , it compresses the subdomains into unreadability .", "label": "", "metadata": {}, "score": "53.277145"}
{"text": "We compare the performance of standard algorithms for collocation identification and topic modeling inference on a variety of corpora with different redundancy levels .We introduce synthetic corpora where we can control the level of redundancy .These synthetic corpora are derived from the Wall Street Journal ( WSJ ) standard corpus .", "label": "", "metadata": {}, "score": "53.309467"}
{"text": "These works aim to predict the parser performance on a given target sentence .Ravi et al .( 2008 ) frame this as a regression problem .Kawahara and Uchimoto ( 2008 ) treat ... . \" ...Genre classification has been found to improve performance in many applications of statistical NLP , including language modeling for spoken language , domain adaptation of statistical parsers , and machine translation .", "label": "", "metadata": {}, "score": "53.326397"}
{"text": "The NSP package we use in our experiments is widely used for collocation and n - gram extraction in the clinical domain [ 19 - 22 ] .Collocations in a corpus of clinical notes are prime candidates to be mapped to meaningful phenotypes [ 19 - 21 ] .", "label": "", "metadata": {}, "score": "53.43117"}
{"text": "Joshi M , Pedersen T , Maclin R : A comparative study of support vector machines applied to the supervised word sense disambiguation problem in the medical domain .[ Proceedings of the 2nd Indian International Conference on Artificial Intelligence ( IICAI'05 ) : 2005 ] .", "label": "", "metadata": {}, "score": "53.44262"}
{"text": "There are many examples of corpora constructed to facilitate the implementation and evaluation of tools for specific problems in biomedical language processing , for example the BioScope corpus [ 21 ] for speculative language detection and the BioCreative I and II gene normalisation corpora [ 22 , 23 ] .", "label": "", "metadata": {}, "score": "53.450653"}
{"text": "The dendrogram shows hierarchical clustering based on cosine difference between each subdomain 's JSD values .The scatter plot is colored according to the best K - means clustering ( determined by the Gap statistic ) projected onto the first two principal components ( normalized ) .", "label": "", "metadata": {}, "score": "53.50297"}
{"text": "The dendrogram shows hierarchical clustering based on cosine difference between each subdomain 's JSD values .The scatter plot is colored according to the best K - means clustering ( determined by the Gap statistic ) projected onto the first two principal components ( normalized ) .", "label": "", "metadata": {}, "score": "53.50297"}
{"text": "The last decade witnessed a technological leap in natural language computation , whereby manually crafted rules gradually give way to more robust corpus - based statistical methods .This is also the case for metaphor research .In the recent years , the problem of metaphor modeling has been steadily gaining interest within the NLP community , with a growing number of approaches exploiting statistical techniques .", "label": "", "metadata": {}, "score": "53.565266"}
{"text": "The first submission , the highest ranked constituency parsing system , uses a combination of PCFG - LA product grammar parsing and self - training .In the second submission , also a constituency parsing ... \" .The DCU - Paris13 team submitted three systems to the SANCL 2012 shared task on parsing English web text .", "label": "", "metadata": {}, "score": "53.620735"}
{"text": "Bodenreider O : The unified medical language system ( UMLS ) : integrating biomedical terminology .Nucleic Acids Res 2004 , 32 : D267 .PubMed View Article .Gildea D : Corpus variation and parser performance .Citeseer ; 2001:167 - 202 .", "label": "", "metadata": {}, "score": "53.6705"}
{"text": "The decision to study verb classes was motivated by the fact that classifications of verbs have been shown to capture a variety of important syntactic and semantic behaviour [ 47 , 48 ] .By learning classes directly from the corpus , we induced a classification that reflects the characteristics of biomedical text and its subdomains .", "label": "", "metadata": {}, "score": "53.758904"}
{"text": "This paper identifies a characteristic of EHR text corpora : their inherent high level of redundancy , caused by the process of cut and paste involved in the creation and editing of patient notes by health providers .We empirically measure this level of redundancy on a large patient note corpus , and verify that such redundancy introduces unwanted bias when applying standard text mining algorithms .", "label": "", "metadata": {}, "score": "53.812096"}
{"text": "We also investigated a more specific kind of semantic behaviour relating to verb - argument predication .This was motivated by the observation that relations between verbs and their arguments are central to important semantic tasks such as semantic role labelling [ 37 , 38 ] .", "label": "", "metadata": {}, "score": "53.813084"}
{"text": "We empirically measure the damage caused by redundancy on the tasks of collocation extraction and topic modeling through a series of controlled experiments .Preliminary qualitative inspection of the results suggests that idiosyncrasies of each patient ( where the redundancy occurs ) explain the observed bias .", "label": "", "metadata": {}, "score": "53.882954"}
{"text": "Distributions over grammatical relations extracted by the C&C parser trained on Genia .Clockwise from the top left : the heatmap shows the pairwise Jensen - Shannon Divergence ( top half ) and statistical significance ( bottom half ) , as well as the homogeneity ( diagonal ) .", "label": "", "metadata": {}, "score": "53.911247"}
{"text": "EHR corpora , however , exhibit specific statistical and linguistic characteristics when compared with corpora in the biomedical literature domain .We focus on copy - and - paste redundancy : clinicians typically copy and paste information from previous notes when documenting a current patient encounter .", "label": "", "metadata": {}, "score": "53.918076"}
{"text": "We investigate whether a redundant corpus exhibits a different distribution of concepts than a less redundant one .We expect that different subsets of the EHR corpus exhibit different levels of redundancy .The All Informative Notes corpus , which contains several notes per patient , but only the ones of types : \" primary - provider \" , \" clinical - note \" and \" follow - up - note \" , is assumed to be highly redundant , since it is homogeneous in style and clinical content .", "label": "", "metadata": {}, "score": "54.103035"}
{"text": "Note that the WSJs5 corpus has roughly 2.5 times the size of WSJ-1300 .The process was repeated 10 times to eliminate bias from the choice of documents repeated .Synthetic corpora with various levels of redundancy , for WSJs5 we report averages and standard deviation based on 10 replications .", "label": "", "metadata": {}, "score": "54.12555"}
{"text": "On this synthetic corpus , we obtain a different list of collocations when using the PMI algorithm : 17,015(\u00b1950 ) instead of 2,737 .The growth in number of extracted collocations is expected since WSJs5 is 2.5 times larger than WSJ-1300 , but this growth is less than expected when comparing the trend ( WSJ-400 , WSJ-600 , WSJ-1300 ) with a growth of ( 565 , 1,000 and 2,737 ) extracted collocations .", "label": "", "metadata": {}, "score": "54.13188"}
{"text": "I think the dependency on N ( total number of words in text being analyzed ) is correct .So the larger the value of N , the higher must be the value of n12 for H0 to be rejected .The algorithm is not mine ( in the post I have a link to a page which shows its use in an engineering context ) , so chances of it being wrong is low :-) .", "label": "", "metadata": {}, "score": "54.15558"}
{"text": "claim 1 , wherein the step of providing a smoothing window of N frames includes the formula : . where w(t ) is the smoothing window , t is time , and \u03b1 is a decay constant .The method as recited in .", "label": "", "metadata": {}, "score": "54.29184"}
{"text": "Abstract .A system and method for voice activity detection , in accordance with the invention includes the steps of inputting data including frames of speech and noise , and deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic and pitch .", "label": "", "metadata": {}, "score": "54.311493"}
{"text": "Distributions over adverb lemmas as tagged by the C&C parser trained on Genia .Clockwise from the top left : the heatmap shows the pairwise Jensen - Shannon Divergence ( top half ) and statistical significance ( bottom half ) , as well as the homogeneity ( diagonal ) .", "label": "", "metadata": {}, "score": "54.41421"}
{"text": "Two implications of noise are possible .The first is false positive identification , i.e. , extracting collocations which are the result of mere chance .The second implication is loss of significant collocations due to noise ( or because important collocations are out - ranked by less important ones ) .", "label": "", "metadata": {}, "score": "54.460636"}
{"text": "Baayen , R. Harald .Analyzing Linguistic Data .A Practical Introduction to Statistics Using R. Cambridge : Cambridge University Press .Dunning , Ted .Accurate methods for the statistics of surprise and coincidence .Computational Linguistics 19 ( 1 ) .", "label": "", "metadata": {}, "score": "54.55931"}
{"text": "The parameter n is the granularity of the method , and its choice determines how stringent the comparison is .In order to compare two notes A and B , we compute the number of fingerprints shared by A and B. The level of similarity of B to A is defined as the ratio ( number of shared fingerprints ) / ( number of fingerprints in A ) .", "label": "", "metadata": {}, "score": "54.569607"}
{"text": "In summary , it uses MFCC - based front - end signal processing in a 39-dimensional feature vector computed every 10 micro - seconds .The acoustic features are labeled according to the sub - phonetic units constructed using a phonetic decision tree .", "label": "", "metadata": {}, "score": "54.627205"}
{"text": "A program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform method steps for voice activity detection , the method steps comprising : . inputting data including frames of speech and noise ; . deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic and pitch ; . tagging the frames of the input data based on the log - likelihood ratio test statistic and pitch characteristics of the input data as being most likely noise or most likely speech ; and .", "label": "", "metadata": {}, "score": "54.738766"}
{"text": "Approximation techniques to make this problem tractable were developed in bioinformatics to search sequence databases and for plagiarism detection .In both fields , fingerprinting schemes are applied .In BLAST , short substrings are used as fingerprints , whose length is defined by biological significance .", "label": "", "metadata": {}, "score": "54.75294"}
{"text": "International Journal of Lexicography 1990 , 3 ( 4 ) : 235 - 244 .View Article .Hockenmaier J : Data and Models for Statistical Parsing with Combinatory Categorial Grammar .PhD thesis .University of Edinburgh ; 2003 .Gildea D , Jurafsky D : Automatic labeling of semantic roles .", "label": "", "metadata": {}, "score": "54.78461"}
{"text": "Observed frequencies are first recorded in a contingency table .where : .We then compute a table of expected frequencies from the marginal value of the observed frequencies .Values of E ij are calculated thus : .N m ( i ) N m ( j ) .", "label": "", "metadata": {}, "score": "55.059532"}
{"text": "Int J Med Inform 2002 , 67 ( 1/3 ) : 63 - 74 .PubMed View Article .Kullo IJ , Fan J , Pathak J , Savova GK , Ali Z , Chute CG : Leveraging informatics for genetic studies : use of the electronic medical record to enable a genome - wide association study of peripheral arterial disease .", "label": "", "metadata": {}, "score": "55.092354"}
{"text": "t . ) when .^ .t . ) score2 . t . ) with . pitch .without . pitch .\u03bb is a weighting factor for LLRT which may be experimentally determined or set in accordance with a user 's confidence that pitch is present .", "label": "", "metadata": {}, "score": "55.100403"}
{"text": "x .t . )H .P .t .Prob .x .t . )H .Then the following decisions may be made based on the likelihood ratio test statistic as : . if .t . ) then .", "label": "", "metadata": {}, "score": "55.18107"}
{"text": "Sentential and discourse features .Sentence length is known to roughly correlate with parsing difficulty and syntactic complexity [ 39 ] .Noun phrase ( NP ) length increases as more information is \" packed \" via pre-/post - modification .Scientific language is known to aim for high information density [ 7 , 40 ] .", "label": "", "metadata": {}, "score": "55.182907"}
{"text": "Chapter 4 describes four multivariate statistical methods : cluster analysis in its hierarchical and non - hierarchical ( i.e. k - means ) instantiations , discriminant functions , factor analysis , and multiple linear regression .As in the previous chapter , the assumptions that should be met are discussed for each method .", "label": "", "metadata": {}, "score": "55.241333"}
{"text": "As such , the LDA topics group words that tend to co - occur .From the viewpoint of disease modeling , LDA topics are an attractive data modeling and corpus exploration tool .As illustrative examples , we show the top-20 tokens corresponding to three topics acquired from a corpus of patient notes in Table 1 .", "label": "", "metadata": {}, "score": "55.269638"}
{"text": "In this way , the noise data is pooled for clustering .The noise data is clustered into classes or clusters to associate similar noise labeled training data , in block 20 .Clustering may be based on , for example , different background ambient environments .", "label": "", "metadata": {}, "score": "55.28833"}
{"text": "Our observation can be put into a contingency table with rows corresponding to the coin and columns corresponding to heads or tails .The elements of the contingency table will be the number of times the coin for that row came up heads or tails .", "label": "", "metadata": {}, "score": "55.66035"}
{"text": "The scatter plot is colored according to the best K - means clustering ( determined by the Gap statistic ) projected onto the first two principal components ( normalized ) .The line plot shows the intra - subdomain spread of JSD values generated by random sampling .", "label": "", "metadata": {}, "score": "55.691322"}
{"text": "The scatter plot is colored according to the best K - means clustering ( determined by the Gap statistic ) projected onto the first two principal components ( normalized ) .The line plot shows the intra - subdomain spread of JSD values generated by random sampling .", "label": "", "metadata": {}, "score": "55.691322"}
{"text": "The scatter plot is colored according to the best K - means clustering ( determined by the Gap statistic ) projected onto the first two principal components ( normalized ) .The line plot shows the intra - subdomain spread of JSD values generated by random sampling .", "label": "", "metadata": {}, "score": "55.691322"}
{"text": "The scatter plot is colored according to the best K - means clustering ( determined by the Gap statistic ) projected onto the first two principal components ( normalized ) .The line plot shows the intra - subdomain spread of JSD values generated by random sampling .", "label": "", "metadata": {}, "score": "55.691322"}
{"text": "This gives us 10,000 JSD values calculated between random articles drawn from this subdomain ( hereafter called \" intra - subdomain \" , in contrast to \" inter - subdomain \" ) .The significance of an inter - subdomain JSD value X between subdomains A and B is the proportion of intra - subdomain JSD values from A and B that are less than X .", "label": "", "metadata": {}, "score": "55.796043"}
{"text": "Acknowledgements .This work was supported by EPSRC grant EP / G051070/1 and the Royal Society , UK .Authors ' contributions .TL and DO collected and pre - processed the corpora and performed the feature extraction .TL carried out the distribution and clustering experiments and designed heat maps , dendrograms , plots and tables included this paper .", "label": "", "metadata": {}, "score": "55.832775"}
{"text": "An alternative route to text mining in the presence of high levels of redundancy consists of keeping all the existing redundant data , but designing redundancy immune statistical learning algorithms .This is a promising route of future research .Methods .", "label": "", "metadata": {}, "score": "55.864487"}
{"text": "The WSJx2 corpus is constructed from WSJ-1300 to simulate redundancy , where each document of WSJ-1300 appears twice in the corpus .The WSJx3 corpus is similar to the WSJx2 corpus , except it contains three copies of each document in the WSJ-1300 corpus .", "label": "", "metadata": {}, "score": "56.007477"}
{"text": "Holm L , Sander C : Removing near - neighbour redundancy from large protein sequence collections .Bioinformatics 1998 , 14 ( 5 ) : 423 .PubMed View Article .Bateman A , Birney E , Durbin R , Eddy SR , Howe KL , Sonnhammer ELL : The Pfam protein families database .", "label": "", "metadata": {}, "score": "56.036377"}
{"text": "Background .Applications of Natural Language Processing ( NLP ) technology to biomedical texts have generated significant interest in recent years .In this paper we identify and investigate the phenomenon of linguistic subdomain variation within the biomedical domain , i.e. , the extent to which different subject areas of biomedicine are characterised by different linguistic behaviour .", "label": "", "metadata": {}, "score": "56.050156"}
{"text": "information for discourse and domain knowledge sub - processes .A table processing system ( TabPro ) is being developed and part of that research requires the construction of a corpus of documents containing tables .This corpus is used for training classification processes and evaluating the performance of the system as a whole .", "label": "", "metadata": {}, "score": "56.086437"}
{"text": "[ 39 ] suggested a model for unsupervised information extraction which takes redundancy into account when extracting information from the web .They showed that the popular information extraction method , Pointwise Mutual Information ( PMI ) , is less accurate by an order of magnitude compared to a method with redundancy handling .", "label": "", "metadata": {}, "score": "56.10244"}
{"text": "The first test data was the C&C task , in which each utterance included 1 to 5-command phrases with short pauses ranging approximately from 100 micro - seconds and 1.5 seconds .Table 2 compares the recognition results obtained when the LLRT - based VAD , a conventional adaptive energy - comparison VAD ( Energy - Comp . ) , or no VAD ( Baseline ) is used .", "label": "", "metadata": {}, "score": "56.21586"}
{"text": "The likelihood ratio test rejects the null hypothesis if the value of this statistic is too small .How small is too small depends on the significance level of the test , i.e. , on what probability of Type I error is considered tolerable ( \" Type I \" errors consist of the rejection of a null hypothesis that is true ) .", "label": "", "metadata": {}, "score": "56.23996"}
{"text": "Table 4 shows each subdomain 's average sentence , base noun phrase , and full noun phrase lengths ( in tokens ) .As mentioned in the previous section , sentence length correlates with certain aspects of the syntactic features , particularly at longer sentence lengths .", "label": "", "metadata": {}, "score": "56.256348"}
{"text": "470 - 473 , May 1997 ; L. R. Rabiner , et al . , \" Application of an LPC Distance Measure to the Voiced - Unvoiced - Silence Detection Problem , \" IEEE Trans . on ASSP , vol .ASSP-25 , no . 4,pp .", "label": "", "metadata": {}, "score": "56.283577"}
{"text": "Journal of the American Medical Informatics Association 1994 , 1 ( 2 ) : 142 - 160 .PubMed View Article .Friedman C , Shagina L , Lussier Y , Hripcsak G : Automated encoding of clinical documents based on natural language processing .", "label": "", "metadata": {}, "score": "56.347652"}
{"text": "Changes in their distribution would affect parsing accuracy , but could be a tractable starting - point for domain adaptation if the problem is anticipated .Grammatical relations ( GR ) , also called syntactic dependencies , specify relationships between words , and by extension , between higher - level syntactic structures .", "label": "", "metadata": {}, "score": "56.425766"}
{"text": "It would be useful , therefore , if the book were to contain at least an appendix with relevant codes .Another problematic issue is the imprecise use of statistical terminology .Consider the following , more small - scale errors : i. Figure 1.12 is called a histogram ( 21 ) , but is really a standard x - y plot without bars ; ii .", "label": "", "metadata": {}, "score": "56.434845"}
{"text": "Distributional line plots .The line plots present the distribution of intra - subdomain JSD values , with each line representing a subdomain .Higher values for one subdomain versus another shows that its texts have more variety with respect to that feature .", "label": "", "metadata": {}, "score": "56.441856"}
{"text": "Daum\u00e9 H III , Marcu D : Domain adaptation for statistical classifiers .Journal of Artificial Intelligence Research 2006 , 26 : 101 - 126 .Jiang J , Zhai C : Instance weighting for domain adaptation in NLP .Proceedings of ACL-07 , Prague , Czech Republic 2007 .", "label": "", "metadata": {}, "score": "56.468758"}
{"text": "Detecting Drug Interactions From Adverse - Event Reports : Interaction Between Paroxetine and Pravastatin Increases Blood Glucose Levels .Clin Pharmacol Ther 2011 , 90 ( 1 ) : 133 - 142 .PubMed View Article .Wang X , Hripcsak G , Markatou M , Friedman C : Active Computerized Pharmacovigilance Using Natural Language Processing , Statistics , and Electronic Health Records : A Feasibility Study .", "label": "", "metadata": {}, "score": "56.471786"}
{"text": "Some clusters of subdomains recur across features , and we present a useful breakdown in Table 3 : these subdomain clusters are present in the optimal clustering for at least 8/10 of the feature sets .The first cluster includes subdomains dealing primarily with microscopic processes and can be further subdivided into groupings of biochemical ( Biochemistry , Genetics ) and cellular ( Cell Biology , Embryology ) study .", "label": "", "metadata": {}, "score": "56.559395"}
{"text": "However , even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena .At the same time , recent work on computational lexical semantics and lexical acquisition techniques , as well as a wide range of NLP methods applying machine learning to open - domain semantic tasks , open many new avenues for creation of large - scale robust tools for recognition and interpretation of metaphor .", "label": "", "metadata": {}, "score": "56.602245"}
{"text": "With these goals in mind , one might want to identify concepts that are associated by looking for frequently co - occurring pairs of concepts or phrases in patient notes , or cluster concepts across patients to identify latent variables corresponding to clinical models .", "label": "", "metadata": {}, "score": "56.6276"}
{"text": "They confirm that in outpatient notes , like for inpatient notes , there is a large amount of redundancy .Different metrics for quantifying redundancy exist for text .Sequence alignment methods such as the one proposed by Zhang et al .", "label": "", "metadata": {}, "score": "56.66092"}
{"text": "Distributions over verb classes built from clustering on the semantics of the object .Clockwise from the top left : the heatmap shows the pairwise Jensen - Shannon Divergence ( top half ) and statistical significance ( bottom half ) , as well as the homogeneity ( diagonal ) .", "label": "", "metadata": {}, "score": "56.7324"}
{"text": "claim 1 , wherein the step of deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic includes the step of : . determining a first probability that a given frame of the input data is noise ; . determining a second probability that the given frame of the input data is speech ; and . determining a LLRT statistic by taking a difference between the logarithms of the first probability from the second probability .", "label": "", "metadata": {}, "score": "56.750774"}
{"text": "Description .BACKGROUND OF THE INVENTION .Field of the Invention .The present invention relates to speech recognition , and more particularly to a system and method for discriminating speech ( silence ) using a log - likelihood ratio and pitch .", "label": "", "metadata": {}, "score": "56.87973"}
{"text": "Redundancy across two documents may be measured in different manners : shared words , shared concepts or overlapping word sequences .The most stringent method examines word sequences , and allows for some variation in the sequences ( missing or changed words ) .", "label": "", "metadata": {}, "score": "57.140358"}
{"text": "It should be understood that the elements shown in FIGS . 1 - 2 may be implemented in various forms of hardware , software or combinations thereof .Preferably , these elements are implemented in software on one or more appropriately programmed general purpose digital computers having a processor and memory and input / output interfaces .", "label": "", "metadata": {}, "score": "57.158947"}
{"text": "View Article .Verspoor K , Cohen KB , Hunter L : The textual characteristics of traditional and Open Access scientific journals are similar .BMC Bioinformatics 2009 , 10 : 183 .PubMed View Article .Friedman C , Kraa P , Rzhetsky A : Two biomedical sublanguages : a description based on the theories of Zellig Harris .", "label": "", "metadata": {}, "score": "57.1939"}
{"text": "Metric for assessing redundancy at the patient level .Given two notes , we computed redundancy for the pair by aligning the two notes .We applied the Smith - Waterman text alignment algorithm , a commonly used string alignment algorithm in bioinformatics [ 52 ] .", "label": "", "metadata": {}, "score": "57.264942"}
{"text": "Pfam [ 44 ] is a non - redundant protein sequence database manually built using representatives from each protein family .This database is used for construction of Hidden - Markov - Model classifiers widely used in Bioinformatics .When constructing a corpus of patient notes for statistical purposes , we encounter patients with many records .", "label": "", "metadata": {}, "score": "57.31451"}
{"text": "It also contains chapters on fundamental corpus - linguistic topics , namely , word frequency lists and collocations .The book consists of six chapters , a list of references and an index .It also includes a vast appendix , which contains tables with critical values of the most important statistical distributions and a table with examples of appropriate statistical tests for different types of variables .", "label": "", "metadata": {}, "score": "57.326843"}
{"text": "2 is a block / flow diagram of a system / method for voice activity detection in accordance with the present invention .DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS .The present invention includes a voice activity ( VAD ) system and method based on a log - likelihood ratio test statistic and pitch combined with a smoothing technique using a running decision window .", "label": "", "metadata": {}, "score": "57.420868"}
{"text": "H 1 input is from probability distribution of speech .The probabilities for x(t ) , given it is a noise frame , and given it is a speech frame , can be written , respectively as : .P .t .", "label": "", "metadata": {}, "score": "57.454403"}
{"text": "A score tag , Tag(t ) , is generated for each input signal , x(t ) , based on the LLRT statistic or the decision to reject or accept H 0 .Pitch For VAD .Pitch is a feature used in some speech applications such as speech synthesis and speech analysis .", "label": "", "metadata": {}, "score": "57.46509"}
{"text": "Distributions over parts of speech as tagged by the C&C parser trained on Genia .Clockwise from the top left : the heatmap shows the pairwise Jensen - Shannon Divergence ( top half ) and statistical significance ( bottom half ) , as well as the homogeneity ( diagonal ) .", "label": "", "metadata": {}, "score": "57.483635"}
{"text": "Table 8 provides descriptive statistics of the different WSJ - based corpora with which we experiment : .The WSJ-1300 corpus contains a random sample of 1,300 documents from the Wall Street Journal corpus , .The WSJ-400 corpus is a subset of WSJ-1300 of 400 documents , .", "label": "", "metadata": {}, "score": "57.73526"}
{"text": "Biomedical Engineering , Medical Informatics and Therapeutics make particular use of present tense verbs and determiners , and markedly less of past tense .The cluster including Communicable Disease and Critical Care shows the opposite trend , perhaps reflecting certain subdomains ' use of narrative .", "label": "", "metadata": {}, "score": "57.778835"}
{"text": "It also may indicate that Biomedical Engineering and Medical Informatics retain aspects of both scientific and general language syntax .Subdomains extremely far from the centre ( top - left ) , e.g. Endocrinology and Vascular Disease , are never grouped together in the lexical features .", "label": "", "metadata": {}, "score": "57.84633"}
{"text": "[ Proceedings of the 2nd ACM SIGHIT symposium on International health informatics : 2012 ] .Zeng QT , Crowell J : Semantic classification of consumer health content .MEDNET Retrieved May 2008 , 2006 : 19 .Jiang Y : A computational semantics system for detecting drug reactions and patient outcomes in personal health messages .", "label": "", "metadata": {}, "score": "57.869347"}
{"text": "Similarity between clusters is calculated using average cosine distance between all members , known as \" average linking \" .The tree leaves represent data instances ( subdomains ) and the paths between them are proportional to the pairwise distance .This allows visualization of multiple potential clusterings , as well as a more intuitive sense of how distinct clusters truly are .", "label": "", "metadata": {}, "score": "57.88376"}
{"text": "Feature extraction .Lexical and syntactic features .We first converted each OpenPMC article from XML to plain text , ignoring \" non - content \" elements such as tables and formulae , and split the result into sentences , aggregating the results by subdomain .", "label": "", "metadata": {}, "score": "58.0112"}
{"text": "Table 1 compares the labeling error from various features used in LLRT .It shows that cepstrum with its time derivatives ( CEP+Delta+DD ) yields the best classification result .In general , the performance improves with more Gaussian mixtures for speech and noise distributions .", "label": "", "metadata": {}, "score": "58.161526"}
{"text": "The shapes of the distributions of concepts differ depending on the presence of redundancy in the corpus .The difference in shapes of distributions confirms in a qualitative fashion our hypothesis about the three corpora and their varying levels of redundancy .", "label": "", "metadata": {}, "score": "58.16529"}
{"text": "We also added a reference subdomain , \" Newswire \" , composed of a 6 million word random sample from the Gigaword corpus .These subdomains were our initial objects of comparison .Distribution of OpenPMC data by subdomain .OpenPMC word count for the subdomains we consider : green coloring indicates data mapped to a single subdomain , orange indicates two subdomains , and red indicates three or more .", "label": "", "metadata": {}, "score": "58.273106"}
{"text": "Assume that both speech and noise observations can be characterized by individual distributions of Gaussian mixture density functions : Let x(t ) be the input signal at time t. The input signals may include acoustic feature vectors , say for example , 24-dimension cepstral vectors .", "label": "", "metadata": {}, "score": "58.32161"}
{"text": "Self - training creates semi - supervised learners from existing supervised learners with minimal effort .We first show results on self - training for constituency parsing within a single domain .While self - training has failed here in the past , we present a simple modification which allows it to succeed , producing state - of - the - art results for English constituency parsing .", "label": "", "metadata": {}, "score": "58.41587"}
{"text": "113 - 120 , April 1979 ) .For recognition - based VAD , the recent advances in speech recognition technology have enabled its widespread use in speech processing applications .The discrimination of speech from background silence can be accomplished using speech recognition systems .", "label": "", "metadata": {}, "score": "58.447113"}
{"text": "An alternative perspective on semantic behaviour is provided by mapping the distribution of syntactically - informed classes of verbs across subdomains .These classes are learned by generalising over the nouns taken by verbs as subject arguments and as direct object arguments in the corpus .", "label": "", "metadata": {}, "score": "58.485683"}
{"text": "In statistics , a likelihood ratio test is a statistical test used to compare the goodness of fit of two models , one of which ( the null model ) is a special case of the other ( the alternative model ) .", "label": "", "metadata": {}, "score": "58.52435"}
{"text": "To achieve robustness to environmental changes , the need for threshold calibration is eliminated by applying the ratio test statistic .The effectiveness of the present invention is evaluated in the context of speech recognition compared with a conventional energy - comparison scheme with dynamically updated thresholds .", "label": "", "metadata": {}, "score": "58.539948"}
{"text": "They simulated tests setting one and two random effects variances to zero .In those particular examples , the simulated p - values with k restrictions most closely matched a 50 - 50 mixture of and .This means that a good approximation was . )", "label": "", "metadata": {}, "score": "58.644493"}
{"text": "The relationship is less pronounced than between nouns and the topic models : a similar comparison of subdomain pairs has lower agreement ( 4/12 between nouns and both types of verb clusters , 6/12 and 7/12 between verbs and direct object - based and verbs and subject - based clusters , respectively ) .", "label": "", "metadata": {}, "score": "58.65697"}
{"text": "Cambridge : Cambridge University Press ; 1988 .Hirschman L , Sager N : Automatic information formatting of a medical sublanguage .In Sublanguage : Studies of Language in Restricted Semantic Domains .Edited by : Kittredge R , Lehrberger J. Berlin : Walter de Gruyter ; 1982 .", "label": "", "metadata": {}, "score": "58.672554"}
{"text": "where is the likelihood function , and is the supremum function .Note that some references may use the reciprocal as the definition .[ 6 ] In the form stated here , the likelihood ratio is small if the alternative model is better than the null model and the likelihood ratio test provides the decision rule as follows : .", "label": "", "metadata": {}, "score": "58.725952"}
{"text": "The differences we observe in this experiment are caused by the fact that some sentences only are copied , in a variable number of times ( some sentences occur once , some twice , and others 5 times ) .Thus , PMI ( which does not simply reflect word frequencies in a corpus , but takes into account global patterns of co - occurrences , since it relies on the probability of seeing terms jointly and terms independently ) does not behave similarly when fed with our different corpora .", "label": "", "metadata": {}, "score": "58.73272"}
{"text": "The reverse is true for the similarity of Rheumatology and Neoplasms .This may reflect higher usage of subdomain - specific vocabulary in particular argument positions , but this needs more in - depth scrutiny to draw detailed conclusions about selectional preferences .", "label": "", "metadata": {}, "score": "58.774174"}
{"text": "Given a corpus , a histogram of term frequencies is computed to examine whether the corpus follows Zipf 's law .According to Zipf 's law , terms frequencies have a long tail in their distribution : that is , very few terms occur frequently ( typically function words and prominent domain words ) while most terms occur only once or twice in the corpus overall .", "label": "", "metadata": {}, "score": "58.85594"}
{"text": "As preprocessing we divided the corpus into its constituent articles , removing stopwords and words shorter than 3 characters .We then used the MALLET toolkit [ 45 ] to induce 100 topics over the entire corpus and make a single topic assignment for each word in the corpus .", "label": "", "metadata": {}, "score": "58.892376"}
{"text": "PubMed View Article .Proceedings of the NAACL - HLT-10 2ndLouhi Workshop on Text and Data Mining of Health Documents , Los Angeles , CA 2010 .Cohen KB , Palmer M , Hunter L : Nominalization and alternations in biomedical language .", "label": "", "metadata": {}, "score": "58.910942"}
{"text": "View Article .Kohane IS : Using electronic health records to drive discovery in disease genomics .Nat Rev Genet 2011 , 12 ( 6 ) : 417 - 428 .PubMed View Article .Tatonetti N , Denny J , Murphy S , Fernald G , Krishnan G , Castro V , Yue P , Tsau P , Kohane I , Roden D , et al .", "label": "", "metadata": {}, "score": "58.926918"}
{"text": "This healthy behavior strongly indicates that Reduced Redundancy Informative Notes indeed behaved as a non - redundant corpus with respect to the LDA algorithm .Model fit as function of number of topics .Patient notes corpora , including the \" Reduced Informative \" corpus .", "label": "", "metadata": {}, "score": "59.056255"}
{"text": "2 , a system / method for voice activity detection is shown in accordance with the present invention .In block 62 , test data is input to the system for voice activity detection , where x(t ) is the input signal at time t , e.g. , input test data from block 62 .", "label": "", "metadata": {}, "score": "59.076584"}
{"text": "PubMed View Article .Roberts A , Gaizauskas R , Hepple M , Guo Y : Mining clinical relationships from patient narratives .BMC Bioinformatics 2008 , 9 ( Suppl 11 ) : S3 .PubMed View Article .Biber D , Gray B : Challenging stereotypes about academic writing : Complexity , elaboration , explicitness .", "label": "", "metadata": {}, "score": "59.265324"}
{"text": "Losses in performance caused by mismatch between training and test domains have been observed for a wide range of problems , from sentiment classification of reviews about different classes of products [ 15 ] to named entity tagging for printed and broadcast news text [ 16 ] .", "label": "", "metadata": {}, "score": "59.30314"}
{"text": "In block 28 , speech Gaussian mixture densities are output to provide speech models for voice activity detection in accordance with the present invention .Speech Gaussian mixture distributions are trained for speech recognition .It is to be understood that the speech and noise models may be employed in speaker dependent and speaker - independent systems .", "label": "", "metadata": {}, "score": "59.426163"}
{"text": "PubMed View Article .Hirschtick R : A piece of my mind .Copy - and - paste .JAMA 2006 , 295 ( 20 ) : 2335 - 2336 .PubMed View Article .Yackel TR , Embi PJ : Copy - and - paste - and - paste .", "label": "", "metadata": {}, "score": "59.476604"}
{"text": "Along with the advent of EHR comes the ability to copy and paste from one note to another .While this functionality has definite benefits for clinicians , among them more efficient documentation , it has been noted that it might impact the quality of documentation as well as introduce errors in the documentation process [ 9 - 13 ] .", "label": "", "metadata": {}, "score": "59.516308"}
{"text": "Cormode G , Hadjieleftheriou M : Finding frequent items in data streams .Proceedings of the VLDB Endowment 2008 , 1 ( 2 ) : 1530 - 1541 .Copyright .\u00a9 Cohen et al . ; licensee BioMed Central Ltd. 2013 .", "label": "", "metadata": {}, "score": "59.631214"}
{"text": "At the same time , POS tags abstract over potentially large classes of words such as the class of all common nouns .For example , \" runs \" may be tagged \" VBZ \" , indicating that it is 3rd person singular , while \" running \" may be tagged \" VBG \" , indicating it is a present participle .", "label": "", "metadata": {}, "score": "59.650253"}
{"text": "Differences in vocabulary are what first come to mind when defining subdomains , and to measure this we considered lemma frequencies .A lemma is a basic word - form that abstracts beyond inflection : for example , the tokens \" runs \" , \" run \" and \" running \" would all be considered instances of the verb lemma \" run \" .", "label": "", "metadata": {}, "score": "59.656742"}
{"text": "For instance , the phrase \" hip rplc \" is a common phrase used to refer to the hip replacement procedure , which does not match any concept on its own in the UMLS .When gathering counts or co - occurrence patterns for association studies with the goal of high - level applications , like detection of adverse drug events or disease modeling , augmenting existing terminologies with such collocations can be beneficial .", "label": "", "metadata": {}, "score": "59.708862"}
{"text": "At its ... \" .Genre classification has been found to improve performance in many applications of statistical NLP , including language modeling for spoken language , domain adaptation of statistical parsers , and machine translation .It has also been found to benefit retrieval of spoken or written docu - ments .", "label": "", "metadata": {}, "score": "59.73586"}
{"text": "The line plot shows the intra - subdomain spread of JSD values generated by random sampling .Distributions over latent topics as modelled by Latent Dirichlet Analysis .Clockwise from the top left : the heatmap shows the pairwise Jensen - Shannon Divergence ( top half ) and statistical significance ( bottom half ) , as well as the homogeneity ( diagonal ) .", "label": "", "metadata": {}, "score": "59.75778"}
{"text": "P(\u00acw 1 ) probability .( n 2 - n 12 ) / N .( N - n 1 ) / N .We then use the Binomial distribution to calculate the expected probabilities from the observed probabilities : .We are now able to calculate the likelihood ratio for hypothesis H 0 and H 1 .", "label": "", "metadata": {}, "score": "59.80638"}
{"text": "For example , Public Health and Psychiatry , which are paired in the verb feature space , are distant according to both selectional preference models .Systems that use lexical frequency information at the level of syntactic arguments may need to adjust their model to account for this .", "label": "", "metadata": {}, "score": "59.81597"}
{"text": "Collocation discovery can help identify lexical variants of medical concepts that are specific to the genre of clinical notes and are not covered by existing terminologies .Topic modeling , another text - mining technique , can help cluster terms often mentioned in the same documents across many patients .", "label": "", "metadata": {}, "score": "59.855255"}
{"text": "Colosimo ME , Morgan AA , Yeh AS , Colombe JB , Hirschman L : Data preparation and interannotator agreement : BioCreAtIvE Task 1B. BMC Bioinformatics 2005 , 6 ( Suppl 1 ) : S12 .PubMed View Article .Genome Biology 2008 , 9 : S3 .", "label": "", "metadata": {}, "score": "59.915672"}
{"text": "A finite - state grammar and a statistical language model are enabled in the decoder to handle commands and dictation .First , individual Gaussian mixture distributions are obtained for speech and silence during the training procedure steps .The first step is to label the training data .", "label": "", "metadata": {}, "score": "59.9594"}
{"text": "PubMed View Article .Li W : Random texts exhibit Zipf's - law - like word frequency distribution .Information Theory , IEEE Transactions on 1992 , 38 ( 6 ) : 1842 - 1845 .View Article .Yoshimasa Tsuruoka YT , Jin - Dong K , Tomoko O , Sophia A , Jun'ichi T : Developing a Robust Part - of - Speech Tagger for Biomedical Text .", "label": "", "metadata": {}, "score": "60.068916"}
{"text": "The step of aligning the training data in a forced alignment mode to identify speech and noise portions of the training data may be performed by employing a speech decoder .The step of clustering the noise portions may include clustering the noise portions in accordance with a plurality of noise ambient environments .", "label": "", "metadata": {}, "score": "60.097954"}
{"text": "Mitigation strategies for handling redundancy .Metadata - based baseline .The metadata - based mitigation strategy leverages the note creation date , the note type and the patient identifier information and selects the last available note per patient in the corpus .", "label": "", "metadata": {}, "score": "60.102882"}
{"text": "For collocations detection , in Reduced Redundancy Informative Notes , 6,034 collocations were extracted , on average each collocation is supported by 37 distinct patients and collocations supported by 3 patients or less make 6 % of the extracted collocation .We see a significant reduction in the number of collocations based on very few patients from 36 % to 6 % ( Table 3 ) .", "label": "", "metadata": {}, "score": "60.10346"}
{"text": "This paper revisits an assump - tion that genre variation is continuous along multiple dimensions , and an early use of principal component analysis to find these dimensions .Results on a very heterogeneous corpus of post-1990s American English reveal four major dimensions , three of which echo those found in prior work and the fourth depending on features not used in the earlier study .", "label": "", "metadata": {}, "score": "60.11931"}
{"text": "Finally , anaphoric determiners are much less frequent in Newswire than any of the biomedical subdomains , and usage also increases dramatically moving from social subdomains to microscopic subdomains , where they account for over half of coreferential terms ( Virology and Microbiology ) .", "label": "", "metadata": {}, "score": "60.123253"}
{"text": "The program storage device as recited in .The program storage device as recited in . claim 10 , wherein the step of counting the tags further comprises the steps of : . comparing a normalized cumulative count to a first threshold and a second threshold ; . if the normalized cumulative count is above or equal to the first threshold and the current tag is most likely speech , the input data is speech ; and .", "label": "", "metadata": {}, "score": "60.1407"}
{"text": "Answers to your questions , to the best of my ( perhaps limited ) understanding ... .So to determine if ( w1,w2 ) are likely to be together in a phrase , we want to know if they are dependent , ie , we have to disprove H0 .", "label": "", "metadata": {}, "score": "60.16738"}
{"text": "The denominator corresponds to the maximum likelihood of an observed outcome varying parameters over the whole parameter space .The numerator of this ratio is less than the denominator .The likelihood ratio hence is between 0 and 1 .Low values of the likelihood ratio mean that the observed result was less likely to occur under the null hypothesis as compared to the alternative .", "label": "", "metadata": {}, "score": "60.338882"}
{"text": "i .O .i .E .i . )E .i . where ln denotes the natural logarithm ( log to the base e ) and the sum is again taken over all cells .The value of G can also be expressed in terms of mutual information of the contingency table or as the difference of the entropy of the contingency table and the entropy of the row and column sums .", "label": "", "metadata": {}, "score": "60.422417"}
{"text": "Increasingly sophisticated systems for both core tasks and applications are being introduced through academic venues such as the annual BioNLP workshops [ 1 ] and also in the commercial marketplace .This meeting of fields has proven mutually beneficial : biologists more than ever rely on automated tools to help them cope with the exponentially expanding body of publications in their field , while NLP researchers have been spurred to address important new problems in theirs .", "label": "", "metadata": {}, "score": "60.42649"}
{"text": "Adverbs ( Figure 7 ) have the lowest JSD values of the lemma types .The subdomains are distinguished by two types of adverbs : markers of scientific discourse , and domain - specific premodiffers .The former include lemmas like \" previously \" , \" significantly \" and \" experimentally \" , with further distinctions between more qualitative and quantitative subdomains .", "label": "", "metadata": {}, "score": "60.44364"}
{"text": "These methods require labeled examples of syntactic structures to learn statistical patterns governing these structures .Labeled data typically requires expert annotators which makes it both time consuming and costly to produce .Furthermo ... \" .Current efforts in syntactic parsing are largely data - driven .", "label": "", "metadata": {}, "score": "60.578953"}
{"text": "One thing I liked in both the approaches described below , is that there is no choosing some arbitary cutoff number to ensure results are good .In both cases the cutoff is 0 , ie if the determinant is negative , then it is dropped and if it is positive , it is retained .", "label": "", "metadata": {}, "score": "60.62708"}
{"text": "It seems appropriate , however , to consider more complex documents -- not solely due to the improvement in extraction technologies , but also due to the content and meta - information that complex structure can offer the IE task .One often used but never exploited component of a more complex document model is the table .", "label": "", "metadata": {}, "score": "60.701927"}
{"text": "Noise Gaussian mixture distributions are trained for noise recognition .In block 24 , speech data is accumulated for the speech labeled training data .In this way , the speech data is pooled for clustering .The speech data is clustered into classes or clusters to associate similar speech labeled training data , in block 26 .", "label": "", "metadata": {}, "score": "60.71646"}
{"text": "Given the correct text contents , the speech / noise labels from forced alignment are treated as correct labels .For each set of Gaussian mixtures , different cepstrum - based features are evaluated , including static cepstrum ( Static CEP ) , linear discriminant analysis ( LDA ) , and time derivative dynamic cepstrum ( CEP+Delta+DD ) .", "label": "", "metadata": {}, "score": "60.72271"}
{"text": "The intra - subdomain variation is much greater and more diverse for the vocabulary features than for the POS and GR features , with the CCG features in between .The Science subdomain 's generalist scope ( encompassing journals such as Science and Endeavour ) gives it unusually high intra - subdomain scores , and we do n't consider it further .", "label": "", "metadata": {}, "score": "60.80964"}
{"text": "Documents are added one by one to the new corpus , a document sharing a proportion of fingerprints larger than the cutoff value with a document already in the corpus is not added .See Figure 6 for pseudo code of this algorithm .", "label": "", "metadata": {}, "score": "60.917313"}
{"text": "Noun distributions ( Figure 4 ) show the highest inter - subdomain divergence .Nouns also show the most intra - subdomain variation , particularly in catch - all subdomains like Medicine , but also in some laboratory sciences like Microbiology and Genetics .", "label": "", "metadata": {}, "score": "60.97026"}
{"text": "In this paper , we address two issues that are related to domain adaptation .The first question is how much genre variation will affect NLP systems ' performance .We investigate the effect of genre variation on the performance of three NLP tools , namely , word segmenter , POS tagger , and parser .", "label": "", "metadata": {}, "score": "61.01853"}
{"text": "The tags are counted in a plurality of frames to determine if the input data is speech or noise . deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic and pitch ; . tagging the frames of the input data based on the log - likelihood ratio test statistic and pitch characteristics of the input data as being most likely noise or most likely speech ; and .", "label": "", "metadata": {}, "score": "61.100323"}
{"text": "Adjective distributions ( Figure 2 ) also have high divergence within and between subdomains .Again , genetics - related subdomains show insignificant differences , as do Virology and Microbiology .In general , we see nouns and adjectives give common - sense semantic pairings ( Tropical Medicine and Communicable Disease , Genetics and Molecular Biology ) and sharply distinguish the \" social sciences \" from the rest .", "label": "", "metadata": {}, "score": "61.13732"}
{"text": "( 0 ) . add ( obs .getColumnVector ( 0 ) . add ( obs .As before , the results look quite believable .103 phrases are recognized from this algorithm , and the top 10 are shown below .", "label": "", "metadata": {}, "score": "61.149902"}
{"text": "Dendrograms .Dendrograms present the results of hierarchical clustering performed directly on the JSD values ( i.e. from the top half of the heat map ) .The algorithm begins with each instance ( in our case , subdomains ) as a singleton cluster , and repeatedly joins the two most similar clusters until all the data is clustered together .", "label": "", "metadata": {}, "score": "61.254"}
{"text": "Mood , A.M. ; Graybill , F.A. ( 1963 ) .Introduction to the Theory of Statistics ( 2nd ed . )McGraw - Hill .ISBN 978 - 0070428638 .", "label": "", "metadata": {}, "score": "61.311813"}
{"text": "The method as recited in . claim 2 , wherein the step of determining a second probability includes the step of comparing the given frame to a model of Gaussian mixtures for speech .The method as recited in .claim 1 , wherein the step of tagging the frames of the input data based on the log - likelihood ratio test statistic and pitch characteristics include the step of tagging the frames according to an equation : .", "label": "", "metadata": {}, "score": "61.379143"}
{"text": "1 , a training system / method for voice activity - detection is shown in accordance with the present invention .Once the labels are obtained as output from forced alignment in block 14 , the training data from block 10 is divided into speech and noise in block 16 .", "label": "", "metadata": {}, "score": "61.55882"}
{"text": "High redundancy and copy - and - paste operations in the notes create a biased sample of the \" patient note \" genre .From a practical perspective , redundant data in a corpus lead to waste of CPU time in corpus analysis and waste of I / O and storage space especially in long pipelines , where each stage of data processing yields an enriched set of the data .", "label": "", "metadata": {}, "score": "61.603836"}
{"text": "Microscopic and computational sciences , particularly Biotechnology , use long noun phrases .Newswire is towards the middle , while the social sciences form the shorter / infrequent end of the spectrum .Table 5 shows the frequency of pronominal / co - referential terms in each subdomain , and three finer - grained distinctions within co - reference : gendered third person ( personal ) , neuter 3rd person ( non - personal ) , and anaphoric determiners .", "label": "", "metadata": {}, "score": "61.62867"}
{"text": "Grammatical relations extracted from the sentence \" Multiple twinning in cubic crystals is represented geometrically \" using the C&C parser .From this output we simply counted occurrences of noun , verb , adjective and adverb lemmas , POS tags , GRs and CCG categories .", "label": "", "metadata": {}, "score": "61.802116"}
{"text": "Please take a moment to check if your company operates such a program .Abstract .Background .The increasing availability of Electronic Health Record ( EHR ) data and specifically free - text patient notes presents opportunities for phenotype extraction .", "label": "", "metadata": {}, "score": "61.81703"}
{"text": "Tested across six domains , our system outperforms all non - oracle baselines including the best domain - independent parsing model .Thus , we are able to demonstrate the value of customizing parsing models to specific domains . ... train models in many different domains but sidestep the problem of domain detection .", "label": "", "metadata": {}, "score": "61.89979"}
{"text": "For the design of VAD , efficiency , accuracy , and robustness are among the most important considerations .Many prevailing VAD schemes have been proposed and used in different speech applications .Based on the operating mechanism , they can be categorized into a threshold - comparison approach , and a recognition - based approach .", "label": "", "metadata": {}, "score": "61.98385"}
{"text": "We also encourage descriptions of proposals and data sets for shared tasks on metaphor processing .In comparison to last year 's workshop , the Second Workshop on Metaphor in NLP will broaden its scope by encouraging submissions on special themes of computational processing of emotions and affect in metaphor , as well as processing of metaphorical language in social media .", "label": "", "metadata": {}, "score": "62.022507"}
{"text": "PubMed View Article .Wrenn JO , Stein DM , Bakken S , Stetson PD : Quantifying clinical narrative redundancy in an electronic health record .J Am Med Inform Assoc 2010 , 17 ( 1 ) : 49 .PubMed View Article .", "label": "", "metadata": {}, "score": "62.0875"}
{"text": "The level of overall redundancy is significant and spread over many documents ( over a third ) .Concept redundancy at the corpus level .Since free - text notes exhibit high level of variability in their language , the redundancy measures may be different when we examine terms normalized against a standard terminology .", "label": "", "metadata": {}, "score": "62.126404"}
{"text": "CCG categories are assigned by a \" super - tagger \" sequence labeller , akin to the process for POS tags .For example , the most frequent CCG category for the verb \" run \" is \" ( S[b]\\NP)/NP \" , which indicates it combines with a noun phrase to the right , then to the left , to form a sentence .", "label": "", "metadata": {}, "score": "62.3872"}
{"text": "EVALUATION . ''Statistical Methods in Language and Linguistic Research ' ' provides a useful and accessible introduction to the world of statistics for beginners .The main advantage of the book , in my opinion , is the fact that it offers a detailed explanation of classical statistical techniques .", "label": "", "metadata": {}, "score": "62.416466"}
{"text": "H . else . if .t . ) then .Reject .H . else . if .t . ) then .Pending . where \u03b1 and \u03b2 are the probabilities for a type I error and type II error , respectively .", "label": "", "metadata": {}, "score": "62.448288"}
{"text": "Biometry : the principles and practice of statistics in biological research ., 3rd edition .New York : Freeman .ISBN 0 - 7167 - 2411 - 1 .Dunning , Ted ( 1993 ) .Accurate Methods for the Statistics of Surprise and Coincidence . , Computational Linguistics , Volume 19 , issue 1 ( March , 1993 ) .", "label": "", "metadata": {}, "score": "62.58876"}
{"text": "SUMMARY OF THE INVENTION .The frames of the input data are tagged based on the log - likelihood ratio test statistic and pitch characteristics of the input data as being most likely noise or most likely speech .The tags are counted in a plurality of frames to determine if the input data is speech or noise .", "label": "", "metadata": {}, "score": "62.60672"}
{"text": "We expect redundancy to be high across notes of the same patient and low across notes of distinct patients .Furthermore , within a single patient record , we expect heavy redundancy across notes from the same note types .We report redundancy on same patient / similar note type ( we focus on the most informative note types : primary provider , follow up and clinical notes ; in this analysis we ignore the template - based note types which are redundant by construction ) .", "label": "", "metadata": {}, "score": "62.639328"}
{"text": "The \" laboratory science \" cluster also uses many foreign words , but avoids Wh - pronouns .The difference between general language ( Newswire ) , social science ( Ethics ) and the biomedical subdomains still dominates the figures .The clusters , however , are less interpretable : there are similarities with the lemma clusters , but oddities are mixed in .", "label": "", "metadata": {}, "score": "62.73371"}
{"text": "Feature choice motivation .We considered subdomain variation across a range of lexical , syntactic , semantic , sentential and discourse features .Here , we motivate our choices and point to NLP applications that make use of specific features , and hence are potentially affected by their variation .", "label": "", "metadata": {}, "score": "62.80715"}
{"text": "Some are template based , such as radiology or lab reports , and others are less structured and contain mostly free text .We identified that note types : \" primary - provider \" , \" clinical - note \" and \" follow - up - note \" contain more information than other note types .", "label": "", "metadata": {}, "score": "63.012665"}
{"text": "Sentence length is defined as the number of non - punctuation tokens in a sentence .Noun phrase length is defined in terms of a sentence 's dependency structure as the number of words from the leftmost word dominated by a head noun to the rightmost dominated word .", "label": "", "metadata": {}, "score": "63.02128"}
{"text": "c .o .l . )H .i .j . )H .i . . . ) .H .\u03c0 . . .j . ) is the \" Mutual Information between the row vector and the column vector \" of the contingency table .", "label": "", "metadata": {}, "score": "63.153637"}
{"text": "McCallum AK : Mallet : A machine learning for language toolkit .Wallach H , Mimno D , McCallum A : Rethinking LDA : Why priors matter .Advances in Neural Information Processing Systems 2009 , 22 : 1973 - 1981 .", "label": "", "metadata": {}, "score": "63.15472"}
{"text": "Clark S , Curran JR : Formalism - independent parser evaluation with CCG and DepBank .Proceedings of ACL-07 , Prague , Czech Republic 2007 .Blitzer J , Drezde M , Pereira F : Biographies , Bollywood , boom - boxes and blenders : Domain adaptation for sentiment classification .", "label": "", "metadata": {}, "score": "63.44223"}
{"text": "The k - means clusters are similar to those for nouns , with the microscopic sciences ( cellular and biochemical ) merged into one cluster .Unlike nouns , the characteristic features include both over- and under - used terms , such as \" clinical \" and \" medical \" .", "label": "", "metadata": {}, "score": "63.594734"}
{"text": "The information in notes can be found in the form of narrative and semi - structured format through lists or templates with free - text fields .As such , much research has been devoted to parsing and information extraction of clinical notes [ 1 - 3 ] with the goal of improving both health care and clinical research .", "label": "", "metadata": {}, "score": "63.63613"}
{"text": "While this involves a manual step , its less work than finding the bigrams manually .There may be other better ways though .About me .I am a programmer interested in Semantic Search , Ontology , Natural Language Processing and Machine Learning .", "label": "", "metadata": {}, "score": "63.647285"}
{"text": "Fourth , we describe the clustering method we used on the raw feature distributions .Finally , we explain how the results of these methods are presented graphically .Data set and preprocessing .The Open Access Subset of PubMed ( OpenPMC ) is the largest publicly available corpus of full - text articles in the biomedical domain [ 27 ] .", "label": "", "metadata": {}, "score": "63.805138"}
{"text": "PubMed View Article .O'Donnell HC , Kaushal R , Barr\u00f3n Y , Callahan MA , Adelman RD , Siegler EL : Physicians ' Attitudes Towards Copy and Pasting in Electronic Note Writing .J Gen Intern Med 2009 , 24 ( 1 ) : 63 - 68 .", "label": "", "metadata": {}, "score": "64.071526"}
{"text": "PubMed View Article .Kho A , Pacheco J , Peissig P , Rasmussen L , Newton K , Weston N , Crane P , Pathak J , Chute C , Bielinski S : Electronic Medical Records for Genetic Research : Results of the eMERGE Consortium .", "label": "", "metadata": {}, "score": "64.08115"}
{"text": "Labeled data typically requires expert annotators which makes it both time consuming and costly to produce .Furthermore , once training data has been created for one textual domain , portability to similar domains is limited .This domain - dependence has inspired a large body of work since syntactic parsing aims to capture syntactic patterns across an entire language rather than just a specific domain .", "label": "", "metadata": {}, "score": "64.30233"}
{"text": "Assessing redundancy through alignment is a more appropriate and more stringent method than counting simple token overlap as in a bag - of - word model .High percentage of alignment between two notes indicates not only that tokens are similar across the two notes , but that the sequences of tokens in the notes are also similar .", "label": "", "metadata": {}, "score": "64.51868"}
{"text": "EHR corpora .We collected a corpus of patient notes from the clinical data warehouse of the New York - Presbyterian Hospital .The study was approved by the Institutional Review Board ( IRB - AAAD9071 ) and follows HIPAA ( Health Insurance Portability and Accountability Act ) privacy guidelines .", "label": "", "metadata": {}, "score": "64.5495"}
{"text": "Authors ' Affiliations .Department of Computer Science , Ben - Gurion University in the Negev .Department of Biomedical Informatics , Columbia University .References .Friedman : A general natural - language text processor for clinical radiology .Jamia - Journal of the American Medical Informatics Association 1994 , 1 ( 2 ) : 161 .", "label": "", "metadata": {}, "score": "64.57704"}
{"text": "Siegler EL , Adelman R : Copy and Paste : A Remediable Hazard of Electronic Health Records .Am J Med 2009 , 122 ( 6 ) : 495 - 496 .PubMed View Article .Markel A : Copy and Paste of Electronic Health Records : A Modern Medical Illness .", "label": "", "metadata": {}, "score": "64.81624"}
{"text": "State of the art articles ( as cited above ) and libraries ( such as the NSP package ) do not include any form of redundancy control or noise reduction .Redundancy mitigation is currently not a standard practice within the field of collocation extraction .", "label": "", "metadata": {}, "score": "64.86599"}
{"text": "Hi Salmon .I ca n't understand usage of chi square test , can you explain few moments ?In all chi square descriptions : chi square test reject H0 hypothesys if result X^2 value more then critical , in other words this mean that difference between observed result and expected distribution is very great .", "label": "", "metadata": {}, "score": "64.97879"}
{"text": "[ 30 ] applied LDA topic modeling to FDA drug side effects labels , their results demonstrated that the acquired topics properly clustered drugs by safety concerns and therapeutic uses .As observed for the field of collocation extraction , redundancy mitigation is not mentioned as standard practice in the case of topic modeling .", "label": "", "metadata": {}, "score": "65.094025"}
{"text": "Latent Dirichlet Allocation ( LDA ) , introduced by Blei et al .[ 27 ] , is an unsupervised generative probabilistic graphical model for topic modeling .Documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over words .", "label": "", "metadata": {}, "score": "65.13631"}
{"text": "I was always afraid of converting mathematical formulas into code .your detailed postings helped me a lot ...I even bookmarked your blog and read it regularly ! ! ! !Have you ever dabbled with unsupervised text / document classification with LDA or pLSI ?", "label": "", "metadata": {}, "score": "65.21798"}
{"text": "Illustrative Tag functions which include pitch may include the following illustrative example : .Tag . t . )f .LLRT .pitch . ) score1 . t . ) score2 . t . ) where . score1 . t . ) when .", "label": "", "metadata": {}, "score": "65.3481"}
{"text": "C&C uses the morpha morphological analyser [ 34 ] , maximum entropy labellers for tagging and supertagging and a log - linear parse model .RASP - parser - style [ 42 ] grammatical relations were extracted from C&C output using deterministic rules .", "label": "", "metadata": {}, "score": "65.355354"}
{"text": "JSD is a finite and symmetric measurement of divergence between probability distributions , defined as .JSD values range between 0 ( identical distributions ) and 1 ( disjoint distributions ) .Random sampling for intra - subdomain divergence .Comparability of JSD values is dependent on the dimensionality of the distributions being compared : approximations of significance break down with large dimensionality [ 50 ] .", "label": "", "metadata": {}, "score": "65.39838"}
{"text": "Metaphor processing is a rapidly growing area in NLP .The ubiquity of metaphor in language has been established in a number of corpus studies and the role it plays in human reasoning has been confirmed in psychological experiments .This makes metaphor an important research area for computational and cognitive linguistics , and its automatic identification and interpretation indispensable for any semantics - oriented NLP application .", "label": "", "metadata": {}, "score": "65.4391"}
{"text": "w .Tag . t .N .w .where w(t ) is the running decision window of N frames long , and \u03c4 is the summation index .The running decision window , w(t ) , can be used to emphasize some score tags by different weighting on observations at different times .", "label": "", "metadata": {}, "score": "65.448975"}
{"text": "sf .jtmt .phrase . setEntry ( 0 , 0 , n12 ) ; obs .setEntry ( 0 , 1 , ( n1 - n12 ) ) ; obs . setEntry ( 1 , 0 , ( n2 - n12 ) ) ; obs .", "label": "", "metadata": {}, "score": "65.467384"}
{"text": "Tag . t . ) AND .c . t . )TH1 . speech .Tag . t . ) AND .c . t . )TH2 . noise .Otherwise .unchanged . where TH1 and TH2 are the normalized thresholds for speech floor and silence ceiling , respectively .", "label": "", "metadata": {}, "score": "65.468185"}
{"text": "Clockwise from the top left : the heatmap shows the pairwise Jensen - Shannon Divergence ( top half ) and statistical significance ( bottom half ) , as well as the homogeneity ( diagonal ) .The dendrogram shows hierarchical clustering based on cosine difference between each subdomain 's JSD values .", "label": "", "metadata": {}, "score": "65.71719"}
{"text": "Clockwise from the top left : the heatmap shows the pairwise Jensen - Shannon Divergence ( top half ) and statistical significance ( bottom half ) , as well as the homogeneity ( diagonal ) .The dendrogram shows hierarchical clustering based on cosine difference between each subdomain 's JSD values .", "label": "", "metadata": {}, "score": "65.71719"}
{"text": "131 - 133 has a serious flaw .A model with 8 independent variables and only 32 observations runs a huge risk of overfitting .As a result , such a model can not be extrapolated to new data , which makes it useless ( see Harrell 2001 ) .", "label": "", "metadata": {}, "score": "65.721985"}
{"text": "Endnotes .Declarations .Acknowledgements .This work was supported by a National Library of Medicine grant R01 LM010027 ( NE ) .Any opinions , findings , or conclusions are those of the authors , and do not necessarily reflect the views of the funding organization .", "label": "", "metadata": {}, "score": "65.75846"}
{"text": "BRIEF DESCRIPTION OF DRAWINGS .The invention will be described in detail in the following description of preferred embodiments with reference to the following figures wherein : .FIG .1 is a block / flow diagram of a system / method for training speech and noise models including Gaussian mixture densities in accordance with the present invention ; and .", "label": "", "metadata": {}, "score": "65.76587"}
{"text": "Notes contain the following metadata : unique patient identifier , date , and note type ( e.g. , Primary - Provider ) .HealthTermFinder identifies named - entities mentions and maps them against semantic concepts in UMLS [49 ] .As such , it is possible to map lexical variants ( e.g. , \" myocardial infarction , \" \" myocardial infarct , \" \" MI , \" and \" heart attack \" ) of the same semantic concept to a UMLS CUI ( concept unique identifier ) .", "label": "", "metadata": {}, "score": "65.90882"}
{"text": "We call notes of these 3 types \" Informative Notes \" .In our experiments , we rely on different variants of the EHR corpus ( see Table 7 ): .The All Notes corpus is our full EHR corpus , .", "label": "", "metadata": {}, "score": "65.963646"}
{"text": "Hopefully it will help in understanding the code .As I mentioned in my update to last week 's post , I now have a pluggable interface for filtering phrases , called IPhraseFilter .There are currently four implementations available in the repository , two from last week and two from this week .", "label": "", "metadata": {}, "score": "66.0207"}
{"text": "sf .jtmt .phrase . log ( p10 ) - Math . log ( 1 - p10 ) - Math . log ( p01 ) - Math . log ( 1 - p01 ) - Math .Results are similar to the previous two approaches , I get 91 phrases with my corpus of three electronic books , and a visual inspection shows that the phrases are quite nice .", "label": "", "metadata": {}, "score": "66.0639"}
{"text": "McClosky et al .( 2010 ) coined the term multiple source domain adaptation .Similar to us , McClosky et al .( 2010 ) regard a target domain as mixture of source domains , b .. by Joseph Le Roux , Jennifer Foster , Joachim Wagner , Rasul Samad , Zadeh Kaljahi , Anton Bryl . \" ...", "label": "", "metadata": {}, "score": "66.2397"}
{"text": "The detailed distribution supports the distinction into 2 groups of notes : those with heavy repetition ( about 37 % of the pairs - with similarity between 40 % and 100 % ) and those with no repetition ( about 63 % of the notes ) .", "label": "", "metadata": {}, "score": "66.29818"}
{"text": "One test included the Command - and - Control ( C&C ) task , in which each utterance included multiple C&C phrases with short pauses in between .The test included 8 speakers with 80 sentences from each speaker .Another test set included a mix C&C / dictation ( MIXED ) task , where C&C phrases are embedded in each dictation utterance with short pauses wrapped around .", "label": "", "metadata": {}, "score": "66.59006"}
{"text": "The method as recited in .The method as recited in .claim 1 , wherein the step of counting the tags further comprises the steps of : . comparing a normalized cumulative count to a first threshold and a second threshold ; . if the normalized cumulative count is above or equal to the first threshold and the current tag is most likely speech , the input data is speech ; and .", "label": "", "metadata": {}, "score": "66.6181"}
{"text": "Under the null hypothesis H 0 : .P(w 1 ) probability .P(w 1 ) .by w1 is same as w2 being preceded by \u00acw1 .Under the alternative hypothesis H 1 : .P(w 1 ) probability .n 12 / N .", "label": "", "metadata": {}, "score": "67.0081"}
{"text": "The book describes two approaches , but the explanation is a bit sketchy , and I could not understand the methods fully at first , so I developed my own .Over the past couple of weeks , I have been trying to figure out these two methods , and I think I now understand them well enough to be comfortable using them .", "label": "", "metadata": {}, "score": "67.03253"}
{"text": "Here consists of the possible combinations of values of the parameters , , , and , which are the probability that coins 1 and 2 come up heads or tails .In what follows , and .The hypothesis space is constrained by the usual constraints on a probability distribution , , and .", "label": "", "metadata": {}, "score": "67.14613"}
{"text": "Resources .While figuring out this stuff , I came across couple of very good online resources , which I would like to share here .An Intuitive Explanation of Bayes ' Theorem by Eliezer S. Yudkowsky - As the title suggests , this is a very easy to understand explanation of Bayes ' theorem based on commonsense explanations .", "label": "", "metadata": {}, "score": "67.18303"}
{"text": "Training and improvement of NLP tools for Medical - Informatics tasks on public available data will continue growing as more EHRs are incorporated into health care givers worldwide .The nature of epidemiological research demands looking at cohorts of patients , such as our kidney patient notes .", "label": "", "metadata": {}, "score": "67.263466"}
{"text": "Admission notes showed a redundancy of 30 % compared to the progress , discharge and sign - out notes of the same patient .More recently , Zhang et al .[ 15 ] experimented with different metrics to assess redundancy in outpatient notes .", "label": "", "metadata": {}, "score": "67.2912"}
{"text": "The ' keyness ' is determined with the help of the log - likelihood test .The method is illustrated by computing the keyness of words in one of Barack Obama 's speeches .The reference corpus , which is used to measure the degree of unexpectedness of the words in Obama 's speech is , somewhat surprisingly , the British National Corpus .", "label": "", "metadata": {}, "score": "67.41464"}
{"text": "We show how web mark - up can be used to improve unsupervised dependency parsing .Starting from raw bracketings of four common HTML tags ( anchors , bold , italics and underlines ) , we refine approximate partial phrase boundaries to yield accurate parsing constraints .", "label": "", "metadata": {}, "score": "67.77632"}
{"text": "Proc AMIA : 2011 , 2011 : 1612 - 1620 .Lin CY : Rouge :A package for automatic evaluation of summaries .[Text Summarization Branches Out : Proceedings of the ACL-04 Workshop : 2004 ] .Altschul SF , Gish W , Miller W , Myers EW , Lipman DJ : Basic local alignment search tool .", "label": "", "metadata": {}, "score": "67.91405"}
{"text": "The mean , median and mode should be in the reverse order in Figure 1.16 ( 24 ) ; ii . screen plot ' ' ( correct : ' ' scree plot ' ' ) ( 117 ) ; v. ' ' beta - axis ' ' ( correct : ' ' y - axis ' ' ) ( 122 ) ; vi . ''", "label": "", "metadata": {}, "score": "68.58777"}
{"text": "In this paper , we address two issues that are related to domain adaptation .The first question is how much genre variation will affect NLP systems ' per ... \" .Domain adaptation is an important task in order for NLP systems to work well in real applications .", "label": "", "metadata": {}, "score": "68.93651"}
{"text": "( Figure 1 ) .Our data set is composed of journals that are assigned a single subdomain .To ensure sufficient data for comparing a variety of linguistic features , we discarded the subdomains with less than one million words of data .", "label": "", "metadata": {}, "score": "68.958145"}
{"text": "Sujit .Great piece of code .I have developed a program to create Bigrams using the Likelihood ratio .How can i specify a particular threshold or how can i determine the most appropriate bigrams for my process ? ?Thanks Srijith .", "label": "", "metadata": {}, "score": "69.339134"}
{"text": "Our EHR corpus can be organized by patient identifier .We can , therefore , quantify the amount of redundancy within a patient record .On average , our corpus contains 14 notes per patient , with standard deviation of 16 , minimum of 1 and 167 maximum notes per patient .", "label": "", "metadata": {}, "score": "69.40587"}
{"text": "17 ] , the most popular sequence similarity algorithm in bioinformatics , is based on hashing of short sub - strings within the genetic sequence and then using the slower optimized dynamic programming alignment for sequences found to share enough sub - sequences .", "label": "", "metadata": {}, "score": "69.51073"}
{"text": "A set of training data was used to train a standard large - vocabulary continuous speech recognition system .The set of training data included 36000 utterances from 1300 speakers .2000 utterances of training data were used in the first experiment to evaluate various features and to determine the number of Gaussian mixtures for speech and silence models .", "label": "", "metadata": {}, "score": "69.586494"}
{"text": "The verb clusters generally agree with the noun clusters , although sometimes emphasise different similarities ( e.g. Vascular Disease and Critical Care are closer together ) .Unlike nouns and adjectives , clusters are distinguished by both under- and over - use of verbs such as \" conserve \" , \" express \" and \" contain \" .", "label": "", "metadata": {}, "score": "69.61439"}
{"text": "Background .The Electronic Health Record ( EHR ) contains valuable information entered by clinicians .Besides its immediate clinical use at the point of care , the EHR , when treated as a repository of medical information across many patients , provides rich data waiting to be analyzed and mined for clinical discovery .", "label": "", "metadata": {}, "score": "69.74715"}
{"text": "Many companies also offer a gift matching program , such that they will match any gift you make to a non - profit organization .Normally this entails your contacting your human resources department and sending us a form that the EMU Foundation fills in and returns to your employer .", "label": "", "metadata": {}, "score": "69.76863"}
{"text": "Our heat maps show three types of values : the top half shows JSD values between pairs of subdomains .The bottom half shows the significance of the JSD values ( the probability that the variation does not occur by chance ) , calculated as described in the section \" Random sampling for intra - subdomain divergence \" above .", "label": "", "metadata": {}, "score": "69.87085"}
{"text": "The program storage device as recited in .claim 11 , wherein the step of determining a first probability includes the step of comparing the given frame to a model of Gaussian mixtures for noise .The program storage device as recited in .", "label": "", "metadata": {}, "score": "70.30013"}
{"text": "Given contents , forced alignment determines the phonetic information for each signal segment using the same mechanism for speech recognition .In the second step , different mixtures of Gaussian densities for speech signals are established using observations labeled as speech in the first step .", "label": "", "metadata": {}, "score": "70.545944"}
{"text": "There is a wide variation in the number of notes per patient , either because of their health status , or because some patients go to different health providers while others have all their visits in the same institution .Furthermore , clinicians typically copy and paste information from previous notes when documenting a current patient encounter .", "label": "", "metadata": {}, "score": "70.64076"}
{"text": "Mach Learn 2010 , 79 ( 1 ) : 123 - 149 .View Article .Blitzer J , Dredze M , Pereira F : Biographies , bollywood , boom - boxes and blenders : Domain adaptation for sentiment classification .Moore RC , Lewis W : Intelligent selection of language model training data .", "label": "", "metadata": {}, "score": "71.27539"}
{"text": "The notion of domain relates to the concepts of topic , register and genre that have long been studied in corpus linguistics [ 2 ] .In the field of biomedical NLP , researchers are most often concerned with the genre of \" biomedical research articles \" .", "label": "", "metadata": {}, "score": "71.27626"}
{"text": "Final Call for Papers : .The Second Workshop on Metaphor in NLP ( co - located with ACL 2014 ) Baltimore , MD , USA - June 26 , 2014 .The main focus of the workshop will be on computational modelling of metaphor using state - of - the - art NLP techniques .", "label": "", "metadata": {}, "score": "71.29277"}
{"text": "Voice activity detection ( VAD ) is an integral and significant part of a variety of speech processing systems , comprising speech coding , speech recognition , and hands - free telephony .For example , in wireless voice communication , a VAD device can be incorporated to switch off the transmitter during the absence of speech to preserve power or to enable variable bit rate coding to enhance capacity by minimizing interference .", "label": "", "metadata": {}, "score": "71.37631"}
{"text": "Personal pronouns are far more frequent in Newswire than any biomedical subdomain , due to scientific language 's concern with objectivity .There is a further distinction between clinical and microscopic subdomains , in that the former are far likelier to use personal pronouns due to a focus on patients and case studies .", "label": "", "metadata": {}, "score": "71.39169"}
{"text": "The Reduced Redundancy Informative Notes corpus contains 3,970 patient notes , 3.18 as many notes as the Last Informative Notes corpus while having same - patient redundancy of only 9.8 % compared to 29 % in the All Informative Notes Corpus .", "label": "", "metadata": {}, "score": "71.41249"}
{"text": "We therefore compute significance scores based on random sampling of the subdomains .For each subdomain , we divide its texts into units of 200 contiguous sentences , and build 101 million - word samples by drawing randomly from these units .", "label": "", "metadata": {}, "score": "71.52031"}
{"text": "A number of researchers have explored the differences between non - technical and scientific language .Biber and Gray [ 7 ] describe two distinctive syntactic characteristics of academic writing which set it apart from general English .Firstly , in academic writing additional information is most commonly integrated by modification of phrases rather than by the addition of extra clauses .", "label": "", "metadata": {}, "score": "72.08727"}
{"text": "i .j .k . i .j . ][ .H .i .j . )H .i . . . ) .H .\u03c0 . . .j . ) . ]H . q .", "label": "", "metadata": {}, "score": "72.21842"}
{"text": "Articles are formatted according to a standard XML tag set [ 28 ] .The National Institute of Health ( NIH ) maintains a one - to - many mapping from journals to 122 subdomains of biomedicine [ 29 ] .The mapping covers about a third of the OpenPMC journals , but these account for over 70 % of the total data by word count .", "label": "", "metadata": {}, "score": "72.22403"}
{"text": "We present a number of semi - supervised parsing experiments on the Irish language carried out using a small seed set of manually parsed trees and a larger , yet still relatively small , set of unlabelled sentences .We take two popular dependency parsers - one graph - based and one transition - based - and ... \" .", "label": "", "metadata": {}, "score": "72.244705"}
{"text": "A first set includes 720 command phrases from three different speakers and the second set contains only breath noises .The results show that a combination of cepstrum and pitch retains good rejection for breath noises for the pitch - based VAD while maintaining good performance in clean environments as the cepstrum - based VAD .", "label": "", "metadata": {}, "score": "73.46869"}
{"text": "Pitch is calculated for speech parts with properties of periodicity .For consonants like fricatives and stops , pitch simply does not exist .Likewise , background noises do not exhibit pitch due to the lack of periodicity .Therefore , pitch itself is not an obvious choice for voice activity detection because the absence of pitch can not distinguish consonants from background noise .", "label": "", "metadata": {}, "score": "73.6721"}
{"text": "In all cases , the actual values are inscribed in each square .The significance scores are shaded from white ( 100 % significance ) to black ( 0 % significance ) .The JSD values are shaded from white ( highest JSD value for the feature set ) to black ( lowest JSD value for the feature set ) .", "label": "", "metadata": {}, "score": "73.79793"}
{"text": "Words are ranked by their significance in the topic ( i.e. , in the first topic the most important word is \" renal \" ) .The first topic includes words pertaining to renal disease , the second to hypertension and the third to symptoms and treatments related to the pulmonary system .", "label": "", "metadata": {}, "score": "73.894554"}
{"text": "One common feature of these corpora is that they have been compiled from just one or two specific subject areas , typically molecular biology .GENIA consists of 2,000 abstracts dealing with transcription factors in human blood cells .PennBioIE is also a corpus of abstracts , in this case covering topics in cancer genomics and the behaviour of enzymes affecting a particular family of proteins .", "label": "", "metadata": {}, "score": "74.07361"}
{"text": "This time round , I read through the entire tutorial ( takes about 2 - 3 hours ) with a view to applying it to real - life ( data mining ) situations .If you are in a similar situation , I highly recommend reading through it .", "label": "", "metadata": {}, "score": "74.39665"}
{"text": "The results show that an unsupervised technique based on topic models is effective - it outperforms random data selection on both languages examined , English and Dutch .Moreover , the technique works better than manually assigned labels gathered from meta - data that is available for English . ...", "label": "", "metadata": {}, "score": "74.52205"}
{"text": "They both rely on patterns of co - occurrence of words .Collocations are word sequences that co - occur more often than expected by chance .Collocations , such as \" heart attack \" and \" mineral water , \" carry more information than the individual words comprising them .", "label": "", "metadata": {}, "score": "75.94432"}
{"text": "[14 ] examined 1,670 patient notes of four types ( resident sign - out note , progress note , admission note and discharge note ) and assessed the amount of redundancy in these notes through time .Redundancy was defined through alignment of information in notes at the line level , using the Levenshtein edit distance .", "label": "", "metadata": {}, "score": "76.025505"}
{"text": "In this context i would like to ask if it possible to use more than 1.5 GB RAM on JVM ?I have 4 GB ram , but unfortunatly because JVM i could n't extend the maximum memory limit to more than 1.5 GB RAM .", "label": "", "metadata": {}, "score": "76.70451"}
{"text": "I love solving problems and exploring different possibilities with open source tools and frameworks . \" ...We show how web mark - up can be used to improve unsupervised dependency parsing .Starting from raw bracketings of four common HTML tags ( anchors , bold , italics and underlines ) , we refine approximate partial phrase boundaries to yield accurate parsing constraints .", "label": "", "metadata": {}, "score": "76.84833"}
{"text": "Her thesis was based on multivariate statistical analyses of periphrastic causatives in Netherlandic and Belgian Dutch .Among her main interests are multifactorial models of language use and spatial representations of natural language semantics in Cognitive Linguistics and typology .She has been teaching courses in Corpus Linguistics and quantitative methods of linguistic analysis at the University of Jena and the University of Marburg in Germany .", "label": "", "metadata": {}, "score": "77.27844"}
{"text": "i .j .k . i .j . and .\u03c0 . . .j .i . k . i .j .i .j .k . i .j .I . r .o .", "label": "", "metadata": {}, "score": "77.91372"}
{"text": "First , the information conveyed in cepstrum is useful in reducing the false silence errors as observed in the cepstrum - only case described above .The information from pitch is effective in lowering the false speech errors as observed in the pitch - only case .", "label": "", "metadata": {}, "score": "78.550995"}
{"text": "The third cluster includes subdomains focused on clinical medicine ( Psychiatry ) or specific patient - types ( Geriatrics , Pediatrics ) .The fourth and final cluster includes subdomains focused on social and ethical aspects of medicine ( Ethics , Education ) .", "label": "", "metadata": {}, "score": "79.33653"}
{"text": "i . q .i .l .o .g . q .i . and .i .j .k . i .j .i .j .k . i .j .j .k . i .", "label": "", "metadata": {}, "score": "80.45491"}
{"text": "Note that under either hypothesis , the distribution of the data is fully specified ; there are no unknown parameters to estimate .The likelihood ratio test is based on the likelihood ratio , which is often denoted by ( the capital Greek letter lambda ) .", "label": "", "metadata": {}, "score": "81.45349"}
{"text": "The authors declare that they have no competing interests .Authors ' contributions .RC participated in the study design , carried out the statistical analyses and wrote the paper .ME participated in study design and wrote the paper .NE participated in study design and wrote the paper .", "label": "", "metadata": {}, "score": "81.64011"}
{"text": "It is therefore to be understood that changes may be made in the particular embodiments of the invention disclosed which are within the scope and spirit of the invention as outlined by the appended claims .Having thus described the invention with the details and particularity required by the patent laws , what is claimed and desired protected by Letters Patent is set forth in the appended claims .", "label": "", "metadata": {}, "score": "82.246216"}
{"text": "The LINGUIST List is under the umbrella of Eastern Michigan University and as such can receive donations through the EMU Foundation , which is a registered 501(c ) Non Profit organization .Our Federal Tax number is 38 - 6005986 .These donations can be offset against your federal and sometimes your state tax return ( U.S. tax payers only ) .", "label": "", "metadata": {}, "score": "83.945656"}
{"text": "Copyright .\u00a9 Lippincott et al ; licensee BioMed Central Ltd. 2011 .Friday , November 06 , 2009 .In my previous post , I described how I used the Binomial Distribution to find the expected probability of a word n - gram , and compared the actual probability for a phrase to figure out if the n - gram is a phrase .", "label": "", "metadata": {}, "score": "87.70654"}
{"text": "All the authors took part in the analysis of the results and in the write - up of the paper .All authors read and approved this document .Authors ' Affiliations .Computer Laboratory , University of Cambridge .References .", "label": "", "metadata": {}, "score": "93.040054"}
