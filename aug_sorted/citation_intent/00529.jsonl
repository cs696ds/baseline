{"text": "High parallelism and the intrinsic low adjacency of parity check matrix lead to longer and complex routing , not fully supported by most FPGA devices .Some designs [ 16 , 25 ] , used time sharing of hardware and memories that reduces the global interconnect routing , at a cost of reduced throughput .", "label": "", "metadata": {}, "score": "32.95934"}
{"text": "However , the enhanced processing density was at the expense of significant deterioration in performance .Another past effort involved using a systolic array to implement a MLP network with a pipelined modification of the on - line back propagation algorithm .", "label": "", "metadata": {}, "score": "33.78125"}
{"text": "In this case , the determining a hardware resource estimate from among the hardware resource estimates that is closest to but less than or equal to the maximum hardware resources available may further include determining the hardware resource estimate from among the hardware resource estimates that maximizes performance .", "label": "", "metadata": {}, "score": "34.140488"}
{"text": "There is , therefore , a need in the art for an improved processing architecture supporting high processing and communication requirements .It would further be desirable for the architecture to provide a platform of modular component that may be assembled and scaled to meet diverse system requirements .", "label": "", "metadata": {}, "score": "34.80506"}
{"text": "2 ) Resource utilization : in terms of hardware resources used and its proportion to the total hardware resources available .Each implementation generally requires a tradeoff between these two factors .High performance typically requires a high degree of parallelism , which may require significant resources .", "label": "", "metadata": {}, "score": "35.00923"}
{"text": "Such techniques were illustrated in [ 5 ] .In general , and given the high computation to communication ratio of the algorithm , the scalability of the execution time as a function of available hardware resources is near linear .In view of the above , the following conclusion section summarizes the findings of this study and presents a number of general lessons learnt through it .", "label": "", "metadata": {}, "score": "35.637306"}
{"text": "When we examine the hardware design in [ 3 ] , a major portion of the performance is attained through fine - grained overlapping of computation throughout the design pipeline .Although AutoPilot has synthesis directives that can create this sort of hardware , the code must be designed in advance to use the correct data access order and code structure , and that software code structure is different from typical software structure that is used in CPU source .", "label": "", "metadata": {}, "score": "36.491848"}
{"text": "First , to maximize performance , the architecture may also implement a pipelined design that uses an out of order weight update rule to overcome data hazards .Second , to minimize resource utilization , the most efficient arithmetic representation may be selected which balances between precision and area .", "label": "", "metadata": {}, "score": "36.73873"}
{"text": "Secondly , they allow rapid prototyping of decoder .Once verified , the algorithm can be employed on the same reconfigurable hardware .It also allows easy handling of different code rates and SNRs , power requirements , block lengths , and other variable parameters .", "label": "", "metadata": {}, "score": "36.887985"}
{"text": "In the embodiments herein , scalability of the network is achieved by using a variable degree of parallelism .The ability to vary the degree of parallelism in the architecture without a redesign allows the designer the flexibility to trade off network performance for resources consumed .", "label": "", "metadata": {}, "score": "36.913425"}
{"text": "To enable a fair comparison , these specific implementation platforms were chosen because they are all based on 90 nm CMOS technology and were purchased off - the - shelf at around the same time .Moreover , each platform was targeted by a different but equally experienced programmer .", "label": "", "metadata": {}, "score": "37.079166"}
{"text": "This application relates to an architecture , systems and methods for implementing artificial neural networks , and in particular , to implementing a scalable artificial neural network using multi - layer perceptrons and error back - propagation on configurable hardware devices .", "label": "", "metadata": {}, "score": "37.696636"}
{"text": "Using an extremely parallel architecture makes it possible to use a low clock frequency , which in turn makes it possible use a slow , low - leakage silicon process , and to lower the supply voltage level of the video decoder block in a SoC. As power has a square dependency on voltage , this gives a huge advantage over designs that require a higher clock - frequency .", "label": "", "metadata": {}, "score": "37.849976"}
{"text": "The hardware synthesis process then maps the optimized code to hardware , performing computation scheduling , resource binding , and pipelining .Finally , AutoPilot generates the interface code so that the synthesized code transparently maintains the same communication interface as the original implementation .", "label": "", "metadata": {}, "score": "38.24408"}
{"text": "The hyperprocessor architecture of the present invention is versatile and scalable , amenable to insertion in applications such as graphics subsystems , home gateways , edge / core routers , and web switches , to name just a few .The hyperprocessor combines the high - performance associated with ASICs with the programmability of processors , extending that programmability to a new level by making configuration application developer - friendly .", "label": "", "metadata": {}, "score": "38.58695"}
{"text": "Note that for smaller sequences , the target FPGA chip could easily fit more processing elements on chip and thus ( provided there is enough bandwidth to transfer more data to the FPGA chip in parallel ) the execution time could be reduced several fold .", "label": "", "metadata": {}, "score": "38.662308"}
{"text": "In a further aspect , the systems and methods described herein allow the customized scalable network to use a variable arithmetic representation for efficiency .It will be understood that the methods described herein may be realized by a hardware description language , which may be stored on a configurable hardware - readable medium for execution by at least one hardware device .", "label": "", "metadata": {}, "score": "38.71061"}
{"text": "Details of these estimations are provided herein in relation to .FIG .19 , and Equations ( 11 ) to ( 14 ) .Generally , the ITER selection module 1025 selects the degree of parallelism that provides the best network performance and uses less than or all of the available resources 1005 .", "label": "", "metadata": {}, "score": "38.754906"}
{"text": "Number . of . patterns . per . epoch .number . of . epochs . clock . rate .As Table VII presents , the hardware simulations of the embodiments described herein consistently achieves three to five orders of magnitude speed up ( 1000\u00d7-100000\u00d7 ) over both Matlab and Weka .", "label": "", "metadata": {}, "score": "38.771793"}
{"text": "This estimate is calculated for each of the multiple degrees of parallelism .The resource estimation may be calculated by , for example , determining the number of network weights using the desired network topology .Then for each degree of parallelism in the set , calculate a measure of the hardware resources required ( i.e. a resource estimate ) to implement the determined number of network weights .", "label": "", "metadata": {}, "score": "38.953354"}
{"text": "When designing an efficient multi mode decoder a typical approach is to find similarities between different modes and then implementing common parts as reusable hardware components .Controlling the data flow between reusable components guarantees multi mode flexibility .One of such efforts is the work by Brack et al .", "label": "", "metadata": {}, "score": "38.991184"}
{"text": "The hyperprocessor also provides a scalable system - on - chip ( SoC ) platform architecture that is easy to program and debug , with increased parallelism options , out - of - order and speculative task execution , and program memory distribution , all available for an application to improve performance .", "label": "", "metadata": {}, "score": "39.235058"}
{"text": "In addition to simplicity ( keeping the number of instructions to a minimum ) , the instructions should be as regular as possible to make decoding easy .Application specific systems may be easily instantiated using the hyperprocessor platform architecture : the architecture provides a structure - the components of control processor , universal register file , and task dispatcher - to provide control of program flow , together with synchronization and communication between tasks .", "label": "", "metadata": {}, "score": "39.471645"}
{"text": "Thus , any application with high fine - grained instruction and data level parallelism , and modest dynamic range data requirements should be expected to achieve similar performance gains on FPGAs .General purpose processors should be expected to fare better for less parallel / regular algorithms on the other hand .", "label": "", "metadata": {}, "score": "39.52498"}
{"text": "For comparison , similar software simulations using Matlab and Weka were also conducted .Simulations were carried out on a computer with an AMD 1.3 GHz processor and 1 Gb of RAM .The Matlab R2006a Neural Network Toolbox was used for simulating various networks and conducting convergence tests .", "label": "", "metadata": {}, "score": "39.62338"}
{"text": "In order to put the speed - up figures shown in Table 4 into perspective , we measured the time it took to develop each of these implementations .Indeed , each of the four implementations was developed by a different Ph.D. student with a comparable experience in programming his / her respective platform .", "label": "", "metadata": {}, "score": "39.675304"}
{"text": "In this case , the method may further include configuring a hardware device based on the hardware configuration .According to yet another aspect , there is provided a method for training a scalable artificial neural network involving multi - layer perceptrons and error back propagation .", "label": "", "metadata": {}, "score": "39.83187"}
{"text": "If the hardware can handle a larger degree of virtualization of arithmetic operations ( tunable neuron and layer parallelism ) , serialization can further be increased with a further linear decrease in resource consumption .Results .Implementation Efficiency .As discussed above , implementation efficiency is explored at two levels : arithmetic representation and resources and performance estimation . A. Level I : Arithmetic Representation .", "label": "", "metadata": {}, "score": "39.834354"}
{"text": "A reasonable throughput of 86 Mb / s at 125 MHz is achieved .In [ 47 ] , the authors presented a parallel check node incorporating the value reuse property of Min - Sum algorithm , for nonstandardized , rate 0.5 regular codes .", "label": "", "metadata": {}, "score": "40.028687"}
{"text": "Next - generation wireless communication standards adopt structured LDPC codes , which hold good interconnection , memory and scalability properties at the decoder implementation level .In these codes , the parity check matrix .The same base matrix is used as a platform for all the different code lengths related to a selected code rate : implementation of a full - mode decoder is thus a challenging task , due to huge variations in code parameters .", "label": "", "metadata": {}, "score": "40.09578"}
{"text": "The state - of - the - art reports a number of design efforts in this domain , thanks to good performance and acceptable degree of flexibility .The work portrayed in [ 39 ] outlines a multicore architecture based on an ASIP concept .", "label": "", "metadata": {}, "score": "40.275497"}
{"text": "In general , instruction level parallelism has been found not exceed a level of about six instructions per cycle .Another solution to satisfying processing demand is to write parallel programs for homogeneous or heterogeneous parallel processors .Although practiced for many years , this approach has not achieved wide acceptance due to the complexity of parallel programs , making development extremely costly .", "label": "", "metadata": {}, "score": "40.490578"}
{"text": "As such , it is customary to perform this on a host ( sequential ) processor as the time involved in this operation is negligible compared to the time it takes to align the query sequence against a whole sequence database .", "label": "", "metadata": {}, "score": "40.729187"}
{"text": "These variables can then be used to estimate the required resources and determine if partially parallel implementation is needed and , if so , establish the ITER value .Implementation details will be described in detail herein .B. Efficient Implementation .", "label": "", "metadata": {}, "score": "40.941193"}
{"text": "Other efforts include designing and building parallel systems based on transputers , digital signal processors ( DSPs ) , or Application Specific Integrated Circuits ( ASICs ) that include multiple parallel processing units and act like ANN accelerators .However , software designs tend to be slower in operation and conventional hardware designs require using special hardware boards or ASIC chips , which limit their use on a large scale .", "label": "", "metadata": {}, "score": "41.061558"}
{"text": "In addition , use of heterogenous processors necessitate complete re - writes of the program for each processor configuration , and this type of architecture is typically limited by bandwidth restrictions between processors and memories .Yet another solution for high - performance systems is pipelining several stages of a computation , and efficient approach that unfortunately lacks flexibility and , more importantly , scalability .", "label": "", "metadata": {}, "score": "41.11331"}
{"text": "Note that the aim of this paper is not to present the best implementation ( from a speed point of view ) on the four architectures but to perform a fair comparison of all four technologies in terms of speed , energy consumption , and development time and cost .", "label": "", "metadata": {}, "score": "41.20872"}
{"text": "Beyond a single chip , a straightforward way of scaling up the algorithm is to split the subject database into . subdatabases and allocate each subdatabase to one GPU chip .Partial results are then reduced by a host processor in a typical scatter - gather manner , as demonstrated in [ 23 ] .", "label": "", "metadata": {}, "score": "41.428177"}
{"text": "The solution proposed in [ 42 ] makes use of a single SIMD ASIP with maximum internal parallelism of 96 .A combined architecture is strictly designed for LDPC codes , but the supported ones range from binary ( WiFi and WiMAX ) to nonbinary ( Galois Field of order 9 ) : the decoding approach is turbo decoder - based .", "label": "", "metadata": {}, "score": "41.552322"}
{"text": "In the case of shared - memory multiprocessors , this is achieved through the proposed Persistence Selective Caching ( PSC ) and CacheBalancer schemes that influence what data is stored in on - chip caches , where it is stored , and for how long .", "label": "", "metadata": {}, "score": "41.596382"}
{"text": "This customization is achieved for an individual network by , for example , taking full advantage of using configurable hardware , such as FPGAs or ASICs .Having both degrees of parallelism and arithmetic representation variables provides a further level of network customization .", "label": "", "metadata": {}, "score": "41.674286"}
{"text": "A single design flow is exploited in [ 28 ] to provide three different implementations , each supporting a different standard .The adaptive single - phase decoding ( ASPD ) [ 45 ] scheduling is enforced , that allows to detach the decoder 's memory requirements from the weight of rows and columns of the . matrix , leaving them dependent on the codeword length only .", "label": "", "metadata": {}, "score": "41.89906"}
{"text": "Implementation of the Smith - Waterman Algorithm on GPU .The parallelization strategy adopted for our GPU implementation is based on multithreading and multiprocessing .Indeed , several threads are allocated to the computation of a single alignment matrix in parallel within a thread block , while several thread blocks are allocated to compute the alignments of different pairs of sequences [ 16 ] .", "label": "", "metadata": {}, "score": "42.04384"}
{"text": "Further , the arithmetic representation is used to further enhance efficiency of resource consumption for a given network .Variable arithmetic representation is used to obtain reasonable convergence performance and keep resource consumption low .For some embodiments , it is possible to go further and constrain each result and parameter in the hardware implementation of Equations ( 1 ) to ( 5 ) , ( 7a ) and 7(b ) to a particular precision and range .", "label": "", "metadata": {}, "score": "42.126118"}
{"text": "These include the following .( i ) Convert loops using break or data - dependent loop bounds to static loop bounds to improve pipelining / parallelization .( ii ) Use FIFO data read & write order for dataflow optimizations .", "label": "", "metadata": {}, "score": "42.35315"}
{"text": "At this step , we examine the synthesis result of the previous step and further parallelize the computation by duplicating logic within the computation pipeline to instantiate multiple , parallel computation pipelines and fit in the Virtex-6 LX240T. In AutoPilot , function parallelism is easily explored through a combination of array partitioning and loop unrolling .", "label": "", "metadata": {}, "score": "42.45247"}
{"text": "Stemming from it , we have developed an LDPC ZONoC - based decoder fully compliant with WiMAX standard : although having a more convoluted graph structure , relies on a smaller number of exchanged messages and guarantees .factor in convergence speed .", "label": "", "metadata": {}, "score": "42.77881"}
{"text": "In general , each optimization step provides some incremental improvement , but the final step shows the greatest benefit .However , this is not to mean that the other steps are not important ; rather , this emphasizes the importance of minimizing resource consumption in order to allow maximum flexibility in the parallelization step .", "label": "", "metadata": {}, "score": "42.959297"}
{"text": "For instance , varying the number of SPPUs , adding / removing special hardware units , or changing the size of the universal register file are all straightforward .While the building blocks vary , the hardware and software architectures remain the same .", "label": "", "metadata": {}, "score": "43.33249"}
{"text": "This technique is applied to QC - LDPC codes for WiMAX in [ 35 ] , and a novel task arrangement algorithm is proposed to assign the processing operation for a variety of QC - LDPC codes to different PEs .The design features four - stage pipelining for task execution , flexible address generation to support multirate decoding , and early termination strategy which dynamically adjusts the number of iterations according to SNR values to save power .", "label": "", "metadata": {}, "score": "43.511204"}
{"text": "Furthermore , if the computation can be divided into different independent small parts , we can instantiate multiple computation pipelines to parallelize the computation by duplicating the logic ( Section 4.5 ) .Hence , for loop optimizations , it is important to consider resource use ; loop optimizations may improve performance , but can limit flexibility of implementing multiple computation pipelines in the parallelization and resource duplication step .", "label": "", "metadata": {}, "score": "43.52819"}
{"text": "Overall , at this level , FastFlow building blocks make it possible to realise arbitrary streaming networks over lock - less channels .In summary , the FastFlow building blocks layer realizes the two basic features : . parallelism exploitation , i.e. the creation , destruction and life cycle control of different flows of controls , and .", "label": "", "metadata": {}, "score": "43.56012"}
{"text": "These operations are often highly parallel .The data parallel model is particularly apt for data - intensive , computation - oriented applications like image and signal processing , neural network computations , etc .The Data Field Model is an attempt to create a formal , data parallel model that is suitable as a basis for high - level data parallel programming and specification .", "label": "", "metadata": {}, "score": "43.660183"}
{"text": "A highly efficient pipelined implementation uses 2 multipliers per weight .As shown in the illustrative examples .As an example , the upper limit of the ratio of multipliers to weights may be determined using a network having a 1 - 1-N 0 topology , as illustrated by Equation ( 15 ) .", "label": "", "metadata": {}, "score": "43.75197"}
{"text": "As shown through the previous sections , in the great majority of current LDPC decoders , some kind of intradecoder communication is necessary .Except for very few single - core implementations based on the single - instruction single datapath ( SISD ) paradigm , the need for message routing or permutation is a constant throughout the wireless communication state of the art .", "label": "", "metadata": {}, "score": "43.838512"}
{"text": "This change is intended to overcome the pipelining data hazard and allow a significant performance increase to be achieved .The pipeline design for the system must also deal with another issue related to the parallel computation of both the feed forward stage and back propagation stage .", "label": "", "metadata": {}, "score": "43.924904"}
{"text": "It is also phase - aware .Using DPAPP , we develop a prediction - driven runtime optimization scheme , which drastically reduces the overhead of searching the optimization space for power - performance efficiency , while achieving near - optimal performance and power savings in real parallel applications .", "label": "", "metadata": {}, "score": "44.05433"}
{"text": "In our GPU implementation , we used constant cache to store the commonly - used constant parameters in order to decrease access time , including the substitution matrix and the query sequence .In addition , we used global memory to store the database sequence as the size of the latter can be in the hundreds of Megabytes .", "label": "", "metadata": {}, "score": "44.129368"}
{"text": "A partially parallel decoder with parallelism P consists of P node processors , while an interconnection structure allows various kinds of message passing according to the implemented architecture .Based on the decoding schedule that is , TPMP or Layered decoding , the datapath can be optimized accordingly .", "label": "", "metadata": {}, "score": "44.21362"}
{"text": "As a result , introducing parallelism can be sensitive to AutoPilot correctly detecting independence between computations .To create a position where we can explore functional parallelism , we define an extra array dimension on data arrays used within the inner loop .", "label": "", "metadata": {}, "score": "44.246315"}
{"text": "For example , both loop unrolling and pipelining enable multiple loop iterations to be executed in parallel with more resource usage ( e.g. , registers or functional units ) , but different optimizations improve performance and use resources in different ways .", "label": "", "metadata": {}, "score": "44.54566"}
{"text": "The prevailing , process - parallel programming paradigms are however hard to master for many applications .Thus , efficient system and software development for these applications , on this kind of systems , will require simpler models on a higher level .", "label": "", "metadata": {}, "score": "44.566235"}
{"text": "In this way , again , only necessary hardware is allocated to perform the calculations of the inherent MLP - BP arithmetic , and resource allocation inefficiencies arise only when the output width is not wholly divisible by the ITER parameter .", "label": "", "metadata": {}, "score": "44.624237"}
{"text": "\" Data is then moved to the SPE where it is processed .The GPP Platform .For the purpose of our GPP - based implementation of the Smith - Waterman algorithm , we targeted a PC with a 3.4 GHz Pentium 4 Prescott processor , 1 GB of RAM , running Windows XP OS .", "label": "", "metadata": {}, "score": "44.63539"}
{"text": "Computation scaling normalized to standard definition video ) .The large computation complexity of stereo matching requires hardware acceleration to meet performance goals , but stereo matching is also rapidly evolving , which demands reduced development time for hardware implementations .Thus , stereo matching is an attractive application for HLS - based hardware design .", "label": "", "metadata": {}, "score": "44.68978"}
{"text": "When possible , we convert imperfectly nested loops to perfectly nested loops to allow loop flattening , which saves 1 cycle of latency for each traversal between loop levels .For inner loops , we normally use pipelining to improve the throughput of computation .", "label": "", "metadata": {}, "score": "44.81967"}
{"text": "In any case where an architecture or hardware configuration or the like is embodied in software , the software may be provided as computer readable code on a physical computer readable media that may be executed by a computing device .According to another aspect , there is provided a method for designing or implementing a hardware configuration of an artificial neural network .", "label": "", "metadata": {}, "score": "44.8545"}
{"text": "These factors are sometimes conflicting ( e.g. , complete unrolling a small to medium size inner loop may be best , pipelining the largest loop may be best , etc . ) .In many cases , these software constraints are easily achieved by software engineers familiar with optimization techniques .", "label": "", "metadata": {}, "score": "44.91266"}
{"text": "However , these constraints sometimes conflict with \" good \" software engineering practices .Examples of \" good \" software practices include maximizing code reuse with heavily parameterized code ; using variable loop bounds and early exit conditions to reduce worst - case paths in comparison to FIFO ordered fine - grained interleaving of computation .", "label": "", "metadata": {}, "score": "44.938454"}
{"text": "The simple hardware - based task scheduling enables the control processor and the task dispatcher to vary the degree of autonomy over scheduling short - lived tasks , an adjustment necessary to accommodate the requirements of different embodiments of the architecture .", "label": "", "metadata": {}, "score": "44.956985"}
{"text": "These decoders make often use of TDMP and VSS , that require either reduced communication or very regular patterns : the involved interconnection structures are simple ; ( ii ) partially parallel architectures : referring to the graph representation of the LDPC . matrix within a selected decoding approach , it is possible to map the graph nodes onto a certain number of processing cores .", "label": "", "metadata": {}, "score": "45.01476"}
{"text": "None of the parallel implementations in [ 20 - 22 ] grant multimode flexibility due to wired connections .In addition , almost all existing fully parallel LDPC decoders are built on custom silicon , which precludes any prospect of reprogramming .", "label": "", "metadata": {}, "score": "45.18815"}
{"text": "For instance , in [ 21 ] , the author presented a GPP implementation of the Smith - Waterman algorithm on a 2.0 GHz Xeon Core 2 Duo processor with 2 GB of RAM running Windows XP SP2 .The software implementation exploited Intel SSE2 technology and resulted in a much higher performance of 1.37 GCUPS .", "label": "", "metadata": {}, "score": "45.225056"}
{"text": "Hardware Implementation Details .This section on hardware implementation details relates to configuring a scalable network having a variable degree of parallelism .Further implementation details relate to pipelined configurations of the scalable network .Even further implementation details relate to configuring a scalable network with a variable arithmetic representation . A. Scalability - A Variable Degree of Parallelism . 1 ) Network Level .", "label": "", "metadata": {}, "score": "45.285652"}
{"text": "Generally , it may be difficult to estimate the required number of slices consumed by every implementation , and it is unnecessary due to the low slice to multiplier consumption ratio .That is , the limiting factor in synthesizing the hardware configuration is the number of multipliers consumed .", "label": "", "metadata": {}, "score": "45.331272"}
{"text": "The ZONoC exploits this propriety by running offline simulations and storing routing information into dedicated memories , effectively wiping out the time spent for routing and traffic control .Overall network complexity is scaled down , since no routing algorithm is necessary ; FIFO length can be trimmed to the minimum necessary , while router architecture is as simple as possible ( Figure 3 ) .", "label": "", "metadata": {}, "score": "45.462624"}
{"text": "Examples of streaming networks that can be build are : .Other orchestrations are also possible , although their correct exploitation may be non - trivial .In particular expressing N - to-1 , 1-to - M , and N - to - M streaming networks might be complex and require mutual exclusion , which is typically a source of a non - negligible overhead in multi - core architectures .", "label": "", "metadata": {}, "score": "45.528854"}
{"text": "In some embodiments , the network performance estimate for each ITER value is calculated by the performance estimation module 1015 using Equations ( 13 ) and ( 14 ) provided herein .At step 960 , an ITER selection module 1025 selects a degree of parallelism ( ITER value 1035 ) from the multiple degrees of parallelism of the set .", "label": "", "metadata": {}, "score": "45.54824"}
{"text": "The first thread in the batch , on the other hand , loads this data as initial data for the subsequent sub - matrix calculation .This operation continues in turn until the end of the entire alignment matrix calculation .Figure 9 : Our GPU parallel thread implementation of the Smith - Waterman algorithm : store and load operations are performed by the final thread and the first thread in each thread batch ( block ) to allow for any sequence length processing .", "label": "", "metadata": {}, "score": "45.588615"}
{"text": "If necessary , output tasks could be popped from the accelerator output channel .More details on FastFlow accelerator technology can be found in [ ADK11].Building Blocks .At this level , the FastFlow programming model can be thought as a hybrid shared - memory / message - passing model .", "label": "", "metadata": {}, "score": "45.6112"}
{"text": "Architecture Overview .Scalability , Efficiency and Pipelining .The following description focuses on an architecture for a customized scalable network with N network layers , where the customized scalable network has a variable degree of parallelism .The customized scalable network may also be pipelined .", "label": "", "metadata": {}, "score": "45.685097"}
{"text": "FIG .7 ) .The hardware device(s ) may be of various types and/or combinations of types , such as FPGAs , processors , and ASICs .Referring now to .FIG .9 there is shown a more detailed schematic diagram of a further example network architecture 200 capable of implementing variable degrees of parallelism in accordance with embodiments described herein .", "label": "", "metadata": {}, "score": "45.743664"}
{"text": "These limitations were addressed by Xiang et al . in [ 34 ] , whereby the authors presented an overlapped TDMP decoding algorithm .The design proposes a block row and column permutation criterion in order to reduce correlation between consecutive rows and uniform distribution of zero and nonzero matrices in columns , with a smart memory management technique .", "label": "", "metadata": {}, "score": "45.770657"}
{"text": "However , this also can make exposing information about code independence ( for parallelism ) difficult .For example , the parallelism code shown in Section 4.5 is required because anything except complete array partitioning does not guarantee that AutoPilot will assume partitioned arrays are independently accessed .", "label": "", "metadata": {}, "score": "45.81591"}
{"text": "As a result , heuristics have typically been used to speed the training process while preventing over - fitting .Yet even with the use of heuristics , this training process is generally limited to off - line learning , to applications where training data is static , or where conditions initially determined will stay the same for the duration of network 's useful function .", "label": "", "metadata": {}, "score": "45.866055"}
{"text": "The nature of the application ( problem ) and the size of the network topology also play an important role .For example , pattern classification problems can allow a higher error threshold than function approximation problems .This impacts the choice of the arithmetic representation and , as such , the hardware device resources used in the implementation .", "label": "", "metadata": {}, "score": "45.870743"}
{"text": "There are many success stories of using HLS tools , but there is little systematic study of using HLS tools for hardware design , particularly when the original software is not written specifically for HLS .The code refinement process for HLS [ 25 ] and the benchmarks proposed by Hara et al .", "label": "", "metadata": {}, "score": "45.955284"}
{"text": "Much effort was dedicated to reducing auxiliary resource usage , such as block rams and slice consuming hardware .The multipliers could generally not be reduced as their number directly impacts the number of multiply - intensive operations the hardware is capable of performing in parallel .", "label": "", "metadata": {}, "score": "45.96913"}
{"text": "We present an unbiased study of the progress of HLS in usability , productivity , performance of produced design , software constraints , and commonly required code optimizations .Based on this study , we present both guidelines for algorithm implementation that will allow HLS compatibility and an effective optimization process for the algorithms .", "label": "", "metadata": {}, "score": "46.02134"}
{"text": "Please note that the current computers may be up to 2 - 3\u00d7 times faster than the computer used for these experiments .Further , it is anticipated that an optimized mapping of the FPGA pipeline may achieve 2 - 3\u00d7 times higher clock rates than 100 MHz as well .", "label": "", "metadata": {}, "score": "46.063534"}
{"text": "( iii ) Automatic temporary buffers for memory access re - use .( iv ) Iteration between array optimizations , pipelining , and parallelization for efficient search of design space .Conclusions .High level synthesis tools offer an important bridging technology between the performance of manual RTL hardware implementations and the development time of software .", "label": "", "metadata": {}, "score": "46.259907"}
{"text": "FastFlow has been originally designed for cache - coherent multiprocessors , and in particular commodity homogenous multi - core ( e.g. Intel core , AMD K10 , etc . ) .It has been then extended to distributed platforms , GPGPUs and heterogenous platforms .", "label": "", "metadata": {}, "score": "46.287987"}
{"text": "In some cases , the hardware resources available may comprise a table of information such as that above relating to particular hardware devices ( processors , chips , etc . ) .In providing the information relating to hardware resources available , a subset of the table may be selected based on , for example , hardware cost , power requirements or the like to set a limit to the provided hardware resources available .", "label": "", "metadata": {}, "score": "46.523884"}
{"text": "A measure of the hardware processing speed available may also be available as an element of the hardware resources available .This processing speed may be referred to as the clock frequency , and may be obtained from hardware specifications .Then a number of updates that can be performed on the number of weights in a predetermined time based on the processing speed is determined based on the given degree of parallelism .", "label": "", "metadata": {}, "score": "46.53869"}
{"text": "Referring now to .FIGS .16 ( a ) and 16 ( b ) there is shown two graphs illustrating the impact of variable degrees of parallelism on resource utilization for an example hardware device and various FPGA chips .It will be understood that the fully serial configuration represents a practical maximum for degree of parallelization .", "label": "", "metadata": {}, "score": "46.56425"}
{"text": "This means that each PE will perform the computation associated to multiple nodes , necessitating memories to store intermediate messages between tasks .Time sharing of PEs greatly reduces the area and routing overhead .Partially parallel architectures are studied extensively and provide a good trade off in throughput , complexity , and flexibility , with some solutions obtaining throughputs up to 1 Gbps .", "label": "", "metadata": {}, "score": "46.565334"}
{"text": "The following section will first present background on the Smith - Waterman algorithm , together with an overview of the target implementation platforms , namely , Xilinx Virtex-4 FPGAs , NVIDIA GeForce 8800GTX GPU , IBM 's Cell BE processor and finally the Pentium 4 Prescott processor .", "label": "", "metadata": {}, "score": "46.79654"}
{"text": "In addition , the loop directives as shown in Table 3 can specify expression balancing for improved fine - grained parallelism , and pipelining of computation within a code section .Data Arrays .Data arrays may be transformed to improve parallelism , resource scheduling , and resource sharing .", "label": "", "metadata": {}, "score": "46.81034"}
{"text": "The PE architecture is independent of code parameters , and the memory capacity sets the only limit to the size of supported codes .Together with the PE , we devised a decoder reconfiguration technique to upload the data necessary for routing and memory management when switching between codes .", "label": "", "metadata": {}, "score": "46.842545"}
{"text": "At step 920 , a set of multiple degrees of parallelism that may be used for implementing the desired network topology is determined in order to calculate each degree 's corresponding resource and performance estimates .Any number of ITER values may be chosen to make up the set of the multiple degrees of parallelism , and each ITER value of the set may be any small or large number .", "label": "", "metadata": {}, "score": "46.871933"}
{"text": "Without such a systematic study , the crucial insights into how to use current state of the art HLS tools are lacking , including the following .( i ) Performance of HLS - produced hardware on typical software .( ii ) Advantages and disadvantages of common code transformations .", "label": "", "metadata": {}, "score": "46.89438"}
{"text": "They are implemented on top of core patterns .Core patterns They provide a general data - centric parallel programming model with its run - time support , which is designed to be minimal and reduce to the minimum typical sources of overheads in parallel programming .", "label": "", "metadata": {}, "score": "46.918938"}
{"text": "There will be empty or useless clock cycles .This does not generally decrease resource utilization since hardware for at least one number per clock cycle must be present at a minimum .For each degree of parallelism of the multiple degrees of parallelism at least one of two estimates are calculated ( step 930 ) .", "label": "", "metadata": {}, "score": "47.015522"}
{"text": "1 is a simplified diagram of the macro - and micro - architecture for a hyperprocessor according to one embodiment of the present invention ; and .FIG .2 is a diagram of an exemplary control processor microarchitecture for use in a hyperprocessor according to one embodiment of the present invention .", "label": "", "metadata": {}, "score": "47.0943"}
{"text": "Computing is currently at an inflection point , with the degree of on - chip thread - level parallelism doubling every one to two years .The number of cores has become one of the most important architectural parameters that characterize performance and power - efficiency of a modern microprocessor , and a computer system in general .", "label": "", "metadata": {}, "score": "47.1426"}
{"text": "This model makes it possible to address fine grain workloads , bursts of fine grain workloads , and coarse grain workloads .During nonblocking phase , the FastFlow run time employes only lock - free and wait - free algorithms in all synchronisation critical paths ( whereas it uses pthreads locks in the blocking phase ) .", "label": "", "metadata": {}, "score": "47.15294"}
{"text": "This relatively low accuracy still requires 10 fractional binary digits , but the combination of bitwidth reduction and smaller , simpler functional units can offer significant gain in terms of both latency and resource .Using constant propagation , AutoPilot can sometimes determine that a set of variables have a fixed range and automatically reduce the bit - width of those variables to reduce storage requirements .", "label": "", "metadata": {}, "score": "47.166225"}
{"text": "Access speed to shared memory is as fast as accessing SP registers as long as there are no bank conflicts [ 12 ] .Device memory offers global access to a larger ( 768 MB ) but slower storage .Any thread in any SP can read from or write to any location in the global memory .", "label": "", "metadata": {}, "score": "47.182663"}
{"text": "a parallelization subsystem configured to provide a variable degree of parallelization to the input layer , at least one hidden layer , and output layer , wherein the parallelization subsystem comprises : . for each layer , a layer synchronization module , the layer synchronization module configured to : . receive an output from the layer ; . synchronize the output from the layer based on the variable degree of parallelization ; and .", "label": "", "metadata": {}, "score": "47.2152"}
{"text": "However , here again , such implementations do not give us the development time , for instance , nor do they guarantee a fair balance of experience between the developers of each implementation .They hence do not serve the particular aims of this paper .", "label": "", "metadata": {}, "score": "47.23748"}
{"text": "After that , comparative implementation results on all platforms are presented in Section 7 before final conclusions are drawn .Background .Pairwise biological sequence alignment is a basic operation in the field of bioinformatics and computational biology with a wide range of applications in disease diagnosis , drug engineering , biomaterial engineering , and genetic engineering of plants and animals [ 1 ] .", "label": "", "metadata": {}, "score": "47.26215"}
{"text": "( DP- ) based algorithms such as the Needleman - Wunsch algorithm [ 2 ] and the Smith - Waterman algorithm [ 3 ] .The latter is the most commonly used DP algorithm as it finds the best local alignment of subsegments of a pair of biological sequences .", "label": "", "metadata": {}, "score": "47.33087"}
{"text": "It portraits an IP core of a full mode LDPC decoder that can be synthesized for a selected code rate specified by WiMAX standard .The unified decoder architecture proposes two different datapaths for TPMP and layered decoding , as in [ 33 ] , and combines them in a single architecture sharing the components common to both .", "label": "", "metadata": {}, "score": "47.450253"}
{"text": "The third term relates to utilization of processors or components , while the fourth relates to instruction level parallelism as described above and the fifth is a technology statement of how fast the processor can be run and how much logic may be fit on a die .", "label": "", "metadata": {}, "score": "47.474518"}
{"text": "FIG .3 , there is shown an example diagram of a network having a degree of parallelism of 1 .This represents a fully parallel hardware configuration where each hardware stage is issued a single input pattern 150 ( or previous layer output ) in one clock cycle .", "label": "", "metadata": {}, "score": "47.60455"}
{"text": "This is true for both the serial and fully parallel configurations .In addition to the impact of arithmetic representation on resources used , arithmetic representation also has a direct impact on ANN convergence to a suitable solution to the modeled problem .", "label": "", "metadata": {}, "score": "47.731735"}
{"text": "To meet the stringent performance or energy constraints , embedded system designers often identify one or more computational intensive kernels ( e.g. , for signal processing , image processing , compression and decompression , cryptographic algorithms , etc . ) for hardware acceleration .", "label": "", "metadata": {}, "score": "47.82419"}
{"text": "Maximum flexibility could be achieved by uploading new check matrices in memory .However , each edge of the graph must be handled separately : as a result , throughput is usually very low , insufficient for most of standard applications .", "label": "", "metadata": {}, "score": "47.873604"}
{"text": "The complete decoder only requires 8 cores , since each of them can handle three processing tasks at once .The simple communication network maintains this parallelism , allowing for efficient memory sharing and collision avoidance .The intrinsic flexibility of the ASIP approach allows multiple standards ( WiFi , WiMAX , LTE , and DVB - RCS ) to be easily supported : the exploitation of the diverse datapath allows a very high best case throughput , while the reduced network parallelism keeps the complexity low .", "label": "", "metadata": {}, "score": "48.047897"}
{"text": "At step 950 , a performance estimation module 1015 calculates a performance estimate for the desired network topology with the given degree of parallelism .This estimate is calculated for each of the multiple degrees of parallelism .In a particular case , the network performance estimate represents a measure of the number of network parameters or weights updated each second when implementing the desired network topology .", "label": "", "metadata": {}, "score": "48.062134"}
{"text": "Implementation results show a significant reduction in complexity with respect to [ 28 , 36 , 56 , 72 ] and comparable or superior throughput .Reducing the NoC Penalty .The NoC approach guarantees a very high degree of flexibility and , in theory , a NoC - based decoder can reach very high throughput .", "label": "", "metadata": {}, "score": "48.06792"}
{"text": "( i ) Libraries for data structures ( e.g. , Standard Template Library ) .( ii ) OpenCV computer vision library for efficient implementations of common , basic vision algorithms .( iii ) Use of dynamic memory reallocation .For example , as an effort to compare and evaluate many stereo matching algorithms , Scharstein et al .", "label": "", "metadata": {}, "score": "48.177372"}
{"text": "Thus , the execution times shown in Table 3 do not include the database transfer time as it is an initial step .In practice , queries are made against fairly static databases , and hence this assumption is reasonable .Table 3 : Performance comparison .", "label": "", "metadata": {}, "score": "48.204166"}
{"text": "In both embedded systems and general purpose computing , a high demand for computing power exists .This demand will continue to increase with increasing system complexities and the trend to address more and more problems with digital solutions .One solution to satisfying such demand is the exploitation of instruction level parallelism ( ILP ) in , for example , very large instruction word ( VLIW ) processors , single instruction multiple data ( SIMD ) processors , superscalar processors , and their variants .", "label": "", "metadata": {}, "score": "48.2528"}
{"text": "The performance of another topology , the 2D toroidal mesh , is evaluated in [ 40 ] .The routing element implements the near - optimal . routing for the torus / mesh [ 75 ] .A whole set of communication - centric parameters is varied in order to evaluate the impact of the network latency on the whole decoder performance .", "label": "", "metadata": {}, "score": "48.284157"}
{"text": "Then , hardware latency in seconds is computed by multiplying the clock period by the measured clock cycles ; speedup is the ratio of hardware latency to original ( unmodified ) software latency .The software execution is performed on an Intel i5 2.67 GHz CPU with 3 GB of RAM .", "label": "", "metadata": {}, "score": "48.292137"}
{"text": "Using a VHDL benchmark module , a root mean square calculation is performed , and results are written to file at desirable epoch resolution .For all hardware simulations , error data points are obtained by testing the average error for the entire data set for every 10 epochs trained .", "label": "", "metadata": {}, "score": "48.392174"}
{"text": "Therefore , this optimization step is a multistep process .First , for each data array in the design , we determine the operand range and redefine the array using AutoPilot 's fixed - point integer ( ap_fixed ) variables to reduce the per - element storage requirement .", "label": "", "metadata": {}, "score": "48.42404"}
{"text": "The Xilinx hardware device platform is intended as an example only and other platforms may be used , such as for example Altera , or a manufactured ASIC under a variety of processes .Table I provided below gives a general idea of consumed resources in terms of slices , multipliers and block rams for various network topologies and degrees of parallelism .", "label": "", "metadata": {}, "score": "48.477264"}
{"text": "data , that are subsequently rearranged by an adaptation network into the desired order according to the current submatrix size .Implementation results show that the proposed MC - CS network outperforms in terms of complexity previous similar solutions as [ 56 - 59 ] , with a saving ranging from .", "label": "", "metadata": {}, "score": "48.47784"}
{"text": "Through the previous three steps , we have reduced the amount of computation and memory resources .In this step , we examine the computation loops in the program and apply loop pipelining , loop merging , loop unrolling , loop flattening , and expression balancing to optimize performance .", "label": "", "metadata": {}, "score": "48.49791"}
{"text": "The decoder achieves a maximum throughput of 287 Mb / s , with support for other similar QC - LDPC codes .An interesting way to tackle the flexibility issue is proposed in [ 35 ] .Here the different code parameters are handled via what has been called processing task arrangement .", "label": "", "metadata": {}, "score": "48.54538"}
{"text": "This problem is however also opening a window of opportunity for hitherto niche parallel computer technologies such as Field Programmable Gate Arrays ( FPGAs ) and Graphics Processor Units ( GPUs ) since the problem of parallel programming has to be tackled for general - purpose processors anyway .", "label": "", "metadata": {}, "score": "48.576817"}
{"text": "After a super - scalar microprocessor 106 ( one of the SPPUs 104 in the exemplary embodiment ) fetches and decodes an instruction , the instruction is dispatched to the appropriate execution unit 109 , and , at least in dynamic scheduling , the results are collected in a program order .", "label": "", "metadata": {}, "score": "48.76565"}
{"text": "The PE is the core of the decoding process , where the algorithm operations are performed .Its design is an important step that heavily affects overall performance , complexity and flexibility of decoder .The PE can be designed to be serial , with internal pipelining to maximize throughput , or parallel , processing all data concurrently .", "label": "", "metadata": {}, "score": "48.855698"}
{"text": "Here , the sequence alignment is performed in several passes .A First - In - First - Out ( FIFO ) memory block is used to store intermediate results from each pass before they are fed back to the array input for the next pass .", "label": "", "metadata": {}, "score": "48.895462"}
{"text": "The results were compared with similar software simulations conducted using MATLAB and WEKA software .To test these example embodiments hardware simulations using ModelSim 6.1 were conducted .Performance was obtained using the number of clock cycles in a training run and a conservative clock frequency estimate of 100 MHz .", "label": "", "metadata": {}, "score": "49.10562"}
{"text": "Rovini et al .in [ 55 ] exploit the simple structure of the barrel shifter to design a circular shifting network for WiMAX codes .This network must be able to handle all the different submatrix sizes of the standard , thus effectively becoming a multisized circular shifting ( MS - CS ) network .", "label": "", "metadata": {}, "score": "49.159126"}
{"text": "General purpose microprocessors and DSPs utilize strong programmability to achieve highly flexible LDPC decoding , allowing to modify various code parameters at run time .Programmable devices are often used in the design , test , and performance comparison of decoding algorithms .", "label": "", "metadata": {}, "score": "49.172623"}
{"text": "Together , this study leads to two groups of future directions for HLS tools : one to improve the usability and accessibility of currently available HLS features , and the second to improve performance gap between HLS and manual design by adding new features .", "label": "", "metadata": {}, "score": "49.256973"}
{"text": "Description .TECHNICAL FIELD OF THE INVENTION .The present invention is directed , in general , to processor design and , more specifically , to high performance processors with high - level multi - threaded parallelism .The invention may be applied to embedded systems as well as general purpose computing .", "label": "", "metadata": {}, "score": "49.27323"}
{"text": "LMPD - ICM is a variation of the original layered decoding : the .matrix is partitioned in several layers , with each layer yielding a core matrix .This consists of the nonzero columns of that layer .The resulting core matrix is further divided into smaller and identical tasks .", "label": "", "metadata": {}, "score": "49.309147"}
{"text": "This feature makes DMA a desirable option for data intensive applications .However , based on our timing trace results on the Cell BE , we found that the computation time within each SPE is the dominant component of the total execution time .", "label": "", "metadata": {}, "score": "49.397606"}
{"text": "It is important to evaluate the design effort required to achieve this level of speedup .Table 7 shows the development effort spent on embedded benchmark kernels and stereo matching algorithms , normalized to development time of a single hardware designer .", "label": "", "metadata": {}, "score": "49.529785"}
{"text": "to support the development of portable and efficient applications for homogenous and heterogenous of platforms , including multicore , many - core ( e.g. GPGPU , FPGA ) , and distributed clusters of them .These two goals have been perceived as a dichotomy for many years by many computer practitioners .", "label": "", "metadata": {}, "score": "49.651634"}
{"text": "In another particular case , the architecture may further include a pipeline subsystem to pipeline the scalable artificial neural network .In yet another particular case , the architecture may further include a variable arithmetic representation for the scalable artificial neural network .", "label": "", "metadata": {}, "score": "49.812004"}
{"text": "For these reasons , stereo matching is representative of many computer vision applications that may demand acceleration ; it requires a fast development cycle , and the available software is representative of algorithms developed for CPU implementations ( but not designed or optimized for HLS ) .", "label": "", "metadata": {}, "score": "49.841034"}
{"text": "( iv ) Automatic detection and conversion for common computation structures such as tree - based reductions .( v )Improved robustness of dataflow transformations , streaming computation for 2D access patterns .Performance Gap .( i ) Detection of memory level dependence across multiple , independent loops and functions , automatic interleaving of computation between the loops and functions .", "label": "", "metadata": {}, "score": "49.957863"}
{"text": "Most of these kernels are implemented with a computational - intensive loop without dynamic memory allocation or complex pointer access .Stereo Matching .Stereo matching is an extremely active area of research in computer vision , and an important underlying technology for 3D video .", "label": "", "metadata": {}, "score": "50.01681"}
{"text": "The model postulates some operations of bounds , with certain properties .Common collection - oriented primitives can be defined in terms of these operations , without referring to the actual form of the bounds .Data fields thus make a very generic form af data parallelism possible , where algorithms become less dependent on the actual data parallel data structure .", "label": "", "metadata": {}, "score": "50.019814"}
{"text": "A lower limit of the ratio may be determined using an example topology with a large number of inputs per neuron .An efficient implementation generally has a low multiplier per weight ratio as will be illustrated using the formulas below .", "label": "", "metadata": {}, "score": "50.032703"}
{"text": "As shown , the runtime is very sensitive to the tile size and tile size 64 \u00d7 64 returns the best results .This is because larger tile size limits the degree of parallelization while smaller tile size limits the unrolling factor ( e.g. , loop iterations ) within one tile .", "label": "", "metadata": {}, "score": "50.07052"}
{"text": "A software accelerator can be feed with asynchronous offloading requests from the main thread ( or any other thread ) , which basically generate a input stream for the accelerator .Results computed from an accelerator can be collected either synchronously or asynchronously .", "label": "", "metadata": {}, "score": "50.07937"}
{"text": "The graph also shows the difference in FPGA chip 175 architectures ( e.g. xc2v8000 has more slices but less multipliers than xc2vp100 ) .This graph shows that when using different ITER levels , the resources needed to implement the same network change , and so does the ability to fit an entire network onto a hardware device having particular resources .", "label": "", "metadata": {}, "score": "50.17151"}
{"text": "189 - 213 , September 2005 ( \" Gadea \" ) .The FPGA implementation only has synapse and layer parallelism but not node parallelism .These results and comparison are generally based only on some current devices and configurations .It will be understood that improved results are expected as faster devices and devices having more available resources are manufactured .", "label": "", "metadata": {}, "score": "50.200073"}
{"text": "The embodiments described herein are intended to allow efficient implementation on two levels : ( 1 ) variable arithmetic representation , and ( 2 ) linking network performance to resource utilization and degree of parallelism .Variable arithmetic representation provides a way to select the arithmetic representation that allows optimal utilization of the hardware device resources while maintaining the precision level necessary to successfully achieve network training .", "label": "", "metadata": {}, "score": "50.255356"}
{"text": "High performance computing applications where power consumption is often a bottleneck should hence benefit from this technology .This relatively high hurdle represents a major problem in the face of further market penetration for FPGA technology , and it is mainly due to FPGAs ' relatively longer development times .", "label": "", "metadata": {}, "score": "50.29608"}
{"text": "The Ultimate Reconfigurable Component , Center for Embedded Computer Systems , TR 03 - 28 , 2003 . A. Canis , et al . , \" LegUp : high - level synthesis for FPGA - based processor / accelerator systems , \" in Proceedings of the Proceedings of the 19th ACM / SIGDA International Symposium on Field - Programmable Gate Arrays , p. 33 , 2011 .", "label": "", "metadata": {}, "score": "50.424934"}
{"text": "Our experiments have highlighted the need for a balanced workload in order to optimize the performance .Furthermore , it is shown that MEP - MAS is scalable as the speedup and throughput almost linearly increases with the number of added pipelines .", "label": "", "metadata": {}, "score": "50.429962"}
{"text": "High - level Patterns .At this level patterns are presented as high - order functions ) , typically predefined methods of a class that can be instanced with a C++11Lambda function .The main design target is to provide the programmer with an easy way to parallelise \" in - place \" a ( semantically meaningful ) chunk of code , e.g. the body of a loop .", "label": "", "metadata": {}, "score": "50.445415"}
{"text": "ASICs can be used to fulfill high computational requirements of LDPC decoding , delivering very high throughputs with reasonable parallelism .The resulting IC usually meets area , power , and speed metrics .However , ASIC designs are limited in their flexibility and usually intended for single standard applications only : flexibility , if reached at all , comes at the cost of very long design time and nonnegligible area , power or speed sacrifices .", "label": "", "metadata": {}, "score": "50.474686"}
{"text": "For ease of explanation , the embodiments described herein will generally relate to implementations using configurable hardware such as FPGAs .In the discussion that follows , it will be understood that hardware resources for the scalable network implementation may be provided by any of the above hardware devices , or , in at least some cases , by a combination thereof .", "label": "", "metadata": {}, "score": "50.495415"}
{"text": "The consequent spreading of interconnect activity over multiple paths results in balanced thermal profiles , and decreased operating temperatures across the system .Over the course of these chapters , this dissertation explores the critical issues impeding the realization of thermal - aware 3D stacked multiprocessors , and details a multifaceted approach towards addressing the challenges of dark silicon .", "label": "", "metadata": {}, "score": "50.915016"}
{"text": "Scalability is implemented using a variable degree of parallelism .A scalable ANN may be implemented in a fully parallel design ( including synapse and node parallelism ) to maximize performance when the resources available on the hardware device allow that .", "label": "", "metadata": {}, "score": "50.930714"}
{"text": "The implementation of the ZK algorithm is based on a 3D array , with one entry for each possible combination of pixel and disparity .Therefore , due to the infeasible storage requirements , we omit ZK from detailed synthesis results .", "label": "", "metadata": {}, "score": "50.965897"}
{"text": "These memories dominate the area occupation , mainly due to the non - binary decoding process .Tables 4 and 5 summarize the specifications of various state - of - the - art ASIC and ASIP solutions for flexible LDPC decoders discussed above .", "label": "", "metadata": {}, "score": "50.97386"}
{"text": "Other arrangements and methods can be implemented by those skilled in the art without departing from the spirit and scope of the embodiments described herein .As a non - limiting example of a further arrangement , there may be provided a system for designing a hardware configuration of an artificial neural network .", "label": "", "metadata": {}, "score": "51.002277"}
{"text": "The topology size of the network that can be implemented on a given hardware device is limited by the number of multipliers available on the given hardware device ( e.g. FPGA ) for use in the example MLP - BP implementation .", "label": "", "metadata": {}, "score": "51.049812"}
{"text": "32 , no . 8 , pp .782 - 784 , 1983 .View at Google Scholar \u00b7 View at Scopus .F. Naessens , B. Bougard , S. Bressinck et al . , \" A unified instruction set programmable architecture for multi - standard advanced forward error correction , \" in Proceedings of the IEEE Workshop on Signal Processing Systems ( SiPS ' 08 ) , pp .", "label": "", "metadata": {}, "score": "51.05605"}
{"text": "From the above set of algorithms , five of the twelve sets of source code can be transformed for high level synthesis compatibility .For each of the five algorithms , we perform transformations to improve suitability for HLS , but we do not redesign the algorithm implementation with HLS in mind .", "label": "", "metadata": {}, "score": "51.098495"}
{"text": "An efficient scalable network implementation should generally maintain reasonable convergence speed and accuracy for a wide range of applications , achieve a high performance rate , and fit a reasonably large network within existing available hardware device resources .As such , there exists a need to develop architectures , systems and methods for implementing ANNs that have built - in mechanisms for balancing between performance and resource requirements in a consistent manner for a wide range of network topologies and varying amounts of hardware device resource availability .", "label": "", "metadata": {}, "score": "51.114197"}
{"text": "Commun .ACM 52 , 10 ( Oct. 2009 ) , 56 - 67 .DOI:10.1145/1562764.1562783 .[ADK11 ] M. Aldinucci , M. Danelutto , P. Kilpatrick , M. Meneghin , and M. Torquati .Accelerating code on multi- cores with fastflow .", "label": "", "metadata": {}, "score": "51.160156"}
{"text": "For this work , we do not develop or use specialized communication protocols .Function Calls .By default , AutoPilot generates RTL for each functional call as a separate module , and function execution is not overlapped .The directives ( Table 2 ) can specify that functions can use fine - grained communication and overlap computation of multiple functions .", "label": "", "metadata": {}, "score": "51.267616"}
{"text": "This can be challenging in cases where by necessity code shares data resources , but the user knows ( and could denote ) that parallel function calls would not interfere .Finally , although AutoPilot has powerful optimizations available , it is sometimes difficult to apply it to code that was not designed in advance to use the optimization .", "label": "", "metadata": {}, "score": "51.30594"}
{"text": "However , a number of design issues arise when using configurable hardware devices to implement ANNs , and specifically MLP - BP .The first is determining the most efficient arithmetic representation format while maintaining adequate precision to achieve learning .Another issue is the architecture , and particularly the means of efficiently implementing large networks when available hardware device resources are limited .", "label": "", "metadata": {}, "score": "51.343098"}
{"text": "The resulting networks are constrained by size and type of algorithm implemented .More recently , the focus on ANN hardware implementation has shifted toward reconfigurable platforms , and particularly Field Programmable Gate Arrays ( FPGAs ) .One past effort used a Runtime Reconfiguration ( RTR ) to improve the hardware density of FPGAs by dividing the BP algorithm into three sequentially executed stages .", "label": "", "metadata": {}, "score": "51.349236"}
{"text": "Considering parallelism .which has to realize the permutations of identity matrix .Typically , a highly flexible barrel shifter allows all possible permutations ( rotations ) of identity matrix .In some implementations , a single node type joining both VN and CN operations is present , thus changing the nature and function of the connections .", "label": "", "metadata": {}, "score": "51.37976"}
{"text": "Once a task is received by an SPPU 104 , the SPPU 104 uses an internal program memory system to retrieve the necessary instructions for the assigned task , independent of the remainder of the system 100 .The simple concept underlying the hyperprocessor uses knowledge gained in microprocessor architectures and instruction level parallelism in application at the system level for task level parallelism ( and resource optimization ) to achieve a program unity .", "label": "", "metadata": {}, "score": "51.393944"}
{"text": "BeN. Together with efficient control signal generation , this solution outperforms in terms of both complexity and flexibility other modified Benes - based decoders as [ 57 , 64 ] , that exploit a secondary BeN to rearrange the first one .", "label": "", "metadata": {}, "score": "51.426598"}
{"text": "The number of dependent cells needed for each alignment is simply equal to the length of the query sequence , since we are calculating cells column by column .After all SPE pairwise alignments are completed , the highest pairwise score calculated by each SPE is returned to the main program ( in the PPE ) for final reduction .", "label": "", "metadata": {}, "score": "51.510696"}
{"text": "Hardware implementation of LDPC decoders is mainly dictated by the nature of application .LDPC codes have been adopted by a number of communication ( wireless , wired , and broadcast ) standards and storage applications : a few of them are briefly summarized in Table 2 .", "label": "", "metadata": {}, "score": "51.516632"}
{"text": "Data Parallelism is a method for parallelizing a single task by processing independent data elements of this task in parallel .The flexibility of the technique relies upon stateless processing routines implying that the data elements must be fully independent .Data Parallelism also supports Loop - level Parallelism where successive iterations of a loop working on independent or read - only data are parallelized in different flows - of - control and concurrently executed .", "label": "", "metadata": {}, "score": "51.53643"}
{"text": "If needed , a graph of nodes can be switched from nonblocking to blocking behaviour , and vice - versa ( via a native distributed protocol ) .The possibility to switch from blocking to nonblocking behaviour is useful to manage bursts of activity interweaved by periods of inactivity .", "label": "", "metadata": {}, "score": "51.654285"}
{"text": "To achieve code rate flexibility , the check node PE is synthesized for maximum check node degree ( .State - of - the - Art .ASIC Implementations .The partially parallel decoder presented by Kuo and Willson in [ 32 ] offers a simple and tailored solution to the mobile WiMAX problem .", "label": "", "metadata": {}, "score": "51.695686"}
{"text": "Indeed , we recognize that our experiment is not statistically significant and that development times for instance would vary significantly for one programmer to another .Nonetheless , our objective was to put the \" speed - up \" values achieved into perspective with an analysis of productivity based on the personal experience of an average Ph.D. student .", "label": "", "metadata": {}, "score": "51.879936"}
{"text": "Task level parallelism has not previously been successfully implemented for various reasons , including principally data and control dependencies among the tasks .Previous attempts at task level parallelism and speculative multithreading have depended on the old paradigm in microprocessors .Just as a data space ( the GPR file ) shared by components within a microprocessor supplies all execution units , all processors 104 within hyperprocessor 100 share the universal register file 105 .", "label": "", "metadata": {}, "score": "51.921715"}
{"text": "The BFAS algorithm uses exponential , square root , and logarithm floating point functions , but with small input ranges ; the cost of a ROM is small compared to the cost of implementing floating point or integer functional units that perform these functions .", "label": "", "metadata": {}, "score": "51.998013"}
{"text": "In the case of an ASIC , the resources may , for example , comprise the amount of silicon area used .In order to determine which degree of parallelism to implement for the scalable network , example formulas are provided herein that estimate network performance and/or hardware resource utilization .", "label": "", "metadata": {}, "score": "52.014328"}
{"text": "In particular , traditional lock - free implementations ( such as Lamport 's solution [ Lam83 ] ) of SPSC queues are correct under sequential consistency only , where none of the current multi - cores implement sequential consistency .Also , some correct queue implementations induce a very high invalidation rate - and thus reduced performance - because they exhibit the sharing of locations that are subject to alternative invalidations from communication partners ( e.g. head and tail of a circular buffers ) .", "label": "", "metadata": {}, "score": "52.03542"}
{"text": "Fastflow relies on wait - free , non - blocking synchronizations .The approach has pros and cons .The main advantage consists in performance : avoiding memory fences dramatically reduces cache coherence overhead .Distributed platforms .Documentation in progress .", "label": "", "metadata": {}, "score": "52.196686"}
{"text": "Fully customized instruction set , pipeline and memory achieve efficient , high - performance decoding : ASIP solutions are able to provide inter- and intra - standard flexibility through limited programmability , guaranteeing average to high throughput .Decoding Schedule .A partial parallel architecture becomes mandatory to realize flexible LDPC decoding .", "label": "", "metadata": {}, "score": "52.24008"}
{"text": "More importantly , the data is written and read in FIFO order .Because of the requirement for this FIFO order , the array stream optimization is not available for the other embedded benchmark kernels or the stereo matching algorithms due to the complex data access order .", "label": "", "metadata": {}, "score": "52.27668"}
{"text": "The number of multipliers used can be estimated by using the following equation ( 11 ) which links the desired network topology and ITER value with the number of multipliers needed to implement the network .MULT .N .h .", "label": "", "metadata": {}, "score": "52.298347"}
{"text": "However , very large values of CN degree increase the latency and limit the achievable throughput to a great extent , requiring a high degree of parallelism to achieve medium - to - high throughputs ( Table 4 ) .Table 4 : Flexible LDPC decoder ASIC implementations .", "label": "", "metadata": {}, "score": "52.299484"}
{"text": "For instance , the process technology of the GPP and GPU devices reported in [ 21 , 23 ] , respectively were more advanced than the FPGA technology we used in this study .Moreover , these implementations do not report the development time which is crucial to assess productivity as will be shown below .", "label": "", "metadata": {}, "score": "52.367577"}
{"text": "The GPP implementation 's steady state power figure however is used , instead of the dynamic power , as there is no distinction between host and accelerator in this case .Multiplying the power figure for each platform with the execution time , we obtain the energy consumed by each implementation as shown in the Table 9 .", "label": "", "metadata": {}, "score": "52.40903"}
{"text": "However , the implementation employs heavy use of memory re - allocation to instantiate the correct combinations of computation blocks and resize storage elements properly .Stereo matching algorithms can be classified into global and local approaches .Global approaches use a complex optimization technique to simultaneously optimize the disparity matching costs for all pixels in the image .", "label": "", "metadata": {}, "score": "52.544067"}
{"text": "This allows the network performance and resource utilization to scale up or down well for large as well as small networks .This feature may make it easier to fit an ANN on embedded applications where the hardware device may have limited resources because of physical size constraints or where the hardware device might be used for more than just running the ANN .", "label": "", "metadata": {}, "score": "52.552444"}
{"text": "C. Efficiency Implementation .According to a further aspect , the systems and methods described herein provide a customized scalable network having an efficient implementation , which may involve using a variable arithmetic representation .The embodiments described herein are intended to consume resources quite efficiently .", "label": "", "metadata": {}, "score": "52.646496"}
{"text": "Transitions from these two states involve calls to the underlying threading library ( and to the O.S. ) .Once created , an accelerator can be run , making it capable of accepting tasks on the input channel .When running , the threads belonging to an accelerator might fall into an active waiting state .", "label": "", "metadata": {}, "score": "52.647408"}
{"text": "Hierarchically , pixel messages are computed on down sampled versions of the image and successively refined as the image is scaled towards the original resolution .Thus , CSBP scales the computation hierarchy in order to limit the maximum memory consumption .", "label": "", "metadata": {}, "score": "52.705917"}
{"text": "FastFlow supports multiprocessors exploiting any memory consistency , including very weak consistency models .FastFlow implementation is lock - free , and for several memory consistency models is also memory fence - free ( e.g. , sequential consistency , total store ordering , and the x86 model ) .", "label": "", "metadata": {}, "score": "52.71972"}
{"text": "Table VII below summarizes the results after training the four problems using the hardware simulations of the embodiments described herein , Matlab , and Weka .A conservative clock rate of 100 MHz is chosen for the hardware operation .The hardware time is calculated using the following equation assuming that one pattern is processed every clock cycle .", "label": "", "metadata": {}, "score": "52.75815"}
{"text": "The modularity of the current architecture is intended to allow for seamless interchangeability of the transfer function module .In some embodiments the transfer function module 320 implements the above Equation ( 2 ) .It may also be implemented as a five - piece linear log - sigmoid approximation as shown below by Equations ( 9 ) and ( 10 ) .", "label": "", "metadata": {}, "score": "52.92106"}
{"text": "T. Theocharides , G. Link , N. Vijaykrishnan , and M. J. Irwin , \" Implementing LDPC decoding on network - on - chip , \" in Proceedings of the 18thInternational Conference on VLSI Design : Power Aware Design of VLSI Systems , pp .", "label": "", "metadata": {}, "score": "52.952644"}
{"text": "coupling the plurality of processor cores or special hardware units and the universal register file with an interconnect , .The method according to . claim 5 , wherein the tasks are dispatched from an instruction memory distributed across the plurality of processor cores or special hardware units .", "label": "", "metadata": {}, "score": "52.95523"}
{"text": "We have demonstrated that HLS can produce high quality designs for embedded benchmark kernels : 4X to 126X speedup .In general , parallelization and loop pipelining are two effective optimizations .For the kernels without data dependency ( e.g. , MM ) , significant speedup is achieved via parallelization and resource duplication .", "label": "", "metadata": {}, "score": "53.02876"}
{"text": "The hardware implementation of LDPC decoders can be serial , partially parallel , and fully parallel .Serial LDPC decoder implementation is the simplest in terms of area and routing .It consists of a single check node , a single variable node , and a memory .", "label": "", "metadata": {}, "score": "53.036343"}
{"text": "We have demonstrated that AutoPilot can achieve high speedup over the software implementation : 4X to 126X speedup for embedded benchmark kernels and 3.5X to 67.9X speedup for stereo matching algorithms .It is important to consider the performance difference between HLS and manual hardware implementations .", "label": "", "metadata": {}, "score": "53.161243"}
{"text": "In some embodiments , the selected ITER value 1035 may also or alternatively be directly output by the system 1000 for use in designing the scalable network 700 .At step 640 , the hardware configuration module 1030 determines a hardware configuration 1040 based on the degree of parallelism or ITER value 1035 selected .", "label": "", "metadata": {}, "score": "53.182457"}
{"text": "At step 630 , the ITER selection module 1025 selects a degree of parallelism to use for implementing the scalable network 700 based on the hardware resources available and the desired network topology 1005 .The ITER selection module 1025 receives the available hardware resources and desired topology 1005 from the input module 1010 .", "label": "", "metadata": {}, "score": "53.26094"}
{"text": "We also offer several guidelines for hardware - friendly software design .For popular embedded benchmark kernels , the designs produced by HLS achieve 4X to 126X speedup over the software version .The stereo matching algorithms achieve between 3.5X and 67.9X speedup over software ( but still less than manual RTL design ) with a fivefold reduction in design effort versus manual RTL design .", "label": "", "metadata": {}, "score": "53.31123"}
{"text": "Implementation of the Smith - Waterman Algorithm on FPGA .In this section , we will present the design of the Smith - Waterman algorithm implementation on FPGA .Figure 6 presents a linear systolic array for the implementation of a general purpose pairwise sequence alignment algorithm based on the dynamic programming algorithms presented in Section 2.1 above .", "label": "", "metadata": {}, "score": "53.368378"}
{"text": "Indeed , factoring the speed - up gains , GPUs can be much more energy efficient than GPPs , as shown in this study .It is important to note at this stage that the above results are very sensitive to the technology used and level of effort spent on the implementation .", "label": "", "metadata": {}, "score": "53.413067"}
{"text": "All data transfer between the host processor and FPGA chip on the HP ProLiant server pass through the Hyper - Transport interface with a bandwidth of 3.2 GB / s .Each slice has two 4-input look - up tables , which can be configured as 16 \u00d7 1 RAM , and two flip - flops in addition to some dedicated logic for fast addition and multiplication .", "label": "", "metadata": {}, "score": "53.41715"}
{"text": "These low - power process technologies have one drawback : they are slow .Therefore the processing architecture must execute the algorithms in a small number of clock cycles , as high clock - frequencies can not be used due to long gate - delays .", "label": "", "metadata": {}, "score": "53.440742"}
{"text": "In addition , the slowdown is exacerbated by several factors including reduced efficiency of for loops versus memset / memcpy calls , limited pipeline and parallelism , inefficient datapath width , and the difference between the CPU clock period and the achievable FPGA clock period .", "label": "", "metadata": {}, "score": "53.458183"}
{"text": "Instead , they access a 256 KB local store ( LS ) memory , which holds both instructions and data .The programmer should keep all the codes and data within the size of LS and manage its contents by transferring data between off - chip memory and LS via mailboxes or direct memory access ( DMA ) .", "label": "", "metadata": {}, "score": "53.54116"}
{"text": "B. Level 2 : Resource and Performance Estimation .Referring now to .FIG .19 there is shown a flowchart diagram of an example method 900 for designing a hardware configuration for implementing a scalable artificial neural network in accordance with embodiments described herein .", "label": "", "metadata": {}, "score": "53.589207"}
{"text": "For the purpose of our FPGA - based implementation of the Smith - Waterman algorithm , we targeted an HP ProLiant DL145 server machine [ 7 ] which has an AMD 64bit processor and a Celoxica RCHTX FPGA board [ 8 ] .", "label": "", "metadata": {}, "score": "53.63202"}
{"text": "x . )f .x . )f .x . )Results .Scalability and Variable Degree of Parallelism .As an illustrative example , test results of an entire architecture coded in VHDL using an example hardware device Xilinx ISE 8.2 and tested under ModelSim 6.1 are provided .", "label": "", "metadata": {}, "score": "53.63409"}
{"text": "A more comprehensive introduction to high - level parallel programming can be found in one of our recent talk .FastFlow architecture is organised in three main tiers : .High - level patterns They are clearly characterised in a specific usage context and are targeted to the parallelisation of sequential ( legacy ) code .", "label": "", "metadata": {}, "score": "53.651146"}
{"text": "Although this ASIC performance has been evaluated only in case of the structured QC - LDPC codes of WiMAX , the true benefit from the dual algorithm comes in case of unstructured codes .The usually more performing layered decoding generates data collisions that are transparent to the two - phase decoding process , enabling the presence of superimposed sub - matrices in the code . matrix .", "label": "", "metadata": {}, "score": "53.676792"}
{"text": "These optimizations are intended to reduce resource use , improve resource utilization , expose software features that can be pipelined and/or parallelized , and take full advantage of available FPGA resources .Baseline - Minimum Modifications .For each benchmark , we generate a baseline implementation - the minimum code modifications so that the algorithm can be properly synthesized using AutoPilot .", "label": "", "metadata": {}, "score": "53.715736"}
{"text": "As for the embedded kernels , we observe fewer opportunities to perform these optimizations .Throughout all of the stereo algorithms , full - width integer data types are commonly used for convenience .However , based on operand range analysis , we can reduce the operand bit - width .", "label": "", "metadata": {}, "score": "53.72394"}
{"text": "As detailed in [ 78 ] , the decoder guarantees more than 70 Mb / s for all rates and block sizes of the standard , with an area of 4.72 mm 2 in 130 nm CMOS technology .Bandwidth and Power Reduction Methods .", "label": "", "metadata": {}, "score": "53.82614"}
{"text": "BFAS required longer than the others , as it was the first stereo matching algorithm implemented and some time was spent on learning the stereo matching problem .The manual stereo matching design presented in [ 3 ] required 4 - 5 months of design effort for an experienced hardware designer to implement the design , plus additional time for a team to design the algorithm .", "label": "", "metadata": {}, "score": "53.988403"}
{"text": "This certainly limits the speedup we achieve .Fortunately , for stereo matching , we can partition the image into sub - images that can independently compute disparity and depth information .The image partition allows us to process multiple sub - images in parallel .", "label": "", "metadata": {}, "score": "54.004463"}
{"text": "Techniques employed for stereo matching algorithms include global energy minimization , filtering , and cost aggregation , which are used throughout image and video processing applications .In particular , these techniques are also employed for image de - noising , image retrieval , feature matching , and face recognition .", "label": "", "metadata": {}, "score": "54.017555"}
{"text": "7,218,616 , which is incorporated herein by reference , to provide the necessary bandwidth for many applications .FIG .2 is a diagram of an exemplary control processor microarchitecture for use in a hyperprocessor according to one embodiment of the present invention .", "label": "", "metadata": {}, "score": "54.02809"}
{"text": "The dependency of each cell is shown in Figure 2 .Here , each cell on the diagonal of the alignment matrix is independent of each other , which allows for a systolic architecture to be used in hardware in order to exploit this parallelism and hence speed up the algorithm execution .", "label": "", "metadata": {}, "score": "54.088436"}
{"text": "FIG .1 is a simplified diagram of the macro - and micro - architecture for a hyperprocessor according to one embodiment of the present invention .Hyperprocessor 100 has a macro - architecture 101 comprising a control processor 102 and a task dispatcher 103 , one or more special purpose processing units ( SPPUs ) 104 and a universal register file ( URF ) 105 .", "label": "", "metadata": {}, "score": "54.184074"}
{"text": "Its high degree of flexibility is exploited to guarantee support over a variety of different codes .The inter - CN communication required by the VSS approach is handled by the CN shuffle network .Its function is to cyclically shift the submatrix rows assigned to each CNU : this means that while each CNU will be physically connected to the same VNU for the whole decoding , the row of the . in 180 nm CMOS technology : the area occupation is relatively small w.r.t . the very high degree of parallelism thanks to the nonuniform 4-bit quantization scheme adopted .", "label": "", "metadata": {}, "score": "54.187874"}
{"text": "Thus , compared to manual design , HLS achieves a fivefold reduction in design effort .Software Constraints .As discussed earlier , typical software constraints of HLS tools require statically declared memory , which also precludes the use of many standard libraries such as STL or OpenCV .", "label": "", "metadata": {}, "score": "54.208904"}
{"text": "The error data is generally an error gradient calculated using output 260 ( generated by the scalable network 700 ) and a target 255 ( the intended or desired output ) .Further , the scalable ANN architecture 700 has a parallelization system 705 configured to provide a predetermined degree of parallelization to each of the input layer 250 , at least one hidden layer 205 , output layer 210 and the back - propagation system 705 .", "label": "", "metadata": {}, "score": "54.245583"}
{"text": "Note that this seems logically identical to a partial partitioning of the data array and partial unrolling of the computation inner loop ; however , this method more clearly signifies functional independence to expose the parallelism opportunity to AutoPilot .Figure 5 : Code Example 3-array partition and complete loop unroll to expose functional parallelism .", "label": "", "metadata": {}, "score": "54.247517"}
{"text": "AES , TDES , and SHA ) available for array stream optimizations , significant speedup is achieved via fine grained pipelining .The benchmarked kernels are widely used in various applications , which indicate that HLS is suitable for a wide range of applications .", "label": "", "metadata": {}, "score": "54.378616"}
{"text": "The chosen level of parallelism to be implemented will generally depend on the constraints imposed by the ANN topology and algorithm to be implemented and the hardware device platform .The embodiments described herein are intended to provide an architecture , systems and methods for implementing different levels of parallelization , such as variable neuron parallelism , variable layer parallelism and variable synapse parallelization .", "label": "", "metadata": {}, "score": "54.39931"}
{"text": "In the case of parallel_for this network is a parametric master - worker with active or passive ( in memory ) task scheduler ( more details in the PDP2014 paper ) .As in OpenMP , parallel_for comes in many variants ( see reference manual ) .", "label": "", "metadata": {}, "score": "54.415302"}
{"text": "Video coding is usually the most power - hungry application a mobile processor has to run .Therefore , minimizing the maximum power consumption figure of a chip often concentrates on finding the most power - efficient way to implement video processing algorithms .", "label": "", "metadata": {}, "score": "54.428024"}
{"text": "Another consequence of the folded architecture is that each PE should now hold .substitution matrix columns ( or look - up tables ) instead of just one .In order to load the initial values of the look - up tables used by the PEs , a serial configuration chain is used , as illustrated in Figure 8 .", "label": "", "metadata": {}, "score": "54.485283"}
{"text": "242 - 254 , 2009 .View at Google Scholar .C. Lattner and V. Adve , \" LLVM : a compilation framework for lifelong program analysis & transformation , \" in Proceedings of the International Symposium on Code Generation and Optimization , pp .", "label": "", "metadata": {}, "score": "54.58797"}
{"text": "It reads input database sequences from disk , transmits different database sequences to different SPEs , and invokes SPEs to perform pairwise sequence alignment using the Smith - Waterman algorithm on independent sequences as illustrated in Figure 11 .Figure 11 : The parallel code flow of Smith - Waterman algorithm on Cell BE .", "label": "", "metadata": {}, "score": "54.593445"}
{"text": "Figure 4 : Code example 2-loop unroll and expression balancing for fine - grained parallelism .For this step , the best benefit is available when computation loops use static loop bounds - a static loop bound allows AutoPilot to perform complete unrolling on the inner loop to increase pipeline efficiency , or partially unroll by a known factor of the upper bound .", "label": "", "metadata": {}, "score": "54.594955"}
{"text": "FPGAs are an attractive platform for applications with high computation demand and low energy consumption requirements .However , design effort for FPGA implementations remains high - often an order of magnitude larger than design effort using high - level languages .", "label": "", "metadata": {}, "score": "54.612427"}
{"text": "( iv ) Use array_map to reduce storage by combining arrays .( v ) Use complete array partitioning to convert arrays to scalars .( vi ) Structure and parameterize likely parallelization locations to simplify parallelism search space .( vii )", "label": "", "metadata": {}, "score": "54.64039"}
{"text": "Thanks to the underlying shared memory architecture , messages flowing into these channels may carry both values and pointers to data structures .The running state happens when all threads are logically able to run ( i.e. they are ready or running at the O.S. level ) .", "label": "", "metadata": {}, "score": "54.645676"}
{"text": "Thus , we must partition the image into overlapping windows so that the computation result is correct .In addition , we also perform function merging , interchange nested loops to improve parallelism opportunity , and share internal memory buffers to reduce resource use if it is possible .", "label": "", "metadata": {}, "score": "54.70373"}
{"text": "Task Parallelism is explicit in the algorithm and consists of running the same or different code on different executors ( cores , processors , machines , etc . ) .Different flows - of - control ( threads , processes , etc . ) may communicate with one another as they work .", "label": "", "metadata": {}, "score": "54.74518"}
{"text": "As explained above , at step 950 , network performance estimates are calculated .Network performance is generally estimated as a function of network topology , clock speed and the ITER value .However , additional hardware specifications can also be considered such as , for example , power consumption .", "label": "", "metadata": {}, "score": "54.781853"}
{"text": "Observe that this stack of layers is purely conceptual .As we shall see , many of these stacks are statically compiled and optimised in a cross - layer fashion into the binary code by way of generative programming techniques , such as inline C++ templates .", "label": "", "metadata": {}, "score": "54.78708"}
{"text": "A major issue in using an MLP - BP network is the difficulty of determining a clear methodology in setting up the initial topology and parameters .Topology has a significant impact on the network 's computational ability to learn the target function and to generalize from training patterns to new patterns .", "label": "", "metadata": {}, "score": "54.850357"}
{"text": "The power measurement results are shown in Table 8 .Table 8 : Power consumption of the Smith - Waterman algorithm implementation on all four technologies .We use the dynamic power figures for the accelerated implementations , that is , the FPGA , GPU , and Cell BE - based implementations , as nearly all of the processing is done on the accelerator , with the host only sending query data and collecting results from the accelerator .", "label": "", "metadata": {}, "score": "54.988266"}
{"text": "On the other hand , if the network has too many free parameters , then a large data set is needed to provide adequate training .In this case , the possibility of over - fit is higher , which jeopardizes generalization as well .", "label": "", "metadata": {}, "score": "54.99529"}
{"text": "Programmable architectures ( DSP and RISC ) mainly differ in the amount of functional unit level parallelism they offer , and both lack module level parallelism , unless an awkward multi - core solution is used .The clock - frequency , and power consumption , required to execute the same video coding algorithms on different platforms varies according to the level of parallelism the architecture implements .", "label": "", "metadata": {}, "score": "55.033035"}
{"text": "M. Lin , I. Lebedev , and J. Wawrzynek , \" OpenRCL : low - power high - performance computing with reconfigurable devices , \" Proceedings of the International Conference on Field Programmable Logic and Applications , pp .458 - 463 , 2010 .", "label": "", "metadata": {}, "score": "55.036797"}
{"text": "As used herein , the degree of parallelism generally relates to the number of clock cycles needed to issue an entire input vector ( pattern ) through one stage ( or layer ) of the network .Parallelism degree of one represents a fully parallel hardware configuration where each hardware stage is issued the entire input vector in one clock cycle .", "label": "", "metadata": {}, "score": "55.040848"}
{"text": "For the SO algorithm , this conversion is relatively simple : disparity computation is dependent within one row of pixels but independent between rows .However , the CSBP , BFAS , and CLM algorithms use windowed computation and a support window that spans both rows and columns of the image .", "label": "", "metadata": {}, "score": "55.07175"}
{"text": "One common Artificial Neural Network ( ANNs ) format consists of multi - layer perceptrons trained using the error back - propagation algorithm ( MLP - BP ) .An MLP - BP network can be used in a wide variety of applications .", "label": "", "metadata": {}, "score": "55.129192"}
{"text": "CMOS technology process ( Tech ) , area occupation ( A ) , normalized area ( A norm ) @130 nm , code type ( C.T ) , flexibility ( Flex . ) design time ( D.T ) , run time ( R.T ) , maximum throughput ( T.P ) , maximum iterations ( It . ) , number of datapaths ( Dp ) , operating frequency .", "label": "", "metadata": {}, "score": "55.13268"}
{"text": "Section 5 presents the experiments and results , and finally Section 6 presents our observations and insights on the productivity , usability , and software constraints to use HLS .AutoPilot High Level Synthesis .AutoPilot supports a subset of C / C++ ; the main unsupported features are dynamic memory allocation and arbitrary indirection ( pointers that are not static arrays ) .", "label": "", "metadata": {}, "score": "55.14339"}
{"text": "The offset Min - Sum decoding algorithm is employed : different sizes of memories are able to comply with DVB - S2 , 802.11n , and 802.16e standards .At run time , the standard serial node architecture enables intrastandard flexibility .", "label": "", "metadata": {}, "score": "55.16489"}
{"text": "This allows us to easily explore various optimizations at high level .Now , we evaluate HLS in terms of the productivity , software constraints , usability , and performance of the tools in order to reach the performance we have demonstrated .", "label": "", "metadata": {}, "score": "55.214806"}
{"text": "Introduction .Since it was first announced in 1965 , Moore 's law has stood up the test of time , providing exponential increases in computing power for science and engineering problems over time .However , while this law was largely followed through increases in transistor integration levels and clock frequencies , this is no longer possible as power consumption and heat dissipation are becoming major hurdles in the face of further clock frequency increases , the so - called frequency or power wall problem .", "label": "", "metadata": {}, "score": "55.355965"}
{"text": "Finally , to enable a powerful AutoPilot optimization - array streaming ( Section 4.3 ) , we change parameters passed in function calls from arrays of data to pointers .For the stereo matching algorithms , the most important code restructuring task is to partition the image into subimages that can independently compute disparity and depth information .", "label": "", "metadata": {}, "score": "55.371887"}
{"text": "Since the FastFlow run - time is implemented via non - blocking threads , they will , if not frozen , fully load the cores in which they are placed , no matter whether they are actually processing something or not .", "label": "", "metadata": {}, "score": "55.37857"}
{"text": "View at Scopus .R. M. Tanner , D. Sridhara , A. Sridharan , T. E. Fuja , and D. Costello , \" LDPC block and convolutional codes based on circulant matrices , \" IEEE Transactions on Information Theory , vol .", "label": "", "metadata": {}, "score": "55.452232"}
{"text": "On the NVIDIA GeForce 8800GTX GPU , each SM can have 768 parallel threads running at the same time .Hence , we split this number into batches of threads or blocks , where each block computes one alignment matrix .For example , we can split the overall number of threads into 8 blocks of 96 threads , with 10 registers allocated to each thread and each block could use almost 2 KB of shared memory .", "label": "", "metadata": {}, "score": "55.46575"}
{"text": "( iv ) Coding style for hardware - friendly software design .These limitations motivate us to investigate the abilities , limitations and techniques to use AutoPilot [ 9 ] , one of the state of the art HLS tools .In this paper , we evaluate the achievable speedup over software design , the performance gap compared to manual design , coding constraints , required code optimizations , and development time to convert and optimize software for HLS .", "label": "", "metadata": {}, "score": "55.512775"}
{"text": "SUMMARY .The provision of a parallelization subsystem allows for the use of a less parallel configuration if necessary to , for example , match with hardware resources available or to provide adequate performance without increasing hardware resource ( and therefore cost ) requirements .", "label": "", "metadata": {}, "score": "55.51876"}
{"text": "One processing module for each sub - operation exists , and instructions enter each module in sequence .For example , if each sub - operation of any instruction takes 1 second to execute , and each instruction has four sub - operations , a non - pipelined processor will execute 3 full instructions in 12 seconds .", "label": "", "metadata": {}, "score": "55.536476"}
{"text": "R. Gallager , \" Low - density parity - check codes , \" IEEE Transactions on Information Theory , vol . 8 , no . 1 , pp .21 - 28 , 1962 .View at Google Scholar .G. Masera , F. Quaglio , and F. Vacca , \" Finite precision implementation of LDPC decoders , \" IEE Proceedings on Communications , vol .", "label": "", "metadata": {}, "score": "55.59015"}
{"text": "All node operations ( CNs and VNs ) are directly realized in hardware PEs and connected through dedicated links .This results in huge connection complexity that in extreme cases dominates the total decoder area and results in severe layout congestion : maximum throughput can be , however , theoretically reached .", "label": "", "metadata": {}, "score": "55.606945"}
{"text": "In order to more clearly illustrate the architecture , systems and methods of the present application , an exemplary ANN network architecture implementation will be described in detail .The example network will be a MLP - BP ANN configured for and implemented on a hardware device , such as a field programmable gate array .", "label": "", "metadata": {}, "score": "55.662632"}
{"text": "A universal register file 105 holds data shared between tasks running on the processor 104 , and serves as the primary means of communication and synchronization .Parallel processing is bandwidth intensive , resulting in a communications bottleneck .Existing network processors employ communications based on variants of the shared bus or the crossbar switch .", "label": "", "metadata": {}, "score": "55.72802"}
{"text": "The DSP solution 's figures are averages of figures published by leading DSP core vendors .This chart clearly demonstrates the well - known performance advantage that algorithm - specific hardwired architectures have over programmable solutions in any application .The drawback is naturally the lack of flexibility .", "label": "", "metadata": {}, "score": "55.7612"}
{"text": "Lang .Syst . , 5(2):190 - 222 , 1983 .[ HK97 ] .Higham , J. Kawash .Critical sections and producer / consumer queues in weak memory systems .In : Proc of the Intl .Symposium on Parallel Architectures , Algorithms and Networks ( ISPAN ) , pages 56 - 63 , 1997 .", "label": "", "metadata": {}, "score": "55.799408"}
{"text": "To get an idea of maximum performance obtainable by current FPGA offerings , a selection of Xilinx FPGA devices is taken and information about the number of multipliers ( MULT ) and maximum frequency of operation ( or clock rate ) is given in Table III .", "label": "", "metadata": {}, "score": "55.89324"}
{"text": "The decoding process consists of D iterations : during iteration ., these are subtracted from the message incoming from RAM I , to generate the VN - CN message .The updated extrinsic generated by PE is added to the corresponding input coming from the FIFO , storing the resulting .", "label": "", "metadata": {}, "score": "55.91356"}
{"text": "4thInternational Workshop on Field - Programmable Logic and Applications , pp .421 - 431 , Springer - Verlag , Prague , Czech Republic , 1994 .User Tools .Site Tools .Fastflow architecture .Fastflow is conceptually designed as a stack of layers that progressively abstract out the shared memory , message - passing and SIMT programming models up to the definition of useful programming abstractions and parallel patterns .", "label": "", "metadata": {}, "score": "55.9692"}
{"text": "In [ 23 ] , a rate-8/9 LDPC decoder with 2.1 Gbps throughput has been reported for magnetic recording .The decoder utilizes four block lengths with maximum consisting of 36864 bits .The varied nature of applications makes the selection of a suitable hardware platform an important choice .", "label": "", "metadata": {}, "score": "55.98162"}
{"text": "Building on these insights , the Ctherm framework is proposed for the thermal - aware design of multiprocessor systems - on - chip ( MPSoC ) .Ctherm enables the concurrent evaluation of thermal and functional performance of MPSoCs using automatically generated fine - grained area , latency and energy models for system components , and facilitates the exploration of thermal behaviour early in the system design flow .", "label": "", "metadata": {}, "score": "56.007385"}
{"text": "TDMP / TPMP ) , code type ( C.T ) , block length .Parallel PE .Realizing high throughput decoders ( supporting data rates up to few hundred Mb / s ) either asks for massive parallelism or high clock frequency , resulting in significant area and power overhead .", "label": "", "metadata": {}, "score": "56.032127"}
{"text": "Further to this , Chapter 2 presents the Pronto system , which enables efficient data transfers in message - passing multiprocessors by minimizing the role of the processing element in the management of transfers .Pronto effectively decreases the overheads incurred in setting up and managing data transfers , thereby yielding shorter communication latencies .", "label": "", "metadata": {}, "score": "56.112118"}
{"text": "This paper showed the design and parallel implementation of the Smith - Waterman algorithm on three different technologies : FPGA , GPU , and IBM Cell BE and compared the results with a standard sequential GPP implementation .Comparison criteria included speed , development time , overall cost , and energy consumption .", "label": "", "metadata": {}, "score": "56.15653"}
{"text": "High level languages such as C have been shown as an effective means for capturing FPGA circuits when the C description is written specifically for HLS and hardware ( e.g. , C implementation is derived from manual FPGA implementation ) [ 24 ] .", "label": "", "metadata": {}, "score": "56.1955"}
{"text": "\" If the total amount of data exceeds the data allocation , it may be loaded down as \" tiles .\" MCF contains plug - in and tile channel constructs to facilitate this as required .The tradeoff here is in increased code complexity .", "label": "", "metadata": {}, "score": "56.220436"}
{"text": "The task dispatching mechanism operates to get as close as possible to the highest possible throughput .The implementation of task dispatcher 103 will differ for different applications .The hyperprocessor model allows programming of a highly concurrent machine as one entity , analogous to programming a single central processing unit ( CPU ) .", "label": "", "metadata": {}, "score": "56.258423"}
{"text": "Finally , for the parallelization step , algorithms with larger resource use have relatively little flexibility to employ resource duplication - BFAS can duplicate 4 disparity computation pipelines ; CSBP can also use 4 disparity pipelines .In contrast , the SO algorithm is significantly simpler - it can allow 20 parallel pipelines with occlusion and 34 without .", "label": "", "metadata": {}, "score": "56.27085"}
{"text": "For example , real - time data mining of customers ' databases that are continuously updated is a growing area with significant commercial interest .Moreover , since ANNs are inherently parallel architectures , there have been some efforts to explore real - time parallel computing architecture implementations .", "label": "", "metadata": {}, "score": "56.27865"}
{"text": "Through evaluation of these kernels , we test the suitability of HLS on a wide range of applications as these kernels are widely used for various applications .However , these kernels are relatively small - real applications will contain multiple computation kernels that communicate , and more complex coding styles and data structures .", "label": "", "metadata": {}, "score": "56.284615"}
{"text": "However , AutoPilot is conservative in applying these optimizations to allow the user flexibility in optimizing the design for area , clock speed , throughput , or some combination of them .All of AutoPilot 's optimizations are available as # pragma annotations and synthesis script directives .", "label": "", "metadata": {}, "score": "56.369095"}
{"text": "These two networks are implemented in [ 61 ] with .BeN , the one at the input of the extrinsic values memory being transparent in LDPC mode .Not every supported standard require all the 12 datapaths to be active : the chosen parallelism is the minimum necessary for throughput compliance , and the same can be said for the working frequency .", "label": "", "metadata": {}, "score": "56.371178"}
{"text": "Following the depth map computation , we can optionally refine the depth map quality in a postprocessing step that uses an adaptive support function .In this aggregation step , each pixel 's contribution to the aggregated choice is scaled based on the distance ( within the support window ) from the center of the window , and color - space distance as shown in Figure 2 .", "label": "", "metadata": {}, "score": "56.39624"}
{"text": "We observe that TDES , AES , and SHA achieve significantly more speedup than the other kernels .Thanks to the powerful array stream optimization applied at the Reduced Bitwidth & BRAM step , we are able to do fine - grained loop and function pipelining in the loop optimization step ( directive ) .", "label": "", "metadata": {}, "score": "56.39811"}
{"text": "The set of patterns provided by FastFlow could be further extended by building new C++ templates .While many of the programming frameworks for multi - core offer Data and Task Parallel skeletons , only few of them offer Stream Parallel skeletons ( such as TBB 's pipeline ) .", "label": "", "metadata": {}, "score": "56.451687"}
{"text": "This thesis presents the design and implementation of a Chip - Multiprocessor ( CMP ) targeted at streaming applications(e.g .MPEG , MP3 ) .Streaming applications are applications which can be split into several distinct stages working on data elements in a pipelined fashion .", "label": "", "metadata": {}, "score": "56.4812"}
{"text": "Since the TPMP has been selected , the NoC must handle the communication between VNs and CNs .The NoC design , however , is completely detached from code and decoding parameters , effectively allowing usage for any LDPC code .The router embeds a modified shortest path routing algorithm that can be executed in 1 clock cycle , together with deadlock - free and buffer - reducing arbitration policies and is connected to its PE via the network interface .", "label": "", "metadata": {}, "score": "56.499336"}
{"text": "The offloading feature is concerned with abstracting over auxiliary hardware or software accelerators ( e.g. GPGPUs or set - of - cores ) .Offloading allows the model to be heterogeneous over the hardware in that code that is to be executed on a CPU which makes use of this layer may be partially offloaded onto accelerators .", "label": "", "metadata": {}, "score": "56.525772"}
{"text": "Application tasks are dynamically scheduled by a hardware scheduler taking the consumer - producer locality into ac- count , thereby minimizing the communication overhead .The array is evaluated in terms of performance , scalability and predictability as a function of varied input stream sizes , multiple pipelines , number of pipeline stages and traffic volume .", "label": "", "metadata": {}, "score": "56.659878"}
{"text": "The microarchitecture 200 is simple , handling data dependencies by a combination of register renaming ( through K - tables and a scheduling mechanims ) and by tagging the registers to indicate whether data available in the universal register file 105 is valid or not .", "label": "", "metadata": {}, "score": "56.730812"}
{"text": "3 illustrates an example diagram of a network having a degree of parallelism of one ; .FIG .4 illustrates an example diagram of a network having a degree of parallelism greater than one ; .FIG .5 illustrates an example graph showing the effects of variable degrees of parallelism on network size and slice consumption ; .", "label": "", "metadata": {}, "score": "56.820606"}
{"text": "At step 620 , information relating to hardware resources available 1005 on one or more hardware devices for use in implementing the scalable ANN 700 is provided to the system 1000 and received by input module 1010 .As noted above , the available hardware resources 1005 may describe resources of one or more hardware devices of various types and combinations of types , such as FPGAs , processors , and ASICs .", "label": "", "metadata": {}, "score": "56.835476"}
{"text": "This improved matrix reordering technique allowing overlapped operation of CNs and VNs and results in 68.75 % reduction in decoding latency compared to nonoverlapped approach .A reconfigurable address generation unit and improved early stopping criterion help to realize a low - power flexible decoder which supports all the 19 block lengths ( 576 - 2304 ) of WiMAX .", "label": "", "metadata": {}, "score": "56.836243"}
{"text": "A.4 targeting a Xilinx Virtex-6 LX240T. Then , if the AutoPilot - produced RTL can fit in the FPGA , we synthesize the RTL using Xilinx ISE 12.1 .Area and clock period data are obtained from ISE after placement and routing reports .", "label": "", "metadata": {}, "score": "56.95241"}
{"text": "VLSI implementation is efficiently tackled in less - than - worst case thanks to VOS [ 49 ] and RPR [ 50 ] techniques , saving area and power consumption .ASIP Implementations .Future mobile and wireless communication standards will require support for seamless service and heterogeneous interoperability : convolutional , turbo , and LDPC codes are established channel coding schemes for almost all upcoming wireless standards .", "label": "", "metadata": {}, "score": "56.97417"}
{"text": "In addition to serial check node architectures , the state - of - the - art for flexible LDPC decoders also reports some solutions utilizing parallel check nodes .The work in [ 37 ] proposes a reconfigurable multimode LDPC decoder for Mobile WiMAX .", "label": "", "metadata": {}, "score": "57.094475"}
{"text": "High - level synthesis ( HLS ) targets this problem : HLS tools synthesize algorithm descriptions written in a high level language ( HLL ) such as C / C++/SystemC. A HLL description can typically be implemented faster and more concisely , reducing design effort and susceptibility to programmer error .", "label": "", "metadata": {}, "score": "57.190582"}
{"text": "Optionally , SO can generate a single depth map , or generate left and right depth maps that can be used with a cross - checking technique to compute pixel occlusion within the depth maps .Cross - Based Local Matching ( CLM ) .", "label": "", "metadata": {}, "score": "57.20948"}
{"text": "Overall complexity and performance of decoder are largely determined by the characteristics of these two functional units .In the next two sections we will discuss them in detail and analyze various design choices aimed at realizing high - performance flexible LDPC decoder .", "label": "", "metadata": {}, "score": "57.22635"}
{"text": "Each SPE has a 256 KB local store memory that is allocated between executable code and data .The executable code section must contain the top - level worker code , the MCF functions , and any additional library functions that are used .", "label": "", "metadata": {}, "score": "57.253616"}
{"text": "The following subsections will present theoretical background on the Smith - Waterman algorithm , followed by an architectural overview of each of the four target hardware platforms .The Smith - Waterman Algorithm for Pairwise Biological Sequence Alignment .Mutation , in particular , manifests itself through three main processes , namely , substitution of residues ( i.e. , a residue A in the sequence is replaced by another residue B ) , insertion of new residues , and deletion of existing residues .", "label": "", "metadata": {}, "score": "57.267586"}
{"text": "From this perspective , switching from message queue to DMA will not improve the performance considerably .Indeed , the average sequence length of the SWISS - PROT database is about 360 , which can be completely packetized into a message queue and transmitted between PPE and SPEs .", "label": "", "metadata": {}, "score": "57.28365"}
{"text": "In addition , when the data is accessed in FIFO order , an array may be specified as streaming , which converts the array to an FIFO or ping - pong buffer , reducing total storage requirements .Table 4 lists the array directives .", "label": "", "metadata": {}, "score": "57.305717"}
{"text": "1976 - 1986 , 2006 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .V. Nagarajan , N. Jayakumar , S. Khatri , and O. Milenkovi\u00e7 , \" High - throughput VLSI implementations of iterative decoders and related code construction problems , \" in Proceedings of the IEEE Global Telecommunications Conference ( GLOBECOM ' 04 ) , vol .", "label": "", "metadata": {}, "score": "57.322685"}
{"text": "Moreover , the resource utilization of this design is static , increasing with the increase of ANN size and topology regardless of the available resources on the hardware device .The resources required for implementing large - scale networks may make this design impractical for current configurable hardware device ( e.g. FPGA ) sizes .", "label": "", "metadata": {}, "score": "57.325737"}
{"text": "( i ) Evaluation of common barriers to HLS compatibility .( ii )An effective HLS optimization process .( iii ) Evaluation of HLS on popular embedded benchmark kernels .( iv )A case study of stereo matching algorithms for HLS suitability .", "label": "", "metadata": {}, "score": "57.329884"}
{"text": "The work in [ 38 ] features a parallel check node based on divided group comparison technique , adaptive code length assignment to improve decoding performance , and early termination scheme .The proposed solution is run time programmable to support arbitrary QC - LDPC codes of variable codes lengths and code rates .", "label": "", "metadata": {}, "score": "57.357147"}
{"text": "116 - 124 , 2010 .View at Google Scholar .G. Gentile , M. Rovini , and L. Fanucci , \" A multi - standard flexible Turbo / LDPC decoder via ASIC design , \" in Proceedings of the 6th International Symposium on Turbo Codes and Iterative Information Processing ( ISTC ' 10 ) , pp .", "label": "", "metadata": {}, "score": "57.385277"}
{"text": "Increasing the traffic volume in the network marginally affects the speedup ( -1.9 % ) .Finally , increasing the traffic volume can cause a high deviation in arrival times between two subsequent data blocks in the pipeline of up to 8 % .", "label": "", "metadata": {}, "score": "57.46735"}
{"text": "As shown , AutoPilot produces high quality designs for all the kernels ; 4X to 126X speedup is achieved .For matrix multiplication , we try two different input sizes , 1024 \u00d7 1024 and 512 \u00d7 512 .For matrix multiplication , additional speedup is achieved at the parallelization step as multiple tiles computation can be run in parallel .", "label": "", "metadata": {}, "score": "57.48405"}
{"text": "As for the stereo matching algorithms , only SO without occlusion can fit in the FPGA after minimum modifications .In addition to area inefficiency , these designs are always slower than the original software , sometimes by an order of magnitude .", "label": "", "metadata": {}, "score": "57.484978"}
{"text": "497 - 510 , 2004 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .T. Vogt and N. Wehn , \" A Reconfigurable application specific instruction set processor for convolutional and turbo decoding in a SDR environment , \" in Proceedings of the Design , Automation and Test in Europe ( DATE ' 08 ) , pp .", "label": "", "metadata": {}, "score": "57.570305"}
{"text": "The full decoder , complete with turbo and LDPC separated PEs , has been synthesized with 90 nm CMOS technology : the decoder is compliant with both turbo and LDPC throughput requirements for all the WiMAX standard codes .Worst - case throughput results overperform the latest similar solutions as [ 39 , 41 , 61 , 84 ] , with a small area occupation and particularly low - power consumption ( 59 mW ) in turbo mode .", "label": "", "metadata": {}, "score": "57.701355"}
{"text": "Figure 7 : Speedup over original software for each kernel .Directive denotes the pipelining and loop optimization step .In summary , AutoPilot offers high - quality designs across a wide range of embedded benchmark kernels .Furthermore , HLS allows us to easily explore various optimizations at high level ( C for AutoPilot ) .", "label": "", "metadata": {}, "score": "57.889412"}
{"text": "Referring now to .FIG .5 , there in shown a graph illustrating variable degrees of parallelism and the corresponding impact on hardware device resources , using FPGAs in this example .The x - axis 170 shows the number of free parameters ( weights ) , which loosely correlates with the computational capacity and topology size of a MLP - BP network .", "label": "", "metadata": {}, "score": "57.92418"}
{"text": "f .x . )f .x . )f .x . )As will be explained further herein , an approximation of the above Equation ( 2 ) may also be used .2 ) Error Back - propagation Computation : At this stage , the weights and biases associated with the neurons are updated according to an error gradient descent vector .", "label": "", "metadata": {}, "score": "57.95272"}
{"text": "The individual SPPU processors 104 may have a superscalar microarchitecture 106 including , for example , an instruction store 107 , a fetch / decode unit 108 , one or more execution units 109 , and a general purpose register ( GPR ) file 110 .", "label": "", "metadata": {}, "score": "57.961636"}
{"text": "C. Pipelined Design .In traditional computer architecture terminology , a pipelined architecture is generally where several instructions are overlapped in execution .In a non - pipelined architecture , each instruction is processed individually , one at a time .Execution of all processor operations associated with this instruction must be completed before the next instruction begins executing .", "label": "", "metadata": {}, "score": "57.966354"}
{"text": "2 ( a ) illustrates an example of node parallelism , .FIG .2 ( b ) illustrates an example of synapse parallelism , and .FIG .2 ( c ) illustrates an example of node and synapse parallelism ; .", "label": "", "metadata": {}, "score": "58.004074"}
{"text": "TDMP results in about 50 % decrease in number of iterations to meet a certain BER , which is equivalent to . increase in throughput and significant memory savings as compared to the standard TPMP schedule .Similar to the TDMP schedule is the vertical shuffle scheduling ( VSS ) [ 18 ] : while TDMP relies on horizontal divisions of the parity check matrix , VSS divides the horizontal layers into subblocks .", "label": "", "metadata": {}, "score": "58.006477"}
{"text": "340 - 347 , September 2011 . F. Quaglio , F. Vacca , C. Castellano , A. Tarable , and G. Masera , \" Interconnection framework for high - throughput , flexible LDPC decoders , \" in Proceedings of the Design , Automation and Test in Europe ( DATE ' 06 ) , p. 6 , March 2006 .", "label": "", "metadata": {}, "score": "58.019264"}
{"text": "In particular , this represents a randomization of the sequence of pattern presentation , which empirically has been shown to improve generalization after training .If one considers the error surface of the gradient descent algorithm , the local randomization of weight updates does not change the overall direction of descent down the error gradient .", "label": "", "metadata": {}, "score": "58.094006"}
{"text": "2776 - 2789 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .C. Condo , M. Martina , and G. Masera , \" A Network - on - Chip - based high throughput turbo / LDPC decoder architecture , \" in Proceedings of the Conference on Design , Automation and Test in Europe ( DATE ' 12 ) , 2012 .", "label": "", "metadata": {}, "score": "58.205902"}
{"text": "In this section , we present the results of our proposed HLS optimization process on both embedded benchmark kernels and various stereo matching algorithms .For each benchmark , we use autocc ( AutoPilot 's C compiler ) and autosim to verify correctness of the modified code .", "label": "", "metadata": {}, "score": "58.357162"}
{"text": "View at Scopus .M. Mansour and N. Shanbhag , \" Memory - efficient turbo decoder architectures for LDPC codes , \" in Proceedings of the IEEE Workshop on Signal Processing Systems ( SIPS ' 02 ) , pp .159 - 164 , October 2002 .", "label": "", "metadata": {}, "score": "58.365425"}
{"text": "However , for stereo matching algorithms , we have to perform some modifications including conversion of dynamic memory to static declarations , conversion of memcpy and memset calls to for loops , and conversion of arbitrary ( run - time changing ) pointers to static pointers to memory locations .", "label": "", "metadata": {}, "score": "58.379486"}
{"text": "6 illustrates an example network implementing full pipelining ; .FIG .7 illustrates a schematic diagram of an architecture for a scalable artificial neural network in accordance with embodiments described herein ; .FIG .8 illustrates a flowchart diagram of a method for designing a hardware configuration for a scalable artificial neural network in accordance with embodiments described herein ; .", "label": "", "metadata": {}, "score": "58.394814"}
{"text": "FIGS .16 ( a ) and 16 ( b ) shown that the effect of varying parallelism is fairly linear with respect to resources consumed - doubling the number of cycles per pattern halves the number of slices and multipliers occupied by the network .", "label": "", "metadata": {}, "score": "58.429108"}
{"text": "In general , the first two terms on the right in the above equation relate to system level issues , while the remaining three relate to processor issues .The first term relates to the program being executed , and the tasks that may be identified for partitioning of the application according to some desired requirements such as time dependence , resource dependence , or any other logistical requirement .", "label": "", "metadata": {}, "score": "58.44975"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . Y. Munekawa , F. Ino , and K. Hagihara , Design and Implementation of the Smith - Waterman Algorithm on the CUDA - Compatible GPU , 2008 . A. Bairoch and R. Apweiler , The SWISS - PROT protein knowledgebase and its supplement TrEMBL , Nucleic Acid Research , Release 56.3 , October 2008 . Y. Song , G. M. Striemer , and A. Akoglu , \" Performance analysis of IBM Cell Broadband Engine on sequence alignment , \" in Proceedings of the NASA / ESA Conference on Adaptive Hardware and Systems ( AHS ' 09 ) , pp .", "label": "", "metadata": {}, "score": "58.560677"}
{"text": "The BFAS algorithm is a new local stereo method developed by a team of our computer vision researchers as a driver algorithm to study HLS capabilities .It consists of an initial estimation using absolute difference between pixel values , multiscale image downsampling [ 41 ] and the fast bilateral filtering method [ 42 ] for initial cost aggregation , and refinement using an adaptive support function .", "label": "", "metadata": {}, "score": "58.637276"}
{"text": "This effectively cancels the viability of pipelining as a strategy to increase performance of MLP - BP .For per epoch training , the following modified Equation ( 7b ) is used and may be herein referred to as the epoch synchronized out of order weight update rule : . w . kj .", "label": "", "metadata": {}, "score": "58.67418"}
{"text": "SUMMARY OF THE INVENTION .The control processor schedules tasks according to control threads for the tasks created during compilation and comprising a hardware context including register files , a program counter and status bits for the respective task .The tasks are dispatched to the processor cores or special hardware units for either parallel or sequential execution .", "label": "", "metadata": {}, "score": "58.709835"}
{"text": "361 - 365 , December 2004 .View at Scopus . H. Zhong , W. Xu , N. Xie , and T. Zhang , \" Area - efficient min - sum decoder design for high - rate quasi - cyclic low - density parity - check codes in magnetic recording , \" IEEE Transactions on Magnetics , vol .", "label": "", "metadata": {}, "score": "58.723625"}
{"text": "Table IV below shows the actual frequencies of operation determined by Xilinx ISE synthesizer , Post Place and Route and Static Timing respectively .Some embodiments achieve about 75 % of clock rates listed in Table III for both Virtex II and Virtex II Pro . 140 MHz .", "label": "", "metadata": {}, "score": "58.745224"}
{"text": "An LDPC decoder implemented on TMS320C64xx could yield 5.4 Mb / s throughput running at 600 MHz [ 24 ] .This performance is not sufficient to support high data rates defined in new wireless standards .Reconfigurable hardware platforms like FPGAs are widely used due to several reasons .", "label": "", "metadata": {}, "score": "58.757122"}
{"text": "The decoder exploits the TDMP VSS technique with a 12-datapath architecture : separate variable - to - check and check - to - variable memory banks are instantiated , one per type for each datapath .Each of these \" macrobanks \" contains 3 \" microbanks , \" each storing 9 values per word .", "label": "", "metadata": {}, "score": "58.7622"}
{"text": "3 ) Multiplier to Weight Ratio .By estimating the number of network weights and multiplier usage , the number of multipliers used per weight ( i.e. the ratio of multipliers to weight ratio ) may also be estimated .The ratio of multipliers used per weight acts as a constraint on the network topology and resource utilization when selecting the ITER value , as the number of weights that can be implemented on the hardware device is limited by the number of the multipliers available for use .", "label": "", "metadata": {}, "score": "58.7827"}
{"text": "We evaluate HLS with AutoPilot using two categories of applications .We first use popular embedded benchmark kernels , which are widely used in various applications .However , these kernels are relatively small in code size and simple in data structure .", "label": "", "metadata": {}, "score": "58.887245"}
{"text": "Computation complexity to measure pixel disparity has multiple scaling factors when we attempt to generate depth maps on successively higher resolution video .For a dense depth map , each pixel must be assigned a disparity , high - definition video requires high frame rate , and increased image resolution also increases disparity range .", "label": "", "metadata": {}, "score": "58.90414"}
{"text": "The proposed ASIP extends the capabilities of previous work FlexiTrep [ 51 ] and is capable to decode convolutional codes , binary / duobinary turbo codes and structured LDPC codes .The proposed ASIP is based on the single - instruction multiple datapath ( SIMD ) paradigm [ 52 ] , that is , a single IP with an internal data parallelism greater than one , and processes whole submatrix of parity check matrix with single instruction .", "label": "", "metadata": {}, "score": "58.950405"}
{"text": "B. Shim , S. R. Sridhara , and N. R. Shanbhag , \" Reliable low - power digital signal processing via reduced precision redundancy , \" IEEE Transactions on Very Large Scale Integration ( VLSI ) Systems , vol .12 , no .", "label": "", "metadata": {}, "score": "58.960564"}
{"text": "Design goals To be able to bring high - definition video to the hands of users , mobile device designers must optimize the power consumption of all components .While the display and wireless transmitter consume a large chunk of the total power , every component of a mobile system must be evaluated for its contribution to the power budget .", "label": "", "metadata": {}, "score": "59.052963"}
{"text": ", whereas the subject sequence is shifted systolically through the array [ 4 ] .Each PE performs one elementary calculation ( see ( 3 ) ) in one clock cycle and populates one column of the alignment matrix in turn ( see Figure 7 ) .", "label": "", "metadata": {}, "score": "59.068016"}
{"text": "The implementation in term of streaming network ( i.e. a network of threads or processes ) of a pattern can be cyclic ( e.g. master - worker , D&C , etc . ) .For this FastFlow uses its own unbound SPSC buffer to avoid deadlocks due to dependency cycles [ ADK12].", "label": "", "metadata": {}, "score": "59.15491"}
{"text": "Programs are divided into many tasks and subtasks .The tasks and subtasks are executed by system components ( SPPUs 104 ) each according to respective capabilities .As used herein , \" tasks \" refer to finite sequences of instructions , as opposed to long - lived communicating sequential processes , and with a bounded variation in execution time .", "label": "", "metadata": {}, "score": "59.15712"}
{"text": "If we use 8 blocks of 64 threads , also 16 registers can be allocated to each thread , but the number of sequence alignments that can be processed at the same time becomes 8 .Rather than adopting the simple method used in [ 17 ] which utilizes the full memory resources for each block , we flexibly allocate resources through setting the number of threads in each block , with no limitation on the overall length of the query sequence .", "label": "", "metadata": {}, "score": "59.18203"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 illustrates an example diagram of a Multi - Layer Perception network containing neurons structured in a plurality of parallel layers ; .FIGS . 2 ( a ) , 2 ( b ) , and 2 ( c ) illustrate examples of three types of hardware parallelism for artificial neural network computations , and in particular .", "label": "", "metadata": {}, "score": "59.20076"}
{"text": "View at Scopus .C. Condo , A parallel LDPC decoder with Network on Chip as underlying architecture , M.S. thesis , Politecnico di Torino , 2010 .C. Condo and G. Masera , \" A flexible NoC - based LDPC code decoder implementation and bandwidth reduction methods , \" in Proceedings of the Conference on Design and Architectures for Signal and Image Processing ( DASIP ' 11 ) , pp . 1 - 8 , November 2011 .", "label": "", "metadata": {}, "score": "59.217365"}
{"text": "We picked stereo matching for 3D image construction , which uses techniques also common for image de - noising , image retrieval , feature matching , and face recognition .In the following , we present the kernels and stereo matching algorithms in details .", "label": "", "metadata": {}, "score": "59.217705"}
{"text": "This shows the FPGA solution to be two orders of magnitude quicker than the GPP solution , with the Cell BE and GPU coming second and third , respectively .The latter two achieve one order of magnitude speed - up compared to GPP .", "label": "", "metadata": {}, "score": "59.223854"}
{"text": "According to the same market research firm , Internet video uploads will grow from 500 K uploads / day in 2007 to 4800 K uploads / day in 2011 .The mobile handset is one of the leading capture platforms for video content .", "label": "", "metadata": {}, "score": "59.234642"}
{"text": "The runtime system throttles concurrency so that power consumption can be reduced and performance can be set at the knee of the scalability curve of each parallel execution phase .We present a dynamic , phase - aware performance prediction model ( DPAPP ) , which combines multivariate regression techniques with runtime analysis of data collected from hardware event counters , to locate optimal operating points of concurrency .", "label": "", "metadata": {}, "score": "59.240795"}
{"text": "H . k . s . )f .j .N .s .w . kj .s . )o .j .s .w . ko .s . )For MLP - BP networks , a typical activation ( or transfer ) function is the log - sigmoid function given by the following equation , as well as the equation of its derivative : . f .", "label": "", "metadata": {}, "score": "59.265778"}
{"text": "Unfortunately , in several computing domains , users are unwilling to sacrifice performance to save power .Futhermore , the opportunities for saving power via other means , such as voltage and frequency scaling , may be limited in heavily optimized applications .", "label": "", "metadata": {}, "score": "59.300644"}
{"text": "They cover most common parallel programming paradigms in data , stream and task parallelism .Notably , FastFlow patterns are C++ class templates and can be extended by end users according to the Object - Oriented methodology .Iterative execution of kernels onto GPGPUs are addressed by a single but very flexible pattern , i.e. stencil - reduce , which also takes care of feeding GPGPUs with data and D2H / H2D synchronisations .", "label": "", "metadata": {}, "score": "59.30432"}
{"text": "Each of these algorithms uses differing underlying techniques to generate depth maps .We do not aim to judge the relative merits of different stereo matching approaches in terms of depth map accuracy .Rather , we discuss algorithm and implementation details that make the algorithms more or less suitable for HLS .", "label": "", "metadata": {}, "score": "59.306576"}
{"text": "We also perform a case study to assess the practical value and possibilities of a highly parallelized H.264 application .The results show that H.264 exhibits sufficient parallelism to efficiently exploit the capabilities of future manycore CMPs .The sustained increase in computational performance demanded by next - generation applications drives the increasing core counts of modern multiprocessor systems .", "label": "", "metadata": {}, "score": "59.31956"}
{"text": "Core Patterns .At its foundations FastFlow implements a ( mid / low - level ) concurrent programming model , which extends C++ language .From the orchestration viewpoint , the process model to be employed is a CSP / Actor hybrid model where processes ( so - called ff_node s ) are named and the data paths between processes are clearly identified .", "label": "", "metadata": {}, "score": "59.321777"}
{"text": "[MS98 ] M. M. Michael and M. L. Scott .Nonblocking algorithms and preemption - safe locking on multiprogrammed shared memory multiprocessors .Journal of Parallel and Distributed Computing , 51(1):1 - 26 , 1998 .[ GMV08 ] J. Giacomoni , T. Moseley , and M. Vachharajani .", "label": "", "metadata": {}, "score": "59.357533"}
{"text": "Still , the programmer can use OpenCL / CUDA directives in the kernel .Distributed .Distributed platforms build on top of TCP / IP and Infiniband / OFED protocols are also supported .FPGA support is planned but not yet fully developed .", "label": "", "metadata": {}, "score": "59.389435"}
{"text": "A complete overview of LDPC decoders , with particular emphasis on flexibility , is drawn .Various classifications are depicted , according to degree of parallelism and implementation choices , focusing on common design choices and elements for flexible LDPC decoders .", "label": "", "metadata": {}, "score": "59.50302"}
{"text": "240 - 252 , January 2007 , the content of which is hereby incorporated by reference .Generally this study relates to the impact of 25 fixed and floating point arithmetic representations on convergence speed , generalization after training , and impact on FPGA resource utilization using several FPGA chips .", "label": "", "metadata": {}, "score": "59.535416"}
{"text": "As will be understood to one of skill in the art , the +1 additional unit reflects a \" bias \" in the input , which is internal to the network and is commonly used in ANN designs .However , some of the ITER values used in the set may also be greater than the number of INPUTs+1 .", "label": "", "metadata": {}, "score": "59.544727"}
{"text": "This is consistent in configurations with degree of parallelism higher than unity .The pHdelta module 830 is responsible for calculating the hidden gradient values .The gradients 865 from the output , or subsequent hidden layer ( in the case of a multilayer network ) , are multiplied together with the weights 860 from each of the subsequent layer 's neurons 215 corresponding to the outputs 820 of the current layer 205 .", "label": "", "metadata": {}, "score": "59.620502"}
{"text": "The gap character \" - \" is introduced to present a character insertion or deletion between sequences .There are four ways to indicate the alignment between two sequence .The most basic pairwise sequence analysis task is to ask whether two sequences are related or not , and by how much .", "label": "", "metadata": {}, "score": "59.63424"}
{"text": "For this reason , they are usually joint to more complex structures .One of the most common implementations among the simplest interconnection structures is the Benes network ( BeN ) .This kind of network is a rearrangeable nonblocking network frequently used as a permutation network .", "label": "", "metadata": {}, "score": "59.635574"}
{"text": "Table 5 : Development times of the Smith - Waterman algorithm implementation on all four technologies .This shows FPGA development time to be one order of magnitude higher than that of Cell BE and GPU , and two orders of magnitude higher than that of GPP .", "label": "", "metadata": {}, "score": "59.63751"}
{"text": "Section 2 provides a brief introduction to LDPC codes and decoding .Section 3 gives an overview of flexible LDPC decoders classifying them on the basis of some important attributes for example , parallelism , implementation platforms , and decoding schedules .", "label": "", "metadata": {}, "score": "59.644203"}
{"text": "FIG .8 .Of course , this hardware configuration may also be output as noted herein to allow use of the hardware configuration in making hardware devices . 1 ) Resource Estimation : .Referring back to step 940 , hardware resource estimate calculations for certain embodiments will be described in further detail .", "label": "", "metadata": {}, "score": "59.700073"}
{"text": "Stereo Matching .Figure 9 shows the speedup over original software for each stereo matching algorithm and optimization step .Figure 8 shows the usage of various resources in combination with speedup for all the optimization steps .As shown , incremental improvement is achieved at each step .", "label": "", "metadata": {}, "score": "59.7744"}
{"text": "The embodiments may enable feed forward computation of an input pattern through the customized network in order to provide network output .The embodiments may also propagate an error gradient determined using the network output and a target through the scalable network .", "label": "", "metadata": {}, "score": "59.782814"}
{"text": "SSEARCH was run on a 3.4 GHz Pentium 4 Prescott processor with 1 GB RAM , running Windows XP Professional .Using the SSEARCH program is perfectly justified for the purpose of this paper since it is a mature piece of software that is widely used by Bioinformaticians in practice .", "label": "", "metadata": {}, "score": "59.82202"}
{"text": "It should be noted that software implementations used IEEE double precision representation and direct calculation of the sigmoid transfer function of Equation 2 was carried out in software .There are a large number of problems or applications in the literature for testing MLP - BP and neural networks in general .", "label": "", "metadata": {}, "score": "59.85765"}
{"text": "4 , pp .888 - 895 , 2012 .View at Google Scholar . E. Yeo , P. Pakzad , B. Nikoli\u0107 , and V. Anantharam , \" High throughput low - density parity - check decoder architectures , \" in Proceedings of the IEEE Global Telecommunicatins Conference ( GLOBECOM ' 01 ) , pp .", "label": "", "metadata": {}, "score": "59.86564"}
{"text": "For a query sequence of length 1023 , 64 threads per block leads to the best performance .Table 2 : Performance comparison for different numbers of threads per block ( 64 , 128 , 256 ) .All query sequences run against the SWISS - PROT database [ 18 ] .", "label": "", "metadata": {}, "score": "59.887505"}
{"text": "The constant space belief propagation algorithm [ 34 ] also generates dense depth maps based on a global energy minimization solution .In original belief propagation [ 35 ] , data cost is computed per pixel and disparity value .Then , each pixel iteratively updates messages with its 4 neighbors based on the smoothness constraint , and the final disparity is estimated as the minimum cost .", "label": "", "metadata": {}, "score": "59.960903"}
{"text": "This language can be used for rapid prototyping of parallel algorithms , and for parallel high - level specification of systems .DFH provides data fields with \" traditional \" array bounds and with sparse bounds , infinite data fields with predicates as bounds , and data fields with cartesian product bounds .", "label": "", "metadata": {}, "score": "59.98803"}
{"text": "Parallelism exploitation patterns ( a.k.a . skeletons ) are usually categorised in three main classes : Task , Data , and Stream Parallelism .Stream Parallelism can be used when there exists a partial or total order in a computation .By processing data elements in order , local state may be maintained in each filter .", "label": "", "metadata": {}, "score": "59.99288"}
{"text": "The number of PEs that could be implemented on an FPGA is limited by the logic resources available on - chip .Clearly , this is not sufficient for many real world sequences where query sequence lengths can be in the thousands .", "label": "", "metadata": {}, "score": "60.010536"}
{"text": "Usability .( i ) Improved loop unrolling / pipelining for complicated loops that require temporary register and/or port duplication .( ii ) Support for port duplication directives to add extra read and/or write ports to BRAM - based storage through directives rather than manual data array duplication .", "label": "", "metadata": {}, "score": "60.03154"}
{"text": "A method of executing a program in an embedded processing system comprising : . scheduling tasks for execution by a plurality of processor cores or special hardware units ; . controlling tasks executed by the plurality of processor cores or special hardware units using a control processor ; . dispatching the tasks to the plurality of processor cores or special hardware units according to scheduling by the control processor ; and .", "label": "", "metadata": {}, "score": "60.092545"}
{"text": "Indeed in the Cell BE implementation , we divided the workload equally among the SPEs and let each SPE run the sequence alignment algorithm on its own data set .If an SPE is assigned to process \" . \" sequences , the program is executed over these one after the other , in a sequential manner .", "label": "", "metadata": {}, "score": "60.092743"}
{"text": "An artificial neural network according to .claim 3 , further comprising one or more neurons in each layer , wherein each neuron comprises : . a weight memory for storing weights associated with the neuron ; . a weighted sum module configured to receive a synchronized input and generate a weighted input sum ; . a transfer function module configured to receive the weighted input sum from the weighted sum module and generate output for the neuron ; . a weight change module configured to receive local gradients and determine changes for the weights associated with the neuron ; and .", "label": "", "metadata": {}, "score": "60.12034"}
{"text": "AutoPilot employs a wide range of standard compiler optimizations such as dead - code elimination , strength reduction , and function inlining .After these code optimizations , synthesis is performed at the function level - producing RTL modules for each function .", "label": "", "metadata": {}, "score": "60.171707"}
{"text": "A different substitution matrix will hence simply mean a different look - up table content .The penalties attributed to a gap can also be stored in the PE .The linear array of Figure 6 can also cater for different matching tasks with few changes .", "label": "", "metadata": {}, "score": "60.201843"}
{"text": "As a rough estimate generally 3 multipliers are required to implement a weight .These estimates constrain the topology to be implemented on a particular hardware device as the number of weights that may be used is limited by the number of multipliers available for use .", "label": "", "metadata": {}, "score": "60.20337"}
{"text": "Field programmable gate array ( FPGA ) devices have long been an attractive option for energy - efficient acceleration of applications with high computation demand .However , hardware development targeting FPGAs remains challenging and time consuming - often requiring hardware design expertise and a register transfer level ( RTL ) algorithm description for efficient implementation .", "label": "", "metadata": {}, "score": "60.21129"}
{"text": "Similarly , TDES , AES , and SHA process streams of data with required sequential dependence between neighbouring elements in the data stream .Thus , it precludes parallelization via duplication of computation pipelines .Fortunately , for these algorithms we can enable the array stream optimization which converts the arrays into FIFOs and then allows efficient fine - grained pipelining of the algorithm computation in the loop optimization step .", "label": "", "metadata": {}, "score": "60.212986"}
{"text": "An artificial neural network according to . claim 1 , further comprising : . a back - propagation subsystem configured to send error data back through the network to adjust weights associated with the output layer and the at least one hidden layer and wherein the parallelization subsystem is further configured to provide a variable degree of parallelization to the back - propagation subsystem .", "label": "", "metadata": {}, "score": "60.218235"}
{"text": "The speed of FPGA implementation was limited by the amount of logic resources on chip as more parallelism could be obtained with more processing elements .Finally , for the Cell - BE , the parallelism was mainly limited by the number of Synergistic Processing Elements ( SPEs ) and the parallelism potential of each SPE .", "label": "", "metadata": {}, "score": "60.252495"}
{"text": "These constraints are more severe in the case of three - dimensional ( 3D ) integrated systems , as a consequence of the complex thermal characteristics exhibited by stacked silicon dies .This dissertation investigates the development of efficient , thermal - aware multiprocessor architectures , and presents methodologies to enable the simultaneous exploration of their thermal and functional behaviour .", "label": "", "metadata": {}, "score": "60.303406"}
{"text": "Support regions are computed independently for the left and right images , and pixels that are in both the left and right support regions are used for cost aggregation .Optimization Process .For all these benchmarks , we perform a five - step optimization process where applicable to convert for HLS compatibility and optimize the hardware implementation .", "label": "", "metadata": {}, "score": "60.312035"}
{"text": "This shows the FPGA platform to be a more economical solution for this particular algorithm despite its relatively high cost , thanks to its much higher performance .The CellBE and GPU came second and third , respectively .We have also measured the power consumed by each implementation ( excluding the host in the case of FPGA , GPU , and Cell BE ) as shown in Table 8 .", "label": "", "metadata": {}, "score": "60.43696"}
{"text": "Local shared memory is allocated automatically if the size of variable required is bigger than the register size .It is not cached and can not be accessed in a coalesced manner like global memory .Texture memory within each SM can be filled with data from the global memory .", "label": "", "metadata": {}, "score": "60.52424"}
{"text": "For the sake of simplicity the following presents the Smith - Waterman algorithm in the case of linear gaps .The extension to the case of affine gaps is straightforward [ 1 ] .The Smith - Waterman ( SW ) algorithm is a widely used pairwise sequence alignment algorithm as it finds the best possible aligned subsegments in a pair of sequences ( the so - called local alignment problem ) .", "label": "", "metadata": {}, "score": "60.598312"}
{"text": "In per - pattern training , patterns are presented to the network one pattern at a time and training follows the above Equations ( 1 ) to ( 6 ) .All processing for each pattern must be completed before the next pattern can be presented for training .", "label": "", "metadata": {}, "score": "60.626427"}
{"text": "Thus , efficient hardware implementation of these kernels could have significant impact on the overall system performance .We choose a subset of applications from MiBench [ 30 ] including three common and representative cryptographic algorithms : AES , TDES , and SHA .", "label": "", "metadata": {}, "score": "60.639874"}
{"text": "Serial PE .As described in Section 2.1 , the LDPC codes specified by majority of standards are based on the so - called structured LDPC codes .Considering a decoder parallelism . , as in state - of - the - art layered decoders , one sub matrix ( equal to P edges ) is processed per clock cycle , with one operation completed by each PE working in a serial fashion .", "label": "", "metadata": {}, "score": "60.64654"}
{"text": "They are typically equipped with self - optimisation capabilities ( e.g. load - balancing , grain auto - tuning , parallelism - degree auto - tuning ) and exhibit limited nesting capability .Examples are : parallel - for , pipeline , stencil - reduce , mdf ( macro - data - flow ) .", "label": "", "metadata": {}, "score": "60.66314"}
{"text": "15 illustrates a further example schematic diagram of the internal structure of a neuron of a network having a variable degree of parallelism in accordance with embodiments described herein ; .FIGS .16 ( a ) and 16 ( b ) illustrate examples graphs showing slice usage and multiplier usage , respectively , considering variable degrees of serialization ; .", "label": "", "metadata": {}, "score": "60.736423"}
{"text": "The published solutions are evaluated at two levels of architectural design : the processing element ( PE ) and the interconnection structure .A qualitative and quantitative analysis of different design choices is carried out , and comparison is provided in terms of achieved flexibility , throughput , decoding efficiency , and area ( power ) consumption .", "label": "", "metadata": {}, "score": "60.751495"}
{"text": "More importantly perhaps these calculations did not account for issues such as technology maturity , backward and forward compatibility , and algorithms ' rate of change , which all play an important role in technology procurement decisions .Unfortunately , these issues are more difficult to quantify and are often subjective and time / location - sensitive .", "label": "", "metadata": {}, "score": "60.80104"}
{"text": "This was empirically found to be more efficient than using vector char4 .Implementation of the Smith - Waterman on IBM Cell BE .Our IBM Cell BE implementation exploits the data parallelism involved in aligning one query sequence with a large database of sequences by assigning different database sequences to the eight SPEs , that is , through multiprocessing .", "label": "", "metadata": {}, "score": "60.851723"}
{"text": "Hardwired Architecture for Video Encoding .Architecture alternatives for mobile video coding The three most common solutions used to implement video coding on mobile chips are hardwired ( HW ) video codecs , video - optimized DSPs , and general - purpose RISC processor cores ( often enhanced with SIMD hardware ) .", "label": "", "metadata": {}, "score": "60.868355"}
{"text": "A so - called phase overlapping algorithm similar to TDMP is proposed which resolves the data dependencies of CNs and VNs of consecutive subiterations and overlaps their operation .The proposed decoder features serial check nodes with Min - Sum algorithm implementation .", "label": "", "metadata": {}, "score": "60.887276"}
{"text": "V-665-V-668 , May 2004 .View at Scopus .T. Zhang and K. Parhi , \" A 54 Mbps ( 3,6)-regular FPGA LDPC decoder , \" in Proceedings of the IEEE Workshop on Signal Processing Systems ( SIPS ' 02 ) , pp .", "label": "", "metadata": {}, "score": "60.958298"}
{"text": "672 - 683 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .X. Y. Shih , C. Z. Zhan , and A. Y. Wu , \" A real - time programmable LDPC decoder chip for arbitrary QC - LDPC parity check matrices , \" in Proceedings of the IEEE Asian Solid - State Circuits Conference ( A - SSCC ' 09 ) , pp .", "label": "", "metadata": {}, "score": "60.96386"}
{"text": "In our stereo matching case study , we examine a variety of stereo matching algorithms , evaluate suitability of the software for AutoPilot compatibility , and convert four suitable software implementations not originally intended for HLS .Our experiments demonstrate that HLS achieves 3.5X to 67.9X speedup with 5X reduction in design effort compared to manual RTL design , where manual RTL design is still faster than the HLS - produced RTL .", "label": "", "metadata": {}, "score": "61.077286"}
{"text": "The control processor 102 is capable of running multiple programs by fetching task - level instructions from multiple contexts , simultaneously or sequentially interleaved .Even though task scheduling in the hyperprocessor 100 is more global than scheduling instructions within microprocessors , many characteristics remain the same .", "label": "", "metadata": {}, "score": "61.21203"}
{"text": "The issue of thermal - aware design for 3D Integrated Circuits ( IC ) using Nagata 's equation - a mathematical representation of the dark silicon problem - is investigated in Chapter 3 .Significantly , the chapter explores the thermal design space of 3D ICs in terms of this equation , and proposes a high - level flow to characterize the specific influence of individual design parameters on thermal behaviour of die stacks .", "label": "", "metadata": {}, "score": "61.277546"}
{"text": "FastFlow run - time is designed to exhibit a nonblocking behaviour , with the possibility to switch to blocking behaviour .Overall , a FastFlow run is a sequence of nonblocking running phases .Among two phases the run - time can switch to a blocking phase by way of a ( original , data - flow ) distributed protocol .", "label": "", "metadata": {}, "score": "61.287987"}
{"text": "According to a leading market research firm , Internet video consumption has increased by nearly 100 % over the past year : from an average of 700 terabytes / day in 2006 , to 1200 terabytes / day in 2007 .They expect video consumption to expand 650 % by 2011 , to 7800 terabytes / day .", "label": "", "metadata": {}, "score": "61.350548"}
{"text": "View at Scopus . F. Kienle , M. Thul , and N. When , \" Implementation issues of scalable LDPC - decoders , \" in Proceedings of the 3rd International Symposium on Turbo Codes and Related Topics , 2003 .D. Seo , A. Ali , W. T. Lim , N. Rafique , and M. Thottethodi , \" Near - optimal worst - case throughput routing for two - dimensional mesh networks , \" in Proceedings of the 32nd Interntional Symposium on Computer Architecture ( ISCA ' 05 ) , pp .", "label": "", "metadata": {}, "score": "61.378685"}
{"text": "This section presents the implementation results of our Smith - Waterman designs on FPGA , GPU , Cell BE , and GPP .Table 3 first presents the execution times of the Smith - Waterman implementation on all four platforms for a number of query sequences against the SWISS - PROT database ( as of August 2008 ) when it contained 392,768 sequences and a total of 141,218,456 characters .", "label": "", "metadata": {}, "score": "61.402657"}
{"text": "The available source includes both published research work [ 32 - 40 ] as well as unpublished stereo matching source code .As stated previously , these codes are developed for stereo matching research , not suitability for HLS .Thus , despite this seeming wealth of available source code , many of the source packages use common programming techniques that are only efficient ( and wise ) to use in software , but unsuitable for HLS support .", "label": "", "metadata": {}, "score": "61.442734"}
{"text": "Indeed , Fastflow is the nth - in - a - row high - level pattern - based high - level parallel programming frameworks we designed in the last fifteen years ( detailed in contributors home pages : MarcoA , Massimo , MarcoD ) .", "label": "", "metadata": {}, "score": "61.443207"}
{"text": "The quasicyclic structure of such codes allows an effective implementation of the layered decoding approach , here exploited with a variable degree of parallelism , and simple interconnection between memories and processing units .The implemented decoding algorithm is the OMS , and it is fixed .", "label": "", "metadata": {}, "score": "61.447052"}
{"text": "49 , no .4 - 5 , pp .589 - 604 , 2005 .View at Google Scholar \u00b7 View at Scopus .C. Ling , K. Benkrid , and T. Hamada , \" A parameterisable and scalable smith - Waterman algorithm implementation on CUDA - compatible GPUs , \" in Proceedings of the IEEE 7th Symposium on Application Specific Processors ( SASP ' 09 ) , pp .", "label": "", "metadata": {}, "score": "61.45182"}
{"text": "In high - performance applications , the universal register file 105 will utilize very fast memory and wide transfers between shared buffers and local caches , while in low - end applications the universal register file 105 may be simply mapped to shared off - chip memory .", "label": "", "metadata": {}, "score": "61.464764"}
{"text": "A N i N h -1 network topology is another example .Ratio .Ratio .N .i . lim .N .i .N .i .N .i .Using these examples , the ratio of multipliers to weights ranges between 2 ( lower limit ) and 3.5 ( upper limit ) .", "label": "", "metadata": {}, "score": "61.482"}
{"text": "A host application written in C++ services user queries and transfers them onto the FPGA board through the Hyper - Transport link .The FPGA configuration accepts a query sequence using an input / output interface based on the DSM library in Handel - C and starts alignment processing against a sequence database held on the FPGA board memory .", "label": "", "metadata": {}, "score": "61.614243"}
{"text": "However , whereas the BFAS algorithm uses a fixed window size and Gaussian filtering for aggregation , CLM uses an adaptive window shape and size to determine the pixels to aggregate .The support region consists of a region of contiguous pixels where the pixel 's luminance value is within an empirically selected delta .", "label": "", "metadata": {}, "score": "61.627983"}
{"text": "The proposed ASIP is able to decode binary turbo codes up to 6144 information bits , duobinary turbo codes and convolutional codes upto 8192 information bits .LDPC decoding capability of block length up to 3456 bits and check node degree up to 28 is sufficient to cover all code rates of WiMAX and WiFi standards .", "label": "", "metadata": {}, "score": "61.66591"}
{"text": "SPMC , MPSC , and MPMC queues can be realized in several different ways , for example using locks , or in a lock - free fashion in order to avoid lock overhead .These operations , however , induce a memory fence , thus a cache invalidation / update , which can seriously impair the performance of parallel programs exhibiting frequent synchronizations ( e.g. for fine - grain parallelism ) .", "label": "", "metadata": {}, "score": "61.740494"}
{"text": "A parallel PE manages all VN - CN messages in parallel and writes back the results simultaneously to all connected VNs .This results in lower update latency and consequently higher throughput .A parallel Min - Sum PE for .is shown in Figure 2(b ) .", "label": "", "metadata": {}, "score": "61.87207"}
{"text": "M. Lynch , H. Patel , A. Abrahamse , A. Rupa Rajendran , and L. Medsker , \" Neural network application in physics \" , In Proceedings of International Joint Conference on Neural Networks , pp .2054- 2058 , Jul. 2001 .", "label": "", "metadata": {}, "score": "61.900284"}
{"text": "Abstract .Flexible channel decoding is getting significance with the increase in number of wireless standards and modes within a standard .A flexible channel decoder is a solution providing interstandard and intrastandard support without change in hardware .However , the design of efficient implementation of flexible low - density parity - check ( LDPC ) code decoders satisfying area , speed , and power constraints is a challenging task and still requires considerable research effort .", "label": "", "metadata": {}, "score": "61.961594"}
{"text": "Additional features and advantages of the invention will be described hereinafter that form the subject of the claims of the invention .Those skilled in the art will appreciate that they may readily use the conception and the specific embodiment disclosed as a basis for modifying or designing other structures for carrying out the same purposes of the present invention .", "label": "", "metadata": {}, "score": "61.96237"}
{"text": "More portable architecture of the implementation ( not relying on nhc ) .Some generalizations of the data fields provided by DFH .Implementation of data field specific optimizations .Parallel implementation .This activity is a continuation of the Data Fields project at KTH , where also the first prototype implementation of Data Field Haskell was developed .", "label": "", "metadata": {}, "score": "61.96475"}
{"text": "The two sets of inputs are presented consecutively one set per clock cycle for a total of 2 clock cycles required for a complete input presentation to the first network layer .After the data is propagated through this layer , the output vector from all of its neurons is returned over 2 clock cycles as well .", "label": "", "metadata": {}, "score": "62.071743"}
{"text": "Representing communication and synchronisation as a channel ensures that synchronisation is tied to communication and allows layers of abstraction at higher levels to compose parallel programs where synchronisation is implicit .At the core patterns level , patterns to build a graph of ff_node s are defined .", "label": "", "metadata": {}, "score": "62.11905"}
{"text": "Various combinations of the two methods have been tried , together with different parallelisms of the 2D torus mesh .Implementation of the ES criterion requires a dedicated processing block with minimal PE modifications , while MS requires a threshold comparison block for each PE and switching to online dynamic routing .", "label": "", "metadata": {}, "score": "62.204773"}
{"text": "Each time a new VN - CN message .denote the maximum row and column weights ( i.e. , CN and VN degrees ) , respectively .A full - mode LDPC decoder for WiMAX must support 6 code rates with weights ranging from 7 to 20 .", "label": "", "metadata": {}, "score": "62.22287"}
{"text": "12 , pp .2966 - 2984 , 2004 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Fanucci , P. Ciao , and G. Colavolpe , \" VLSI design of a fully - parallel high - throughput decoder for turbo gallager codes , \" IEICE Transactions on Fundamentals of Electronics , Communications and Computer Sciences , vol .", "label": "", "metadata": {}, "score": "62.265327"}
{"text": "20 , no . 2 , pp .284 - 287 , 1974 .View at Google Scholar \u00b7 View at Scopus .J. Zhang and M. Fossorier , \" Shuffled belief propagation decoding , \" in Proceedings of the 36th Asilomar Conference on Signals Systems and Computers , vol .", "label": "", "metadata": {}, "score": "62.285435"}
{"text": "While the ES method guarantees an average .energy per frame decoding reduction regardless of the implementation , the MS method 's results change with the size of the NoC. Since stopped messages can lead to additional errors , a performance sacrifice must be accepted : among the solutions presented in [ 79 ] , with 0.3 dB BER loss , a 9-PE NoC is sufficient to support the whole WiMAX standard .", "label": "", "metadata": {}, "score": "62.305527"}
{"text": "As explained above , the calculations of Equations ( 3 ) to ( 4 ) are performed at the layer level by the error back propagation module 305 .That is , the error back propagation module 305 calculates the error terms and local gradients for each neuron in its layer .", "label": "", "metadata": {}, "score": "62.31022"}
{"text": "The error BP computation step compares the network 's 100 overall output 125 to a target ( not shown ) , computes an error gradient , and propagates the error through layers 110 by adjusting the neuron 105 weights to correct for it .", "label": "", "metadata": {}, "score": "62.314972"}
{"text": "This paper explores the pros and cons of reconfigurable computing in the form of FPGAs for high performance efficient computing .Comparison criteria include speed , energy consumption , and purchase and development costs .The study shows that FPGAs largely outperform all other implementation platforms on performance per watt criterion and perform better than all other platforms on performance per dollar criterion , although by a much smaller margin .", "label": "", "metadata": {}, "score": "62.474487"}
{"text": "In [ 79 ] , two methods aimed at reducing power and increasing throughput are studied and implemented .The first one is the iteration early - stopping ( ES ) criterion proposed in [ 80 ] , that allows to stop the decoding when all the information bits of a codeword are correct , regardless of the redundancy bits .", "label": "", "metadata": {}, "score": "62.518356"}
{"text": "Min - Sum ( MS ) algorithm [ 10 ] is a simple approximation of the SP : its easy implementation suffers an 0.2 dB performance loss compared to SP decoding [ 11 ] .Normalized Min - Sum ( NMS ) algorithm [ 12 ] gives better performance than MS by multiplying the MS check node update by a positive constant . subiterations .", "label": "", "metadata": {}, "score": "62.543053"}
{"text": "In contrast , we evaluate AutoPilot using popular embedded benchmark kernels , and real - world stereo matching software .More importantly , we evaluate HLS using software not designed for HLS , and optimize ourselves ( rather than allowing the tool vendor to find the best optimization ) , tracking design effort .", "label": "", "metadata": {}, "score": "62.574894"}
{"text": "26 ] bear similarity to our work .In [ 25 ] , various coding guidelines are introduced to make code more HLS friendly and better performing .In [ 26 ] , CHStone , a suite of benchmarks for HLS , is proposed , and the benchmarks are analysed in terms of source level characteristics , resource utilization , and so forth .", "label": "", "metadata": {}, "score": "62.57601"}
{"text": "No matter how fast other threads can execute the kernel code , they have to wait for a synchronization point of all threads .Obviously , this only occurs when the length of the database subject sequence is longer than the allocated space in shared memory .", "label": "", "metadata": {}, "score": "62.656174"}
{"text": "The ASIC is composed of 12 parallel datapaths able to decode both turbo and LDPC codes through the BCJR algorithm .As most of the SIMD cores , the decoder handles communication by means of shared memories .Memory management can be challenging , especially in case the parallel datapaths are assigned to fractions of the same codeword .", "label": "", "metadata": {}, "score": "62.724525"}
{"text": "Observations and Insights .Through our experiments , we have demonstrated that HLS can achieve significant speedup for both embedded benchmark kernels and complex stereo matching algorithms .Also , because of the dual requirements of high - performance and fast develop cycle , HLS is an attractive platform for acceleration of these applications .", "label": "", "metadata": {}, "score": "62.75084"}
{"text": "FIG .7 but with a customized arrangement of physical neurons ( e.g. perceptrons ) based on the degree of parallelization .In keeping with the architecture of .The hardware configuration may be output in various formats , for example in a hardware description language , which can later be used to configure a specific hardware device such as an FPGA or ASIC .", "label": "", "metadata": {}, "score": "62.79013"}
{"text": "459 - 462 , September 2000 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .T. Brack , M. Alles , T. Lehnigk - Emden et al . , \" Low complexity LDPC code decoders for next generation standards , \" in Proceedings of the Design , Automation and Test in Europe Conference and Exhibition ( DATE ' 07 ) , pp .", "label": "", "metadata": {}, "score": "62.80319"}
{"text": "TABLE V .COMPARISON BETWEEN CURRENT ANN HARDWARE ACCELERATORS AND PROPOSED ARCHITECTURE .Proposed Architecture .Feedforward , ML .BP .Variable .Variable .Degree of .up to 175 GCUPS .Parallelization . dependent .Testing on Benchmark Problems .", "label": "", "metadata": {}, "score": "62.807854"}
{"text": "The system according to . claim 1 , wherein each task comprises a finite sequence of instructions with a bounded variation in execution time .The system according to . claim 1 wherein the task dispatcher transmits tasks to the plurality of processor cores or special hardware units for selectively either parallel or sequential execution by the one or more processor cores or special hardware units .", "label": "", "metadata": {}, "score": "62.833054"}
{"text": "Note that such a topology is not common in practice .Ratio .Ratio .N .o .lim .N .o .N .o .N .o .The lower limit is reached when the situation reverses , with each neuron having a high number of inputs , and the number of neurons kept minimal .", "label": "", "metadata": {}, "score": "62.83682"}
{"text": "An artificial neural network according to .An artificial neural network according to .claim 4 , wherein each neuron further comprises a pipeline buffer in tune with a latency delay .An artificial neural network according to . claim 1 , further comprising a pipeline subsystem to pipeline the artificial neural network .", "label": "", "metadata": {}, "score": "62.873383"}
{"text": "B. Bond , K. Hammil , L. Litchev , and S. Singh , \" FPGA circuit synthesis of accelerator data - parallel programs , \" in Proceedings of the 18thIEEE International Symposium on Field - Programmable Custom Computing Machines , pp .", "label": "", "metadata": {}, "score": "62.93651"}
{"text": "The memory hierarchy in CUDA devices consists of registers , shared memory , global memory , texture memory , and constant memory .Each SP has its own registers ( 1024 ) and operates the same kernel code as other SPs , but with different data sets .", "label": "", "metadata": {}, "score": "62.950165"}
{"text": "Each node is connected to a set of other nodes distributed on the available PEs : different nodes will have different links , resulting in a widely varied PE - to - PE communication pattern .This situation calls for flexible and complex interconnection structures .", "label": "", "metadata": {}, "score": "63.025673"}
{"text": "CSBP primarily uses one large array of data , so there is no gain via the use of array directives , and the data element size was already chosen well for the storage .However , for all of the stereo matching algorithms , the bitwidth optimization also reduced LUT , FF , and DSP use due to reduced size datapath computation units .", "label": "", "metadata": {}, "score": "63.035107"}
{"text": "Rams .N .h .N .i .ITER .N .o .N .h .ITER .Similar resource estimation can also be established on other systems , including , for example , multi - core and heterogeneous systems such as the IBM IBM 's cell broadband engine architecture .", "label": "", "metadata": {}, "score": "63.045216"}
{"text": "Problems with complex weight space generally require higher precision than problems with more simple weight space .None of these issues can be determined before training starts .As such it is critical that the implementation be able to change the arithmetic representation when it is clear than one representation is hindering the ANN from achieving a suitable solution level .", "label": "", "metadata": {}, "score": "63.1326"}
{"text": "FIG .15 ) , where both write ports update the memories with the same weight values to keep both memories up to date .The read ports are then dedicated to reading back these values , one port for feed forward calculations , one port for weight recall during update . 2 ) Hardware Delay : .", "label": "", "metadata": {}, "score": "63.219276"}
{"text": "4 , pp .561 - 570 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .T. Oliver , B. Schmidt , and D. Maskell , \" Hyper customized processors for bio - sequence database scanning on FPGAs , \" in Proceedings of the ACM / SIGDA 13th ACM International Symposium on Field Programmable Gate Arrays ( FPGA ' 05 ) , pp .", "label": "", "metadata": {}, "score": "63.251972"}
{"text": "Using a minimum ratio of 2 multipliers to each weight ( as illustrated above ) , the largest theoretical performance for this example MLP - BP implementation can be obtained on a Virtex 5 SX series FPGA from Xilinx .The FPGA contains 640 multipliers , can operate at 550 MHz , and thus can achieve a maximum of 176 G CUPS .", "label": "", "metadata": {}, "score": "63.30128"}
{"text": "Furthermore , as long as a task 's effects are contained within the universal register file 105 , squashing a task is simple and efficient , allowing for efficient speculative task execution .Communication and synchronization between tasks is primarily accomplished via the universal register file 105 .", "label": "", "metadata": {}, "score": "63.5214"}
{"text": "The address generators generate the address of RAMS ( I , Sa , Sb and E ) , while the permutation RAM generates the control signals for permutation network according to the rotation of identity matrix .Multimode flexibility is achieved by reconfiguring AGs and PRAMs each time a new code needs to be supported .", "label": "", "metadata": {}, "score": "63.54755"}
{"text": "[53 ] has been defined to give a good comparison regardless of different clock frequencies .DE gives the number of decoded bits per clock cycle per iteration , while Dp is the total degree of parallelism , taking into account both the number of PEs and their possible multiple datapaths .", "label": "", "metadata": {}, "score": "63.589077"}
{"text": "( vi ) Directions for future study and enhancements of HLS tools .The rest of this paper is organized as follows .Section 2 discusses the AutoPilot HLS tool and its supported features .Section 3 discusses the embedded benchmarks kernels , the stereo matching problem , and various stereo matching algorithms for HLS .", "label": "", "metadata": {}, "score": "63.64517"}
{"text": "The eight SPEs are the primary computing engines on the Cell processor .Each SPE contains a Synergistic Processing Unit ( SPU ) , a memory flow controller , a memory management unit , a bus interface , and an atomic unit for synchronization mechanisms [ 14 ] .", "label": "", "metadata": {}, "score": "63.68802"}
{"text": "Then , to evaluate the suitability of HLS on real - world applications , we perform a case study of stereo matching , an active area of computer vision research that uses techniques also common for image denoising , image retrieval , feature matching , and face recognition .", "label": "", "metadata": {}, "score": "63.699352"}
{"text": "However , it is not always feasible to apply this optimization as the data has to be written and read in FIFO order .Of all our benchmark applications , we only can apply the array stream optimization for the three cryptographic algorithms , AES , SHA , and TDES .", "label": "", "metadata": {}, "score": "63.710464"}
{"text": "It is important to emphasize that this performance gap is a gap between HLS hardware produced from software not designed for HLS and manually produced RTL .This is not to suggest that HLS - produced hardware can not achieve performance near manual designs , but to point out that the current abilities of HLS can not be easily used in general software not designed for HLS .", "label": "", "metadata": {}, "score": "63.713577"}
{"text": "J. L\u00f6rincz and D. Begu\u0161i\u0107 , \" Physical layer analysis of emerging IEEE 802.11n WLAN standard , \" in Proceedings of the 8th International Conference Advanced Communication Technology ( ICACT ' 06 ) , pp .189 - 194 , February 2006 .", "label": "", "metadata": {}, "score": "63.75505"}
{"text": "The processor 200 has an optimized pipeline ( early branch detection ) and implements hardware multithreading ( two full contexts in hardware ) .The microarchitecture for processor 200 , which may be implemented by any superscalar architecture , is simple , where pipeline stages are denoted by the dashed lines in .", "label": "", "metadata": {}, "score": "63.86487"}
{"text": "117 - 126 , February 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .G. Stitt , F. Vahid , and W. Najjar , \" A code refinement methodology for performance- improved synthesis from C , \" in Proceedings of the International Conference on Computer - Aided Design , pp .", "label": "", "metadata": {}, "score": "63.88395"}
{"text": "MCF adds up to 64 KB depending on the functions that are used .Rounding this up suggests that the worker code would somewhat be greater than half of the available SPE memory ( 128 KB ) .These estimates suggest that each SPE could receive a full code segment and a complete set of protein sequence without the need for further partitioning .", "label": "", "metadata": {}, "score": "63.98989"}
{"text": "However , in other embodiments the chosen arithmetic representation may be a global setting - the same selected arithmetic representation will apply for all parameters . D. Activation Function .In accordance with embodiments described herein , each neuron 215 of the network layers contains a transfer function module 320 .", "label": "", "metadata": {}, "score": "64.00168"}
{"text": "References .R. Durbin , S. Eddy , S. Krogh , and G. Michison , Biological Sequence Analysis : Probabilistic Models for Proteins and Nucleic Acids , Cambridge University Press , 1998 .S. B. Needleman and C. D. Wunsch , \" A general method applicable to the search for similarities in the amino acid sequence of two proteins , \" Journal of Molecular Biology , vol .", "label": "", "metadata": {}, "score": "64.01262"}
{"text": "an output port for outputting the output vector .Description .PRIORITY CLAIM .This application claims the priority of U.S. Provisional Application No .60/869,146 filed on Dec. 8 , 2006 , the entire content of which is hereby incorporated by reference .", "label": "", "metadata": {}, "score": "64.0748"}
{"text": "Nonetheless , we note that the performance per watt figures in Table 11 still show FPGAs to be far superior to the other technologies on energy efficiency criterion .We note finally that the Smith - Waterman algorithm implementation scales extremely well with data sizes and computing resources with the four technologies used ( FPGAs , GPUs , Cell BE , or GPP ) .", "label": "", "metadata": {}, "score": "64.10486"}
{"text": "This shows GPUs to be more economic on performance per $ grounds compared with other technologies , followed closely by GPPs .Such conclusion however is not valid according to the criteria set in this paper , since the GPP and GPU implementations reported in [ 21 , 23 ] , respectively were based on more advanced process technologies , brought to market after Virtex-4 FPGAs .", "label": "", "metadata": {}, "score": "64.13258"}
{"text": "215 - 219 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .C. H. Liu , C. C. Lin , S. W. Yen et al . , \" Design of a multimode QC - LDPC decoder based on shift - routing network , \" IEEE Transactions on Circuits and Systems II : Express Briefs , vol .", "label": "", "metadata": {}, "score": "64.15626"}
{"text": "The network is sized to handle the largest submatrix size of the standard , 96 : when decoding a smaller code , dummy messages are routed as well , with a dedicated flag .Two stages of barrel shifters provide the shift function to real and dummy messages alike , together with a single permutation network : a lookup engine finally selects the useful ones basing its decision on the flag bits , shift size and submatrix size .", "label": "", "metadata": {}, "score": "64.16957"}
{"text": "It measures the disparity between corresponding points in an object between two or more time - synchronized but spatially separated images , captured by a multiple camera system [ 31 ] .Input images are rectified to make the problem easy and accurate , so corresponding pixels are assumed to be on the same horizontal line in the left and right images .", "label": "", "metadata": {}, "score": "64.18753"}
{"text": "In addition , numerous specific details are set forth in order to provide a thorough understanding of the embodiments described herein .However , it will be understood by those of ordinary skill in the art that some embodiments may be practiced without these specific details .", "label": "", "metadata": {}, "score": "64.21824"}
{"text": "Blocking synchronisations fit well coarse grain parallelism ( milliseconds tasks or more ) , whereas Nonblocking fine grain parallelism .Blocking synchronisations make it possible to exploit over - provisioning ( e.g. for load balancing ) and energy consumption .However , they exhibits large overheads ( also due to OS involvement ) .", "label": "", "metadata": {}, "score": "64.3985"}
{"text": "The GPU Platform .For the purpose of our GPU - based implementation of the Smith - Waterman algorithm , we targeted the GeForce 8800GTX GPU from NVIDIA Corp.[ 11 ] .The SP clock frequency is 1,350 MHz .Like many - core CPUs , CUDA uses threads for parallel execution .", "label": "", "metadata": {}, "score": "64.482285"}
{"text": "They are implemented on top of building blocks .Building blocks It provides the basic blocks to build ( and generate via C++ header - only templates ) the run - time support of core patterns .Typical objects at this level are queues ( e.g. wait - free fence - free SPSC queues , bound and unbound ) , process and thread containers ( as C++ classes ) mediator threads / processes ( extensible and configurable schedulers and gatherers ) .", "label": "", "metadata": {}, "score": "64.58952"}
{"text": "Here , the alignment score is the largest of three alternatives ( saturated to zero in case all three values are negative as it is better to start a new subsegment alignment than continue a subalignment with a negative score ) .", "label": "", "metadata": {}, "score": "64.6586"}
{"text": "M. Martina , G. Masera , S. Papaliralabos , P. Mathiopoulos , and F. Gioulekas , \" On practical implementation and generalization of . max . operation for Turbo and LDPC decoders , \" IEEE Transactions on Instrumentation and Measurement , vol .", "label": "", "metadata": {}, "score": "64.66408"}
{"text": "Distributed memory in each PE then behaves as a register chain .Each PE configuration memory is loaded with the corresponding look - up tables sequentially .At the end of the configuration , Cfg is reset to 0 indicating the start of the operation mode .", "label": "", "metadata": {}, "score": "64.73032"}
{"text": "More importantly , tiling enable us to run multiple tiles in parallel ( Section 4.5 ) .To efficiently use memory bandwidth , we transform arrays to increase element size and match the system 's bound on memory access bit - width .", "label": "", "metadata": {}, "score": "64.73922"}
{"text": "12 , pp .4117 - 4122 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .G. Lechner , J. Sayir , and M. Rupp , \" Efficient DSP implementation of an LDPC decoder , \" in Proceedings of the IEEE International Conference on Acoustics , Speech , and Signal Processing , vol .", "label": "", "metadata": {}, "score": "64.73937"}
{"text": "Further , the description is not to be considered as limiting the scope of the application and the claims herein .Generally speaking , embodiments described herein relate to architectures , systems and methods for configuring and implementing scalable ANNs .The architecture , systems and methods are intended to provide a customized scalable network with a variable degree of parallelism .", "label": "", "metadata": {}, "score": "64.83476"}
{"text": "Other ImpulseC pragmas are specifically related to the coding style , which requires explicit identification of certain variable types used for interfunction communication .LegUp is an academic - initiated open source HLS tool [ 23 ] .Given a C program , LegUp can automatically perform hardware software codesign , where some program segments are mapped to custom hardware ( synthesized from the C - code ) and the remaining code is mapped onto an FPGA - based soft processor .", "label": "", "metadata": {}, "score": "64.84233"}
{"text": "PE outputs the result to output ports corresponding to each input which is not included in the set , for example , . requires additional circuitry which adds to complexity and latency of PE .As shown in the figure , the complexity of PE is dominated by logic components ( e.g. , comparators ) and increases almost linearly with node degree .", "label": "", "metadata": {}, "score": "64.860954"}
{"text": "This shows the FPGA solution to be three orders of magnitude more energy efficient than GPP , while the Cell BE and the GPU came second and third , respectively ( with one order of magnitude energy efficiency compared to GPP ) .", "label": "", "metadata": {}, "score": "64.9195"}
{"text": "These patterns can be arbitrarily nested to build large and complex graphs .However , not all graphs can be build .This enforce the correctness ( by - construction ) of all streaming networks that can be generated .In particular , they are deadlock - free and data - race free .", "label": "", "metadata": {}, "score": "64.96901"}
{"text": "A significant disadvantage of state - of - the - art DTMs lies in their inability to account for the non - uniform thermal behaviour of die stacks , leading to the ineffective management of temperatures and in degraded system performance .", "label": "", "metadata": {}, "score": "64.99309"}
{"text": "Flexible Decoders .Parallelism .The standard TPMP algorithm described in the previous section exploits the bipartite nature of the Tanner Graph : since no direct connection is present between nodes of the same kind , all CN ( or VN ) operations are independent from each other and can be performed in parallel .", "label": "", "metadata": {}, "score": "65.09749"}
{"text": "The RSPA can be dynamically reconfigured to choose between the two decoding modes according to different block LDPC codes .With intelligent hardware reuse via modular design the overhead due to the double decoding approach is reduced to a minimum , with an overall acceptable power consumption .", "label": "", "metadata": {}, "score": "65.321"}
{"text": "M. Awais , A. Singh , E. Boutillon , and G. Masera , \" A novel architecture for scalable , high throughput , multi - standard LDPC decoder , \" in Proceedings of the 14th Euromicro Conference on Digital System Design ( DSD ' 11 ) , vol .", "label": "", "metadata": {}, "score": "65.37283"}
{"text": "When cells are calculated , we keep track of their updated values in a temporary register ( cell calculations ) which is updated each time a new column is calculated .The entire pairwise alignment matrix is not stored in memory , but rather just the temporary cell calculations column .", "label": "", "metadata": {}, "score": "65.44115"}
{"text": "428 - 435 , October 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .B. M. Smith , L. Zhang , and H. Jin , \" Stereo matching with nonparametric smoothness priors in feature space , \" in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops , pp .", "label": "", "metadata": {}, "score": "65.55188"}
{"text": "Very few state of the art solutions have managed to solve this problem , and those who do suffer from large complexity and power consumption .We have tried to overcome these shortcomings in some recent works .NoC - Based WiMAX LDPC Decoder .", "label": "", "metadata": {}, "score": "65.559555"}
{"text": "GPGPUs .GPGPUs are supported by way of OpenCL and/or CUDA .At the current development status , kernel business code should be written either in OpenCL or CUDA .FastFlow takes care of H2D / D2H ( asynchronous ) data transfers and synchronisations .", "label": "", "metadata": {}, "score": "65.58374"}
{"text": "20 , no . 1 , pp .15 - 26 , 2010 .View at Publisher \u00b7 View at Google Scholar .K. Zhang , J. Lu , G. Lafruit , R. Lauwereins , and L. Van Gool , \" Real - time accurate stereo with bitwise fast voting on CUDA , \" in Proceedings of the 12th International Conference on Computer Vision Workshops , pp .", "label": "", "metadata": {}, "score": "65.6494"}
{"text": "Based on the observation that inter - frame dependencies have a limited spatial range we propose a new parallelization strategy , called Dynamic 3D - Wave .It allows certain MBs of consecutive frames to be decoded in parallel .Using this new strategy we analyze the limits to the available MB - level parallelism in H.264 .", "label": "", "metadata": {}, "score": "65.691055"}
{"text": "19 illustrates a flowchart diagram of a method for designing a hardware configuration for implementing a scalable artificial neural network in accordance with embodiments described herein ; and .FIG .20 illustrates a schematic diagram of a system for designing a hardware configuration for a scalable artificial neural network in accordance with embodiments described herein ; . DETAILED DESCRIPTION .", "label": "", "metadata": {}, "score": "65.70085"}
{"text": "We also perform a case study on stereo matching using HLS .Stereo matching contains multiple kernels related through data communication .Ideally , we want to convert the data arrays that are communicated through kernels into FIFOs and allow pipelining between kernels as mentioned earlier .", "label": "", "metadata": {}, "score": "65.816895"}
{"text": "Figure 7 : Illustration of the execution of the Smith - Waterman on the linear array processor .The architecture of Figure 6 can cater for different sequence symbol types , sequence lengths , match scores , and matching task .Given a particular substitution matrix , for example , BLOSUM50 , all possible match scores for a particular symbol represent one column in the substitution matrix .", "label": "", "metadata": {}, "score": "65.900764"}
{"text": "AutoPilot 's optimizations are very powerful - array map and array partition can have significant impact on storage requirements , and together with loop unrolling , it is possible to explore possible parallelism points quite easily .However , automatic transformations sometimes make this task more difficult ; by default AutoPilot will attempt to completely unroll an inner loop to expose parallelism when pipelining , but when the loop has variable bounds , this can result in significant overhead .", "label": "", "metadata": {}, "score": "66.054214"}
{"text": "The input vector is then processed through the hidden layer achieving both node and synapse parallelism .In stage 2 , the entire output of the hidden layer 155 is issued to the output layer 160 in one clock cycle .A degree of parallelism higher than one represents a partially parallel system , which facilitates hardware reuse , since each hardware stage is required to process only a portion of an input vector in one cycle .", "label": "", "metadata": {}, "score": "66.10333"}
{"text": "Theoretically one new instruction is fed into the processor at each clock cycle thus achieving the ideal one instruction per cycle rate .Referring now to .FIG .6 , there is shown an example network architecture implementing full pipelining using per epoch training , where in this example each epoch 190 contains 4 patterns ( e.g. patterns 1 - 4 ) .", "label": "", "metadata": {}, "score": "66.13745"}
{"text": "As will be explained further herein , when implementing a pipelined network embodiment Equation ( 6 ) above will modify slightly to implement an out of order weight update rule .Training : Per - Pattern vs. Epoch .MLP training can be conducted using either a per - pattern or epoch ( a.k.a . batch ) training method .", "label": "", "metadata": {}, "score": "66.18425"}
{"text": "In [ 81 ] , an extensive analysis of performance of various NoC topologies is performed in the context of multiprocessor turbo decoders .Flexibility can be explored also in terms of types of code supported : in [ 82 ] , we have consequently extended the topology analysis to LDPC codes , in order to find a suitable architecture for a dual turbo / LDPC codes .", "label": "", "metadata": {}, "score": "66.21083"}
{"text": "With FastFlow we advocate a different approach to the implementation of these queues , which require neither locks nor atomic operations .SPMC , MPSC channels are realised by using only SPSC queues and a mediator thread , which enforce the correct serialisation of producers and consumers .", "label": "", "metadata": {}, "score": "66.26915"}
{"text": "Its . of 1.416 mm 2 is the minimum among all WiMAX solutions discussed above , but with very low DE stains overall performance .Among the ASIP solutions ( Table 5 ) , the work in [ 40 ] can not effectively be compared to the others in terms of area , not providing complete estimations .", "label": "", "metadata": {}, "score": "66.29823"}
{"text": "BRAM optimizations are effective for the embedded benchmark kernels and stereo matching algorithms .For arrays with few total elements ( in our case , less than 100 ) and statically determined access order , we use complete array partitioning which directs AutoPilot to use registers instead of BRAMs .", "label": "", "metadata": {}, "score": "66.33008"}
{"text": "ITER - clock cycles ( iterations ) per input pattern .As an example of memory blocks , an estimate for the number of block rams is provided .This number will generally be less than the number of multipliers used .", "label": "", "metadata": {}, "score": "66.3429"}
{"text": "We can see that the FPGA solution is 50x more expensive than the GPP solution , followed by the Cell BE ( 19x ) and the GPU ( 8x ) .Based on these figures , we can measure the performance per dollar spent by dividing the GCUPS figures of Table 4 by the overall cost figures given in Table 6 for each platform .", "label": "", "metadata": {}, "score": "66.34454"}
{"text": "6 , pp .5778 - 5781 , May 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . K. Gunnam , G. Choi , and M. Yeary , \" A parallel VLSI architecture for layered decoding for array LDPC codes , \" in Proceedings of the 6th International Conference on Embedded Systems , 20th International Conference on VLSI Design , pp .", "label": "", "metadata": {}, "score": "66.37277"}
{"text": "[29 ] manages to deliver more than 1 Gb / s throughputs for most code lengths and rates .The result is achieved via the instantiation of 3 PEs with internal parallelism of 30 : the similarity of WiMedia codes with the QC - LDPC of WiMAX allows a multiple submatrix - level parallelism in the decoder .", "label": "", "metadata": {}, "score": "66.448044"}
{"text": "Directives can specify that data accesses use particular communication interface protocols such as ACK , Valid , memory , or FIFO ( among others ) .Additionally , users can define their own protocol and define a code region as a protocol so that code in that region is not rescheduled .", "label": "", "metadata": {}, "score": "66.45866"}
{"text": "This second read after write data hazard may be solved by adding hardware delay elements tuned to the latency of the feed forward and back propagation pipeline stages .These delay elements ensure that the proper ( updated ) weight is read .", "label": "", "metadata": {}, "score": "66.4957"}
{"text": "5 , Article ID 4815264 , pp .815 - 830 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .K. Zhang , J. Lu , and G. Lafruit , \" Cross - based local stereo matching using orthogonal integral images , \" IEEE Transactions on Circuits and Systems for Video Technology , vol .", "label": "", "metadata": {}, "score": "66.50348"}
{"text": "22 , no . 7 , pp .675 - 684 , 2000 .View at Google Scholar \u00b7 View at Scopus .Q. Yang , L. Wang , and N. Ahuja , \" A constant - space belief propagation algorithm for stereo matching , \" in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , pp .", "label": "", "metadata": {}, "score": "66.51582"}
{"text": "A . barrel shifter manages the interlayer communication : since the number of rows that compose the layer never change in DVB - S2 , a change of code will mean a different workload on the communication structure , but very easy reconfiguration .", "label": "", "metadata": {}, "score": "66.56503"}
{"text": "By default all data arrays are mapped to local BRAMs ; scalar variables are mapped to registers .AutoPilot can apply optimizations to five groups of software source code : communication interfaces , function calls , for loops , data arrays , and labeled regions ( a named code section enclosed by curly brackets ) .", "label": "", "metadata": {}, "score": "66.649"}
{"text": "PARITY problem : The PARITY problem is a classification problem aimed at determining a parity output for a three bit input .The topology used for simulations is 3 - 10 - 1 ( 3 inputs , 10 hidden neurons and 1 output neuron ) .", "label": "", "metadata": {}, "score": "66.71814"}
{"text": "View at Google Scholar .C. He , A. Papakonstantinou , and D. Chen , \" A novel SoC architecture on FPGA for ultra fast face detection , \" in Proceedings of the IEEE International Conference on Computer Design , pp .", "label": "", "metadata": {}, "score": "66.72226"}
{"text": "Horizontal axis .Scanline Optimization ( SO ) .Scanline optimization [ 32 ] ( Software is an internally developed version of the algorithm in [ 32 ] . ) is a simple 1D - optimization variant of a dynamic programming stereo matching formulation .", "label": "", "metadata": {}, "score": "66.788086"}
{"text": "In some embodiments , the ITER value 1035 is directly output by the system 1000 for use in designing the scalable network implementation .The ITER value 1035 selected by the ITER selection module 1025 may also be provided to a hardware configuration module 1030 .", "label": "", "metadata": {}, "score": "66.82425"}
{"text": "M. Martina and G. Masera , \" Turbo NOC : a framework for the design of network - on - chip - based turbo decoder architectures , \" IEEE Transactions on Circuits and Systems I : Regular Papers , vol .57 , no .", "label": "", "metadata": {}, "score": "66.91465"}
{"text": "P. Bjesse , K. Claessen , M. Sheeran , and S. Singh , \" Lava : hardware design in Haskell , \" in Proceedings of the 3rd ACM SIGPLAN International Conference on Functional Programming , vol .3 , pp .174 - 184 , September 1998 .", "label": "", "metadata": {}, "score": "66.91912"}
{"text": "In Min - Sum decoding , out of all LLRs considered by a CN , only two magnitudes are of interest , that is , minimum and the second minimum .The PE works serially maintaining three variables , namely , MIN , MIN2 , and INDEX .", "label": "", "metadata": {}, "score": "66.92769"}
{"text": "For example , AutoPilot contains a loop_tripcount directive that is used for performance analysis , but not in the synthesis process .If also used during the synthesis process to specify bounds and typical iterations on variable loops , this could allow easier optimization of such code .", "label": "", "metadata": {}, "score": "67.04077"}
{"text": "Whoever completes its computation first sends the results back to the PPE by means of the other message queue .This process continues until PPE transmits all the sequences to the SPEs .The manager then deallocates memory , destroys the MCF network , and terminates the program .", "label": "", "metadata": {}, "score": "67.08158"}
{"text": "They make it possible to build very general ( deadlock - free ) cyclic process networks .They are not graphs of tasks , they are graphs of parallel executors ( processes / threads ) .Tasks or data items flows across them .", "label": "", "metadata": {}, "score": "67.10321"}
{"text": "That is , each neuron 215 of a layer 205 / 210 receives input 230 during one clock cycle , which is either a full input vector or part of an input vector depending on the ITER value .In this case , the synchronization module / blocks may still be present in the architecture but the degree of parallelization ( ITER value ) will be set to one .", "label": "", "metadata": {}, "score": "67.11775"}
{"text": "After reading one sequence from the database , the manager puts it into one message queue and sets up a loop in which the PPE sends the message to SPEs separately .The manager then waits for the synchronization semaphore from the SPEs when they finish pulling the data into local store .", "label": "", "metadata": {}, "score": "67.13251"}
{"text": "Here , a novel approach to processing element design is proposed , allowing a high percentage of shared logic between turbo and LDPC decoding .The TDMP approach allows the usage of BCJR decoding algorithm for both codes , while the communication network can be split into smaller supercode - bound interleavers , effectively merging LDPC and turbo tasks .", "label": "", "metadata": {}, "score": "67.15027"}
{"text": "Note here that if the length of the database subject sequence is smaller than the number of threads in the block , additional waiting time should be added for the threads in the batch to finish their computations .This is easy to imagine , for example , if thread 0 has already completed its row calculation , but thread . of the previous sub - matrix alignment to complete its task before obtaining its initial data for the sub - matrix alignment .", "label": "", "metadata": {}, "score": "67.18033"}
{"text": "For embedded benchmark kernels , most of the arrays can be completely partitioned for better memory bandwidth because the arrays used by the kernels are relatively small and there are relatively few arrays in total .We observe that there are few opportunities to perform reduced bit - width optimization for the embedded benchmark kernels because the bit - width has typically been optimized already .", "label": "", "metadata": {}, "score": "67.23009"}
{"text": "NoC - based decoders are multiprocessor systems composed of various instantiations of the same IP associated to a routing element , which are linked in defined pattern .This pattern can be represented with a graph , in which every node corresponds to a processor and a router : the arcs are the physical links among routers , thus identifying a topology .", "label": "", "metadata": {}, "score": "67.31866"}
{"text": "Structured LDPC codes decoding , regardless of their implementation , often require shift or shuffle operation to route information between PEs or to / from memories .This is particularly true for some kinds of LDPC codes , as QC - LDPC and shift -LDPC [ 54 ] .", "label": "", "metadata": {}, "score": "67.36732"}
{"text": "This may also be referred to as an application performance requirement .Four example problems were selected that generally represent a mix between research - oriented problems and practical ones , and also a mix between classification type problems and function approximation problems .", "label": "", "metadata": {}, "score": "67.380936"}
{"text": "Fastflow SPSC queues can be directly used to write parallel programs by writing a C++ program that spawns a set of ff_node s and orchestrates them in pairs each of them sharing ( at least ) a SPSC queue descriptor .Each thread in the pair has a fixed role in using the queue , either producer or consumer .", "label": "", "metadata": {}, "score": "67.38951"}
{"text": "The third stage includes universal register file 105 , bi - directionally coupled to fetch / branch unit 202 , and dispatch unit 206 , receiving instructions from decode unit 203 and transmitting control signals to register file 205 .The dispatch unit 206 sends tasks to SPPUs 104 in the hyperprocessor 100 , and receives signals representing the state of the execution of those tasks .", "label": "", "metadata": {}, "score": "67.442535"}
{"text": "ImpulseC uses a highly customized subset of the C language , with coding style restrictions to make the input more similar to HDL .As a result , ImpulseC supports a wide range of loop and data array transformations , again without function or dataflow pragmas ( dataflow hardware is described explicitly ) .", "label": "", "metadata": {}, "score": "67.49225"}
{"text": "As such , the error back propagation module 305 is also a component of the back propagation system 705 ( .FIG .7 ) .Referring now to .FIG .11 , there is shown an example hardware diagram of the internal structure of a portion 800 of each layer 205 / 210 of the network 200 capable of implementing variable degrees of parallelism in accordance with some embodiments described herein .", "label": "", "metadata": {}, "score": "67.54582"}
{"text": "In this study , stereo matching presents the additional challenge that software implementations are created by computer vision researchers unfamiliar with hardware design constraints .Thus , our stereo matching case study must optimize software not originally designed for HLS implementation .", "label": "", "metadata": {}, "score": "67.54733"}
{"text": "In Proc . of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming ( PPoPP ) , pages 43 - 52 , New York , NY , USA , 2008 .ACM .[AB+09 ] K. Asanovic , R. Bodik , J. Demmel , T. Keaveny , K. Keutzer , J. Kubiatowicz , N. Morgan , D. Patterson , K. Sen , J. Wawrzynek , D. Wessel , and K. Yelick .", "label": "", "metadata": {}, "score": "67.56401"}
{"text": "Once the \u0394w ( i.e. the change for all weights ) from all the patterns are accumulated and averaged , weights are updated using the above Equation ( 6 ) .Thus the weights of the network are updated only once per epoch .", "label": "", "metadata": {}, "score": "67.599464"}
{"text": "For Loops .For loops are kept rolled by default to maintain the maximum opportunity for resource sharing .AutoPilot directives can specify full or partial unrolling of the loop body , combination of multiple loops , and combination of nested loops .", "label": "", "metadata": {}, "score": "67.62604"}
{"text": "Referring now to .FIG .10 , there is shown an example diagram of the internal structure of each layer 205 / 210 of the network 200 capable of implementing a variable degree of parallelism in accordance with embodiments described herein .", "label": "", "metadata": {}, "score": "67.665474"}
{"text": "443 - 453 , 1970 .View at Google Scholar \u00b7 View at Scopus .T. F. Smith and M. S. Waterman , \" Identification of common molecular subsequences , \" Journal of Molecular Biology , vol .147 , no . 1 , pp .", "label": "", "metadata": {}, "score": "67.68087"}
{"text": "HLS tools promise hardware development abstracted from software designer knowledge of the implementation platform .In this paper , we present an unbiased study of the performance , usability and productivity of HLS using AutoPilot ( a state - of - the - art HLS tool ) .", "label": "", "metadata": {}, "score": "67.702835"}
{"text": "That is , instead of calculating the change for the current weight n , the weight change for the weight of the n - latency iteration ( i.e. clock cycle ) is calculated or the accumulated weight change including the n - latency iteration is calculated depending on the training pattern used .", "label": "", "metadata": {}, "score": "68.01693"}
{"text": "Perfomance .Applications .Task . )Tasks .Processor . )Processors .Instruction . )Instructions .Cycle . )Cycles .Second . ) . . .This equation is an oversimplification of much more complicated and interdependent variables .", "label": "", "metadata": {}, "score": "68.073105"}
{"text": "WiMAX which is a wireless metropolitan area network ( WMAN ) standard and IEEE 802.11n WiFi which is a wireless local area network ( WLAN ) standard .Both standards have adopted LDPC codes as an optional channel coding scheme with various code lengths and code rates .", "label": "", "metadata": {}, "score": "68.09417"}
{"text": "WiMAX standard features four code rates , that is , 1/2 , 2/3 , 3/4 , and 5/6 with .LDPC Decoding Algorithms .The nature of LDPC decoding algorithms is mainly iterative .Most of these algorithms are derived from the well - known belief propagation ( BP ) algorithm [ 5 ] .", "label": "", "metadata": {}, "score": "68.26723"}
{"text": "As explained above , the neuron output 235 makes up part of its layer 's output vector , which is then synchronized at the synchronization block 220 every ITER number of cycles to provide feed forward data for the next layer .", "label": "", "metadata": {}, "score": "68.29201"}
{"text": "Together , the characterization and the Ctherm framework further our understanding of the thermal behaviour of die stacks , and provide a practical template for the realization of thermal - aware electronic design automation tooling for 3D ICs .The management of thermal issues that arise in 3D MPSoCs at runtime is examined in Chapter 4 .", "label": "", "metadata": {}, "score": "68.3508"}
{"text": "The ratio is generally calculated by dividing the number of multipliers ( from Equation ( 11 ) ) by the number of weights ( from Equation ( 13 ) ) , for a given topology and ITER value .In some embodiments , an upper limit of the ratio and lower limit of the ratio are calculated in order to determine a general range of multipliers to weight ratios for multiple network topologies .", "label": "", "metadata": {}, "score": "68.36001"}
{"text": "View at Scopus .G. A. Harrison , J. M. Tanner , D. R. Pilbeam , and P. T. Baker , Human Biology : An Introduction to Human Evolution , Variation , Growth , and Adaptability , Oxford Science , 1988 .", "label": "", "metadata": {}, "score": "68.38524"}
{"text": "1073 - 1079 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .S. Paris and F. Durand , \" A fast approximation of the bilateral filter using a signal processing approach , \" in Proeedings of the 9th European Conference on Computer Vision , 2006 .", "label": "", "metadata": {}, "score": "68.54175"}
{"text": "As a case study we investigate the parallelism available in video decoders , an important application domain now and in the future .Specifically , we analyze the parallel scalability of the H.264 decoding process .First we discuss the data structures and dependencies of H.264 and show what types of parallelism it allows to be exploited .", "label": "", "metadata": {}, "score": "68.55118"}
{"text": "Also , the variations in throughput due to different NoC parallelisms are shaded by the impact of latency .The work in [ 76 ] describes a flexible LDPC decoder design tackling the communication problem with two different NoC solutions .The first network is a De Bruijn NoC adopting online dynamic routing , implementing the same modified shortest path algorithm described in [ 70 ] , while the second , a 2D torus , is based on a completely novel concept named zero overhead NoC ( ZONoC ) .", "label": "", "metadata": {}, "score": "68.562126"}
{"text": "One of the limitations of the traditional BeN is the number of its inputs and outputs , that are bound to be a power of 2 .However , LDPC decoders often need a permutation of different size : for example , WiMAX codes require shift permutations of sizes corresponding to the possible expansion factors , that is , from 24 to 96 with steps of 4 .", "label": "", "metadata": {}, "score": "68.56487"}
{"text": "First , for the code restructuring step , BFAS results in a 50 % reduction in AutoPilot estimated LUT use , 70 % fewer flip - flops , 60 % fewer DSP blocks , and 95 % fewer BRAMs .The other stereo matching algorithms do not employ computation resources as heavily , so there was less benefit for LUT , FF , or DSP resources , but all of them received at least 90 % reduction in memory resources .", "label": "", "metadata": {}, "score": "68.57007"}
{"text": "Data caching is supported to alleviate task dependency issues .The universal register file 105 keeps track of which entries are in use by which processor 104 in read or write modes , keeping track of data dependencies .Coherency mechanisms provided by the universal register file 105 improve scalability of parallel execution and therefore enable use of a larger number of SPPUs 104 .", "label": "", "metadata": {}, "score": "68.59942"}
{"text": "F. Guilloud , E. Boutillon , and J. Danger , \" \u03bb -min decoding algorithm of regular and irregular LDPC codes , \" in Proceedings of the 3rd International Symposium on Turbo Codes and Related Topics , pp .451 - 454 , September 2003 .", "label": "", "metadata": {}, "score": "68.64938"}
{"text": "Referring now to .FIG .8 there is shown a flowchart diagram of an example method 600 for designing a hardware configuration for a scalable ANN in accordance with embodiments described herein .Certain steps of the method 600 may be implemented by a system for designing a hardware configuration for implementing a scalable artificial neural network , such as the example system 1000 illustrated in .", "label": "", "metadata": {}, "score": "68.69808"}
{"text": "Moreover , the processing word length in the FPGA systolic array is 16 bits , and the circuit was clocked at 80 MHz .Table 4 presents the corresponding performance figures in Giga Cell Updates Per Seconds ( GCUPS ) ( the CUPS ( or Cell Updates Per Second ) is a common performance measure used in computational biology .", "label": "", "metadata": {}, "score": "68.70314"}
{"text": "We used Cell SDK version 3.0 and Mercury 's MultiCore Framework ( MCF ) to develop our CellBE implementation .MCF uses a Function Offload Engine ( FOE ) model .In this model , the PPE acts as a manager directing the work of the SPEs .", "label": "", "metadata": {}, "score": "68.758804"}
{"text": "In general , a more parallel network with many inputs to neurons will generate better performance in CUPS than a more serial network with many neurons but few inputs .N i -N h -1 .N i -1-N o .", "label": "", "metadata": {}, "score": "68.84675"}
{"text": "N o .N i-N h-N o .Results .Performance .Performance in Terms of CUPS .Using Equations ( 11 ) , ( 13 ) and ( 14 ) as a guide , it is now possible to derive boundaries on maximum performance of a network fully utilizing available resources of an example hardware device , in this case FPGAs .", "label": "", "metadata": {}, "score": "68.8943"}
{"text": "The performance of a wide set of topologies ( ring , spidergon , toroidal meshes , honeycomb , De Bruijn , and Kautz ) has been evaluated in terms of achievable throughput and complexity , considering different parallelisms .The simulations revealed the Kautz topology [ 83 ] to be the best trade - off in terms of throughput and complexity between LDPC and turbo codes , with a partially adaptive router architecture and FIFO - length based routing .", "label": "", "metadata": {}, "score": "68.92156"}
{"text": "The degree of similarity between pairs of biological sequences is measured by a score , which is a summation of odd - log scores between pairwise residues , in addition to gap penalties .The odd - log scores are based on the statistical likelihood of any possible alignment of pairwise residues and is often summarised in a substitution matrix ( e.g. , BLOSUM50 , BLOSUM62 , PAM ) .", "label": "", "metadata": {}, "score": "68.94901"}
{"text": "Since ANNs have an inherently parallel processing architecture , it is important to have a similarly parallel processing architecture on the hardware device , an FPGA in this example , to take advantage of this inherent parallelism and maximize performance .Generally , hardware devices are chosen to provide a maximal degree of parallelism for the ANN being implemented , however , it may not always be possible to provide a maximal degree of parallelism .", "label": "", "metadata": {}, "score": "68.97788"}
{"text": "However , some of the benchmarks use significantly more BRAM resources than available in the FPGA chip we use ( Xilinx Virtex-6 LX240 T ) .In addition , the BFAS software versions also have complex computation , which causes overconstrained use of LUT , FF and DSP resources as well .", "label": "", "metadata": {}, "score": "69.12291"}
{"text": "6 , pp .1098 - 1102 , 2005 .View at Google Scholar .N. Wiberg , Codes and decoding on general graphs , Ph.D. dissertation , Linkoping University , Linkoping , Sweden , 1996 .J. Chen and M. P. C. Fossorier , \" Near optimum universal belief propagation based decoding of LDPC codes and extension to turbo decoding , \" in Proceedings of the IEEE International Symposium on Information Theory ( ISIT ' 01 ) , p. 189 , June 2001 .", "label": "", "metadata": {}, "score": "69.15003"}
{"text": "Processes typically stream data items ( they are not tasks ) onto channels , they can be either references ( e.g. pointers in the shared - memory ) or messages with a payload ( e.g. in a distributed platform ) .In both cases , the data item acts as synchronisation token .", "label": "", "metadata": {}, "score": "69.192825"}
{"text": "This can be achieved through setting the proper number of threads in each block .Here , since each SM has 8192 registers and can keep at most 768 parallel threads , for a query sequence of length 512 , if we use 1 block of 512 threads , 16 registers can be used for each thread .", "label": "", "metadata": {}, "score": "69.27848"}
{"text": "The 2 steps of the MLP - BP algorithm are as follows : . 1 ) Feed Forward Computation : The computation performed by each neuron 105 in layer s during the feed forward computation stage is as follows : . o . k . s . )", "label": "", "metadata": {}, "score": "69.38219"}
{"text": "415 - 428 , 2011 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .X. Y. Shih , C. Z. Zhan , C. H. Lin , and A. Y. Wu , \" An 8.29 mm2 52 mW multi - mode LDPC decoder design for mobile WiMAX system in 0.13 \u03bc m CMOS process , \" IEEE Journal of Solid - State Circuits , vol .", "label": "", "metadata": {}, "score": "69.42557"}
{"text": "At 19 bits , slice utilization jumps as the synthesizer uses the 18 bit built - in multiplier resources for the 18 significant bits of the number , and adds hardware using general FPGA fabric to manage the extra bit of 2 's complement representation .", "label": "", "metadata": {}, "score": "69.478"}
{"text": "Classification problems require less precision in its output than functions approximation since what is needed is for the network to pick one class among many .An arithmetic representation that is very limited in precision could be suitable for a classification problem but not for a function approximation problem .", "label": "", "metadata": {}, "score": "69.49776"}
{"text": "Thus , we select stereo matching [ 27 ] as a case study of HLS on complex real - world applications .Stereo matching is an important underlying technology for 3D video ; the depth maps generated by stereo matching are used for interpolated video views and 3D video streams .", "label": "", "metadata": {}, "score": "69.55681"}
{"text": "Although AutoPilot has synthesis directives that can merge loops or eliminate memory buffers that are used in FIFO order , these directives are relatively limited compared to transformations we can perform manually .Reduced Bitwidth and BRAMs .The bit - width optimization is mainly effective for stereo matching algorithms ; their computation involves a lot of arrays and the array element bitwidth can be reduced for some of these arrays .", "label": "", "metadata": {}, "score": "69.5819"}
{"text": "429 - 434 , June 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .N. De Bruijn , \" A combinatorial problem , \" Koninklijke Nederlandse Akademie , vol .49 , pp .758 - 764 , 1946 .", "label": "", "metadata": {}, "score": "69.81107"}
{"text": "Neurons 215 are provided with error data via an input line 850 .After the neurons weights are updated every ITER number of cycles during the back propagation stage , the neuron weights ( bW ) and gradients ( bD ) 820 are provided to the previous layer 205 / 210 in the network 200 .", "label": "", "metadata": {}, "score": "69.98959"}
{"text": "The desired network topology 1005 provides the number of theoretical inputs , the number of neurons in theoretical hidden layers , and the number of neurons in a theoretical output layer 110 .An example desired network topology is 12 - 6 - 10 , with 12 inputs , 6 neurons in the hidden layer(s ) , and 10 neurons in the output layer .", "label": "", "metadata": {}, "score": "70.08751"}
{"text": "This paper is supported by the Advanced Digital Sciences Center ( ADSC ) under a grant from the Agency for Science , Technology , and Research of Singapore .References .J. Bodily , B. Nelson , Z. Wei , D.-J. Lee , and J. Chase , \" Comparison study on implementing optical flow and digital communications on FPGAs and GPUs , \" ACM Transactions on Reconfigurable Technology and Systems , vol .", "label": "", "metadata": {}, "score": "70.298996"}
{"text": "ff : : ParallelFor pf ; . pf .In the specific case , the only syntactic difference between OpenMP and FastFlow are that FastFlow provides programmers with C++ templates instead of compiler pragmas .It is worth to notice that despite the similar syntax , the implementation of the parallel_for and all other high - level patterns in FastFlow is quite different from OpenMP and other mainstream programming frameworks ( Intel TBB , etc ) .", "label": "", "metadata": {}, "score": "70.489395"}
{"text": "734 - 738 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .F. T. Leighton , Introduction to Parallel Algorithms and Architectures : Arrays , Trees , Hypercubes , Morgan Kaufmann Publishers , 1992 .", "label": "", "metadata": {}, "score": "70.53203"}
{"text": "An artificial neural network according to . claim 8 , wherein the variable arithmetic representation is a local variable arithmetic representation .An artificial neural network according to . claim 1 , wherein the artificial neural network is implemented on a hardware technology selected from the set of : VLSI \" very large scale integrated \" chip , ASIC \" application specific integrated circuit \" , and FPGA \" field programmable gate arrays \" .", "label": "", "metadata": {}, "score": "70.53649"}
{"text": "Customized interconnects for specific applications is are undesirable because of time and cost implications .Accordingly , embodiments of the hyperprocessor 100 preferably employ the Octagon interconnect , disclosed in U.S. patent application Ser .No .10/090,899 entitled \" OCTAGONAL INTERCONNECTION NETWORK FOR LINKING PROCESSING NODES ON AN SOC DEVICE AND METHOD OF OPERATING SAME \" and filed Mar. 5 , 2002 , now U.S. Pat .", "label": "", "metadata": {}, "score": "70.53998"}
{"text": "Currently , the project is dormant .One M. Sc . thesis project was recently carried out within the project : Data Field Haskell 98 , where an earlier implementation of DFH was ported to Haskell 98 .If this project is revived ( or somebody else picks up the thread ) , then the following is on the wish list : .", "label": "", "metadata": {}, "score": "70.79549"}
{"text": "Although not nonblocking in general , the ByN is non - blocking in case of shift operations only .Moreover , it is composed of averagely half of the .The work described in [ 68 ] portrays a highly parallel shuffle network based on the ByN paradigm .", "label": "", "metadata": {}, "score": "70.851425"}
{"text": "With the word flexibility regarding channel decoding , we mean the ability of a decoder to support different types of codes , enabling its usage in a wide variety of situations .Much research has been done in this sense after the great increase in number of standards , standard complexity , and code variety witnessed during the last years .", "label": "", "metadata": {}, "score": "71.160706"}
{"text": "20 .The system components may be implemented in software , by hardware description languages or by various hardware platforms .At step 610 , a desired network topology 1005 is provided to the system 1000 and received by input module 1010 .", "label": "", "metadata": {}, "score": "71.17227"}
{"text": "The depth map is subsequently used to generate interpolated view angles and 3D video streams .Figure 1 : Example image capture for stereo matching .Two cameras physically offset capture an image of the same scene .The disparity between the objects in the left and right images infers information about object depth .", "label": "", "metadata": {}, "score": "71.21497"}
{"text": "The lack of standards ( e.g. , standard FPGA hardware boards , standard FPGA APIs ) however remains a major problem for FPGA programmers .Note here that the purchase cost of FPGA , GPU and Cell BE includes the cost of the host machine .", "label": "", "metadata": {}, "score": "71.285934"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .J. Cho , N. R. Shanbhag , and W. Sung , \" Low - power implementation of a high - throughput LDPC decoder for IEEE 802.11N standard , \" in Proceedings of the IEEE Workshop on Signal Processing Systems ( SiPS ' 09 ) , pp .", "label": "", "metadata": {}, "score": "71.53638"}
{"text": "View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . D. E. Hocevar , \" A reduced complexity decoder architecture via layered decoding of LDPC codes , \" in Proceedings of the IEEE Workshop on Signal Processing Systems Design and Implementation , pp .", "label": "", "metadata": {}, "score": "71.63165"}
{"text": "The weights are updated for a given pattern ( or input vector ) at the output layer 210 first , and then in the hidden layer 205 .This is in reverse of the sequence of weight recalls that occur during feed forward operation for another pattern .", "label": "", "metadata": {}, "score": "71.65756"}
{"text": "With a tile size of 64 \u00d7 64 , there are 256 total tiles for an array size of 1024 \u00d7 1024 .For the hardware design , we can fit 16 computation pipelines in the FPGA , therefore , we can execute 16 tiles in parallel .", "label": "", "metadata": {}, "score": "71.68701"}
{"text": "We packetize and transmit each sequence in a message queue between PPE and SPEs .First , the manager and the workers all initialize the MCF network .Then , the PPE feeds the worker code into the local store memory of each SPE and signals them to start .", "label": "", "metadata": {}, "score": "71.736946"}
{"text": "Table 6 : Common resolutions , frame rates , and disparity ranges ( disparity range is computed with the same image sensor size ( 17.3 .m . m . , focal length ( 2.5 mm ) , distance between cameras ( 12 mm ) and image depth ( 0.5 m ) for each image resolution .", "label": "", "metadata": {}, "score": "71.78353"}
{"text": "In recent years , HLS has made significant advances in both the breadth of HLS compatible input source code and quality of the output hardware designs .Ongoing development of HLS has led to numerous industry and academia - initiated HLS tools [ 4 - 25 ] that can generate device - specific RTL descriptions from popular HLLs such as C , C++ , SystemC , CUDA , OpenCL , MATLAB , Haskell , and specialized languages or language subsets .", "label": "", "metadata": {}, "score": "71.80837"}
{"text": "a collective channel ( e.g. SPMC , MPSC ) implemented via SPSCs+mediator are sometime faster with respect to CAS - based implementation ( this really depends on the platform , parallelism degree and computation grain ) .Mediator thread makes it possible to easily program scheduling policy for both item distribution and gathering .", "label": "", "metadata": {}, "score": "71.85066"}
{"text": "The method according to . claim 5 , wherein the tasks are selectively scheduled for either out - of - order or speculatively while preserving correctness of a sequentially specified program including the tasks .The method according to . claim 5 , wherein the tasks are selectively scheduled for parallel , pipelined , or mixed execution .", "label": "", "metadata": {}, "score": "71.915985"}
{"text": "The throughput synchronized output data 295 can be fed through an explicit parallelization block 275 , or can be used as is in its reduced form .Either way both configurations provide the final network output 260 .This may reduce the I / O requirements of the network 200 in line with the ITER parameter .", "label": "", "metadata": {}, "score": "71.91603"}
{"text": "However , this situation creates a data hazard ( e.g. read before write data hazard ) .Data hazards refer to situations when the pipeline must be stalled to wait for another instruction to complete execution due to the coupling of data among these instructions .", "label": "", "metadata": {}, "score": "71.95368"}
{"text": "Euro - Par 2011 Parallel Processing , volume 6853 of LNCS , pages 170 - 181 , Bordeaux , France , Aug. 2011 .Springer .[ ADK12 ] M. Aldinucci , M. Danelutto , P. Kilpatrick , M. Meneghin , and M. Torquati .", "label": "", "metadata": {}, "score": "71.957855"}
{"text": "Berkeley Design Technology , Inc. ( BDTI ) [ 29 ] offers HLS tool certification program which evaluates the capabilities of HLS tools in terms of quality of results and usability .However , the evaluation workload focuses exclusively on the digital signal processing applications .", "label": "", "metadata": {}, "score": "71.98477"}
{"text": "11 illustrates an example schematic diagram of a portion of the internal structure of a layer of a network having a variable degree of parallelism in accordance with embodiments described herein ; .FIG .12 illustrates a further example schematic diagram of the internal structure of a hidden layer of a network having a variable degree of parallelism in accordance with embodiments described herein ; .", "label": "", "metadata": {}, "score": "72.01415"}
{"text": "Further example hardware devices include intelligent embedded sensors used in automotive and aerospace applications .The hardware device may also be used as a personal device such as a hearing device , a personal digital assistant , an iPod \u2122 , a videogame console , and a Blackberry \u2122 .", "label": "", "metadata": {}, "score": "72.04335"}
{"text": "switches allows to handle WiMAX standard various submatrix sizes .The implemented decoder guarantees a very high degree of flexibility with complexity lower or comparable to [ 36 , 63 - 65 ] .Networks - on - Chip .Networks - on - Chip ( NoCs ) [ 69 ] are versatile interconnection structures that allow communication among all the connected devices through the presence of routing elements .", "label": "", "metadata": {}, "score": "72.22046"}
{"text": "a plurality of processor cores or special hardware units for executing tasks ; . a control processor controlling tasks executed by the plurality of processor cores or special hardware units ; . a task dispatcher dispatching tasks to the plurality of processor cores or special hardware units according to scheduling by the control processor ; . a universal register file containing data to be processed by tasks executed by the plurality of processor cores or special hardware units ; and .", "label": "", "metadata": {}, "score": "72.27761"}
{"text": "The increasing availability of high - definition ( HD ) content and display options in the home is driving consumer expectations ever higher for video resolution on the handset .Whether movie trailers , music videos , or user - generated - content , consumers increasingly want , and expect their mobile devices to capture and playback HD video without adversely impacting battery life .", "label": "", "metadata": {}, "score": "72.35405"}
{"text": "When the ITER is above one , an input pattern is divided by ITER into equal segments .For example , for an ITER of 2 , an 11 input layer will be divided to 2 sets of 6 and 5 inputs .", "label": "", "metadata": {}, "score": "72.584175"}
{"text": "The goal here is to recall a set of weights during a pattern 's traversal of the feed - forward path which was generated by the completion of weight updates belonging to the same previously presented pattern across all layers .As a solution , in some embodiments the neuron 215 contains a pipeline buffer tuned to the latency ( as explained above ) of the forward and backward pipeline stages , as appropriate .", "label": "", "metadata": {}, "score": "72.604645"}
{"text": "As given in ( 4 ) , the CN update consists of sign update and magnitude update , where the latter depends on the type of decoding algorithm , of which several are commonly used ( Table 1 ) .The sum product ( SP ) algorithm [ 8 ] gives near - optimal results ; however , the implementation of the transcendental function .", "label": "", "metadata": {}, "score": "72.72862"}
{"text": "Figure 1 : Generalized datapath of LDPC Decoder .( a ) TPMP Decoding , ( b ) Layered Decoding .TPMP Datapath .In the TPMP structure depicted in [ 26 ] for a generic belief propagation algorithm , each VN consists of 4 dual port RAMs : I , Sa , Sb , and E , as shown in Figure 1(a ) .", "label": "", "metadata": {}, "score": "72.77311"}
{"text": "This solution gives us the best performance in our experiments .Blowfish and ADPCM can not be parallelized with the resource duplication optimization due to data dependency .Blowfish and adpcm process data block by block , with data processing serialized between blocks .", "label": "", "metadata": {}, "score": "72.78259"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. Flynn , \" Very high - speed computing systems , \" Proceedings of the IEEE , vol .54 , no .12 , pp .1901 - 1909 , 1966 .", "label": "", "metadata": {}, "score": "72.79228"}
{"text": "CatapultC [ 13 ] and ImpulseC [ 17 ] are two widely used industry HLS tools .CatapultC and ImpulseC use transformations similar to AutoPilot but with fewer total features .CatapultC supports C++/SystemC , with data array and loop pragmas , but no function or dataflow transformations .", "label": "", "metadata": {}, "score": "72.81775"}
{"text": "For a more complete understanding of the present invention , and the advantages thereof , reference is now made to the following descriptions taken in conjunction with the accompanying drawings , wherein like numbers designate like objects , and in which : .", "label": "", "metadata": {}, "score": "72.86224"}
{"text": "View at Google Scholar \u00b7 View at Scopus . Y. Liu , K. Benkrid , A. Benkrid , and S. Kasap , \" An FPGA - based web server for high performance biological sequence alignment , \" in Proceedings of the NASA / ESA Conference on Adaptive Hardware and Systems ( AHS ' 09 ) , pp .", "label": "", "metadata": {}, "score": "72.9359"}
{"text": "As an example consider a given layer that receives 10 inputs ( synapses ) from a previous layer .For the feed forward computation stage the portion 800 of the layer 205 / 210 shown receives input 300 ( fXi ) and control signals 810 ( address , write line ) , and provides an output vector containing output 235 from each neuron 215 .", "label": "", "metadata": {}, "score": "72.988686"}
{"text": "In most cases , AutoPilot can achieve this initiation interval .However , in some cases the computation on the inner loop requires multiple reads and/or writes from / to different addresses in the same BRAM .Thus , for these loops the initiation interval is longer to account for the latency of multiple independent BRAM reads / writes .", "label": "", "metadata": {}, "score": "73.17615"}
{"text": "FIGS . 1 and 2 , discussed below , and the various embodiments used to describe the principles of the present invention in this patent document are by way of illustration only and should not be construed in any way to limit the scope of the invention .", "label": "", "metadata": {}, "score": "73.18308"}
{"text": "15 represents network hardware for feed forward computations , and the bottom portion for back propagation computations .The input vector 300 is presented at fXi along with control signals 810 ( represented using dashed lines ) .The weighted sum module 310 is illustrated as a Parallel Multiply Accumulator ( PMAC ) .", "label": "", "metadata": {}, "score": "73.30104"}
{"text": "the . epoch .w . kj .s . )n . ) for .all . other . patterns . in .the . epoch .b . )That is , the out of order weight update rule is in tune with the degree of parallelization selected for the network implementation by updating the weights for use in the next ITER iteration .", "label": "", "metadata": {}, "score": "73.489174"}
{"text": "That is , the weight change module 325 determines the changes to the weights for the neuron 215 by multiplying the output from the previous layer ( i.e. the input vector 300 ) with the local gradients , and a learning rate .", "label": "", "metadata": {}, "score": "73.5533"}
{"text": "We noted the power meter reading , at steady state , when the Smith - Waterman algorithm was running .This includes two parts : an idle power component and a dynamic power component .The idle power component can be obtained from the power meter when the machine is in the idle state , which means that no Smith - Waterman algorithm implementation was running on it .", "label": "", "metadata": {}, "score": "73.68614"}
{"text": "The results are presented in Table 10 ( performance is expressed in Mega CUPS per watt ) .Table 10 : Performance per watt figures of the Smith - Waterman algorithm implementation on all four technologies .This again highlights the high energy efficiency of the FPGA solution , followed by Cell BE and GPU .", "label": "", "metadata": {}, "score": "73.729385"}
{"text": "o . k . s . ) s .M .j .N .s .w . jk .s .j .s .s .M . where .w jk ( s+1 ) synaptic weight of neuron j in the ( s+1 ) layer , associated with the output of current neuron k. .", "label": "", "metadata": {}, "score": "73.85127"}
{"text": "FIG .20 .At step 910 a desired network topology and information relating to hardware resources available for one or more hardware devices 1005 is provided to the system 1000 and received by input module 1010 .The desired network topology provides the number of inputs , neurons in the hidden layer(s ) , and neurons in the outer layer .", "label": "", "metadata": {}, "score": "73.95548"}
{"text": "It should be noted that the functionality associated with any particular controller may be centralized or distributed , whether locally or remotely .Definitions for certain words and phrases are provided throughout this patent document , and those of ordinary skill in the art will understand that such definitions apply in many , if not most , instances to prior as well as future uses of such defined words and phrases .", "label": "", "metadata": {}, "score": "74.019066"}
{"text": "A 9 - 10 - 2 network topology is used for simulations .SIN problem : This is a function approximation problem .One period of the sine wave is generated by using 13 equidistant points in [ 0 , 2\u03c0 ) range .", "label": "", "metadata": {}, "score": "74.0446"}
{"text": "For matrix multiplication , one of the stringent resources is on - chip BRAM .Before tiling , the estimated number of required BRAMs is 5595 for 1024 \u00d7 1024 arrays , which is too big to fit into the FPGA .", "label": "", "metadata": {}, "score": "74.159546"}
{"text": "The backward data flow in the neuron 215 consists of the weights 860 ( bWi ) , input data 300 ( bXi ) vector , gradient 865 ( bOi ) .There is also shown the corresponding address ( bAi ) and a write enable line ( bWei ) 810 ( controls ) which differentiates between testing and training passes .", "label": "", "metadata": {}, "score": "74.31795"}
{"text": "The control processor schedules tasks according to control threads for the tasks created during compilation and comprising a hardware context including register files , a program counter and status bits for the respective task .The tasks are dispatched to the processor cores or special hardware units for parallel , sequential , out - of - order or speculative execution .", "label": "", "metadata": {}, "score": "74.43738"}
{"text": "Referring now to .FIG .1 there is shown an example diagram of a MLP - BP network 100 containing neurons 105 numbered 1 to N structured in a plurality of parallel layers 110 numbered 0 to M. When implementing the BP algorithm , each neuron 105 contains two key arithmetic functions that perform forward and backward computations .", "label": "", "metadata": {}, "score": "74.48317"}
{"text": "For this approximation scheme , the transfer function module 320 implements an approximation calculation summarized in Equations ( 9,10 ) below .f .x . ) x .x .x .x .x .x .x .x .", "label": "", "metadata": {}, "score": "74.5417"}
{"text": "Finally , Section 6 draws the conclusions .LDPC Decoding .Introduction .LDPC codes [ 5 ] are a special class of linear block codes .A binary LDPC code is represented by a sparse parity check matrix .If the number of edges entering in a node is constant for all nodes of the graph , the LDPC code is called regular , being otherwise irregular in case of variable node degree .", "label": "", "metadata": {}, "score": "74.68594"}
{"text": "9 illustrates a schematic diagram of an example network having a variable degree of parallelism in accordance with embodiments described herein ; .FIG .10 illustrates an example schematic diagram of the internal structure of a layer of a network having a variable degree of parallelism in accordance with embodiments described herein ; .", "label": "", "metadata": {}, "score": "74.83147"}
{"text": "Recall that we perform data tiling to matrix multiplication .In our experiments , we explore different tile sizes ( 8 \u00d7 8 , 16 \u00d7 16 , 32 \u00d7 32 , 64 \u00d7 64 , and 128 \u00d7 128 ) .", "label": "", "metadata": {}, "score": "74.9712"}
{"text": "In Proc . of 18thIntl .Euro - Par 2012 Parallel Processing , volume 7484 of LNCS , pages 662 - 673 , Rhodes Island , Greece , aug 2012 .Springer .ffnamespace / architecture . txt \u00b7 Last modified : 2014/09/12 19:06 by aldinuc A hyperprocessor includes a control processor controlling tasks executed by a plurality of processor cores , each of which may include multiple execution units , or special hardware units .", "label": "", "metadata": {}, "score": "75.03419"}
{"text": "Therefore , we use the array_map pragma to map the arrays together into a single array that is stored in a single BRAM .It is important to note that AutoPilot provides one powerful BRAM optimization - array streaming .The array stream pragma converts data arrays that are accessed in FIFO order into smaller , fixed - size buffers ( significantly reducing BRAM use ) , and also allows dataflow optimizations which overlap computation of multiple RTL blocks in the same manner as pipelining does on smaller computation units .", "label": "", "metadata": {}, "score": "75.58702"}
{"text": "The outputs of the neurons 215 in the outer layer 210 are synchronized together with the transfer function derivative 840 , according to the degree of parallelism ITER selected at synthesis .The serialized outputs 295 ( network output 260 ) and transfer function derivatives 840 are passed to the pHdelta module 830 , together with the serialized target vector .", "label": "", "metadata": {}, "score": "75.68242"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Google Scholar .Synopsys , \" Synthesizing Algorithms from MATLAB and Model - based Descriptions .Introduction to Synphony HLS White pape \" .Altera , \" Nios II C - to - Hardware ( C2H ) Compiler \" .", "label": "", "metadata": {}, "score": "75.741196"}
{"text": "Curtis - Maury , Matthew and Blagojevic , Filip and Antonopoulos , Christos and Nikolopoulos , Dimitrios ( 2007 ) Prediction - based Power - Performance Adaptation of Multithreaded Scientific Codes .Technical Report TR-07 - 21 , Computer Science , VT .", "label": "", "metadata": {}, "score": "75.7484"}
{"text": "View at Google Scholar \u00b7 View at Scopus .K. Benkrid , Y. Liu , and A. Benkrid , \" A highly parameterized and efficient FPGA - Based skeleton for pairwise biological sequence alignment , \" IEEE Transactions on Very Large Scale Integration ( VLSI ) Systems , vol .", "label": "", "metadata": {}, "score": "75.77356"}
{"text": "Depending on the given level of parallelism , all inputs 300 to a layer 205 / 210 can be applied in parallel , or in portions over several ITER cycles .In this example , these inputs 300 are distributed to all neurons 215 via neuron inputs 230 using a limited width bus , which has the necessary width to carry only the necessary number of inputs 230 to accommodate a given level of parallelism .", "label": "", "metadata": {}, "score": "75.782394"}
{"text": "As will be explained herein each neuron 215 is implemented with sufficient hardware in order to process a given number of inputs proportional to the given degree of parallelism .A valid output vector consisting of the individual neuron 215 outputs 235 is generated by the layer 205 / 210 for all neurons 215 every ITER number of clock cycles .", "label": "", "metadata": {}, "score": "75.8827"}
{"text": "Multicore .Implementation - wise , a ff_node is a C++ object that is mapped onto a OS thread ( POSIX or OS native threads ) .Typically ff_nodes have a nonblocking behaviour , i.e. do not suspend on pushing or popping messages from channels .", "label": "", "metadata": {}, "score": "75.91786"}
{"text": "As a result of all layers 205 / 210 being throughput synchronized by the synchronization blocks 220 using the same ITER parameter , the inputs 240 / 245 to the EBP modules 225 are carried backward in a format that is already correctly reduced in width .", "label": "", "metadata": {}, "score": "75.93361"}
{"text": "Over - fit occurs during training when input patterns of a limited dataset are presented too many times , and the network has more free parameters than needed .This results in a network that is capable of recognizing previously seen patterns very well , but fails to produce a good generalization to predict outcomes for some or all of the remainder of possible different input patterns .", "label": "", "metadata": {}, "score": "76.02751"}
{"text": "The mobile phone has become an all - purpose portable media player device .Carried everywhere to enable constant consumer access to voice communications , even low - cost mobile phones have incorporated audio player , video camcorder and other features to create an always available multi - purpose multimedia device .", "label": "", "metadata": {}, "score": "76.17772"}
{"text": "Note that , in this case , the gradient 865 calculation is external to the neuron 215 .Shift registers 825 are required to align the data correctly as inputs to various pipelined hardware modules .The shift registers 825 are represented with a single Z symbol .", "label": "", "metadata": {}, "score": "76.210236"}
{"text": "13 illustrates a further example schematic diagram of the internal structure of an outer layer of a network having a variable degree of parallelism in accordance with embodiments described herein ; .FIG .14 illustrates an example schematic diagram of the internal structure of a neuron of a network having a variable degree of parallelism in accordance with embodiments described herein ; .", "label": "", "metadata": {}, "score": "76.22461"}
{"text": "680 - 683 , May 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .S. Gupta , N. Dutt , R. Gupta , and A. Nicolau , \" SPARK : a high - lev l synthesis framework for applying parallelizing compiler transformations , \" in Proceedings of the International Conference on VLSI Design , p. 461 , Los Alamitos , Calif , USA , 2003 .", "label": "", "metadata": {}, "score": "76.261284"}
{"text": "11 ) , a synchronization block 220 ( e.g. biased serializer in this example ) , pHdelta module 830 , and another synchronization block 835 ( e.g. a deserializer in this example ) .The biased serializer 220 takes a parallel number of inputs from neurons 215 and multiplexes them into a narrower synchronized bus of ITER number of parts .", "label": "", "metadata": {}, "score": "76.378975"}
{"text": "ITER .A neuron 215 generally has a weighted sum module 310 , a weight memory 315 , and a transfer function module 320 for performing the feed forward calculations .The weight memory 315 may include one or a plurality of physical weight memories .", "label": "", "metadata": {}, "score": "76.38382"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Zhang , K. Zhang , T. S. Chang , G. Lafruit , G. K. Kuzmanov , and D. Verkest , \" Real - time high - definition stereo matching on FPGA , \" in Proceedings of the 19th ACM / SIGDA International Symposium on Field - Programmable Gate Arrays , pp .", "label": "", "metadata": {}, "score": "76.42204"}
{"text": "First , tiling enables us to do a complete loop unrolling for the inner most loop computation within one tile as the loop bounds are smaller compared to the original version .Second , tiling reduces the BRAM usage for one tile , thus we can parallelize the computations of multiple tiles by instantiating multiple pipelines .", "label": "", "metadata": {}, "score": "76.550644"}
{"text": "Unlike [ 63 ] , the starting point of the design is the nonoptimized .BeN : from here all the switches are removed where no signal is passed , whereas switches with fixed output are replaced by wires .This adhoc trimming technique , together with an efficient algorithm for control signal creation , allow a 26.6%-71.1 % area reduction with respect to previously published shift network solutions like [ 27 , 55 , 66 ] .", "label": "", "metadata": {}, "score": "76.570435"}
{"text": "Referring to .FIG .17 there is shown a graph of synthesis results in terms of slices 380 consumed when using various arithmetic representations in a fully parallel network with 5 - 5 - 2 topology .The various arithmetic representations include : fixed point integer with 5 bits 390 , fixed point integer with 4 bits 385 , and fixed point integer with 3 bits 395 .", "label": "", "metadata": {}, "score": "76.658966"}
{"text": "In wireline communication domain , LDPC codes are adopted in 10 Gbit Ethernet copper ( 10GBASE - T ) standard which specifies a high code rate LDPC code with a fixed code length of 2048 bits , with a very high decoding throughput of 6.4 Gbps .", "label": "", "metadata": {}, "score": "76.68725"}
{"text": "The resource utilization of the kernels are low due to their small size .The utilization for LUT is from 1 % to 28 % .FF utilization ranges from 1 % to 20 % .For all the kernels except MM , the required BRAM usage is very small because the array sizes are small and are successfully completely partitioned .", "label": "", "metadata": {}, "score": "76.737335"}
{"text": "As noted above , these processors 104 need not be homogenous , but instead may be two or more of several different processors or may comprise just specific hardware for one function .As the execution units 109 are subunits within the processor 104 , each processor 104 is itself a subunit in the hyperprocessor 100 , as shown .", "label": "", "metadata": {}, "score": "77.08302"}
{"text": "After CN update is finished for one block row , the results are immediately used to update the VNs , whose results are then used to update the next layer of check nodes .Therefore , an updated information is available to CNs at each subiteration .", "label": "", "metadata": {}, "score": "77.11951"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .J. Dielissen , A. Hekstra , and V. Berg , \" Low cost LDPC decoder for DVB - S2 , \" in Proceedings of the Design , Automation and Test in Europe ( DATE ' 06 ) , vol .", "label": "", "metadata": {}, "score": "77.35887"}
{"text": "Best DE value is held by the DVB - S2 decoder presented in [ 30 ] , together with an average TAR .Explicitly enabling the decoding of just 20 codes , however , lowers its FE measure .Among serial PE - based run time flexible solutions discussed above , the work in [ 34 ] achieves very high throughput , TAR and DE with a small area occupation of 2.46 mm 2 , yielding the best FE of all decoders .", "label": "", "metadata": {}, "score": "77.64414"}
{"text": "The width of all these buses is the same , and coincides with the number of inputs ( n ) , including bias , for the layer .There is also shown an accumulator unit 880 ( optional ) which eliminates the one cycle latency between reading a weight and writing its update .", "label": "", "metadata": {}, "score": "77.82239"}
{"text": "Artificial Neural Networks are devices intended to simulate or mimic the behaviour of the network of neurons that exist in the human brain .Artificial neural networks generally consist of one or more layers containing neurons .The neural network is trained by presenting known data at an input and then testing the actual output against the desired output ( training data ) and adjusting the neural network accordingly .", "label": "", "metadata": {}, "score": "77.92113"}
{"text": "However , threads running in the SMs are restricted to read only access to these memories .The host CPU , on the other hand , does have write access to these memories .The Cell BE Platform .For the purpose of our Cell BE - based implementation , we used an IBM IntelliStation Z Pro Workstation with a Cell Acceleration Board ( CAB ) .", "label": "", "metadata": {}, "score": "77.98654"}
{"text": "High - Level Synthesis : Productivity , Performance , and Software Constraints . 1 Advanced Digital Sciences Center , 1 Fusionopolis Way , No . 08 - 10 Connexis North Tower , Singapore 138632 2 Department of Electrical and Computer Engineering , University of Illinois at Urbana - Champaign , Urbana , IL 61801 , USA .", "label": "", "metadata": {}, "score": "78.00185"}
{"text": "17 illustrates an example graph of synthesis results for a fully parallel network having a 5 - 5 - 2 topology in terms of slices consumed when using various arithmetic representations ; .FIG .18 illustrates an example graph of synthesis results for a fully serial network having a 5 - 5 - 2 topology in terms of slices consumed when using various arithmetic representations ; .", "label": "", "metadata": {}, "score": "78.05201"}
{"text": "FIG .7 there is shown a schematic diagram of an example architecture of a scalable ANN 700 in accordance with embodiments described herein .The scalable ANN architecture 700 has an input layer 250 , at least one hidden layer 205 and an output layer 210 .", "label": "", "metadata": {}, "score": "78.12423"}
{"text": "In stage 2 : cycle 2 , the other half is issued .In this case , there is a time between stage 1 : cycle 2 and stage 2 : cycle 1 needed to process the pattern through stage 1 , thus stage 1 : cycle 2 and stage 2 : cycle 1 are not consecutive clock cycles .", "label": "", "metadata": {}, "score": "78.35018"}
{"text": "References .[ Lam74 ] L. Lamport .A new solution of dijkstra 's concurrent programming problem .Commun .ACM , 17(8):453 - 455 , 1974 .[Lam83 ] L. Lamport .Specifying concurrent program modules .ACM Trans .", "label": "", "metadata": {}, "score": "78.41615"}
{"text": "FIG .18 there is shown a graph of synthesis results in terms of slices 405 consumed when using various arithmetic representations in a fully serial network with 5 - 5 - 2 topology .The various arithmetic representations include : fixed point integer with 5 bits 410 , fixed point integer with 4 bits 415 , and fixed point integer with 3 bits 420 .", "label": "", "metadata": {}, "score": "78.46474"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . S. S. Huang , A. Hormati , D. F. Bacon , and R. Rabbah , \" Liquid metal : object - oriented programming across the hardware / software boundary , \" in Proceedings of the European Conference on Object - Oriented Programming , pp .", "label": "", "metadata": {}, "score": "78.468445"}
{"text": "Referring now to .FIG .2 there is shown examples of three types of hardware parallelism for ANN computations .Black colored components represent active components while gray colored represent inactive components .FIG .2 ( a ) illustrates an example of node parallelism , where a synapse 130 simultaneously provides input to all nodes 140 .", "label": "", "metadata": {}, "score": "78.477844"}
{"text": "Finally , it is worth mentioning that , currently , our query lengths are limited to 1024 residues , but we are working on some indexing strategies which will allow us to increase the length of a query .Figure 12 : Illustration of the Smith - Waterman calculation on the Cell BE .", "label": "", "metadata": {}, "score": "78.60281"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. Alles , N. Wehn , and F. Berens , \" A synthesizable IP core for WiMedia 1.5 UWB LDPC code decoding , \" in Proceedings of the IEEE International Conference on Ultra - Wideband ( ICUWB ' 09 ) , pp .", "label": "", "metadata": {}, "score": "78.68205"}
{"text": "2 .The first stage includes a control store 201 , which disburses tasks or operations to the second stage and receives branching control signals from the second stage .The second stage is occupied by a fetch / branch unit 202 , a decode unit 203 , and a K - table unit 204 .", "label": "", "metadata": {}, "score": "78.792206"}
{"text": "Code Restructuring .For the embedded benchmark kernels we perform various code restructuring transformations including data tiling and block merging .For matrix multiplication , we perform data tiling to the source code since the array size is too big to fit into the BRAM of FPGA .", "label": "", "metadata": {}, "score": "79.05934"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . D. Scharstein , R. Szeliski , and R. Zabih , \" A taxonomy and evaluation of dense two - frame stereo correspondence algorithms , \" in Proceedings of the IEEE Workshop on Stereo and Multi - Baseline Vision , p. 0131 , 2001 .", "label": "", "metadata": {}, "score": "79.12998"}
{"text": "View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .C. Zhang , Z. Wang , J. Sha , L. Li , and J. Lin , \" Flexible LDPC decoder design for multigigabit - per - second applications , \" IEEE Transactions on Circuits and Systems I : Regular Papers , vol .", "label": "", "metadata": {}, "score": "79.458206"}
{"text": "FPGAs achieved 4.6x more performance for each $ spent and 584x more performance for each Watt consumed , compared to GPPs .The IBM Cell BE came second as it achieved 2.3x more performance for each $ spent and 31x more performance for each Watt consumed , compared to CPUs .", "label": "", "metadata": {}, "score": "79.75695"}
{"text": "Referring now to .FIG .15 there is shown another example schematic diagram of the hardware structure of each individual neuron 215 capable of implementing variable degrees of parallelism in accordance with embodiments described herein .The top portion of the schematic in .", "label": "", "metadata": {}, "score": "80.00833"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .T. Meltzer , C. Yanover , and Y. Weiss , \" Globally optimal solutions for energy minimization in stereo vision using reweighted belief propagation , \" in Proceedings of the 10th IEEE International Conference on Computer Vision , vol .", "label": "", "metadata": {}, "score": "80.074814"}
{"text": "At the layer level , the error back propagation stage is comprised of the error back propagation module 305 ( i.e. EBP module 225 ) which receives error data , or an error gradient vector .The error back propagation module 305 generally implements the above equation ( 3 ) and equation ( 4 ) in order to generate an error term and a local gradient for each of its neurons 215 .", "label": "", "metadata": {}, "score": "80.0977"}
{"text": "FIG .13 there is shown a detailed example hardware diagram of the internal structure of an outer layer 210 of a network 200 capable of implementing a variable degree of parallelism in accordance with embodiments described herein .The outer layer 210 contains : the neuron portion 800 , a synchronization block 220 ( e.g. a serializer in this example ) , pHdelta module 830 , and another synchronization block 835 ( e.g. a deserializer 835 in this example ) .", "label": "", "metadata": {}, "score": "80.12674"}
{"text": "i .ITER .N .o .N .h .ITER .N .o .ITER .N .o .N .h .ITER .Where : .N i -number of inputs .N h -number of hidden neurons .", "label": "", "metadata": {}, "score": "80.13219"}
{"text": "3 ) Neuron Level .Referring now to .FIG .14 there is shown an example diagram of the structure of each individual neuron 215 capable of implementing a variable degree of parallelism in accordance with embodiments described herein .The number of synthesized inputs 300 ( herein par ) feeding a neuron 215 is selected using the number of synthesized synapses .", "label": "", "metadata": {}, "score": "80.17059"}
{"text": "There are two types of gap penalties , known as linear gaps and affine gaps .The linear gap is a simple model with constant gap penalty ( .An Affine gap has opening and extension penalties .The constant penalty for opening a gap is normally bigger than the penalty for extending a gap , which is more biologically realistic as few gaps are as frequent as a single gap in practice .", "label": "", "metadata": {}, "score": "80.54353"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . Y. Hara , H. Tomiyama , S. Honda , and H. Takada , \" Proposal and quantitative analysis of the CHStone benchmark program suite for practical C - based high - level synthesis , \" Journal of Information Processing , vol .", "label": "", "metadata": {}, "score": "80.734184"}
{"text": "The transfer function module 320 provides the neuron output 235 .Two dual port memories are used as weight memory 315 ; both are updated simultaneously to synchronize their contents , to overcome the above mentioned data hazard problem .One dual port memory has port A to read current weights for the forward data flow and port B to write updated weights ( following back propagation ) in the same clock cycle .", "label": "", "metadata": {}, "score": "81.257645"}
{"text": "Some of the directives ( as denoted in Table 3 ) can also be applied to arbitrary sections of code labeled and enclosed by curly brackets .This allows the programmer to guide AutoPilot 's pipelining and expression balancing optimizations to reduce the optimization space .", "label": "", "metadata": {}, "score": "81.56049"}
{"text": "The IBM Cell BE is essentially a distributed memory , multiprocessing system on a single chip ( see Figure 5 ) .All these elements are connected with an on - chip Element Interconnect Bus ( EIB ) .The first level instruction and data cache on the PPE are 32 KB and the level 2 cache is 512 KB .", "label": "", "metadata": {}, "score": "81.64477"}
{"text": "n .ITER . )[ .w . kj .s . )n . ) w . kj .s . )n . latency . ) epoch .If . the .n .ITER . is .the .", "label": "", "metadata": {}, "score": "82.075424"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus Data Field Haskell .The continuing advances in semiconductor and hardware technology are leading to a situation where transistors are free and communication costly .This will make parallel systems - on - a - chip standard .", "label": "", "metadata": {}, "score": "82.48689"}
{"text": "This work gives an overview of the most remarkable techniques in context of flexible channel decoding .We will discuss design and implementation of two major functional blocks of flexible decoders : processing element ( PE ) and interconnection structure .Various design choices are analyzed in terms of achieved flexibility , performance , design novelty , and area ( power ) consumption .", "label": "", "metadata": {}, "score": "82.667816"}
{"text": "The number of inputs ( par ) determines the width of the weighted sum module 310 .If more than one cycle is required to calculate the weighted input sum , the result of partial weighted sums are accumulated over the ITER number of cycles required to complete the calculation .", "label": "", "metadata": {}, "score": "82.85559"}
{"text": "The FastFlow SPSC queue implementation is largely inspired by Fastforward queues [ GMV08].As with Fastforward queues , the push operation ( issued by the producer ) always reads and writes pwrite ( i.e. tail pointer ) only , and the pop ( issued by the consumer ) always reads and writes pread ( i.e. head pointer ) only .", "label": "", "metadata": {}, "score": "83.6147"}
{"text": "That is , the weight change module 325 reads the currents weights from the weight memory 315 and updates them using the received weight changes .These updated weights are then stored in the weight memory 315 for recall .In some embodiments where pipelining is used , the weight update module 325 implements the above Equation ( 7a ) or ( 7b ) , depending on the training technique , instead of Equation ( 6 ) , in order provide out of order weight update .", "label": "", "metadata": {}, "score": "84.07932"}
{"text": "The Cell BE uses two schemes to transfer data between the DRAM and the SPEs : ( 1 ) message queue and ( 2 ) direct memory access ( DMA ) .In the message queue mode , the PPE reads the data from the DRAM , packetizes the data , and places packets into the message queue for the target SPE to read .", "label": "", "metadata": {}, "score": "84.18501"}
{"text": "For these access patterns , sharing the same physical BRAM does not result in additional read or write latency .Therefore , for such arrays , we use array_map to combine the arrays and share physical BRAMs .For example , in Figure 3 , we show code extracted from BFAS ; there are 4 parameter arrays with 101 entries each that are used in only one function in synchronized order .", "label": "", "metadata": {}, "score": "84.2351"}
{"text": "The number of neurons 215 in the layer 205 / 210 corresponds to the size of each layer of the scalable network topology , or the size of each layer of the desired network topology divided by the given degree of parallelism .", "label": "", "metadata": {}, "score": "85.08997"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . E. Tola , V. Lepetit , and P. Fua , \" DAISY :An efficient dense descriptor applied to wide - baseline stereo , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}, "score": "85.38289"}
{"text": "2 ( b ) illustrates an example of synapse parallelism , where all synapses 130 simultaneously provide input to a node 140 .FIG .2 ( c ) illustrates an example of node and synapse parallelism , where all synapses 130 simultaneously provide input to all nodes 140 .", "label": "", "metadata": {}, "score": "85.60628"}
{"text": "As is shown in .FIG .6 , patterns for new epochs 190 , such as for example an epoch 190 with patterns 5 - 8 , are continuously presented to the network .The back propagation stream 190 of weight updates propagates at the same time as the stream of new patterns through the feed forward stage 185 .", "label": "", "metadata": {}, "score": "85.63778"}
{"text": "FIG .12 , there is shown an example hardware diagram of the internal structure of a hidden layer 205 of a network 200 capable of implementing a variable degree of parallelism in accordance with embodiments described herein .The hidden layer 205 contains : the internal portion 800 ( .", "label": "", "metadata": {}, "score": "85.974045"}
{"text": "FIG .1 .However , for simplicity only one hidden layer 110 and one output layer 110 will be used to explain the example embodiments .Note that the input layer 110 does not typically contain neurons 105 and instead comprises the input pattern(s ) 115 used to train the network 100 , and as such the input layer 110 ( layer 0 ) functions somewhat differently than layers 1 to M. The output layer 110 , or the last layer M in the network 100 , provides the network output 125 .", "label": "", "metadata": {}, "score": "86.86069"}
{"text": "Referring now to .During stage 1 : cycle 1 , half of the input vector 170 is issued to the hidden layer 155 .In stage 1 : cycle 2 , the other half of the input vector 170 is issued .", "label": "", "metadata": {}, "score": "87.06295"}
{"text": "The address determines which virtual network this input 250 belongs .As the data propagates through the hardware , the virtual network 200 specified effectively gets trained ( or accessed during recall ) on the input pattern 250 and output 260 /target 255 combination .", "label": "", "metadata": {}, "score": "88.09765"}
{"text": "If a training epoch for a given virtual network 200 consists of more than one pattern 250 , all patterns 250 within this epoch are presented together as well .A different virtual network 200 can be accessed for every epoch presented during training , or every pattern 200 tested during recall .", "label": "", "metadata": {}, "score": "88.78842"}
{"text": "122 comments Architecture , system and method for artificial neural network implementation US 8103606 B2 .Abstract .In a particular case , the architecture includes a back - propagation subsystem that is configured to adjust weights in the scalable artificial neural network in accordance with the variable degree of parallelization .", "label": "", "metadata": {}, "score": "88.856415"}
{"text": "The updated weight must then be written back to memory ( weight memory 315 ) at the same time as the next weight is read for the next update cycle .A write - through memory configuration is selected for the weight memory 315 since the weight that is read in one cycle must be equal to the updated weight from the previous cycle .", "label": "", "metadata": {}, "score": "88.97468"}
{"text": "The implicit or explicit synchronization 270 is also a component of the parallelization system 710 .The former configuration relating to the synchronized data stream requires some form of implicit data set decomposition 265 / 270 in order to implicitly partition both the input vector 250 and target vector 255 into ITER number of parts either before a training session or at run - time .", "label": "", "metadata": {}, "score": "89.338844"}
{"text": "The second dual port memory of the weight memory 315 recalls the weight to the weight update module 315 via port A and updates the weight change via port B. .B. Pipeline Implementation .According to another aspect , the embodiments described herein provide a customized scalable network that is pipelined .", "label": "", "metadata": {}, "score": "89.40219"}
{"text": "Each network layer 205 / 210 has multiple neurons 215 in a full neuron parallelism configuration and a throughput or synchronization block 220 .Each synchronization block 220 is a component of the parallelization subsystem 710 .The synchronization blocks 220 translate the parallel outputs 235 from neurons 215 in one layer 205 / 210 into a synchronized sequence 295 ( i.e. serialized feed forward data ) appropriate for input 230 to neurons 215 in the next layer 205 / 210 .", "label": "", "metadata": {}, "score": "89.73806"}
{"text": "A forall construct , similar to lambda - abstraction , can be used to define data fields in a succinct and generic manner .The current version of DFH extends Haskell 98 .Its implementation is a modified version of nhc98 pre - release 19 ( 2000 - 06 - 05 ) , originally from the functional programming group at York .", "label": "", "metadata": {}, "score": "90.2086"}
{"text": "317 MHz .227 MHz .227 MHz .Virtex 5 .397 MHz .361 MHz .361 MHz .Comparison with Commercial and Research ANN Hardware Accelerators .Using CUPS as a measurement term , these results may be compared to some recent commercial and research efforts to build hardware accelerators for ANN computation and particularly MLP - BP .", "label": "", "metadata": {}, "score": "90.47798"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .J. Lin , Z. Wang , L. Li , J. Sha , and M. Gao , \" Efficient shuffle network architecture and application for WiMAX LDPC decoders , \" IEEE Transactions on Circuits and Systems II : Express Briefs , vol .", "label": "", "metadata": {}, "score": "90.479706"}
{"text": "This relates to the classification of three iris plant varieties using lengths and widths of petals and sepals taken from 150 samples of the flower .Fifty samples / patterns belong to each of the classes .A 4 - 2 - 3 network topology is used for simulations .", "label": "", "metadata": {}, "score": "90.51935"}
{"text": "Weight .f .ITER .Where f is the expected operational clock frequency .As such , network performance in terms of CUPS may be estimated using the network topology ( which is used to calculate the number of weights ) , the ITER value , and clock frequency ( rate ) .", "label": "", "metadata": {}, "score": "91.6272"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus High Performance Biological Pairwise Sequence Alignment : FPGA versus GPU versus Cell BE versus GPP . 1 Institute of Integrated Systems , School of Engineering , The University of Edinburgh , Kings Buildings , Mayfield Road , Edinburgh EH9 3JL , UK 2 Electrical and Computer Engineering Department , The University of Arizona , Tucson , AZ 85721 - 0104 , USA .", "label": "", "metadata": {}, "score": "92.10182"}
{"text": "The input vector 250 for network 200 undergoes implicit or explicit synchronization 265 in order to provide a synchronized sequence 295 appropriate for input 230 to the neurons 215 of the first hidden layer 205 of the network 100 .The implicit or explicit synchronization 265 is also a component of the parallelization system 710 .", "label": "", "metadata": {}, "score": "92.88127"}
{"text": "The biased serializer 220 uses a serialized input port of a narrow width and converts it into one wide parallel output port .The final output 295 is double buffered and is updated once every ITER number of cycles to correspond to the first clock cycle of a set of patterns representing one full neuron output vector of data .", "label": "", "metadata": {}, "score": "93.0264"}
{"text": "Where : .N i -number of inputs .N h -number of hidden neurons .N o -number of output neurons .Since a network can update its weights once each ITER number of cycles , the network performance measurement in CUPS can be calculated by the following equation ( 14 ) : .", "label": "", "metadata": {}, "score": "94.23532"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .W. R. Pearson and D. J. Lipman , \" Improved tools for biological sequence comparison , \" Proceedings of the National Academy of Sciences of the United States of America , vol . 85 , no . 8 , pp .", "label": "", "metadata": {}, "score": "94.63043"}
{"text": "The synchronization blocks 220 generate the synchronized sequence 295 using the received output for input to the next layer at every clock cycle .That is , one parallel output is provided to the synchronization block 220 every ITER cycles , which is partitioned into one synchronized output consisting of ITER number of ( almost ) equal chunks to be provided to neurons 215 of the next layer over ITER number of cycles .", "label": "", "metadata": {}, "score": "96.32889"}
{"text": "Department of Electronics and Telecommunications , Politecnico di Torino , 10129 Torino , Italy .Received 4 November 2011 ; Revised 14 February 2012 ; Accepted 22 February 2012 .Academic Editor : Amer Baghdadi .Copyright \u00a9 2012 Muhammad Awais and Carlo Condo .", "label": "", "metadata": {}, "score": "96.98312"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . Y. L. Wang , Y. L. Ueng , C. L. Peng , and C. J. Yang , \" Processing - task arrangement for a low - complexity full - mode WiMAX LDPC codec , \" IEEE Transactions on Circuits and Systems I : Regular Papers , vol .", "label": "", "metadata": {}, "score": "100.34498"}
{"text": "The weight memory 315 holds the weights associated with the neuron .The size and width of the weight memory is determined by the number of inputs 300 , or par .The weight memory 315 has a read port in connection with the input of the weighted sum module 310 for weight recall .", "label": "", "metadata": {}, "score": "103.30195"}
{"text": "Academic Editor : Kiyoung Choi .Copyright \u00a9 2012 Yun Liang et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "108.9449"}
{"text": "Academic Editor : Kentaro Sano .Copyright \u00a9 2012 Khaled Benkrid et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "113.319824"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus", "label": "", "metadata": {}, "score": "139.97571"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .", "label": "", "metadata": {}, "score": "142.46906"}
