{"text": "We present LDA - SP , which utilizes LinkLDA ( Erosheva et al ., 2004 ) to model selectional preferences .By simultaneously inferring latent topics and topic distri ... \" .The computation of selectional preferences , the admissible argument values for a relation , is a well - known NLP task with broad applicability .", "label": "", "metadata": {}, "score": "27.617527"}
{"text": ", 2004 ) to model selectional preferences .By simultaneously inferring latent topics and topic distributions over relations , LDA - SP combines the benefits of previous approaches : like traditional classbased approaches , it produces humaninterpretable classes describing each relation 's preferences , but it is competitive with non - class - based methods in predictive power .", "label": "", "metadata": {}, "score": "27.677124"}
{"text": "In the clinical domain , Arnold et al .[28 ] used LDA for comparing patient notes based on topics .A topic model was learned for different cohorts , with the number of topics derived experimentally based on log - likelihood fit of the created model to a test set .", "label": "", "metadata": {}, "score": "31.861193"}
{"text": "This is similar to the approach used by Arnold et al .( 2010 ) [ 28 ] and is accepted as a method for comparing LDA performance [ 54 ] .The topic models were learned using the Collapsed Gibbs Sampler provided in Mallet [ 55 ] with the recommended parameters and with hyper - parameter optimization as described in Wallach et al .", "label": "", "metadata": {}, "score": "32.002678"}
{"text": "LDA reduces the complex process of producing a document into a small number of simple probabilistic steps and thus specifies a probability distribution over all possible documents .Using standard statistical techniques , one can invert the process and infer the set of latent topics responsible for generating a given set of documents [ 15 ] .", "label": "", "metadata": {}, "score": "32.53172"}
{"text": "( Blei \" Introduction \" 84 ) .Blei stages topic modeling as an ex post facto method for challenging our assumptions about natural language data .In other words , once a collection has been created , LDA can test our assumptions about what topics are discoverable .", "label": "", "metadata": {}, "score": "32.896168"}
{"text": "We also evaluate LDA - SP 's effectiveness at filtering improper applications of inference rules , where we show substantial improvement over Pantel et al . 's system ( Pantel et al . , 2007 ) . by Hui Lin , Jeff Bilmes - IN THE 49TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS : HUMAN LANGUAGE TECHNOLOGIES ( ACL - HLT , 2011 . \" ...", "label": "", "metadata": {}, "score": "33.469734"}
{"text": "I reviewed the simple assumptions behind LDA and the potential for the larger field of probabilistic modeling in the humanities .Probabilistic models promise to give scholars a powerful language to articulate assumptions about their data and fast algorithms to compute with those assumptions on large archives .", "label": "", "metadata": {}, "score": "34.255913"}
{"text": "Are there such known limitations of LDA ?Some reference including a ... .I want to use a neural network to do some topic analysis in a textual corpus .I have used neural networks before where there is a clear decision boundary between the category to which some observation ... .", "label": "", "metadata": {}, "score": "34.28458"}
{"text": "We outperform text - only models in two different evaluations , and demonstrate that low - level visual features are directly compatible with the existing model .( 2 ) We present a novel way to integrate visual features into the LDA model using unsupervised clusters of images .", "label": "", "metadata": {}, "score": "34.77732"}
{"text": "I have performed LDA using the topicmodels package in R. I have a dataset containing user activity with 168 dimensions , where I want to extract clusters using unsupervised learning .It is not obvious to me whether to use a topic modelling approach in Latent ... .", "label": "", "metadata": {}, "score": "34.954407"}
{"text": "I think I understand the main ideas of hierarchical dirichlet processes , but I do n't understand the specifics of its application in topic modeling .Basically , the idea is that we have the following ... .Question : Does the inference of a trained topic model ( LDA ) used on a subselection of a text corpus result in more accurate document - document - relations ?", "label": "", "metadata": {}, "score": "35.0754"}
{"text": "( Blei \" Introduction \" 78 ) .Presented as a method of discovery and description , computer scientists see topics as revealing latent thematic trends that pervade large and otherwise unstructured text corpora , and with respect to the data used to create the topic model , this conclusion makes sense and works well .", "label": "", "metadata": {}, "score": "35.970695"}
{"text": "Topic modeling .The algorithm for topic modeling that we analyze , LDA , is a complex inference process which captures patterns of word co - occurrences within documents .To investigate the behavior of LDA on corpora with varying levels of redundancy , we rely on two standard evaluation criteria : log - likelihood fit on withheld data and the number of topics required in order to obtain the best fit on the withheld data .", "label": "", "metadata": {}, "score": "37.28647"}
{"text": "Li F , Pietro P : A Bayesian hierarchical model for learning natural scene categories .Proc of the 10th IEEE CVPR 2005 , 2 : 524 - 531 .Lu C , Hu X , Chen X , Park J , He T , Li Z : Probabilistic models for topic learning from images and captions in online biomedical literatures .", "label": "", "metadata": {}, "score": "37.33236"}
{"text": "We thus employ this model for aspect discovery .Its basic idea is that documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over words .The LDA model is represented ( using plate notation ) as a probabilistic graphical model in Figure 1 .", "label": "", "metadata": {}, "score": "37.798454"}
{"text": "In this paper , we propose an approach which employs LDA , a topic generative model , to promoting ranking diversity for biomedical information retrieval .Our contribution is three - fold .First , to the best of our knowledge , this is the first study of adopting topic model to biomedical IR .", "label": "", "metadata": {}, "score": "37.841835"}
{"text": "This kind of summary templates can be useful in various applications .We first develop an entity - aspect LDA model to simultaneously cluster both sentences and words int ... \" .In this paper , we propose a novel approach to automatic generation of summary templates from given collections of summary articles .", "label": "", "metadata": {}, "score": "38.08956"}
{"text": "Results .In this paper , we propose an approach which employs a topic generative model called Latent Dirichlet Allocation ( LDA ) to promoting ranking diversity for biomedical information retrieval .Different from other approaches or models which consider aspects on word level , our approach assumes that aspects should be identified by the topics of retrieved documents .", "label": "", "metadata": {}, "score": "38.15149"}
{"text": "Additionally , for smaller corpus sizes , an increasing offset may be beneficial ( see Table 1 in Hoffman et al . ) .Args : . corpus ( gensim corpus ) : The corpus with which the LDA model should be updated .", "label": "", "metadata": {}, "score": "38.20763"}
{"text": "Wei X , Croft W : LDA - based document models for ad - hoc retrieval .Proceedings of the 29th annual international ACM SIGIR 2006 , 178 - 185 .Mimno D , McCallum A : Expertise modeling for matching papers with reviewers .", "label": "", "metadata": {}, "score": "38.273624"}
{"text": "This paper further proposes to use the multi - modality manifold - ranking algorithm for extracting topic - focused summary from multiple documents by considering the within - document sentence relationships and the cross - document sentence relationships as two separate modalities ( graphs ) .", "label": "", "metadata": {}, "score": "38.471622"}
{"text": "Since they focused on redundant document filtering , experiments in their study were only conducted on a set of relevant documents .Zhai et al .[5 ] proposed a sub - topic retrieval framework which models relevance and redundancy within the language modeling framework .", "label": "", "metadata": {}, "score": "38.48792"}
{"text": "David Blei , credited with developing LDA and probabilistic topic modeling methods , describes topic models the following way : .Topic models have been developed with information engineering applications in mind .As a statistical model , however , topic models should be able to tell us something , or help us form a hypothesis , about the data .", "label": "", "metadata": {}, "score": "38.779636"}
{"text": "On both topics and document weights , the model tries to make the probability mass as concentrated as possible .[ 3 ] Technical books about this field include Bishop , C. 2006 .Pattern Recognition and Machine Learning .Springer ; Koller , D. and Friedman , N. 2009 .", "label": "", "metadata": {}, "score": "39.22348"}
{"text": "Given a collection of texts , they reverse the imaginary generative process to answer the question \" What is the likely hidden topical structure that generated my observed documents ? \" The generative process for LDA is as follows .First choose the topics , each one from a distribution over distributions .", "label": "", "metadata": {}, "score": "39.351044"}
{"text": "Recent investigations into grounded models of language have shown that holistic views of language and perception can provide higher performance than independent views .In this work , we improve a two - dimensional multimodal version of Latent Dirichlet Allocation ( Andrews et al . , 2009 ) in various ways .", "label": "", "metadata": {}, "score": "39.38826"}
{"text": "View Article .Zhou G , Zhao J , Liu K , Cai L : Exploiting web - derived selectional preference to improve statistical dependency parsing .Proceedings of ACL : 2011 , 2011 : 1556 - 1565 .Chen HB , Huang HH , Tan CT , Tjiu J , Chen HH : A statistical medical summary translation system .", "label": "", "metadata": {}, "score": "39.743935"}
{"text": "We thus propose an approach which employs Latent Dirichlet Allocation ( LDA ) [ 11 ] , a topic generative model , to promote diversity and reduce redundancy in the ranked list for biomedical information retrieval .Specifically , we discover topic distributions of retrieval passages and word distributions of each topic dimension using LDA model , and then re - rank retrieved passages with topic distribution similarity between passages based on a \" N -size slide window \" strategy .", "label": "", "metadata": {}, "score": "39.902"}
{"text": "[ 30 ] applied LDA topic modeling to FDA drug side effects labels , their results demonstrated that the acquired topics properly clustered drugs by safety concerns and therapeutic uses .As observed for the field of collocation extraction , redundancy mitigation is not mentioned as standard practice in the case of topic modeling .", "label": "", "metadata": {}, "score": "39.98895"}
{"text": "View Article PubMed .Blaschke C , Valencia A : The Frame - Based Module of the SUISEKI Information Extraction System .Bioinformatics 2002 , 17 ( 2 ) : 14 - 20 .Huang M , Zhu X , Ding S , Yu H , Li M : ONBIRES : ONtology - based BIological Relation Extraction System .", "label": "", "metadata": {}, "score": "40.43032"}
{"text": "The fact that these look like topics has to do with the statistical structure of observed language and how it interacts with the specific probabilistic assumptions of LDA .( Blei \" Introduction \" 79 ) .The topics from Science read as comprehensible , cohesive topics because the texts from which they were derived aim to use language that identifies very literally with its subject .", "label": "", "metadata": {}, "score": "40.460236"}
{"text": "S O , L MP , H H , R A : The use of common ontologies and controlled vocabularies to enable data exchange and deposition for complex proteomic experiments .Pacific Symposium on Biocomputing 2005 , 186 - 196 .Joachims T : Text categorization with support vector machines : learning with many relevant features .", "label": "", "metadata": {}, "score": "41.10383"}
{"text": "For example , LDA assumes that text documents in large corpora tend to draw from categories of language that are associated with the subjects of those documents .In an effort to discover the semantic composition of a large collection of text documents , LDA calculates the likelihood that words that refer to similar subjects appear in similar contexts , and then the LDA algorithm groups those words into \" topics .", "label": "", "metadata": {}, "score": "41.12449"}
{"text": "More specifically , we propose two strategies to incorporate the query information into a probabilistic model .Experimental results on two different genres of data show that our proposed approach can effectively extract a multi - topic summary from a document collection and the summarization performance is better than baseline methods .", "label": "", "metadata": {}, "score": "41.226265"}
{"text": "Following the similar procedure in the variational inference , in this section , we utilize an empirical Bayesian method to estimate the parameters of the CMW model .This time , we are looking for the optimal model parameters to tighten the lower bound of likelihood and obtain the following update equations : .", "label": "", "metadata": {}, "score": "41.315964"}
{"text": "The number of topics is a free parameter of LDA - given two LDA models with the same log - likelihood on withheld data , the one with the lower number of topics has better explanatory power ( fewer latent variables or topics are needed to explain the data ) .", "label": "", "metadata": {}, "score": "41.597126"}
{"text": "Given a standard LDA model with few 1000 topics and few millions of documents , trained with Mallet / collapsed Gibbs sampler : When inferring a new document : Why not just skip sampling and simply use ... .Typically , I see people calculate the perplexity / likelihood of a topic model against a held out set of documents , but is this always necessary / appropriate ?", "label": "", "metadata": {}, "score": "41.620644"}
{"text": "Unlike LSA , there is no natural ordering between the topics in LDA .Calculate the Umass topic coherence for each topic .Algorithm from Mimno , Wallach , Talley , Leenders , McCallum : Optimizing Semantic Coherence in Topic Models , CEMNLP 2011 .", "label": "", "metadata": {}, "score": "41.78493"}
{"text": "Intelligent Systems , IEEE 2009 , 24 ( 2 ) : 8 - 12 .View Article .Dredze M , Blitzer J , Talukdar PP , Ganchev K , Graca J , Pereira F : Frustratingly hard domain adaptation for dependency parsing .", "label": "", "metadata": {}, "score": "41.952553"}
{"text": "We first develop an entity - aspect LDA model to simultaneously cluster both sentences and words into aspects .We then apply frequent subtree pattern mining on the dependency parse trees of the clustered and labeled sentences to discover sentence patterns that well represent the aspects .", "label": "", "metadata": {}, "score": "42.035797"}
{"text": "To understand this discrepancy , we examine the topics obtained on the redundant corpora qualitatively .Topics are generated by LDA as ranked lists of words .Once a topic model is applied on a document , we can compute the topic assignment for each word in the document .", "label": "", "metadata": {}, "score": "42.108826"}
{"text": "Methods correlation analysis .By the CMW model , we map different methods into the latent topic space , where we are able to analyze the relationship between the different methods .Meanwhile , there are intrinsic inherit relationships between the methods , defined in the MI ontology and organized as a concept hierarchy .", "label": "", "metadata": {}, "score": "42.44021"}
{"text": "Kaptein R , Koolen M , Kamps J : Experiments with result diversity and entity ranking : text , anchors , links , and Wikipedia .Proc of TREC-18 2009 .Huang X , Hu Q : A bayesian learning approach to promoting diversity in ranking for biomedical information retrieval .", "label": "", "metadata": {}, "score": "42.527206"}
{"text": "Advances in informatics 2005 , LNCS 3746 : 382 - 392 .View Article .Smith TF , Waterman MS , Fitch WM : Comparative biosequence metrics .J Mol Evol 1981 , 18 ( 1 ) : 38 - 46 .", "label": "", "metadata": {}, "score": "42.687828"}
{"text": "Matthew R , Boutell XS , Luo Jiebo , M Brown C : Learning multi - label scene classification .Pattern Recognition 2004 , 37 ( 9 ) : 1757 - 1771 .View Article .Rinaldi F , Kappeler T , Kaijurand K : OntoGene In Biocreative II .", "label": "", "metadata": {}, "score": "42.692894"}
{"text": "Baldridge J , Morton T , Bierner G : The opennlp maximum entropy package .[ Technical report , SourceForge ] .Teufel S , Elhadad N : Collection and Linguistic Processing of a Large - scale Corpus of Medical Articles .", "label": "", "metadata": {}, "score": "42.73819"}
{"text": "Surveying Blei 's list of key terms in each topic in Figure 2 clarifies the way in which models predict thematic trends in large text corpora .The sense that each of the words in each of the columns belongs together makes a compelling case for LDA 's ability to use Dirichlet allocation to sort large collections of documents into topical categories .", "label": "", "metadata": {}, "score": "42.755196"}
{"text": "[ 7 ] .Their experimental results demonstrated that the hidden property based re - ranking method can achieve promising and stable performance improvements .Yin et al .[ 8 ] proposed a cost - based re - ranking method to promote ranking diversity .", "label": "", "metadata": {}, "score": "42.939087"}
{"text": "In this sense , the major advantage of the CMW model is that it properly exploits such informative correlations to reinforce the extraction performance .The improvements against the manually revised templates approach validate that the CMW model does exploit more precise and general patterns for the desired methods from the large - scale statistics , confirming the reasonable underlying semantic structure from another perspective .", "label": "", "metadata": {}, "score": "42.995796"}
{"text": "Banerjee S , Pedersen T : The design , implementation , and use of the ngram statistics package .[Computational Linguistics and Intelligent Text Processing ] .Wallach HM , Murray I , Salakhutdinov R , Mimno D : Evaluation methods for topic models .", "label": "", "metadata": {}, "score": "42.998924"}
{"text": "Unsurprisingly , humanists interested in sorting , sifting , and organizing large collections of text , managing large document archives , and creating better browsing options for digital libraries find LDA 's potential exciting and promising .Furthermore , humanists interested in uncovering the \" latent patterns \" in large datasets are likewise enthused by the algorithm 's potential for exploratory studies .", "label": "", "metadata": {}, "score": "43.170143"}
{"text": "Results .In this article , we develop a generative topic model , the Correlated Method - Word model ( CMW model ) to extract the detection methods from the literature .In the CMW model , we formulate the correlation between the different methods and related words in a probabilistic framework in order to infer the potential methods from the given document .", "label": "", "metadata": {}, "score": "43.376358"}
{"text": "So the process LDA employs does not change : topics remain a distribution of words over a fixed vocabulary , such that topics are formed only by those words included in the dataset and in the statistical distribution of those words across the entire set .", "label": "", "metadata": {}, "score": "43.71879"}
{"text": "In this paper , we ask three research questions : ( i ) how can redundancy be quantified in large - scale text corpora ?( ii )Conventional wisdom is that larger corpora yield better results in text mining .But how does the observed text redundancy in EHR affect text mining ?", "label": "", "metadata": {}, "score": "43.753857"}
{"text": "In particular , LDA is a type of probabilistic model with hidden variables .Viewed in this context , LDA specifies a generative process , an imaginary probabilistic recipe that produces both the hidden topic structure and the observed words of the texts .", "label": "", "metadata": {}, "score": "43.81453"}
{"text": "Chen X , Lu C , An Y , Achananuparp P : The topic - perspective model for social tagging system .Proc of the 16th KDD 2010 .Minka T , Lafferty J : Expectation - propagation for the generative aspect model .", "label": "", "metadata": {}, "score": "44.43332"}
{"text": "The redundant corpus , though 6.9 times larger , produces the same fit as the non - redundant corpus ( Last Informative Note ) .When applied to the synthetic WSJ corpora , we get a finer picture of the behavior of LDA under various corpora sizes and redundancy levels ( Figure 4 ) .", "label": "", "metadata": {}, "score": "44.447227"}
{"text": "Each author chooses to varying degrees how much of each kind of topic they use for each document ; however , the number of total available topics , just like the total number of kinds of produce remains constant .While this constraint , the assumption that all the words in a corpus could be derived from a limited set of topics , strikes the human reader as an artificial limitation , it is a necessary constraint in order for LDA to work .", "label": "", "metadata": {}, "score": "44.703384"}
{"text": "How can one mitigate the impact of redundancy on text mining ?Results .We analyze a large - scale EHR corpus and quantify redundancy both in terms of word and semantic concept repetition .We observe redundancy levels of about 30 % and non - standard distribution of both words and concepts .", "label": "", "metadata": {}, "score": "44.78708"}
{"text": "As examples , we have developed topic models that include syntax , topic hierarchies , document networks , topics drifting through time , readers ' libraries , and the influence of past articles on future articles .Each of these projects involved positing a new kind of topical structure , embedding it in a generative process of documents , and deriving the corresponding inference algorithm to discover that structure in real collections .", "label": "", "metadata": {}, "score": "44.81301"}
{"text": "Graph - based manifold - ranking methods have been successfully applied to topic - focused multi - document summarization .This paper further proposes to use the multi - modality manifold - ranking algorithm for extracting topic - focused summary from multiple documents by considering the within - document sentence ... \" .", "label": "", "metadata": {}, "score": "44.960903"}
{"text": "As such , the LDA topics group words that tend to co - occur .From the viewpoint of disease modeling , LDA topics are an attractive data modeling and corpus exploration tool .As illustrative examples , we show the top-20 tokens corresponding to three topics acquired from a corpus of patient notes in Table 1 .", "label": "", "metadata": {}, "score": "45.093513"}
{"text": "This phenomenon also hampers the use of machine learning methods by preventing a good division of the data to non - overlapping test and train sets .Results and discussion .Quantifying redundancy in a large - scale EHR corpus .Word sequence redundancy at the patient level .", "label": "", "metadata": {}, "score": "45.421852"}
{"text": "Haug P , Koehler S , Lau L , Wang P , Rocha R , Huff S : A natural language understanding system combining syntactic and semantic techniques .Proc Annu Symp Comput Appl Med Care 1994 , 247 - 251 .", "label": "", "metadata": {}, "score": "45.45748"}
{"text": "Coverage comparison with the baseline models .We compare the coverage performance of the four models on the same data set partition as in Figure 4 and we use the same model parameter settings .Rinaldi utilized the expert revised patterns to perform the extraction and achieved the best performance in the BioCreative II challenge evaluation [ 13 ] .", "label": "", "metadata": {}, "score": "45.539932"}
{"text": "We focus on copy - and - paste redundancy : clinicians typically copy and paste information from previous notes when documenting a current patient encounter .Thus , within a longitudinal patient record , one expects to observe heavy redundancy .In this paper , we ask three research questions : ( i ) How can redundancy be quantified in large - scale text corpora ?", "label": "", "metadata": {}, "score": "45.651016"}
{"text": "We show that this algorithm does not require the slower alignment stage of BLAST and that it accurately identifies instances of copy - paste operations .Text mining techniques .We review two established text - mining techniques : collocation identification and topic modeling .", "label": "", "metadata": {}, "score": "45.676346"}
{"text": "Both of these analyses require that we know the topics and which topics each document is about .Topic modeling algorithms uncover this structure .They analyze the texts to find a set of topics - patterns of tightly co - occurring terms - and how each document combines them .", "label": "", "metadata": {}, "score": "45.810028"}
{"text": "The advantages of the generative topic models are : 1 ) it would be easy to postulate complex latent structures responsible for a set of observations ; 2 ) the correlation between different factors could be easily exploited by introducing the latent topic variables .", "label": "", "metadata": {}, "score": "45.910004"}
{"text": "Unfortunately , this re - ranking method would reduce their system 's performance and decrease the Aspect MAP of the original results for the genomics aspect retrieval [ 10 ] .However , the previous work considers the aspects of user query and retrieved documents mainly on word level .", "label": "", "metadata": {}, "score": "46.013718"}
{"text": "In this paper , we focused on intrinsic , quantitative evaluations to assess the impact of redundancy on two text - mining techniques .Qualitative analysis as well as task - based evaluations are needed to get a full understanding of the role of redundancy in clinical notes on text - mining methods .", "label": "", "metadata": {}, "score": "46.0801"}
{"text": "For humans interpreting topic models , key word distributions are often where the process begins .[5 ] For more information on how LDA has been used by humanists to detect changing attitudes toward patriotism and nationalism , see : Nelson , Robert K. Mining the Dispatch .", "label": "", "metadata": {}, "score": "46.092705"}
{"text": "Beginning with a simple word frequency based model ( Nenkova and Vanderwende , 2005 ) , we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way .Our final model , HIERSUM , utilizes a hierarchical LDA - style model ( Blei et al .", "label": "", "metadata": {}, "score": "46.31629"}
{"text": "The simplest topic model is latent Dirichlet allocation ( LDA ) , which is a probabilistic model of texts .Loosely , it makes two assumptions : .There are a fixed number of patterns of word use , groups of terms that tend to occur together in documents .", "label": "", "metadata": {}, "score": "46.565277"}
{"text": "It aims to distill the most important information from a set of documents to generate a compressed summary .Given a sentence graph generated from a set of documents where vertices represent sentences and edges indic ... \" .Multi - document summarization has been an important problem in information retrieval .", "label": "", "metadata": {}, "score": "46.793346"}
{"text": "To gain some intuitive understanding of how this works , this presentation contains some nice illustrations , as well as a good explanation of LDA in general .An additional comment I 'll put here , since I ca n't comment on your original question : From what I 've seen , the alpha- and beta - parameters can somewhat confusingly refer to several different parameterizations .", "label": "", "metadata": {}, "score": "46.803574"}
{"text": "We observe that the log - likelihood graphs for them have the same shape , with the larger corpora achieving higher log - likelihood , and the best fits obtained with topic numbers between 100 and 200 ( Figure 4 a ) .", "label": "", "metadata": {}, "score": "46.874283"}
{"text": "This paper identifies a characteristic of EHR text corpora : their inherent high level of redundancy , caused by the process of cut and paste involved in the creation and editing of patient notes by health providers .We empirically measure this level of redundancy on a large patient note corpus , and verify that such redundancy introduces unwanted bias when applying standard text mining algorithms .", "label": "", "metadata": {}, "score": "47.00082"}
{"text": "The goal is for scholars and scientists to creatively design models with an intuitive language of components , and then for computer programs to derive and execute the corresponding inference algorithms with real data .The research process described above - where scholars interact with their archive through iterative statistical modeling - will be possible as this field matures .", "label": "", "metadata": {}, "score": "47.02046"}
{"text": "[5 ] There are some methods .For an excellent discussion of these issues in the context of the philosophy of science , see Gelman , A. , and C.R. Shalizi . \"Philosophy and the Practice of Bayesian Statistics . \"", "label": "", "metadata": {}, "score": "47.023155"}
{"text": "When Michael Witmore refers to texts as \" massively addressable at different levels of scale , \" as he does in his two blog posts in Debates in the Digital Humanities ( 2012 ) , he taps into a similar vein of thought as Jorie Graham .", "label": "", "metadata": {}, "score": "47.21843"}
{"text": "Instead the hope is to uncover new methods for addressing enduring humanities questions that we might fruitfully ask about figurative language with LDA .LDA Topics and Poetry .A form of text mining developed in response to the growing challenge of managing , organizing , and navigating large , digitized document archives , topic modeling was developed with primarily non - fiction corpora in mind .", "label": "", "metadata": {}, "score": "47.32309"}
{"text": "It defines the mathematical model where a set of topics describes the collection , and each document exhibits them to different degree .The inference algorithm ( like the one that produced Figure 1 ) finds the topics that best describe the collection under these assumptions .", "label": "", "metadata": {}, "score": "47.34229"}
{"text": "Perotte A , Bartlett N , Elhadad N , Wood F : Hierarchically Supervised Latent Dirichlet Allocation .[ NIPS :2011 ] .Bisgin H , Liu Z , Fang H , Xu X , Tong W : Mining FDA drug labels using an unsupervised learning technique - topic modeling .", "label": "", "metadata": {}, "score": "47.401215"}
{"text": "Given a sentence graph generated from a set of documents where vertices represent sentences and edges indicate that the corresponding vertices are similar , the extracted summary can be described using the idea of graph domination .In this paper , we propose a new principled and versatile framework for multi - document summarization using the minimum dominating set .", "label": "", "metadata": {}, "score": "47.44626"}
{"text": "Feature selection .The CMW model is proposed to capture the correlation between methods and the \" related \" words .However , no curations explicitly annotate which words or sentences are related to the curated methods .So we employ \u03c7 2 statistic [ 26 ] to select the most relevant feature words from the whole text .", "label": "", "metadata": {}, "score": "47.491024"}
{"text": "Frequently , in topic modeling comprehensible results are understood to be thematic or semantically meaningful .In other words , when reading key word distributions , it is usually obvious that there is a thematic array that humans can read and interpret sensibly .", "label": "", "metadata": {}, "score": "47.50644"}
{"text": "In Proceedings of the 1st international workshop on Text mining in bioinformatics : 2006 .ACM ; 2006:7 - 14 .McInnes BT , Pedersen T , Pakhomov SV : Determining the syntactic structure of medical terms in clinical notes .In Proceedings of the Workshop on BioNLP 2007 : Biological , Translational , and Clinical Language Processing : 2007 .", "label": "", "metadata": {}, "score": "47.564953"}
{"text": "I think you need to give some more detail on which LDA formulation you are using .Generally it is only RDA models that have those parameters , LDA usually is defined entirely by mean vector , covariance matrix and prior probabilities . -", "label": "", "metadata": {}, "score": "47.644135"}
{"text": "From another perspective , since these \" indicators \" are organized in a probability framework and accordingly contribute to the desired methods , the CMW model could better overcome the issue caused by the diversity in the method mentions .The reasonable word distribution under methods confirms that the CMW model captures the in - depth correlation between the methods and related words from the literature .", "label": "", "metadata": {}, "score": "47.807716"}
{"text": "Although the CMW model is proposed to address the extraction problem in documents with at least one detection method , in most situation , the curators do n't know whether the document is PPI related or experimentally confirmed beforehand .So it is necessary to evaluate the model 's capability to classify the irrelevant documents .", "label": "", "metadata": {}, "score": "47.83057"}
{"text": "And it outperforms the best result reported in the BioCreative II challenge evaluation ( F - Score improved 12.4 % ) .From the promising results , we could see that the proposed CMW model overcomes the diversity in the method descriptions and appropriately solve the detection method extraction issue .", "label": "", "metadata": {}, "score": "47.93412"}
{"text": "These functions each combine two terms , one which encourages the summary to be representative of the corpus , and the other which positively rewards diversity .Critically , our functions are monotone nondecreasing and su ... \" .We design a class of submodular functions meant for document summarization tasks .", "label": "", "metadata": {}, "score": "48.339592"}
{"text": "The MMR method selects a document that has the highest combination of a similarity score with respect to a query and a dissimilarity score with respect to the documents selected at earlier ranks at each iteration .Zhang et al .[ 4 ] presented four redundancy measures .", "label": "", "metadata": {}, "score": "48.446938"}
{"text": "Nelson 's LDA analysis uses the topic distributions over thousands of Dispatch articles over the course of the war to track relationships between increases in military draft and fatalities and the patriotic rhetoric .[5 ] Nelson 's work in this area represents one of the most ambitious and successful projects to date in the humanities that uses probabilistic topic modeling .", "label": "", "metadata": {}, "score": "48.50862"}
{"text": "Obviously , this manner is not suitable for the large - scale data processing and its flexibility is not desirable .Generative topic model .Nowadays , in the machine learning community , the generative topic model is receiving more and more attentions .", "label": "", "metadata": {}, "score": "48.63112"}
{"text": "Machine Learning 2003 , 50 ( 1 - 2 ) : 5 - 43 .View Article .Copyright .\u00a9 Wang et al .2009 .This article is published under license to BioMed Central Ltd.Can somebody explain what is the natural interpretation for LDA hyperparameters ?", "label": "", "metadata": {}, "score": "48.64266"}
{"text": "These are the two basic notions in the CMW model .Besides , SVM model is the most powerful discriminative model for the classification task with decent performance [ 11 ] .All the baseline models are operating on the same feature set as the CMW model employs .", "label": "", "metadata": {}, "score": "48.887794"}
{"text": "In the this representation , e denotes the detection methods associating with the document , w denotes the observed words and t in the right panel denotes the latent topic factors in the CMW model .The traditional approach ( the left panel of Figure 2 ) simply assumes the relation between the detection methods and related words is determined by the direct mapping .", "label": "", "metadata": {}, "score": "49.02468"}
{"text": "We use the same data set partition as in Figure 4 and evaluate the precision and recall performance of the CMW model .Extraction performance .Since there is few work to compare with , we employ the well studied Na\u00efve Bayes , KNN and SVM as the baseline methods to evaluate the capability of the proposed CMW model .", "label": "", "metadata": {}, "score": "49.033306"}
{"text": "The choosing of the parameters in LDA will be discussed in the next subsection .Discussion .Impact of parameter \u03b2 .The statistical model LDA we have described is conditioned on three parameters , the Dirichlet hyper - parameters \u03b1 and \u03b2 , and the number of topics T .", "label": "", "metadata": {}, "score": "49.12009"}
{"text": "In particular , we assume the applied methods are governed by a set of latent topics and the corresponding word descriptions are also influenced by the same topic factors , which characterize the correlation between the methods and related words .Under this setting , we appeal to the generative topic model to capture such latent correlations and infer the potential methods from the observed words by the statistic inference technique .", "label": "", "metadata": {}, "score": "49.139206"}
{"text": "In this scenario , we control for vocabulary : only word types that appear in the smaller corpus ( Last Informative Note ) are considered for collocations .To measure the impact of redundancy on the extracted collocations , for each collocation , we count the number of patients whose notes contain this collocation .", "label": "", "metadata": {}, "score": "49.1493"}
{"text": "Conventional wisdom is that larger corpora yield better results in text mining .But how does the observed EHR redundancy affect text mining ?Does such redundancy introduce a bias that distorts learned models ?Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?", "label": "", "metadata": {}, "score": "49.19084"}
{"text": "[ 1 ] .I will then discuss the broader field of probabilistic modeling , which gives a flexible language for expressing assumptions about data and a set of algorithms for computing under those assumptions .With probabilistic modeling for the humanities , the scholar can build a statistical lens that encodes her specific knowledge , theories , and assumptions about texts .", "label": "", "metadata": {}, "score": "49.217224"}
{"text": "Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?( iii )How can one mitigate the impact of redundancy on text mining ?Before presenting results of our experiments and methods , we first review previous work in assessing redundancy in the EHR , two standard text - mining techniques of interest for data - driven disease modeling , and current work in how to mitigate presence of information redundancy .", "label": "", "metadata": {}, "score": "49.45773"}
{"text": "Topic Modeling and Digital Humanities .Introduction .Topic modeling provides a suite of algorithms to discover hidden thematic structure in large collections of texts .The results of topic modeling algorithms can be used to summarize , visualize , explore , and theorize about a corpus .", "label": "", "metadata": {}, "score": "49.624233"}
{"text": "Li FF , Perona P : A Bayesian Hierarchical Model for Learning Natural Scene Categories .2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2005 , 524 - 531 .Buntine WL : Operations for Learning with Graphical Models .", "label": "", "metadata": {}, "score": "49.645336"}
{"text": "In \" Reading TeaLeaves : How Humans Interpret Topic Models , \" ( pdf ) Jonathan Chang , Jorden Boyd - Graber , Sean Gerrish , Chong Wang , and David Blei suggest methods for measuring the \" interpretability of a topic model \" ( 2 ) .", "label": "", "metadata": {}, "score": "49.649113"}
{"text": "View Article .Banko M , Brill E : Mitigating the paucity - of - data problem : Exploring the effect of training corpus size on classifier performance for natural language processing .Association for Computational Linguistics ; 2001:1 - 5 .", "label": "", "metadata": {}, "score": "49.68583"}
{"text": "Collocation discovery can help identify lexical variants of medical concepts that are specific to the genre of clinical notes and are not covered by existing terminologies .Topic modeling , another text - mining technique , can help cluster terms often mentioned in the same documents across many patients .", "label": "", "metadata": {}, "score": "49.703663"}
{"text": "We expect that the lower the similarity threshold , the lower the actual redundancy level of the resulting corpus ( in other words , we verify that our fingerprinting redundancy reduction algorithm effectively reduces redundancy ) .Descriptive statistics of reduced corpora .", "label": "", "metadata": {}, "score": "49.725212"}
{"text": "Computational linguistics 2003 , 29 ( 3 ) : 333 - 347 .View Article .Atterer M , Sch tze H : The effect of corpus size in combining supervised and unsupervised training for disambiguation .Association for Computational Linguistics ; 2006:25 - 32 .", "label": "", "metadata": {}, "score": "49.749363"}
{"text": "The evaluation results show that our approach can achieve 8 % improvement over the highest Aspect MAP reported in TREC 2007 Genomics track .Although the proposed method is not as good as the ones presented in [ 8 ] and [ 12 ] in terms of MAP performance , it is still promising because we do not employ other resources such as Wikipedia , which is more efficient in data preprocessing .", "label": "", "metadata": {}, "score": "49.753757"}
{"text": "A side effect of these three re - ranking strategies is that they favor long documents , as the long documents tend to contain more distinct terms .In biomedical retrieval domain , Zhu et al .[ 9 ] proposed a clustering - based ranking algorithm called GRASSHOPPER to promote ranking diversity .", "label": "", "metadata": {}, "score": "49.878315"}
{"text": "( 3 )We provide two novel ways to extend the bimodal models to support three or more modalities .We find that the three- , four- , and five - dimensional models significantly outperform models using only one or two modalities , and that nontextual modalities each provide separate , disjoint knowledge that can not be forced into a shared , latent structure .", "label": "", "metadata": {}, "score": "49.888367"}
{"text": "Yin X , Huang X , Zhou X , Li Z : A survival modeling approach to biomedical search result diversification .Proc of the 33nd ACM SIGIR 2010 , 901 - 902 .Hofmann T : Probabilistic latent semantic indexing .", "label": "", "metadata": {}, "score": "50.138706"}
{"text": "Each document in the corpus exhibits the topics to varying degree .For example , suppose two of the topics are politics and film .LDA will represent a book like James E. Combs and Sara T. Combs ' Film Propaganda and American Politics : An Analysis and Filmography as partly about politics and partly about film .", "label": "", "metadata": {}, "score": "50.267227"}
{"text": "With such efforts , we can build the field of probabilistic modeling for the humanities , developing modeling components and algorithms that are tailored to humanistic questions about texts .Acknowledgments .The author thanks Jordan Boyd - Graber , Matthew Jockers , Elijah Meeks , and David Mimno for helpful comments on an earlier draft of this article .", "label": "", "metadata": {}, "score": "50.274517"}
{"text": "PubMed .Manning CD , Schutze H : Foundations of statistical natural language processing .MIT Press , Cambridge MA ; 1999:151 - 190 .Joshi M , Pakhomov S , Pedersen T , Chute CG : A comparative study of supervised learning as applied to acronym expansion in clinical reports .", "label": "", "metadata": {}, "score": "50.311325"}
{"text": "Goldbery A , Gael DAJ , Settles B , Zhu X , Craven M : Ranking biomedical passages for relevance and diversity .University of Wisconsin , Madison at TREC Genomics 2006 ; Proc of TREC-15 2006 .Blei D , Ng A , Jordan M : Latent Dirichlet allocation .", "label": "", "metadata": {}, "score": "50.311993"}
{"text": "Critically , our functions are monotone nondecreasing and submodular , which means that an efficient scalable greedy optimization scheme has a constant factor guarantee of optimality .When evaluated on DUC 2004 - 2007 corpora , we obtain better than existing state - of - art results in both generic and query - focused document summarization .", "label": "", "metadata": {}, "score": "50.32283"}
{"text": "Latent Dirichlet Allocation ( LDA ) , introduced by Blei et al .[ 27 ] , is an unsupervised generative probabilistic graphical model for topic modeling .Documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over words .", "label": "", "metadata": {}, "score": "50.359604"}
{"text": "None of this body of work consider the query information .More recently , some research effort has been made to incorporate the query information into the topic model .The model uses a multinomial distribution to select whether to sample a word from a document - specific , a query ... . \" ...", "label": "", "metadata": {}, "score": "50.457047"}
{"text": "Aspect discovery and transformation .Aspect discovery using LDA .Discovering aspects covered by each retrieved passage is the first step for re - ranking .Recently , a number of approaches [ 11 , 13 ] to modeling document content are proposed and based on the principle that the probability distribution over words in a document can be expressed as a mixture of topics , where each topic is a probability distribution over words .", "label": "", "metadata": {}, "score": "50.497562"}
{"text": "Topics .Figure 1 : Some of the topics found by analyzing 1.8 million articles from the New York Times .Each panel illustrates a set of tightly co - occurring terms in the collection .Hoffman , M. , Blei , D. Wang , C. and Paisley , J. \" Stochastic variational inference . \"", "label": "", "metadata": {}, "score": "50.632065"}
{"text": "Blei DM , Ng AY , Jordan MI : Latent dirichlet allocation .J Mach Learn Res 2003 , 3 : 993 - 1022 .Arnold CW , El - Saden SM , Bui AAT , Taira R : Clinical Case - based Retrieval Using Latent Topic Analysis .", "label": "", "metadata": {}, "score": "50.654972"}
{"text": "Therefore , the correlations between the detection methods and related words are characterized by the latent topic factors ; and from the observed words , we are able to infer the potential methods in the given document according to such correlations .", "label": "", "metadata": {}, "score": "50.681644"}
{"text": "In the method - level evaluation , the baseline models only retrieve most of the major methods ( e.g. the top 5 methods ) but ignoring the other minor ones , while the CMW model exhibits superior retrieve power .We demonstrate the coverage performance of each model on the testing set to compare their retrieval capability .", "label": "", "metadata": {}, "score": "50.744804"}
{"text": "Demner - Fushman D , Humphrey S , Ide N , Loane R , Mork J , Ruch P , Ruiz M , Smith L , Wilbur W , Aronsona A : Combining resources to find answers to biomedical questions .Proc of TREC-16 2007 .", "label": "", "metadata": {}, "score": "50.775932"}
{"text": "Most of the discriminative classifiers fail to exploit such relations .The competitive performance confirms that the dependence assumptions in the model are reasonable and it is necessary to model the correlation between the different methods and words in the detection method extraction issue .", "label": "", "metadata": {}, "score": "50.811043"}
{"text": "[ 6 ] employed a top down sliding window to diversify ranked list of retrieved documents .They kept the highest ranked result as is and chose from the next n documents the one that maximizes diversity according to some diversity indicators , such as the number of new terms or new links introduced by the next document .", "label": "", "metadata": {}, "score": "50.816116"}
{"text": "Many studies have indeed shown that cross - domain learned corpora yield poor language models [ 35 ] .The field of domain adaptation attempts to compensate for the poor quality of cross - domain data , by adding carefully picked text from other domains [ 36 , 37 ] or other statistical mitigation techniques .", "label": "", "metadata": {}, "score": "50.83046"}
{"text": "We apply our method on five Wikipedia entity categories and compare our method with two baseline methods .Both quantitative evaluation based on human judgment and qualitative comparison demonstrate the effectiveness and advantages of our method . \" ...We introduce a method to learn a mixture of submodular \" shells \" in a large - margin setting .", "label": "", "metadata": {}, "score": "51.003708"}
{"text": "In this paper , we propose a generative probabilistic model , the Correlated Method - Word model , to automatically extract the interaction detection methods from the biological literature .This problem is not well studied by the previous researches .By introducing the latent topic factors , the proposed model formulates the correlation between the detection methods and related words in a probabilistic framework in order to infer the potential methods from the observed words .", "label": "", "metadata": {}, "score": "51.011417"}
{"text": "This healthy behavior strongly indicates that Reduced Redundancy Informative Notes indeed behaved as a non - redundant corpus with respect to the LDA algorithm .Model fit as function of number of topics .Patient notes corpora , including the \" Reduced Informative \" corpus .", "label": "", "metadata": {}, "score": "51.015167"}
{"text": "LDA model .Figure 1 shows a probabilistic graphical representation of LDA model .Aspect distribution transformation .We construct \u03b8 matrix of Eq .( 1 ) in light of LDA model discussed in above subsection , which is the matrix of passage - specific mixture weights for these T aspects discovered .", "label": "", "metadata": {}, "score": "51.055565"}
{"text": "Another straightforward solution is to treat the extraction issue as a classification problem - for each detection method in the ontology definition , a set of binary classifiers are built to make yes / no decisions [ 11 , 12 ] .", "label": "", "metadata": {}, "score": "51.07892"}
{"text": "Blei DM , Ng AY , Jordan MI : Latent Dirichlet Allocation .The Journal of Machine Learning Research 2003 , 3 ( 2 - 3 ) : 993 - 1022 .View Article .Steyvers M , Griffiths T : Probabilistic Topic Models .", "label": "", "metadata": {}, "score": "51.162388"}
{"text": "Hence , it is important of a biomedical IR system to be able to provide relevant and diverse answers to fulfill biologists ' information needs .However traditional IR model only concerns with the relevance between retrieved documents and user query , but does not take redundancy between retrieved documents into account .", "label": "", "metadata": {}, "score": "51.163784"}
{"text": "[ Proceedings of the 2nd ACM SIGHIT symposium on International health informatics : 2012 ] .Zeng QT , Crowell J : Semantic classification of consumer health content .MEDNET Retrieved May 2008 , 2006 : 19 .Jiang Y : A computational semantics system for detecting drug reactions and patient outcomes in personal health messages .", "label": "", "metadata": {}, "score": "51.16598"}
{"text": "With these goals in mind , one might want to identify concepts that are associated by looking for frequently co - occurring pairs of concepts or phrases in patient notes , or cluster concepts across patients to identify latent variables corresponding to clinical models .", "label": "", "metadata": {}, "score": "51.176025"}
{"text": "One may ask , however , whether the fact that the sentences are repeated in EHR corpora reflects on their semantic importance from a clinical standpoint , and therefore , whether the collocations extracted from the full EHR corpus contain more clinically relevant collocations .", "label": "", "metadata": {}, "score": "51.246292"}
{"text": "I have difficulties understanding the VB implementation lda - c .In particular , the method expects as input a bag - of - words representation of documents , where distinct words appearing in a document are ... .I 'm trying to implement Latent Dirichlet Allocation ( LDA ) on a bigram language model .", "label": "", "metadata": {}, "score": "51.26659"}
{"text": "Furthermore , the discriminative classification algorithms assume the methods are independent in prior and the words are also independent when observing the given methods .Thus they would neglect the latent patterns within both methods and words .Inference and parameter estimation .", "label": "", "metadata": {}, "score": "51.281425"}
{"text": "We empirically measure the damage caused by redundancy on the tasks of collocation extraction and topic modeling through a series of controlled experiments .Preliminary qualitative inspection of the results suggests that idiosyncrasies of each patient ( where the redundancy occurs ) explain the observed bias .", "label": "", "metadata": {}, "score": "51.360123"}
{"text": "Conclusion .From the promising experiment results , we can see that the CMW model overcomes the issues caused by the diversity in the method mentions and properly captures the in - depth correlations between the detection methods and related words .", "label": "", "metadata": {}, "score": "51.49543"}
{"text": "Downey D , Etzioni O , Soderland S : Analysis of a probabilistic model of redundancy in unsupervised information extraction .Artif Intell 2010 , 174 ( 11 ) : 726 - 748 .View Article .Altschul SF , Madden TL , Sch\u00e4ffer AA , Zhang J , Zhang Z , Miller W , Lipman DJ : Gapped BLAST and PSI - BLAST : a new generation of protein database search programs .", "label": "", "metadata": {}, "score": "51.58003"}
{"text": "In \" Probabilistic Topic Models , \" Blei uses two illustrations to explain how topic modeling of a large , digitized collection of Science works .The first illustration depicts an excerpt from one article within the collection titled \" Seeking Life 's Bare ( Genetic ) Necessities \" and demonstrates the relationship between topics and keyword distributions .", "label": "", "metadata": {}, "score": "51.731953"}
{"text": "The results of high redundancy in patient notes are consistent with Wrenn et al .[14 ] observations on a similar EHR dataset .The contrast between same - patient and across - patient redundancy , however , is surprising given that the whole corpus is sampled from a population with at least one shared chronic condition .", "label": "", "metadata": {}, "score": "51.743355"}
{"text": "If , on the other hand , the distribution is asymmetric , a high alpha - value means that a specific topic distribution ( depending on the base measure ) is more likely for each document .Similarly , high beta - values means each topic is more likely to contain a specific word mix defined by the base measure .", "label": "", "metadata": {}, "score": "51.81471"}
{"text": "Ono T , Hishigaki H , Tanigami A , Takagi T : Automated extraction of information on protein protein interactions from the biological literature .IEEE Intelligent Systems 2001 , 17 ( 2 ) : 155 - 161 .Huang M , Zhu X , Hao Y , Payan DG , Qu K , Li M : Discovering patterns to extract protein protein interactions from full texts .", "label": "", "metadata": {}, "score": "52.00904"}
{"text": "We perform our approach on TREC 2007 Genomics collection and two distinctive IR baseline runs , which can achieve 8 % improvement over the highest Aspect MAP reported in TREC 2007 Genomics track .Conclusions .The proposed method is the first study of adopting topic model to genomics information retrieval , and demonstrates its effectiveness in promoting ranking diversity as well as in improving relevance of ranked lists of genomics search .", "label": "", "metadata": {}, "score": "52.129677"}
{"text": "The CMW model achieved competitive results , F - Score improved 12.4 % .Here , we briefly conclude the performance of the CMW model .The extraction performance outperforms the discriminative baseline methods confirms that the dependence assumptions in the proposed CMW model are reasonable .", "label": "", "metadata": {}, "score": "52.22439"}
{"text": "Ideally , in order to provide a comprehensive picture of all interpretations to the query , it would be better for an information retrieval system to return a ranked list of retrieved documents or passages taking both relevance and diversity into account .", "label": "", "metadata": {}, "score": "52.30243"}
{"text": "MIT Press ; and Murphy , K. 2013 .Machine Learning : A Probabilistic Approach .MIT Press .[ 4 ] The name \" latent Dirichlet allocation \" comes from the specification of this generative process .In particular , the document weights come from a Dirichlet distribution - a distribution that produces other distributions - and those weights are responsible for allocating the words of the document to the topics of the collection .", "label": "", "metadata": {}, "score": "52.326477"}
{"text": "We compare the results of these methods on synthetic data with controlled levels of redundancy and observe significant performance variation .Finally , we compare two mitigation strategies to avoid redundancy - induced bias : ( i ) a baseline strategy , keeping only the last note for each patient in the corpus ; ( ii ) removing redundant notes with an efficient fingerprinting - based algorithm .", "label": "", "metadata": {}, "score": "52.34116"}
{"text": "Therefore , there is great practical demand of automatically extracting the detection methods from the literature .The first critical assessment of detection method extraction was carried out by the BioCreative II challenge evaluation [ 9 ] .But only two groups ( out of sixteen ) submitted their results .", "label": "", "metadata": {}, "score": "52.4361"}
{"text": "Rather than selecting from just a few poems , LDA allowed me to cast my net as wide as 4,500 poems .Second , both LDA and our existing model of ekphrasis presuppose that latent patterns of language , when discovered , can be used to describe the corpus as a whole .", "label": "", "metadata": {}, "score": "52.45758"}
{"text": "Int J Med Inform 2002 , 67 ( 1/3 ) : 63 - 74 .PubMed View Article .Kullo IJ , Fan J , Pathak J , Savova GK , Ali Z , Chute CG : Leveraging informatics for genetic studies : use of the electronic medical record to enable a genome - wide association study of peripheral arterial disease .", "label": "", "metadata": {}, "score": "52.461014"}
{"text": "Note that the statistical models are meant to help interpret and understand texts ; it is still the scholar 's job to do the actual interpreting and understanding .A model of texts , built with a particular theory in mind , can not provide evidence for the theory .", "label": "", "metadata": {}, "score": "52.588837"}
{"text": "These goals are at odds .With few terms assigned to each topic , the model captures the observed words by using more topics per article .With few topics assigned to each article , the model captures the observed words by using more terms per topic .", "label": "", "metadata": {}, "score": "52.978683"}
{"text": "Daraselia N , Yuryev A , Egorov S , Novichkova S , Nikitin A , Mazo I : Extracting human protein interactions from MEDLINE using a full - sentence parser .Bioinformatics 2004 , 20 ( 5 ) : 604 - 611 .", "label": "", "metadata": {}, "score": "53.007545"}
{"text": "We first use the perplexity as the criterion to evaluate the effect of the number of topic factors , which is the only arbitrary parameter in the CMW model .The perplexity on a set of testing documents is calculated as follows : . where D is the set of testing documents and N d is the number of methods in the document d .", "label": "", "metadata": {}, "score": "53.06645"}
{"text": "For computational efficiency , we develop a variational inference procedure to approximate the lower bound of the desired posterior distribution of methods in a given document .In particular , we define the following fully factorized distribution on the latent variables : . where the Dirichlet parameters \u03b3 , \u03c3 and the Multinomial parameters \u03d5 , \u03bb are free variational parameters .", "label": "", "metadata": {}, "score": "53.09178"}
{"text": "More recently , Perotte et al .leveraged topic models in a supervised framework for the task of assigning ICD-9 codes to discharge summaries [ 29 ] .There , the input consisted of the words in the discharge summaries and the hierarchy of ICD-9 codes .", "label": "", "metadata": {}, "score": "53.09451"}
{"text": "Mutual information and topic modeling .Collocation identification was carried out on the different corpora using the Ngram Statistics Package [ 53 ] , which provides an implementation for collocation detection using True Mutual Information ( TMI ) and Pointwise Mutual Information ( PMI ) .", "label": "", "metadata": {}, "score": "53.175835"}
{"text": "We contribute the nice coverage performance to the smoothing factor introduced to the method distribution .Because the whole corpus is sparse and unbalanced , the minor methods possess little proportion in the training set .However , the baseline models do not take the sparseness into account , so that they fail to retrieve the minor ones from the testing cases .", "label": "", "metadata": {}, "score": "53.17923"}
{"text": "Bodenreider O : The unified medical language system ( UMLS ) : integrating biomedical terminology .Nucleic Acids Res 2004 , 32 : D267 .PubMed View Article .Gildea D : Corpus variation and parser performance .Citeseer ; 2001:167 - 202 .", "label": "", "metadata": {}, "score": "53.206833"}
{"text": "Moreover , most of existing work assumes that documents related to the query only talks about one topic .Unfortunately , statistics show that a large portion of summarization tasks talk about multiple topics .In this paper , we try to break limitations of the existing methods and study a new setup of the problem of multi - topic based query - oriented summarization .", "label": "", "metadata": {}, "score": "53.274048"}
{"text": "Joshi M , Pedersen T , Maclin R : A comparative study of support vector machines applied to the supervised word sense disambiguation problem in the medical domain .[ Proceedings of the 2nd Indian International Conference on Artificial Intelligence ( IICAI'05 ) : 2005 ] .", "label": "", "metadata": {}, "score": "53.28222"}
{"text": "Conventional wisdom is that larger corpora yield better results in text mining .In fact , it is well established empirically that larger datasets yield more accurate models of text processing ( see for example , [ 31 - 34 ] ) .", "label": "", "metadata": {}, "score": "53.30741"}
{"text": "We held out 20 % of collection for the testing purpose and used the remaining 80 % to train the model , in accordance with 5-fold cross - validation .Figure 4 demonstrates that the generalization power of the CMW model gets improved with more topic factors .", "label": "", "metadata": {}, "score": "53.606842"}
{"text": "We could discover from Figure 5 that the extraction performance peaks close to the place where the perplexity reaches the minimum .This is consistent with the foregoing perplexity result .These results give us insight about determining the proper size of topics for the CMW model .", "label": "", "metadata": {}, "score": "53.76643"}
{"text": "This lack of consistency explains the confusion and consequently low performance achieved by LDA on redundant corpora .Mitigation strategies for handling redundancy .Given a corpus with inherent redundancy , like the EHR corpus , the basic goal of redundancy mitigation is to choose the largest possible subset of the corpus with an upper bound on the amount of redundancy in that subset .", "label": "", "metadata": {}, "score": "53.87297"}
{"text": "The constraints of choosing one textual \" unity \" correspondingly expands our ability to address a larger scale of texts , revealing patterns and relationships that might otherwise have remained hidden .Revising Ekphrasis .Topic modeling with LDA first captured my attention as a possible way to ask discovery - oriented questions about a genre of poetry called ekphrasis - poems written to , for , or about the visual arts .", "label": "", "metadata": {}, "score": "53.924942"}
{"text": "Our method can produce corpora with different redundancy amounts quickly , without alignment of documents and without any prior knowledge of the documents .We confirmed that the parameter of our Selective Fingerprinting method is a good predictor of document alignment and can be used as the sole method for removing redundancy .", "label": "", "metadata": {}, "score": "54.019135"}
{"text": "But as the number of topics exceeds a limit , the model becomes too specific ( higher perplexity ) .Therefore we could conclude that the topic factors could be treated as the discriminate granularity of the model , that is it operates as a tradeoff between the generality and specificity .", "label": "", "metadata": {}, "score": "54.156494"}
{"text": "View Article .Kohane IS : Using electronic health records to drive discovery in disease genomics .Nat Rev Genet 2011 , 12 ( 6 ) : 417 - 428 .PubMed View Article .Tatonetti N , Denny J , Murphy S , Fernald G , Krishnan G , Castro V , Yue P , Tsau P , Kohane I , Roden D , et al .", "label": "", "metadata": {}, "score": "54.16674"}
{"text": "And in the future work , we are planning to associate the extracted methods with the annotated interaction pairs and retrieve the evidence sentences in the documents , which would provide a more throughout annotation of the protein interactions in the biological literature .", "label": "", "metadata": {}, "score": "54.302425"}
{"text": "The CMW model achieved competitive results ( F - Score improved 12.4 % ) , illustrated in Table 2 .We operate the CMW model on the BioCreative II testing corpus ( 300 full text documents ) to compare with the best result reported in the evaluation .", "label": "", "metadata": {}, "score": "54.486195"}
{"text": "Even more striking , when examining the behavior of WSJs5 ( with 3,300 documents sampled from 1,300 distinct documents ) up to 100 topics , we observe it reaches the same fit as WSJ-600 .We have seen that for the naturally occurring WSJ corpus training on more data produces better fit to held out data ( see Figure 4 a ) .", "label": "", "metadata": {}, "score": "54.550194"}
{"text": "In particular , the value of \u03b2 affects the granularity of the model .Increasing \u03b2 can be expected to decrease the number of topics used to describe retrieved passages .In other words , retrieved passages can be sensibly factorized into a set of topics at several different scales , and the particular scale of the topics assessed by the model will be set by \u03b2 .", "label": "", "metadata": {}, "score": "54.562943"}
{"text": "Of course , whether or not results are indeed actionable depends to a large extent on the ability to find a fair and measurable degree of success .Actionable results require that researchers are clear about their a priori assumptions and the composition of the dataset and the predicted degree to which the results might be found reliable .", "label": "", "metadata": {}, "score": "54.753128"}
{"text": "This work is inspired by a corpus of 1.3 million Twitter conversations , which will be made publicly available .This huge amount of data , available only because Twitter blurs the line between chatting and publishing , highlights the need to be able to adapt quickly to a new medium . by Alan Ritter , Oren Etzioni - In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics ( ACL , 2010 . \" ...", "label": "", "metadata": {}, "score": "54.84214"}
{"text": "The information in notes can be found in the form of narrative and semi - structured format through lists or templates with free - text fields .As such , much research has been devoted to parsing and information extraction of clinical notes [ 1 - 3 ] with the goal of improving both health care and clinical research .", "label": "", "metadata": {}, "score": "54.86552"}
{"text": "For the symmetric distribution , a high alpha - value means that each document is likely to contain a mixture of most of the topics , and not any single topic specifically .A low alpha value puts less such constraints on documents and means that it is more likely that a document may contain mixture of just a few , or even only one , of the topics .", "label": "", "metadata": {}, "score": "54.95056"}
{"text": "PubMed View Article .Pearson WR : [ 5 ] Rapid and sensitive sequence comparison with FASTP and FASTA .Academic Press ; 1990:63 - 98 .[Methods in Enzymology .vol .Volume 183 ] .HaCohen - Kerner Y , Tayeb A , Ben - Dror N : Detection of simple plagiarism in computer science papers .", "label": "", "metadata": {}, "score": "55.14785"}
{"text": "I divided a unlabeled dataset into training and testing sets .Is it rational to label the training data with dynamic topic model ( I want to take time ... .I 'm experimenting with topic models for my master thesis .", "label": "", "metadata": {}, "score": "55.19461"}
{"text": "In probabilistic modeling , we provide a language for expressing assumptions about data and generic methods for computing with those assumptions .As this field matures , scholars will be able to easily tailor sophisticated statistical methods to their individual expertise , assumptions , and theories .", "label": "", "metadata": {}, "score": "55.215073"}
{"text": "Re- ranking performance is effected by the parameters chosen from LDA model .Comparison with NLMinter baseline run , we only show the re - ranking results with parameters of \u03b2 whose values are equal to 0.04 in algorithm 1 and 0.06 in algorithm 2 , respectively .", "label": "", "metadata": {}, "score": "55.304955"}
{"text": "We employ LDA model to discover topic distribution of retrieval passages and word distribution of each topic dimension .Second , since retrieved passages ' distribution for each aspect is different , even the same weight value in different aspects would be of different importance , we made transformations with topic distribution .", "label": "", "metadata": {}, "score": "55.314026"}
{"text": "Model fit as function of number of topics on the WSJ corpora .In ( a ) we compare the effect of size on LDA , bigger corpora yield better fit .In ( b ) we examine the effect of redundancy : the doubled / trebled corpora reduce fit slightly while the noisier WSJs5 performs almost as badly as training on the smaller WSJ-600 corpus .", "label": "", "metadata": {}, "score": "55.426376"}
{"text": "The Markov Random Walk model has been recently exploited for multi - document summarization by making use of the link relationships between sentences in the document set , under the assumption that all the sentences are indistinguishable from each other .However , a given document set usually covers a f ... \" .", "label": "", "metadata": {}, "score": "55.4832"}
{"text": "The level of overall redundancy is significant and spread over many documents ( over a third ) .Concept redundancy at the corpus level .Since free - text notes exhibit high level of variability in their language , the redundancy measures may be different when we examine terms normalized against a standard terminology .", "label": "", "metadata": {}, "score": "55.522026"}
{"text": "Experimental results on the DUC2001 and DUC2002 datasets demonstrate the good effectiveness of our proposed summarization models .The results also demonstrate that the ClusterCMRW model is more robust than the ClusterHITS model , with respect to different cluster numbers .Categories and Subject Descriptors : . ...", "label": "", "metadata": {}, "score": "55.61989"}
{"text": "Besides , since the correlation between the methods and word occurrences is underlying ( a document usually associates with multiple detection methods ) , we use the indexing variable y to indicate such latent structure between them .Thus , the joint probability on the observed methods , words and latent variables in one document is given as follows : .", "label": "", "metadata": {}, "score": "55.65607"}
{"text": "Re- ranking performance .We preprocessed the retrieved passages of two baseline runs .Re- ranking results of the proposed methods on TREC 2007 Genomics collection are shown in Table 1 and Table 2 .The values in the parentheses are the relative rates of improvement over the original results .", "label": "", "metadata": {}, "score": "55.85771"}
{"text": "These documents are taken as the irrelevant documents .Meanwhile , we randomly select another 1000 documents from the evaluation corpus as relevant documents .In Eq ( 17 ) , we define the relevance score of each document by the posterior probability of the most potential method in that document as follows : .", "label": "", "metadata": {}, "score": "55.903027"}
{"text": "It is very useful to help users grasp the main information related to a query .Existing work can be mainly classified into two categories : supervised method and unsupervised method .T ... \" .Query - oriented summarization aims at extracting an informative summary from a document collection for a given query .", "label": "", "metadata": {}, "score": "56.0116"}
{"text": "In the second video he shows the effect of alpha with some sample graphs .The smaller alpha the more sparse the distribution .Also , he introduces some inference approaches .The answer depends on whether you are assuming the symmetric or asymmetric dirichlet distribution ( or , more technically , whether the base measure is uniform ) .", "label": "", "metadata": {}, "score": "56.027534"}
{"text": "Evaluating Topic Models of Figurative Language .As Ian H. Witten , Eibe Frank , and Mark A. Hall remind us in Data Mining : Practical Machine Learning Tools and Techniques , the guiding factors for text mining generally and topic modeling specifically are to generate actionable and comprehensible results ( 9.5 ) .", "label": "", "metadata": {}, "score": "56.04782"}
{"text": "Figure 1 further details the full histogram of redundancy for pairs of same - patient informative notes .The redundancy ( percentage of aligned tokens ) was computed for the notes of a random sample of 100 patients .For instance , it indicates that 7.6 % of the same patient note pairs in the corpus have between 20 % and 30 % identity .", "label": "", "metadata": {}, "score": "56.06706"}
{"text": "We compare the performance of standard algorithms for collocation identification and topic modeling inference on a variety of corpora with different redundancy levels .We introduce synthetic corpora where we can control the level of redundancy .These synthetic corpora are derived from the Wall Street Journal ( WSJ ) standard corpus .", "label": "", "metadata": {}, "score": "56.08019"}
{"text": "How to design an algorithm to predict how many upvotes a review would get in a certain time period after publishing .Let 's say the review comes from Yelp .So the ... .I 'd like to get a list of limitations of LDA .", "label": "", "metadata": {}, "score": "56.197605"}
{"text": "In that case , the aim of the variational inference is to find the optimal variational parameters which could minimize the Kullback - Leibler ( KL ) divergence between the variational distribution and the true posterior distribution .Following the general recipe for the variational approximation , we take derivatives with respect to the variational parameters and obtain the following coordinate ascent algorithm : .", "label": "", "metadata": {}, "score": "56.212315"}
{"text": "Other exemplary topic modeling projects have used Wikipedia , NIH grants , JSTOR , and an archive of Classics journals .[ 3 ] As literary scholars well know , however , poems exercise language in ways purposefully inverse to other forms of writing , such as journal articles , encyclopedia entries , textbooks , and newspaper articles .", "label": "", "metadata": {}, "score": "56.291267"}
{"text": "Proc AMIA : 2011 , 2011 : 1612 - 1620 .Lin CY : Rouge :A package for automatic evaluation of summaries .[Text Summarization Branches Out : Proceedings of the ACL-04 Workshop : 2004 ] .Altschul SF , Gish W , Miller W , Myers EW , Lipman DJ : Basic local alignment search tool .", "label": "", "metadata": {}, "score": "56.36706"}
{"text": "Topic modeling algorithms search through the space of possible topics and document weights to find a good representation of the collection of documents .Mathematically , the topic model has two goals in explaining the documents .First , it wants its topics to place high probability on few terms .", "label": "", "metadata": {}, "score": "56.431534"}
{"text": "We observe that the lists of extracted collocations on these two corpora differ markedly ( collocations were extracted with a threshold of 0.001 and 0.01 for TMI and PMI respectively ) .The PMI algorithm identified 15,814 collocations in the All Informative Notes corpus , and 2,527 in the Last Informative Notes corpus .", "label": "", "metadata": {}, "score": "56.466328"}
{"text": "In this sense , when the number of topic factors exceeds a limit , the quality of the estimated parameters decreases and hampers the prediction power .Methods perplexity .Lower perplexity on the testing data indicates a better generalization capability .", "label": "", "metadata": {}, "score": "56.48988"}
{"text": "Experiments conducted on TREC 2007 Genomics track collection demonstrate the e effectiveness of our approach .The evaluation results show that our approach can achieve 8 % improvement over the highest Aspect MAP reported in TREC 2007 Genomics track .In future research , we intend to extend this work by exploring both more complex models and more sophisticated algorithms .", "label": "", "metadata": {}, "score": "56.518616"}
{"text": "The average amount of redundancy in removed note pairs is sampled as well .Redundancy is computed in the same way as in Section 2.1.1 .We randomly sampled 2,000 same - patient pairs of notes and aligned them using Smith - Waterman alignment .", "label": "", "metadata": {}, "score": "56.523335"}
{"text": "In terms of the non - figurative language found in topic models of the journal Science , Blei explains that topics detect thematic trends across texts : .We formally define a topic to be a distribution over a fixed vocabulary .", "label": "", "metadata": {}, "score": "56.546017"}
{"text": "Endnotes .Declarations .Acknowledgements .This work was supported by a National Library of Medicine grant R01 LM010027 ( NE ) .Any opinions , findings , or conclusions are those of the authors , and do not necessarily reflect the views of the funding organization .", "label": "", "metadata": {}, "score": "56.57872"}
{"text": "We propose the first unsupervised approach to the problem of modeling dialogue acts in an open domain .Trained on a corpus of noisy Twitter conversations , our method discovers dialogue acts by clustering raw utterances .Because it accounts for the sequential behaviour of these acts , the learned mode ... \" .", "label": "", "metadata": {}, "score": "56.683754"}
{"text": "doi : 10.1111/j.2044 - 8317.2011.02037.x .About David M. Blei .David M. Blei is an associate professor of Computer Science at Princeton University .His research focuses on probabilistic topic models , Bayesian nonparametric methods , and approximate posterior inference .", "label": "", "metadata": {}, "score": "56.719944"}
{"text": "Besides understanding the impact of the number of topic factors on the generalization capability , we would be more interested in their explicit effect on the extraction performance .Here , we evaluate the precision and recall performance of the model under different number of topic factors .", "label": "", "metadata": {}, "score": "56.738926"}
{"text": "PubMed View Article .Kho A , Pacheco J , Peissig P , Rasmussen L , Newton K , Weston N , Crane P , Pathak J , Chute C , Bielinski S : Electronic Medical Records for Genetic Research : Results of the eMERGE Consortium .", "label": "", "metadata": {}, "score": "56.744087"}
{"text": "Holm L , Sander C : Removing near - neighbour redundancy from large protein sequence collections .Bioinformatics 1998 , 14 ( 5 ) : 423 .PubMed View Article .Bateman A , Birney E , Durbin R , Eddy SR , Howe KL , Sonnhammer ELL : The Pfam protein families database .", "label": "", "metadata": {}, "score": "56.77806"}
{"text": "Comparison of extracted collocations on synthetic redundant corpora and non - redundant corpora ( WSJ - X words / Y distinct words ) .Collocations were extracted using using True Mutual Information and Pointwise Mutual Information ( with cutoffs of 0.001 and 0.01 respectively ) .", "label": "", "metadata": {}, "score": "56.823257"}
{"text": "Finally , she uses those estimates in subsequent study , trying to confirm her theories , forming new theories , and using the discovered structure as a lens for exploration .She discovers that her model falls short in several ways .", "label": "", "metadata": {}, "score": "56.92592"}
{"text": "Conclusions .Before applying text - mining techniques , one must pay careful attention to the structure of the analyzed corpora .While the importance of data cleaning has been known for low - level text characteristics ( e.g. , encoding and spelling ) , high - level and difficult - to - quantify corpus characteristics , such as naturally occurring redundancy , can also hurt text mining .", "label": "", "metadata": {}, "score": "56.98131"}
{"text": "We see that the significantly smaller Last Informative Note performs as well as All Informative Notes ( 8,557 notes vs. 1,247 ) while Reduced Redundancy Informative Notes ( 3,970 notes ) outperforms both .As we showed in Figure 4 a , we would expect a larger corpus to yield a better fit on the model : All Informative Notes is more than 7 times larger than Last Informative , still it yields the same fit on held out data .", "label": "", "metadata": {}, "score": "57.02784"}
{"text": "Yin X , Huang X , Li Z : Promoting ranking diversity for biomedical information retrieval using Wikipedia .Proc of the 32nd European Conference on Information Retrieval 2010 .Zhu X , Goldberg A , Gael JV , Andrzejewski D : Improving diversity in ranking using absorbing random walks .", "label": "", "metadata": {}, "score": "57.05789"}
{"text": "Human subjects ( generally disciplinary experts ) were then asked to determine which word in each group did not belong .Chang , et al .discovered that with relative high success , human readers could discern a thematic connection between terms to reliably distinguish the single out - of - place term .", "label": "", "metadata": {}, "score": "57.076763"}
{"text": "Recall that , each row of the multinomial parameter \u03f5 is the method distribution under a particular topic , so that each column of \u03f5 represents a method in the topic space .By normalizing \u03f5 by column , we can represent the different methods over the latent topic factors .", "label": "", "metadata": {}, "score": "57.137463"}
{"text": "To simplify the model , we have assumed the topic size k is known and fixed on the whole corpus .These are the latent variables .Besides , \u03b1 and \u03b7 are the parameters of k -dimensional and E -dimensional Dirichlet distributions that postulate the topic and method prior distributions on the corpus and \u03b2 is a k \u00d7 V matrix , which represents the word distribution under topics .", "label": "", "metadata": {}, "score": "57.21506"}
{"text": "First , for each document , a distribution over topics is sampled from a Dirichlet distribution .Second , for each word in the document , a single topic is chosen according to this distribution .Finally , each word is sampled from a multinomial distribution over words specific to the sampled topic .", "label": "", "metadata": {}, "score": "57.21927"}
{"text": "They confirm that in outpatient notes , like for inpatient notes , there is a large amount of redundancy .Different metrics for quantifying redundancy exist for text .Sequence alignment methods such as the one proposed by Zhang et al .", "label": "", "metadata": {}, "score": "57.225983"}
{"text": "As more neighbors arrive , with baskets to examine , you can refine your predictions about what the available selection of produce have been at the market .In the case of the farmer 's market , your approach to predicting the 10 kinds of produce and the available quantities of each based on the contents of your neighbor 's baskets is akin to the way LDA algorithms approach texts .", "label": "", "metadata": {}, "score": "57.23375"}
{"text": "Methods for identifying redundancy in large string - based databases exist in both bioinformatics and plagiarism detection [ 40 - 42 ] .A similar problem has been addressed in the creation of sequence databases for bioinformatics : Holm and Sander [ 43 ] advocated the creation of non - redundant protein sequence databases and suggested that databases limit the level of redundancy .", "label": "", "metadata": {}, "score": "57.342983"}
{"text": "Competing interests .The authors declare that they have no competing interests .Authors ' contributions .Wang carried out the major work of the paper , proposed the model , implemented the experiments and drafted the manuscript .Huang gave directions in the process and revised the draft .", "label": "", "metadata": {}, "score": "57.354843"}
{"text": "Conference on Uncertainty in Artificial Intelligence 2002 .The Y , Newman D : A collapsed variational Bayesian inference algorithm for latent Dirichlet allocation .Proc of 20th NIPS 2006 .Porteous I , Newman D , Ihler A , Asuncion A , Smyth P , Welling M : Fast collapsed Gibbs sampling for latent Dirichlet allocation .", "label": "", "metadata": {}, "score": "57.38569"}
{"text": "D stands for the size of document collection .Estimating \u03d5 and \u03b8 provides information about the topics in a collection and the weights of those topics in each document .A host of algorithms have been used to estimate these parameters , ranging from Mean field variational methods [ 11 ] , Expectation propagation [ 17 ] , Gibbs sampling [ 18 ] , Collapsed variational inference [ 19 ] to Fast Collapsed Gibbs Sampling [ 20 ] .", "label": "", "metadata": {}, "score": "57.450966"}
{"text": "EHR corpora , however , exhibit specific characteristics when compared with corpora in the biomedical literature domain or the general English domain .This paper is concerned with the inherent characteristics of corpora composed of longitudinal records in particular and their impact on text - mining techniques .", "label": "", "metadata": {}, "score": "57.4948"}
{"text": "At the task of producing generic DUC - style summaries , HIERSUM yields state - of - the - art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al .( 2007 ) 's state - of - the - art discriminative system .", "label": "", "metadata": {}, "score": "57.691116"}
{"text": "Approximation algorithms for performing summarization are also proposed and empirical experiments are conducted to demonstrate the effectiveness of our proposed framework . byPeng Li , Jing Jiang , Shanghai Jiao - In : Proceedings of the 48th ACL . \" ...", "label": "", "metadata": {}, "score": "57.714737"}
{"text": "[ 39 ] suggested a model for unsupervised information extraction which takes redundancy into account when extracting information from the web .They showed that the popular information extraction method , Pointwise Mutual Information ( PMI ) , is less accurate by an order of magnitude compared to a method with redundancy handling .", "label": "", "metadata": {}, "score": "57.83091"}
{"text": "[ 2 ] They look like \" topics \" because terms that frequently occur together tend to be about the same subject .But what comes after the analysis ?Some of the important open questions in topic modeling have to do with how we use the output of the algorithm : How should we visualize and navigate the topical structure ?", "label": "", "metadata": {}, "score": "57.85923"}
{"text": "Herein lies the rub for texts as highly figurative , purposefully ambiguous , and semantically rich as poetry .Returning once again to Blei 's article , he writes : \" The interpretable topic distributions arise by computing the hidden structure that likely generated the observed collection of documents , \" which he clarifies further in a footnote : .", "label": "", "metadata": {}, "score": "57.919937"}
{"text": "Detecting Drug Interactions From Adverse - Event Reports : Interaction Between Paroxetine and Pravastatin Increases Blood Glucose Levels .Clin Pharmacol Ther 2011 , 90 ( 1 ) : 133 - 142 .PubMed View Article .Wang X , Hripcsak G , Markatou M , Friedman C : Active Computerized Pharmacovigilance Using Natural Language Processing , Statistics , and Electronic Health Records : A Feasibility Study .", "label": "", "metadata": {}, "score": "57.923065"}
{"text": "The wealth of information has led to an increasing amount of interest in and need for applying information retrieval techniques to access the scientific literature in genomics and related biomedical disciplines .Hence , it is important of a biomedical IR system to be able to provide relevant and diverse answers to fulfill biologists ' information needs .", "label": "", "metadata": {}, "score": "57.949337"}
{"text": "Drawing from a longstanding tradition of competition between poets and painters and the verbal and visual arts , our most recognized critical model for ekphrasis turns on the axis of difference , otherness , hostility , and competition .LDA , then , offered an attractive alternative for asking questions about the ekphrastic tradition for two reasons .", "label": "", "metadata": {}, "score": "58.088593"}
{"text": "The model algorithmically finds a way of representing documents that is useful for navigating and understanding the collection .In this essay I will discuss topic models and how they relate to digital humanities .I will describe latent Dirichlet allocation , the simplest topic model .", "label": "", "metadata": {}, "score": "58.104862"}
{"text": "In the biological domain , ignoring the correlation within both methods and words would hinder the performance since there are intrinsic relations .In another point of view , from the perspective of involvement of domain experts , some approaches achieved acceptable results on the small data set .", "label": "", "metadata": {}, "score": "58.18525"}
{"text": "11 ] Topic modeling is frequently used to help discover information in a variety of languages .I choose \" other \" rather than \" foreign \" here , since not all \" other \" languages would be for all researchers \" foreign \" ones .", "label": "", "metadata": {}, "score": "58.209373"}
{"text": "pickle_protocol defaults to 2 so the pickled object can be imported in both Python 2 and 3 .Tools . \" ...We present an exploration of generative probabilistic models for multi - document summarization .Beginning with a simple word frequency based model ( Nenkova and Vanderwende , 2005 ) , we construct a sequence of models each injecting more structure into the representation of document set content and exhib ... \" .", "label": "", "metadata": {}, "score": "58.23251"}
{"text": "In order to utilize the CMW model , we need to compute the posterior distribution of the methods in a given document , that is : .Unfortunately , this posterior distribution is intractable : the couples between the continuous variable \u03b8 and discrete variable \u03b2 , \u03f5 induce a combinatorial number of terms , making it impossible to efficiently get the exact inference result .", "label": "", "metadata": {}, "score": "58.2458"}
{"text": "Abstract .Background .The increasing availability of Electronic Health Record ( EHR ) data and specifically free - text patient notes presents opportunities for phenotype extraction .Text - mining methods in particular can help disease modeling by mapping named - entities mentions to terminologies and clustering semantically related terms .", "label": "", "metadata": {}, "score": "58.254757"}
{"text": "Topic models of poetry do not reflect the anecdotal evidence that LDA frequently leads to semantically meaningful word distributions .Instead , topic models of the Revising Ekphrasis dataset created four consistently recurring types of topics .When viewed as forms of discourse , topics can be re - considered in light of whether or not close readings show that individual documents are entering into a form of discourse for a thematic purpose .", "label": "", "metadata": {}, "score": "58.30198"}
{"text": "Link Analysis PageRank [ 22 ] and HITS [ 9 ] are two popular algorithms for link analysis between web pages and they have been success ... . byJie Tang , Limin Yao , Dewei Chen - SIAM International Conference Data Mining , 2009 . \" ...", "label": "", "metadata": {}, "score": "58.322"}
{"text": "A similar pattern is observed at the bi - gram level ( a Zipfian distribution for the non - redundant corpus and a non - Zipfian distribution for the redundant corpus ) .Impact of redundancy on text mining .We have observed that redundant corpora exhibit different statistical profiles than non - redundant ones , according to their word occurrence distributions .", "label": "", "metadata": {}, "score": "58.350006"}
{"text": "One could reasonably expect that since the language of stillness , breathlessness , desire , and competition are commonly found in ekphrastic poetry , that LDA might be able to locate ekphrastic poems within a much larger corpus - in this case 4,500 poems .", "label": "", "metadata": {}, "score": "58.4543"}
{"text": "PubMed View Article .Wrenn JO , Stein DM , Bakken S , Stetson PD : Quantifying clinical narrative redundancy in an electronic health record .J Am Med Inform Assoc 2010 , 17 ( 1 ) : 49 .PubMed View Article .", "label": "", "metadata": {}, "score": "58.493683"}
{"text": "Finally , for each word in each document , choose a topic assignment - a pointer to one of the topics - from those topic weights and then choose an observed word from the corresponding topic .Each time the model generates a new document it chooses new topic weights , but the topics themselves are chosen once for the whole collection .", "label": "", "metadata": {}, "score": "58.56327"}
{"text": "The Last Informative Note corpus is a subset of All Informative Notes , and contains only the most recent note for each patient .Synthetic WSJ redundant corpora .We construct synthetic corpora with a controllable level of redundancy to compare the behavior of the text mining methods on various levels of redundancy .", "label": "", "metadata": {}, "score": "58.57164"}
{"text": "Comparison of the two reranking strategies .The parameter \u03b2 indicates the scale of topics for the retrieved passages .Given different \u03b2 , retrieved passages can be factorized into a series of topics at different scales .We propose two re - ranking algorithms and two distance metrics , and therefore have four re - ranking algorithms , whose re - raking performance can be also shown in Figure 3 .", "label": "", "metadata": {}, "score": "58.740585"}
{"text": "Results and discussion .We collect 5319 full - text documents from PubMed [ 23 ] with method annotations from another two public curated interaction databases : MINT and IntAct .We utilize the macro - precision , macro - recall and macro - Fscore [ 25 ] to evaluate the performance in average .", "label": "", "metadata": {}, "score": "58.748917"}
{"text": "The NSP package we use in our experiments is widely used for collocation and n - gram extraction in the clinical domain [ 19 - 22 ] .Collocations in a corpus of clinical notes are prime candidates to be mapped to meaningful phenotypes [ 19 - 21 ] .", "label": "", "metadata": {}, "score": "58.8974"}
{"text": "Trained on a corpus of noisy Twitter conversations , our method discovers dialogue acts by clustering raw utterances .Because it accounts for the sequential behaviour of these acts , the learned model can provide insight into the shape of communication in a new medium .", "label": "", "metadata": {}, "score": "58.92752"}
{"text": "14 ] .[ 2 ] The process of determining the number of topics to tell the model to use is not , as of yet , a standardized procedure .The measure for the \" right \" topic number is often derived through trial and error .", "label": "", "metadata": {}, "score": "58.942444"}
{"text": "EHR corpora .We collected a corpus of patient notes from the clinical data warehouse of the New York - Presbyterian Hospital .The study was approved by the Institutional Review Board ( IRB - AAAD9071 ) and follows HIPAA ( Health Insurance Portability and Accountability Act ) privacy guidelines .", "label": "", "metadata": {}, "score": "59.05166"}
{"text": "Along with the advent of EHR comes the ability to copy and paste from one note to another .While this functionality has definite benefits for clinicians , among them more efficient documentation , it has been noted that it might impact the quality of documentation as well as introduce errors in the documentation process [ 9 - 13 ] .", "label": "", "metadata": {}, "score": "59.05193"}
{"text": "( We only illustrate part of the clustering result because of the page limit . )From the clustering result in Figure 8 , we can discover that most of the sibling nodes within the MI ontology are successfully clustered with the correct hierarchy ( red circles mean the correct clusters ) .", "label": "", "metadata": {}, "score": "59.085236"}
{"text": "For example , we could apply our approach to other test collections , such as ClueWeb09 collection , to investigate whether the approach is still effective for improving ranking diversity in the Web search .Furthermore , ranking diversity plays an important role in a range of tasks or applications , such as information retrieval , social network analysis and recommendation system , etc .", "label": "", "metadata": {}, "score": "59.100388"}
{"text": "Figure 2 shows the distribution of UMLS concepts ( CUI ) frequencies in the three corpora with expected decreasing levels of redundancy : the All Informative Notes corpus , the All Notes corpus , and the Last Informative Note Corpus .We observe that the profile in the non - redundant Last Informative Note corpus differs markedly from the ones of the redundant corpora ( All Notes and All Informative Notes ) .", "label": "", "metadata": {}, "score": "59.173817"}
{"text": "The model assumes that words in the key word distribution are often found in the context of other words also listed in the key word distribution .[ 10 ] OCR - Optical Character Recognition software visually changes scanned print pages into digitized text .", "label": "", "metadata": {}, "score": "59.181633"}
{"text": "Redundancy across two documents may be measured in different manners : shared words , shared concepts or overlapping word sequences .The most stringent method examines word sequences , and allows for some variation in the sequences ( missing or changed words ) .", "label": "", "metadata": {}, "score": "59.18773"}
{"text": "Textual and literary scholarship requires a willingness to isolate a particular aspect of the text through often abstract or arbitrary constraints , producing what Witmore calls \" unities . \"To a certain extent , textual scholarship implies a double bind : no one can address a text at all of its possible levels simultaneously , and yet , by constraining our understanding of what a text is , we make a caricature of it .", "label": "", "metadata": {}, "score": "59.22062"}
{"text": "For the efficiency reason , we re - ranked only the top 100 passages .Distinctive improvements over all baseline runs in terms of Aspect MAP can be observed .Table 1 shows the comparison of our proposed methods and NLMinter on TREC 2007 Genomics collection .", "label": "", "metadata": {}, "score": "59.26548"}
{"text": "The All EHR corpus , which contains all notes of all types , fits between these two extremes , since we expect less redundancy across note types , even for a single patient .One standard way of characterizing large corpora is to plot the histogram of terms and their raw frequencies in the corpus .", "label": "", "metadata": {}, "score": "59.27684"}
{"text": "In the highly - redundant All Informative Notes corpus , the peak is the most pronounced , with more concepts occurring four to eight times in the corpus than once .Concept - distribution .Distribution of UMLS concept occurrences in corpora with different levels of redundancy .", "label": "", "metadata": {}, "score": "59.410408"}
{"text": "Proc of TREC-15 2006 .Amati G , Rijsbergen CV : Probabilistic models of information retrieval based on measuring the divergence from randomness .ACM Transactions on Information Systems 2002 , 20 ( 4 ) : 357 - 389 .View Article .", "label": "", "metadata": {}, "score": "59.46093"}
{"text": "It discovers a set of \" topics \" - recurring themes that are discussed in the collection - and the degree to which each document exhibits those topics .Figure 1 illustrates topics found by running a topic model on 1.8 million articles from the New York Times .", "label": "", "metadata": {}, "score": "59.465538"}
{"text": "Comparison with the baseline models .We compare the F - score performance of the four models on different proportions of the data used for training .In this comparison , we set the size of topics in the CMW model to be 250 and k in the KNN model to be 37 .", "label": "", "metadata": {}, "score": "59.49179"}
{"text": "The basic idea of above three methods is to penalize redundancy by lowering an item 's rank if it is similar to the items already ranked .However , these methods often treat relevance ranking and diversity ranking separately , and sometimes with heuristic procedures .", "label": "", "metadata": {}, "score": "59.56245"}
{"text": "Conditioned on the model parameters ( \u03b1 , \u03b2 , \u03b7 ) , the CMW model assumes the following generative process of the methods and related words in one document : .Our basic notion about each component of this model is that , the discrete occurrences of detection methods and related words in the given document are governed by the topic - specific distributions ( e.g. matrix \u03f5 and \u03b2 ) respectively .", "label": "", "metadata": {}, "score": "59.77863"}
{"text": "McCallum AK : Mallet : A machine learning for language toolkit .Wallach H , Mimno D , McCallum A : Rethinking LDA : Why priors matter .Advances in Neural Information Processing Systems 2009 , 22 : 1973 - 1981 .", "label": "", "metadata": {}, "score": "59.924805"}
{"text": "Methods .Correlated Method - Word model .We present the Correlated Method - Word model ( CMW model ) to extract the detection methods from the biological literature .The CMW model is depicted in Figure 1 with graphical representation .", "label": "", "metadata": {}, "score": "60.002182"}
{"text": "The joint probability can be obtained from the graph by taking the product of the conditional distribution of nodes given their parents , see Eq ( 1 ) .Graphical model representation of the CMW model .Following the standard graphical model formalism [ 19 ] : nodes represent the random variables and edges indicate the possible dependence .", "label": "", "metadata": {}, "score": "60.015675"}
{"text": "We use a pre - estimated threshold to retrieval the most probable methods .In the KNN model , we make the prediction by ranking the candidate methods in the union of the unlabeled sample 's k -nearest labeled neighbors , and weight the candidate methods by the similarity between the desired unlabeled sample and its neighbors .", "label": "", "metadata": {}, "score": "60.01956"}
{"text": "Admission notes showed a redundancy of 30 % compared to the progress , discharge and sign - out notes of the same patient .More recently , Zhang et al .[ 15 ] experimented with different metrics to assess redundancy in outpatient notes .", "label": "", "metadata": {}, "score": "60.221813"}
{"text": "The save method does not automatically save all NumPy arrays using NumPy , only those ones that exceed sep_limit set in gensim.utils.SaveLoad.save .Return a list of ( word , probability ) 2-tuples for the most probable words in topic topicid .", "label": "", "metadata": {}, "score": "60.300755"}
{"text": "Proc of the 21st ACM SIGIR 1998 .Zhang Y , Callan J , Minka T : Novelty and redundancy detection in adaptive filtering .Proc of the 25th ACM SIGIR 2002 .Zhai C , Cohen W , Lafferty J : Beyond independent relevance : methods and evaluation metrics for subtopic retrieval .", "label": "", "metadata": {}, "score": "60.471237"}
{"text": "corpus must be an iterable ( repeatable stream of documents ) , .In distributed mode , the E step is distributed over a cluster of machines .This update also supports updating an already trained model ( self ) with new documents from corpus ; the two models are then merged in proportion to the number of old vs. new documents .", "label": "", "metadata": {}, "score": "60.627472"}
{"text": "Therefore , another algorithm named rank - NWin - Group is proposed to ensure that the new ranking S is just the original ranking R with slight adjustments .The key idea of this algorithm is described below .For the first passage in S , we still choose a passage containing the largest aspect coverage from the slide window , add it into S and remove it from R .", "label": "", "metadata": {}, "score": "60.71569"}
{"text": "WSJx2 , WSJx3 , and WSJs5 are all larger in size than WSJ-1300 .We therefore would expect them to reach higher log - likelihood , but this does not occur .Instead , their log - likelihood graphs keep increasing as the number of topics increases , all the while remaining consistently inferior to the WSJ-1300 corpus , from which they are derived .", "label": "", "metadata": {}, "score": "60.733932"}
{"text": "This baseline run proposes a new approach to the generation of orthographic variants of search terms , and the generation of the I(n)B2 [ 23 ] with the article title included in each passage , or with both the article and orthographic variants .", "label": "", "metadata": {}, "score": "60.923378"}
{"text": "We focus on the All Informative Notes corpus .The metadata - based baseline produces the Last Informative Note corpus .The content - based mitigation strategy , which relies on fingerprinting , can produce corpora with varying levels of redundancy .", "label": "", "metadata": {}, "score": "60.9423"}
{"text": "Chatr - aryamontri A , Ceol A , Licata L , Cesareni G : Annotating molecular interactions in the MINT database .Proceedings of the second biocreative challenge evaluation workshop 2007 , 55 - 59 .Krallinger M , Leitner F , Valencia A : Assessment of the Second BioCreative PPI task : Automatic Extraction of Protein - Protein Interactions .", "label": "", "metadata": {}, "score": "61.003464"}
{"text": "Therefore , Aspect MAP is a measurement for both relevance and diversity of an IR ranked list .Our work is inspired by several recent papers that concerned with promoting ranking diversity in IR ranked list .The most representative method is maximum marginal relevance ( MMR ) proposed by Carbonell et al .", "label": "", "metadata": {}, "score": "61.037186"}
{"text": "The fact that redundancy never occurs across patients , but within same - patient notes only , seems to create unintended biases in the extracted collocations .The results on the WSJ and its synthetic variants confirm our results on the EHR corpora : collocations extracted on a redundant corpus differ significantly from those extracted on a corpus of similar size without redundancy .", "label": "", "metadata": {}, "score": "61.07678"}
{"text": "Siegler EL , Adelman R : Copy and Paste : A Remediable Hazard of Electronic Health Records .Am J Med 2009 , 122 ( 6 ) : 495 - 496 .PubMed View Article .Markel A : Copy and Paste of Electronic Health Records : A Modern Medical Illness .", "label": "", "metadata": {}, "score": "61.10643"}
{"text": "Fingerprinting algorithm .Detecting redundancy within the notes of a single patient is feasible using standard alignment methods borrowed from bioinformatics such as : Smith - Waterman [ 52 ] , FastA [ 41 ] or Blast2seq [ 40 ] .However , some available EHR corpora are de - identified to protect patient privacy [ 57 ] and notes are not grouped by patients .", "label": "", "metadata": {}, "score": "61.166885"}
{"text": "We put each group into the slide window in turn , re - rank the passages in current group , and add them into S finally .The process of re - ranking in groups is similar to algorithm rank - NWin .", "label": "", "metadata": {}, "score": "61.21691"}
{"text": "Declarations .Acknowledgements .The authors would like to thank anonymous reviewers for their valuable comments and suggestions .This research is supported by the Fund of State Key Laboratory of Software Development Environment ( under grant no . SKLSDE-2011ZX-03 ) and the National Natural Science Foundation of China ( under grant no .", "label": "", "metadata": {}, "score": "61.24666"}
{"text": "Metric for assessing redundancy at the patient level .Given two notes , we computed redundancy for the pair by aligning the two notes .We applied the Smith - Waterman text alignment algorithm , a commonly used string alignment algorithm in bioinformatics [ 52 ] .", "label": "", "metadata": {}, "score": "61.35232"}
{"text": "where D is the set of documents associating with the desired method e and M d is the number of words in the document d .In Table 3 , we collect top 20 terms for 6 different methods according to Eq ( 15 ) from the corpus .", "label": "", "metadata": {}, "score": "61.41205"}
{"text": "For example , we can isolate a subset of texts based on which combination of topics they exhibit ( such as film and politics ) .Or , we can examine the words of the texts themselves and restrict attention to the politics words , finding similarities between them or trends in the language .", "label": "", "metadata": {}, "score": "61.44507"}
{"text": "Pfam [ 44 ] is a non - redundant protein sequence database manually built using representatives from each protein family .This database is used for construction of Hidden - Markov - Model classifiers widely used in Bioinformatics .When constructing a corpus of patient notes for statistical purposes , we encounter patients with many records .", "label": "", "metadata": {}, "score": "61.633007"}
{"text": "It would take even the most proficient human reader an extraordinary period of time to read 17,000 articles from Science .Therefore , while we know through disciplinary familiarity and deduction that the topics in Figure 2 are likely topics to be found throughout the journal 's publication , we would n't be able to detect or retain those patterns through human reading .", "label": "", "metadata": {}, "score": "61.646774"}
{"text": "The E - Step and M - Step are repeated until the bound on the likelihood converges ( relative change in likelihood is less than 0.001 % ) .The convergency rate of the process depends on the size of parameters in the model , ( e.g. number of words , methods and topics ) .", "label": "", "metadata": {}, "score": "61.700695"}
{"text": "Some topics have higher probabilities of appearing in the document than others , as represented by the taller bars in the graph .On the right side of the graphic , the topic keyword distributions are listed vertically in columns .At the top of each column is a bolded word surrounded by quotation marks that serves as a label created by Blei to describe the words in the topic and demonstrating Blei 's rationale for claiming that topics are thematic .", "label": "", "metadata": {}, "score": "61.71519"}
{"text": "We use SV M light [ 27 ] toolkit to implement a linear kernel SVM model with the default parameters .We perform comparisons on different proportions of the data used for training .In this comparison , we set the size of topics in the CMW model to be 250 and k in the KNN model to be 37 .", "label": "", "metadata": {}, "score": "61.736122"}
{"text": "The input , Full EHR corpus , is the largest .As expected , the Last Informative Note corpus obtained through our metadata - based baseline is the smallest corpus .While redundancy is reduced , its size is also drastically decreased from the original corpus .", "label": "", "metadata": {}, "score": "61.747154"}
{"text": "The shapes of the distributions of concepts differ depending on the presence of redundancy in the corpus .The difference in shapes of distributions confirms in a qualitative fashion our hypothesis about the three corpora and their varying levels of redundancy .", "label": "", "metadata": {}, "score": "61.78904"}
{"text": "Competing interests .The authors declare that they have no competing interests .Authors ' contributions .YC proposed reranking strategies , carried on the experiments and drafted the manuscript .XY and JXH contributed in the study design and experiments .", "label": "", "metadata": {}, "score": "61.857803"}
{"text": "PubMed View Article .O'Donnell HC , Kaushal R , Barr\u00f3n Y , Callahan MA , Adelman RD , Siegler EL : Physicians ' Attitudes Towards Copy and Pasting in Electronic Note Writing .J Gen Intern Med 2009 , 24 ( 1 ) : 63 - 68 .", "label": "", "metadata": {}, "score": "62.08938"}
{"text": "To formulate this notion in a probabilistic framework , we follow the general settings in the LDA model that we assume the document - specific topic proportion \u03b8 is drawn from the k -dimensional Dirichlet distribution Dir ( \u03b1 ) , which determines the topic mixture proportion .", "label": "", "metadata": {}, "score": "62.113476"}
{"text": "Although the algorithm can not account for what words mean , much like your method of discovery about Asian pears , LDA does a surprisingly good job of sorting words based on co - occurrence .Finally , LDA sorts words into topics based on prior knowledge that there are a finite number of topics in the overall corpus - much the same way that you knew to look for 10 types of produce .", "label": "", "metadata": {}, "score": "62.15664"}
{"text": "Authors ' Affiliations .Department of Computer Science , Ben - Gurion University in the Negev .Department of Biomedical Informatics , Columbia University .References .Friedman : A general natural - language text processor for clinical radiology .Jamia - Journal of the American Medical Informatics Association 1994 , 1 ( 2 ) : 161 .", "label": "", "metadata": {}, "score": "62.191875"}
{"text": "PubMed View Article .Li W : Random texts exhibit Zipf's - law - like word frequency distribution .Information Theory , IEEE Transactions on 1992 , 38 ( 6 ) : 1842 - 1845 .View Article .Yoshimasa Tsuruoka YT , Jin - Dong K , Tomoko O , Sophia A , Jun'ichi T : Developing a Robust Part - of - Speech Tagger for Biomedical Text .", "label": "", "metadata": {}, "score": "62.205536"}
{"text": "However , a given document set usually covers a few topic themes with each theme represented by a cluster of sentences .The topic themes are usually not equally important and the sentences in an important theme cluster are deemed more salient than the sentences in a trivial theme cluster .", "label": "", "metadata": {}, "score": "62.285057"}
{"text": "In Nelson 's project , poetry is combined with opinion articles and political and agricultural reports , and the composition of the dataset seemingly allows the poetic texts to map well with its prose counterparts .However , topic models of purely figurative language texts like poetry do not produce topics with the same thematic clarity as those in Blei 's topic model of Science or even Nelson 's model of the Richmond Daily Dispatch .", "label": "", "metadata": {}, "score": "62.340347"}
{"text": "However can someone explain what it means to choose larger values of these hyperparameters versus smaller values ?Does that mean putting any prior beliefs in terms of topic sparsity in documents and mutual exclusiveness of topics in terms of words ?", "label": "", "metadata": {}, "score": "62.389137"}
{"text": "Cormode G , Hadjieleftheriou M : Finding frequent items in data streams .Proceedings of the VLDB Endowment 2008 , 1 ( 2 ) : 1530 - 1541 .Copyright .\u00a9 Cohen et al . ; licensee BioMed Central Ltd. 2013 .", "label": "", "metadata": {}, "score": "62.45736"}
{"text": "A mixture of such shells can then also be so instantia ... \" .We introduce a method to learn a mixture of submodular \" shells \" in a large - margin setting .A submodular shell is an abstract submodular function that can be instantiated with a ground set and a set of parameters to produce a submodular function .", "label": "", "metadata": {}, "score": "62.458603"}
{"text": "An alternative route to text mining in the presence of high levels of redundancy consists of keeping all the existing redundant data , but designing redundancy immune statistical learning algorithms .This is a promising route of future research .Methods .", "label": "", "metadata": {}, "score": "62.48595"}
{"text": "56 ] .The log - likelihood graphs were computed on withheld datasets .A non - redundant withheld dataset of 233 Informative notes was created for EHR corpus ( all the notes from the same patients were removed from the redundant corpora to prevent contamination between corpora and the withheld dataset ) .", "label": "", "metadata": {}, "score": "62.551384"}
{"text": "Note : do not save as a compressed file if you intend to load the file back with mmap .Note : If you intend to use models across Python 2/3 versions there are a few things to keep in mind : .", "label": "", "metadata": {}, "score": "62.688446"}
{"text": "Genomics collections only contain a fraction of millions of biomedical literatures indexed by MEDLINE , but as far as we know , they are the largest and the only biomedical text collections with both manual relevance assessments and diversity evaluation available for biomedical text retrieval research .", "label": "", "metadata": {}, "score": "62.729736"}
{"text": "Acknowledgements .This work was supported by the Chinese Natural Science Foundation under grant No .60572084 , National High Technology Research and Development Program of China ( 863 Program ) under No .2006AA02Z321 , as well as Tsinghua Basic Research Foundation under grant No . 052220205 and No . 053220002 .", "label": "", "metadata": {}, "score": "62.76399"}
{"text": "In this section , we introduce two re - ranking algorithms based on a slide window to promote ranking diversity .We set the slide window with size N , and put top N passages from R as candidate passages into the slide window when re - ranking .", "label": "", "metadata": {}, "score": "62.9514"}
{"text": "I 'm trying to easily implement ... .I have texts and their metadata and a response variable ( how many times the text has been read ) .I 'm interesting in finding out how the latent topics in the set of texts are related to the popularity ... .", "label": "", "metadata": {}, "score": "63.000183"}
{"text": "Since we focus on biomedical domain , we tend to employ smaller values of \u03b2 , which will result in more topics that address specific fields .We should choose the value of \u03b2 for each specific user query .In order to improve experimental efficiency , we choose \u03b2 according to the retrieval passages instead .", "label": "", "metadata": {}, "score": "63.008682"}
{"text": "Methods .Aspects from retrieved passages can not simply be identified on word level because a specific word can be used to represent more than one topic in different passage contexts .In this case , we assume that aspects should be identified by latent topics hidden in passages which are considered to be more abstract .", "label": "", "metadata": {}, "score": "63.016262"}
{"text": "This is not the case , however , in a genre like poetry , where the use of highly figurative speech actually increases the scope of the language one might expect to see in a document .For example , literary devices such as metaphor or simile compare two objects , experiences , or feelings that are completely unalike , and in doing so isolates and heightens our awareness of what makes them similar .", "label": "", "metadata": {}, "score": "63.3818"}
{"text": "What makes a text a text - its susceptibility to varying levels of address - is a feature of book culture and the flexibility of the textual imagination .We address ourselves to this level , in this work , and think about its relation to some other .", "label": "", "metadata": {}, "score": "63.419167"}
{"text": "See Table 2 .The second type of error , loss of signal can also be observed .Another method for selecting the significant collocations is using a top - N cutoff instead of a PMI cutoff .Comparing the top 1,000 collocations with TMI for All Informative Notes and Last Informative Notes , we find a marked difference of 196 collocations .", "label": "", "metadata": {}, "score": "63.42089"}
{"text": "The matching performance is demonstrated in Table 1 .We apply a string matching algorithm with all the names / synonyms from the MI ontology on a set of 740 documents , annotated with 96 methods and provided by the BioCreative II challenge evaluation .", "label": "", "metadata": {}, "score": "63.42331"}
{"text": "Furthermore , words in one passage are not independent , which together construct passage topics .It can be also observed that two passages even with the same words can express different topics .We thus assume that latent topics can be identified by word distribution .", "label": "", "metadata": {}, "score": "63.45097"}
{"text": "The detection methods available to identify protein interactions vary in their level of resolution and the confidence of reliability .Therefore , it is important to identify such detection methods in order to validate the reported interactions .Some interaction databases , such as MINT [ 6 ] and IntAct [ 7 ] , require the interaction entries to be experimentally confirmed .", "label": "", "metadata": {}, "score": "63.47371"}
{"text": "Existing work can be mainly classified into two categories : supervised method and unsupervised method .The former requires training examples , which makes the method limited to predefined domains .While the latter usually utilizes clustering algorithms to find ' centered ' sentences as the summary .", "label": "", "metadata": {}, "score": "63.499603"}
{"text": "class gensim.models.ldamodel .The constructor estimates Latent Dirichlet Allocation model parameters based on a training corpus : .If given , start training from the iterable corpus straight away .If not given , the model is left untrained ( presumably because you want to call update ( ) manually ) .", "label": "", "metadata": {}, "score": "63.539795"}
{"text": "A high beta - value will similarly lead to topics being more similar in terms of what words they contain .So , yes , the alpha - parameters specify prior beliefs about topic sparsity / uniformity in the documents .I 'm not entirely sure what you mean by \" mutual exclusiveness of topics in terms of words \" though .", "label": "", "metadata": {}, "score": "63.545197"}
{"text": "The observation illustrates that there are a clear correlation between Aspect MAP and Passage MAP .Furthermore , we demonstrate that two different distance metrics , with or without weight , do not influence re - ranking performance significantly .The comparison results shown in Figure 3 indicate that both of the two proposed re - ranking methods are effective in promoting diversity for biomedical information retrieval , and rank - NWin - Group outperforms rank - NWin in most cases .", "label": "", "metadata": {}, "score": "63.63683"}
{"text": "This is expected based on the definition of PMI , and we confirm this prediction on WSJx2 and WSJx3 which produce exactly the same list of collocations as WSJ-1300 ( WSJx2 is a corpus constructed by doubling every document in WSJ-1300 ) .", "label": "", "metadata": {}, "score": "63.68941"}
{"text": "We expect redundancy to be high across notes of the same patient and low across notes of distinct patients .Furthermore , within a single patient record , we expect heavy redundancy across notes from the same note types .We report redundancy on same patient / similar note type ( we focus on the most informative note types : primary provider , follow up and clinical notes ; in this analysis we ignore the template - based note types which are redundant by construction ) .", "label": "", "metadata": {}, "score": "63.7544"}
{"text": "What our algorithm learns are the mixture weights over such shells .We provide a risk bound guarantee when learning in a large - margin structured - prediction setting using a projected subgradient method when only approximate submodular optimization is possible ( such as with submodular function maximization ) .", "label": "", "metadata": {}, "score": "63.825096"}
{"text": "For TREC 2007 Genomics track , there are three levels of retrieval performance measured : passage retrieval , aspect retrieval , and document retrieval .Each of these provides insight into the overall performance for a user trying to answer the given questions .", "label": "", "metadata": {}, "score": "63.850105"}
{"text": "For the purposes of modeling poetry data , word intrusion would not be as effective a method for determining a model 's accuracy at categorizing documents or detecting latent patterns unless the specific changes that happen to the nature of topic distributions for poetic corpora are adjusted for . \" Intruders \" as individual words does not work for LDA topics of poetry because poems purposefully access and repurpose language in unexpected ways .", "label": "", "metadata": {}, "score": "63.8789"}
{"text": "In particular , both the topics and the document weights are probability distributions .The topics are distributions over terms in the vocabulary ; the document weights are distributions over topics .( For example , if there are 100 topics then each set of document weights is a distribution over 100 items . )", "label": "", "metadata": {}, "score": "63.94152"}
{"text": "I am running into a few issues regarding the output .To test it , I was using a file with just 3 lines ( 3 documents ... .Reading the help of CrossValidated about wether or not this question would belong here and StackOverflow it says \" if it needs statistical expertise to understand or answer , ask it here \" .", "label": "", "metadata": {}, "score": "63.94936"}
{"text": "Mitigation strategies for handling redundancy .Metadata - based baseline .The metadata - based mitigation strategy leverages the note creation date , the note type and the patient identifier information and selects the last available note per patient in the corpus .", "label": "", "metadata": {}, "score": "64.01805"}
{"text": "Background .Interaction detection method extraction .The study of protein interactions is one of the most pressing biological problems .In the literature mining community , considerable efforts have been made to automatically extract the protein - protein interactions ( PPI ) from the literature [ 1 - 3 ] and some practical systems have been put into use [ 4 , 5 ] .", "label": "", "metadata": {}, "score": "64.04041"}
{"text": "Minka TP : Expectation Propagation for approximate Bayesian inference .Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence 2001 , 362 - 369 .Attias H : A variational Bayesian framework for graphical models .Advances in Neural Information Processing Systems 2000 , 209 - 215 .", "label": "", "metadata": {}, "score": "64.064865"}
{"text": "Its purpose is to study how a biomedical retrieval system can support a user to gather information about different aspects of a query .Biomedical retrieval system should return relevant information at the passage level ; meanwhile , judges would comprehensively rate the retrieved passages by relevance as well as aspect diversity .", "label": "", "metadata": {}, "score": "64.12544"}
{"text": "We develop an alternating EM procedure to find the optimal parameters as follows : .( E - Step )For each document in the training corpus , optimizing the variational parameters ( \u03b3 , \u03d5 , \u03bb , \u03c3 ) according to equations ( 3 ) - ( 6 ) ; .", "label": "", "metadata": {}, "score": "64.22365"}
{"text": "Interpreting Models of Figurative Language Texts .Topic models of poetry do have a form of comprehensibility , but our understanding of coherence between topic keywords needs to be slightly different in models of poetry than in models of non - fiction texts .", "label": "", "metadata": {}, "score": "64.25805"}
{"text": "However , the second passage is not redundant in fact .The above problems are due to two following reasons : firstly , one or more co - occurrence words in a passage are used to identify the aspect .However , it is common sense for us that a specific word can express more than one latent topics according to different contexts in a passage .", "label": "", "metadata": {}, "score": "64.33478"}
{"text": "Training and improvement of NLP tools for Medical - Informatics tasks on public available data will continue growing as more EHRs are incorporated into health care givers worldwide .The nature of epidemiological research demands looking at cohorts of patients , such as our kidney patient notes .", "label": "", "metadata": {}, "score": "64.37037"}
{"text": "This manner is somehow analogous to the idea that to extract templates from the overlapping of different method descriptions .But the diversity in the method mentions brings the traditional template generation algorithms with low support and low confidence problems .Furthermore , when there are multiple methods in one document , the traditional approach would fail to figure out the latent correlations .", "label": "", "metadata": {}, "score": "64.46254"}
{"text": "We investigate whether a redundant corpus exhibits a different distribution of concepts than a less redundant one .We expect that different subsets of the EHR corpus exhibit different levels of redundancy .The All Informative Notes corpus , which contains several notes per patient , but only the ones of types : \" primary - provider \" , \" clinical - note \" and \" follow - up - note \" , is assumed to be highly redundant , since it is homogeneous in style and clinical content .", "label": "", "metadata": {}, "score": "64.56784"}
{"text": "Relevance distribution in relevant and irrelevant documents .In the diagram , red line indicates the relevance scores in the relevant document set and the blue dots indicate the relevance scores in the irrelevant document set .If we select the classification threshold as the green line indicates , we would achieve a promising classification performance : in terms of precision 0.745 , recall 0.676 and AUC 0.819 .", "label": "", "metadata": {}, "score": "64.60589"}
{"text": "Assessing redundancy through alignment is a more appropriate and more stringent method than counting simple token overlap as in a bag - of - word model .High percentage of alignment between two notes indicates not only that tokens are similar across the two notes , but that the sequences of tokens in the notes are also similar .", "label": "", "metadata": {}, "score": "64.650536"}
{"text": "because even a disciplinary expert might have trouble identifying the \" intruder \" word as an outlier .Table 3 : Titles of the 15 poems with the highest predicted proportions of Topic 2 in them and their corresponding topic distributions .", "label": "", "metadata": {}, "score": "64.66765"}
{"text": "Word intrusion tests ( the kind suggested by Chang , et .Semantically opaque topics - Some topics , such as Topic 2 in \" The Starry Night , \" appear at first to have little comprehensibility .Unlike semantically evident topics , they are difficult to synthesize into the single phrases simply by scanning the keywords associated with the topic .", "label": "", "metadata": {}, "score": "64.81642"}
{"text": "Understanding how topic modeling algorithms handle figurative language means allowing for a similar beautiful failure - not a failure of language , but a necessary inclination toward form that involves a diminishing of language 's possible meanings .In the following article , I suggest that topic modeling poetry works , in part , because of its failures .", "label": "", "metadata": {}, "score": "64.86441"}
{"text": "5 ] ( After all , the theory is built into the assumptions of the model . )Rather , the hope is that the model helps point us to such evidence .Using humanist texts to do humanist scholarship is the job of a humanist .", "label": "", "metadata": {}, "score": "64.88374"}
{"text": "Experimental results on the DUC benchmark datasets demonstrate the effectiveness of the proposed multi - modality learning algorithms with all the three fusion schemes .I want to compute the similarity between documents of two groups of documents .All documents have the same term vector of length 100 , but documents in group A are probabilities , whereas documents in ... .", "label": "", "metadata": {}, "score": "64.91443"}
{"text": "Table 8 provides descriptive statistics of the different WSJ - based corpora with which we experiment : .The WSJ-1300 corpus contains a random sample of 1,300 documents from the Wall Street Journal corpus , .The WSJ-400 corpus is a subset of WSJ-1300 of 400 documents , .", "label": "", "metadata": {}, "score": "64.98384"}
{"text": "It also supports the special value ' auto ' , which learns an asymmetric prior directly from your data .Turn on distributed to force distributed computing ( see the web tutorial on how to set up a cluster of machines for gensim ) .", "label": "", "metadata": {}, "score": "65.00627"}
{"text": "Some are template based , such as radiology or lab reports , and others are less structured and contain mostly free text .We identified that note types : \" primary - provider \" , \" clinical - note \" and \" follow - up - note \" contain more information than other note types .", "label": "", "metadata": {}, "score": "65.25208"}
{"text": "Less stringent metrics include : amount of shared words , amount of shared concepts or amount of overlapping bi - grams [ 16 ] .While these methods have been shown to identify semantic similarity of texts , they do not specifically capture instances of copy - paste operations , which reproduce whole paragraphs .", "label": "", "metadata": {}, "score": "65.26423"}
{"text": "One by one as your neighbors return , you survey the contents of their baskets .Looking into more and more baskets and revising your predictions , you reconsider based on which produce appears together in a basket the most frequently how to reorganize the 10 produce types .", "label": "", "metadata": {}, "score": "65.490555"}
{"text": "Note that the WSJs5 corpus has roughly 2.5 times the size of WSJ-1300 .The process was repeated 10 times to eliminate bias from the choice of documents repeated .Synthetic corpora with various levels of redundancy , for WSJs5 we report averages and standard deviation based on 10 replications .", "label": "", "metadata": {}, "score": "65.613846"}
{"text": "It 's not in document form , because I pre - selected certain ... .I have an unpublished corpus consisting of 135 texts representing one year each .I do topic modelling ( using Mallet ) and then inspect the topic distribution over time .", "label": "", "metadata": {}, "score": "65.64802"}
{"text": "The humanities , fields where questions about texts are paramount , is an ideal testbed for topic modeling and fertile ground for interdisciplinary collaborations with computer scientists and statisticians .The Wider World of Probabilistic Models .Topic modeling sits in the larger field of probabilistic modeling , a field that has great potential for the humanities .", "label": "", "metadata": {}, "score": "65.672134"}
{"text": "The whole corpus consists of 115 unique method annotations , and each document associates with 1.99 different methods in average .Figure 3 demonstrates the unbalanced method distribution on the whole corpus .Statistics of the corpus .In the whole corpus , 5 dominate detection methods take up nearly 59.3 % occurrences and 86.1 % ( 99 out of 115 ) methods occur in less than 10 % documents .", "label": "", "metadata": {}, "score": "65.71308"}
{"text": "While semantically evident topics gravitate toward recurring images , metaphors , and particular literary devices , semantically opaque topics often emphasize tone .Searching for thematic coherence in topics formed from poetic corpora would prove disappointing since topic keyword distributions in a thematic light appear at first glance to be riddled with \" intrusions . \"", "label": "", "metadata": {}, "score": "65.749725"}
{"text": "For collocations detection , in Reduced Redundancy Informative Notes , 6,034 collocations were extracted , on average each collocation is supported by 37 distinct patients and collocations supported by 3 patients or less make 6 % of the extracted collocation .We see a significant reduction in the number of collocations based on very few patients from 36 % to 6 % ( Table 3 ) .", "label": "", "metadata": {}, "score": "65.77551"}
{"text": "We arrange the relevance scores in a descending order in Figure 9 , so that it is easy to discover that the relevance scores in the relevant document set are significantly greater than those in the irrelevant document set .If we select the threshold as the green line indicated , we would achieve a promising classification performance : in terms of precision 0.745 , recall 0.676 and AUC 0.819 .", "label": "", "metadata": {}, "score": "65.78357"}
{"text": "4 : Given top N passages in R , we find a passage pass 1 containing the most aspect coverage value using Eq . 8 : Choose top N passages in R as candidate passages and if the length of rank R is less than N , take all passages in R as candidate passages ; . 9 : for each passage i of candidate passages do .", "label": "", "metadata": {}, "score": "66.1337"}
{"text": "It is a full - text biomedical collection consisting of 162,259 documents from about 49 genomics - related journals indexed by MEDLINE [ 1 , 2 ] .There are 36 official topics for the track in 2007 , which are in the form of questions asking for lists of specific entities that cover different portions of full answers .", "label": "", "metadata": {}, "score": "66.287346"}
{"text": "There is a wide variation in the number of notes per patient , either because of their health status , or because some patients go to different health providers while others have all their visits in the same institution .Furthermore , clinicians typically copy and paste information from previous notes when documenting a current patient encounter .", "label": "", "metadata": {}, "score": "66.34203"}
{"text": "PubMed View Article .Hirschtick R : A piece of my mind .Copy - and - paste .JAMA 2006 , 295 ( 20 ) : 2335 - 2336 .PubMed View Article .Yackel TR , Embi PJ : Copy - and - paste - and - paste .", "label": "", "metadata": {}, "score": "66.36194"}
{"text": "For plagiarism detection , HaCohen - Kerner et al .[42 ] compare two fingerprinting methods : ( i ) Full fingerprinting - all substrings of length n of a string are used as fingerprints .This means that for a string of length m , m - n+1 fingerprints will be used ; and ( ii ) Selective Fingerprinting - non - overlapping substrings are chosen .", "label": "", "metadata": {}, "score": "66.54462"}
{"text": "Those represent the individual produce items in each produce type that could be found in the places in the text that are highlighted in yellow , pink , and blue .Figure 1 : Illustrative example of Science topic model ( Blei \" Introduction \" 78 ) .", "label": "", "metadata": {}, "score": "66.60167"}
{"text": "Algorithm 2 rank - NWin - Group Algorithm .1 : Input : An initial passage ranking R produced for current user query only with respect to relevance , and the size N of the slide window .2 : Output : A reranked passage list S . 3 : Process : .", "label": "", "metadata": {}, "score": "66.72905"}
{"text": "The most common OCR errors have been filtered out through a preprocessing technique that searches for such errors and fixes them ; however , machines are n't perfect and some of these features remain in the final dataset .Their presence may sort out as if they were features of another language .", "label": "", "metadata": {}, "score": "66.7514"}
{"text": "In the case of Topic 12 , the poems included in the topic and shown in Table 2 tend to be longer and to include greater incidence of repetition .It is possible that these poems share thematic affinities , but the strength of those affinities have more to do with linguistic structure than meaning .", "label": "", "metadata": {}, "score": "66.83394"}
{"text": "By \u03c7 2 statistic , we approximate the dependence between word t and method e , so that we can preserve the words , which are the most relevant to the method descriptions , by the following formulation : .In the following experiments , we select the top 3000 terms to build up the feature set according to Eq ( 13 ) .", "label": "", "metadata": {}, "score": "66.87721"}
{"text": "Notes contain the following metadata : unique patient identifier , date , and note type ( e.g. , Primary - Provider ) .HealthTermFinder identifies named - entities mentions and maps them against semantic concepts in UMLS [49 ] .As such , it is possible to map lexical variants ( e.g. , \" myocardial infarction , \" \" myocardial infarct , \" \" MI , \" and \" heart attack \" ) of the same semantic concept to a UMLS CUI ( concept unique identifier ) .", "label": "", "metadata": {}, "score": "66.90391"}
{"text": "Model selection results .Figure 2 shows the log - likelihood of the data for different settings of the number of topics T for query 200 , 221 and 231 with \u03b2 being equal to 0.06 .As mentioned above , the value of T depends on the choices of \u03b1 and \u03b2 , which will also be affected by specific decisions made in forming the dataset such as the use of stop - word list , etc .", "label": "", "metadata": {}, "score": "66.96417"}
{"text": "Mach Learn 2010 , 79 ( 1 ) : 123 - 149 .View Article .Blitzer J , Dredze M , Pereira F : Biographies , bollywood , boom - boxes and blenders : Domain adaptation for sentiment classification .Moore RC , Lewis W : Intelligent selection of language model training data .", "label": "", "metadata": {}, "score": "67.06062"}
{"text": "High redundancy and copy - and - paste operations in the notes create a biased sample of the \" patient note \" genre .From a practical perspective , redundant data in a corpus lead to waste of CPU time in corpus analysis and waste of I / O and storage space especially in long pipelines , where each stage of data processing yields an enriched set of the data .", "label": "", "metadata": {}, "score": "67.15096"}
{"text": "First , we choose a passage from the slide window as the first passage in ranking S , which contains the largest aspect coverage as show in Eq . where N t ( a tq ) denotes the importance of passage P q for the aspect A t and stands for the aspect coverage of passage P q .", "label": "", "metadata": {}, "score": "67.599106"}
{"text": "What does this have to do with the humanities ?Here is the rosy vision .A humanist imagines the kind of hidden structure that she wants to discover and embeds it in a model that generates her archive .The form of the structure is influenced by her theories and knowledge - time and geography , linguistic theory , literary theory , gender , author , politics , culture , history .", "label": "", "metadata": {}, "score": "67.62427"}
{"text": "[ 7 ] For simplicity 's sake , I have ignored the smaller topics and will focus just on the top three topics found in the document .In Table 1 , which directly follows the poem , there are three columns that list the topics from which \" The Starry Night \" is predicted by the LDA to draw most heavily .", "label": "", "metadata": {}, "score": "67.6788"}
{"text": "\u0398 i denotes the importance distribution of passage collection for the aspect A i .Re- ranking with N -size slide window .Re- ranking problem is defined as this : Given a query q and an initial ranking R produced for this query only with respect to relevance , we build a new ranking S taking account of both relevance and diversity .", "label": "", "metadata": {}, "score": "67.981766"}
{"text": "Two implications of noise are possible .The first is false positive identification , i.e. , extracting collocations which are the result of mere chance .The second implication is loss of significant collocations due to noise ( or because important collocations are out - ranked by less important ones ) .", "label": "", "metadata": {}, "score": "68.02519"}
{"text": "We artificially introduce redundancy by randomly sampling documents and repeating them until a controlled level of redundancy is achieved .Collocation identification .We expect that in a redundant corpus , the word sequences ( n - grams ) which are copied often will be over - represented .", "label": "", "metadata": {}, "score": "68.07466"}
{"text": "The process is not unlike the critical assumptions made about ekphrasis - that it draws repeatedly from the same tropes and conventions .Unpacking the Assumptions of LDA .I will return to this example throughout the article to illustrate how highly figurative language texts such as poetry respond to LDA differently than texts that strive for more literal meaning .", "label": "", "metadata": {}, "score": "68.28078"}
{"text": "id2word is a mapping from word ids ( integers ) to words ( strings ) .It is used to determine the vocabulary size , as well as for debugging and topic printing . alpha and eta are hyperparameters that affect sparsity of the document - topic ( theta ) and topic - word ( lambda ) distributions .", "label": "", "metadata": {}, "score": "68.3721"}
{"text": "The traditional discriminative classifiers are not able to figure out such relationships .Methods clustering tree .We utilize an accumulative clustering algorithm to perform the hierarchical clustering and build up the \" pedigree \" tree of the detection methods .Red circles in the figure mean the correct clusters according to the MI ontology definition .", "label": "", "metadata": {}, "score": "68.74931"}
{"text": "State of the art articles ( as cited above ) and libraries ( such as the NSP package ) do not include any form of redundancy control or noise reduction .Redundancy mitigation is currently not a standard practice within the field of collocation extraction .", "label": "", "metadata": {}, "score": "68.846985"}
{"text": "On this synthetic corpus , we obtain a different list of collocations when using the PMI algorithm : 17,015(\u00b1950 ) instead of 2,737 .The growth in number of extracted collocations is expected since WSJs5 is 2.5 times larger than WSJ-1300 , but this growth is less than expected when comparing the trend ( WSJ-400 , WSJ-600 , WSJ-1300 ) with a growth of ( 565 , 1,000 and 2,737 ) extracted collocations .", "label": "", "metadata": {}, "score": "68.90222"}
{"text": "Topics 32 and 54 , as illustrated above in Anne Sexton 's \" The Starry Night , \" exemplify how LDA groups terms in ways that appear upon first blush to be thematic as well .As I mentioned earlier , though , the illusion of thematic comprehensibility obscures what is actually being captured by the topic model .", "label": "", "metadata": {}, "score": "68.914505"}
{"text": "It was the first model in the project to produce results that prompted a reconsideration of the tropes and conventions of ekphrasis .Secondly , it illustrates how figurative language resists thematic topic assignments and by doing so , effectively increases the attractiveness of topic modeling as a methodological tool for literary analysis of poetic texts .", "label": "", "metadata": {}, "score": "68.95436"}
{"text": "Background .The Electronic Health Record ( EHR ) contains valuable information entered by clinicians .Besides its immediate clinical use at the point of care , the EHR , when treated as a repository of medical information across many patients , provides rich data waiting to be analyzed and mined for clinical discovery .", "label": "", "metadata": {}, "score": "69.06541"}
{"text": "Affiliated with .Abstract .Background .Considerable efforts have been made to extract protein - protein interactions from the biological literature , but little work has been done on the extraction of interaction detection methods .It is crucial to annotate the detection methods in the literature , since different detection methods shed different degrees of reliability on the reported interactions .", "label": "", "metadata": {}, "score": "69.07367"}
{"text": "For instance , the phrase \" hip rplc \" is a common phrase used to refer to the hip replacement procedure , which does not match any concept on its own in the UMLS .When gathering counts or co - occurrence patterns for association studies with the goal of high - level applications , like detection of adverse drug events or disease modeling , augmenting existing terminologies with such collocations can be beneficial .", "label": "", "metadata": {}, "score": "69.21817"}
{"text": "These values of \u03b2 are relatively small and can be expected to give rise to a fine - grained decomposition of the collection into topics that address specific research fields .Impact of parameters \u03b1 and T .Given values of \u03b2 , the problem of choosing appropriate values for \u03b1 and T thus is a problem of model selection . and \u03b2 , and explore the consequences of varying T , for each fixed \u03b2 value we set the values of T from 10 to 100 in steps of 10 consecutively .", "label": "", "metadata": {}, "score": "69.65522"}
{"text": "13 : end for .15 : end for .16 : Find the max distance R passage pass rest in candidate passages ; .19 : end while .20 : return S .The advantage of the Algorithm 1 is that it considers aspect distinctions between candidate passages in the slide window and observed passages ranked in S .", "label": "", "metadata": {}, "score": "69.71208"}
{"text": "Our EHR corpus can be organized by patient identifier .We can , therefore , quantify the amount of redundancy within a patient record .On average , our corpus contains 14 notes per patient , with standard deviation of 16 , minimum of 1 and 167 maximum notes per patient .", "label": "", "metadata": {}, "score": "69.72243"}
{"text": "Recalling my earlier example of the farmers ' market , the pink , blue , and yellow topics are like the types of produce at the market .On the far right hand side of Figure 1 is a bar graph that represents the proportions of the yellow , pink , and blue topics the model predicts are in the document ( an article in this case ) .", "label": "", "metadata": {}, "score": "69.78441"}
{"text": "Given our disparate expectations for how language should operate in poetry as opposed to non - fiction , should the same standards for evaluating topic models of non - figurative language texts guide the principles we use to evaluate the accuracy of topic models of figurative language collections ?", "label": "", "metadata": {}, "score": "69.8123"}
{"text": "17 ] , the most popular sequence similarity algorithm in bioinformatics , is based on hashing of short sub - strings within the genetic sequence and then using the slower optimized dynamic programming alignment for sequences found to share enough sub - sequences .", "label": "", "metadata": {}, "score": "69.894844"}
{"text": "All Informative , input corpus , the corpus obtained by the redundancy reduction baseline ( Last Informative Note ) , and the corpora produced by the fingerprinting redundancy reduction strategy at different level .Computation time for constructing a redundancy - reduced corpus at a given similarity threshold using the selective fingerprinting is 6 minutes ( with an Intel Xeon CPU X5570 2.93 GHz ) .", "label": "", "metadata": {}, "score": "70.23938"}
{"text": "Approximation techniques to make this problem tractable were developed in bioinformatics to search sequence databases and for plagiarism detection .In both fields , fingerprinting schemes are applied .In BLAST , short substrings are used as fingerprints , whose length is defined by biological significance .", "label": "", "metadata": {}, "score": "70.56935"}
{"text": "\u03b8 is the matrix of document - specific mixture weights for these T topics , each being drawn independently from a symmetric Dirichlet ( \u03b2 ) prior .For each word , z denotes the topic responsible for generating that word , drawn from the \u03b8 distribution for that document , and w is the word itself , drawn from the topic distribution \u03d5 corresponding to z .", "label": "", "metadata": {}, "score": "70.613075"}
{"text": "We would normally expect the words human , genome , dna , genetic to be found in articles about \" genetic necessities .\" By glancing over the words in the topic keyword distributions , we gather together a sense of what the article might be about .", "label": "", "metadata": {}, "score": "70.838905"}
{"text": "[14 ] examined 1,670 patient notes of four types ( resident sign - out note , progress note , admission note and discharge note ) and assessed the amount of redundancy in these notes through time .Redundancy was defined through alignment of information in notes at the line level , using the Levenshtein edit distance .", "label": "", "metadata": {}, "score": "70.94873"}
{"text": "The working scheme of this ranking method based on N size slide window is described in Algorithm 1 , named rank - NWin .Algorithm 1 rank - NWin Algorithm .1 : Input : An initial passage ranking R produced for current user query only with respect to relevance , and the size N of the slide window .", "label": "", "metadata": {}, "score": "71.06171"}
{"text": "Background .Traditional information retrieval ( IR ) system should respond with a ranked list of retrieved documents or passages to users , according to their probabilities of relevance to the query .The model only concerns with the relevance between retrieved documents and user query , but does not take redundancy between retrieved documents into account .", "label": "", "metadata": {}, "score": "71.21126"}
{"text": "We employ two retrieval baseline runs , NLMinter [ 21 ] and UniNE2 [ 22 ] .NLMinter developed by U.S. National Library of Medicine achieved the best performance in TREC 2007 Genomics track in terms of Aspect MAP , Passage2 MAP and Document MAP .", "label": "", "metadata": {}, "score": "71.238976"}
{"text": "The Reduced Redundancy Informative Notes corpus contains 3,970 patient notes , 3.18 as many notes as the Last Informative Notes corpus while having same - patient redundancy of only 9.8 % compared to 29 % in the All Informative Notes Corpus .", "label": "", "metadata": {}, "score": "71.456665"}
{"text": "All authors have read and approved the final manuscript .Authors ' Affiliations .State Key Laboratory of Intelligent Technology and Systems , Tsinghua National Laboratory for Information Science and Technology , Department of Computer Science and Technology , Tsinghua University .", "label": "", "metadata": {}, "score": "71.512535"}
{"text": "Otherwise , return ( gamma , None ) .gamma is of shape len(chunk ) x self.num_topics .Avoids computing the phi variational parameter directly using the optimization presented in Lee , Seung : Algorithms for non - negative matrix factorization , NIPS 2001 .", "label": "", "metadata": {}, "score": "71.88564"}
{"text": "separately can be used to define which arrays should be stored in separate files .ignore parameter can be used to define which variables should be ignored , i.e. left out from the pickled lda model .By default the internal state is ignored as it uses its own serialisation not the one provided by LdaModel .", "label": "", "metadata": {}, "score": "71.97946"}
{"text": "The aim of the aspect retrieval task is to promote retrieval ranking diversity in the ranked list of retrieved passages .Aspects of a retrieved passages could be a list of named entities or MeSH terms [ 2 ] , representing answers that cover different portions of a full answer to the query .", "label": "", "metadata": {}, "score": "72.160225"}
{"text": "It also support special values of ' asymmetric ' and ' auto ' : the former uses a fixed normalized asymmetric 1.0/topicno prior , the latter learns an asymmetric prior directly from your data .eta can be a scalar for a symmetric prior over topic / word distributions , or a matrix of shape num_topics x num_words , which can be used to impose asymmetric priors over the word distribution on a per - topic basis .", "label": "", "metadata": {}, "score": "72.40026"}
{"text": "We call notes of these 3 types \" Informative Notes \" .In our experiments , we rely on different variants of the EHR corpus ( see Table 7 ): .The All Notes corpus is our full EHR corpus , .", "label": "", "metadata": {}, "score": "72.518875"}
{"text": "What exactly is a topic ?Formally , a topic is a probability distribution over terms .In each topic , different sets of terms have high probability , and we typically visualize the topics by listing those sets ( again , see Figure 1 ) .", "label": "", "metadata": {}, "score": "72.72491"}
{"text": "The differences we observe in this experiment are caused by the fact that some sentences only are copied , in a variable number of times ( some sentences occur once , some twice , and others 5 times ) .Thus , PMI ( which does not simply reflect word frequencies in a corpus , but takes into account global patterns of co - occurrences , since it relies on the probability of seeing terms jointly and terms independently ) does not behave similarly when fed with our different corpora .", "label": "", "metadata": {}, "score": "72.76572"}
{"text": "Similarly , topics can also be created by grouping together distinctive dialects and languages other than English .We will not be considering these topics in detail other than to point out that they exist .Large \" chunk \" topics - Longer or extended poems that outsize the majority of other documents in the subset pull one or more topics toward language specific to that particular poem .", "label": "", "metadata": {}, "score": "73.10141"}
{"text": "2 Answers 2 .In the first video he covers extensively the basic idea of topic modelling and how Dirichlet distribution come into play .The plate notation is explained as if all hidden variables are observed to show the dependencies .", "label": "", "metadata": {}, "score": "73.45993"}
{"text": "Next , we need to choose an appropriate value of T for each specific query .However , this requires to sum over all possible assignments of words to topics z .Figure 2 shows the log - likelihood of the data for different settings of the number of topics T for query 200 , 221 and 231 in our data collection with \u03b2 being equal to 0.06 .", "label": "", "metadata": {}, "score": "73.79087"}
{"text": "The parameter n is the granularity of the method , and its choice determines how stringent the comparison is .In order to compare two notes A and B , we compute the number of fingerprints shared by A and B. The level of similarity of B to A is defined as the ratio ( number of shared fingerprints ) / ( number of fingerprints in A ) .", "label": "", "metadata": {}, "score": "73.95007"}
{"text": "For poetry data in particular and literary texts in general , close reading and contextual understanding work together , like the weaving and unraveling of Penelope at her loom , in order to identify relations between texts by shuttling between computational de - familiarization and scholarly experience .", "label": "", "metadata": {}, "score": "74.03511"}
{"text": "In the example below , the words removed before the topic model was run have been struck out .Returning to the farmer 's market example from earlier in this article , \" The Starry Night \" is an example of what one neighbor 's basket of produce ( poem / document ) might look like .", "label": "", "metadata": {}, "score": "74.04267"}
{"text": "minimum_probability controls filtering the topics returned for a document ( bow ) .Example : .Given a chunk of sparse document vectors , estimate gamma ( parameters controlling the topic weights ) for each document in the chunk .The whole input chunk of document is assumed to fit in RAM ; chunking of a large corpus must be done earlier in the pipeline .", "label": "", "metadata": {}, "score": "74.38214"}
{"text": "20 : return S .Distance ( i , j ) in algorithms rank - NWin and rank - NWin_Group is the measurement of the aspect distinction between two passages .Given two passages , the more different the aspects are , the larger value of Distance ( i , j ) will be .", "label": "", "metadata": {}, "score": "74.50674"}
{"text": "Passage MAP , Passage2 MAP , Aspect MAP and Document MAP , defined in [ 1 ] and [ 2 ] , are four evaluation metrics corresponding to the three levels of retrieval performance .In this paper , we mainly focus on two evaluation metrics , Aspect MAP and Passage2 MAP , since our objective is to promote diversity in the ranked list of retrieved passages .", "label": "", "metadata": {}, "score": "74.57091"}
{"text": "This suggests that for each aspect the distribution of the retrieved passages is different .Second , even the same weight value in different columns of \u03b8 matrix would have a different importance for different aspects .Therefore , we tend to make transformation of \u03b8 matrix to represent the importance of each passage in each aspect .", "label": "", "metadata": {}, "score": "74.69778"}
{"text": "Hersh W , Cohen A , Ruslen L , Roberts P : TREC 2007 Genomics track overview .Proc of TREC-16 2007 .Hersh W , Cohen A , Roberts P , Rekapalli H : TREC 2006 Genomics track overview .Proc of TREC-15 2006 .", "label": "", "metadata": {}, "score": "75.75487"}
{"text": "where a ji stands for the weight of the aspect A i for passage P j , and D denotes the number of retrieved passages .In addition , we get a new matrix \u0398 shown as Eq .( 4 ) to measure the passages . importance for each aspect .", "label": "", "metadata": {}, "score": "76.11453"}
{"text": "Impact of \u03b2 parameter .Figure 3 shows NLMinter and UniNE2 system performance with varying \u03b2 .Figures 3(a ) and 3(b ) respectively show NLMinter and UniNE2 system performances at aspect level with different \u03b2 .It can be seen from Figure 3(a ) that when \u03b2 's value is between 0.03 and 0.07 , performance improvements on aspect level can be achieved for all re - ranking strategies .", "label": "", "metadata": {}, "score": "76.58472"}
{"text": "array of not .Numpy can in some settings turn the term IDs into floats , these will be converted back into integers in inference , which incurs a performance hit .For distributed computing it may be desirable to keep the chunks as numpy arrays .", "label": "", "metadata": {}, "score": "77.14128"}
{"text": "The WSJx2 corpus is constructed from WSJ-1300 to simulate redundancy , where each document of WSJ-1300 appears twice in the corpus .The WSJx3 corpus is similar to the WSJx2 corpus , except it contains three copies of each document in the WSJ-1300 corpus .", "label": "", "metadata": {}, "score": "77.154915"}
{"text": "The first one can be seen as the original Euclidean distance as shown in Eq .We thus regard \u03bc t as the weight value and then get another equation for Euclidean distance as shown in Eq .Results .Dataset and evaluation metrics .", "label": "", "metadata": {}, "score": "77.40224"}
{"text": "For num_topics number of topics , return num_words most significant words ( 10 words per topic , by default ) .The topics are returned as a list - a list of strings if formatted is True , or a list of ( word , probability ) 2-tuples if False .", "label": "", "metadata": {}, "score": "78.06873"}
{"text": "The lines from the bar graph on the far right point to the places in the text where words that are associated with the yellow , pink , and blue topics can be found in the document .Essentially , the histogram in Figure 1 is showing the equivalent in the farmers ' market example of there being more apples than pears or grapes in a single basket .", "label": "", "metadata": {}, "score": "78.08798"}
{"text": "For example , \" structure \" , \" crystal \" , \" helix \" are gathered to x - ray , and \" yeast \" , \" two - hybrid \" , \" site \" are gathered to two hybrid .These are the informative terms in the MI ontology definition of these methods .", "label": "", "metadata": {}, "score": "78.15985"}
{"text": "The detailed distribution supports the distinction into 2 groups of notes : those with heavy repetition ( about 37 % of the pairs - with similarity between 40 % and 100 % ) and those with no repetition ( about 63 % of the notes ) .", "label": "", "metadata": {}, "score": "78.24194"}
{"text": "In the real situation , different authors prefer different words and phrases to describe the same methods .Although the ontology has already included so many different descriptions , biologists would just mention \" yeast 2-h \" , which is not included in the ontology , in their manuscripts .", "label": "", "metadata": {}, "score": "78.38685"}
{"text": "However , some potential relationships between words might exist .As shown in the above instance , the word kidney represents two different topics in the two passages , as it has distinctive contexts and relationships with other words .Therefore , it is insufficient to identify aspect on word level .", "label": "", "metadata": {}, "score": "78.485306"}
{"text": "Text highlighted in blue can be found in Topic 54 .Table 1 : Keyword distributions generated by a 60 topic model of 4500 poems ( Note : Keywords in this table are representative of the entire model , not just words from \" The Starry Night .", "label": "", "metadata": {}, "score": "78.816376"}
{"text": "The authors declare that they have no competing interests .Authors ' contributions .RC participated in the study design , carried out the statistical analyses and wrote the paper .ME participated in study design and wrote the paper .NE participated in study design and wrote the paper .", "label": "", "metadata": {}, "score": "79.04242"}
{"text": "9 : for each passage j in group i do .11 : for each passage k in S do .S k ) ; . 13 : end for .15 : end for .16 : Rank passages in group i according to distance R in a descend order .", "label": "", "metadata": {}, "score": "80.37961"}
{"text": "The followings are examples of queries from the 2007 Genomics Track : .Query 200 : What serum [ PROTEINS ] change expression in association with high disease activity in lupus ?Query 221 : Which [ PATHWAYS ] are mediated by CD44 ?", "label": "", "metadata": {}, "score": "81.12578"}
{"text": "\u00a9 Chen et al . licensee BioMed Central Ltd. 2012 .This article is published under license to BioMed Central Ltd.", "label": "", "metadata": {}, "score": "81.36542"}
{"text": "I should underscore here that I am not arguing that the African American practice of the elegy is necessarily distinctive from other traditions of the elegy .But I want to suggest that such practice is continuous .Dunbar 's poems of the 1890s point us directly to more recent elegies written by African Americans in the latter part of the twentieth century .", "label": "", "metadata": {}, "score": "81.62857"}
{"text": "For the rest of passages in R , if the number of passages in R is not less than N , we will put the top N passages in R into the slide window , or else we will put all the passages in R into slide window .", "label": "", "metadata": {}, "score": "81.95032"}
{"text": "Documents are added one by one to the new corpus , a document sharing a proportion of fingerprints larger than the cutoff value with a document already in the corpus is not added .See Figure 6 for pseudo code of this algorithm .", "label": "", "metadata": {}, "score": "82.074524"}
{"text": "What , if anything , changes if we work through a parallel example of how a topic model \" reads \" Anne Sexton 's \" The Starry Night \" ?The model used for this example used 4,500 poems from the Revising Ekphrasis dataset to generate 60 topics .", "label": "", "metadata": {}, "score": "82.10308"}
{"text": "The following two topic examples found in the same topic model as \" The Starry Night \" demonstrate how the model clusters these : .Topic 4 : de la el en green verde con los mi se del poem n lo os poema yo oo ya sobre .", "label": "", "metadata": {}, "score": "82.39719"}
{"text": "Affiliated with .Affiliated with .Abstract .Background .In the biomedical domain , there are immense data and tremendous increase of genomics and biomedical relevant publications .The wealth of information has led to an increasing amount of interest in and need for applying information retrieval techniques to access the scientific literature in genomics and related biomedical disciplines .", "label": "", "metadata": {}, "score": "82.397865"}
{"text": "Under the \" Topic 12 \" label are the probable proportions for each document expressed in decimals .In the second column are the corresponding poem titles .[ 12 ] .Table 2 : Titles of poems in the Revising Ekphrasis dataset with the highest probable proportion of Topic 12 , listed in descending order .", "label": "", "metadata": {}, "score": "82.8554"}
{"text": "Given a corpus , a histogram of term frequencies is computed to examine whether the corpus follows Zipf 's law .According to Zipf 's law , terms frequencies have a long tail in their distribution : that is , very few terms occur frequently ( typically function words and prominent domain words ) while most terms occur only once or twice in the corpus overall .", "label": "", "metadata": {}, "score": "83.00039"}
{"text": "[ 13 ] For more on the ekphrastic conversation between Anne Sexton and W. D. Snodgrass regarding \" The Starry Night , \" see Loizeaux , Elizabeth Bergmann .Twentieth - Century Poetry and the Visual Arts .[14 ] The author would like to thank the Maryland Institute for Technology in the Humanities , especially Travis Brown , Jennifer Guiliano , and Trevor Mu\u00f1oz , for the support she received while performing the research that led to this paper .", "label": "", "metadata": {}, "score": "83.0784"}
{"text": "LDA does not produce names for the topics it discovers or sort words with an understanding of what words mean .Imagine that while you are sorting through baskets , you come across an Asian pear .You 've never seen an Asian pear before , but the Asian pear was in a basket with a large number of apples and pears .", "label": "", "metadata": {}, "score": "83.241745"}
{"text": "Words are ranked by their significance in the topic ( i.e. , in the first topic the most important word is \" renal \" ) .The first topic includes words pertaining to renal disease , the second to hypertension and the third to symptoms and treatments related to the pulmonary system .", "label": "", "metadata": {}, "score": "83.71431"}
{"text": "Authors ' Affiliations .State Key Laboratory of Software Development Environment , Beihang University .Beijing Key Laboratory of Network Technology , Beihang University .College of Information Science and Technology , Drexel University .School of Information Technology , York University .", "label": "", "metadata": {}, "score": "84.103"}
{"text": "They both rely on patterns of co - occurrence of words .Collocations are word sequences that co - occur more often than expected by chance .Collocations , such as \" heart attack \" and \" mineral water , \" carry more information than the individual words comprising them .", "label": "", "metadata": {}, "score": "84.48244"}
{"text": "Topic 32 includes words that could fall under the rubric of \" night , \" and the words in Topic 54 could be described as the \" natural world .\" Topic 2 , on the other hand , does not have the same unambiguous comprehensibility that 32 and 54 do : the words in Topic 2 are more loosely connected .", "label": "", "metadata": {}, "score": "85.576294"}
{"text": "There are \" intruder \" words in this category .By looking solely at the words in the list and not taking into consideration \" The Starry Night , \" words such as long , world , and day are not necessarily words we might classify as \" death \" words in the strictest sense .", "label": "", "metadata": {}, "score": "85.65155"}
{"text": "\u03b8 i denotes the aspects distribution for each passage P i . a ij stands for the weight of the aspect A j given the passage P i such that equals one .We have observed the following two interesting phenomena from the column of matrix \u03b8 .", "label": "", "metadata": {}, "score": "86.179695"}
{"text": "Like Penelope , Graham entertains the illusion , if only momentarily , of a choice between bringing a creative impulse into form or allowing it to come undone .A weaver of language , Graham subtly , deftly , but unsuccessfully attempts to delay the inevitable moment in poetic creation in which complexity of thought adopts form through language , and so realized is also reduced .", "label": "", "metadata": {}, "score": "87.51223"}
{"text": "This avoids pickle memory errors and allows mmap'ing large arrays back on load efficiently .You can also set separately manually , in which case it must be a list of attribute names to be stored in separate files .The automatic check is not performed in this case . ignore is a set of attribute names to not serialize ( file handles , caches etc ) .", "label": "", "metadata": {}, "score": "88.03693"}
{"text": "fname_or_handle is either a string specifying the file name to save to , or an open file - like object which can be written to .If the object is a file handle , no special array handling will be performed ; all attributes will be saved to the same file .", "label": "", "metadata": {}, "score": "88.61057"}
{"text": "This is the question that began Revising Ekphrasis , a digital topic modeling and corpus discovery project I developed that uses digital and computational tools to explore ekphrastic and non - ekphrastic poetry .The topic model represented in this article is one of several from the Revising Ekphrasis project .", "label": "", "metadata": {}, "score": "88.61426"}
{"text": "1146 - -1157 , Seattle , WA , October 2013 .Bibtex : .Topic Modeling and Figurative Language . ... to have them for an instant in her hands both at once , the story and its undoing ... from \" Self Portrait as Hurry and Delay \" [ Penelope at her loom ] .", "label": "", "metadata": {}, "score": "89.90874"}
{"text": "As literary scholars , we understand that Sexton 's use of the tumultuous night sky depicted by Vincent Van Gogh provides a conceit for the more significant thematic exploration of two artists ' struggle with mental illness .Therefore , it is important not to be seduced by the seeming transparency of semantically evident topics .", "label": "", "metadata": {}, "score": "90.55816"}
{"text": "In fact , Dunbar is not the only African American poet included in the list of documents that draw heavily from Topic 2 . \" The Slave 's Complaint \" by George Moses Horton ( 1797 - 1884 ) is also included .", "label": "", "metadata": {}, "score": "90.80342"}
{"text": "Many of your neighbors rave about the quality of the produce there , but you would like to know what kinds of produce are available before you decide to drive across town to try it out .One Saturday morning , your neighbors leave for the market with empty baskets and return with full baskets .", "label": "", "metadata": {}, "score": "91.3325"}
{"text": "For instance , given two retrieval passages : the first one is related to some disease research , in which kidneys of white rats are used as experimental materials ; the second one is relevant to subject of kidney transplantation .Obviously , the aspect of kidney occurs in both passages .", "label": "", "metadata": {}, "score": "91.4979"}
{"text": "It is more accurate to say that Topics 32 and 54 participate in discourses surrounding \" night \" and \" natural landscapes \" in Anne Sexton 's \" The Starry Night .\" [ 13 ] She enters into that discourse through the other surrounding discourses that include night and natural landscape .", "label": "", "metadata": {}, "score": "92.25932"}
{"text": "[ 8 ] .Figure 3 : \" The Starry Night \" by Anne Sexton .Text with a strike through it has been removed as a stopword during preprocessing .Text highlighted in green can be found in Topic 32 .", "label": "", "metadata": {}, "score": "94.691925"}
{"text": "Identifying that Dunbar 's \" We Wear the Mask \" and \" Beyond the Years \" draw from discourses associated with elegy supports recent scholarship by Marcellus Blout in his 2007 essay titled , \" Paul Lawrence Dunbar and the African American Elegy : \" .", "label": "", "metadata": {}, "score": "94.962036"}
{"text": "control , buffer , pp , record , isi , bait , cancer , antibody , extract , c - terminus , bead , sirna , tumor , stain , gene , yeast , sds , luciferase , embo , cdna . coip . antibody , pp , record , extract , yeast , domain , sequence , expression , blot , cdna , clone , activity , luciferase , growth , transfect , acid , fusion , sirna , mmedta , link .", "label": "", "metadata": {}, "score": "96.49152"}
{"text": "29 % of the produce ( words ) would be like apples ( Topic 32 ) , 12 % of the produce would be corn ( Topic 2 ) , and 9 % of the produce would be like grapes ( Topic 54 ) .", "label": "", "metadata": {}, "score": "96.76065"}
{"text": "The size of the \" topics \" likewise reflects your estimation of how much of each kind of produce is available .You were able to predict that there were more apples and pears at the market than there were blueberries and tomatoes because across the whole sampling of baskets there were more apples and pears and fewer pints of blueberries .", "label": "", "metadata": {}, "score": "99.62902"}
{"text": "Topic 2 .Topic 54 .night light moon stars day dark sun sleep sky wind time eyes star darkness bright . death life heart dead long world blood earth man soul men face day pain die .tree green summer flowers grass trees flower spring leaves sun fruit garden winter leaf apple .", "label": "", "metadata": {}, "score": "99.648506"}
{"text": "Could Horton , a poet and a slave , whose poems were written down by school children and printed under the title The Hope of Liberty in 1829 have been an influential part of Dunbar 's inclination toward the elegiac ?It would take a combination of more topic modeling tests and more traditional historical and archival research to answer that question ; however , these are the questions we have been hoping topic modeling might help produce .", "label": "", "metadata": {}, "score": "100.46146"}
{"text": "[ 3 ] For more information on how LDA has been used by humanists to detect changing attitudes toward patriotism and nationalism , see : Nelson , Robert K. Mining the Dispatch .[ 4 ] In the farmers ' market example mentioned earlier in this article , each topic ( kinds of produce ) is composed of the words ( Gala apple , Bosc pear , yellow squash , etc . ) in the document ( basket ) .", "label": "", "metadata": {}, "score": "100.527435"}
{"text": "The fifteen words below each Topic number represents a sampling of the word distribution that makes up the whole topic .For example , in the farmer 's market example the topic with the largest percentage would be \" apples .\" Under the \" apples \" topic , we might find Macintosh , Fuji , Honeycrisp , and Gala , all words associated with apples .", "label": "", "metadata": {}, "score": "100.6559"}
{"text": "Over the remaining baskets , Asian pears tend to appear in other baskets where there are also other kinds of pears more often than in baskets where there are also apples .As a result , you come to the conclusion that , since Asian pears frequently appear in baskets with other pears , the Asian pear in each future basket should be sorted with the pears .", "label": "", "metadata": {}, "score": "108.27561"}
