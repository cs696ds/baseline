{"text": "T . k . ) j .T .C . ni .T . k .T .j . ) idf .T .j . ) where .( c ) means for selecting I T terms for use as index terms for document D from among terms in the N 0 documents based upon the scores f D ( T k ) achieved by the terms .", "label": "", "metadata": {}, "score": "27.174725"}
{"text": "5 ] Attempts have been made to put idf on a probabilistic footing , [ 6 ] by estimating the probability that a given document d contains a term t as the relative document frequency , .Namely , the inverse document frequency is the logarithm of \" inverse \" relative document frequency .", "label": "", "metadata": {}, "score": "27.63253"}
{"text": "This states that the the weight W , of a term T , in a document D , is : . where tf(T , D ) is the term frequency of T in D .DN is the total number of documents df(T ) is the sum of frequencies of T in every document considered or as it called the document frequency of T .", "label": "", "metadata": {}, "score": "29.894722"}
{"text": "TF - IDF is a workhorse of NLP , and it is straightforward to calculate .Basically what that says is for every word in a document calculate the number of times it appears , and then divide by the number of times the most common word appears in the document .", "label": "", "metadata": {}, "score": "29.95948"}
{"text": "D .T .T .TF .TD .IDF .T .where : .T 0 is the number of terms which occur in the query Q i , .TF TD is Robertson 's term frequency for term T in document D , .", "label": "", "metadata": {}, "score": "29.99231"}
{"text": "TF .TD .IDF .T .where : .T 0 is the number of terms in the search query Q , and .TF TD is Robertson 's term frequency for the Term T in the Document D , . where : .", "label": "", "metadata": {}, "score": "30.08814"}
{"text": "TF .TD .IDF .T .where : .T 0 is the number of terms in the search query Q , and .TF TD is Robertson 's term frequency for the term T in the document D , . where : .", "label": "", "metadata": {}, "score": "30.08814"}
{"text": "The Inverse Document Frequency ( IDF ) matrix is constructed using the Eq .Here , is the total number of documents in the corpus and is the total number of documents where the term appears [ 17 ] .The TF and IDF are next multiplied to form a TF - IDF matrix .", "label": "", "metadata": {}, "score": "30.309402"}
{"text": "T .where : .T 0 is the number of terms which occur in the collection of terms included in the search , .TF TD is Robertson 's term frequency for term T in document D , .N TD is the number of times the term T occurs in document D , .", "label": "", "metadata": {}, "score": "30.825901"}
{"text": "[ 3 ] .In the case of the term frequency tf ( t , d ) , the simplest choice is to use the raw frequency of a term in a document , i.e. the number of times that term t occurs in document d .", "label": "", "metadata": {}, "score": "30.9932"}
{"text": "This is the conventional Robertson 's term frequency score for an unsegmented text document .W .STD .f .D .T .n . )T .L .SD .f .D .T .t . ) where f D ( T n ) has the value set forth above , and L SD is the number of index terms in segment S i of document D. .", "label": "", "metadata": {}, "score": "31.191875"}
{"text": "While these approaches have different theoretical bases , their similarity scoring functions all employ some variant of tf\u00d7idf information . are the weight of the query term t in document d and query q , respectively .Using a tf\u00d7idf metric ensures that a high term frequency in an individual document increases the similarity contribution , while a high frequency across all documents reduces its contribution .", "label": "", "metadata": {}, "score": "32.500443"}
{"text": "So , normalize the frequency of a term t by the length of the document d in which it occurs .Then you can compute cosine similarity between your tf - idf vectors .The cosine similarity is still a valid measure .", "label": "", "metadata": {}, "score": "33.476364"}
{"text": "tf - idf , short for term frequency - inverse document frequency , is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus .[ 1 ] : 8 It is often used as a weighting factor in information retrieval and text mining .", "label": "", "metadata": {}, "score": "33.673534"}
{"text": "Popular scoring functions that make use of tf\u00d7idf information include the Vector Space Model [ 21 ] and the Okapi BM25 metric [ 19].Many others are possible [ 24].For each term that occurs in T ( the set of which forms the vocabulary ) , an inverted index stores a list of documents that contain that term .", "label": "", "metadata": {}, "score": "33.79775"}
{"text": "S .D .T .T .TF .TD .where : T 0 is the number of terms T which occur in the query Q i , and .TF TD is the term frequency score for document D based on the frequency of occurrence in document D of term T. .", "label": "", "metadata": {}, "score": "34.15808"}
{"text": "D .T .T .TF .TD .IDF .T .where : S D is the total score for the document D , .T 0 is the number of terms which occur in the query Q , .", "label": "", "metadata": {}, "score": "34.430542"}
{"text": "In this embodiment , the weights W STD assigned to terms T in the segments S i of the document D are equal .In this embodiment , the factors W STD , the weights assigned to terms T in segment S i of document D , may all be considered to be equal to 1.0 , and the formula simplifies to : .", "label": "", "metadata": {}, "score": "36.51994"}
{"text": "SD .T .L .SD .W .STD .N .STD .where : .L SD is the number of different terms in segment S i of document D , .H .SO .N .", "label": "", "metadata": {}, "score": "37.081062"}
{"text": "Consequently , two words that were distant in the original vector space can be near in the compressed space , causing the inductive semantic space and knowledge acquisition effects reported in the [ 19 ] .The SVD is a matrix factorization technique that decomposes the TF - IDF matrix into three different matrices as shown in Eq .", "label": "", "metadata": {}, "score": "37.099335"}
{"text": "T .j .T . k . )n .N . tf .T . k .n . ) tf .T .j .n . )( b ) means for calculating , for terms T k which occur in the N 0 documents selected , the co - occurrence f D ( T k ) of that term T k with document D : . f .", "label": "", "metadata": {}, "score": "37.1391"}
{"text": "D .T .T .S . i .S .TF .STD .where : S D is the total score for the document D , .T 0 is the number of terms which occur in the search query Q , and .", "label": "", "metadata": {}, "score": "37.31228"}
{"text": "L D is the length of document D , .L 0 is the average length of a document in the collection C 0 being searched , and .N is the number of documents in the collection C 0 .N T is the number of documents containing the term T in the collection C 0 , and .", "label": "", "metadata": {}, "score": "37.352295"}
{"text": "T .S . i .S .TF .STD .IDF .ST .where : .S D is the total score for the document D , .T 0 is the number of terms which occur in the search query Q , .", "label": "", "metadata": {}, "score": "37.37897"}
{"text": "L 0 is the average length of a document in the collection being searched , and .N is the number of documents in the collection .N T is the number of documents containing the term T in the collection , and .", "label": "", "metadata": {}, "score": "37.57232"}
{"text": "The formula for calculating a total score SD for a document D may be written generally as : .S .D .T .T .TF .TD .where : T 0 is the number of terms T which occur in the collection of terms included in the search , and .", "label": "", "metadata": {}, "score": "38.022068"}
{"text": "For one term queries , the value of idf is simply a constant multiplier to the final ranking score , and so not useful for discriminating documents .If these data structures are to be used for bag - of - strings search , then the idf factor may become important , and can be easily extracted using method WT , which is still faster than Zet - io in our experiments .", "label": "", "metadata": {}, "score": "38.3722"}
{"text": "A TF / IDF distance is constructed just like a Jaccard distance .But then it is given training instances for the IDF weighting through the method trainIdf(String ) .Each string sent to training counts as a document .In general , the IDF values may be constructed from anywhere ( for instance , by running over a large corpus of sentences for sentence - level IDF ) .", "label": "", "metadata": {}, "score": "38.46481"}
{"text": "W .SD .H .SD . )N .N .W .SD .IDF .ST . log .N .K .N .ST . ) log .N .K .In this embodiment , if the document has only a single segment , then W SD may be considered to be equal to 1.0 for that segment , and the formula further reduces to : .", "label": "", "metadata": {}, "score": "39.055496"}
{"text": "n ] over an alphabet \u03a3 of size \u03c3 .A wavelet tree computes D[i ] in time O(log\u03c3 ) , as well as rankc(D , i ) , the number of occurrences of symbol c in D[1 .i ] , and selectc(D , j ) , the position in D of the j - th occurrence of symbol c. An example of a wavelet tree is shown in Fig .", "label": "", "metadata": {}, "score": "39.50579"}
{"text": "W .STD .H .SD . )N .N .W .SD . where : .N 0 is the number of documents in the collection C 0 , and .K 1 and K 2 are constants ( In one embodiment , K 1 may be assigned a value of 0.5 , and K 2 1.5 , but these values may be varied without departing from the spirit and scope of the invention . )", "label": "", "metadata": {}, "score": "39.903866"}
{"text": "T .L .SC .W .STC .N .STC .where : .L SC is the number of different terms in segment S i of supercategory S C , .H .SO .C .C .", "label": "", "metadata": {}, "score": "40.07923"}
{"text": "L 0 is the average length of a supercategory , and .N is the number of supercategories in the collection .N T is the number of supercategories containing the term T , and .K 3 and K 4 are constants .", "label": "", "metadata": {}, "score": "40.159893"}
{"text": "W SD is the weight assigned to segment S i of document D , .W STD is the weight assigned to term T in segment S i of document D , and .N STD is the number of times the term T occurs in segment S i of document D , .", "label": "", "metadata": {}, "score": "40.174686"}
{"text": "ep ] if that subarray were sorted .To get the first unique document number in D[sp .ep],1 ) .ep],1 + tfq , d1 ) .This lists the documents and their tf values in increasing document number order .", "label": "", "metadata": {}, "score": "40.546883"}
{"text": "In an embodiment of the system , a segment S 1 may be required to have equal weight W SD in all documents .When it is determined to calculate a term frequency score under a given search query Q for a document D with S 0 segments in the collection of documents C 0 being searched under the system , a generalized term frequency score may be calculated as follows : .", "label": "", "metadata": {}, "score": "40.622795"}
{"text": "A technique for taking into account the segment of a document in which a given term occurs , in the course of calculating a term frequency score for that document , therefore may be useful .According to the system being described herein , a weight W SD may be assigned to each segment S i of a document D containing S 0 segments .", "label": "", "metadata": {}, "score": "40.68406"}
{"text": "( c ) means for selecting the N 0 documents from the collection of documents C 0 which achieve the highest scores upon application of the search query Q ; and .( d ) means for selecting I T terms for use as index terms for document D from among terms in the N 0 documents based upon the co - occurrence of terms in the N 0 documents with terms in the document D. .", "label": "", "metadata": {}, "score": "40.715664"}
{"text": "( The Index Terms may consist of a set of terms chosen from among the Terms T which occur in the collection of documents , or they may be chosen independently of whether they occur among the Terms in the document collection . )", "label": "", "metadata": {}, "score": "40.976555"}
{"text": "is called the inverse document frequency of T .So we can write : .Now of course , there is a reason why all this gives good results .I will not go into detail but basically what is implied by the above formula is that the weight given to term in respect to a document is higher if : .", "label": "", "metadata": {}, "score": "41.160873"}
{"text": "Notice that a missing word in a tf - idf vector is actually a word with a frequency of 0 .So you elongate both vectors to the same length by adding and couple of 0 's and youb compute the cosine similarity .", "label": "", "metadata": {}, "score": "41.25077"}
{"text": "In order to find the variations in language in each email that the Machine receives , the Machine relies on two simple concepts , one called TF - IDF and the other Cosine Similarity .TF - IDF stands for \" Term Frequency - Inverse Document Frequency , \" and is a way to assign weights to individual words based on their importance in a collection of documents .", "label": "", "metadata": {}, "score": "41.43841"}
{"text": "H .SC .T .L .SC .N .STC .where : .L SC is the number of different terms in segment S i of supercategory S C , .H .SO .C .C .", "label": "", "metadata": {}, "score": "41.440292"}
{"text": "One particular formula in the prior art which may be used to assign a total score S D to a document D utilizes Robertson 's term frequency score : .S .D .T .T .TF .TD .", "label": "", "metadata": {}, "score": "41.575058"}
{"text": "Hence an inverse document frequency factor is incorporated which diminishes the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely .Karen Sp\u00e4rck Jones ( 1972 ) conceived a statistical interpretation of term specificity called IDF , which became a cornerstone of term weighting : .", "label": "", "metadata": {}, "score": "41.856224"}
{"text": "If no such Index Terms I j remain at the step 2520 , control instead passes to a step 2530 at which an Index Term or Index Terms are selected to be associated with the Document D i being processed .In one embodiment of the system , a single Index Term I M , whose total score T ( D i , I j ) for the Document D i being processed is the highest , is selected as the index term for Document D i .", "label": "", "metadata": {}, "score": "42.08679"}
{"text": "Many researchers use the BM25 algorithm in articles , steering their studies to retrieve information in several fields , not only in the Abstract [ 31 , 36 , 37 ] .By this assumption , we test how the MAP measure increases if we look for documents related to the queries in the Abstract , Title , and Mesh fields using the BM25 , TF - IDF BM25 , TF - IDF Log TF and TF - IDF Raw TF formulas ( see Table 7 ) .", "label": "", "metadata": {}, "score": "42.322464"}
{"text": "The documents may be Web pages , Web sites or other collections of material .The search query Q which is applied may comprise all of the terms in document D. Preselected stop terms may be eliminated .The search query Q may be applied to select documents from among the documents in the collection C 0 by calculating for each document D in the collection C 0 a score S D based upon the occurrence in the document D of terms in the search query Q. In applying the search query Q to the collection of documents C 0 the total score S D for a document D in the collection C 0 may be calculated using a formula utilizing Robertson 's term frequency for the term T in the document D. The number N 0 of documents chosen by application of the search query Q may be predetermined .", "label": "", "metadata": {}, "score": "42.57964"}
{"text": "D .T . k . ) j .T .C . ni .T . k .T .j . ) idf .T .j . ) where .( In one embodiment , \u03b4 may be assigned a value of 0.01 , but this value may be varied without departing from the spirit and scope of the invention . )", "label": "", "metadata": {}, "score": "42.88541"}
{"text": "I .j . ) where .This system permits varying weights to be assigned to different Index Terms I j associated with a given Document D. Other reasons and methods of varying the weight assigned to an Index Term associated with a Document will be apparent to one of ordinary skill in the art .", "label": "", "metadata": {}, "score": "42.897816"}
{"text": "D .i .I .j . ) k .K .L .D .i .D . k . )K . where .Control then passes to a step 2520 , at which it is determined if there remain any further Index Terms I j for which total scores T ( D i , I j ) have not yet been calculated for the Document D i being processed .", "label": "", "metadata": {}, "score": "42.946213"}
{"text": "Problem 1 .Problem 2 .In the ranked document search problem , we focus on the specific case where\u02c6S(q , di ) is the tf\u00d7idf measure .tf\u00d7idf is the basic building block for a large class of similarity measures used in the most successful IR systems .", "label": "", "metadata": {}, "score": "43.07154"}
{"text": "After the parameterization , we test how the MAP increases if we look for documents related to the queries in the Abstract , Title , and Mesh fields , using the TF - IDF BM25 weighting algorithm ( see Table 9 ) .", "label": "", "metadata": {}, "score": "43.626965"}
{"text": "We demonstrate the functionality of the framework by recomposing succinct solutions for document retrieval .\" We have shown that our structure can use , instead , O(n(log \u03c3 + log D ) ) bits for the tf measure ( and slightly more for others ) , but the constants are still large .", "label": "", "metadata": {}, "score": "43.67357"}
{"text": "W STC is the weight assigned to term T in segment S i of supercategory S C , and .N STC is the number of times the term T occurs in segment S i of supercategory S C , .H .", "label": "", "metadata": {}, "score": "43.854824"}
{"text": "L D is the length of document D , .L O is the average length of documents in the collection C 0 to be searched , and .K 1 and K 2 are constants .where : .N is the number of documents in the collection C 0 to be searched .", "label": "", "metadata": {}, "score": "43.922626"}
{"text": "L D is the length of document D , .L O is the average length of documents in the collection C 0 to be searched , and .K 1 and K 2 are constants .where : .N is the number of documents in the collection C 0 to be searched .", "label": "", "metadata": {}, "score": "43.922626"}
{"text": "In one embodiment of the system , scores are assigned to documents utilizing Robertson 's term frequency score , and the generalized term frequency score S D for a document D may be calculated as follows : .S .D .", "label": "", "metadata": {}, "score": "44.143513"}
{"text": "This set of N 0 documents has the property that Documents in it contain Terms also found in Document D i , the document which is having index terms assigned to it .The next steps 2100 to 2150 in the process 2050 then attempt to determine which other terms in the N 0 documents occur most frequently with the Terms T j in the Document D i .", "label": "", "metadata": {}, "score": "44.242294"}
{"text": "The cells of the matrix consist of weighted term - frequency ( T - F ) and inverse document frequency ( IDF ) matrix described in the previous section .Since many words do not appear in any given document , the matrix is often sparse .", "label": "", "metadata": {}, "score": "44.44553"}
{"text": "C .T .T .TF .TD .IDF .T .where : .TF TD is Robertson 's term frequency for term T in supercategory S C , .N TC is the number of times the term T occurs in supercategory S C , .", "label": "", "metadata": {}, "score": "44.62704"}
{"text": "Second , note that the measure is symmetric , so that the order of the string arguments does n't matter .Looking at \" The \" and \" the \" , we find an edit distance of 1.0 , corresponding to the substitution of a lower - case ' t ' for an upper - case ' T ' .", "label": "", "metadata": {}, "score": "44.75449"}
{"text": "Since the ratio inside the idf 's log function is always greater than or equal to 1 , the value of idf ( and tf - idf ) is greater than or equal to 0 .As a term appears in more documents , the ratio inside the logarithm approaches 1 , bringing the idf and tf - idf closer to 0 .", "label": "", "metadata": {}, "score": "44.958534"}
{"text": "This requires a general data structure of O(nlogn ) bits , plus a specific one of O((n / f)logn ) bits .This approach does not exactly solve the ranked document search problem .Gagie et al .introduce their method as .", "label": "", "metadata": {}, "score": "45.13762"}
{"text": "SC .H .SC . )C .C .W .SC .where : .C 0 is the number of supercategories and .K 1 and K 2 are constants ( In one embodiment , K 1 may be assigned a value of 0.5 , and K 2 1.5 , but these values may be varied without departing from the spirit and scope of the invention . )", "label": "", "metadata": {}, "score": "45.1858"}
{"text": "SC .H .SC . )C .C .W .SC .where : .C 0 is the number of supercategories and .K 1 and K 2 are constants ( In one embodiment , K 1 may be assigned a value of 0.5 , and K 2 1.5 , but these values may be varied without departing from the spirit and scope of the invention . )", "label": "", "metadata": {}, "score": "45.1858"}
{"text": "Variations of the tf - idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document 's relevance given a user query .tf - idf can be successfully used for stop - words filtering in various subject fields including text summarization and classification .", "label": "", "metadata": {}, "score": "45.290916"}
{"text": "If it is determined at the step 2170 that all Documents D i , have had index terms assigned , this portion of the system is completed .According to .FIG .4 , in one embodiment of the system described herein , there may be a very large number of Documents D 2420 which contain Terms T 2410 .", "label": "", "metadata": {}, "score": "45.337524"}
{"text": "It may therefore be useful to utilize automatic techniques to generate appropriate index terms for documents , based upon analysis of the characteristics of the terms which occur in the documents .In one embodiment of the system described herein , additional index terms are added to a set of documents D in a document collection automatically .", "label": "", "metadata": {}, "score": "45.788086"}
{"text": "And then you move on to the Inverse Document Frequency : .Calculating the Inverse Document Frequency of a word goes like this : take the number of documents you have and divide by the number of documents a given word appears in , and then take the logarithm of the result .", "label": "", "metadata": {}, "score": "45.923283"}
{"text": "Only the bitvectors ( preprocessed for rank and select ) are present in the actual structure , the numbers above each bitvector are included only to aid explanation .It stores an array D[1 .n ] , aligned to the suffix array A[1 .", "label": "", "metadata": {}, "score": "46.070995"}
{"text": "i .D . k . ) m .M . m .D .i . ) where : .If any such Documents D k remain at the step 2500 , control returns to the step 2480 at which a further Document D k , which has had Index Term I j manually assigned to it , is chosen for calculation .", "label": "", "metadata": {}, "score": "46.131325"}
{"text": "The method involves determining co - occurrences of terms in other documents with the electronic document , and selecting terms as index terms based upon those scores .The method permits the efficient retrieval of electronic documents .( c ) selecting I T terms for use as index terms for document D from among terms in the N 0 documents based upon the scores f D ( T k ) achieved by the terms .", "label": "", "metadata": {}, "score": "46.47131"}
{"text": "Finally , the query is reformulated adding the descriptors contained in the MeSH fields extracted in the previous step .In Table 10 the results of the experiment with the proposed strategy are shown .The query expansion is applied in the Abstract , Title , and MeSH fields of the documents and the weighting algorithm is TF - IDF BM25 .", "label": "", "metadata": {}, "score": "46.50353"}
{"text": "When you multiply TF and IDF together you get a score representing a value for the importance of the words in a document corrected by their importance in the collection of documents .The effect of this calculation is that rare words are more important than common ones in similarity calculations .", "label": "", "metadata": {}, "score": "46.833687"}
{"text": "D[sp .ep],1 + ?By traversing to nodes with larger ranges in a greedy fashion , we will reach the document leaves in tf order , and reach the first k leaves potentially having explored much less of the tree than we would have using a depth - first - style traversal .", "label": "", "metadata": {}, "score": "47.278214"}
{"text": "calculated to determine if there is a document number of interest in the left and right child .Again , this approach produces the document numbers in increasing docu- ment number order .These can obviously be post - processed to extract the k documents with the highest tfq , dvalues by sorting the docc values .", "label": "", "metadata": {}, "score": "47.397293"}
{"text": "At the end of ( b ) the heap contains the top - k document numbers and tf values .Page 15 .components , and treating each component as a term .The index is comprised of two pieces .To save space , the lists are compressed by storing the block numbers in increasing order and encoding only the difference ( gap ) between adjacent items with a suitable integer code .", "label": "", "metadata": {}, "score": "47.43216"}
{"text": "Because of the lexicographic ordering , all the suffixes starting with a given substring t of T form a range A[sp .Self - indexes [ 13 ] offer the same functionality as a suffix array but are heavily compressed .More formally , they can ( 1 ) extract any text substring T [ i .. Wavelet Trees .", "label": "", "metadata": {}, "score": "47.458336"}
{"text": "In this embodiment , the R Index Terms with the highest total scores T ( D i , I j ) are selected .In another embodiment , all Index Terms whose total scores T ( D i , I j ) exceed a predetermined cutoff score To are selected as index terms for Document D i .", "label": "", "metadata": {}, "score": "47.46941"}
{"text": "2 , the user first inputs the query .The relevant abstracts are obtained from the PubMed .The text processing is performed on these abstracts and term frequency ( TF ) and inverse document frequency ( IDF ) are obtained .", "label": "", "metadata": {}, "score": "47.71717"}
{"text": "Sadakane [ 20 ] proposes a 2n+o(n ) bit data structure built over the suffix array to compute idftfor a given t. Nbits .Other 3.2Top - k Retrieval In IR it is typical that only the top k ranked documents are required , for some k , as for example in Web search .", "label": "", "metadata": {}, "score": "48.13823"}
{"text": "5(b ) gives pseudocode for the final method .To derive a top - k listing algorithm , we apply Obs . 1 in rounds .As the al- gorithm proceeds , we will accumulate candidates for the top - k documents in a min - heap of at most k pairs of the form ( d , tfq , d ) , keyed on tfq , d .", "label": "", "metadata": {}, "score": "48.22213"}
{"text": "BM25 is a probabilistic model , where the weight of a search term is assigned based on its frequency within the document and the frequency of the query term .The corresponding weighting function is as follows : .TF - IDF Weighting Algorithm .", "label": "", "metadata": {}, "score": "48.42953"}
{"text": "Matching Processes Testing .Parameterization of the Weighting Algorithms .The weighting algorithms used for ranking the retrieved documents in our tests are Okapi BM25 and TF - IDF , explained in Section 2 .Finding the set of optimal parameters is costly to compute , since they have local maxima that are singularity values [ 35 ] .", "label": "", "metadata": {}, "score": "48.467873"}
{"text": "Appendix A covers the related basic concepts .Page 3 .Suffix Arrays and Self - Indexes .The suffix array A[1 .n ] of a text collection T of length n is a permutation of ( 1 ... n ) , so that the suffixes of T , starting at the consecutive positions indicated in A , are lexicographically sorted [ 10 ] : T [ A[i].", "label": "", "metadata": {}, "score": "48.490715"}
{"text": "In the embodiment of the system in which only the index terms automatically associated with the document by the system are utilized to carry out a search query , the formula for the score assigned to a document according to the system reduces to the following : .", "label": "", "metadata": {}, "score": "48.92936"}
{"text": "For four word queries , all of the self - indexing methods are clearly more efficient than the inverted file methods .Adding an idf computation to Greedy and Quantile will not make them less efficient than WT .6 Discussion We have implemented document listing algorithms that , to date , had only been theoretical proposals .", "label": "", "metadata": {}, "score": "49.15506"}
{"text": "If d does not already have an entry in the heap,3then we add the pair ( d , tfq , d ) to the heap , with priority tfq , d .This ends the first round .We continue , in round 2 , to probe the ele- ments X[m/4 ] and X[3m/4 ] , and their frequencies fX[m/4]and fX[3m/4].", "label": "", "metadata": {}, "score": "49.226624"}
{"text": "At a step 2120 , the system then proceeds by calculating the co - occurrence C n ( T j , T k ) of the Term T k from the N 0 documents with the Term T j from the Document D i .", "label": "", "metadata": {}, "score": "49.25508"}
{"text": "C .T .T .S . i .TF .STC .IDF .ST .where : .S C is the total score for the supercategory S C , .W SC , the weight assigned to segment S i of the supercategories , .", "label": "", "metadata": {}, "score": "49.38299"}
{"text": "Other sections or segments into which a document may be divided will be apparent to one of ordinary skill in the art .The weights W SD assigned to the segments of documents may be chosen arbitrarily .In an embodiment of the system , a given segment S i may be required to have equal weight W SD in all documents .", "label": "", "metadata": {}, "score": "49.440037"}
{"text": "5 gives pseudocode for our new methods .Page 14 .Algorithms for computing the top - k documents by tf .The algorithm in ( a ) maintains a priority queue h of ( node , range ) pairs , each pair having priority equal to the length of the range component .", "label": "", "metadata": {}, "score": "49.505188"}
{"text": "The original terms and the index terms may be used together in searches , or the index terms alone may be used .It may be thought that the occurrence among the additional terms of a term for which a search is being made may be more or less important as a predictor of the utility of the document than the occurrence of a term found in the document itself .", "label": "", "metadata": {}, "score": "49.58103"}
{"text": "Sadakane [ 20 ] offers a different space - time tradeoff .He builds a compressed suffix arrayA , and a parentheses representation of C in order to run RMQ queries on it without accessing C. Furthermore , he stores a bitvector B indicating the points of T where documents start .", "label": "", "metadata": {}, "score": "49.641556"}
{"text": "By also trying the right child each time we have gone to the left , all the distinct successive d values in the interval are discovered .They show that it is possible to get the i - th document in the interval directly in O(logN ) time .", "label": "", "metadata": {}, "score": "49.960903"}
{"text": "SVD is a technique that creates an approximation of the original word by document matrix .After SVD , the original matrix is equal to the product of three matrices , word by latent concept , latent concept by latent concept and latent concept by document .", "label": "", "metadata": {}, "score": "49.976376"}
{"text": "In the above formula N is the number of examples in a node , k is the number of classes - e.g. email variations - and n is the number of examples belonging to the most popular class .In order to calculate the accuracy of the models , the Machine holds one example from each email variation back , and then it uses those to test the decision tree 's accuracy using a standard calculation called the F Score .", "label": "", "metadata": {}, "score": "50.08908"}
{"text": "In turn , this will remove the restriction that IR system users must express their information needs as terms in the language chosen by the system , rather than in a more intuitive way .Our methods return the top - k documents in tf order , which departs from the tf\u00d7idf framework of most information retrieval systems .", "label": "", "metadata": {}, "score": "50.10824"}
{"text": "By representing D with a wavelet tree , values C[i ] can calculated on de- mand , rather than stored explicitly [ 22].The CSA is used to find D[sp .Page 5 .O(logN ) time .Gagie et al .", "label": "", "metadata": {}, "score": "50.407753"}
{"text": "27 , no . 3 , pp .129 - 146 , 1976 .View at Google Scholar \u00b7 View at Scopus .J. Ramos , Using Tf - Idf to Determine Word Relevance in Document Queries , 2003 .S. Gauch , J. Wang , and S. M. Rachakonda , \" A corpus analysis approach for automatic query expansion and its extension to multiple databases , \" ACM Transactions on Information Systems , vol .", "label": "", "metadata": {}, "score": "50.753986"}
{"text": "If no such supercategories S j remain at the step 2920 , control instead passes to a step 2930 at which is selected a supercategory S M whose total score T ( C i , S j ) for the category C i being processed is the highest .", "label": "", "metadata": {}, "score": "50.807556"}
{"text": "Inverted indexes require the definition of terms in T prior to their construction .In the case of many natural languages , the choice of terms is simply the vocabulary of the language : words .In turn , for the inverted index to operate efficiently , queries must be composed only of terms that are in the index .", "label": "", "metadata": {}, "score": "50.998955"}
{"text": "In fact , the new ranked document search algo- rithms are three times faster than a highly tuned inverted file implementation that assumes terms to be English words .Our approach is to build data structures that allow us to efficiently calculate the frequency of a query pattern in a document ( tf ) on the fly , unlike traditional inverted indexes that stores precomputed tf values for specific query patterns ( usually words ) .", "label": "", "metadata": {}, "score": "51.024475"}
{"text": "2 is to apply LSA using the TF and IDF matrices generated in the text pre - processing step .Latent semantic analysis ( LSA ) .The TF - IDF data matrix ( A ) is first normalized across the rows by dividing frequency of the word in each document by the highest frequency of that word in all the documents .", "label": "", "metadata": {}, "score": "51.043793"}
{"text": "This could be for example the number of occurences(frequency ) of this keyword in the respective document .An entry in the inverted index would look like : .As you can see the big advantage of this approach is that you do n't need to scan the documents every time you make a query .", "label": "", "metadata": {}, "score": "51.091137"}
{"text": "After every such category C i of merchants or stores 2210 is selected at the step 2240 , control passes to a step 2340 .In one embodiment the query is run by utilizing Robertson 's term frequency score , where the score for a supercategory S C is determined by : .", "label": "", "metadata": {}, "score": "51.114075"}
{"text": "During the in - block scanning phase , as we locate positions of pattern oc- currence , these positions must be mapped to document numbers and tf values accumulated .Clearly once all blocks have been scanned we will also know idf .", "label": "", "metadata": {}, "score": "51.255386"}
{"text": "N ST is the number of documents in the collection C 0 containing the term T in the segment S i , .K 3 and K 4 are constants .( In one embodiment , K 3 may be assigned a value of 0.5 , and K 4 1.0 , but these values may be varied without departing from the spirit and scope of the invention . )", "label": "", "metadata": {}, "score": "51.3145"}
{"text": "5 ] .Wu , H. C. ; Luk , R. W. P. ; Wong , K. F. ; Kwok , K. L. ( 2008 ) .\"Interpreting TF - IDF term weights as making relevance decisions \" .ACM Transactions on Information Systems 26 ( 3 ) : 1 . doi : 10.1145/1361684.1361686 .", "label": "", "metadata": {}, "score": "51.32869"}
{"text": "Tokens are weighted more heavily if they occur in few documents .See the class documentation for a full definition of TF / IDF distance .Running the Demo .The TF / IDF distance demo may be run from ant using the tf - idf target : .", "label": "", "metadata": {}, "score": "51.40911"}
{"text": "2 demonstrates that this is more than recouped whenever k is small , relative to the total number of documents containing q. Table 2 shows that the average docc is well above 10 for all pattern lengths in the current experimental setup .", "label": "", "metadata": {}, "score": "51.64473"}
{"text": "Whatever particular formula is used , documents are ranked in order of their total scores S D , and those which achieve the highest score are presented , typically in order of their scores , to the user .In order to improve the effectiveness of information retrieval methods , additional terms may be associated with documents before term frequency scores are calculated .", "label": "", "metadata": {}, "score": "51.65117"}
{"text": "Because the singular values are ordered in decreasing size , it is possible to remove the smaller dimensions and still account for most of the variance .The approximation to the original matrix is optimal , in the least squares sense , for any number of dimensions one would choose .", "label": "", "metadata": {}, "score": "51.674133"}
{"text": "This enables the comparisons of the query and the documents based on semantics .A cosine similarity is used as a measure of similarity as proposed in [ 18 ] .The breakthrough provided by LSA is a solution to the synonymy problem , i.e. , the problem that multiple words can express the same meaning .", "label": "", "metadata": {}, "score": "51.70002"}
{"text": "Another array , C[1 .n ] , stores in C[i ] the last occurrence of D[i ] in D[1 .The algorithm first finds A[sp .To retrieve all of the unique values in D[sp .ep ] , it starts with the interval [ s ..", "label": "", "metadata": {}, "score": "51.770706"}
{"text": "C ST is the number of supercategories containing the term T in the segment S i , .K 3 and K 4 are constants .( In one embodiment , K 3 may be assigned a value of 0.5 , and K 4 1.0 , but these values may be varied without departing from the spirit and scope of the invention . )", "label": "", "metadata": {}, "score": "51.807484"}
{"text": "C ST is the number of supercategories containing the term T in the segment S i , .K 3 and K 4 are constants .( In one embodiment , K 3 may be assigned a value of 0.5 , and K 4 1.0 , but these values may be varied without departing from the spirit and scope of the invention . )", "label": "", "metadata": {}, "score": "51.807484"}
{"text": "1 Answer 1 .If I read Wikipedia right , tf / idf is not unbounded . tf $ \\le 1 $ ( would be 1 only if the document had all words the same ) and idf $ \\le \\log N , N$ the number of documents , with equality if only one document has the term .", "label": "", "metadata": {}, "score": "51.97107"}
{"text": "The total number of elements probed ( and hence quantile queries ) to list all documents is at most 4m / fmin , where fminis the k - th highest frequency in the result .3We can determine this easily in O(1 ) time by maintaining a bitvector of size N. .", "label": "", "metadata": {}, "score": "51.980053"}
{"text": "T. Gagie , S. Puglisi , and A. Turpin .Range quantile queries : Another virtue of wavelet trees .In Proc . 16thSPIRE , LNCS 5721 , pp\u02d91 - 6 , 2009 .R. Grossi , A. Gupta , and J. Vitter .", "label": "", "metadata": {}, "score": "51.994125"}
{"text": "Given the variable efficiency of two - word queries with WT ( due to the diverse number of possible document matches for each query ) , it is difficult to draw definitive conclusions on the relative algorithm performance .When the phrase length is increased , the two standard Zettair methods get slower per query , as expected , because they now have to intersect more inverted lists to produce the final ranked result .", "label": "", "metadata": {}, "score": "52.062798"}
{"text": "Automated thresholding to extract semantically relevant documents .An R - test is employed to extract semantically relevant documents for a query [ 21 ] .The following procedure describes the R - test .i ) Randomly select the terms from the term document matrix . ii ) Find the relevance ( ranking using similarity measure or other ways ) of the query with the documents based on the GO and PubMed term document space . iii ) Repeat the steps 1 and 2 for 25 iterations as proposed in [ 21 ] . iv ) Arrange the document ranks based on the median rank ( r ) as shown in the Fig .", "label": "", "metadata": {}, "score": "52.27086"}
{"text": "This process addresses the problem of synonymy by projecting the vectors into low - dimensional space in retrieving abstracts .The comparison between the query and database entries is performed using similarity measure .The cosine similarity measure is found to be well suited for this application .", "label": "", "metadata": {}, "score": "52.335747"}
{"text": "Page 2 . contain errors .Other types of text simply do not have a standard definition of a term , such as biological sequences ( DNA , protein ) and multimedia signals .With this in mind , in this paper we take the view of a text database ( or collection ) T as a string of n symbols drawn from an alphabet \u03a3. Queries are also strings ( or sets of strings ) composed of symbols drawn from \u03a3. Here , the symbols in \u03a3 may be bytes , letters , nucleotides , or even words if we so desire ; and the documents may be articles , chromosomes or any other texts in which we need to search .", "label": "", "metadata": {}, "score": "52.85174"}
{"text": "C .T .T .S . i .S .TF .STC .IDF .ST .where : .S C is the total score for the supercategory S C , .S 0 is the number of segments in the supercategory S C , .", "label": "", "metadata": {}, "score": "52.8829"}
{"text": "In one embodiment of the system , the set of Terms T j in the Document D i used to create the Query Q i comprises all of the Terms in the Document D i .In another embodiment , the set of Terms T j comprises all of the Terms in the Document D i except certain common words , referred to as stop words , such as \" the \" or \" and .", "label": "", "metadata": {}, "score": "52.944595"}
{"text": "LingPipe implements a second kind of token - based distance in the class spell .TfIdfDistance .By varying tokenizers , different behaviors may be had with the same underlying implementation .TF / IDF distance is based on vector similarity ( using the cosine measure of angular similarity ) over dampened and discriminatively weighted term frequencies .", "label": "", "metadata": {}, "score": "52.946285"}
{"text": "T .C .i .S .j . ) k .K .L .C .i .C . k . )K . where .Control then passes to a step 2920 , at which it is determined if there remain any further supercategories S j for which total scores T ( C i , S j ) have not yet been calculated for the category C i being processed .", "label": "", "metadata": {}, "score": "53.126343"}
{"text": "Inverted indexes require the tex- tual units ( words , q - grams , characters ) of the vocabulary to be defined before indexing commences in order to limit the size of the index and vocabulary , and to allow tf\u00d7idf information to be precomputed and stored .", "label": "", "metadata": {}, "score": "53.161945"}
{"text": "ep ] using quantile(D[sp . ep],r ) in O(logN ) time .In the remainder of this section we refer to D[sp .ep ] as X[1 .m ] with m a power of 2 , and assume we can probe X as if it were sorted ( with each probe requiring O(logN ) time ) .", "label": "", "metadata": {}, "score": "53.348053"}
{"text": "At a step 2490 , the process 2450 then calculates the log likelihood ratio L ( D i , D k ): .L .D .i .D . k . ) log .m .M . m .", "label": "", "metadata": {}, "score": "53.586998"}
{"text": "Fig .2 shows the total time for 200 queries of each query length for all methods .The document listing method of Gagie et al .with our optimizations ( number 4 on the graphs ) is clearly the fastest method for finding all documents and tfq , d values that contain the query q in document number order .", "label": "", "metadata": {}, "score": "53.883274"}
{"text": "9 illustrates a relationship between items of interest , categories and supercategories when categories in a collection have been assigned to supercategories .FIG .10 illustrates a relationship between categories and supercategories .FIG .11 is a flow chart which illustrates a process , according to the present invention , of assigning a supercategory to a query .", "label": "", "metadata": {}, "score": "54.136208"}
{"text": "S. E. Robertson and S. Walker , Microsoft Cambridge at Trec-9 : Filtering Track , 2001 .2 Answers 2 .The term count in the given document is simply the number of times a given term appears in that document .", "label": "", "metadata": {}, "score": "54.146202"}
{"text": "In this method , a small set of documents is retrieved using the original user query ; these documents are all assumed to be relevant without any intervention by the user [ 27 ] .The content of the assessed documents is used to adjust the weights of terms in the original query and/or to add keywords to the query .", "label": "", "metadata": {}, "score": "54.243053"}
{"text": "It may desirable in this embodiment of the system to associate each Document D 2420 with one and only one Index Term I 2440 , or it may be desired to associate a plurality of Index Terms with a Document D. .", "label": "", "metadata": {}, "score": "54.667103"}
{"text": "Compressed representa- tions of sequences and full - text indexes .ACM TALG , 3(2):article 20 , 2007 .J. Fischer and V. Heun .A new succinct representation of RMQ - information and improvements in the enhanced suffix array .In Proc .", "label": "", "metadata": {}, "score": "54.732067"}
{"text": "The method of . claim 17 , wherein the number I T is 30 .A device for automatically choosing index terms to be associated with a document D , for purposes of facilitating document retrieval processes , comprising : .( a ) means for creating a search query Q comprised of terms in document D ; .", "label": "", "metadata": {}, "score": "54.790535"}
{"text": "Moreover , we found that choosing any value of k from 1 to 100 had little effect on the runtime of Greedy and Quantile .This is a result of the low occ and docc for that set of queries , thus requiring less work from the self - index methods .", "label": "", "metadata": {}, "score": "54.81829"}
{"text": "To find the document a given position i is contained in we simply ( binary ) search for the smallest value greater than i in this array .Because we scan text blocks left - to - right , positions of occurrence are mapped to documents in increasing order , allowing the amount of the mapping array searched to be reduced as block scanning proceeds : a small optimization .", "label": "", "metadata": {}, "score": "54.86255"}
{"text": "Persin et al .[14 ] give different heuristics to support top - k ranked retrieval ( under the tf\u00d7idf model ) when inverted lists are sorted by decreasing tf .Anh and Moffat [ 1 ] study various generalizations of this idea under the name \" impact ordering \" .", "label": "", "metadata": {}, "score": "54.862846"}
{"text": "A further similarity with Jaccard distance is that various tokenization factories may be plugged in to form the basis of the comparison .Code Walk Through .The code for TF / IDF distance is more involved than that for Jaccard distance , because the IDF values need to be computed from data .", "label": "", "metadata": {}, "score": "55.079777"}
{"text": "Section 3 describes the preprocessing and Query Expansion methods employed in this research for retrieving relevant documents and the experimental results .Finally , the conclusions are included in Section 4 .Information Retrieval Process .In Information Retrieval , the query process is composed of two main phases , indexing and matching ( see Figure 1 ) .", "label": "", "metadata": {}, "score": "55.211563"}
{"text": "It is helpful if the collection C 0 has the property that the usage of terms in documents in it is characteristic of the usage of terms that will be found in documents over which searches will be carried out using the additional index terms added to the documents .", "label": "", "metadata": {}, "score": "55.217438"}
{"text": "S . i .S .W .SD .In one embodiment of the system , an entire document itself is considered a single segment , and the additional index terms associated with the document , such as by the system described herein , are considered a second segment .", "label": "", "metadata": {}, "score": "55.219498"}
{"text": "The inverse document frequency is a measure of how much information the word provides , that is , whether the term is common or rare across all documents .It is the logarithmically scaled inverse fraction of the documents that contain the word , obtained by dividing the total number of documents by the number of documents containing the term , and then taking the logarithm of that quotient .", "label": "", "metadata": {}, "score": "55.502766"}
{"text": "The GO terms are used as the query vector ( q 0 ) to inquire the Eigen mapped documents .Since the comparison needs to be performed in the same space , the query expansion is performed by mapping the query vector to the Eigen space as shown in Eq .", "label": "", "metadata": {}, "score": "55.51542"}
{"text": "While the number of terms added may vary without departing from the spirit and scope of the invention , in one embodiment 30 terms are chosen to be added as index terms .After index terms are assigned to Document D i at the step 2160 , control passes to a step 2170 .", "label": "", "metadata": {}, "score": "55.76332"}
{"text": "We present two new algorithms for ranking documents against a query without making any assumptions on the structure of the underlying text .We build on existing theoretical techniques , which we have implemented and compared empirically with new approaches introduced in this pa- per .", "label": "", "metadata": {}, "score": "55.809464"}
{"text": "claim 20 , further comprising means for selecting the I T terms for use as index terms for document D , which means are comprised of .( a ) means for calculating , for terms T k which occur in the N 0 documents selected , the co - occurrence C n ( T j , T k ) of that term T k with terms T j in document D : . where . co .", "label": "", "metadata": {}, "score": "56.117264"}
{"text": "However , applying such information - theoretic notions to problems in information retrieval leads to problems when trying to define the appropriate event spaces for the required probability distributions : not only documents need to be taken into account , but also queries and terms .", "label": "", "metadata": {}, "score": "56.173176"}
{"text": "The device of . claim 26 , wherein in applying the search query Q to the collection of documents C 0 the total score S D for a document D in the collection C 0 is .S .D .T .", "label": "", "metadata": {}, "score": "56.19665"}
{"text": "The method of .claim 7 , wherein in applying the search query Q to the collection of documents C 0 the total score S D for a document D in the collection C 0 is .S .D .T .", "label": "", "metadata": {}, "score": "56.231926"}
{"text": "FIG .2 , each Term T 2010 may occur in one or more Documents D 2020 , and each Document D 2020 contains one or more Terms T 2010 .According to .FIG .3 , this method 2050 proceeds first at a step 2060 to select a Document D i which has not yet had index terms assigned to it .", "label": "", "metadata": {}, "score": "56.247223"}
{"text": "View Article .Dumais ST : Latent Semantic Analysis .Annual Review of Information Science and Technology ( ARIST )2004 , 38 : 189 - 230 . chapter 4 .Zhang C , Lu X , Zhang X : Significance of Gene Ranking for Classification of Microarray Samples .", "label": "", "metadata": {}, "score": "56.289215"}
{"text": "Note that the word \" gene \" shows up in 3 documents and has an IDF of 0.85 , whereas the word \" encodes \" shows up in only one document and thus has a weight of 1.95 .Finally note that the period ( . ) shows up in each string , so has an IDF weight of 0.0 , effectively throwing it out of the comparison process .", "label": "", "metadata": {}, "score": "56.320225"}
{"text": "Other factors which may be used to vary the weight assigned to a term in calculating a term frequency score will also be apparent to one of ordinary skill in the art .Documents in a collection which is being searched may be divided into different sections or segments , such as an introduction or summary , a main body , footnotes , captions , and the like .", "label": "", "metadata": {}, "score": "56.357063"}
{"text": "Methods for doing so by manual means will be apparent to one of ordinary skill in the art .The manual assignment of index terms to a document may be time consuming , and this may make it impractical to assign index terms to large collections of documents by this method .", "label": "", "metadata": {}, "score": "56.379387"}
{"text": "These techniques help to overcome vocabulary mismatch issues by expanding the original query with additional relevant terms and reweighting the terms in the expanded query .In this paper , different text preprocessing and query expansion approaches are combined to improve the documents initially retrieved by a query in a scientific documental database .", "label": "", "metadata": {}, "score": "56.642014"}
{"text": "Else we check the frequency of the the minimum item .If it is less than fX[m/4 ] , we extract the minimum and insert ( X[m/4],fX[m/4 ] ) .We then perform the same check and update with ( X[3m/4],fX[3m/4 ] ) .", "label": "", "metadata": {}, "score": "56.710735"}
{"text": "The translation is presented like a set of keywords ( or index terms ) which represents the query and summarizes the information in which the user is interested .Information Retrieval using only keywords is not usually very efficient .In general , information about a particular issue can be represented with different keywords which may not coincide exactly with the terms entered in the query by the user .", "label": "", "metadata": {}, "score": "56.712646"}
{"text": "In Information Retrieval , a document is indexed by the frequency of its words .Statistical analysis of this process shows that some words have low frequency , while others have high frequency [ 11 ] .For example , and , of , and the appear frequently in the documents without significant information .", "label": "", "metadata": {}, "score": "56.834587"}
{"text": "In applications like spell checking , they will be weighted as log probabilities .When used for distance , they 'll be negated to give edit distances .General Weighted Edit Distance .The class spell .WeightedEditDistance implements a more general notion of weighted edit distance that allows the weights to be set on a per - character basis .", "label": "", "metadata": {}, "score": "56.85711"}
{"text": "ABSTRACT .Text search engines return a set of k documents ranked by similarity to a query .Typically , documents and queries are drawn from natural language text , which can readily be partitioned into words , allowing optimizations of data structures and algorithms for ranking .", "label": "", "metadata": {}, "score": "56.941998"}
{"text": "This method has been described by Xu and Croft , in Improving the Effectiveness of Informational Retrieval with Local Context Analysis , which is incorporated herein by reference .FIG .2 illustrates a collection of Documents D 2020 which contain Terms T 2010 .", "label": "", "metadata": {}, "score": "56.97406"}
{"text": "It makes it possible to obtain several measures related to information retrieval [ 30 ] .The most commonly used are the following .Average Precision .For systems that return a ranked sequence of documents , it is preferable to consider the order in which the returned documents are presented .", "label": "", "metadata": {}, "score": "57.156345"}
{"text": "The method of . claim 2 , wherein co - occurrences f D ( T k ) are calculated for all terms contained in the N 0 documents selected , except that preselected stop terms are eliminated .The method of .", "label": "", "metadata": {}, "score": "57.15701"}
{"text": "For instance , see Ristad and Yianilos ( 1997 ) , or Kernighan , Chruch and Gale ( 1990 ) .The latter introduces more complex context - sensitive edits .Typicall , the edits are n't marked in corpora , so latent alignments must be computed using techniques such as expectation maximization ( EM ) .", "label": "", "metadata": {}, "score": "57.20288"}
{"text": "v )Consider the consistently high ranked documents under null hypothesis .These ranks will follow a uniform distribution as shown in the Fig .4 .The documents that are considered significant using p - value are considered relevant and displayed in the order of relevance .", "label": "", "metadata": {}, "score": "57.248924"}
{"text": "A similarity metric,\u02c6S(q , di ) , is used to evaluate each document direlative to a user query q ( often a list of terms or words ) .If docu- ments are treated as \" bags of terms \" , similarity can be measured using simple statistical properties of the vocabulary [ 23].", "label": "", "metadata": {}, "score": "57.396645"}
{"text": "Note we can insert zero to two new elements in the queue .Fig .5(a ) gives pseudo code .In the worst case , this approach will explore almost as much of the tree as would be explored during the constrained depth- first traversal of Gagie et al . , and so requires O(docclogN ) time .", "label": "", "metadata": {}, "score": "57.49346"}
{"text": "We see this work as an important first step toward practical ranked retrieval for large general - text collections , and an extension of current indexing methods beyond traditional algorithms that assume a lexicon of terms a priori .2 Basic Concepts Relevance Ranking .", "label": "", "metadata": {}, "score": "57.612198"}
{"text": "This weight is a statistical measure used to evaluate the importance of a word to a document in a collection or corpus .The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus .", "label": "", "metadata": {}, "score": "57.91842"}
{"text": "5 is a flow chart which illustrates an overall process , according to the present invention , of automatically assigning index terms to documents , where some documents have previously had index terms assigned to them .FIG .6 illustrates a relationship between terms , documents and index terms after documents in a collection have had index terms assigned to them automatically .", "label": "", "metadata": {}, "score": "57.94787"}
{"text": "Then the Machine calculates information gain for each split by looping over every possible value for an attribute and by calculating the difference between the entropy of the overall data set and the entropy of splitting the data on that value : .", "label": "", "metadata": {}, "score": "58.008343"}
{"text": "These are the words that do not offer any significant improvement in the semantics or the search retrieval and also introduce noise in the corpus .A porter - stemming algorithm is used to stem the words in the document to their root words [ 15 ] .", "label": "", "metadata": {}, "score": "58.055267"}
{"text": "Some information retrieval techniques such as are employed in these circumstances choose documents for retrieval from among documents in a collection based upon the occurrence of specified terms in the documents in the collection .( Hereinafter , for simplicity , \" document \" shall be used to refer to the items , such as Web pages or Web sites , in the collection being analyzed . )", "label": "", "metadata": {}, "score": "58.148674"}
{"text": "( b ) Corpus - specific terms are found by analyzing the contents of a particular full - text database to identify terms used in similar ways .It may be hand - built , a time - consuming and ad hoc process , or created automatically .", "label": "", "metadata": {}, "score": "58.24261"}
{"text": "We present two new algorithms for ranking documents against a query without making any assumptions on the structure of the underlying text .We build on existing theoretical techniques , which we have implemented and compared empirically with new approaches introduced in this paper .", "label": "", "metadata": {}, "score": "58.27076"}
{"text": "The ROC curves are one of the ways to analyse the cost benefit ratio .The problem at hand is a binary classifier where the abstract is either associated to GO term or not .There are four possible alternatives that may be obtained from the classifier viz . true positives ( TP ) , false positives ( FP ) , true negatives ( TN ) and false negatives ( FN ) .", "label": "", "metadata": {}, "score": "58.343452"}
{"text": "claim 30 , wherein the number N 0 is 50 .The device of . claim 21 , wherein all documents whose scores upon application of the search query Q exceed a given cutoff score are selected .The device of . claim 21 , wherein co - occurrences f D ( T k ) are calculated for all terms contained in the N 0 documents selected .", "label": "", "metadata": {}, "score": "58.361206"}
{"text": "TT_DISTANCE .It has special weights for spaces or hyphens , digit subsitution , capital for lowercase , and so on .Follow the link to the constant for a full version .Spell Checking .The spell checker uses weighted edit distances to model likelihoods of errors in formulating queries ( typos and brainos ) .", "label": "", "metadata": {}, "score": "58.424862"}
{"text": "Time to find word based queries using Zettair and the best of the new methods for 2 and 4 word queries on wsj .Term - based Search .However , these approaches are not directly comparable to com- mon word - based queries at which traditional inverted indexes excel .", "label": "", "metadata": {}, "score": "58.532482"}
{"text": "Table 9 : Evaluation measures using the pseudorelevance feedback in Abstract , Title , and MeSH fields .Use of MeSH to Expand Queries .As many authors have already worked with MeSH fields to retrieve information , we focus this part of the research on testing its efficiency in query expansion .", "label": "", "metadata": {}, "score": "58.565422"}
{"text": "LSA 's solution to the synonymy problem made it attractive to a variety of researchers outside of information retrieval .The geometrical interpretation provided in [ 20 ] gives an insight into the underlying principles of LSA .In general , there are many parameters ( for example selecting threshold ) that need to be determined for any semantic space .", "label": "", "metadata": {}, "score": "58.608253"}
{"text": "The indexing step offers the user the ability to apply local and global weighting methods , including tf - idf .Disclosed are methods and systems for automatically assigning index terms to electronic documents such as Web pages or sites in a manner which may be used to facilitate the retrieval of electronic documents of interest .", "label": "", "metadata": {}, "score": "58.862762"}
{"text": "These scores which are calculated may be referred to as term frequency scores , insofar as the score assigned to a document depends on the frequency of occurrence of terms in the document .There are a variety of different formulae which may be used to calculate these term frequency scores , including for example the Robertson 's term frequency score ( RTF ) .", "label": "", "metadata": {}, "score": "58.942116"}
{"text": "All documents whose scores upon application of the search query Q exceed a given cutoff score may be selected .Co- occurrences may be calculated for all terms contained in the N 0 documents selected .Preselected stop terms may be eliminated .", "label": "", "metadata": {}, "score": "59.01809"}
{"text": "7 illustrates a relationship between items of interest , categories and supercategories when some but not all categories in a collection have been manually assigned to supercategories .FIG .8 is a flow chart which illustrates an overall process , according to the present invention , of automatically assigning categories to supercategories , where some categories have previously been assigned to supercategories .", "label": "", "metadata": {}, "score": "59.08123"}
{"text": "Other techniques for selecting terms to be utilized will be apparent to one of ordinary skill in the art .Based upon the scores achieved by the documents in the collection , the documents may be ranked , and a predetermined number of documents may be presented to the user , or all documents which achieve scores above a predetermined cutoff may be presented .", "label": "", "metadata": {}, "score": "59.21582"}
{"text": "4.2 Top - k via Quantile Probing We now exploit the fact that in a sorted array X[1 .In general we have the following : Observation 1 On a sorted array X[1 .ep].However , we can access the elements of D[sp .", "label": "", "metadata": {}, "score": "59.217957"}
{"text": "Specifically , sharing the token \" kDa \" counts for more than sharing the word \" is \" .Following the dump of terms and IDFs is the comparison values .As with Jaccard distance , strings are distance zero from themselves , and all distances are between zero and one .", "label": "", "metadata": {}, "score": "59.26113"}
{"text": "In one embodiment , the number I T may be 30 .All terms whose scores exceed a given cutoff score may be selected for use as index terms .DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT(S ) .Referring to .FIG .", "label": "", "metadata": {}, "score": "59.290752"}
{"text": "2 illustrates a relationship between terms and documents .FIG .3 is a flow chart which illustrates a process , according to the present invention , of automatically assigning index terms to documents .FIG .4 illustrates a relationship between terms , documents and index terms when some but not all documents in a collection have had index terms manually assigned to them .", "label": "", "metadata": {}, "score": "59.36434"}
{"text": "Once the Machine has clustered the emails and found the variations , it takes the demographics of the users who sent in the email and creates a Machine Learning model called a Decision Tree for every variation of each email & 8212 ; except the most popular one .", "label": "", "metadata": {}, "score": "59.387337"}
{"text": "In this regard , GOPUBMED provides redundant information already available from GO .The other method GO - KDS [ 7 ] uses a machine learning approach to address the mentioned objectives in section I. The well - annotated abstracts linked to the GO terms are obtained from various sources such as SwissProt , GenBank , and FlyBase etc .", "label": "", "metadata": {}, "score": "59.498154"}
{"text": "Elimination of stopwords can significantly reduce the size of the indexing structure , speed up the calculation and increase accuracy .Okapi BM25 Weighting Algorithm .Okapi BM25 , or BM25 , is a weighting function used to rank documents according to their relevance to a given query [ 12 ] .", "label": "", "metadata": {}, "score": "59.512333"}
{"text": "Any tokenizer factory may be plugged into the Jaccard distance .As shown in the next section , a TF / IDF - based distance may use exactly the same variety of tokenizers with roughly the same effect .Stemming , Stoplisting and Case Normalization .", "label": "", "metadata": {}, "score": "59.538204"}
{"text": "( A \" term \" may be any word , number , acronym , abbreviation or other collection of letters , numbers and symbols which may be found in a fixed order in a document . )In some methods , a search may be made among the documents in the collection for some or all of the terms in a search query generated by the user .", "label": "", "metadata": {}, "score": "59.68194"}
{"text": "In order to evaluate the results of the retrieval process , a program inside the TREC conference , trec .Trec_eval makes it possible to obtain measures such as the Total number of documents over all queries ( Retrieved , Relevant and Rel_ret ( relevant , and retrieved ) ) or MAP , R - prec , and Interpolated Recall - Precision Averages .", "label": "", "metadata": {}, "score": "59.694878"}
{"text": "The relevant abstracts are further presented to the user in the order of decreasing PubMed Ids .PubMed I d is the index number for each abstract in the repository .PubMed therefore presents the results in the order of latest to the oldest .", "label": "", "metadata": {}, "score": "59.893044"}
{"text": "In this paper , authors have used a very simplistic approach to determine the BM25 parameters values .Tuning the BM25 free parameters ( .M. H. Coletti and H. L. Bleich , \" Medical subject headings used to search the biomedical literature , \" Journal of the American Medical Informatics Association , vol . 8 , no .", "label": "", "metadata": {}, "score": "59.919853"}
{"text": "In our experiments , the .Query Expansion .Query expansion techniques have been studied for nearly three decades .The various methods proposed in the literature can be classified into the following three groups [ 16 ] : query specific , corpus specific , and language specific .", "label": "", "metadata": {}, "score": "60.06478"}
{"text": "The SEGOPubmed is queried with the GO terms and the significant abstracts are retrieved by applying R - test and are compared with the ground truth .The number of true positives and false positives among the retrieved abstracts are recorded to build the receiver operating characteristic ( ROC ) curves .", "label": "", "metadata": {}, "score": "60.066612"}
{"text": "( Lines interpolated for clarity . )Due to Obs .5 Experiments We evaluated our new algorithms ( Greedy from Section 4.1 and Quantile from Section 4.2 ) with English text and protein collections .We also implemented our improved version of Gagie et al . 's Wavelet Tree document listing method , labelled WT .", "label": "", "metadata": {}, "score": "60.254025"}
{"text": "However , manual association is time consuming and therefore costly , and this is particularly the case if the categories and supercategories may change frequently .This embodiment of the system described herein therefore permits categories to be assigned to supercategories automatically , after an initial group of categories have been assigned manually .", "label": "", "metadata": {}, "score": "60.27707"}
{"text": "In this embodiment , a certain number of the categories may have been assigned to supercategories manually , while the remainder may have been assigned to supercategories utilizing a variety of automatic or semi - automatic index term augmentation techniques .In one segment are the terms and term identifiers associated with the categories assigned to the supercategory manually , while each of the other segments comprises the terms and term identifiers associated with the categories assigned to the supercategory by a particular automatic or semi - automatic method .", "label": "", "metadata": {}, "score": "60.361343"}
{"text": "Succinct data structures for flexible text retrieval systems .J. Discrete Algorithms , 5(1):12 - 22 , 2007 .G. Salton , A. Wong , and C. S. Yang .A vector space model for automatic indexing .Comm .ACM , 18(11):613 - 620 , 1975 .", "label": "", "metadata": {}, "score": "60.41803"}
{"text": "( In these techniques , all of the terms may be used , or certain common words , referred to as stop words , such as \" the \" or \" and \" , may be omitted . )Another technique that may be employed is to select index terms which have previously been associated with the document being accessed or selected by the user .", "label": "", "metadata": {}, "score": "60.563374"}
{"text": "Consider the example tree of Fig .1 , where we list the distinct numbers in D[3 . .13].A depth - first traversal begins by following the leftmost path to leaf 8 .As we step left to a child , we take note of the number of 0-bits in the range used in its parent node , labelled n0on each branch .", "label": "", "metadata": {}, "score": "60.651176"}
{"text": "K 3 and K 4 are constants .The method of . claim 8 , wherein K 1 equals 0.5 , K 2 equals 1.5 , K 3 equals 0.5 , and K 4 equals 1.0 .The method of . claim 2 , wherein all terms whose scores f D ( T k ) exceed a given cutoff score are selected for use as index terms .", "label": "", "metadata": {}, "score": "60.671333"}
{"text": "The trained SVM system is validated using the abstracts obtained in 2001 .The system performed with an accuracy of 70.5 % .The linking of 26500 abstracts is further generalized to 12 million abstracts ( in 2001 ) .It was claimed that the 70.5 % accuracy obtained on the training set is acceptable and generalizes this result to 12 million abstracts .", "label": "", "metadata": {}, "score": "60.720142"}
{"text": "We continue to intersect the candidate list with the remaining gathered lists until either no lists remain , or the size of the candidate list becomes less than a threshold .At this point , for each item ( block number ) in the candidate list , we scan each of the corresponding text block looking for occurrences of q. The intersection phase of the algorithm can be thought of as a filtering step : blocks that can not contain the pattern are eliminated from the later scanning phase .", "label": "", "metadata": {}, "score": "60.776608"}
{"text": "It is difficult to model these word vectors in a relational database , especially if you want to calculate TF - IDF and Cosine Similarity for the documents quickly .So the Message Machine uses a key - value store database that I built called Daybreak , which we will open source very soon .", "label": "", "metadata": {}, "score": "60.927372"}
{"text": "C .i .C . k . ) log .m .M . m .C .i .C . k . ) m .M . m .C .i . ) where : .If any such manually assigned categories C k remain at the step 2900 , control returns to the step 2880 at which a further manually assigned category C k is chosen for calculation .", "label": "", "metadata": {}, "score": "60.94425"}
{"text": "The cost curves plotted show the performance of SEGOPubmed for only 3 GO terms .For a complete investigation of the performance for all the 60 GO terms considered , TPF and FPF values at the threshold given by the R - test are mentioned in tables 1 and 2 . Conclusions .", "label": "", "metadata": {}, "score": "60.95828"}
{"text": "Fig . 1 ( b ) shows the cost curve for the test data .Fig . 1 ( b ) shows the similar performance as seen for the training data and hence can be used to classify the test documents to the GO terms .", "label": "", "metadata": {}, "score": "61.019577"}
{"text": "After the query is run at step 2080 , at a step 2090 a number of documents N 0 in C 0 which achieve the highest scores under the search query Q i are selected .For example , in various embodiments the number N 0 may be between 10 and 300 , but it may vary depending on operational considerations which will be apparent to one of ordinary skill in the art .", "label": "", "metadata": {}, "score": "61.105812"}
{"text": "D .T .T .TF .TD .IDF .T .where : .H .D .T .L .D .N .TD .H .O .N .N .H .D . )", "label": "", "metadata": {}, "score": "61.233917"}
{"text": "For this sake we generated 44,693 additional queries aligned on English word boundaries from the wsj collection .Statistics of these phrase queries of word length 2 to 15 are given in Appendix D. Short of implementing an in - memory search engine , it is difficult to choose a baseline inverted file implementation that will efficiently solve the top - k doc- ument listing problem .", "label": "", "metadata": {}, "score": "61.269028"}
{"text": "Then store bitvector Broot[1 .At the leaves , where all the symbols of the corresponding Dleaf are equal , nothing is stored .Page 4 .The top row of each node shows D , the second row the bitvector Bv , and numbers in circles are node numbers for reference in the text .", "label": "", "metadata": {}, "score": "61.293674"}
{"text": "These techniques also may be utilized when a user is accessing certain material , in order to make available material that it is thought may be of interest to a user who has accessed the original material .These techniques may also be utilized when a user , given access to particular material , requests other similar material .", "label": "", "metadata": {}, "score": "61.429886"}
{"text": "FIG .10 , it is desirable in this embodiment of the system to assign each category 2210 of merchants or stores to one and only one supercategory 2220 of banner advertisements .Each supercategory further has associated with it the category identifier terms which are unique to the categories assigned to it .", "label": "", "metadata": {}, "score": "61.562626"}
{"text": "4 shows the time for searching for two- and four - word patterns .Page 11 .than the new methods , as expected from Fig . 2 .The Zet - ph has better performance , on average , than Zet , and Zet - io is the most efficient of all word - based inverted indexing methods tested .", "label": "", "metadata": {}, "score": "61.645866"}
{"text": "However , manual association is time consuming and therefore costly , and this is particularly the case if the Documents and/or Index Terms may change frequently .The system described herein therefore permits Documents to be assigned Index Terms automatically , after an initial group of Documents have been assigned manually .", "label": "", "metadata": {}, "score": "61.732346"}
{"text": "The priority of a pair favors larger ranges , and ties are broken in favor of deeper nodes .Page 7 . one or more 0-bits ( resp .1-bits ) then at least one document to report lies on the left subtree ( resp .", "label": "", "metadata": {}, "score": "61.767433"}
{"text": "Document Corpora .As seen in Figure 1 , three document corpora are needed to analyze the efficiency of a query system : the original document corpus , the textual descriptions of the users queries ( topics ) , and the relevant judgments given by the experts [ 3 ] .", "label": "", "metadata": {}, "score": "61.903297"}
{"text": "The indexing step preprocesses documents and queries in order to obtain keywords ( relevant words , also named terms ) to be used in the query .At this point , it is important to consider the use of stemming and stopword lists in order to reduce related words to their stem , base or root form .", "label": "", "metadata": {}, "score": "62.018345"}
{"text": "Efficient algorithms for document retrieval problems .In Proc . 13thSODA , pp\u02d9657 - 666 , 2002 .G. Navarro and V. M\u00a8 akinen .Compressed full - text indexes .Surveys , 39(1):article 2 , 2007 .M. Persin , J. Zobel , and R. Sacks - Davis .", "label": "", "metadata": {}, "score": "62.059128"}
{"text": "This process incorporates the semantics into the retrieved document space .Next the GO terms are mapped into the semantic space and semantically related abstracts are retrieved and displayed based on relevance tagged to each of the GO terms .Creation of corpus .", "label": "", "metadata": {}, "score": "62.19793"}
{"text": "Distances and Proximities .Their signatures are both very simple .The distance interface specifies a single method which computes a distance between two objects of type E : .The proximity interface also specifies a single method : .String similarity can be specified in terms of distance .", "label": "", "metadata": {}, "score": "62.214977"}
{"text": "MeSH thesaurus is a controlled vocabulary used for indexing , cataloging , and searching for biomedical and health - related information and documents .It imposes uniformity to the indexing of the scientific literature .MeSH thesaurus contains approximately . thousand terms and is updated annually to reflect changes in medicine and medical terminology .", "label": "", "metadata": {}, "score": "62.22609"}
{"text": "FIG .5 , the process 2450 of assigning Index Terms 2440 to Documents 2420 begins at a step 2460 in which an ( as - yet - unprocessed ) Document D i to which no Index Terms have been assigned manually is selected .", "label": "", "metadata": {}, "score": "62.253357"}
{"text": "it does n't appear that often in other documents in the collection . which in simple words means that this term is distinctive for the document in question .Quite a few variants of the above weighting algorithm exist .An example of such a type of search engine is Perlfect Search which I have written .", "label": "", "metadata": {}, "score": "62.28457"}
{"text": "The new strategy consists of expanding the queries with the MeSH Headings related to its terms .For the first time , we analyze the query and extract its keywords .Each keyword is automatically introduced at the PubMed online tool to match it with the Entry terms stored in MEDLINE .", "label": "", "metadata": {}, "score": "62.324284"}
{"text": "Matching is the process of computing the similarity between documents and queries by weighting terms , the most frequently applied algorithms being the TF - IDF and BM25 algorithms .Most retrieval systems return a ranked document list in response to a query , where the documents more similar to the query considered by the system are first on the list .", "label": "", "metadata": {}, "score": "62.338585"}
{"text": "right child ) .Thus , two wavelet tree rank operations are avoided ; an important practical improvement .We now recast Gagie et al . 's algorithm .When listing all distinct documents in D[sp .ep ] , the algorithm of Gagie et al . can be thought of as a depth - first traversal of the wavelet tree that does not follow paths which do not lead to document numbers not occurring in D[sp .", "label": "", "metadata": {}, "score": "62.34844"}
{"text": "This research aims to improve the efficiency of the queries based on classic models ( where documents are retrieved even if only a small part of them is related to the query ) , when they are performed in public scientific databases , such as Pubmed .", "label": "", "metadata": {}, "score": "62.47788"}
{"text": "ep ] is very fast , and about the same for all the query lengths tested .A low occ value means this range is smaller , and so less work for the document listing methods .Fig .3 summarizes the time per document listed , and clearly shows that the top - k methods ( Quantile and Greedy ) do more work per document listed .", "label": "", "metadata": {}, "score": "62.58761"}
{"text": "Full - text . edu.au 2Department of Computer Science , Univ . of Chile .gnavarro@dcc.uchile.cl Abstract .Text search engines return a set of k documents ranked by similarity to a query .Typically , documents and queries are drawn from natural language text , which can readily be partitioned into words , allow- ing optimizations of data structures and algorithms for ranking .", "label": "", "metadata": {}, "score": "62.61242"}
{"text": "4 illustrates the relationship of Terms , Documents and Index Terms , when some Documents have been assigned Index Terms manually , and others have not had Index Terms assigned .( It will be understood by one of ordinary skill in the art that the system here described may also be applied where an initial group of documents have had Index Terms assigned by another automatic method , rather than manually . )", "label": "", "metadata": {}, "score": "62.77315"}
{"text": "173 - 180 , 2002 .View at Google Scholar \u00b7 View at Scopus .K. Shin and S. Y. Han , \" Improving information retrieval in medline by modulating mesh term weights , \" in Natural Language Processing and Information Systems , F. Meziane and E. Mtais , Eds . , vol .", "label": "", "metadata": {}, "score": "62.790867"}
{"text": "D Query Data Table 2 summarizes attributes of the queries used .Note the unusually low aver- age occ and docc values for the queries of length 5 for the protein data set .Page 16 .query lengthprotein queries avg total avg doc avg total avg doc occ 3 10,458 12,510 4 972 5 304 6 723 7 979 8 764 9 682 10 + 535 Table 2 .", "label": "", "metadata": {}, "score": "62.815327"}
{"text": "Other circumstances where it may be desirable to utilize information retrieval techniques to identify documents that may be of interest to a user will be apparent to one of ordinary skill in the art .Information retrieval techniques may choose documents from among the documents in a collection based upon the occurrence in the documents of specified terms .", "label": "", "metadata": {}, "score": "62.820084"}
{"text": "For example , the most relevant keywords of the top documents previously retrieved can be added to the query in order to rerank the documents .This process is known as relevance feedback .The retrieval can be further enhanced by modifying the words of the queries using other keywords more representative of the document content ( e.g. , including MeSH Headings ) .", "label": "", "metadata": {}, "score": "62.950832"}
{"text": "The Fig . 1 ( a ) shows the cost curve of the performance of SEGOPubmed for the training dataset .As shown in Fig . 1 ( a ) , the SEGOPubmed recorded very small FPF and very large TPF .", "label": "", "metadata": {}, "score": "62.980236"}
{"text": "87 - 91 , 2003 .View at Google Scholar \u00b7 View at Scopus .L. V. Gault , M. Shultz , and K. J. Davies , \" Variations in Medical Subject Headings ( MeSH ) mapping : from the natural language of patron terms to the controlled vocabulary of mapped lists , \" Journal of the Medical Library Association , vol .", "label": "", "metadata": {}, "score": "63.0019"}
{"text": "( If no co - occurrences have been found between the category C i being processed and any category manually assigned to a supercategory , the category C i being processed is not assigned to any supercategory . )Control then passes to a step 2940 at which it is determined if there remain any further unassigned categories C i not yet processed .", "label": "", "metadata": {}, "score": "63.05466"}
{"text": "Suffix arrays : a new method for on - line string searches .SIAM J. Computing , 22(5):935 - 948 , 1993 .G. Manzini .An analysis of the Burrows - Wheeler transform .J. ACM , 48(3):407- 430 , 2001 .", "label": "", "metadata": {}, "score": "63.084984"}
{"text": "JASIS , 47(10):749 - 764 , 1996 .J. M. Ponte and W. B. Croft .A language modeling approach to information retrieval .In Proc . 21th ACM SIGIR , pp\u02d9275 - 281 , 1998 .S. Puglisi , W. Smyth , and A. Turpin .", "label": "", "metadata": {}, "score": "63.178505"}
{"text": "Control then passes to a step 2880 at which a category C k , which has been manually assigned to supercategory S j is selected .At a step 2890 , the process 2850 then calculates the log likelihood ratio L ( C i , C k ): .", "label": "", "metadata": {}, "score": "63.223637"}
{"text": "Relevance weighting of search terms .JASIST , 27:129 - 146 , 1976 .S. E. Robertson , S. Walker , S. Jones , M. Hancock - Beaulieu , and M. Gatford .Okapi at TREC-3 .In D. K. Harman , editor , Proc . 3rd TREC , 1994 .", "label": "", "metadata": {}, "score": "63.376637"}
{"text": "The method of . claim 2 , wherein the search query Q which is applied comprises all of the terms in document D. .The method of . claim 2 , wherein the search query Q which is applied comprises all of the terms in document D with preselected stop terms eliminated .", "label": "", "metadata": {}, "score": "63.47386"}
{"text": "The ontology - based search is hence a most relevant alternative .The LSA is incorporated into this framework to find the semantically meaningful and relevant abstracts .The abstracts are ordered based on relevance and ontology based terms .The main building blocks of the SEGOPubmed are shown in the Fig . 2 .", "label": "", "metadata": {}, "score": "63.66606"}
{"text": "FPF hence , enables the comparison of performance of various classifiers employed in the study .The detailed steps of the performed evaluation may be listed as : .Construct the Ground truth by downloading GO terms and their associated abstracts .", "label": "", "metadata": {}, "score": "63.771202"}
{"text": "Borrajo et al .[ 23 ] study the use of dictionaries in the classification of biomedical texts with three different dictionaries ( BioCreative [ 24 ] , NLPBA [ 25 ] and an ad hoc subset of the UniProt database named Protein [ 26 ] ) .", "label": "", "metadata": {}, "score": "63.791794"}
{"text": "This application inspects the frequency of the terms in the abstracts for extract the relevant abstracts related to the proteins [ 12 ] .This application is also based on direct term matching concept of query and keywords from abstracts .The semantics of the query and the abstracts are not addressed by any of these systems .", "label": "", "metadata": {}, "score": "63.864853"}
{"text": "For instance , \" the \" and \" hte \" have a distance of one ( 1 ) with transposition , because \" the \" can be converted to \" hte \" by a single transposition of the first two characters .", "label": "", "metadata": {}, "score": "64.10066"}
{"text": "Indexing Processes Testing .The first tests are based on a study of the benefits produced by the use of stemming and stopwords in the indexing of documents and queries .We analyze the impact of stemming algorithms ( Porter and Krovetz ) and stopword lists ( NLM and SMART ) in the retrieval of documents from the corpus Cystic Fibrosis .", "label": "", "metadata": {}, "score": "64.393616"}
{"text": "They are generally used interchangeably with the MeSH Heading for the purpose of indexing and retrieval , thus increasing the access points to MeSH indexed data .The Cystic Fibrosis collection also contains 100 queries and the documents relevant to each query [ 1 ] ( see Table 2 ) .", "label": "", "metadata": {}, "score": "64.538956"}
{"text": "The abstracts thus may be browsed categorically based on the ontology terms .This process yields information similar to the information obtained from the GO .The GO already provides the information of linking abstracts to the GO terms [ 5 ] .", "label": "", "metadata": {}, "score": "64.642654"}
{"text": "First , text pre - processing is performed to extract the meaningful words from the abstracts .This is performed by i ) eliminating the stop words , ii ) stemming the words to their root words and iii ) forming the dictionary from all the stemmed words .", "label": "", "metadata": {}, "score": "64.69366"}
{"text": "Methods .The PubMed is one of the highly used repository for biomedical literature [ 1 ] .The results from the PubMed query are arranged in the order of entry of the abstracts into the repository .The order of arrangement intended by most of the users is the relevance of the abstracts to the query .", "label": "", "metadata": {}, "score": "64.73192"}
{"text": "This actually introduces multiple paths , as substituting a character for itself has cost 0 either through a match or substitute operation .The match could actually bet set to Double .NEGATIVE_INFINITY without changing any scores here .Finally , the transposition weight is set to negative infinity , effectively turning off transposition .", "label": "", "metadata": {}, "score": "64.76837"}
{"text": "Control then passes to a step 2540 at which it is determined if there remain any further Documents D i , which were not assigned index terms manually , which have not yet been processed .If any such unprocessed Documents D i remain at the step 2540 , control returns to the step 2460 at which a further as - yet - unprocessed Document D i is chosen for processing .", "label": "", "metadata": {}, "score": "64.79535"}
{"text": "View Article PubMed .Deerwester S , Dumais ST , Furnas GW , Landauer TK , Harshman R : Indexing by latent semantic analysis .Journal of the American Society for Information Science 1999 , 41 ( 6 ) : 391 - 407 .", "label": "", "metadata": {}, "score": "64.862625"}
{"text": "One technique that may be employed to select terms to be utilized in the process is to permit the user to specify terms by defining a search query .Another technique that may be employed is to select some or all of the terms in a document being accessed by the user .", "label": "", "metadata": {}, "score": "64.90281"}
{"text": "When a user searches the site , the Machine looks up the query words in our email indexes and returns an list of emails ordered by each email 's Cosine Similarity to the user 's query .The code is really very small .", "label": "", "metadata": {}, "score": "64.91491"}
{"text": "250 - 269 , 1999 .View at Google Scholar \u00b7 View at Scopus .View at Scopus . Y. Qiu and H. P. Frei , \" Concept based query expansion , \" in Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , pp .", "label": "", "metadata": {}, "score": "65.054"}
{"text": "A final note about the demographic information the Machine uses to create the decision trees : the Machine uses basic demographic information like age , sex , household income , state , and whether the user is a likely voter .It also includes an extra bit of information we 're calling a \" donation signal \" that represents the average previous donation amount asked for by each campaign by user .", "label": "", "metadata": {}, "score": "65.41824"}
{"text": "FixedWeightEditDistance(double matchWeight , double deleteWeight , double insertWeight , double substituteWeight , double transposeWeight ) ; .In the demo , these values are read from the command line , parsed into doubles , and spuplied to the constructor .Otherwise , this program is just like the last one , only we do not report proximities , but only distances .", "label": "", "metadata": {}, "score": "65.43117"}
{"text": "The device of .The device of . claim 21 , wherein the number I T of terms chosen as index terms is predetermined .The device of . claim 36 , wherein the number I T is 30 .The device of . claim 21 , wherein all terms whose scores f D ( T k ) exceed a given cutoff score are selected for use as index terms .", "label": "", "metadata": {}, "score": "65.43408"}
{"text": "The present study is limited to only a few well - referenced keywords .A comprehensive and evaluation based on semantic - space similarity of the SEGOPubmed is currently under investigation .The present technique also does not incorporate the concept of polysemy in linking the abstracts to the GO terms .", "label": "", "metadata": {}, "score": "65.54088"}
{"text": "( In some methods , all terms except certain common words , referred to as stop words , such as \" the \" or \" and \" , may be included in the search . )In other methods , a search may be made for index terms which have been associated with that document by various means .", "label": "", "metadata": {}, "score": "65.55284"}
{"text": "The best values obtained in our tests with the Cystic Fibrosis corpora are .Table 5 : Testing values of the parameters for BM25 .MAP is used as the evaluation measure .For the TF - IDF weighting algorithm with Okapi TF formula , the parameters obtained for Okapi BM25 are the best approach , using the correspondence shown in Table 3 .", "label": "", "metadata": {}, "score": "65.58505"}
{"text": "Table 10 : Evaluation measures using query expansion with descriptors , applied in MeSH , Title , and Abstract fields .The figure shows that curves of the query expansion algorithms for the combination Porter stemmer - NLM stopwords are closest to the upper right hand corner of the graph ( where recall and precision are maximized ) , which indicates the best performance .", "label": "", "metadata": {}, "score": "65.62616"}
{"text": "The user can now skim through the results using ontology terms based on relevance .Please note that only relevant abstracts are displayed because of the thresholding process .Declarations .Acknowledgements .The authors acknowledge the Herff College of Engineering Fellowship , Student support from the Bioinformatics Program and faculty start - up grants from the Electrical and Computer Engineering at the University of Memphis for partial funding of this research .", "label": "", "metadata": {}, "score": "65.73074"}
{"text": "Document retrieval based on Abstract , MeSH , and Title fields seems more effective than looking at each of these fields individually .In addition , the use of relevance feedback , a technique widely used by researchers in this field , produces a great improvement in the retrieval of scientific documents .", "label": "", "metadata": {}, "score": "65.78769"}
{"text": "When the Machine receives an email it needs to find others that have similar content .There are many document similarity algorithms - two that I find most beautiful are the sim hash and min hash algorithms - but I chose a more standard measure called Cosine Similarity .", "label": "", "metadata": {}, "score": "65.82922"}
{"text": "ki .T .j .T . k . )n .N . tf .T . k .n . ) tf .T .j .n . )The system then proceeds to a step 2130 .", "label": "", "metadata": {}, "score": "65.91968"}
{"text": "These techniques may be called into play in response to a search query initiated by the user .Alternatively , they may be called into play when a user requests additional documents that are similar to a document to which he has been given access .", "label": "", "metadata": {}, "score": "65.91971"}
{"text": "We are particularly interested in these techniques because they are commonly used to add useful words to a query .Unfortunately , casual users seldom provide a system with the relevance judgments needed in relevance feedback .In such situations , ad hoc or blind feedback is commonly used to expand the user query .", "label": "", "metadata": {}, "score": "65.97838"}
{"text": "In one embodiment of the system described herein , there may be a very large number of individual merchants or stores to be organized into categories of products or services for presentation .In this embodiment of the system , there are fewer categories of products or services than individual merchants or stores .", "label": "", "metadata": {}, "score": "66.03981"}
{"text": "The first form of term weighting is due to Hans Peter Luhn ( 1957 ) and is based on the Luhn Assumption : .The weight of a term that occurs in a document is simply proportional to the term frequency .", "label": "", "metadata": {}, "score": "66.08412"}
{"text": "G. K. Zipf , Human Behavior and the Principle of Least Effort , Addison - Wesley , Reading , Mass , USA , 1949 . S. E. Robertson , S. Walker , S. Jones , M. M. Hancock - Beaulieu , and M. Gatford , Okapi at Trec-3 , 1996 .", "label": "", "metadata": {}, "score": "66.100655"}
{"text": "For instance , using a case normalizing tokenizer filter would produce results in which \" The \" and \" the \" were considered a single ( matching ) token .Similarly , using a stemming filter , the tokens \" named \" and \" name \" would be considered equivalent .", "label": "", "metadata": {}, "score": "66.42792"}
{"text": "In addition , documents in a collection which is being searched may consist of various segments or sections .The segments or sections may include a title , an abstract or introduction or summary , captions , and footnotes .Other sections or segments into which a document may be divided will be apparent to one of ordinary skill in the art .", "label": "", "metadata": {}, "score": "66.51918"}
{"text": "According to .FIG .7 , in one embodiment of the system described herein , there may be a very large number of individual items of interest 2810 to be organized into categories 2820 for presentation .While the number may vary without departing from the spirit and scope of the invention , there may be about 20,000 categories .", "label": "", "metadata": {}, "score": "66.52107"}
{"text": "No .09/283,268 , to Jay Ponte , having a common application date of Mar. 31 , 1999 , having the same inventor and assignee as herein named .TECHNICAL FIELD .This invention relates to techniques for organizing material on computer networks for retrieval , and more particularly to methods of indexing material of interest to a user .", "label": "", "metadata": {}, "score": "66.59089"}
{"text": "The FP is the number of un - associated abstracts among the retrieved abstracts .On the contrary , TN is the number of truly un - associated abstracts among the rejected abstracts by the SEGOPubmed .FN is the number of truly associated abstracts rejected by the SEGOPubmed .", "label": "", "metadata": {}, "score": "66.67136"}
{"text": "The first two are implementations of V\u00a8 alim\u00a8 aki and M\u00a8 akinen [ 22 ] and Sadakane [ 20 ] as described in Section 3 , labelled VM and Sada respectively .It is described in detail in Appendix C. Experimental Data .", "label": "", "metadata": {}, "score": "66.68042"}
{"text": "In general when writing search algorithms the easiest way to optimize your code is to a create an inverted index .An inverted index is a structure which maps each keyword that you want to make searchable to a list of documents that it occurs in .", "label": "", "metadata": {}, "score": "66.69126"}
{"text": "D .T .T .S . i .S .TF .STD .IDF .ST .where : .H .SD .T .L .SD .N .STD .H .SO .N .", "label": "", "metadata": {}, "score": "66.79409"}
{"text": "The format of the data uses a labeled bracketing , the topics are a description in natural language of the information that the user needs , typically one sentence , and , finally , the relevance judgments are done by potential users , called experts or judges .", "label": "", "metadata": {}, "score": "66.85615"}
{"text": "Is there a reason you went with a tree - based approach rather than something more like clustering around centroids ?I 'm guessing it 's equal parts speed and the \" low startup threshold \" you mention , but it seems like the centroid - based approaches would more easily scale to other dimensions like demographic information about the recipients and dates of arrival .", "label": "", "metadata": {}, "score": "66.93047"}
{"text": "Table 1 shows the memory use of the methods on the two data sets .The Sada method exhibits a higher than expected memory usage because the protein collection has a high proportion of short documents .The .Page 10 .", "label": "", "metadata": {}, "score": "66.96591"}
{"text": "Mean Average Precision ( MAP ) .R -precision .R -precision ( R -prec ) is the precision after R documents have been retrieved , where R is the number of relevant documents for the topic .Methods and Results .", "label": "", "metadata": {}, "score": "67.487"}
{"text": "The organization of abstracts according to the relevance would greatly enhance the search experience of the user .Further , the thresholding technique would provide only relevant abstracts to the user .Statistical evaluation of SEGOPubmed using GO curated term associations .", "label": "", "metadata": {}, "score": "67.51427"}
{"text": "The other two abstracts extracted by SGP are PMID :9213309 and PMID : 9599668 which contain the word ' cell growth ' .The abstracts are relevance ranked in the order PMIDs : 8267680 , 9599668 , 11139434 , 15601852 and 9213309 .", "label": "", "metadata": {}, "score": "67.70592"}
{"text": "The method of .claim 39 wherein the comparing includes : . determining a log likelihood ratio between each of the identified documents and the document D. .The method of .claim 39 wherein the score is a total score based on scores for each of the identified documents .", "label": "", "metadata": {}, "score": "67.81326"}
{"text": "Space - efficient algorithms for document retrieval .In B. Ma and K. Zhang , editors , Proc . 18thCPM , LNCS 4580 , pp\u02d9205 - 215 , 2007 .I. Witten , A. Moffat , and T. Bell .Managing Gigabytes .", "label": "", "metadata": {}, "score": "67.81518"}
{"text": "7 illustrates the relationship of items of interest , categories and supercategories , when some categories have been assigned to supercategories , and others remain unassigned .While the number may vary without departing from the spirit and scope of the invention , in one embodiment there may be about 2,000 categories manually assigned to supercategories .", "label": "", "metadata": {}, "score": "67.819855"}
{"text": "Description .CROSS - REFERENCE TO RELATED APPLICATIONS .This patent application is a continuation - in - part of the following U.S. patent applications : \" Weighted Term Ranking for On - Line Query Tool \" , Ser .No .", "label": "", "metadata": {}, "score": "67.95845"}
{"text": "The categories presented may be chosen by any one of a number of techniques that will be familiar to one of ordinary skill in the art .In this embodiment of the system described herein , it is desired to present additional material to a user who is searching for items of interest .", "label": "", "metadata": {}, "score": "67.99914"}
{"text": "Although it has worked well as a heuristic , its theoretical foundations have been troublesome for at least three decades afterward , with many researchers trying to find information theoretic justifications for it .[5 ] .Sp\u00e4rck Jones 's own explanation did not propose much theory , aside from a connection to Zipf 's law .", "label": "", "metadata": {}, "score": "68.12744"}
{"text": "The Lemur toolkit used in our experiments implements the Rocchio formulation for pseudo relevance feedback .It first applies the standard retrieval model [ 1 , 2 ] to retrieve . is the parameter used to weight the importance of the retrieved documents .", "label": "", "metadata": {}, "score": "68.216705"}
{"text": "Landauer TK , Foltz PW , Laham D : An Introduction to Latent Semantic Analysis .Discourse Processes 1998 , 25 ( 2 - 3 ) : 259 - 284 .View Article .Salton G , McGill MJ : Introduction to modern information retrieval .", "label": "", "metadata": {}, "score": "68.37089"}
{"text": "Experimental results show that the proposed combinations of techniques greatly enhance the efficiency obtained by traditional queries .Introduction .Biomedical knowledge is growing at a high pace , and large collections of publications offer an excellent opportunity for discovering hidden biomedical knowledge by applying information retrieval ( IR ) and related technologies .", "label": "", "metadata": {}, "score": "68.61118"}
{"text": "THE The 18.0 .THE THE -0.0 .We do not print proximities this time ; they 're just the negations of the edit distances .Note that in these results , because the match score is 0.0 , identical strings are still at distance 0.0 .", "label": "", "metadata": {}, "score": "68.83468"}
{"text": "This is the approach taken by relevance feedback systems , where related terms come from the contents of user - identified relevant documents .This has been shown to be quite effective , but it requires that users indicate which documents are relevant .", "label": "", "metadata": {}, "score": "68.88179"}
{"text": "The categories presented may be chosen by any one of a number of techniques that will be familiar to one of ordinary skill in the art .It may be desirable present additional material to a user who is searching for items of interest .", "label": "", "metadata": {}, "score": "68.963486"}
{"text": "The system described herein may be utilized in one embodiment in connection with the assignment of categories consisting of items of interest into categories of categories , or supercategories .In this embodiment , an item of interest may be considered to be a merchant , store or other source for a product or service , or a number of ( related or unrelated ) products or services .", "label": "", "metadata": {}, "score": "68.97218"}
{"text": "For each collection , a total of 200 queries of character lengths ranging from 3 to 20 which appear at least 5 times in the collection were randomly generated , for a total of 3,600 sample queries .Each query was run 10 times .", "label": "", "metadata": {}, "score": "69.04323"}
{"text": "The device of . claim 43 wherein the means for comparing includes : . means for determining a log likelihood ratio between each of the identified documents and the document D. .The device of . claim 43 wherein the score is a total score based on scores for each of the identified documents .", "label": "", "metadata": {}, "score": "69.257904"}
{"text": "The GOPUBMED addresses the problem of refining the search results by introducing the concept of ontology based browsing .The ontology based browsing uses the domain knowledge and taxonomies to hierarchically organize the terms in the given corpus .User query is processed to retrieve relevant abstracts and structure based on the relevance provided by the ontology .", "label": "", "metadata": {}, "score": "69.29228"}
{"text": "The close examination of these abstracts reveals that ' pathogenesis ' does not occur as a single word in one of the abstracts ( PMID : 16113213 ) and the other abstract ( PMID : 11785977 ) semantically addresses the issues of ' pathogenesis ' .", "label": "", "metadata": {}, "score": "69.3026"}
{"text": "The machine only assumes that models with an F Score higher than 0.90 are accurate models .Once the Machine finds an accurate model , it does a Depth First Search of the tree and collects the demographic factors that produced each split .", "label": "", "metadata": {}, "score": "69.32042"}
{"text": "The device of . claim 21 , wherein the documents are Web sites .The device of . claim 21 , wherein the search query Q which is applied comprises all of the terms in document D. .The device of . claim 21 , wherein the search query Q which is applied comprises all of the terms in document D with preselected stop terms eliminated .", "label": "", "metadata": {}, "score": "69.5396"}
{"text": "Page 9 .Time per document listed as in Fig .2 , with 25th and 75th percentiles ( boxes ) , median ( solid line ) , and outliers ( whiskers ) .Peak memory use during search ( MB ) for the algorithms on wsj and protein .", "label": "", "metadata": {}, "score": "69.592255"}
{"text": "However , in many new search domains the requirement to choose terms prior to indexing is either not easily accomodated , or leads to unacceptable restrictions on queries .For example , several Far East languages are not easily parsed into words , and a user may adopt a different parsing as that used to create the index .", "label": "", "metadata": {}, "score": "69.687706"}
{"text": "In a further embodiment of the system described herein , it is desired to present further information to a user who has visited a Web site , when the Web site has permitted the user to enter terms describing an item of interest to the user .", "label": "", "metadata": {}, "score": "69.73718"}
{"text": "The information is sent to , or received from , a network or server in the form of packets of data .The World Wide Web portion of the Internet comprises a subset of interconnected Internet sites which may be characterized as including information in a format suitable for graphical display on a computer screen .", "label": "", "metadata": {}, "score": "69.80734"}
{"text": "In concrete terms , Cosine Similarity measures the angle between the two vectors formed by each document 's words ( technically , it is the angle between the two hyperplanes that the vectors represent ) .To calculate Cosine Similarity for two documents you take the dot product of each document 's word vector and divide that by the product of each vector 's magnitude .", "label": "", "metadata": {}, "score": "69.82699"}
{"text": "One consequence is that measuring the practical impact of new theoretical proposals is a difficult task , since older base- line implementations may not rely on the same basic components , and reimplementing from scratch can be very time - consuming .", "label": "", "metadata": {}, "score": "69.94915"}
{"text": "Weighted Edit Distance .Edit distance has been generalized in many different ways .In LingPipe , we 've considered simple weighted edit distance , where the cost of a substitution , insertion , deletion and transposition may vary and may depend on the actual characters being edited .", "label": "", "metadata": {}, "score": "69.95081"}
{"text": "The method of . claim 2 , wherein the number N 0 of documents chosen by application of the search query Q is predetermined .The method of .claim 12 , wherein the number N 0 is 50 .The method of . claim 2 , wherein all documents whose scores upon application of the search query Q exceed a given cutoff score are selected .", "label": "", "metadata": {}, "score": "70.05759"}
{"text": "FIG .8 , the process 2850 of assigning categories 2820 to supercategories in this embodiment of the system 2840 begins at a step 2860 in which an ( as - yet - unprocessed ) unassigned category C i is selected .", "label": "", "metadata": {}, "score": "70.12241"}
{"text": "Statistical properties for the 44,693 randomly generated English word queries from the wsj collection .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .", "label": "", "metadata": {}, "score": "70.22831"}
{"text": "Conclusions .We have developed and evaluated preprocessing and query expansion techniques for retrieving documents in several fields of biomedical articles belonging to the corpus Cystic Fibrosis , a corpus of MEDLINE documents .We test the benefit of using stemming and stopwords in the preprocessing of documents and queries , following the investigations of other authors .", "label": "", "metadata": {}, "score": "70.34089"}
{"text": "There are a variety of distance measures defined in terms of edit operations of various kinds .Damerau - Levenstein Distance .The simplest form of edit distances were introduced in the by Damerau ( 1964 ) and Levenshtein ( 1965 ) .", "label": "", "metadata": {}, "score": "70.400665"}
{"text": "Find the significant abstracts using the R - test ( see methods ) .Compare the retrieved abstracts with the ground truth .Calculate the true positive fraction and false positive fraction .Construct the ROC curve .The validation for both testing and training is done using three GO terms i ) ribosomal chaperone activity , ii ) transition metal ion transport and iii ) autophagic vacuole fusion in step 5 .", "label": "", "metadata": {}, "score": "70.42053"}
{"text": "Pages , in turn , may include links to other pages within the site , or to pages in other Web sites , facilitating the user 's rapid movement from one page or site to another .In view of the quantity of information and material available on computer networks such as the Web , and for other reasons as well , automated or semi - automated techniques for retrieving information that is thought to be relevant to a user at a given time may be employed .", "label": "", "metadata": {}, "score": "70.43212"}
{"text": "Information Retrieval focuses on finding documents whose content matches with a user query from a large document collection .As formulating well - designed queries is difficult for most users , it is necessary to use query expansion to retrieve relevant information .", "label": "", "metadata": {}, "score": "70.448715"}
{"text": "\" Our technique is to translate these top-$k$ problems into multidimensional geometric search problems .As an additional bonus , we describe some improvements to those problems .Study of Query Expansion Techniques and Their Application in the Biomedical Information Retrieval .", "label": "", "metadata": {}, "score": "70.47766"}
{"text": "Differing provisions from the publisher 's actual policy or licence agreement may be applicable . \"However , the IR indexes suffer from some drawbacks such as big size , search performance and security .Indexing plays very important role in databases performances and now the same concept can be used for developing secure databases[13,14,15].", "label": "", "metadata": {}, "score": "70.50372"}
{"text": "We 've been publishing our collection for a few months , and today we are publishing the latest results of our analysis .The Machine uses techniques from Natural Language Processing and Machine Learning to analyze every email our readers forward to it .", "label": "", "metadata": {}, "score": "70.53294"}
{"text": "The user then has the opportunity to select any of the categories presented , and to have displayed to him the list of merchants , stores or other sources associated with the category .The process then concludes , and a banner advertisement associated with the supercategory chosen at the step 2360 is displayed to the user .", "label": "", "metadata": {}, "score": "70.57242"}
{"text": "( 1 ) We implement , empirically validate and compare existing theoretical proposals for document listing search on general texts , and include a new variant of our own .( 2 ) We propose two novel algorithms for ranked document search using general query patterns .", "label": "", "metadata": {}, "score": "70.68567"}
{"text": "Fixed Weight Edit Distance .The simplest form of weighted edit distance simply sets a constant cost for each of the edit operations : match , substitute , insert , delete , transpose .The LingPipe class spell .FixedWeightEditDistance implements this approach .", "label": "", "metadata": {}, "score": "70.736305"}
{"text": "The best split is the one that will produce the highest information gain .The split routine is a binary split function that for categorical variables splits based on whether or not a row 's attribute equals the condition , and for continuous variables , whether or not the attribute is greater or equal to the condition .", "label": "", "metadata": {}, "score": "70.92214"}
{"text": "These series of associations may be downloaded and used as ground truth to evaluate the performance of SEGOPubmed .Empirical evaluation .The statistically evaluation of the performance of SEGOPubmed is performed using the ground truth constructed as described in the previous section .", "label": "", "metadata": {}, "score": "70.95998"}
{"text": "There are as many as 16 million ( and counting ) abstracts referenced by the PubMed as of 2006 [ 1 , 2 ] .Finding meaningful abstracts or papers from such a huge database is a great challenge .More than often the classical key - word based search engines yield results that are not meaningful to the query .", "label": "", "metadata": {}, "score": "71.041306"}
{"text": "317 - 323 , 2001 .View at Google Scholar \u00b7 View at Scopus .J. O. Ebbert , D. M. Dupras , and P. J. Erwin , \" Searching the medical literature using PubMed : a tutorial , \" Mayo Clinic Proceedings , vol .", "label": "", "metadata": {}, "score": "71.07225"}
{"text": "Bhanu Chander Vanteru carried out the following tasks i ) curated abstracts from PubMed repository , ii )Parsed the XML files , iii ) performed preprocessing steps such as stemming , stop word removal , iv ) constructed TF , IDF matrices .", "label": "", "metadata": {}, "score": "71.081535"}
{"text": "J. Zobel and A. Moffat .Inverted files for text search engines .ACM Computing Surveys , 38(2):1 - 56 , 2006 .In Proc . 4thACM Computing Filtered document retrieval with .Page 13 .A Basic IR Concepts Relevance Ranking .", "label": "", "metadata": {}, "score": "71.33983"}
{"text": "The search engine used by PubMed is the ' Entrez ' system [ 3 ] .The Entrez system performs the search operation in two steps .In the first step , the Entrez performs the query translation in which it identifies the existence of Medical Subject Headings ( MeSH ) terms in the query .", "label": "", "metadata": {}, "score": "71.41022"}
{"text": "137 - 166 , Springer , Berlin , Germany , 2004 .View at Google Scholar .M. F. Porter , \" An algorithm for suffx stripping , \" Program , vol .14 , no . 3 , pp .130 - 137 , 1980 .", "label": "", "metadata": {}, "score": "71.47208"}
{"text": "The user then may select a particular category from the list of categories displayed to him , and the items of interest ( merchants or stores ) in that category will be displayed for him .In this embodiment of the system described herein , it is desired to present additional material to a user who is searching for particular products or services , in addition to the list of categories which contain merchants or stores who may carry the desired product or service .", "label": "", "metadata": {}, "score": "71.476776"}
{"text": "Expert annotators assign MeSH Headings terms to the documents in order to allow the user to retrieve the information that explains the same concept with different terminology .On average , .Each MeSH Heading is related to several Entry terms .", "label": "", "metadata": {}, "score": "71.525085"}
{"text": "Well , decision trees give you a list of factors that contribute to the model , and honestly it was a lot simpler than running SVD or a Regression model , where it would be harder to single out how the factors interacted because they 'd be assigned scores .", "label": "", "metadata": {}, "score": "71.75514"}
{"text": "Alternatively , Krovetz Stemmer removes inflectional suffixes in three steps : the conversion of a plural to its single form , the conversion of past to present tense , and the removal of -ing .The process firstly removes the suffix and then , through a process of checking in a dictionary , returns the stem to a word [ 10 ] .", "label": "", "metadata": {}, "score": "71.86193"}
{"text": "References 1 . V. Anh and A. Moffat .Pruned query evaluation using pre - computed impacts .In Proc . 29thACM SIGIR , pp\u02d9372 - 379 , 2006 . A. Apostolico .The myriad virtues of subword trees .In Combinatorial Algorithms on Words , NATO ISI Series , pages 85 - 96 .", "label": "", "metadata": {}, "score": "71.87071"}
{"text": "The LSA technique is applied on the PubMed abstracts obtained based on the user query and the semantic similarity between the query and the abstracts .The analysis using well - referenced keywords show that the proposed semantic - sensitive technique outperformed the string comparison based techniques in associating the relevant abstracts to the GO terms .", "label": "", "metadata": {}, "score": "71.99997"}
{"text": "View Article PubMed .Thomas G , Lieth CWV : PubFinder : a tool for improving retrieval rate of relevant PubMed abstracts .Nucleic Acids Research 2005 , 33 : W774-W778 .View Article .Tanabe L , Scherf U , Smith LH , Lee JK , Hunter L , Weinstein JN : MedMiner : An Internet Text - Mining Tool for Biomedical Information , with Application to Gene Expression Profiling .", "label": "", "metadata": {}, "score": "72.033325"}
{"text": "K 3 and K 4 are constants .The device of .claim 27 , wherein K 1 equals 0.5 , K 2 equals 1.5 , K 3 equals 0.5 , and K 4 equals 1.0 .The device of .The device of . claim 21 , wherein the number N 0 of documents chosen by application of the search query Q is predetermined .", "label": "", "metadata": {}, "score": "72.07454"}
{"text": "Using query expansion ( QE ) techniques , a query is reformulated to improve retrieval performance and obtain additional relevant documents by expanding the original query with additional relevant terms and reweighting the terms in the expanded query .Query expansion techniques are widely used for improving the efficiency of textual information retrieval systems , helping to overcome vocabulary mismatch issues including words in queries with the same or related meaning .", "label": "", "metadata": {}, "score": "72.28401"}
{"text": "The bottleneck of this approach is that there is no option to refine the search results from the retrieved abstracts .The user has to manually skim through all the possible abstracts to find the relevant ones since they might be deeply buried inside the retrieved abstracts .", "label": "", "metadata": {}, "score": "72.35925"}
{"text": "M. Mitra , A. Singhal , and C. Buckley , \" Improving automatic query expansion , \" in Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , pp .206 - 214 , ACM Press , 1998 .", "label": "", "metadata": {}, "score": "72.51967"}
{"text": "Finally , we perform a study to improve searching expanding queries with MeSH terms .For this , we have enhanced queries locating Entry terms in them and obtaining MeSH Headings in PubMed in order to expand the original query and to map it with the documents .", "label": "", "metadata": {}, "score": "72.8194"}
{"text": "By setting up a character tokenizer factory ( tokenizer .CharacterTokenizer , the comparison will be at the character level rather than the token level ( and whitespace will be ignored ) .At the other extreme , a line tokenizer factory ( tokenizer .", "label": "", "metadata": {}, "score": "73.041824"}
{"text": "As such , we employed Zettair in three modes .Zettair was modified to ensure that all efficiency mea- surements were done in ram , just as the self - indexing methods require .Time to load posting lists into memory is not counted in the measurements .", "label": "", "metadata": {}, "score": "73.076645"}
{"text": "Berry MW : Large scale singular value computations .The International Journal of Supercomputer Applications 1992 , 6 ( 1 ) : 13 - 49 .Landauer TK , Foltz P , Laham D : An Introduction to Latent Semantic Analysis .", "label": "", "metadata": {}, "score": "73.12966"}
{"text": "Code Walk Through .The code is trivial .We simply use the distance constant in the Jaro - Winkler class , and then read in arguments to split and compare : .The command - line arguments are then provided as pairs of strings separated by a vertical bar , as in : .", "label": "", "metadata": {}, "score": "73.13566"}
{"text": "Background .The development of new technologies in the fields of bio - informatics , bio - engineering and functional genomics has lead to the vast amount of research .The advent of these new research fields has lead to an exponential growth of the literature .", "label": "", "metadata": {}, "score": "73.269"}
{"text": "However , Zet - io pre- orders the inverted lists to maximize efficiency , removing many of the standard calculations performed in Zet and Zet - ph .This makes Zet - io comparable with the computational cost of our new methods .", "label": "", "metadata": {}, "score": "73.281624"}
{"text": "Substitution Matrices : PAM and BLOSUM .For comparing sequences of proteins , biologically informed models represent how likely each of the 20 amino acids making up proteins are to be inserted , deleted , or substituted for one another .These likelihoods ( on a log scale ) form the basis of edit - distance based comparisons of sequences .", "label": "", "metadata": {}, "score": "73.4236"}
{"text": "Salton G : The smart document retrieval project .Proceedings of the 14th annual international ACM SIGIR conference on Research and development in information retrieval 1991 , 356 - 358 .Porter MF : An algorithm for suffix stripping .Electronic Library and Information Systems 2006 , 40 ( 3 ) : 211 - 218 .", "label": "", "metadata": {}, "score": "73.495384"}
{"text": "The rest of the code just iterates through the arguments and prints out distances and proximities like all the other demos .References .Damerau , Fred J. 1964 .A technique for computer detection and correction of spelling errors , Communications of the ACM 7 ( 3):171 - 176 .", "label": "", "metadata": {}, "score": "73.57244"}
{"text": "In practical terms the most popular variation is likely either the \" control \" version , or the one sent to folks the campaigns do not know much about .I decided to use decision trees in the Machine after speaking with Prof. David Karger at MIT .", "label": "", "metadata": {}, "score": "73.63275"}
{"text": "I played with adding time into the initial clustering , but it did n't seem to matter much .That makes perfect sense .I often find myself managing large masses of data , but do n't often have the opportunity to go through analysis , so it 's definitely interesting to see how people with the opportunity handle it .", "label": "", "metadata": {}, "score": "73.72168"}
{"text": "All distances are between zero ( 0 ) and one ( 1 ) .Proximity for Jaccard distance is defined as one minus the distance , so proximity also ranges between zero and one .To see why the distance is 0.35 for the last ( and closest ) example , consider the size of the set of words in both sentences divided by the total number of words in both : .", "label": "", "metadata": {}, "score": "73.776924"}
{"text": "the htne 17.0 .the thhe 8.0 .the the -0.0 .the then 8.0 .the The 9.0 .the THE 27.0 .then hte 19.0 .then htne 18.0 .then thhe 18.0 .then the 10.0 .then then -0.0 . then The 19.0 .", "label": "", "metadata": {}, "score": "74.02038"}
{"text": "In Proc . 13thSPIRE , pp\u02d9122 - 133 , 2006 .R. Raman , V. Raman , and S. Rao .Succinct indexable dictionaries with applica- tions to encoding k - ary trees and multisets .In Proc .SODA , pp\u02d9233 - 242 , 2002 .", "label": "", "metadata": {}, "score": "74.03974"}
{"text": "Simple Custom Weighted Edit Distance .We 've implemented a customized edit disance as a static nested class in src / WeightedEditDistanceDemo . java .Here 's the complete code for the weighted edit distance implementation : .Empirical Edit Distances .", "label": "", "metadata": {}, "score": "74.16754"}
{"text": "Note that case variation and space no longer matter .Note that any pair of spellings of \" the \" have distance zero , including \" the \" , \" The \" , \" THE \" , and \" T H E \" .", "label": "", "metadata": {}, "score": "74.333206"}
{"text": "Relevance scores can be 0 ( which indicates nonrelevance ) , 1 ( which indicates marginal relevance ) , and 2 ( which indicates high relevance ) .Table 2 : A sample of query with its relevant documents and relevance scores .", "label": "", "metadata": {}, "score": "74.377"}
{"text": "The relevance ranking for the word collagen is in the order PMIDs : 9284952 , 10647622 , 15601852 , 2725422 , 3936345 and 10983877 .The other query term used in this study is ' Rab 5 ' , which yielded 623 abstracts .", "label": "", "metadata": {}, "score": "74.46542"}
{"text": "In the simpler Levenshtein distance , the allowable edit operations are the deletion of a single character , the insertion of a single character and the substitutione of one character for another .In Damerau 's version , transposition is also an allowable edit .", "label": "", "metadata": {}, "score": "74.4785"}
{"text": "Computer networks have become increasingly important for the storage and retrieval of documents and other material .The Internet , of which the World Wide Web is a part , includes a series of interlinked computer networks and servers around the world .", "label": "", "metadata": {}, "score": "74.63664"}
{"text": "Each category further has associated with it a category identifier term which is unique to it , and serves to identify the category .In this embodiment of the system , it is desired to choose a banner advertisement to present to a user .", "label": "", "metadata": {}, "score": "74.83202"}
{"text": "In Proc . 14th SODA , pp\u02d9841 - 850 , 2003 .W.-K. Hon , R. Shah , and J. S. Vitter .Space - efficient framework for top - k string retrieval problems .In Proc .FOCS , pp\u02d9713 - 722 , 2009 . U.", "label": "", "metadata": {}, "score": "74.98375"}
{"text": "R. Baeza - Yates and B. Ribeiro - Neto .Modern Information Retrieval .Addison Wesley , 1999 .M. Bender and M. Farach - Colton .The LCA problem revisited .LATIN , LNCS 1776 , pp\u02d988 - 94 , 2000 .", "label": "", "metadata": {}, "score": "75.16425"}
{"text": "Results .The Empirical analysis is performed to compare the performance of the SEGOPubmed with the GOPubmed .The analysis is initially performed using a few well - referenced query words .Further , statistical analysis is performed using GO curated dataset as ground truth .", "label": "", "metadata": {}, "score": "75.32732"}
{"text": "The GO term ' pathogenesis ' is used to find abstracts that are semantically related to the keyword .The analysis using SGP resulted in 5 abstracts whose PMIDs are 16113213 , 15367862 , 15304337 , 1554866 , and 11785977 in the decreasing order of their relevance .", "label": "", "metadata": {}, "score": "75.33093"}
{"text": "The research issues addressed in GOPubmed [ 4 ] and GO - KDS [ 7 ] is closest to the work presented in this paper .The GOPubmed used the concept of ontology - based search into the PubMed [ 4 ] .", "label": "", "metadata": {}, "score": "75.342"}
{"text": "The construction of ground truth using GO is shown first .Construction of ground truth using GO .The GO is a consortium that aims to describe the genes and gene products of any organism by providing a controlled vocabulary .The GO extracts the genes / gene products by manually reading the PubMed abstracts and associates them with the vocabulary .", "label": "", "metadata": {}, "score": "75.40109"}
{"text": "Smith TC , Cleary JG : Automatically linking medline abstracts to the geneontology .Proc of Bio - Ontologies Meeting 2003 .Plake C , Schiemann T , Pankalla M , Hakenberg J , Leser U : ALIBABA : PubMed as a graph .", "label": "", "metadata": {}, "score": "75.49806"}
{"text": "For example , the abstract , PMID : 8267680 deals with the affect of alkaline phosphatase in drug resistant tumor cells .This study analyzes the affect of alkaline phosphatase on cell growth that semantically may be extracted using SEGOPubmed .The analysis using the SEGOPubmed extracted 5 abstracts that were rendered highly ranked to be semantically related to ' cell growth ' .", "label": "", "metadata": {}, "score": "75.653275"}
{"text": "The edit distance demo may be run through ant : using the edit - distance target : .The demo takes its command line arguments and returns the edit distances with ( Dist2 ) and without ( Dist1 ) transposition , and the proximities , with ( Prox2 ) and without ( Prox1 ) transposition .", "label": "", "metadata": {}, "score": "75.763275"}
{"text": "Ashburner M , Ball CA , Blake JA , Botstein D , Butler H , Cherry JM , Davis AP , Dolinski K , Dwight SS , Eppig JT : Gene Ontology : tool for the unification of biology .Nature Genetics 2000 , 25 : 25 - 29 .", "label": "", "metadata": {}, "score": "76.11961"}
{"text": "Because the splits may end up with rows that belong to many different email variations , this error estimate throws away decision rules - by converting a branch into a leaf - that were assigned to too many different email variations .", "label": "", "metadata": {}, "score": "76.155876"}
{"text": "For example , the keyword ' blood cancer ' retrieves abstracts that do not have any relevance with that keyword .The closer inspection reveals that all the abstracts in PubMed repository published in the journal ' blood cancer research ' are retrieved .", "label": "", "metadata": {}, "score": "76.265915"}
{"text": "I would have expected it to show some \" fine tuning \" or divergence / convergence in message , based on the campaign .In itself , that lack of a correlation strikes me as interesting .Gives a sense that maybe they 're not as sophisticated as they 're giving themselves credit for .", "label": "", "metadata": {}, "score": "76.47819"}
{"text": "T .D .i .I .j . ) k .K .W .D . k .I .j . )L .D .i .D . k . ) k .K .W .", "label": "", "metadata": {}, "score": "76.65744"}
{"text": "claim 39 wherein the assigning includes : . assigning a predetermined number of the index terms associated with the highest scores to the document D. .A device for automatically assigning an index term to a document D , the device comprising : . means for selecting one or more index terms from a plurality of index terms ; . means for identifying one or more documents of a plurality of documents to which each of the one or more index terms has been assigned ; . means for comparing , for each of the one or more index terms , each of the identified documents to the document D ; . means for determining a score for each of the one or more index terms based on the comparing ; and .", "label": "", "metadata": {}, "score": "76.68393"}
{"text": "1 Introduction Text search is a vital enabling technology in the information age .Web search engines such as Google allow users to find relevant information quickly and easily in a large corpus of text , T .Typically , a user provides a query as a list of words , and the information retrieval ( IR ) system returns a list of relevant documents from T , ranked by similarity .", "label": "", "metadata": {}, "score": "76.79509"}
{"text": "A pair of documents with a cosine similarity of one are identical , and a Cosine Similarity of zero would describe a pair of documents that have no words in common .Every email blast in the Machine has one or more variations .", "label": "", "metadata": {}, "score": "76.829926"}
{"text": "There are 6 abstracts retrieved by the SGP , 5 of which are also retrieved by the GOPUBMED .The abstract PMID : 3936345 relevance ranked # 5 by the SEGOPubmed is not retrieved by term matching techniques .This abstract talks about the inflammatory responses in the collagen - induced arthritis models .", "label": "", "metadata": {}, "score": "76.89154"}
{"text": "Weighted Edit Distance in LingPipe .Tsuruoka and Tsujii Distance .LingPipe provides a pre - specified weighted edit distance for comparing protein names , following the specification found in Tsuruoka and Tsujii ( 2003 ) .The implementation of T & T eidt distance is defined as a constant in the approximate dictionary chunker package , namely dict .", "label": "", "metadata": {}, "score": "77.03386"}
{"text": "The abstracts are next scanned to find the list of words , which are indicative of discrimination between the abstracts .These words are used to find the relevant abstracts from the PubMed .The MedMiner [ 10 ] is another related work in which the user is asked for list of gene names or processes .", "label": "", "metadata": {}, "score": "77.068825"}
{"text": "Conclusions .The LSA technique is applied on the PubMed abstracts obtained based on the user query and the semantic similarity between the query and the abstracts .The analyses using well - referenced keywords show that the proposed semantic - sensitive technique outperformed the string comparison based techniques in associating the relevant abstracts to the GO terms .", "label": "", "metadata": {}, "score": "77.412155"}
{"text": "View Article PubMed .Copyright .\u00a9 Vanteru et al ..This article is published under license to BioMed Central Ltd.About String Comparison .String comparison attempts to measure the similarity between strings .This is useful for applications ranging from database deduplication and record linkage to terminology extraction , spell checking , and k - nearest - neighbors classifiers .", "label": "", "metadata": {}, "score": "77.43041"}
{"text": "Porter Stemmer is a process for removing suffixes from words , such as gerunds and plurals , and replacing inflectional endings [ 9 ] .It is composed of rules , each of which deals with a specific suffix and has certain conditions to satisfy .", "label": "", "metadata": {}, "score": "77.56647"}
{"text": "trec queries occoccocc 17,204 10,446 6,071 4,086 2,312 2,000 1,523 2,177 114,379 48,123 23,660 9,355 4,320 6,365 2,035 3,390 919 230 664 879 761 649 523 Table 3 shows the statistical properties of the new phrase queries of varying word length , from 2 to 15 .", "label": "", "metadata": {}, "score": "77.68846"}
{"text": "Mohammed Yeasin carried out the following tasks : i ) defining the problem ( ii ) supervision of the whole work from inception to completion iii ) revised the manuscript and provided critical comments to improve the intellectual merit of the contribution .", "label": "", "metadata": {}, "score": "77.86733"}
{"text": "While the invention has been disclosed in connection with the preferred embodiments shown and described in detail , various modifications and improvements thereon will become readily apparent to those skilled in the art .Accordingly , the spirit and scope of the present invention is to be limited only by the following claims .", "label": "", "metadata": {}, "score": "78.02507"}
{"text": "According to .FIG .9 , all categories 2820 containing items of interest 2810 will have been assigned to supercategories 2840 , except for those categories 2820 as to which it has been determined that the category 2820 has no co - occurrences with any manually - assigned category 2820 .", "label": "", "metadata": {}, "score": "78.14813"}
{"text": "Stemming is the process of reducing related words to their stem , base or root form through affix removal .Its aim is to adapt different derivational or inflectional variants of the same word to a single indexing form [ 1 , 2 ] .", "label": "", "metadata": {}, "score": "78.234825"}
{"text": "A Web site may permit a user to obtain lists of relevant items of interest , such as Web sites , other documents or names of merchants carrying merchandise in particular categories .The site may be organized so that an item of interest may be considered to be in more than one category .", "label": "", "metadata": {}, "score": "78.26522"}
{"text": "BRIEF DESCRIPTION OF DRAWINGS .The above - mentioned and other features of the invention will now become apparent by reference to the following description taken in connection with the accompanying drawings in which : .FIG .1 is a schematic diagram of a computer system that may be operated according to the present invention .", "label": "", "metadata": {}, "score": "78.4477"}
{"text": "Even better the indexer could work incrementally and only examine files that have been modified(or created ) since the last indexing time .The other problem that has to be solved is picking a good scoring algorithm that will calculate a score for each keyword , for each document that it occurs in .", "label": "", "metadata": {}, "score": "78.45944"}
{"text": "While the number may vary without departing from the spirit and scope of the invention , there may be about 50 categories into which the banner advertisements may be divided .( To avoid confusion with the categories into which the items of interest are divided , these banner advertisement categories will be referred to hereafter as \" supercategories . \" )", "label": "", "metadata": {}, "score": "78.54747"}
{"text": "L33T - Speak Edits .It 's possible to produce a crude version of edit distance which places ordinary spellings and their L33t - speak variants close together .The basic rules of L33 t are that vowels can be deleted , or substituted with numerical look - alikes .", "label": "", "metadata": {}, "score": "78.718346"}
{"text": "The code for this demo is in src / JaccardDistanceDemo . java .It is almost trivial , and only varies from the other examples in terms of how the distance object is set up : .The JaccardDistance class implements both the distance and proximity interfaces , with proximity defined to be one minus the distance .", "label": "", "metadata": {}, "score": "78.73355"}
{"text": "The local area network 2004 , which is coupled to and exchanges data with the workstation , may also contain data and/or program information for use by the workstation 2002 .The Internet 2005 may be accessed in a conventional manner by the workstation 2002 .", "label": "", "metadata": {}, "score": "78.78175"}
{"text": "PubMed .Chen H , Sharp B : Content - rich biological network constructed by mining PubMed abstracts .BMC Bioinformatics 2004 , 5 ( 1 ) : 147 .View Article PubMed .Marcotte EM , Xenarios I , Eisenberg D : Mining literature for protein - protein interactions .", "label": "", "metadata": {}, "score": "78.85654"}
{"text": "View at Google Scholar \u00b7 View at Scopus .R. Apweiler , A. Bairoch , C. H. Wu et al . , \" UniProt : the universal protein knowledgebase , \" Nucleic Acids Research , vol .32 , pp .D115-D119 , 2004 .", "label": "", "metadata": {}, "score": "78.95072"}
{"text": "The weight for deleting alpha - numeric characters is -1 , and the weight for deleting all other characters is 0 .This includes space , punctuation , etc .The insertion weights are set to be equal to the deletion weights , so that insertion and deletion are symmetric .", "label": "", "metadata": {}, "score": "79.08405"}
{"text": "863 - 871 , 2005 .Z. Yang , H. Lin , Y. Li , B. Liu , and Y. Lu , \" Trec genomics track experiments at dutai , \" in Text REtrieval Conference , 2005 .T. Brants and Google Inc , \" Natural language processing in information retrieval , \" in Proceedings of the 14th Meeting of Computational Linguistics in the Netherlands , pp . 1 - 13 , 2004 . Y. Fan , X. Huang , and York University at TREC , \" Enterprise email discussion search , \" in Proceedings of the 15th Text Retrieval Conference ( TREC ' 06 ) , M. Ellen Voorhees and P. Lori Buckland , Eds . , vol .", "label": "", "metadata": {}, "score": "79.1071"}
{"text": "S. E. Robertson and S. Walker , \" Okapi / keenbow at trec-8 , \" 1999 . E. Greengrass , \" Information retrieval : a survey , \" Tech .Rep. tr - r52 - 008 - 001 , united States Department of Defense , 2001 .", "label": "", "metadata": {}, "score": "79.125626"}
{"text": "This extra bit of information is actually the most common predictor of which email a particular person will get , and makes our models much stronger .If you 'd like to see the Message Machine in action , and see how political campaigns are targeting you , please forward political emails you receive to emails@messagemachine.propublica.org .", "label": "", "metadata": {}, "score": "79.14127"}
{"text": "Subsequently , term matching is used to link the abstracts categorically into the GO terms .The process begins with the user submitting the query .The GOPUBMED links to the PubMed via the e - utilities provided by the Entrez System to retrieve the relevant abstracts .", "label": "", "metadata": {}, "score": "79.28018"}
{"text": "The \" distance \" from \" the \" to \" then \" is 8.0 , representing a single insertion , whereas the distance measured the other way is 10.0 .Code Walk Through .The code for this demo is in src / FixedEditDistanceDemo . java .", "label": "", "metadata": {}, "score": "79.365814"}
{"text": "In the case where the terms comprising documents and queries are fixed as words in the English language , Greedy is capable of processing 4600 queries per second , com- pared to the best inverted indexing method , Zet - io , which processes only 1400 on average .", "label": "", "metadata": {}, "score": "79.7758"}
{"text": "Code Walk Through .The code for the edit distance demo is trivial .First , we assign edit distances to constants , including edit distance with and without transpose , and proximity , with and without transpose : .The boolean argument to the constructor indicates whether transposition is considered an edit or not .", "label": "", "metadata": {}, "score": "79.853096"}
{"text": "Spell checking may be used for restoring case to uniform case data by employing weighted edit distance that charges no penalty for converting among case variants .Jaccard Distance .Another common method for comparing strings , which is actually much more efficient to implement , is the so - called \" Jaccard distance \" .", "label": "", "metadata": {}, "score": "79.88933"}
{"text": "\" GREEDY is also dependent on size of the [ sp . ep ] range , requiring two orders of magnitudes more time on ENWIKI - BIG than on ENWIKI - SML , matching the difference in their sizes .This is due to the faster extraction of inverse SA values and the use of a \u03a8 - based CSA instead of a WT based one .", "label": "", "metadata": {}, "score": "79.904236"}
{"text": "Similarity can also be specified in terms of proximity .If two strings are more similar , the proximity between them will be greater .It 's always possible to convert a proximity into a distance or vice - versa by either negation ( additive inverse ) or inversion ( multiplicative inverse ) .", "label": "", "metadata": {}, "score": "80.05925"}
{"text": "The banner advertisements in turn may be divided into categories 2840 .While the number may vary without departing from the spirit and scope of the invention , there may be about 50 categories 2840 into which the banner advertisements may be divided .", "label": "", "metadata": {}, "score": "80.53941"}
{"text": "J. Leveling and G. J. F. Jones , \" Sub - word indexing and blind relevance feedback for English , Bengali , Hindi , and Marathi IR , \" ACM Transactions on Asian Language Information Processing , vol .9 , no . 3 , article 12 , 2010 .", "label": "", "metadata": {}, "score": "80.550385"}
{"text": "More importantly , Decision Trees give easily parsable rules of the classification structure instead of lists of numbers like other Machine Learning classifiers .Incidentally , Karger is well known for the wonderful algorithm , Karger 's algorithm , that finds the minimum cut of a graph , and you should try to find some time to read up on it .", "label": "", "metadata": {}, "score": "80.60332"}
{"text": "The workstation may also be connected to a local area network 2004 and may access to the Internet 2005 .The Internet 2005 may include or be coupled to remote storage 2006 .The workstation 2002 may be any one of a variety of commercially available computers capable of providing the functionality described in more detail below .", "label": "", "metadata": {}, "score": "80.65224"}
{"text": "Affiliated with .Abstract .Background .The technological advances in the past decade have lead to massive progress in the field of biotechnology .The documentation of the progress made exists in the form of research articles .The PubMed is the current most used repository for bio - literature .", "label": "", "metadata": {}, "score": "80.698845"}
{"text": "In one embodiment , all terms in the N 0 documents are used .In another embodiment , all terms in the N 0 documents except certain common words , referred to as stop words , such as \" the \" or \" and , \" are used .", "label": "", "metadata": {}, "score": "80.78215"}
{"text": "View at Scopus . E. D. Liddy and S.-H. Myaeng , \" Tipster panel - dr - link 's linguistic - conceptual approach to document detection , \" in TREC , pp .113 - 130 , 1992 .View at Google Scholar .", "label": "", "metadata": {}, "score": "81.44847"}
{"text": "N - gram Comparisons .Jaro - Winkler Distance .There are a family of distance measures defined by the U.S. Census Bureau for comparing single person names .The original metric was defined by Matt Jaro and later refined by Bill Winkler .", "label": "", "metadata": {}, "score": "81.46452"}
{"text": "In response to the user providing terms related to the product(s ) or service(s ) which he is seeking ( such as , for example , \" automobiles , used \" ) , the Web site may display for the user a list of categories .", "label": "", "metadata": {}, "score": "81.49799"}
{"text": "The system may be accessed by the user through the Internet 2005 from his workstation 2002 using a Web browser of conventional design , as would be familiar to one of ordinary skill in the art .In the prior art , it is well known that information retrieval techniques may be utilized to identify documents , such as Web pages or sites , or portions of documents which may be of interest to a user .", "label": "", "metadata": {}, "score": "81.7584"}
{"text": "The PubMed is enquired using these keywords for extracting the abstracts .The retrieved abstracts are organized semantically using GO terms as tags .The word ' Levimisole Inhibitor ' retrieves abstracts related to the enzymes that inhibit the affect of the drug Levimisole .", "label": "", "metadata": {}, "score": "81.94743"}
{"text": "In Table 4 we can see that stemming is an effective technique to improve MAP .The performances are usually different between weak ( Krovetz ) and strong ( Porter ) stemming methods [ 12 , 31 , 32 ] , but in our case the results are similar .", "label": "", "metadata": {}, "score": "81.96869"}
{"text": "1 .The remote storage 2006 may also contain data and/or program information for the workstation 2002 or may contain other information , as will become apparent from the description below .The system described herein permits a user ( utilizing the computer system 2001 which includes the workstation 2002 ) who has accessed the Internet 2005 , either directly or through the local area network 2004 , to be given access to material that may be of interest to him .", "label": "", "metadata": {}, "score": "82.1161"}
{"text": "In this paper , three GO terms viz . 'cell growth ' , ' collagen ' , and ' pathogenesis ' are used to evaluate the performance of SEGOPubmed .The keyword ' cell growth ' is present in 2 out of 136 abstracts , which is evident from GOPUBMED .", "label": "", "metadata": {}, "score": "82.693306"}
{"text": "Clarence Swinney political historian Lifeaholics of America - burlington nc author - Lifeaholic - Success by working for a Life not just a Living .It 's the q&a forum for machine learning related topics , including information retrieval .And it 's just a hunch but if your vectors are defined over the entire vocabulary , and elements corresponding to words that do n't appear in the document are given a value of zero , then I do n't see why you 'd have trouble doing cosine . -", "label": "", "metadata": {}, "score": "82.73729"}
{"text": "The sequence of edits must be minimal , but need not be unique .Further note that \" Bret \" can be converted to \" Brett \" with a single insertion of a ' t ' character .The distance between \" Bob \" and \" bob \" is also 1 , as it requires the substitution of a lowercase ' b ' for its uppercase equivalent ' B ' .", "label": "", "metadata": {}, "score": "83.21112"}
{"text": "The extraction of the relevant abstracts based on string matching can not capture the underlying semantics .If the abstracts were to be retrieved only on the basis of keywords , their synonyms are not used in the search process .For example , Leukemia , blood cancer and bone marrow cancer are synonymous terms .", "label": "", "metadata": {}, "score": "83.45773"}
{"text": "Results .Analysis using well referenced keywords .This section presents the performance analysis of SEGOPubmed .To assess the performance of the proposed method , the comparison of the SEGOPubmed is made with the earlier proposed methods for ontology based literature search , namely GOPubmed .", "label": "", "metadata": {}, "score": "83.59233"}
{"text": "Chinese Word Segmentation .The Chinese word segmenter is an application of spell checking , using a custom weighted edit distance in which the only allowable edit is the insertion of a space ( between tokens ) .See the chinese tokenization tutorial for more information on the role of weighted edit distance .", "label": "", "metadata": {}, "score": "83.914246"}
{"text": "Hence , this procedure suffers severe scaling problems .The other related works include ( but not limited to ) , ALIBABA [ 8 ] which represents the relations among cells , diseases , drugs , proteins , species and tissues as a inter - connected graph extracted from PubMed .", "label": "", "metadata": {}, "score": "84.25246"}
{"text": "htne the 17.0 .htne then 18.0 .htne The 26.0 . htne THE 35.0 . thhe hte 17.0 . thhe htne 18.0 . thhe thhe -0.0 . thhe the 10.0 . thhe then 18.0 . thhe The 17.0 . thhe THE 35.0 .", "label": "", "metadata": {}, "score": "84.576256"}
{"text": "For example , here is a representation of the Decision Tree model generated for a single Obama for America message : .The decision tree algorithm is a very simple tree - building algorithm , in pseudocode : .The formula the Machine uses to decide the best split is a straight entropy calculation : .", "label": "", "metadata": {}, "score": "84.83686"}
{"text": "This article has been published as part of BMC Genomics Volume 9 Supplement 1 , 2008 : The 2007 International Conference on Bioinformatics & Computational Biology ( BIOCOMP'07 ) .Competing interests .The authors declare that they have no competing interests .", "label": "", "metadata": {}, "score": "85.27963"}
{"text": "Software Testing and Excellence Program , University Of Memphis University of Memphis .References .McEntyre J , Lipman D : PubMed : bridging the information gap .Canadian Medical Association Journal 2001 , 164 ( 9 ) : 1317 - 1319 .", "label": "", "metadata": {}, "score": "85.62381"}
{"text": "Proximity is Inverse Distance .For simple edit distance , proximities are defined by additively inverting distances with negation : .Alternative Proximity from Edit Distance .It also makes sense to define proximity as the multiplicative inverse distance instead of the additive inverse : .", "label": "", "metadata": {}, "score": "85.8985"}
{"text": "Because the term \" the \" is so common , term freqency will tend to incorrectly emphasize documents which happen to use the word \" the \" more frequently , without giving enough weight to the more meaningful terms \" brown \" and \" cow \" .", "label": "", "metadata": {}, "score": "86.038315"}
{"text": "The edit distance between strings is only zero if the strings are identical .The distance between \" Brett \" and \" Brent \" is one ( 1 ) , because it requires a substitution of an ' n ' for a ' t ' .", "label": "", "metadata": {}, "score": "86.44026"}
{"text": "When the GOPUBMED is searched with the keyword Alzheimer ' , the results are displayed categorically based on the relevant keywords ' brain development'/ ' cell ' etc . from the GO .It does not however take into account the two main problems viz i ) Semantics and ii ) Relevance ranking .", "label": "", "metadata": {}, "score": "86.961945"}
{"text": "The demo may be invoked from the ant target fixed - edit - distance : . hte htne 8.0 .hte thhe 17.0 .hte the 9.0 .hte then 17.0 .hte The 18.0 .hte THE 27.0 .htne hte 10.0 .", "label": "", "metadata": {}, "score": "87.6798"}
{"text": "The State - of - the - art technologies such as GOPubmed use simple keyword - based techniques for retrieving abstracts from the PubMed and linking them to the Gene Ontology ( GO ) .This paper changes the paradigm by introducing semantics enabled technique to link the PubMed to the Gene Ontology , called , SEGOPubmed for ontology - based browsing .", "label": "", "metadata": {}, "score": "88.148056"}
{"text": "JaccardDistance operates at a token level , comparing two strings by first tokenizing them and then dividing the number of tokens shared by the strings by the total number of tokens .Running the Demo .The demo may be run using the jaccard target in ant : .", "label": "", "metadata": {}, "score": "88.18269"}
{"text": "These thesauri can then be used for automatic or manual query expansion .( c ) Language - specific terms may be found from generally available online thesauri that are not tailored for any particular text collection .Liddy and Myaeng [ 21 ] use the Longman 's Dictionary of Contemporary English , a semantically coded dictionary .", "label": "", "metadata": {}, "score": "88.715805"}
{"text": "If we compare different stopword removal methods , we can see that removing stopwords improves the performance .From our experiments , using the largest stopword list ( SMART ) results is better than using the list with fewer stopwords .The Porter stemmer with SMART stopword list provides the best results .", "label": "", "metadata": {}, "score": "88.87892"}
{"text": "No one I asked ever said under 50 % .It is 27 % .In Fiscal 2012 federal tax revenue was 2450Billion .We borrowed 1100 Billion .Our national income is 14,000 Billion .2450 is a Tax Rate of 17.6 % .", "label": "", "metadata": {}, "score": "89.15055"}
{"text": "Many Obama for America emails contain a \" quick donate \" box that asks for more money when a particular constituent has saves his credit card information .If an email has that box we assume the user is a previous donor .", "label": "", "metadata": {}, "score": "89.17561"}
{"text": "( For example , in one embodiment the category \" Auto Dealers , Used Cars \" may be assigned to a supercategory also comprising other categories related to automobiles , such as \" Automobile Dealers \" and/or \" Auto Repair & Service . \" )", "label": "", "metadata": {}, "score": "89.18352"}
{"text": "I 've never seen anybody attack it from the similarity standpoint , and that focuses the idea a lot better , I think .( I 'm also completely ashamed to say that I had to invent something a lot like TF - IDF for a toy project at the day job .", "label": "", "metadata": {}, "score": "89.57254"}
{"text": "This paper presents the concept of Semantics Enabled linking of GO with PubMed , called , SEGOPubmed to address the aforementioned problems .The SEGOPubmed adapts the concept of latent semantic analysis ( LSA ) [ 13 ] for linking the PubMed abstracts to the Gene Ontology .", "label": "", "metadata": {}, "score": "89.685425"}
{"text": "ProPublica has been collecting political emails for a project we call the Message Machine , with the help of more than 600 readers who have shared demographic information with us and who have so far forwarded us more than 30,000 political emails .", "label": "", "metadata": {}, "score": "90.277176"}
{"text": "The demo is run like all the others , with inputs specified as command - line arguments and outputs computing all pairwise distances .Comparing Dialects with Edit Distance .Nerbonne et al . 's ( 1999 ) Edit distance and dialect proximity provides an example of the use of edit distance to compare dialects .", "label": "", "metadata": {}, "score": "91.60985"}
{"text": "The hte 16.0 .The htne 24.0 .The thhe 17.0 .The the 9.0 .The then 17.0 .The The -0.0 .The THE 18.0 .THE hte 27.0 .THE htne 35.0 .THE thhe 35.0 .THE the 27.0 .", "label": "", "metadata": {}, "score": "91.92558"}
{"text": "JaroWinklerDistance , as well as in Winkler 's ( 2006 ) survey paper .Running the Demo .The demo may be run from the ant target jaro - winkler : .The demo compares a sequence of name pairs , printing out distance and proximity information .", "label": "", "metadata": {}, "score": "92.506676"}
{"text": "The underlying processes and techniques have not been clearly understood from this paper [ 10 ] .A natural language processing ( NLP ) based approach to find the relations among the genes , proteins and drugs is incorporated into an online application called Chilibot [ 11 ] .", "label": "", "metadata": {}, "score": "93.5925"}
{"text": "Binary codes capable of correcting deletions , insertions , and reversals .Soviet Physics Doklady .", "label": "", "metadata": {}, "score": "95.86989"}
{"text": "Asymmetric \" Distance \" .Although the standard mathematical definition of distance ( see the previous sidebar ) requires symmetry , the real - world notion is rather more flexible .If by distance , we mean flight time , then flying from New York to London is shorter than the other way around because of the jet stream .", "label": "", "metadata": {}, "score": "96.39092"}
{"text": "Unfortunately , truly capturing l33t - speak requires multiple substitutions , and sensitivity to sound .Peripheral vowels tend to get dropped .Because the ' i ' in \" elite \" is pronounced like \" ee \" in American English , the word becomes \" 3l33 t \" , but because it 's fun to drop vowels , this reduces to just plain \" l33 t \" .", "label": "", "metadata": {}, "score": "97.013336"}
{"text": "Suppose we have a set of English text documents and wish to determine which document is most relevant to the query \" the brown cow \" .A simple way to start out is by eliminating documents that do not contain all three words \" the \" , \" brown \" , and \" cow \" , but this still leaves many documents .", "label": "", "metadata": {}, "score": "102.68079"}
{"text": "In this embodiment , items of interest ( merchants or stores , such as , for example , \" Lannan Chevrolet , Oldsmobile \" ) may be assigned to more than one category ( variety of product or service ) .In this embodiment , it is desired to present categories to a user in response to his request .", "label": "", "metadata": {}, "score": "105.97263"}
{"text": "They pay most of individual income tax but little of income in payroll tax .The big question is how much of Total Income do they pay not the Adjusted Gross Income which has their deductions .Mitt Romney is proposing a 20 % tax cut which means more borrowing like Bush who gave top 5 % 48 % of his tax cuts and borrowed 6100 Billion(5800 on 9 - 30 - 1 to 11.900 on 9 - 30 - 09 ) or doubled our debt in 8 years .", "label": "", "metadata": {}, "score": "109.253685"}
{"text": "Received 31 August 2013 ; Accepted 15 December 2013 ; Published 2 March 2014 .Academic Editors : G. Lu and J. Tang .Copyright \u00a9 2014 A. R. Rivas et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "109.30497"}
