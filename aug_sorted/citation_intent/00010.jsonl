{"text": "The authors conducted an experiment using RekEmoZio Database , classifier are Instance - Based Learning ( IB ) , Decision Tree ( ID3 , C4.5 ) , Naive Bayes ( NB ) and Naive Bayesian Tree learner ( NBT ) .Experiments were carried out with and without FSS in order to compare the difference classification rates by feature selection process .", "label": "", "metadata": {}, "score": "27.749975"}
{"text": "In this paper , we reported a machine learning approach for biomedical WSD .The approach was evaluated with a benchmark dataset , NLM - WSD , to facilitate the comparison with the results of previous work .The average accuracy results of our method , compared to some recent reported results ( Table 6 ) , are promising and proving that our method outperforms those recently reported methods .", "label": "", "metadata": {}, "score": "28.433517"}
{"text": "Agirre et al .proposed a graph - based WSD technique which is considered unsupervised but relies on UMLS [ 2 ] .The concepts of UMLS are represented as a graph , and WSD is done using personalized page rank algorithm [ 2 ] .", "label": "", "metadata": {}, "score": "29.697237"}
{"text": "In this work , we extended the previous research to uncover relationships between CFS and SNPs and compared a variety of machine learning techniques including naive Bayes , the SVM algorithm , and the C4.5 decision tree algorithm .Furthermore , we employed feature selection methods to identify a subset of SNPs that have predictive power in distinguishing CFS patients from controls .", "label": "", "metadata": {}, "score": "30.131025"}
{"text": "We did not compare the substitution method with other methods for WSD .In addition , we used an SVM classifier for all the experiments .Since the goals of our study did not include the comparison of different algorithms , we do not present related results here .", "label": "", "metadata": {}, "score": "30.838377"}
{"text": "[ 6 ] proposed a Semi - Supervised Learning ( SSL ) algorithm for heterogeneous datasets having both labeled and unlabeled samples .Their example data were comprised of DNA microarray expressions and phylogenic reconstructions , with class labels corresponding to gene function .", "label": "", "metadata": {}, "score": "30.899914"}
{"text": "Finally , we employed naive Bayes , SVM , and C4.5 decision tree with the wrapper - based feature selection approach , respectively .Table 5 demonstrates the result of a repeated 10-fold cross - validation experiment for the six predictive algorithms with the wrapper - based approach .", "label": "", "metadata": {}, "score": "31.49516"}
{"text": "Methods .We employed the dataset that was original to the previous study by the CDC Chronic Fatigue Syndrome Research Group .To uncover relationships between CFS and SNPs , we applied three classification algorithms including naive Bayes , the support vector machine algorithm , and the C4.5 decision tree algorithm .", "label": "", "metadata": {}, "score": "31.62648"}
{"text": "Next , we applied the naive Bayes , SVM , and C4.5 decision tree classifiers , respectively , with the hybrid feature selection approach that combines the chi - squared and information - gain methods .Table 4 shows the result of a repeated 10-fold cross - validation experiment for the six predictive algorithms with the hybrid approach .", "label": "", "metadata": {}, "score": "31.696747"}
{"text": "The authors use three dataset ( 400 , 528 , 2096 features ) .Naive Bayes classifier and the Support Vector Machine are used in experiments as classification methods ( as Wrapper approach ) .Compare EDA - R feature ranking to two other selection strategies , sequential backward elimination ( SBE ) and an advanced filter method described by [ Koller and Sahami , 1996 ] ( KS ) .", "label": "", "metadata": {}, "score": "31.924511"}
{"text": "Specifically , we systematically evaluated Naive Bayes and Logistic Regression classifiers , as well as mixtures of Naive Bayes and Logistic Regression in a sequence - based 10-fold cross - validation setup .The results of our experiments show that global sequence similarity through the means of the mixture of experts approach can be exploited to improve the performance of classifiers trained to label biomolecular sequence data .", "label": "", "metadata": {}, "score": "32.046146"}
{"text": "5 iterations of a 2 fold cross validation were applied .Experiments were run in a SUN SPARC machine The MLC++ software was used to execute Naive Bayes and ID3 algorithms .The authors claim \" In the majority of real datasets , the accuracy maintenances with considerable dimensionality reductions are achieved for ID3 , in the case of NB the dimensionality reduction is normally coupled with notable accuracy improvements \" .", "label": "", "metadata": {}, "score": "32.899265"}
{"text": "Here , we examined these issues in the context of word sense disambiguation .The methodology we used to quantify the impact of various factors on the error rate , and hence on the performance of the WSD classifier , is a well - known , theory - based , statistical methodology .", "label": "", "metadata": {}, "score": "33.496674"}
{"text": "The remainder of this paper is organized as follows .Section 2 reviews the existing Bayesian network classifiers .We describe our algorithm and its theoretical proofs in Section 3 .Section 4 details the experimental procedures and results of the proposed algorithm .", "label": "", "metadata": {}, "score": "34.189404"}
{"text": "In a demonstration of their technique aimed at web page classification , the addition of unlabeled samples decreased classification error relative to classification using only labeled data .In a subsequent study , Nigam and Ghani [ 5 ] further examined the performance of the co - training algorithm and specifically its sensitivity to the independence of the feature sets .", "label": "", "metadata": {}, "score": "34.59877"}
{"text": "We tested two statistical pattern recognition algorithms , Na\u00edve Bayes and Support Vector Machines ( SVMs ) , as meta - classifiers .Since the meta - data are highly imbalanced , we created a balanced dataset by under - sampling as described previously [ 19 ] and compared the performance of Na\u00efve Bayes and SVM classifiers trained with both datasets ( Table 1 ) .", "label": "", "metadata": {}, "score": "34.630947"}
{"text": "It is equivalent to learning the best Bayesian network among those in which .Based on above analysis , this paper presents an optimization model to learn the structure of Bayesian classifier , which inspired by constraint - based Bayesian network structure learning method .", "label": "", "metadata": {}, "score": "34.703793"}
{"text": "Despite their naive design and apparently oversimplified assumptions , naive Bayes classifiers have worked quite well in many complex real - world situations .In 2004 , an analysis of the Bayesian classification problem showed that there are sound theoretical reasons for the apparently implausible efficacy of naive Bayes classifiers .", "label": "", "metadata": {}, "score": "34.78543"}
{"text": "5 ] Still , a comprehensive comparison with other classification algorithms in 2006 showed that Bayes classification is outperformed by other approaches , such as boosted trees or random forests .[ 6 ] .An advantage of naive Bayes is that it only requires a small amount of training data to estimate the parameters necessary for classification .", "label": "", "metadata": {}, "score": "36.02462"}
{"text": "The analysis of the results was performed using statistical methodology including nonparametric tests followed by post - hoc procedures designed especially for multiple 1\u00d7N and N\u00d7N comparisons .Affiliated with .Abstract .Background .Automated techniques have been developed that address the WSD problem for a number of text processing situations , but the problem is still a challenging one .", "label": "", "metadata": {}, "score": "36.131344"}
{"text": "Paccanaro A , Casbon JA , Saqi MAS : Spectral clustering of protein sequences .Nucleic Acids Research 2006 , 34(5):1571 - 1580 .Mitchell TM : Machine Learning McGraw Hill ; 1997 .Ng AY , Jordan MI : On discriminative vs. generative classifiers : A comparison of logistic regression and naive Bayes .", "label": "", "metadata": {}, "score": "36.3239"}
{"text": "In this manner , the overall classifier can be robust enough to ignore serious deficiencies in its underlying naive probability model .[ 3 ] Other reasons for the observed success of the naive Bayes classifier are discussed in the literature cited below .", "label": "", "metadata": {}, "score": "36.604538"}
{"text": "The highest F - measure for a meta - classifier ( 0.3335 ) was obtained from the Na\u00efve Bayes meta - classifier using the unbalanced dataset .Thus , the meta - classifier trained with the Na\u00efve Bayes algorithm using the unbalanced dataset provides superior results over any single classifier and was used for further experiments .", "label": "", "metadata": {}, "score": "36.657963"}
{"text": "Naive Bayes classifier is a simple and effective classification method , but its attribute independence assumption makes it unable to express the dependence among attributes and affects its classification performance .In this paper , we summarize the existing improved algorithms and propose a Bayesian classifier learning algorithm based on optimization model ( BC - OM ) .", "label": "", "metadata": {}, "score": "36.89189"}
{"text": "These three methods are supervised methods and used various machine learning algorithm and wide sets of features .For example , Stevenson-2008 used linguistic features , CUI 's , MeSH terms , and combination of these features .They employed three learners VSM ( vector space model ) , Na\u00efve Bayes ( NB ) , and SVM .", "label": "", "metadata": {}, "score": "37.01806"}
{"text": "The authors begin by referring to the work of [ Inza et al . , 2000 ] and indicate that their paper is an improvement on the method of FSS - ENBA .The authors claim that the evolution control and surrogate approach can be used to reduce the computational cost by integrating approximate model by using the past evaluation knowledge in some cases .", "label": "", "metadata": {}, "score": "37.558937"}
{"text": "During learning , we train either a collection of M Na\u00efve Bayes classifiers or a collection of M Logistic Regres- be the leaf nodes and be sion classifiers , one classifier at each leaf node 1 , ? , M. Na\u00efve Bayes and Logistic Regression are briefly described in the next section .", "label": "", "metadata": {}, "score": "38.421516"}
{"text": "Since naive Bayes is also a linear model for the two \" discrete \" event models , it can be reparametrised as a linear function .Obtaining the probabilities is then a matter of applying the logistic function to , or in the multiclass case , the softmax function .", "label": "", "metadata": {}, "score": "38.61682"}
{"text": "where is the probability of class generating the term .This event model is especially popular for classifying short texts .It has the benefit of explicitly modelling the absence of terms .Note that a naive Bayes classifier with a Bernoulli event model is not the same as a multinomial NB classifier with frequency counts truncated to one .", "label": "", "metadata": {}, "score": "38.947594"}
{"text": "In this study , we employed the hybrid feature selection and wrapper - based feature selection approaches to find a subset of SNPs that maximizes the performance of the prediction model , depending on how these methods incorporate the feature selection search with the classification algorithms .", "label": "", "metadata": {}, "score": "38.993057"}
{"text": "In [ 1 ] , Stevenson et al .use supervised learners with linguistic features extracted from the context of the word in combination with MeSH terms for disambiguation .The UMLS has been used , by Humphrey et al . , as a knowledge source for assigning the correct sense for a given word [ 13 ] .", "label": "", "metadata": {}, "score": "39.10177"}
{"text": "The performance of all models was evaluated both with and without feature selection , using repeated 10-fold cross - validation testing .Results .Tables 3 , 4 and 5 summarize the results of repeated 10-fold cross - validation experiments by naive Bayes , SVM ( with four kernels including linear , polynomial , sigmoid , and Gaussian radial basis function ) , and C4.5 decision tree using SNPs with and without feature selection .", "label": "", "metadata": {}, "score": "39.178436"}
{"text": "In this paper , we aimed to further an understanding of the different factors affecting the performance of ML techniques for WSD by systematically simulating a variety of situations where different sample size , sense distribution , degree of difficulty , and cross validation methods were used .", "label": "", "metadata": {}, "score": "39.22882"}
{"text": "Hence , instead of using a \" hard \" partitioning of the data , the authors use a \" soft \" partitioning , i.e. , the data is allowed to simultaneously lie in more than one region .The HME has a tree - structured architecture that is known a priori .", "label": "", "metadata": {}, "score": "39.369377"}
{"text": "The authors introduce a \" Fast estimation of Distribution Algorithm \" ( FEDA ) .It use Bayesian Networks to estimate the probability distribution of each generation and extended as approximate models to assign approximate fitness value .The main idea is the high possible solutions have more chances to be evaluated by actual fitness function and FEDA rejects repeat evaluate some useless individuals .", "label": "", "metadata": {}, "score": "39.520134"}
{"text": "Clustering techniques [ 2 ] are applied to the datasets for assigning samples to their corresponding group solely based on similar expression levels .Supervised algorithms on the other hand classify [ 3 ] samples according to their externally determined class .None of the standard supervised and unsupervised techniques are appropriate for datasets with some unlabeled samples ; Semi - supervised algorithms can address these situations .", "label": "", "metadata": {}, "score": "39.832085"}
{"text": "Because there are three genotypes per locus , each SNP was coded as 0 for homozygote of the major allele , 1 for heterozygote , and 2 for homozygote of the minor allele , respectively .Classification algorithms .In this study , we used three families of classification algorithms , including naive Bayes , SVM , and C4.5 decision tree , as a basis for comparisons .", "label": "", "metadata": {}, "score": "40.059273"}
{"text": "In this paper , the authors present a simple EDA as wrapper for feature subset selection for splice site prediction .In this case , the authors compare using greed search with heuristic search using a sample EDA ( UMDA , [ M\u00fchlenbein , 1998 ] ) approach .", "label": "", "metadata": {}, "score": "40.15892"}
{"text": "In another work , Jimeno - Yepes and Aronson evaluate four unsupervised methods on the whole NLM - WSD set [ 4 ] as well as NB and combination of the four methods .The accuracy of the four methods ranges from 58.3 % to 88.3 % ( NB ) on the whole set , and NB was found to be the best performer followed by CombSW ( 76.3 % ) [ 4 ] .", "label": "", "metadata": {}, "score": "40.413723"}
{"text": "Blum and Mitchell [ 4 ] introduced the co - training algorithm for improving the sample classification performance when there are few labeled samples and many unlabeled samples .The co - training algorithm assumes that there are two independent sets of features available , such that each feature set is good enough to train a good classifier .", "label": "", "metadata": {}, "score": "40.827656"}
{"text": "For example , we studied 42 candidate SNPs , and these 42 SNPs yield 2 42 possible models .The three classifiers were chosen for comparison because they cover a variety of techniques with different representational models , such as probabilistic models for naive Bayes , regression models for SVM , and decision tree models for the C4.5 algorithm [ 32 ] .", "label": "", "metadata": {}, "score": "40.878437"}
{"text": "In Proceedings of AAAI-96 workshop on Integrating Multiple Learned Models .Edited by : Chan PK .Menlo Park , CA : AAAI Press ; 1996:40 - 46 .Chan PK , Stolfo SJ : Experiments in multistrategy learning by meta - Learning .", "label": "", "metadata": {}, "score": "40.97892"}
{"text": "The experiments used the C++ implementations of the ecGA and BOA that are distributed by their authors on the web .The sGA and Naive Bayes were coded by C++ .Complier is g++ 2.96 using -O2 optimizations .The experiments were executed on a single processor with dual 1.5 GHz Intel Xeon processors and 512 Mb of memory .", "label": "", "metadata": {}, "score": "41.246613"}
{"text": "Our approach combines unsupervised and supervised learning techniques .Given a set of sequences and a similarity measure defined on pairs of sequences , we learn a mixture of experts model by using spectral clustering to learn the hierarchical structure of the model and by using bayesian techniques to combine the predictions of the experts .", "label": "", "metadata": {}, "score": "41.63936"}
{"text": "Given a collection of labeled samples L and unlabeled samples U , start by training a naive Bayes classifier on L .Until convergence , do : .Predict class probabilities for all examples x in .Re- train the model based on the probabilities ( not the labels ) predicted in the previous step .", "label": "", "metadata": {}, "score": "41.694885"}
{"text": "In this study we introduce GLAD , a new Semi - Supervised Learning ( SSL ) method for combining independent annotated datasets and unannotated datasets with the aim of identifying more robust sample classifiers .In our method , independent models are developed using subsets of genes for the annotated and unannotated datasets .", "label": "", "metadata": {}, "score": "41.747368"}
{"text": "First , naive Bayes is the simplest form of Bayesian network , in which all features are assumed to be conditionally independent [ 20 ] .Let ( X 1 , ... , X p ) be features ( that is , SNPs ) used to predict class C ( that is , disease status , \" CFS \" or \" control \" ) .", "label": "", "metadata": {}, "score": "41.903748"}
{"text": "In this paper , we also demonstrated that ambiguity of biomedical entities is a significant problem , which has a substantial impact on text mining and retrieval tasks in the biomedical domain .ML methods are still needed for WSD , which is critical for increasing the accuracy of biomedical natural language , text mining , and information retrieval systems .", "label": "", "metadata": {}, "score": "42.08141"}
{"text": "Naive Bayes ( NB ) [ 9 - 11 ] is a simple and effective classification model .Although its performance can be comparable with other classification methods , such as decision trees and neural network , its attribute of independence assumption limits its real application .", "label": "", "metadata": {}, "score": "42.305286"}
{"text": "It is clear that TAN and BAN are useful to model correlations among attribute nodes that can not be captured by naive Bayes .They embody a good tradeoff between the equality of the approximation of correlations among attributes and the computational complexity in the learning stage .", "label": "", "metadata": {}, "score": "42.317398"}
{"text": "In this paper we propose the Genetic Learning Across Datasets concept ( GLAD ) , and demonstrate an implementation that enables feature selection across unlabeled and labeled datasets .GLAD algorithms are distinct from previous approaches of semi - supervised learning in that the datasets analyzed may have very different statistical distributions , such as would arise in datasets collected independently by labs using different measurement technology .", "label": "", "metadata": {}, "score": "42.326626"}
{"text": "5 , pp .563 - 569 , 2011 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Jiang , Z. Cai , D. Wang , and H. Zhang , \" Improving tree augmented naive Bayes for class probability estimation , \" Knowledge - Based Systems , vol .", "label": "", "metadata": {}, "score": "42.45275"}
{"text": "Our approach in this paper is a supervised approach .In this paper , we present and evaluate a supervised method for biomedical word sense disambiguation .The method is based on machine learning and uses some feature selection techniques in constructing feature vectors for the words to be disambiguated .", "label": "", "metadata": {}, "score": "42.522522"}
{"text": "For testing the classification accuracy on the independent set , only unique classifiers were used .Figure 2 compares the performance of the unique classifiers on the testing set for two approaches : 1 - using only labeled samples 2 - using labeled plus unlabeled samples .", "label": "", "metadata": {}, "score": "42.79042"}
{"text": "The authors state that \" they did not find any evidence to support or reject the use of the sophisticated model building EAs in this problem .Taking into account the ( preliminary ) experiments where the simple GA with smaller populations was much faster than the other algorithms and found feature subset of similar quality .", "label": "", "metadata": {}, "score": "42.843544"}
{"text": "Schijvenaars BJ , Mons B , Weeber M , Schuemie MJ , van Mulligen EM , Wain HM , et al .: Thesaurus - based disambiguation of gene symbols .BMC Bioinformatics 2005 , 6 : 149 .View Article PubMed .Maglott D , Ostell J , Pruitt KD , Tatusova T : Entrez Gene : Gene - centered information at NCBI .", "label": "", "metadata": {}, "score": "43.07496"}
{"text": "Therefore it is important that we understand the different elements affecting their performance .Methods .After manually reviewing a set of WSD papers in the biomedical domain , different issues associated with performance were enumerated .For an initial study , we conducted experiments to evaluate the effect of three confounding issues : \" sample size \" , \" sense distribution \" and \" degree of difficulty \" , and we used an automatically generated data set .", "label": "", "metadata": {}, "score": "43.101406"}
{"text": "As described previously , we use the SVM algorithm combined with dataset undersampling to create the classifier .Design and evaluation of the meta - classifier .The meta - classifier uses the classification decisions from the base classifiers as its inputs ( Figure 1 ) .", "label": "", "metadata": {}, "score": "43.142437"}
{"text": "The evaluation results proved the competitiveness of the proposed approach as it outperforms some recently published techniques including supervised techniques .Related Work .In the biomedical domain , the applications of text mining and machine learning techniques were quite successful and encouraging [ 6 ] .", "label": "", "metadata": {}, "score": "43.510857"}
{"text": "4 , pp .119 - 128 , 2012 .View at Google Scholar . Y. Sun , Y. Y. Tang , S. X. Ding , S. P. Lv , and Y. F. Cui , \" Diagnose the mild cognitive impairment by constructing Bayesian network with missing data , \" Expert Systems with Applications , vol .", "label": "", "metadata": {}, "score": "44.045"}
{"text": "Supervised ML methods have also been applied to WSD in the biomedical domain .Hatzivassiloglou [ 10 ] developed a disambiguation system to determine the class of a known biomedical named entity by choosing one of three pre - defined senses : gene , RNA , protein .", "label": "", "metadata": {}, "score": "44.172264"}
{"text": "In addition , papers should also characterize the difficulty of the WSD task , the WSD situations addressed and not addressed , as well as the ML methods and features used .This should lead to an improved understanding of the generalizablility and the limitations of the methodology .", "label": "", "metadata": {}, "score": "44.367825"}
{"text": "To test the null hypothesis of no differences in the error rates among the different sample sizes ( and overall probability distribution ) for the BSA and PCA abbreviations , we used Friedman 's test .Then we performed sub - analysis using the sign - test ( see Methods section for details ) .", "label": "", "metadata": {}, "score": "44.400208"}
{"text": "[ 11 ] .Despite the fact that the far - reaching independence assumptions are often inaccurate , the naive Bayes classifier has several properties that make it surprisingly useful in practice .In particular , the decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one - dimensional distribution .", "label": "", "metadata": {}, "score": "44.540478"}
{"text": "Engelson SP , Dagan I : Minimizing manual annotation cost in supervised training from corpora .34th Annual Meeting of Association for Computational Linguistics 319 - 326 .Pustejovsky J , Castano J , Cochran B , Kotecki M , Morrell M : Automatic extraction of acronym - meaning pairs from MEDLINE databases .", "label": "", "metadata": {}, "score": "44.662437"}
{"text": "The link between the two can be seen by observing that the decision function for naive Bayes ( in the binary case ) can be rewritten as \" predict class if the odds of exceed those of \" .Expressing this in log - space gives : .", "label": "", "metadata": {}, "score": "44.679714"}
{"text": "When we applied our system onto the species disambiguation task , the results are also encouraging as shown in Table 8 .The evaluation results of our method compare very well with those reported in [ 9 ] as shown in Table 7 .", "label": "", "metadata": {}, "score": "44.703373"}
{"text": "239 - 245 , 2012 .View at Publisher \u00b7 View at Google Scholar .J. Cheng and R. Greiner , \" Comparing Bayesian network classifiers , \" in Proceedings of the 15th Conference on Uncertainty in Artificial Intelligence , K. B. Laskey and H. Prade , Eds . , pp .", "label": "", "metadata": {}, "score": "44.74524"}
{"text": "Therefore , when comparing the performance of different WSD systems , data sets with the same degree of difficulty should be used .Resnik [ 36 ] stated the importance of the semantic similarity of senses and proposed a method to compute performance , which takes similarity of senses into account .", "label": "", "metadata": {}, "score": "44.7489"}
{"text": "In addition , we use the chi - squared statistic to estimate the dependence coefficients among attributes from dataset .We believe that the use of more sophisticated methods could improve the performance of the current BC - OM and make its advantage stronger .", "label": "", "metadata": {}, "score": "44.888954"}
{"text": "Meta - learning strategies such as Combiner are trained using base - level classifiers in which each base - level classifier has been trained using the same input data and different classification algorithms .In our case , we vary both the type of classification algorithm and the type of features used for training , although the set of proteins used to derive that used to train each of the base - classifiers are identical .", "label": "", "metadata": {}, "score": "44.992416"}
{"text": "While naive Bayes often fails to produce a good estimate for the correct class probabilities , [ 12 ] this may not be a requirement for many applications .For example , the naive Bayes classifier will make the correct MAP decision rule classification so long as the correct class is more probable than any other class .", "label": "", "metadata": {}, "score": "45.014122"}
{"text": "Freund Y , Schapire RE : A decision - theoretic generalization of on - line learning and an application to boosting .J Comput Syst Sci Int 1997 , 55 : 119 - 139 .View Article .S\u00f6ding J , Biegert A , Lupas AN : The HHpred interactive server for protein homology detection and structure prediction .", "label": "", "metadata": {}, "score": "45.01834"}
{"text": "The method of Joshi-2005 uses five supervised learning methods and collocation features , while McInnes-2007 uses NB [ 1 ] .Our evaluation is done on 31 words ( as explained in Section 3 ) .We obtained the results of the other methods on these 31 words from the references shown in Table 6 to allow for direct comparison .", "label": "", "metadata": {}, "score": "45.118298"}
{"text": "All these three approaches , including the hybrid , wrapper - based , embedded methods , have the advantage that they include the interaction between feature subset search and the classification model , while both the hybrid and wrapper - based methods may have a risk of over - fitting [ 34 ] .", "label": "", "metadata": {}, "score": "45.14937"}
{"text": "Witten IH , Frank E : Data Mining : Practical Machine Learning Tools and Techniques .San Francisco , CA , USA : Morgan Kaufmann Publishers 2005 .Domingos P , Pazzani M : On the optimality of the simple Bayesian classifier under zero - one loss .", "label": "", "metadata": {}, "score": "45.25923"}
{"text": "Similarly , another study by Lin and Hsu indicated a potential epistatic interaction between the CRHR1 and NR3C1 genes with a two - stage Bayesian variable selection methodology [ 13 ] .These studies utilized the same dataset by the CDC Chronic Fatigue Syndrome Research Group .", "label": "", "metadata": {}, "score": "45.361034"}
{"text": "Overview of the PoGO training and evaluation procedure .The PoGO classifier uses a Combiner configuration in which two base - level classifiers are trained on 45 % of the training proteins and evaluated on another 45 % of the training proteins .The remaining 10 % of the training proteins are used to evaluate the meta - classifier .", "label": "", "metadata": {}, "score": "45.456875"}
{"text": "Pavlidis P , Weston J , Cai J , Noble WS : Learning gene functional classifications from multiple data types .J Comp Biol 2002 , 9 ( 2 ) : 401 - 411 .View Article .Nariai N , Kolaczyk ED , Simon K : Probabilistic Protein Function Prediction from Heterogeneous Genome - Wide Data .", "label": "", "metadata": {}, "score": "45.52807"}
{"text": "View Article .Jung J : Automatic Assignment of Protein Function with Supervised Classifiers .Quevillon E , Silventoinen V , Pillai S , Harte N , Mulder N , Apweiler R , Lopez R : InterProScan : protein domains identifier .Nucleic Acids Res 2005 , ( 33 Web Server ) : W116 - 120 .", "label": "", "metadata": {}, "score": "45.856438"}
{"text": "Another type of WSD approach uses established knowledge from curated terminology systems [ 23 , 24 ] .In the biomedical domain , Schijvenaars [ 13 ] developed a simple thesaurus - based algorithm to disambiguate human gene symbols using training data from PubMed abstracts and annotations from the Online Mendelian Inheritance in Man(OMIM )", "label": "", "metadata": {}, "score": "45.907043"}
{"text": "In the situation that such a split is not available , a random assignment of features into two sets still performs better than using only one feature set .They also introduced the co - EM algorithm , a hybrid that iteratively updates the unlabeled data labels using EM .", "label": "", "metadata": {}, "score": "45.9737"}
{"text": "It is not a single algorithm for training such classifiers , but a family of algorithms based on a common principle : all naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature , given the class variable .", "label": "", "metadata": {}, "score": "46.000015"}
{"text": "It is very important that the baseline of a classification task is reported because it shows how much of an improvement there is using a classifier as compared to the baseline .As shown in our experiments , when there is a majority sense of 0.9 or more , the performance of a WSD classifier may seem high , but that is not due to the classifier .", "label": "", "metadata": {}, "score": "46.02164"}
{"text": "Podowski 's [ 28 ] work covered task types 2 and 3 , while Hatzivassiloglou 's [ 10 ] work addressed task type 4 .Many evaluations report their results for a set of words , but the difficulty levels and types of disambiguation task types are not stratified .", "label": "", "metadata": {}, "score": "46.15918"}
{"text": "Second , we used the wrapper - based feature selection approach , in which the feature selection algorithm acts as a wrapper around the classification algorithm .The wrapper - based approach conducts best - first search for a good subset using the classification algorithm itself as part of the function for evaluating feature subsets [ 29 ] .", "label": "", "metadata": {}, "score": "46.16682"}
{"text": "Third , the C4.5 algorithm builds decision trees top - down and prunes them using the upper bound of a confidence interval on the re - substitution error [ 23 ] .By using the best single feature test , the tree is first constructed by finding the root node ( that is , SNP ) of the tree that is most discriminative for classifying CFS versus control .", "label": "", "metadata": {}, "score": "46.250347"}
{"text": "Ninth International Conference on Information and Knowledge Management ( CIKM-2000 ) 2000 , 86 - 93 .Li T , Zhu S , Li Q , Ogihara M : Gene Functional Classification by Semi - supervised Learning from heterogeneous data .Proceedings of The 18th Annual ACM Symposium on Applied Computing ( SAC 2003)-Bioinformatics Track 2003 , 78 - 82 .", "label": "", "metadata": {}, "score": "46.341576"}
{"text": "View Article .Weston J , Watkins C : Multiclass support vector machines .Proceedings of ESANN99 .Copyright .\u00a9 Xu et al .2006 .This article is published under license to BioMed Central Ltd.Naive Bayes has been studied extensively since the 1950s .", "label": "", "metadata": {}, "score": "46.384483"}
{"text": "Most of the above papers reporting on the use of ML for WSD follow a similar pattern .A set of ambiguous words is selected , a corpus for each word is collected , and the different senses within the corpus are annotated ( automatically or manually ) .", "label": "", "metadata": {}, "score": "46.45169"}
{"text": "In the wrapper - based approach , no knowledge of the classification algorithm is needed for the feature selection process , which finds optimal features by using the classification algorithm as part of the evaluation function [ 29 ] .Moreover , the search for a good feature subset is also built into the classifier algorithm in C4.5 decision tree [ 24 ] .", "label": "", "metadata": {}, "score": "46.476955"}
{"text": "View at Google Scholar .X. W. Chen , G. Anantha , and X. T. Lin , \" Improving bayesian network structure learning with mutual information - based node ordering in the K2 algorithm , \" IEEE Transactions on Knowledge and Data Engineering , vol .", "label": "", "metadata": {}, "score": "46.480854"}
{"text": "This training algorithm is an instance of the more general expectation - maximization algorithm ( EM ) : the prediction step inside the loop is the E -step of EM , while the re - training of naive Bayes is the M -step .", "label": "", "metadata": {}, "score": "46.551785"}
{"text": "Currently , our method is supervised and required annotated instances in both classes to be able to test new samples .References .M. Stevenson , Y. Guo , R. Gaizauskas , and D. Martinez , \" Knowledge sources for word sense disambiguation of biomedical text , \" in Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing ( BioNLP ' 08 ) , pp .", "label": "", "metadata": {}, "score": "46.5735"}
{"text": "A unique two - term scoring function was derived to independently score the labeled and unlabeled data models .An overall score is computed as a weighted average of the two terms as shown below .We defined the labeled data model score as the standard leave - one - out - cross - validation accuracy for the labeled training samples .", "label": "", "metadata": {}, "score": "46.576797"}
{"text": "Thus , it is likely that our findings are applicable to other ML methods because similar issues have been discussed in the general ML literature [ 43 ] .Earlier studies have investigated a number of the issues discussed here in the context of constructing better classifiers .", "label": "", "metadata": {}, "score": "46.667625"}
{"text": "EDA base on GA and does not have crossover and mutation operator .It generates new solutions by the factorization of the probability distribution of best individuals in each generation of the search .The authors state that in ENBA , this factorization is carried out by a Bayesian network .", "label": "", "metadata": {}, "score": "46.879524"}
{"text": "The applications of SVM are abound ; in particular , in NLP domain like text categorization , relation extraction , named entity recognition , SVM proved to be the best performer .The Disambiguation Step In the testing step , we want to disambiguate an instance .", "label": "", "metadata": {}, "score": "46.906586"}
{"text": "Therefore , this type of method may not be applicable and ML approaches may be useful .Recently , Humphrey [ 26 ] proposed another type of statistical - based method to resolve the ambiguity problem within the UMLS Metathesaurus .They used a Journal Descriptor Indexing ( JDI ) method , which is ultimately based on statistical associations between words in a training set of MEDLNE citations and a small set of journal descriptors assumed to be inherited by the citations .", "label": "", "metadata": {}, "score": "46.97661"}
{"text": "In bioinformatics and computational biology , there are quite a few tasks similar to WSD like biomedical term disambiguation , gene protein name disambiguation , and disambiguating species for biomedical named entities [ 9 - 11 ] .The task of biomedical named entity disambiguation or classification is an augmentation of the well - known task of biomedical named entity recognition ( NER ) .", "label": "", "metadata": {}, "score": "47.02179"}
{"text": "But some reported that certain classification algorithms were better than others .It is still an unclear issue , probably due to the interaction of different combinations of issues .The comparison between different classifiers should be a carefully controlled experiment .The notion that a lower absolute error rate is indicative of the superiority of a classifier is generally flawed because it ignores the possibility that the differences in the different experiments performed are not statistically significant [ 38 ] .", "label": "", "metadata": {}, "score": "47.07941"}
{"text": "A q9 statistic [ Zhang and Zhang , 2002 ] is used to be a selection criterion .The authors claim that their method \" performs a fast detection of relevant feature subsets using the technique of constrained feature subsets .Compared to the traditional greedy methods the gain in speed can be up to one order of magnitude , with results being comparable or even better than the greedy methods . \"", "label": "", "metadata": {}, "score": "47.093185"}
{"text": "As with the above approaches , independent models are developed for each dataset .They show that minimizing the disagreement in predictions between these models leads to improved accuracy , and introduced a co - updating technique for iteratively improving prediction concordance .Recently , Qi et al .", "label": "", "metadata": {}, "score": "47.108265"}
{"text": "One was the hybrid feature selection approach combining the chi - squared and information - gain methods .The other was the wrapper - based feature selection method .Results .The naive Bayes model with the wrapper - based approach performed maximally among predictive models to infer the disease susceptibility dealing with the complex relationship between CFS and SNPs .", "label": "", "metadata": {}, "score": "47.379494"}
{"text": "Therefore , a problem of searching for an optimal classifier can be turned into finding the maximum value of the objective function in feasible fields .In addition , we have proved the existence and uniqueness of the numerical solution .BC - OM offers a new opinion for the research of extended Bayesian classifier .", "label": "", "metadata": {}, "score": "47.519753"}
{"text": "As is evident in figure 1 , adding unlabeled samples increased the mean accuracy of the models significantly .This figures shows the improvement of the classification by adding unlabeled samples into the experiments .Figure 2 displays the improvements of the classification accuracies for the population of unique classifiers in each cancer group .", "label": "", "metadata": {}, "score": "47.55298"}
{"text": "M. Weeber , J. Mork , and A. Aronson , \" Developing a test collection for biomedical word sense disambiguation , \" in Proceedings of the Symposium American Medical Informatics Association ( AMIA ' 01 ) , 2001 .M. F. Porter , \" An algorithm for suffix stripping , \" Program , vol .", "label": "", "metadata": {}, "score": "47.783253"}
{"text": "The gat- ing nodes combine the predictions of the expert classifiers based on an estimate of the cluster membership of a test protein sequence .The combination scheme Table 2 : Experimental results on the DNA - protein sequence data set .Experimental results with Naive Bayes ( NB ) and Logistic Regression ( LR ) models , and Mixture of Experts ( ME ) models on the non - redundant DNA - protein sequence data set , where the identity cutoffs are 30 % and 90 % .", "label": "", "metadata": {}, "score": "47.81933"}
{"text": "Let .Figure 1 schematically illustrates the structures of the Bayesian classifiers considered in this paper .In naive Bayes , each attribute node has the class node as its parent , but does not have any parent from attribute nodes .Computing . can be easily estimated from training examples , naive Bayes is easy to construct .", "label": "", "metadata": {}, "score": "48.021393"}
{"text": "Next , we prove the correctness of BC - OM algorithm under the faithfulness assumption .The next two results establish the existence and uniqueness properties of solution to .Experimental Results .We run our experiments on 20 data sets from the UCI repository of Machine Learning datasets [ 28 ] , which represent a wide range of domains and data characteristics .", "label": "", "metadata": {}, "score": "48.029358"}
{"text": "Thus , we compared the PR curves for NB and the mixture of NB models as well as LR and mixture of LR models on both RNA- and DNA - protein interface predic- tion tasks .While this is true for any identity cutoff for both RNA- and DNA - pro- tein sequence data sets , we show results only for 30 % identity cutoff .", "label": "", "metadata": {}, "score": "48.041496"}
{"text": "This could also be due to the existence of other confounding factors in the datasets that were used .In our study , we controlled for this factor by using \" bag - of - word \" features in all experiments , but it would be interesting to see if the performance improves when different feature vectors are used .", "label": "", "metadata": {}, "score": "48.289024"}
{"text": "However , the advances in automatic text annotation and tagging techniques with the help of the plethora of knowledge sources like ontologies and text literature in the biomedical domain will help lessen this limitation .The proposed method utilizes the interaction model ( mutual information ) between the context words and the senses of the target word to induce reliable learning models for sense disambiguation .", "label": "", "metadata": {}, "score": "48.325356"}
{"text": "We also measured the performance of the Interpro2GO mapping by using it to assign GO terms to proteins and measuring performance with Sensitivity , Specificity , and F - measure .All of the PoGO classifiers outperformed the Interpro2GO mapping ( data not shown ) .", "label": "", "metadata": {}, "score": "48.45176"}
{"text": "Ginter [ 27 ] introduced a new family of classifiers , which were based on an ordering and weighing of the feature vectors obtained from word counts and word co - occurrence in the text .This method was used to determine whether a term was a gene versus a protein and achieved 86 % accuracy .", "label": "", "metadata": {}, "score": "48.46131"}
{"text": "View at Google Scholar .J. Pearl , Probabilistic Reasoning in Intelligent Systems , Morgan Kaufmann , San Francisco , Calif , USA , 1988 .D. M. Chickering , \" Learning Bayesian networks is NP - Complete , \" in Learning From Data : Artificial Intelligence and Statistics V , D. Fisher and H. Lenz , Eds . , pp .", "label": "", "metadata": {}, "score": "48.485855"}
{"text": "And they need a lot of computing power .For example , in supervised machine learning ( I learned that term a month ago , do n't expect me to be very academic ) you show the machine some examples ( experience ) of what you want and the machine extract some patterns from them .", "label": "", "metadata": {}, "score": "48.492355"}
{"text": "In addition , we calculated sensitivity , the proportion of correctly predicted responders of all tested responders , and specificity , the proportion of correctly predicted non - responders of all the tested non - responders .To investigate the generalization of the prediction models produced by the above algorithms , we utilized the repeated 10-fold cross - validation method [ 33 ] .", "label": "", "metadata": {}, "score": "48.62361"}
{"text": "Introduction .With the development of information technology , in particular the progress of network technology , multimedia technology and communication technology , massive data analysis , and processing become more and more important .Since Bayesian network as classifier has a solid mathematical basis and takes the prior information of samples into consideration , it is now one of the hottest areas in machine learning and data mining fields .", "label": "", "metadata": {}, "score": "48.63817"}
{"text": "Another benefit is this method can evaluate the feature weights , which is shown to be useful to extract knowledge from complex data .Reference : .Koller D , Sahami M : Toward optimal feature selection .In Proceedings Of the 13th International Conference on Machine Learning 1996:284 - 292 .", "label": "", "metadata": {}, "score": "48.642353"}
{"text": "This process is similar to ranking of features except that interactions between features are also considered [ 25 ] .Feature Selection .In this work , we employed two feature selection approaches to find a subset of SNPs that maximizes the performance of the prediction model .", "label": "", "metadata": {}, "score": "48.82042"}
{"text": "Jordan MI , Jacobs RA : Hierarchical mixtures of experts and the EM algorithm .Neural Computation 1994 , 6:181 - 214 .Dempster AP , Laird NM , Rubin DB : Maximum likelihood from incomplete data via the EM algorithm .Journal of the Royal Sta- tistical Society 1977 , 39:1 - 38 .", "label": "", "metadata": {}, "score": "48.82986"}
{"text": "[ 4 ] and Kim et al .[5 ] used Support Vector Machines to identify residues in a protein sequence that undergo post - translational modifications .The classifier is trained to label the target element .This procedure can produce reli- able results in settings where there exists a local sequence pattern that is predictive of the label for the target site .", "label": "", "metadata": {}, "score": "48.843224"}
{"text": "The authors derived a feature ranking method ( EDA - R ) from the estimated distribution of the algorithm to solve this problem .The authors also claim that another advantage of EDA - R is it can be used to evaluate the features weight .", "label": "", "metadata": {}, "score": "48.84549"}
{"text": "Spectral clustering falls within the category of graph parti- tioning algorithms that partition the data into disjoint clusters by exploiting the eigenstructure of a similarity matrix .In general , to find an optimal graph partitioning is NP complete .Shi and Malik [ 15 ] proposed an approxi- mate spectral clustering algorithm that optimizes the nor- malized cut ( NCut ) objective function .", "label": "", "metadata": {}, "score": "48.995483"}
{"text": "View Article PubMed .Kohavi R , John GH : Wrappers for feature subset selection .Artificial Intelligence 1997 , 97 : 273 - 324 .View Article .Lin E , Hwang Y : A support vector machine approach to assess drug efficacy of interferon - alpha and ribavirin combination therapy .", "label": "", "metadata": {}, "score": "48.996"}
{"text": "The authors state this may be some different detail in experiments setup .Chen , H. ; Yuan , S. & Jiang , K. ( 2005 ) , ' Fitness Approximation in Estimation of Distribution Algorithms for Feature Selection ' , Lecture notes in computer science 3809 , 904 .", "label": "", "metadata": {}, "score": "49.19609"}
{"text": "With the same sample size change , the error rate for PCA dropped from 43.00 % to only 28.53 % .Results for BPD are shown in Table 5 , which contains the results from three different multi - class SVM algorithms .We used Friedman 's test [ 33 ] to compare the different multi - class algorithms , and stratified the analysis by probability distribution using sample size ( four levels ) and multi - class algorithm ( three levels ) as the two factors in the ANOVA table .", "label": "", "metadata": {}, "score": "49.32911"}
{"text": "By the way we are going to use an classification algorithm called naive Bayes that uses the famous Bayes theorem , and that I already mentioned in a previous post .I 'm not going to explain how the algorithm works , I 'll just show you that it works !", "label": "", "metadata": {}, "score": "49.33664"}
{"text": "The BGEN method trains a kernel classifier using both labeled and unlabeled data .Their example data consisted of expression profiles of wild type and mutant C. elegant embryos and identified enriched genes , with a small subset of genes labeled according to involvement in development of cell lineage .", "label": "", "metadata": {}, "score": "49.37424"}
{"text": "The algorithm is the core of the method and it is an obvious instance of the Strategy design pattern .We are using BayesAlgorithm but well we could have used CbayesAlgorithm that uses the Complementary Naive Bayes Algorithm .ClassifierContext is the interface you 'll use to classify documents .", "label": "", "metadata": {}, "score": "49.492798"}
{"text": "We used a package called \" Spider \" [ 46 ] to perform all the SVM training and testing .For abbreviations with only two senses ( BSA , PCA , RSV ) , a binary SVM classifier was used .For BPD , which has three different senses , three different multi - class SVM methods [ 47 ] : \" mc - svm \" , \" one - vs - rest \" , \" one - vs - one \" , were used . \" Mc - svm \" implements the algorithm with a decision function which considers all classes at once , while \" one - vs - rest \" and \" one - ve - one \" are constructed by combining several binary SVM classifiers .", "label": "", "metadata": {}, "score": "49.496456"}
{"text": "And , we also propose a new method to measure the dependent relationships between attributes .The theoretical basis of this method is established by Theorem 1 [ 24 ] . reflects the underlying probabilistic dependence relations among the nodes and a set of assertions about conditional independencies .", "label": "", "metadata": {}, "score": "49.55891"}
{"text": "Previous results have shown that these steps improve classification accuracy and reduce learning time [ 19 ] .Sequence Similarity .Several previous methods including GoFigure [ 14 ] , GOblet [ 22 ] , and OntoBlast [ 23 ] use sequence similarity based on BLAST [ 2 ] results as features .", "label": "", "metadata": {}, "score": "49.59869"}
{"text": "Bruce R , Wiebe J : Word sense disambiguation using decomposable models .Proceedings of the Thirty - second Annual Meeting of the Association of Computational Linguistics 139 - 146 .Lee YK , Ng HT : An empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation .", "label": "", "metadata": {}, "score": "49.67237"}
{"text": "If available , labels were removed from one of the component datasets , thus creating a combined dataset with both labeled and unlabeled subsets .All datasets were produced using Affymetrix GeneChips , and in two cases the labeled and unlabeled datasets were collected with different Affymetrix GeneChips .", "label": "", "metadata": {}, "score": "49.681343"}
{"text": "As a supervised technique , this method consists of two stages learning ( or training ) stage and a testing ( or application ) stage .The trained models ( classifiers ) produced from the learning phase will then be used to disambiguate unseen and unlabeled examples in the testing phase .", "label": "", "metadata": {}, "score": "49.699215"}
{"text": "We first segment the data by the class , and then compute the mean and variance of in each class .Let be the mean of the values in associated with class c , and let be the variance of the values in associated with class c .", "label": "", "metadata": {}, "score": "49.71393"}
{"text": "These assumptions lead to two distinct models , which are often confused .[ 9 ] [ 10 ] .When dealing with continuous data , a typical assumption is that the continuous values associated with each class are distributed according to a Gaussian distribution .", "label": "", "metadata": {}, "score": "49.72264"}
{"text": "^ Narasimha Murty , M. ; Susheela Devi , V. ( 2011 ) .Pattern Recognition : An Algorithmic Approach .ISBN 0857294946 .^ John , George H. ; Langley , Pat ( 1995 ) .Estimating Continuous Distributions in Bayesian Classifiers .", "label": "", "metadata": {}, "score": "49.866264"}
{"text": "View Article .Pedersen T , Bruce R : Distinguishing word senses in untagged text .Second Conference on Empirical Methods in Natural Language Processing .Hsu G , Lin C : A comparison of methods for multi - class support vector machines .", "label": "", "metadata": {}, "score": "49.96837"}
{"text": "An independent classifier is trained for each GO term , making the system amenable to updating , without having to re - train the whole system .The resulting system is robust .It provides better accuracy and can assign GO terms to a higher percentage of unannotated protein sequences than other methods that we tested .", "label": "", "metadata": {}, "score": "49.9929"}
{"text": "Science 1999 , 286 : 531 - 537 .View Article PubMed .Blum A , Mitchell TM : Combining labeled and unlabeled data with co - training .Proceedings of the Eleventh Annual Conference on Computational Learning Theory 1998 , 92 - 100 .", "label": "", "metadata": {}, "score": "50.02506"}
{"text": "In the previous work , [ 17 ] , we introduced a method for term disambiguation and evaluated it with biomedical terms to disambiguate gene and protein names in medical texts .The method relies on representing the instances of the word to be disambiguated , . , as a feature vector , and the components of this vector are neighborhood context words in the training instances .", "label": "", "metadata": {}, "score": "50.04254"}
{"text": "The model can be very big .This is where Hadoop enters the scene .The offline process can be sent to a cluster running hadoop , and using the same libraries ( Mahout ! )you perform what looks like the exactly same algorithms and get the results faster .", "label": "", "metadata": {}, "score": "50.098145"}
{"text": "The same study , which was also performaned for the Fly organism , showed similar results , but with slightly higher ambiguity rates .For a more complete description of this study and the results , please [ see additional file 1 ] .", "label": "", "metadata": {}, "score": "50.405327"}
{"text": "Moreover , the gene - gene and gene - environment interactions in these candidate genes have been assessed using the odds ratio based multifactor dimensionality reduction method [ 12 ] and the stochastic search variable selection method [ 13 ] .In the studies of genomics , the problem of identifying significant genes remains a challenge for researchers [ 14 ] .", "label": "", "metadata": {}, "score": "50.44712"}
{"text": "A Method for WSD .A word sense disambiguation method is an algorithm that assigns the most accurate sense to a given word in a given context .Our method is a supervised method requiring a training corpus that contains manually disambiguated instances of the ambiguous words .", "label": "", "metadata": {}, "score": "50.47829"}
{"text": "View Article .Vapnik V : The Nature of Statistical Learning Theory .New York , NY , USA : Springer - Verlag 1995 .Burges CJ : A tutorial on support vector machines for pattern recognition .Data Min Knowl Disc 1998 , 2 : 127 - 167 .", "label": "", "metadata": {}, "score": "50.50255"}
{"text": "The number in each node indicates the number of protein sequences belonging to it .The Needleman - Wunch global alignment score was used as a pairwise similarity measure during the clustering process .Page 12 .Thus , having the hierarchical clustering stored , we devise a procedure that allows each sequence in the training set to simultaneously lie in all clusters , with a different weigth in each cluster . , n in the training set compute its cluster membership as follows : , we 1 .", "label": "", "metadata": {}, "score": "50.58321"}
{"text": "There were several limitations to this study as follows .Firstly , the small size of the sample does not allow drawing definite conclusions .Secondly , we imputed missing values before comparing algorithms .Thus , we depended on unknown characteristics of the missing data , which could be either missing completely at random or the result of some experimental bias [ 25 ] .", "label": "", "metadata": {}, "score": "50.679012"}
{"text": "That is , .[ 4 ] .With a multinomial event model , samples ( feature vectors ) represent the frequencies with which certain events have been generated by a multinomial where is the probability that event i occurs ( or K such multinomials in the multiclass case ) .", "label": "", "metadata": {}, "score": "50.7325"}
{"text": "devised a rule based system to disambiguate biomedical entity names , like gene products , based on species .In that approach [ 9 ] , some parsing techniques are used and syntactic parse tree with paths between words to determine if there exists a path between species word and the entity name .", "label": "", "metadata": {}, "score": "51.149864"}
{"text": "[ 2 ] It also finds application in automatic medical diagnosis .[ 3 ] .In the statistics and computer science literature , Naive Bayes models are known under a variety of names , including simple Bayes and independence Bayes .[ 1 ] : 482 .", "label": "", "metadata": {}, "score": "51.16366"}
{"text": "Note that the PR curves of the ensembles are closer to those of the baseline classifiers .Discussion Reliable methods for identifying putative functional sites in protein sequences is an important problem with broad applications in computational biology , e.g. , rational drug design .", "label": "", "metadata": {}, "score": "51.186104"}
{"text": "Other issues in addition to sample size , distribution of senses , and difficulty of the task also affect the performance and subsequent assessment of WSD classifiers , as noted below : .As often discussed in various papers , different features were evaluated to see their contribution to classifier performance [ 10 , 20 , 29 ] .", "label": "", "metadata": {}, "score": "51.320404"}
{"text": "Khan S , Situ G , Decker K , Schmidt CJ : GoFigure : automated Gene Ontology annotation .Bioinformatics 2003 , 19 ( 18 ) : 2484 - 2485 .PubMed View Article .Martin DM , Berriman M , Barton GJ : GOtcha : a new method for prediction of protein function assessed by the annotation of seven genomes .", "label": "", "metadata": {}, "score": "51.383026"}
{"text": "One of the problems of supervised machine learning for WSD is the need for an annotated training ( and testing ) data set for each ambiguous word , which may require a huge effort .In our study , we proposed a simple \" full - term substitution \" method , which is described in more detail in the Methods section , to automatically generate training data , but this is only applicable for abbreviations .", "label": "", "metadata": {}, "score": "51.44542"}
{"text": "Abstractly , naive Bayes is a conditional probability model : given a problem instance to be classified , represented by a vector representing some n features ( independent variables ) , it assigns to this instance probabilities .The problem with the above formulation is that if the number of features n is large or if a feature can take on a large number of values , then basing such a model on probability tables is infeasible .", "label": "", "metadata": {}, "score": "51.44736"}
{"text": "Improved models are iteratively generated using a genetic algorithm feature selection technique .Our results show that the addition of unannotated data into training , significantly improves classifier robustness .Background .The introduction of DNA microarray technology in 1995 [ 1 ] has likely resulted in a huge volume of as yet undiscovered and potentially medically useful knowledge within gene expression profiles .", "label": "", "metadata": {}, "score": "51.477325"}
{"text": "Typical examples of these : .Classification : it is supervised learning , you give the machine a lot of instances of ... things ( documents for example ) along with their category .From all of those the machine learns to classify future instances in the known categories .", "label": "", "metadata": {}, "score": "51.514122"}
{"text": "With any classifier , it is possible to tradeoff the Precision against Recall .Hence , it is more informative to compare the Pre- cision - Recall ( PR ) curves which show the tradeoff over their entire range of possible values than to compare the performance of the classifiers for a particular choice of the .", "label": "", "metadata": {}, "score": "51.526035"}
{"text": "GLM ( general linear model ) architectures of mixture of experts achieved better results for ME with an adaptive variance parameter for each expert , whereas MLP ( multilayer perceptron ) architectures - for standard mixtures of experts .[ Show abstract ] [ Hide abstract ] ABSTRACT : Several experiments were conducted in order to investigate the usefulness of mixture of experts approach to an online internet system assisting in real estate appraisal .", "label": "", "metadata": {}, "score": "51.553173"}
{"text": "Also words with parentheses or square brackets are not ignored and part of speech is not used .After the text preprocessing is completed , for each word we convert the instances into numeric feature vectors .Then , we use SVM for training and testing with 5-fold cross validation 5FCV such that 80 % of the instances are used for training and the remaining 20 % are used for testing , and this is repeated five times by changing the training - testing portions of the data .", "label": "", "metadata": {}, "score": "51.56389"}
{"text": "The Blosum62 sub- stitution matrix was used for costs .The resulting entries in the matrix W are normalized and scaled so that each value is between 0 and 1 .The mixture of experts models consist of NB and LR at the leaves , respectively ( see Methods sec- tion for further details ) .", "label": "", "metadata": {}, "score": "51.579445"}
{"text": "Of all the kernel functions , the sigmoid kernel performed best , outperforming the other three kernels in terms of AUC .In addition , the numbers of SNPs selected by these six models with the wrapper - based approach were ranged from 6 to 12 SNPs ( Table 5 ) .", "label": "", "metadata": {}, "score": "51.589058"}
{"text": "Cantu - Paz , E. ( 2002 ) , ' Feature subset selection by estimation of distribution algorithms ' , , 303 - -310 .The authors want to determine if the EDAs present advantages over other GA methods in terms of accuracy or speed in this problem .", "label": "", "metadata": {}, "score": "51.689583"}
{"text": "As illustrated in the tables , the mixture of experts models that capture global sequence similarity outperform the baseline models .Comparison of Precision - Recall curves for Na\u00efve Bayes , mixture of Na\u00efve Bayes and ensemble of Na\u00efve Bayes mod- els on the non - redundant RNA - protein data set at 30 % identity cutoff .", "label": "", "metadata": {}, "score": "51.732204"}
{"text": "Consider the problem of classifying documents by their content , for example into spam and non - spam e - mails .Imagine that documents are drawn from a number of classes of documents which can be modelled as sets of words where the ( independent ) probability that the i - th word of a given document occurs in a document from class C can be written as .", "label": "", "metadata": {}, "score": "51.75137"}
{"text": "Mulder N , Apweiler R : InterPro and InterProScan : tools for protein sequence classification and comparison .Methods Mol Biol 2007 , 396 : 59 - 70 .PubMed View Article .Jung J , Thon MR : Automatic annotation of protein functional class from sparse and imbalanced data sets .", "label": "", "metadata": {}, "score": "51.872803"}
{"text": "A lot of modern web sites are using machine learning techniques .In simple words , we can say that a computer program is said to learn from experience E with respect to some class of tasks T and performance measure P , if its performance at tasks in T , as measured by P , improves with experience E. .", "label": "", "metadata": {}, "score": "51.94973"}
{"text": "Results from our experiments demonstrated that these three factors were intrinsically connected .Notice that as expected , with any distribution , the error rate generally decreased as the sample size increased .However the observed decrease in error rate was more dramatic in the cases where the different senses were well separated .", "label": "", "metadata": {}, "score": "52.001495"}
{"text": "For example , when there is a majority sense for an ambiguous word , the improvement of a WSD classifier is believed to be very small .Results from our study showed there was a difference only when the distribution was very uneven and the task was difficult .", "label": "", "metadata": {}, "score": "52.035587"}
{"text": "Each data instance in the training set contains the information about the observed phenotypic value as a class label and the SNPs of the subjects as features .Given a training set of instance - label pairs , the SVM algorithm maps the training vectors into a higher dimensional space by employing a kernel function and then finds a linear separating hyperplane with the maximal margin in this higher dimensional space .", "label": "", "metadata": {}, "score": "52.09484"}
{"text": "Authors ' contributions .JJ proposed the learning scheme and implemented the classifier ; GY contributed to the implementation of the web site ; MT suggested the basic idea and guided the overall system .JJ , GY , SS and MT wrote and revised the manuscript .", "label": "", "metadata": {}, "score": "52.105064"}
{"text": "However , in our study , we found that adding an extra layer of feature selection on top of both the SVM and C4.5 decision tree algorithms was advantageous in both the hybrid and wrapper - based methods .In this work , we used the proposed feature selection approaches to assess CFS - susceptible individuals and found a panel of genetic markers , including COMT , CRHR2 , NR3C1 , POMC , and TPH2 , which were more significant than the others in CFS .", "label": "", "metadata": {}, "score": "52.14697"}
{"text": "More specifically , they excluded samples with a majority sense larger than a threshold because they realized the contribution of the classifier would not be much for those cases .When reporting the results ( i.e. error rate ) , not all papers reported confidence intervals ( or a similar metric , such as standard deviations ) .", "label": "", "metadata": {}, "score": "52.173046"}
{"text": "ME - NB - local exploits the local sequence similarity to construct the hierarchical structure .ME - NB - random randomizes the global similarity matrix and constructs the hierarchical structure based on the randomized matrix .Comparison of Correlation Coefficient for Na\u00efve Bayes and mixture of Na\u00efve Bayes models that capture global sequence similarity on the non - redundant RNA - protein data sets constructed using various identity cutoffs , starting from 30 % and ending at 90 % in steps of 10 .", "label": "", "metadata": {}, "score": "52.20546"}
{"text": "The authors want to find a way to perform a fast detection of relevant feature subsets using the technique of constrained feature subsets .The authors begin by referring to work of tradition Feature Subset Selection ( FSS ) methods which are sequential and are based on a greedy heuristic [ kohavi and Johnm 1997].", "label": "", "metadata": {}, "score": "52.23651"}
{"text": "It was presented to show the degree of difficulty among different abbreviations .Results from 5-fold cross - validation showed no statistical difference with results from 10-fold cross - validation , which indicated 5-fold cross - validation might be used in evaluation in order to save computational power ( for a discussion of the relative merits of 5-fold cross - validation vs. 10-fold cross - validation , see [ 35 ] ) .", "label": "", "metadata": {}, "score": "52.2724"}
{"text": "Lin E , Huang LC : Identification of Significant Genes in Genomics Using Bayesian Variable Selection Methods .Computational Biology and Chemistry : Advances and Applications 2008 , 1 : 13 - 18 .Lee KE , Sha N , Dougherty ER , Vannucci M , Mallick BK : Gene selection : a Bayesian variable selection approach .", "label": "", "metadata": {}, "score": "52.341484"}
{"text": "In the case of Combiner , the training dataset T is divided into two equal parts T 1 and T 2 .The base - level learning algorithms are trained using T 1 and then the resulting classifiers are used to predict functional categories for T 2 .", "label": "", "metadata": {}, "score": "52.35042"}
{"text": "We discuss the classification principles of Bayesian classifier from a new view .Because chi - squared tests are a standard tool for measuring the dependency between pairs of variables [ 23 ] , BC - OM first introduces the chi - squared statistic to define the dependence coefficients of variables .", "label": "", "metadata": {}, "score": "52.409637"}
{"text": "The cluster separation term is given by a modified ratio of the inter - cluster distance to the mean cluster size .The consistent proportion term , is defined as the RMS difference between the sorted actual and expected class priors .The class priors may be estimated from the labeled data , or may be available externally .", "label": "", "metadata": {}, "score": "52.46883"}
{"text": "The disadvantage to this approach is that interdependencies among the labels can not be incorporated into the classifier , thus potentially increasing error .The advantage , however , is that a wide range of binary classification algorithms may be applied to the problem .", "label": "", "metadata": {}, "score": "52.517834"}
{"text": "Hence , there is an urgent need for devel- opment of computational tools that can accurately anno- tate biomolecular data .Machine learning methods currently offer one of the most cost - effective approaches to construction of predictive models in applications where representative training data are available .", "label": "", "metadata": {}, "score": "52.57813"}
{"text": "View at Google Scholar . A. A. Balamurugan , R. Rajaram , S. Pramala , S. Rajalakshmi , C. Jeyendran , and J. Dinesh Surya Prakash , \" NB+ : an improved Naive Bayesian algorithm , \" Knowledge - Based Systems , vol .", "label": "", "metadata": {}, "score": "52.628044"}
{"text": ", m , and m is the number of classifiers in the collection .Each individual classifier in the collection was trained on approximately instances , where l represents the total number of train- ing instances available to the ensemble .Performance evaluation To assess the performance of classifiers in this study , we report the following measures : Precision , Recall , Correla- tion Coefficient ( CC ) , and F - Measure ( FM ) .", "label": "", "metadata": {}, "score": "52.6325"}
{"text": "PubMed View Article .Altschul SF , Madden TL , Schaffer AA , Zhang J , Zhang Z , Miller W , Lipman DJ : Gapped BLAST and PSI - BLAST : a new generation of protein database search programs .Nucleic Acids Res 1997 , 25 ( 17 ) : 3389 - 3402 .", "label": "", "metadata": {}, "score": "52.693436"}
{"text": "The main classes of approaches of word sense disambiguation include supervised methods and unsupervised methods .The supervised methods rely on training and learning phases that require a dataset or corpus containing manually disambiguated instances to be used to train the system [ 5 , 6 ] .", "label": "", "metadata": {}, "score": "52.69368"}
{"text": "Liu H , Teller V , Friedman C : A multi - aspect comparison study of supervised word sense disambiguation .J Am Med Inform Assoc 2004 , 11 : 320 - 331 .View Article PubMed .Leroy G , Rindflesch TC : Effects of information and machine learning algorithms on word sense disambiguation with small datasets .", "label": "", "metadata": {}, "score": "52.739563"}
{"text": "During classification , given a test sequence xtest , we extract the local windows corresponding to its elements . , N in the hierarchical clus- tering root node that makes the final prediction .Page 13 .Logistic Regression Logistic Regression ( LR ) [ 19 ] is a supervised learning algo- rithm that belongs to the class of discriminative models .", "label": "", "metadata": {}, "score": "52.759933"}
{"text": "We applied naive Bayes , SVM , and C4.5 decision tree with the wrapper - based approach , respectively .Evaluation of the Predictive Performance .To measure the performance of prediction models , we used the receiver operating characteristic ( ROC ) methodology and calculated the area under the ROC curve ( AUC ) [ 30 , 31 ] .", "label": "", "metadata": {}, "score": "52.916664"}
{"text": "Given a set of sequences and a similarity measure defined on pairs of sequences , we learn a mixture of experts model by using spectral clustering to learn the hierarchical structure of the model and by using bayesian techniques to combine the predictions of the experts .", "label": "", "metadata": {}, "score": "52.94255"}
{"text": "As many available datasets will not have the desired annotation for any samples , this method extends the usability of the limited number of adequately annotated microarray datasets .Methods .Datasets .We conducted three experiments , each addressing a different cancer diagnostic problem : ALL / AML differential diagnosis , prediction of response to imatinib in CML , and prediction of outcome in DLBCL .", "label": "", "metadata": {}, "score": "52.97973"}
{"text": "[ 13 ] .This prior probability distribution might be based on our knowledge of frequencies in the larger population , or on frequency in the training set .However , given the sample the evidence is a constant and thus scales both posteriors equally .", "label": "", "metadata": {}, "score": "53.018173"}
{"text": "These papers are important in that they report on useful methods and provide insights and overall results .However , a deeper and more systematic analysis is needed in order to obtain a better understanding of the different factors affecting the performance of ML methods for WSD .", "label": "", "metadata": {}, "score": "53.033882"}
{"text": "Nucleic Acid Res 2000 , 28:235 - 242 .Allers J , Shamoo Y : Structure - based analysis of protein - RNA interactions using the program ENTANGLE .J mol Biol 2001 , 311:75 - 86 .Duda R , Hart E , Stork D : Pattern Classification Second edition .", "label": "", "metadata": {}, "score": "53.11994"}
{"text": "Most researchers have now adopted AUC for evaluating predictive ability of classifiers owing to the fact that AUC is a better performance metric than accuracy [ 31 ] .In this study , AUC was used as a value to compare the performance of different prediction models on a dataset .", "label": "", "metadata": {}, "score": "53.184097"}
{"text": "The problem that the authors want to solve is to improve the classification rates for Automatic Emotion Recognition in Speech .The authors refer to the work of affective computing and indicate that they use the several machine learning techniques as a basis for their work .", "label": "", "metadata": {}, "score": "53.186073"}
{"text": "bin / mahout testclassifier -m examples / bin / work / spam / bayes - model -d examples / bin / work / spam / prepared - test -type bayes -ng 1 -source hdfs -method sequential .And after a while we get the following results .", "label": "", "metadata": {}, "score": "53.235542"}
{"text": "Therefore , a problem of searching for an optimal classifier can be turned into finding the maximum value of the objective function in feasible fields .The function extremum corresponds to the best classifier .Finally , BC - OM improves the efficiency of classification and delete irrelevant or redundant attributes by using the d - separation rule of Bayesian network .", "label": "", "metadata": {}, "score": "53.253647"}
{"text": "The Learning Phase From the labeled training examples of the word , we build the feature vectors using the top context words selected by MI or M2 as features .After that , we use the support vector machine ( SVM ) [ 23 ] as the learner to train the classifier using the training vectors .", "label": "", "metadata": {}, "score": "53.262466"}
{"text": "It is spam if ( i.e. , ) , otherwise it is not spam .^ Caruana , R. ; Niculescu - Mizil , A. ( 2006 ) .An empirical comparison of supervised learning algorithms .Proc . 23rdInternational Conference on Machine Learning .", "label": "", "metadata": {}, "score": "53.275215"}
{"text": "We subsequently based our assessment of performance on error rates and associated standard errors .Our method also differs from related work because the sample size for each sense is always fixed , whereas in related work the sample size for the entire corpus is generally fixed but not the sample sizes of the senses .", "label": "", "metadata": {}, "score": "53.337517"}
{"text": "Most authors compute performance statistics by first calculating the statistics for each protein individually , and then calculating an average over all of the tested proteins .In a traditional machine - learning approach , performance statistics are calculated for each functional category .", "label": "", "metadata": {}, "score": "53.37018"}
{"text": "6 , pp .1088 - 1100 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. Chen and H. Al - Mubaid , \" Context - based term disambiguation in biomedical literature , \" in Proceedings of the 19th International Florida Artificial Intelligence Research Society Conference ( FLAIRS ' 06 ) , pp .", "label": "", "metadata": {}, "score": "53.549908"}
{"text": "For each sense , we recorded all the retrieved PMIDs , randomly selected 250 , and then obtained the corresponding abstracts to form a data pool , from which all the experiments were drawn .Feature vector and machine - learning algorithm .For all the experiments in this paper , we used the simple \" bag - of - word \" method to construct the feature vector .", "label": "", "metadata": {}, "score": "53.662407"}
{"text": "They reported an F - measure of over 0.7 for genes with sufficient number of known document references .Liu [ 29 ] investigated the effect of window size and claimed that biomedical ambiguous words needed a larger window size than general English ambiguous words .", "label": "", "metadata": {}, "score": "53.710686"}
{"text": "Conclusion .Several different independent aspects affect performance when using ML techniques for WSD .We found that combining them into one single result obscures understanding of the underlying methods .Although we studied only four abbreviations , we utilized a well - established statistical method that guarantees the results are likely to be generalizable for abbreviations with similar characteristics .", "label": "", "metadata": {}, "score": "53.723232"}
{"text": "Table 3 .The result of a repeated 10-fold cross - validation experiment using naive Bayes , support vector machine ( SVM ) , and C4.5 decision tree without feature selection .Data are presented as mean \u00b1 standard deviation .The result of a repeated 10-fold cross - validation experiment using naive Bayes , support vector machine ( SVM ) , and C4.5 decision tree with the hybrid feature selection approach that combines the chi - squared and information - gain methods .", "label": "", "metadata": {}, "score": "53.759727"}
{"text": "We attribute this to the additional feature types , such as sequence similarity and protein structure that were included in the dataset .For proteins that to not have matched to the InterPro database , these additional feature types are often times still assigned to the protein , and can be sufficient for predicting the GO terms .", "label": "", "metadata": {}, "score": "53.770058"}
{"text": "For example , Joshi-2005 tested their system on 28 words ( out of the whole set 50 words ) and other techniques used 22 words , 15 words , or the whole set [ 1 ] .In Table 6 , the results of the three methods ( Joshi-2005 , McInnes-2007 , and Stevenson-2008 ) are taken from Stevenson et al .", "label": "", "metadata": {}, "score": "53.827034"}
{"text": "Table 1 : Experimental results on the RNA - protein sequence data set .Experimental results with Naive Bayes ( NB ) and Logistic Regression ( LR ) models , and Mixture of Experts ( ME ) models on the non - redundant RNA - protein sequence data set , where the identity cutoffs are 30 % and 90 % .", "label": "", "metadata": {}, "score": "53.835617"}
{"text": "[ 1 ] trained Na\u00efve Bayes classifiers to identify RNA - protein interface residues in a protein sequence .Yan et al .[ 2 ] developed a two - stage classifier to identify protein - pro- tein interaction sites .Qian and Sejnowski [ 3 ] trained Neu- ral Networks to predict protein secondary structure , i.e. , classifying each residue in a protein sequence into one of the three classes : helix ( H ) , strand ( E ) or coil ( C ) .", "label": "", "metadata": {}, "score": "54.02043"}
{"text": "The expert networks output class probabilities for each input x , while the gating networks learn how to combine the predictions of the experts up the tree with the final prediction output by the root .The parameters of the gat- ing networks are learned using Expectation Maximization algorithm [ 10].", "label": "", "metadata": {}, "score": "54.056168"}
{"text": "The original data set for PCA contained 6 different senses , but we only used the two that were very similar for our experiments .We used a simple \" full - form substitution \" method to automatically generate a data set for the experiments described in this paper , and this dataset was partitioned into training and testing sets .", "label": "", "metadata": {}, "score": "54.081917"}
{"text": "In particular , the cross - validation folds are the same for all the experiments on each data set .Finally , we compared related algorithms via two - tailed .-test with a 95 percent confidence level .According to the statistical theory , we speak of two results for a data set as being \" significantly different \" only if the probability of significant difference is at least 95 percent [ 30 ] .", "label": "", "metadata": {}, "score": "54.148216"}
{"text": "Saeys Y , Inza I , Larra\u00f1aga P : A review of feature selection techniques in bioinformatics .Bioinformatics 2007 , 23 : 2507 - 2517 .View Article PubMed .Guyon I , Weston J , Barnhill S , Vapnik V : Gene selection for cancer classification using support vector machines .", "label": "", "metadata": {}, "score": "54.16087"}
{"text": "Forman G : An extensive empirical study of feature selection metrics for text classification .J Machine Learning Research 2003 , 3 : 1289 - 1305 .View Article .Zheng C , Kurgan L : Prediction of beta - turns at over 80 % accuracy based on an ensemble of predicted secondary structures and multiple alignments .", "label": "", "metadata": {}, "score": "54.199753"}
{"text": "Implementation and Results .Overview of the PoGO classifier .Protein functional annotation is a multi - label classification problem in which each protein may be assigned one or more GO terms .Various approaches may be applied to solving multi - label classification problems , but the simplest method , and the one we employed , is to consider each GO term as an independent classification problem .", "label": "", "metadata": {}, "score": "54.328773"}
{"text": "Liu H , Johnson SB , Friedman C : Automatic resolution of ambiguous terms based on machine learning and conceptual relations in the UMLS .J Am Med Inform Assoc 2002 , 9 : 621 - 636 .View Article PubMed .Sehgal AK , Srinivasan P , Bodenreider O : Gene terms and English words : An ambiguous mix .", "label": "", "metadata": {}, "score": "54.33155"}
{"text": "Both authors read and approved the final manuscript .Authors ' Affiliations .Exagen Diagnostics , Inc. Houston .Department of Electrical and Computer Engineering , Texas A&M University .References .Schena M , Shalon D , Davis RW , Brown PO : Quantitative monitoring of gene expression patterns with a complementary DNA microarray .", "label": "", "metadata": {}, "score": "54.398445"}
{"text": "For experiments aimed at answering a clinical question , such information might include patient disease stage , or response to a particular drug .The cost of producing adequately annotated datasets has been a barrier to the widespread application of microarray technology in medicine .", "label": "", "metadata": {}, "score": "54.551598"}
{"text": "Thus , MI can be used as a means to estimate the amount of information interaction between a context work and a class label .So , MI is used to select the context words with the highest discriminating capability between . and .", "label": "", "metadata": {}, "score": "54.571884"}
{"text": "Conclusions .In many real - world applications , classification is often required to make optimal decisions .In this paper , we summarize the existing improved algorithms for naive Bayes and propose a novel Bayesian classifier model : BC - OM .We conducted a systematic experimental study on a number of UCI datasets .", "label": "", "metadata": {}, "score": "54.60228"}
{"text": "When the degree of difficulty is very high , increasing the sample size will not help much unless an extraordinarily large size is used , which would be very costly .There are different types of WSD and some are more difficult than others .", "label": "", "metadata": {}, "score": "54.673405"}
{"text": "We obtained the data from the project of Wang et al .[ 9 ] .From their data , we tested the biomedical entity names that occur in at least two species with at least 3 occurrences in each species .This enables us to use two instances for training and one for testing and repeat it three times .", "label": "", "metadata": {}, "score": "54.72062"}
{"text": "Page 11 .of We first compute the pairwise similarity matrix Wn \u00d7 n for the protein sequences in the training set based on a com- mon global sequence alignment method .Second , using this similarity matrix , we apply 2-way spectral clustering algorithm , described in the next subsection , to recursively bipartition the training set of protein sequences until a splitting criterion is met .", "label": "", "metadata": {}, "score": "54.780807"}
{"text": "With any classifier , it is possible to tradeoff the Precision against Recall .Hence , it is more informative to compare the Precision - Recall curves which show the tradeoff over their entire range of possible values than to compare the performance of the classifiers for a particular choice of the tradeoff .", "label": "", "metadata": {}, "score": "54.851185"}
{"text": "Z. Zheng and R. Srihari , \" Optimally combining positive and negative feature for text categorization , \" in Proceedings of the Workshop on Learning from Imbalanced Data Sets II ( ICML ' 03 ) , 2003 .C. D. Manning and H. Schutze , Foundations of Statistical Natural Language Processing , The MIT Press , 1999 .", "label": "", "metadata": {}, "score": "54.88594"}
{"text": "Hatzivassiloglou V , Duboue PA , Rzhetsky A : Disambiguating proteins , genes , and RNA in text : a machine learning approach .Bioinformatics 2001 , 17 ( Suppl 1 ) : S97 - 106 .PubMed .Chen L , Liu H , Friedman C : Gene name ambiguity of eukaryotic nomenclatures .", "label": "", "metadata": {}, "score": "54.931763"}
{"text": "The classifier will be then used to disambiguate unseen and unlabeled examples in the application phase .One of the main strength of this method is that the features are selected for learning and classification .Feature Selection The features selected from the training examples have great impact on the effectiveness of the machine learning technique .", "label": "", "metadata": {}, "score": "54.993835"}
{"text": "The results of our experiments show that global sequence similarity can be exploited to improve the performance of classifiers trained to label biomolecular sequence data .Conclusion : The mixture of experts model helps improve the performance of machine learning methods for identifying functionally important sites in biomolecular sequences .", "label": "", "metadata": {}, "score": "55.01203"}
{"text": "Page 4 .Hence , we conclude that global similarity is helpful in improving the perform- ance of classifiers trained to label biomolecular sequence data .An ensemble of classifiers [ 7,8 ] is simply a collection of classifiers , each trained on a bal- anced subsample of the training data .", "label": "", "metadata": {}, "score": "55.02791"}
{"text": "Aronson AR : Effective mapping of biomedical text to the UMLS Metathesaurus : the MetaMap program .Proc AMIA Symp 2001 , 17 - 21 : 17 - 21 .Weeber M , Klein H , Aronson AR , Mork JG , de Jong - van den Berg LT , Vos R : Text - based discovery in biomedicine : the architecture of the DAD - system .", "label": "", "metadata": {}, "score": "55.03273"}
{"text": "The discussion so far has derived the independent feature model , that is , the naive Bayes probability model .The naive Bayes classifier combines this model with a decision rule .One common rule is to pick the hypothesis that is most probable ; this is known as the maximum a posteriori or MAP decision rule .", "label": "", "metadata": {}, "score": "55.06626"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" for BSA , RSV and PCA data sets with fixed distribution of \" ( 0.5 , 0.5 ) \" using 5-fold cross validation .Discussion .Issues and our experiments .", "label": "", "metadata": {}, "score": "55.116863"}
{"text": "Our results as shown in Table 8 are not directly comparable with those in Table 7 due to the difference in the size of test set .However , we can see that our method 's performance is reasonably well standing in terms of precision , recall , and F1 .", "label": "", "metadata": {}, "score": "55.14724"}
{"text": "Chalmel F , Lardenois A , Thompson JD , Muller J , Sahel JA , Leveillard T , Poch O : GOAnno : GO annotation based on multiple alignment .Bioinformatics 2005 , 21 ( 9 ) : 2095 - 2096 .PubMed View Article .", "label": "", "metadata": {}, "score": "55.15504"}
{"text": "Feature selection using the hybrid and wrapper - based approaches clearly improved naive Bayes , SVM , and C4.5 decision tree .Discussion .We have compared three classification algorithms including naive Bayes , SVM , and C4.5 decision tree in the presence and absence of feature selection techniques to address the problem of modeling in CFS .", "label": "", "metadata": {}, "score": "55.18309"}
{"text": "442 - 449 , 2011 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . S. Nikolajewa , R. Pudimat , M. Hiller , M. Platzer , and R. Backofen , \" BioBayesNet : a web server for feature extraction and Bayesian network modeling of biological sequence data , \" Nucleic acids research , vol .", "label": "", "metadata": {}, "score": "55.199276"}
{"text": "Then the probability that a given document D contains all of the words , given a class C , is .( This technique of \" log - likelihood ratios \" is a common technique in statistics .In the case of two mutually exclusive alternatives ( such as this example ) , the conversion of a log - likelihood ratio to a probability takes the form of a sigmoid curve : see logit for details . )", "label": "", "metadata": {}, "score": "55.233574"}
{"text": "e . s . . .( .We also use the baseline method which is the most frequent sense ( mfs ) for each word .This lead , to a total of 31 words tested in this evaluation , and 18 words were dropped because they do not have at least two instances annotated for each one of two senses .", "label": "", "metadata": {}, "score": "55.2475"}
{"text": "If small data sets lead to overfitting , then we would expect to see a correlation between data set size and classifier performance [ 34 ] , where classifiers trained with a smaller number of proteins would tend to have higher performance .We compared the performance vs. dataset size for GO terms that were present in the taxon specific and the randomly undersampled datasets but found no correlation in any dataset ( Table S2 , Additional File 1 ) .", "label": "", "metadata": {}, "score": "55.27464"}
{"text": "Inputs were the SNP genetic markers .Outputs were the CFS status .In our study , we used the following four kernels [ 21 , 22 ] : .The parameter \u03b3 was set to 0.05 when we evaluated SVM based on the feature section procedures described in the next section .", "label": "", "metadata": {}, "score": "55.287178"}
{"text": "In addition , they can be applied rapidly and consistently to large datasets , saving many hours of human curation .Draft genome sequences and machine generated gene models are becoming available for an increasing number of fungal species but machine annotations of protein functions are still limited .", "label": "", "metadata": {}, "score": "55.31689"}
{"text": "Moreover , Geortzel and colleagues showed that the COMT , NR3C1 , and TPH2 genes were associated with CFS using SVM without feature selection [ 9 ] .A study by Lin and Huang also identified significant SNPs in SLC6A4 , CRHR1 , TH , and NR3C1 genes using a Bayesian variable selection method [ 14 ] .", "label": "", "metadata": {}, "score": "55.408028"}
{"text": "Figure 9 shows the tree structure produced by the 2-way spectral clustering algorithm when applied to a set of 147 RNA - protein sequences .The similarity matrix is com- puted based on the Needleman - Wunsch global alignment algorithm .In the figure , to keep the tree smaller , we stopped bipartitioning a node when the number of sequences at a given cluster falls below 30 % of the total sequences in the training set .", "label": "", "metadata": {}, "score": "55.422157"}
{"text": "The authors begin by referring to the work of Feature Subset Selection and state that how to determine the rate of crossover and mutation is a problem in GA . .The authors appear first present a new search engine FSS - ENBA for feature subset selection .", "label": "", "metadata": {}, "score": "55.518295"}
{"text": "Quinlan JR : C4.5 : Programs for Machine Learning .San Francisco , CA , USA : Morgan Kaufmann Publishers 1993 .Breiman L , Friedman JH , Olshen RA , Stone CJ : Classification and regression trees .Boca Raton , FL , USA : CRC Press 1995 .", "label": "", "metadata": {}, "score": "55.707657"}
{"text": "In this work we sought to improve the performance of classifiers that make predictions on residues in protein sequences by taking into account the global similarity between the protein sequences in the data set in addition to the local features extracted around each residue .", "label": "", "metadata": {}, "score": "55.71219"}
{"text": "In our experiments , missing values are replaced with the modes and means of the corresponding attribute values from the available data .For example , if the sex of someone is missing , it can be replaced by the mode ( the value with the highest frequency ) of the sexes of all the others .", "label": "", "metadata": {}, "score": "55.71582"}
{"text": "W688 - 693 , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Google Scholar .M. Minsky , \" Steps toward artificial intelligence , \" Proceedings of the Institute of Radio Engineers , vol .", "label": "", "metadata": {}, "score": "55.81083"}
{"text": "Summary statistics and performance evaluation of the taxon - specific classifiers .Performance comparison of the InterPro base - classifier on taxon - specific and the UniProt training datasets .No F - measure threshold was applied while computing the performance metrics .We compared the performance of classifiers trained with each of these data sets using 10-fold cross validation as described previously .", "label": "", "metadata": {}, "score": "55.82198"}
{"text": "The results of our experiments show that global sequence similarity can be exploited to improve the performance of classifiers trained to label biomolecular sequence data .The mixture of experts model helps improve the performance of machine learning methods for identifying functionally important sites in biomolecular sequences .", "label": "", "metadata": {}, "score": "55.83571"}
{"text": "For example , progress on sequenc- ing technologies has resulted in the release of hundreds of complete genome sequences .With the exponentially from IEEE International Conference on Bioinformatics and Biomedicine ( BIBM ) 2008 Philadelphia , PA , USA .Page 2 .", "label": "", "metadata": {}, "score": "55.843395"}
{"text": "Mohammad S , Pedersen T : Combining lexical and syntactic features for supervised word sense disambiguation .Proc of the CoNLL .Wilks Y , Fass D , Guo C , MacDonald J , Plate T , Slator B : Providing Machine Tractable Dictionary Tools Cambridge , MA : MIT Press 1990 .", "label": "", "metadata": {}, "score": "55.87259"}
{"text": "B. L. Humphreys , D. A. B. Lindberg , H. M. Schoolman , and G. O. Barnett , \" The unified medical language system : an informatics research collaboration , \" Journal of the American Medical Informatics Association , vol .5 , no . 1 , pp . 1 - 11 , 1998 .", "label": "", "metadata": {}, "score": "55.881767"}
{"text": "BC - OM Algorithm and Its Correctness .In this subsection , we present the main algorithm of this paper .Our method starts with finding the best Bayesian classifier by solving the above optimization model .Second , we use the d - separation rule of Bayesian network to delete irrelevant or redundant attributes in the network which have low dependence degree with the class variable .", "label": "", "metadata": {}, "score": "55.88683"}
{"text": "Shi J , Malik J : Normalized cuts and image segmentation .Pattern Analysis and Machine Intelligence 2000 , 22(8):888 - 905 .Dhillon IS : Co - clustering documents and words using bipartite spectral graph partitioning .Proceedings of SIGKDD International Conference on Knowledge Discovery and Data Mining 2001:269", "label": "", "metadata": {}, "score": "56.139008"}
{"text": "Our heuristic significantly reduces the scheduling delay in the execution of experts when re - execution of the task - compression algorithm is not needed from O(N2 ) time , where N denotes the number of experts , to O(N ) time .Experimental evaluation of the heuristic on a test case in motor control shows that these time savings occur and scheduled experts ' deadlines are met in up to 90 % of all cycles .", "label": "", "metadata": {}, "score": "56.306778"}
{"text": "This figure shows the plots of ' ' error rate ' ' versus ' ' sample size ' ' with different sense distributions of PCA data set ( case where the 2 ambiguous senses are very similar ) using 5-fold cross validation .", "label": "", "metadata": {}, "score": "56.31359"}
{"text": "Each feature was measured and ranked according to its merit in both methods .The measurement of the merit for the two methods is defined as follows .The information - gain method measures the decrease in the entropy of a given feature provided by another feature , and the chi - squared method is based on Pearson chi - squared statistic to measure divergence from the expected distribution .", "label": "", "metadata": {}, "score": "56.392654"}
{"text": "A description of the different multi - class algorithms is provided in the Methods section .Table 5 .Results for BPD data set .Annotation of the table : Dist : Distribution of senses ; S. Size : sample size ; Err .", "label": "", "metadata": {}, "score": "56.426895"}
{"text": "In this study , we used 4 abbreviations from Liu 's abbreviation list .However , we used a different method to collect the datasets because we wanted to control the sample sizes of the senses for our experiments .Leroy [ 30 ] tried to reduce the training sample size by supplying external knowledge from the UMLS for supervised machine learning algorithms , but the results were not promising .", "label": "", "metadata": {}, "score": "56.513565"}
{"text": "and we get .Conclusions .As we have seen , the spam filtering process can be separated into two parts .An offline process where you have a lot of mails already classified by someone , and train the classifier .And an online process where you test a document to classify it using the model previously created .", "label": "", "metadata": {}, "score": "56.578438"}
{"text": "Moreover , following the same intuitive reasoning of mutual information , MI , we define another method , M2 , for selecting the words as features to be included in the feature vectors as follows : .M .In the following example , assume that the target word .", "label": "", "metadata": {}, "score": "56.614754"}
{"text": "The test selects the feature with the highest normalized information gain as the root node .Then , the C4.5 algorithm finds the rest nodes of the tree recursively on the smaller sub - lists of features according to the test .In addition , feature selection is an inherent part of the algorithm for decision trees [ 24 ] .", "label": "", "metadata": {}, "score": "56.64799"}
{"text": "We use the pepstat and compseq programs in EMBOSS [ 26 ] to compute the biochemical properties based on the amino acid sequence of each protein .Unlike the previous datasets , the biochemical properties are not sparse , and are numeric rather than binary .", "label": "", "metadata": {}, "score": "56.77127"}
{"text": "Considering only the base classifiers , the InterPro term classifier had the highest average F - measure value ( Table 1 ) .Surprisingly , the BLAST classifier had low F - measure as well as the lowest specificity , indicating that it results in a large number of false - positive annotations .", "label": "", "metadata": {}, "score": "56.879646"}
{"text": "For each abbreviation , we measured error rates of the SVM classifier under different combinations of sample size , sense distribution , cross validation scheme ( 5-fold vs. 10-fold ) , and multi - class SVM algorithms ( for BPD only , which has 3 different senses ) .", "label": "", "metadata": {}, "score": "56.924023"}
{"text": "We evaluate our approach to learning a mixture of experts model on two biomolecular sequence labeling tasks : RNA- and DNA - protein interface predic- tion tasks .Results The main result of our study is that taking into account global sequence similarity through the means of a mixture of experts model can improve the performance of the clas- sifiers trained to label biomolecular sequence data .", "label": "", "metadata": {}, "score": "56.925697"}
{"text": "G. Chartrand and P. Zhang , Introduction to Graph Theory , McGraw - Hill , New York , NY , USA , 2005 .R. E. Neapolitan , Learning Bayesian Networks , Prentice Hall , Englewood Cliffs , NJ , USA , 2004 .", "label": "", "metadata": {}, "score": "56.968117"}
{"text": "In addition , the tab - separated data files of the GO annotations are available for download , enabling to import of the data into other programs .The classification algorithms , undersampling , feature selection and the computation of performance metrics were performed in MATLAB [ 35 ] using the pattern recognition toolbox [ 36 ] .", "label": "", "metadata": {}, "score": "57.01269"}
{"text": "Datasets are German , soybean , chess , anneal and mushroom from UCI repository .The populations have 2000 individuals .Classifier is a naive Bayes ( NB ) .The authors claim that the FEDA can get a more compact classifier with higher accuracy and less actual evaluations compare with FSS - ENBA .", "label": "", "metadata": {}, "score": "57.05622"}
{"text": "Follow are the data set used in experiments .The first four data sets are available in the UCI repository [ Blake and Merz , 1998].The definition of Random21 is from the paper by [ Inza et al . 2000].", "label": "", "metadata": {}, "score": "57.087517"}
{"text": "Mahout was designed with this in mind .Most of its algorithms were tailored to work over Hadoop .But the interesting thing is that they can also work without it for testing purposes , or when you must incorporate the algorithms to a server without the needs of distributed computation , like how we did in this post .", "label": "", "metadata": {}, "score": "57.18986"}
{"text": "25 , no . 3 , pp .394 - 400 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. Chen and H. Al - Mubaid , \" Context - based term disambiguation in biomedical literature , \" in Proceedings of the 19th International Florida Artificial Intelligence Research Society Conference ( FLAIRS ' 06 ) , pp .", "label": "", "metadata": {}, "score": "57.2041"}
{"text": "PubMed View Article .Forslund K , Sonnhammer ELL : Predicting protein function from domain content .Bioinformatics 2008 , 24 ( 15 ) : 1681 - 1687 .PubMed View Article .Falkenauer E : On Method Overfitting .J Heuristics 1998 , 4 ( 3 ) : 281 - 287 .", "label": "", "metadata": {}, "score": "57.309597"}
{"text": "This is the event model typically used for document classification , with events representing the occurrence of a word in a single document ( see bag of words assumption ) .The likelihood of observing a histogram x is given by .If a given class and feature value never occur together in the training data , then the frequency - based probability estimate will be zero .", "label": "", "metadata": {}, "score": "57.325676"}
{"text": "The results of Wang et al . are shown in Table 7 , whereas the results of our proposed system are shown in Table 8 in terms of precision , recall , and F1 .Table 8 : Precision , recall , and F1 results of our method on the fivefold in the species disambiguation experiments .", "label": "", "metadata": {}, "score": "57.368816"}
{"text": ", m , the task is to learn a classifier that can predict the labels for each element of a new input sequence , xtest .There is a large body of work on learning predictive mod- els to label biomolecular sequence data .", "label": "", "metadata": {}, "score": "57.381138"}
{"text": "For the details of the ambiguity study , please refer to the sub - section \" Gene Ambiguity for mining MEDLINE \" in the Methods section .Research in automated WSD can be traced back to the 1950s [ 15 ] .A number of WSD methods have been addressed for the general English domain .", "label": "", "metadata": {}, "score": "57.39739"}
{"text": "View at Scopus . H. Al - Mubaid , \" Context - based technique for biomedical term classification , \" in Proceedings of the IEEE Congress on Evolutionary Computation ( CEC ' 06 ) , pp .5726 - 5733 , Vancouver , Canada , July 2006 .", "label": "", "metadata": {}, "score": "57.4356"}
{"text": "Third , classification is done by applying obtained classifier to predict the class label of test data .We prove the correctness of proposed method under the faithfulness assumption for the data distribution .From the detailed steps of BC - OM , we can see that BC - OM classifier relaxes the restrictions on condition variable and further meets the need of practical application .", "label": "", "metadata": {}, "score": "57.440056"}
{"text": "Since our goal is to develop a classifier for fungal proteins the previous experiments were performed with a training dataset comprised only of proteins from fungi .Larger training datasets generally result in more robust classifiers so we evaluated the performance of PoGO when non - fungal proteins are included in the training data .", "label": "", "metadata": {}, "score": "57.446194"}
{"text": "Overall classifier performance after excluding poorly performing GO term classifiers .Properties were computed after removing individual GO term classifiers with an F - measure below the indicated threshold .As shown in Table 3 , PoGO outperforms the other classifiers by a considerable margin .", "label": "", "metadata": {}, "score": "57.484444"}
{"text": "The hierarchical structure of the mixture of experts model is constructed based on global sequence similarity .Page 6 .The prediction of the ensemble of classifiers is computed from the predictions of the indi- vidual classifiers using majority voting .An example is misclassified by the ensemble if a majority of the classifi- ers misclassifies it .", "label": "", "metadata": {}, "score": "57.570297"}
{"text": "To further analyze the effects of \" sample size \" , \" sense distribution \" and \" degree of difficulty \" on the error rate , an error decomposition model will be explored .Methods to measure the degree of distances among different senses are also being studied .", "label": "", "metadata": {}, "score": "57.601833"}
{"text": "Ginter F , Boberg J , Salakoski T , Salakoski T : New Techniques for Disambiguation in Natural Language and Their Application to Biological Text .Journal of Machine Learning Research 2004 , 5 : 605 - 621 .Podowski RM , Cleary JG , Goncharoff NT , Amoutzias G , Hayes WS : AZuRE , a scalable system for automated term disambiguation of gene and protein names .", "label": "", "metadata": {}, "score": "57.623108"}
{"text": "The accuracy of each model is based on the percentage of successful predictions on the test sets of each data set .In all experiments , the accuracy of each model on each data set are obtained via 10 runs of 5-fold cross validation .", "label": "", "metadata": {}, "score": "57.650726"}
{"text": "The ngrams are groups of words .Giving more ngrams you add more context to each word ( surrounding words ) .The most ngrams you use the better the results should be .We are using 1 because the better results obviously cost more processing time .", "label": "", "metadata": {}, "score": "57.66871"}
{"text": "We construct a feature vector .for the instance .the same way as in the learning step .The induced learning model ( classifier ) from the learning step will be employed to classify it ( assign .to one of the two senses .", "label": "", "metadata": {}, "score": "57.714207"}
{"text": "Markatou M , Tian H , Biswas S , Hripcsak G : Analysis of variance of cross - validation estimators of the generalization error .Journal of Machine Learning Research 2005 , 6 : 1127 - 1168 .Resnik P , Yarowsky D : Distinguishing systems and distinguishing senses : New evaluation tools for words sense disambiguation .", "label": "", "metadata": {}, "score": "57.71891"}
{"text": "PubMed View Article .Clare A , King RD : Predicting gene function in Saccharomyces cerevisiae .Bioinformatics 2003 , 19 ( S2 ) : 42 - 49 .Deng XG , Huimin , Ali HH : Learning Yeast Gene Functions from Heterogeneous Sources of Data Using Hybrid Weighted Bayesian Networks .", "label": "", "metadata": {}, "score": "57.759007"}
{"text": "Dietterich TG : Approximate statistical tests for comparing supervised classification learning algorithms .Neural Computation 1998 , 10 : 1895 - 1924 .View Article PubMed .Salzberg SL : On comparing classifiers : Pitfalls to avoid and a recommended approach .Data Mining and Knowledge Discovery 1997 , 1 : 317 - 328 .", "label": "", "metadata": {}, "score": "57.79293"}
{"text": "In one instance , c - myc might refer to a human gene , while in another instance it refers to a mouse gene .For example , in Table 3 , the biomedical entity name BCL-2 ( a protein name ) in the first text ( no . 1 ) is human while in the second one is a mouse protein .", "label": "", "metadata": {}, "score": "57.82051"}
{"text": "An additional issue is that this study limited the disambiguation of gene symbols to gene senses and one other category called \" non - gene sense \" , but the actual sense in this category was not resolved .This could be critical for NLP systems accessing phenotypic or disease - related information .", "label": "", "metadata": {}, "score": "57.889877"}
{"text": ": Semi - supervised analysis of gene expression profiles for lineage - specific development in the Caenorhabditis elegans embryo .Bioinformatics 2006 , 22 ( 14 ) : e417 - 423 .View Article PubMed .Armstrong SA , et al .: MLL translocations specify a distinct gene expression profile that distinguishes a unique leukaemia .", "label": "", "metadata": {}, "score": "57.939644"}
{"text": "View Article PubMed .Friedman M : The use of ranks to avoid the assumption of normality implicit in the analysis of variance .Journal of the American Statistical Association 1937 , 32 : 675 - 701 .View Article .Rifkin R , Klatau A : In defense of one - vs - all classification .", "label": "", "metadata": {}, "score": "57.94255"}
{"text": "Ng HT , Lee HB : Integrating multiple knowledge sources to disambiguate word sense : An examplar - based approach .Proc 34th Ann Meeting Assoc for Comput Ling 40 - 47 .Merkel M , Andersson M : Combination of contextual features for word sense disambiguation .", "label": "", "metadata": {}, "score": "57.955734"}
{"text": "This , in effect , would cause GO terms that are never found within a taxonomic group to be removed from the classifier , thus the error of the individual GO term classifier does not contribute to the overall error of the system .", "label": "", "metadata": {}, "score": "57.969063"}
{"text": "Yan C , Dobbs D , Honavar V : A Two - Stage Classifier for Identi- fication of Protein - Protein Interface Residues .Bioinformatics 2004 , 20(Suppl 1):i371-i378 .Qian N , Sejnowski T : Predicting the secondary structure of globular proteins using neural networks models .", "label": "", "metadata": {}, "score": "57.981766"}
{"text": "When you train the classifier you provide it with a file ( yes , a single file ) that contains one document per line , already analyzed .\" Analyzed \" in the same sense that Lucene analyzes documents .In fact what we are going to use is the Lucene StandardAnalizer to clean a little the documents and transform them into a stream of terms .", "label": "", "metadata": {}, "score": "58.01425"}
{"text": "We also found that taxon - specific classifiers have significantly better performance than species independent systems .Functional annotations provided by PoGO are being used for fungal comparative genomics projects in our research group .We also provide a public web server where users can annotate protein sequences .", "label": "", "metadata": {}, "score": "58.0473"}
{"text": "If each ambiguous gene symbol in an article were accompanied by its corresponding long form , the disambiguation task would be much easier .Schijvenaars [ 13 ] showed that 33 % of the human genes in their thesaurus were affected by homonymy .", "label": "", "metadata": {}, "score": "58.082645"}
{"text": "Since the data sets are highly imbalanced , we perform undersampling of the negative class as described previously [ 19 ] .This step removes members of the negative class so that the training dataset will have the same number of proteins as the positive class .", "label": "", "metadata": {}, "score": "58.114876"}
{"text": "In the multivariate Bernoulli event model , features are independent booleans ( binary variables ) describing inputs .Like the multinomial model , this model is popular for document classification tasks , [ 9 ] where binary term occurrence features are used rather than term frequencies .", "label": "", "metadata": {}, "score": "58.18444"}
{"text": "The experimental platform is a personal computer with Pentium 4 , 3.06 GHz CPU , 0.99 GB memory , and Windows XP .Our implementation is based on the BayesNet Toolbox for Matlab [ 29 ] , which provides source code to perform several operations on Bayesian networks .", "label": "", "metadata": {}, "score": "58.192696"}
{"text": "We utilized the training corpus of the labeled instances of the word to be disambiguated to compile the list of all context words ( . as explained above ; all instances of one sense are under one class label .We notice that if the context word , . , is mostly occurring in class .", "label": "", "metadata": {}, "score": "58.19561"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of BPD data set ( where there are 3 ambiguous senses that are different ) using 5-fold cross validation and \" one - vs - rest \" algorithm .", "label": "", "metadata": {}, "score": "58.264984"}
{"text": "Several classifiers have also been developed that utilize features from laboratory experiments such as gene expression profiles [ 7 , 8 ] , and protein - protein interactions [ 8 , 9 ] .A classifier is used to determine the relationships between protein features and their potential functions .", "label": "", "metadata": {}, "score": "58.275272"}
{"text": "Furthermore , the set of proteins used for evaluation is not consistent among all of the protein function classifiers .Authors usually employ cross - validation in order to evaluate their classifier using hold - out sets from the training data set .Standard protein data sets have been developed for annual competitions , such as the one that is often held in conjunction with the Annual International Conference on Intelligent Systems for Molecular Biology ( ISMB ) but these data sets are not useful for taxon specific classifiers such as PoGO .", "label": "", "metadata": {}, "score": "58.428215"}
{"text": "[ 15 ] .By using feature selection techniques , the key goal is to find responsible genes and SNPs for certain diseases or certain drug efficacy .It is vital to select a small number of SNPs that are significantly more influential than the others and ignoring the SNPs of lesser significance , thereby allowing researchers to focus on the most promising candidate genes and SNPs for diagnostics and therapeutics [ 16 , 17 ] .", "label": "", "metadata": {}, "score": "58.54135"}
{"text": "Comparison of F - Measure for Na\u00efve Bayes and mixture of Na\u00efve Bayes models on the DNA - protein data set Figure 8 Comparison of F - Measure for Na\u00efve Bayes and mixture of Na\u00efve Bayes models on the DNA - protein data set .", "label": "", "metadata": {}, "score": "58.578766"}
{"text": "The best result of Stevensons-2008 for subsets was 85.1 % using a subset of 22 words defined by Stevenson et al .[ 1 ] .The results of the three methods ( single , subset , full ) in Table 6 are taken directly from Agirre et al .", "label": "", "metadata": {}, "score": "58.586853"}
{"text": "The evaluation results showed that the approach is very competitive and outperforms recently reported results of other published techniques .Introduction .Word sense disambiguation is the task of determining the correct sense of a given word in a given context .In the general language domain , and within natural language processing ( NLP ) , the word sense disambiguation ( WSD ) problem has been studied and investigated extensively over the past few decades [ 1 , 2 ] .", "label": "", "metadata": {}, "score": "58.59659"}
{"text": "Therefore , although we studied only four abbreviations , the results concerning sample size , sense similarity , and distributions are likely to be generalizable for abbreviations with similar characteristics .The results presented here agree with general results presented in the literature on the performance of classifiers [ 43 - 45 ] .", "label": "", "metadata": {}, "score": "58.621326"}
{"text": "This article has been published as part of BMC Bioinformatics Volume 10 Sup- plement 4 , 2009 : Proceedings of the IEEE International Conference on Bio- informatics and Biomedicine ( BIBM ) 2008 .References 1 .Terribilini M , Lee JH , Yan C , Jernigan RL , Honavar V , Dobbs D : Pre- dicting RNA - binding Sites from Amino Acid Sequence .", "label": "", "metadata": {}, "score": "58.62367"}
{"text": "The system achieved an accuracy rate of 92.7 % on an automatically generated testing set .Schijvenaars 's study described an effective method for gene disambiguation , but the evaluation results were limited to certain conditions .The automatically generated testing set contained human genes symbols that appeared as long - form and short - form pairs ( e.g. prostate specific antigen ( PSA ) ) in articles , where at least 6 articles were determined to be associated with each gene sense .", "label": "", "metadata": {}, "score": "58.69102"}
{"text": "A number of automated methods have been developed in recent years that vary both in the sources of features used as evidence for the classifier and in the classification algorithm used to assign protein functions .The most common feature types rely on sequence similarity , often using BLAST [ 2 ] to identify similar proteins from a large database .", "label": "", "metadata": {}, "score": "58.699196"}
{"text": "CH and NG were employees of Exagen Diagnostics during the course of this research and the preparation of this manuscript .Additionally , CH owns stock in Exagen Diagnostics .Authors ' contributions .CH devised and implemented the GLAD algorithm , and contributed to the final preparation of the manuscript .", "label": "", "metadata": {}, "score": "58.732803"}
{"text": "The main weakness of the supervised and machine - learning - based methods for WSD is their dependency on the annotated training text which includes manually disambiguated instances of the ambiguous word [ 2 , 17 ] .However , over the time , the increasing volumes of text and literature in very high rates and the new algorithms and techniques for text annotation and concept mapping will alleviate this problem .", "label": "", "metadata": {}, "score": "58.734413"}
{"text": "For example , a simple feature vector of size 5 can be as follows : .This feature vector represents an instance that has the first , third , and fourth context words available in its context , and 1.23 is the MI value of the context word with the highest MI .", "label": "", "metadata": {}, "score": "58.780403"}
{"text": "To estimate the parameters for a feature 's distribution , one must assume a distribution or generate nonparametric models for the features from the training set .[ 8 ] .The assumptions on distributions of features are called the event model of the Naive Bayes classifier .", "label": "", "metadata": {}, "score": "58.82496"}
{"text": "It is clear that in some situations , it would be useful to model correlations among attributes .BC - OM is a good tradeoff between the quality of the approximation of correlations among attributes and the computational complexity in the learning stage .", "label": "", "metadata": {}, "score": "58.894825"}
{"text": "In addition , many of the previously published protein function annotation systems utilize features obtained from laboratory experiments such as transcriptional profiling or protein - protein interaction assays .These methods can not be applied to most fungal proteomes since experimental data are not available .", "label": "", "metadata": {}, "score": "58.914257"}
{"text": "Meanwhile , we also recorded the percentage of ambiguous words that were removed from the ambiguous word - list for different thresholds .We removed words with frequencies higher than 10 % , 1 % , 0.1 % and 0.05 % from the two lists of the mouse organism .", "label": "", "metadata": {}, "score": "58.9273"}
{"text": "King RD , Karwath A , Clare A , Dephaspe L : Genome scale prediction of protein functional class from sequence using data mining .Proc of the sixth ACM SIGKDD Inter Conf on Knowledge discovery and data mining 2003 .Pellegrini M , Marcotte EM , Thompson MJ , Eisenberg D , Yeates TO : Assigning protein functions by comparative genome analysis : Protein phylogenetic profiles .", "label": "", "metadata": {}, "score": "58.943016"}
{"text": "Aliferis CF , Statnikov A , Tsamardinos I , Schildcrout JS , Shepherd BE , Harrell FE Jr : Factors influencing the statistical power of complex data analysis protocols for molecular signature development from microarray data .PLoS One 2009 , 4 : e4922 .", "label": "", "metadata": {}, "score": "59.020317"}
{"text": "To exemplify , assume the pair consisted of the error rates obtained under sample size 20 and 40 .Then the set of observations was comprised of those error rates obtained from the 30 simulation runs .The null hypothesis would be that the median error rate when the sample size is 20 equals the median error rate when the sample size is 40 .", "label": "", "metadata": {}, "score": "59.077507"}
{"text": "The rationale of selecting these SNPs is described in detail elsewhere [ 8 ] .Briefly , most of these SNPs are intronic or intergenic except that rs4633 ( COMT ) , rs1801291 ( MAOA ) , and rs6196 ( NR3C1 ) are synonymous coding changes [ 8 ] .", "label": "", "metadata": {}, "score": "59.164288"}
{"text": "Against this background , we hypothesize that classifiers trained to label biomolecular sequence data can be improved by taking into account the global sequence sim- ilarity between the protein sequences in addition to the local features extracted around each site .The intuition behind this hypothesis is that the more similar two sequences are , the greater the likelihood that their func- tional sites have similar patterns .", "label": "", "metadata": {}, "score": "59.18714"}
{"text": "This analysis revealed that in the case of BSA the improvements in terms of error rate were statistically significant across distributions as the sample size increased from 20 to 40 .For the case of RSV , a much more substantial four - fold increase in the sample size was needed in order to observe an appreciable decrease of the error rate .", "label": "", "metadata": {}, "score": "59.31005"}
{"text": "Applied Bioinformatics 2005 , 4 ( 3 ) : 195 - 203 .PubMed .Rice PL , Ian , Bleasby A : EMBOSS :The European Molecular Biology Open Software Suite .Trends Genet 2000 , 16 ( 6 ) : 276 - 277 .", "label": "", "metadata": {}, "score": "59.323036"}
{"text": "The datastore represents the model that you previously created training the classifier .We are using a InMemoryBayesDatastore ( there is also HbaseBayesDatastore that uses the Hadoop database ) , and we are providing it the base path and the ngrams size .We are using ngrams of 1 to simplify this example .", "label": "", "metadata": {}, "score": "59.420624"}
{"text": "When resources are insufficient to run all experts in every cycle , it becomes necessary to execute the most responsible experts within each cycle .The problem of adaptively scheduling experts with dynamic responsibilities can be formulated as a succession of optimization problems .", "label": "", "metadata": {}, "score": "59.598667"}
{"text": "For example , an e - value threshold might be applied to BLAST search results instead of utilizing the e - value directly .The problems with this approach are that the data from each data source is weighted differently and that distinctions between data points can be lost during transformation .", "label": "", "metadata": {}, "score": "59.716137"}
{"text": "The hierarchical structure of the mixture of experts model is constructed based on global sequence similarity .Page 5 .In Figures 1 , 2 , 3 , and 4 we show the PR curves for the mix- ture and the ensemble models on both RNA- and DNA- protein sequence data sets for 30 % identity cutoff .", "label": "", "metadata": {}, "score": "59.755196"}
{"text": "Reliable identification of such interaction sites from protein sequences has broad applications ranging from rational drug design to the analysis of metabolic and signal transduction networks .The RNA- and DNA - protein interface data sets consist of RNA- and DNA - binding protein sequences , respectively , extracted from structures in the Protein Data Bank ( PDB ) [ 11].", "label": "", "metadata": {}, "score": "59.762566"}
{"text": "PubMed View Article .Marcotte EM , Pellegrini M , Thompson MJ , Yeates TO , Eisenberg D : A combined algorithm for genome - wide prediction of protein function .Nature 1999 , 402 ( 6757 ) : 83 - 86 .PubMed View Article .", "label": "", "metadata": {}, "score": "59.76561"}
{"text": "Table 3 : Number of sequences , as well as positive and negative instances used in our experiments for the RNA- and DNA - protein data sets .Number of sequences as well as number of positive ( + ) and negative ( - ) instances in the non - redundant RNA- and DNA - protein sequence data sets for 30 % , 60 % , and 90 % identity cutoffs .", "label": "", "metadata": {}, "score": "59.945187"}
{"text": "All performance metrics were computed using 10-fold cross validation .We calculate the performance of each protein individually , and then report the overall average values .The various classifiers that we tested were all trained using different data sources and were developed to annotate different sets of GO terms .", "label": "", "metadata": {}, "score": "60.023827"}
{"text": "Each context word .or with .or combination and in any distribution .We want to determine that , if we see a context word . suggests that this example belongs to .or to .Thus , we use as features those context words .", "label": "", "metadata": {}, "score": "60.101395"}
{"text": "To understand the effects of increased sample size on the error rate , we stratified by the sense distribution and then tested the null hypothesis of no difference between the error rates obtained under the different sample sizes using the sign test .The sign test is a non - parametric test that does not impose any distributional assumptions , such as normality , on the data .", "label": "", "metadata": {}, "score": "60.132263"}
{"text": "We tested a range of threshold values and compared the performance to our previous classifier Automated Annotation of Protein Functional Class ( AAPFC ) [ 19 ] which only uses InterPro terms as features .We also compared the performance to MultiPfam2GO [ 33 ] a classifier that can assign GO terms to proteins on the basis of protein domains that are described in PFAM .", "label": "", "metadata": {}, "score": "60.15308"}
{"text": "I . and . is the total number of training examples .MI is a well - known concept in information theory and statistical learning .MI is a measure of interaction and common information between two variables [ 22 ] .In this work , we adapted MI to represent the interaction between the context words .", "label": "", "metadata": {}, "score": "60.183258"}
{"text": "Shatkay H , Feldman R : Mining the biomedical literature in the genomic era : an overview .J Comput Biol 2003 , 10 : 821 - 855 .View Article PubMed .Fukuda K , Tamura A , Tsunoda T , Takagi T : Toward information extraction : identifying protein names from biological papers .", "label": "", "metadata": {}, "score": "60.185684"}
{"text": "Notice that if we stratify by the abbreviation , the mean error rates form a two - way table where the columns correspond to different sample sizes and the rows correspond to different sense distributions .The significance of this methodology is that it provides a comprehensive way to quantify the effects of sample size and sense distribution on the error rate .", "label": "", "metadata": {}, "score": "60.405563"}
{"text": "Second , the model was trained by nine - tenths of the data and tested by the remaining tenth of data to estimate the predictive performance .Then , the above procedure was repeated nine more times by leaving out a different tenth of data as testing data and different nine - tenths of the data as training data .", "label": "", "metadata": {}, "score": "60.407326"}
{"text": "1471 - 2105 - 7 - 334-S1.doc Additional File 1 : Supplementary material for gene ambiguity for mining MEDLINE ( DOC 925 KB ) .Authors ' contributions .HX carried out data collection , programming , experiments using SVM and drafted the manuscript .", "label": "", "metadata": {}, "score": "60.4218"}
{"text": "PubMed View Article .Vinayagam A , del Val C , Schubert F , Eils R , Glatting KH , Suhai S , Konig R : GOPET : a tool for automated predictions of Gene Ontology terms .BMC Bioinformatics 2006 , 7 : 161 .", "label": "", "metadata": {}, "score": "60.52574"}
{"text": "Tree - augmented naive Bayes ( TAN ) [ 9 ] is an extended tree - like naive Bayes in which the class node directly points to all attribute nodes and an attribute node can have only one parent from another attribute node .", "label": "", "metadata": {}, "score": "60.54392"}
{"text": "In the biomedical named entity disambiguation , the extracted entity names ( e.g. , gene product names ) will be applied onto a process such that each occurrence should be disambiguated as either gene name or protein name as the same name can refer to a gene or protein .", "label": "", "metadata": {}, "score": "60.590847"}
{"text": "The values of a , b , c , d for .is more highly related with the class . than . , and so it has more discriminating power than . , and this is quantified by their MI values .MI values for . and . are 1.8 and 1.2 , respectively .", "label": "", "metadata": {}, "score": "60.620163"}
{"text": "Figures 1 , 2 and 3 show the error rate versus the sample size for each distribution of the BSA , PCA and RSV data sets with 5-fold cross - validation .As the figures indicate , the reduction of the error rate as a function of the sample size is more dramatic for BSA than for PCA .", "label": "", "metadata": {}, "score": "60.638885"}
{"text": "Let K0 out of K sequences go to the left child node , and K1 out of K go to the right child node .We recursively place the sequence xi in all the nodes of with different weights , starting from the root , based on its estimated cluster membership computed above .", "label": "", "metadata": {}, "score": "60.709885"}
{"text": "There is increasing demand to quickly annotate newly sequenced genomes so that they can be used for designing microarray analyses , proteomics , comparative genomics , and other experiments .It is clear that manual gene function annotation can not be scaled to meet the influx of newly sequenced model organisms .", "label": "", "metadata": {}, "score": "60.73832"}
{"text": "Of all the kernel functions , the linear kernel performed better than the other three kernels in terms of AUC .In addition , with the hybrid approach , the desired numbers of the top - ranked SNPs for the SVM models of linear , polynomial , sigmoid , and Gaussian radial basis function kernels were 14 , 9 , 4 , and 3 out of 42 SNPs , respectively .", "label": "", "metadata": {}, "score": "60.783264"}
{"text": "The resulting feature set contains 3182 features .We employ undersampling and feature selection as described previously , and also utilize the SVM algorithm to train the classifier .Biochemical properties .Other authors have previously shown that biochemical properties of proteins , such as a protein 's charge , amino acid composition , are useful for functional classification [ 25 ] .", "label": "", "metadata": {}, "score": "60.80234"}
{"text": "Therefore , it is often desirable to incorporate a small - sample correction , called pseudocount , in all probability estimates such that no probability is ever set to be exactly zero .This way of regularizing naive Bayes is called Laplace smoothing when the pseudocount is one , and Lidstone smoothing in the general case .", "label": "", "metadata": {}, "score": "60.807796"}
{"text": "Experimental determination of such sites lags far behind the number of known biomolecular sequences .Hence , there is a need to develop reliable computational methods for identifying functionally important sites from biomolecular sequences .Results : We present a mixture of experts approach to biomolecular sequence labeling that takes into account the global similarity between biomolecular sequences .", "label": "", "metadata": {}, "score": "60.88804"}
{"text": "View Article PubMed .Shipp MA , et al . :Diffuse large B - cell lymphoma outcome prediction by gene expression profiling and supervised machine learning .Nature Medicine 2002 , 8 : 68 - 74 .View Article PubMed .Savage KJ , et al .", "label": "", "metadata": {}, "score": "60.983356"}
{"text": "Edited by : Bhargava BK .Washington , DC : Association for Computing Machinery ( ACM ) ; 1993:314 - 323 .Yu C , Zavaljevski N , Desai V , Johnson S , Stevens FJ , Reifman J : The development of PIPA : an integrated and automated pipeline for genome - wide protein function annotation .", "label": "", "metadata": {}, "score": "61.02618"}
{"text": "Bioinformatics 2007 , 23 : 71 - 76 .View Article PubMed .Lin E , Hsu SY : A Bayesian approach to gene - gene and gene - environment interactions in chronic fatigue syndrome .Pharmacogenomics 2009 , 10 : 35 - 42 .", "label": "", "metadata": {}, "score": "61.151"}
{"text": "The performance was measured using both a 5-fold and a 10-fold cross - validation method .Experiments .For example , a sample testing set with size 20 and sense distribution ( 0.5 , 0.5 ) means 10 samples in the set are with one sense and the other 10 samples are with the other sense .", "label": "", "metadata": {}, "score": "61.18732"}
{"text": "The i th binary SVM classifier is trained by considering all instances associated with the i th class as positive examples and the others as negative instances .It applies the N classifiers and chooses the one with the highest confidence .\" One - vs - one \" , also known as \" one - against - one \" , constructs N(N-1)/2 binary SVM classifiers where each is trained with data from two classes : one as positive and one as negative .", "label": "", "metadata": {}, "score": "61.220943"}
{"text": "In this way , weights of each data source can be learned by the meta - classifier .Meta - learning classifiers are useful for combining multiple weak learning algorithms and for combining heterogeneous data sources .We developed a functional classification system called PoGO ( Prediction of Gene Ontology terms ) that enables us to assign GO terms to fungal proteins in a high - throughput fashion without the requiring evidence from laboratory experiments .", "label": "", "metadata": {}, "score": "61.254772"}
{"text": "The authors claim that the problem of the most common usage of GA / EDAs in feature selection is to search for an optimal solution which is lost information and not enough for whole elimination process .In this paper , the authors present a new method for feature subset selection applied to splice site prediction , based on estimation of distribution algorithms .", "label": "", "metadata": {}, "score": "61.36695"}
{"text": "PubMed View Article .Ranea JAG , Yeats C , Grant A , Orengo CA : Predicting Protein Function with Hierarchical Phylogenetic Profiles : The Gene3D Phylo - Tuner Method Applied to Eukaryotic Genomes .PLoS Comput Biol 2007 , 3 ( 11 ) : e237 .", "label": "", "metadata": {}, "score": "61.485397"}
{"text": "The F - measure values obtained with PoGO were comparable to , although slightly lower than , those obtained for MultiPfam2GO .For example , at a threshold value of 0.7 , the average F - measure for MultiPfam2GO [ 33 ] was 0.99 while the F - Measure for PoGO was 0.98 ( Table 2 ) .", "label": "", "metadata": {}, "score": "61.54121"}
{"text": "We extracted and tested our system on a total 465 instances of entity names with an average of 8 instances per species for each entity name .In the original dataset ( gold standard ) , 90 % of the terms have all their instances occurring in only one species [ 9 ] and so can not be tested in our system .", "label": "", "metadata": {}, "score": "61.565258"}
{"text": "A novel heuristic is proposed to enable real - time execution rate adaptation in MoE systems with insufficient resources .In any given cycle , the heuristic uses sensitivity analysis to test whether one of two pre - computed schedules is the optimal solution of the optimization problem to avoid re - optimization when the test result is positive .", "label": "", "metadata": {}, "score": "61.608788"}
{"text": "ME - NB - local exploits the local sequence similarity to construct the hierarchical structure .ME - NB - random randomizes the global similarity matrix and constructs the hierarchical structure based on the randomized matrix .Page 7 .Hence , to learn the hierarchical structure of the model , we use hierarchical clustering of the sequences in the data set .", "label": "", "metadata": {}, "score": "61.65193"}
{"text": "Let tioned and let S be a similarity function between pairs of sequences .Recursively bipartition each subgraph obtained at Step 3 . if necessary .Hierarchical structure produced by spectral clustering on a data set of 147 protein sequences Figure 9 Hierarchical structure produced by spectral cluster- ing on a data set of 147 protein sequences .", "label": "", "metadata": {}, "score": "61.66192"}
{"text": "We have developed a web server that enables users to annotate protein sequences using the taxon specific classifiers described in this manuscript ( Figure 2 ) .The classification results are stored on the server in flat files , and are presented to the user in a table that contains the annotated GO terms as well as and InterPro terms and links to a detailed page for each protein .", "label": "", "metadata": {}, "score": "61.810215"}
{"text": "Nucleic Acids Res 2004 , ( 32 Database ) : D262 - 266 .Vinayagam A , Konig R , Moormann J , Schubert F , Eils R , Glatting KH , Suhai S : Applying Support Vector Machines for Gene Ontology based gene function prediction .", "label": "", "metadata": {}, "score": "61.87526"}
{"text": "IEEE 7th International Symposium on Bioinformatics 2007:320- 326 .Davis J , Goadrich M : The Relationship Between Precision-Recall and ROC Curves .Proceedings of the 23rdInternational Con- ference on Machine Learning 2006:233 - 240 .Baldi P , Brunak S , Chauvin Y , Andersen C , Nielsen H : Assessing the accuracy of prediction algorithms for classification : an over- view .", "label": "", "metadata": {}, "score": "61.923805"}
{"text": "Out of the 100 instances of depression , 85 instances are tagged with the first sense , and remaining 15 instances are tagged with \" None \" ( i.e. , no instances tagged with a second sense ) , and so it was excluded in this evaluation .", "label": "", "metadata": {}, "score": "61.93325"}
{"text": "However , evidence of associations with CFS for other genes was inconsistent in these studies .The potential reason for the discrepancies between the results of this study and those of other studies may be the sample sizes .The studies conducted on small populations may have biased a particular result .", "label": "", "metadata": {}, "score": "62.052753"}
{"text": "These weights enable the learner to induce quite reliable models for sense disambiguation .All the results showed that the technique is fairly successful and effective in the disambiguation task .Thus , more research work should be exerted to carry out further improvements on the performance of this technique .", "label": "", "metadata": {}, "score": "62.08529"}
{"text": "Tables 2 , 3 , 4 show the improvements in more detail .The addition of unlabeled samples increases the range from 70 % to 100 % .In CML experiments , adding unlabeled samples increases the minimum accuracy from 0 % to 11.11 % .", "label": "", "metadata": {}, "score": "62.228493"}
{"text": "In EV3 , we kept .Table 5 contains the results of EV2 and EV3 .To judge on performance of our method and compare our results with similar techniques , we included several reported results from three recent publications from 2008 to 2010 [ 1 , 2 , 4 ] with our results in Table 6 under the same experimental settings .", "label": "", "metadata": {}, "score": "62.378082"}
{"text": "Hand DJ : Construction and assessment of classification rules Chichester , England : John Wiley & Sons 1997 .Hand DJ : Assessing Classification Rules .Journal of Applied Statistics 1994 , 21 : 3 - 16 .View Article .Fukunaga K , Hayes RR : Effect of sample size in classifier design .", "label": "", "metadata": {}, "score": "62.452133"}
{"text": "Declarations .Acknowledgements .We thank Exagen Diagnostics for support in conducting this research and presenting these results .This article has been published as part of BMC Genomics Volume 9 Supplement 2 , 2008 : IEEE 7 th International Conference on Bioinformatics and Bioengineering at Harvard Medical School .", "label": "", "metadata": {}, "score": "62.458145"}
{"text": "Very good results ! ! !A server to classify spam in real time .But we have n't done anything different from the 20newsgroup example yet !Now , what can we do if we want to classify mails as they are coming .", "label": "", "metadata": {}, "score": "62.461742"}
{"text": "Conclusion .In this study we proposed a new technique for concurrently mining labeled and unlabeled datasets .This method supplements standard supervised learning with clustering of data lacking clinical annotation to estimate the predictive power of gene subsets .The performance of our algorithm was evaluated in comparison with supervised learning only on microarray data from three different cancer types .", "label": "", "metadata": {}, "score": "62.579266"}
{"text": "Background .Our ability to obtain genome sequences is quickly outpacing our ability to annotate genes and identify gene functions .The automated annotation of gene models in newly sequenced genomes is greatly facilitated by easy - to - use software pipelines [ 1 ] .", "label": "", "metadata": {}, "score": "62.5949"}
{"text": "The average accuracy of our method is the highest ( 90.3 % ) , and the closest one is NB ( 86.0 % ) .Our method also outperforms all 10 other methods in 12 out of 31 words followed by NB which outperforms the rest in 7 words .", "label": "", "metadata": {}, "score": "62.63891"}
{"text": "TAN takes the naive Bayes and adds edges to it in which the class node directly points to all attribute nodes and an attribute node can have only one parent from another attribute node .Computing .It is an efficient extend of naive Bayes .", "label": "", "metadata": {}, "score": "62.730377"}
{"text": "Performance represents an average of all classifiers trained with each data set and is measured by 10-fold cross validation .Performance evaluation .Performance evaluation of protein function classifiers performance is a complex issue , since no standard methods exist [ 32 ] .", "label": "", "metadata": {}, "score": "62.835808"}
{"text": "In constructing BAN , they use a scoring function based on the minimum description length principle .Unfortunately , the search for the best network is performed in the space of all possible networks , and the number of elements in this space increases exponentially with the number of nodes , finding the best structure is NP - hard [ 17 , 18 ] .", "label": "", "metadata": {}, "score": "62.89382"}
{"text": "We used . , and the window size is 5 .The accuracy results of this first evaluation ( EV1 ) are shown in Table 4 .The detailed results of this evaluation are included in Table 5 .In the second evaluation ( EV2 ) and third evaluation ( EV3 ) , we changed the parameter and the word / features selection formula .", "label": "", "metadata": {}, "score": "63.005398"}
{"text": "In this example , the annotations assigned to the BLAST hits are used as features .We employ a similar approach .The feature set is comprised of hit obtained in a BLAST search of a database of GO annotated proteins ( excluding machine annotated terms ) using an expect threshold ( E -value ) of 1 -10 .", "label": "", "metadata": {}, "score": "63.213417"}
{"text": "View Article .Erdmann G , Berger S , Sch\u00fctz G : Genetic dissection of glucocorticoid receptor function in the mouse brain .J Neuroendocrinol 2008 , 20 : 655 - 659 .View Article PubMed .Garcia A , Steiner B , Kronenberg G , Bick - Sander A , Kempermann G : Age - dependent expression of glucocorticoid- and mineralocorticoid receptors on neural precursor cell populations in the adult murine hippocampus .", "label": "", "metadata": {}, "score": "63.218697"}
{"text": "Diettrich TG : Machine Learning for Sequential Data : A Review .Proceedings Joint IAPR International Workshop on Structural , Syntactic , and Statistical Pattern Recognition 2002:15 - 30 .Dietterich TG : Ensemble Methods in Machine Learning .Lecture Notes in Computer Science 2000 , 1857:1 - 15 .", "label": "", "metadata": {}, "score": "63.303146"}
{"text": "However there is a concern that a very limited set of words may have accounted for the vast majority of ambiguity .Therefore , for each ambiguous word , we calculated its frequency , which is defined as the ratio between the number of abstracts containing the word and the total number of abstracts in the pool .", "label": "", "metadata": {}, "score": "63.63179"}
{"text": "The labeled training instances will be used to extract the word features for the feature vectors .Suppose the word .labeled with sense . or .( i.e. , in the set .or in the set . can be viewed as . and .", "label": "", "metadata": {}, "score": "63.775375"}
{"text": "We describe a classifier called PoGO ( Prediction of Gene Ontology terms ) that uses statistical pattern recognition methods to assign Gene Ontology ( GO ) terms to proteins from filamentous fungi .PoGO is organized as a meta - classifier in which each evidence source ( sequence similarity , protein domains , protein structure and biochemical properties ) is used to train independent base - level classifiers .", "label": "", "metadata": {}, "score": "63.880684"}
{"text": "Authors ' Affiliations .Department of Computer Science , Texas A&M University .Centro Hispano - Luso de Investigaciones Agrarias ( CIALE ) , Department of Microbiology and Genetics , University of Salamanca .Samsung Electronic Co. .References .Cantarel BL , Korf I , Robb SMC , Parra G , Ross E , Moore B , Holt C , S\u00e1nchez Alvarado A , Yandell M : MAKER : an easy - to - use annotation pipeline designed for emerging model organism genomes .", "label": "", "metadata": {}, "score": "63.97075"}
{"text": "The main variations are usually in the selection of features and choice of machine - learning algorithms .Experiments are usually performed on a fixed amount of documents ( i.e. 1,000 abstracts ) per an ambiguous word , where the entire set consists of all the senses , and the sense distribution is generally uneven .", "label": "", "metadata": {}, "score": "63.983067"}
{"text": "They are often trained only to one species , are not available for high - volume data processing , or require the use of data derived by experiments such as microarray analysis .To meet the increasing need for high throughput , automated annotation of fungal genomes , we have developed a tool for annotating fungal protein sequences with terms from the Gene Ontology .", "label": "", "metadata": {}, "score": "64.12826"}
{"text": "Using Bayes ' theorem , the conditional probability can be decomposed as .In practice , there is interest only in the numerator of that fraction , because the denominator does not depend on and the values of the features are given , so that the denominator is effectively constant .", "label": "", "metadata": {}, "score": "64.183426"}
{"text": "We also prepared another dataset called UniProt that includes all GO term - annotated proteins in the UniProt database regardless of the taxonomic origin .In all cases , we removed GO terms from the proteins that were annotated with the evidence code IEA ( Inferred from Electronic Annotation ) , and those that had less than 10 representative proteins .", "label": "", "metadata": {}, "score": "64.23051"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . H. Xu , M. Markatou , R. Dimova , H. Liu , and C. Friedman , \" Machine learning and word sense disambiguation in the biomedical domain : design and evaluation issues , \" BMC Bioinformatics , vol .", "label": "", "metadata": {}, "score": "64.29158"}
{"text": "Subjects .The dataset , including SNPs , age , gender , and race , was original to the previous study by the CDC Chronic Fatigue Syndrome Research Group [ 18 ] .More information is available on the website [ 18 ] .", "label": "", "metadata": {}, "score": "64.366394"}
{"text": "We wish to be able to use a mathematical programming formulation , and this formulation requires that we are able to measure the impact of adding or removing a single arc from the network .In order to approximate the impact of adding such an arc , we define the dependence coefficient .", "label": "", "metadata": {}, "score": "64.37599"}
{"text": "When the annotators did not assign any sense for an instance , then that instance is tagged with \" none \" .Only one term \" association \" with all of its 100 instances were annotated none and so dropped from the testing .", "label": "", "metadata": {}, "score": "64.53688"}
{"text": "The predictions are then used as features for the meta - classifier .To evaluate the performance of the set of base - classifiers together with the meta - classifier , we perform ten - fold cross validation by constructing ten datasets in which 10 % of the proteins are held out of the training dataset .", "label": "", "metadata": {}, "score": "64.54992"}
{"text": "Smith AK , Dimulescu I , Falkenberg VR , Narasimhan S , Heim C , Vernon SD , Rajeevan MS : Genetic evaluation of the serotonergic system in chronic fatigue syndrome .Psychoneuroendocrinology 2008 , 33 : 188 - 197 .View Article PubMed .", "label": "", "metadata": {}, "score": "64.5547"}
{"text": "View Article PubMed .Humphrey SM , Rogers WJ , Kilicoglu H , Demner - Fushman D , Rindflesch TC : Word sense disambiguation by selecting the best semantic type based on Journal Descriptor Indexing : Preliminary experiment .Journal of the American Society for Information Science and Technology 2006 , 57 : 96 - 113 .", "label": "", "metadata": {}, "score": "64.593765"}
{"text": "The root node is the largest cluster containing all the protein sequences such that each node in the training set .Once a cluster is partitioned into its two subclusters , it becomes their parent in the resulting tree structure .We store all the intermediate clusters computed by the algorithm .", "label": "", "metadata": {}, "score": "64.68399"}
{"text": "Results for BSA data set .Annotation of the table : Dist : Distribution of senses ; S. Size : sample size ; Err .Rate : Error Rate ; SE : Standard Error of error rates ; CV : cross - validation ; .", "label": "", "metadata": {}, "score": "64.75608"}
{"text": "In all cases , the classifiers trained with taxon specific datasets performed better than the classifier trained with the UniProt dataset .Since the Fungi dataset is significantly smaller than the UniProt dataset , we reasoned that the improved performance could be due to overfitting .", "label": "", "metadata": {}, "score": "64.87926"}
{"text": "View Article PubMed .Frank O , et al . :Gene expression signature of primary imatinib - resistant chronic myeloid leukemia patients .Leukemia 2006 , 20 : 1400 - 7 .View Article PubMed .Yong ASM , et al .: Molecular profiling of CD34 + cells identifies low expression of CD7 , along with high expression of proteinase 3 or elastase , as predictors of longer survival in patients with CML .", "label": "", "metadata": {}, "score": "65.01257"}
{"text": "No assumptions are made about the original distribution ( e.g. normal vs. other ) of the documents .Analysis of variance models are versatile statistical tools for studying the relation between error rates and sense distribution , sample size , and degree of difficulty of a task .", "label": "", "metadata": {}, "score": "65.27672"}
{"text": "For all other sense distributions , an increase in the sample size did not produce a significant reduction in the error rate - that is , there are no statistically significant differences between the error rates .We would like to stress here a limitation of the current study .", "label": "", "metadata": {}, "score": "65.33925"}
{"text": "When the senses are well separated , any increase in the sample size results in a statistically significant decrease of the error rate .This holds for all sense distributions and it is in agreement with the finding that for BSA there was no significant effect of the sense distributions on the error rates for the different sample sizes used .", "label": "", "metadata": {}, "score": "65.360016"}
{"text": "Recall that for each abbreviation , each sense distribution and each sample size we run the experiment 30 times .The error rate was computed using both a 5-fold and a 10-fold cross - validation scheme .Let the size of the training set be denoted by n .", "label": "", "metadata": {}, "score": "65.369965"}
{"text": "Conclusions .In this paper , we describe a meta - classifier for assigning GO terms to proteins using heterogeneous feature sets .By using multiple , heterogeneous data sources , we developed a classifier that offers improved accuracy compared to previously reported annotation methods .", "label": "", "metadata": {}, "score": "65.4588"}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : Several experiments were conducted in order to investigate the usefulness of mixture of experts ( ME ) approach to an online internet system assisting in real estate appraisal .All experiments were performed using 28 real - world datasets composed of data taken from a cadastral system and GIS data derived from a cadastral map .", "label": "", "metadata": {}, "score": "65.50796"}
{"text": "For BSA and RSV , the estimated distributions were the same as one of the 5 simulated distributions , and therefore the experiments used only 5 combinations for those two .For PCA , the estimated distribution was ( 0.67 , 0.33 ) .", "label": "", "metadata": {}, "score": "65.529755"}
{"text": "Multiple comparisons , adjusted for multiple testing , indicated that when the overall significance level is 0.1 , the sense distributions ( 0.5 , 0.5 ) and ( 0.6 , 0.4 ) impact the error rate .These results show that almost balanced sense distributions and rather large training sample sizes reduce the error rate to approximately half of our best guess , which is using the majority sense .", "label": "", "metadata": {}, "score": "65.533875"}
{"text": "Data set for experiments .Four abbreviations were used in the experiments .Table 1 lists the detailed information about the abbreviations and their senses .These abbreviations were originally specified in the ABBR data set [ 8 ] .We chose them by considering the different levels of semantic similarity among their senses .", "label": "", "metadata": {}, "score": "65.56456"}
{"text": "AAAI Fall Symp 93 98 - 107 .Hamosh A , Scott AF , Amberger J , Bocchini C , Valle D , McKusick VA : Online Mendelian Inheritance in Man ( OMIM ) , a knowledgebase of human genes and genetic disorders .", "label": "", "metadata": {}, "score": "65.60261"}
{"text": "This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of RSV data set ( case where the 2 ambiguous senses both refer to viruses but the viruses are different types of viruses ) using 5-fold cross validation .", "label": "", "metadata": {}, "score": "65.649536"}
{"text": "MoE systems find application in many domains , including classification , image processing , time - series prediction , data mining , fault - tolerance , modeling , etc [ 4 ] [ 6 ] [ 11 ] [ 15 ] [ 16].", "label": "", "metadata": {}, "score": "65.80658"}
{"text": "170 , no . 8 - 9 , pp .653 - 666 , 2006 .View at Publisher \u00b7 View at Google Scholar .Affiliated with .Abstract .Background .Automated protein function prediction methods are the only practical approach for assigning functions to genes obtained from model organisms .", "label": "", "metadata": {}, "score": "66.05238"}
{"text": "9 , supplement 11 , article S7 , 2008 .View at Google Scholar .57 , no . 1 , pp .96 - 113 , 2006 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. Stevenson , E. Agirre , and A. Soroa , \" Exploiting domain information for Word Sense Disambiguation of medical documents , \" Journal of the American Medical Informatics Association .", "label": "", "metadata": {}, "score": "66.23802"}
{"text": "In their study , rare senses ( senses appearing in less than 40 documents ) were excluded from the testing set .This makes the disambiguation task easier because it reduces the problem of sparse senses .In addition , the training set was created based on long - form and short - form pairs , where ambiguous words not having long - forms were not tested .", "label": "", "metadata": {}, "score": "66.26439"}
{"text": "We now determine the probability distribution for the sex of the sample . where and are the parameters of normal distribution which have been previously determined from the training set .Note that a value greater than 1 is OK here - it is a probability density rather than a probability , because height is a continuous variable .", "label": "", "metadata": {}, "score": "66.270485"}
{"text": "The amount of WSD research in the biomedical domain is not proportional to the extent of the problem .As an example , in the biomedical texts , the term \" blood pressure \" has three possible senses according to the Unified Medical Language System ( UMLS )", "label": "", "metadata": {}, "score": "66.3179"}
{"text": "Troyanskaya OG , Dolinski K , Owen AB , Altman RB , Botstein D : A Bayesian framework for combining heterogeneous data sources for gene function prediction ( in Saccharomyces cerevisiae ) .Proc Natl Acad Sci USA 2003 , 100 ( 14 ) : 8348 - 8353 .", "label": "", "metadata": {}, "score": "66.39942"}
{"text": "An overfitted classifier can perform well when the instances ( proteins in our case ) are similar to the ones in the training data , but perform poorly when presented with instances that are not similar to the training data .To determine whether the improved performance is due to over - fitting , we trained PoGO classifiers with 10 smaller datasets containing the same number of proteins as the Fungi dataset .", "label": "", "metadata": {}, "score": "66.466034"}
{"text": "The full - form in the title or abstract of the article was then replaced with the ambiguous abbreviation , and the appropriate sense was noted separately .Table 1 shows the number of articles that were obtained for the different abbreviations and senses .", "label": "", "metadata": {}, "score": "66.52255"}
{"text": "Page 10 .The leaf nodes consist of expert classifiers , while the gating nodes com- bine the output of each classifier to the root of the tree which makes the final prediction .The gating nodes com- bine the predictions of the expert classifiers based on an estimate of the cluster membership of a test protein sequence .", "label": "", "metadata": {}, "score": "66.61905"}
{"text": "coordinate is the percentage of misclassifications according to BC - OM .Thus , points below the diagonal line correspond to data sets on which BC - OM performs better .From Figures 2 and 3 , we can see that BC - OM generally outperforms NB and TAN as is also demonstrated in Table 3 .", "label": "", "metadata": {}, "score": "66.82886"}
{"text": "Nucleic Acids Res 2003 , 31 ( 13 ) : 3712 - 3715 .PubMed View Article .G\u00fcnther Z : OntoBlast function : From sequence similarities directly to potential functional annotations by ontology terms .Nucleic Acids Res 2003 , 31 ( 13 ) : 3799 - 3803 .", "label": "", "metadata": {}, "score": "66.897934"}
{"text": "View Article PubMed .Schuemie MJ , Weeber M , Schijvenaars BJA , van Mulligen EM , van der Eijk CC , Jelier R , et al .: Distribution of information in biomedical abstracts and full - text publications .Bioinformatics 2004 , 20 : 2597 - 2604 .", "label": "", "metadata": {}, "score": "66.90436"}
{"text": "Electronic supplementary material .1471 - 2105 - 11 - 215-S1.PDF Additional file 1 : Supplementary Tables .Table 1 - Comparison of classifier methods for assigning Gene Ontology ( GO ) terms using biochemical properties .Table 2 - Performance comparison of four different taxon - specific data sets and randomly undersampled UniProt data sets .", "label": "", "metadata": {}, "score": "66.9769"}
{"text": "View Article PubMed .Fukuda K , Straus SE , Hickie I , Sharpe MC , Dobbins JG , Komaroff A : The chronic fatigue syndrome : a comprehensive approach to its definition and study .Ann Intern Med 1994 , 121 : 953 - 959 .", "label": "", "metadata": {}, "score": "67.004745"}
{"text": "Comparison of Na\u00efve Bayes , mixture of Na\u00efve Bayes and ensemble of Na\u00efve Bayes models on the DNA - protein data set Figure 3 Comparison of Na\u00efve Bayes , mixture of Na\u00efve Bayes and ensemble of Na\u00efve Bayes models on the DNA - protein data set .", "label": "", "metadata": {}, "score": "67.09666"}
{"text": "View Article PubMed .Sanders P , Korf J : Neuroaetiology of chronic fatigue syndrome : an overview .World J Biol Psychiatry 2008 , 9 : 165 - 171 .View Article PubMed .Lin E , Hwang Y , Wang SC , Gu ZJ , Chen EY : An artificial neural network approach to the drug efficacy of interferon treatments .", "label": "", "metadata": {}, "score": "67.097916"}
{"text": "For example , in identify- ing RNA - protein and DNA - protein interface residues from amino acid sequences , there is typically no consensus sequence around each site .Classifiers trained using machine learning to distinguish \" positive \" examples from the \" negative \" ones , must \" learn \" to do so by learning the characteristics associated with known \" positive \" and \" negative \" examples .", "label": "", "metadata": {}, "score": "67.11549"}
{"text": "A naive Bayes classifier considers each of these features to contribute independently to the probability that this fruit is an apple , regardless of any possible correlations between the color , roundness and diameter features .For some types of probability models , naive Bayes classifiers can be trained very efficiently in a supervised learning setting .", "label": "", "metadata": {}, "score": "67.12953"}
{"text": "One example is Interpro2GO , a manually curated mapping , of InterPro terms to GO terms .The GOA project relies on several such mappings to provide automated GO annotations for users [ 10 , 11 ] .More sophisticated classifiers have been developed using machine learning algorithms which can automatically deduce the relationships between the features and the functional categories based on a set of previously annotated proteins that serve as training examples .", "label": "", "metadata": {}, "score": "67.13166"}
{"text": "The source code for the web server have been released under the terms of the BSD license and is available in Additional File 2 as well as on the PoGO home page .Flowchart of the PoGO web server .Four different sequence analysis programs converts data to InterPro term , Blast result , Bio - chemical property and protein structure information , which is represented by the gray and black box .", "label": "", "metadata": {}, "score": "67.37601"}
{"text": "We ran- domly selected a sequence from each cluster returned by BlastClust .Thus , the resulting non - redundant RNA - pro- tein sequence data set for 30 % identity cutoff has 180 pro- tein sequences .The total number of amino acid residues is 33,235 .", "label": "", "metadata": {}, "score": "67.431595"}
{"text": "One of those is the 20 newsgroups example that tries to classify many mails from a newsgroup into their categories .This example is found in the Mahout wiki , and luckily for us , the format of the newsgroups are pretty the same as our mails .", "label": "", "metadata": {}, "score": "67.45099"}
{"text": "For senses that correspond to the same syntactic category , the similarity of their semantic categories will affect the difficulty of the task ( i.e. the bovine serum albumin sense of BSA is substantially different from the body surface area sense ) .Even for senses within the same semantic class , two close senses will be much more difficult to classify than two unrelated meanings .", "label": "", "metadata": {}, "score": "67.599045"}
{"text": "Bruce [ 19 ] applied a Bayesian algorithm and chose features based on their \" informative \" nature .They tested their methods on the interest corpus , which is a corpus consisting of 6 different senses for the word interest , and achieved a precision of 79 % .", "label": "", "metadata": {}, "score": "67.72971"}
{"text": "Table 3 shows the number of sequences as well as the number of positive ( + ) and negative ( - ) instances in the non - redundant RNA- and DNA - protein sequence data sets for 30 % , 60 % , and 90 % identity cutoffs .", "label": "", "metadata": {}, "score": "67.9755"}
{"text": "Tables 2 , 3 and 4 display the results for BSA , PCA and RSV , each of which has two senses .The distribution shown with bold font in column 1 is the estimated distribution of the senses , which is calculated based on the number of retrieved articles for each sense and the number of retrieved articles for all the senses .", "label": "", "metadata": {}, "score": "67.98207"}
{"text": "MM and CF conceived of the study , and participated in its design and coordination and helped to draft the manuscript .MM also performed statistical analysis and interpreted the results .HL advised in the design of study .All authors read and approved the final manuscript .", "label": "", "metadata": {}, "score": "68.035614"}
{"text": "For that , we use feature selection techniques such as mutual information ( MI ) [ 19 , 20 ] as follows .For each context word .that do not contain .that do not contain .Therefore , the mutual information ( MI ) can be defined as .", "label": "", "metadata": {}, "score": "68.128296"}
{"text": "For PCA this effect was significant .The effect of different sample sizes on the error rate was significant for BSA , RSV , and BPD .For those two distributions , an increase from 20 to 80 was also significant .Smaller increases in the sample size had an insignificant effect .", "label": "", "metadata": {}, "score": "68.1362"}
{"text": "A panel of 42 SNPs by the CDC Chronic Fatigue Syndrome Research Group .rs2171363 , rs4760816 , rs4760750 , rs1386486 , rs1487280 , rs1872824 , rs10784941 .The \" rs number \" means the NCBI SNP ID .In this study , we imputed missing values for subjects with any missing SNP data by replacing them with the modes from the data [ 19 ] .", "label": "", "metadata": {}, "score": "68.20613"}
{"text": "Results .Support Vector Machine ( SVM ) classifiers were applied to an automatically generated data set containing four ambiguous biomedical abbreviations : BPD , BSA , PCA , and RSV , which were chosen because of varying degrees of differences in their respective senses .", "label": "", "metadata": {}, "score": "68.361176"}
{"text": "The online version of this article ( doi : 10 .1186/\u200b1471 - 2105 - 7 - 334 ) contains supplementary material , which is available to authorized users .Background .During the last few years , there has been a surge of interest in information extraction and text mining of the biomedical literature [ 1 , 2 ] .", "label": "", "metadata": {}, "score": "68.366104"}
{"text": "Individual GO terms or groups of GO terms may also be re - trained , as new training data of evidence sources become available .PoGO consists of four base classifiers , each of which utilizes distinct data sources , and a meta - classifier for combining the outputs from the base classifiers into a final classification .", "label": "", "metadata": {}, "score": "68.52744"}
{"text": "View Article PubMed .Eisen MB , Spellman PT , Brown PO , Botstein D : Cluster analysis and display of genome - wide expression patterns .PNAS 1998 , 95 : 14863 - 14868 .View Article PubMed .Golub TR , et al .", "label": "", "metadata": {}, "score": "68.59235"}
{"text": "Caragea C , Sinapov J , Silvescu A , Dobbs D , Honavar V : Glycosyla- tion site prediction using ensembles of Support Vector Machine classifiers .BMC Bioinformatics 2007 , 8:438 .Kim JH , Lee J , Oh B , Kimm K , Koh I : Prediction of phosphoryla- tion sites using SVMs .", "label": "", "metadata": {}, "score": "68.84137"}
{"text": "Identification of functionally important sites in biomolecular sequences has broad applications ranging from rational drug design to the analysis of metabolic and signal transduction networks .Experimental determination of such sites lags far behind the number of known biomolecular sequences .Hence , there is a need to develop reliable computational methods for identifying functionally important sites from biomolecular sequences .", "label": "", "metadata": {}, "score": "68.950516"}
{"text": "Default analyzer is a Lucene analyzer ( actually it is wrapped within a mahout class ) .We are going to train the classifier .Training the classifier implies feeding mahout with the train file and letting him build internal structures with the data ( yes , as you can deduce by my use of the word \" internal \" , I do n't have any idea how that structures work ) .", "label": "", "metadata": {}, "score": "69.004395"}
{"text": "Background .In this section , we discuss previous work that is relevant to this paper , and describe some of the notations used firstly .We use boldface capital letters such as .Classification is a basic task in data analysis and pattern recognition that requires the construction of a classifier , that is , a function that assigns a class label to instances described by a set of attributes .", "label": "", "metadata": {}, "score": "69.00765"}
{"text": "The server will be as simple as we can ( this is just a proof of concept ) : .As we are going to do a very simple example we are going to use a simple servlet .The important class is SpamClassifier .", "label": "", "metadata": {}, "score": "69.13096"}
{"text": "View Article PubMed .Gaudan S , Krisch H , Rebholz - Schuhmann D : Resolving abbreviations to their senses in Medline .Bioinformatics 2005 , 21 : 3658 - 3664 .View Article PubMed .Schuemie MJ , Kors JA , Mons B : Word sense disambiguation in the biomedical domain : an overview .", "label": "", "metadata": {}, "score": "69.41191"}
{"text": "Using the InterProScan application [ 21 ] , we can obtain InterPro terms for unannotated proteins .Using InterProScan , we identified 3339 InterPro terms in the fungal protein dataset .We employed Support Vector Machines ( SVM ) algorithm as the classifier as described previously [ 19 ] .", "label": "", "metadata": {}, "score": "69.51799"}
{"text": "If the classifier for the Fungi dataset was overfitted , we would expect that it would have better performance than the classifiers derived from the sub - sampled datasets .The average F - measure of the subsampled classifiers is 0.4135 while the F - measure for the Fungi classifier is 0.3101 , indicating that the Fungi classifier is not subject to overfitting .", "label": "", "metadata": {}, "score": "69.54054"}
{"text": "Yngve VH : Syntax and the problem of multiple meaning .Machine Translation of Languages New York , John Wiley & Sons 1955 , 208 - 226 .Mooney RJ : Comparative experiments on disambiguating word senses : An illustration of the role of bias in machine learning .", "label": "", "metadata": {}, "score": "69.80298"}
{"text": "This is a tutorial , so we are not trying to classify very difficult mails just to show how simple it can be done with Mahout ( of course , the difficult stuff was programmed by the developers of this library ) .This corpus is a pretty easy one and the results will be very satisfying .", "label": "", "metadata": {}, "score": "69.81218"}
{"text": "In our case , the random variables in the pair are the error rates obtained under the different sample sizes used .For each abbreviation , each sense distribution and each cross - validation scheme we have 6 pairs of random variables corresponding to different combinations of the sample size .", "label": "", "metadata": {}, "score": "69.848335"}
{"text": "Get a ham / spam corpus from the web ( already classified of course ) .Train a classifier with 80 % of the corpus , and leave 20 % for testing .Create a simple web service that classifies spam online .You provide it a mail , and it will say \" good \" or \" bad \" ( or \" ham \" or \" spam \" ) .", "label": "", "metadata": {}, "score": "69.86919"}
{"text": "Competing interests .The authors declare that they have no competing interests .Authors ' contributions .LCH and SYH participated in the design of the study and coordination .EL performed the statistical analysis and helped to draft the manuscript .All authors read and approved the final manuscript .", "label": "", "metadata": {}, "score": "69.978745"}
{"text": "In biomedical text , named entities , like gene name , are used the same way irrespective of the species of the entity .As a result , it will be difficult to extract relevant medical information automatically from texts using information extraction system .", "label": "", "metadata": {}, "score": "69.9849"}
{"text": "Then , the context words . are ordered based on their MI values , and the top .words .with highest MI values are selected as features .In this research , we experimented with .values of 100 , 200 , and 300 .", "label": "", "metadata": {}, "score": "70.03455"}
{"text": "When such sequences are removed from the data sets , the number of sequences reduces from 435 to 246 in the case of RNA - protein interface data set , and from 1259 to 317 in the case of DNA - protein interface data set .", "label": "", "metadata": {}, "score": "70.049904"}
{"text": "5 , pp .628 - 640 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .W. J. Conover , Practical Nonparametric Statistics , John Wiley & Sons , New York , NY , USA , 1999 .", "label": "", "metadata": {}, "score": "70.15211"}
{"text": "View Article PubMed .Rajeevan MS , Smith AK , Dimulescu I , Unger ER , Vernon SD , Heim C , Reeves WC : Glucocorticoid receptor polymorphisms and haplotypes associated with chronic fatigue syndrome .Genes Brain Behav 2007 , 6 : 167 - 176 .", "label": "", "metadata": {}, "score": "70.4922"}
{"text": "Biomedical WSD ( NLM - WSD ) .Dataset We used the benchmark dataset NLM - WSD for biomedical word sense disambiguation [ 24 ] .This dataset was created as a unified and benchmark set of ambiguous medical terms that have been reviewed and disambiguated by reviewers from the field .", "label": "", "metadata": {}, "score": "70.515"}
{"text": "Page 9 .A residue was identified as interface residue using Entangle with the default parameters [ 12].While construct- ing our non - redundant sequence data sets , we applied var- ious identity cutoffs , starting from 30 % and ending at 90 % in steps of 10 .", "label": "", "metadata": {}, "score": "70.62349"}
{"text": "PubMed View Article .Murzin AG , Brenner SE , Hubbard T , Chothia C : SCOP : a structural classification of proteins database for the investigation of sequences and structures .J Mol Biol 1995 , 247 : 536 - 540 .PubMed .", "label": "", "metadata": {}, "score": "70.68898"}
{"text": "Figure 4 shows plots of the error rate versus sample size for each distribution of the BPD data set based on the 5-fold cross validation using the \" one - vs - rest \" algorithm .The plots for the four different sense distributions are very similar and actually agree with results obtained indicating that the effect of the different distributions on the error rate is insignificant .", "label": "", "metadata": {}, "score": "70.79595"}
{"text": "Protein Tertiary Structure .The fourth feature set is protein structure as computed using the HHpred program [ 28 ] which is used for protein homology detection and structure prediction using the SCOP database [ 29 ] .We use the top 10 selected templates as features and the remaining undefined templates are set to zero for each protein .", "label": "", "metadata": {}, "score": "70.827126"}
{"text": "\" [ Show abstract ] [ Hide abstract ] ABSTRACT : Mixture - of - Experts ( MoE ) systems solve intricate problems by combining results generated independently by multiple computational models ( the \" experts \" ) .Given an instance of a problem , the responsibility of an expert measures the degree to which the expert 's output contributes to the final solution .", "label": "", "metadata": {}, "score": "70.90031"}
{"text": "Table 1 demonstrates the demographic characteristics of study subjects .Candidate genes .In the present study , we only focused on the 42 SNPs as described in Table 2 [ 18 ] .Six of the genes ( COMT , MAOA , MAOB , SLC6A4 , TH , and TPH2 ) play a role in the neurotransmission system [ 8 ] .", "label": "", "metadata": {}, "score": "70.962006"}
{"text": "During the course of our experiments , we discovered that taxon - specific classifiers outperform classifiers that are trained with larger datasets from a wide array of taxa .We developed a taxon - specific classifier for Fungi and we are currently using it to assign GO terms to the proteomes of more than 30 filamentous fungi .", "label": "", "metadata": {}, "score": "70.96762"}
{"text": "Well the computers are pretty dumb in learning things , so you have to show them a lot of examples to infer the pattern .Classification , however , is only part of the problem .There are three big areas that Mahout targets ( and there will be more in the future because the project is relatively new ) .", "label": "", "metadata": {}, "score": "71.07442"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .G. K. Savova , A. R. Coden , I. L. Sominsky et al . , \" Word sense disambiguation across two domains : biomedical literature and clinical notes , \" Journal of Biomedical Informatics , vol .", "label": "", "metadata": {}, "score": "71.27838"}
{"text": "The same study , which was also performed for the Fly organism , showed similar results , but with slightly higher ambiguity rates .This study shows that the ambiguity among gene symbols , English words and other biomedical terms is extensive and the distribution of ambiguity is very sparse .", "label": "", "metadata": {}, "score": "71.32522"}
{"text": "Our annotation system overcomes many of the shortcomings that we found in other methods .We also provide a web server where users can submit protein sequences to be annotated .Electronic supplementary material .The online version of this article ( doi : 10 .", "label": "", "metadata": {}, "score": "71.332344"}
{"text": "The NLM - WSD corpus contains 50 ambiguous terms with 100 instances for each term for a total of 5000 examples .Each example is basically a Medline abstract containing one or more occurrences of the ambiguous word .The instances of these ambiguous terms were disambiguated by 11 annotators who assigned a sense for each instance [ 24 ] .", "label": "", "metadata": {}, "score": "71.38169"}
{"text": "From a general point of view , we can see that from the first data set to the last one , the highlighted numbers change from few to even more in the sixth column of Table 2 .It means the advantage of BC - OM is more evident with the increase of data size .", "label": "", "metadata": {}, "score": "71.419266"}
{"text": "GenBank Gene Accession Numbers were used to generate the common features .Table 1 provides additional details on these datasets .Demonstrations .For this study we implemented a GLAD algorithm as a wrapper technique for feature selection .A Genetic Algorithm ( GA ) is used for generating a population of relevant feature subsets .", "label": "", "metadata": {}, "score": "71.42273"}
{"text": "Clin Cancer Res 2004 , 10 : 2725 - 2737 .View Article PubMed .Chen K , Kurgan L , Ruan J : Prediction of flexible / rigid regions from protein sequences using k - spaced amino acid pairs .BMC Struct Biol 2007 , 7 : 25 .", "label": "", "metadata": {}, "score": "71.45662"}
{"text": "As the Friedman 's test indicated , the effect of the sense distribution on the error rate is significant .When the sense distribution is ( 0.5 , 0.5 ) there are statistically significant differences between the pairs of error rates produced under sample size ( 20 and 120 ) , the sample sizes ( 40 and 120 ) and the sample sizes ( 80 and 120 ) .", "label": "", "metadata": {}, "score": "71.50475"}
{"text": "Pharmacogenomics 2006 , 7 : 387 - 394 .View Article PubMed .Goertzel BN , Pennachin C , de Souza Coelho L , Gurbaxani B , Maloney EM , Jones JF : Combinations of single nucleotide polymorphisms in neuroendocrine effector and receptor genes predict chronic fatigue syndrome .", "label": "", "metadata": {}, "score": "71.583176"}
{"text": "Authors ' contributions CC and JS carried out the computations .CC prepared an initial draft of the manuscript .All authors participated in experimental design , discussions , and manuscript prepa- ration .All authors read and approved the final manu- script .", "label": "", "metadata": {}, "score": "71.617096"}
{"text": "From Table 3 , we can see that BC - OM significantly outperforms NB ( 9 wins and 4 losses ) , TAN ( 12 wins and 5 losses ) and BAN ( 11 wins and 5 losses ) in accuracy .Figures 2 , 3 , and 4 show two scatter - plots comparing BC - OM with NB , TAN , and BAN , respectively .", "label": "", "metadata": {}, "score": "71.881424"}
{"text": "We are in front of a big explosion of open source code that was ignited by the Lucene spark .All this projects are in some way related to content processing .For all of you interested in search and information retrieval , now we are going to talk about another project for a domain that 's outside the strict confines of search , but can teach you some interest things about content processing .", "label": "", "metadata": {}, "score": "71.96811"}
{"text": "As indicated in Table 3 , the average values of AUC for the SVM prediction models of linear , polynomial , sigmoid , and Gaussian radial basis function kernels were 0.55 , 0.59 , 0.61 , and 0.62 , respectively .Of all the kernel functions , the Gaussian radial basis function kernel gave better performance than the other three kernels in terms of AUC .", "label": "", "metadata": {}, "score": "71.97211"}
{"text": "Acknowledgments .This work was supported by the National Natural Science Foundation of China ( nos .60974082 and 61075055 ) , the National Funds of China for Young Scientists ( no .11001214 ) , and the Fundamental Research Funds for the Central Universities ( no . K5051270013 ) .", "label": "", "metadata": {}, "score": "72.052925"}
{"text": "NB , TAN , and BAN are best in 6 , 5 , and 3 cases , respectively .When the number of samples is larger than 400 , the performance of TAN and BAN is better than that of NB , and BC - OM is best .", "label": "", "metadata": {}, "score": "72.05832"}
{"text": "It has been suggested that CFS is a heterogeneous disorder with a complex and multifactorial aetiology [ 3 ] .Among hypotheses on aetiological aspects of CFS , one possible cause of CFS is genetic predisposition [ 5 ] .Single nucleotide polymorphisms ( SNPs ) can be used in clinical association studies to determine the contribution of genes to disease susceptibility or drug efficacy [ 6 , 7 ] .", "label": "", "metadata": {}, "score": "72.204216"}
{"text": "Notice also the relatively small standard deviations that are associated with those error rates .In particular , we notice that when the sense distribution ( P1 , P2 ) was very unbalanced ( i.e. 0.9 , 0.1 ) , then the error rate was almost equal to the minority sense proportion .", "label": "", "metadata": {}, "score": "72.21442"}
{"text": "Comparison of Logistic Regression , mixture of Logistic Regression and ensemble of Logistic Regression models on the RNA - protein data set Figure 2 Comparison of Logistic Regression , mixture of Logistic Regression and ensemble of Logistic Regression mod- els on the RNA - protein data set .", "label": "", "metadata": {}, "score": "72.27451"}
{"text": "For example the training file will look like this . ham new mahout version released .spam buy viagra now special discount .A small program comes with Mahout to turn directories of documents into this format .The directory must have an internal directory for each category .", "label": "", "metadata": {}, "score": "72.47733"}
{"text": "Learning mixture of experts models Here we present our approach to learning a mixture of experts model that takes into account the global similarity between biomolecular sequences .Unlike the Hierarchical Mixture of Experts model [ 9 ] , we assume that the structure of our model is not known a priori .", "label": "", "metadata": {}, "score": "72.50148"}
{"text": "PubMed .Fawcett T : An introduction to ROC analysis .Pattern Recognit Lett 2006 , 27 : 861 - 874 .View Article .Hewett R , Kijsanayothin P : Tumor classification ranking from microarray data .BMC Genomics 2008 , 9 ( Suppl 2 ) : S21 .", "label": "", "metadata": {}, "score": "72.51364"}
{"text": "Four ambiguous abbreviations : BPD , BSA , PCA , and RSV , were used in this study .They were chosen because they were associated with varying degrees of differences between their respective senses .For example , two of the senses of PCA studied are very similar whereas two senses of BSA are very different .", "label": "", "metadata": {}, "score": "72.65829"}
{"text": ":The Gene Ontology Annotation ( GOA )Project : Implementation of GO in SWISS - PROT , TrEMBL , and InterPro .Genome Res 2003 , 13 : 662 - 672 .PubMed View Article .Camon E , Magrane M , Barrell D , Lee V , Dimmer E , Maslen J , Binns D , Harte N , Lopez R , Apweiler R : The Gene Ontology Annotation ( GOA )", "label": "", "metadata": {}, "score": "72.74608"}
{"text": "SVM : .Declarations .Acknowledgements .This research was supported by funds from the United States Department of Agriculture ( grant number 2007 - 35600 - 17829 ) and the Ministerio de Ciencia e Innovaci\u00f3n of Spain ( grant number AGL2008 - 03177/AGR ) .", "label": "", "metadata": {}, "score": "72.910416"}
{"text": "The range of sample size per sense ranges from 10 - 40 , with increments of 10 per sense .Average error rates ( Err .Rate ) and average standard errors ( SE ) were reported for each combination of distribution and sample size ( see Methods section ) .", "label": "", "metadata": {}, "score": "72.98593"}
{"text": "Figure 4 also shows BC - OM outperforming BAN , though the difference in performance is not as marked as in the results of Figures 2 and 3 .In other words , the performance of BC - OM and BAN is similar in terms of the percentage of misclassifications .", "label": "", "metadata": {}, "score": "73.24089"}
{"text": "Class . are the instances of .with the first sense , while .are the instances of . instances in the second sense .Each instance is shown with its context words within certain window size .The target word . is shown in bold face .", "label": "", "metadata": {}, "score": "73.45569"}
{"text": "Conclusion .In this study , we proposed several alternative methods for assessing models in genomic studies of CFS .Our method was also based on the feature selection methods .Our findings suggested that our experiments may provide a plausible way to identify models in CFS .", "label": "", "metadata": {}, "score": "73.53603"}
{"text": "Thus , if this term blood pressure is found in a medical text , the reader has to manually judge and determines which one of these three senses is intended in that text .Word sense disambiguation contributes in many important applications including the text mining , information extraction , and information retrieval systems [ 1 , 2 , 4 ] .", "label": "", "metadata": {}, "score": "73.727295"}
{"text": "It has also been shown that if a curve dominates in PR space , it also dominates in ROC space [ 22].Page 14 .Publish with BioMed Central and every scientist can read your work free of charge \" BioMed Central will be the most significant development for disseminating the results of biomedical research in our lifetime . \"", "label": "", "metadata": {}, "score": "74.182365"}
{"text": "Error Rate versus Sample Size with different sense distributions of BSA data set .This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of BSA data set ( case where the 2 ambiguous senses are very different ) using 5-fold cross - validation .", "label": "", "metadata": {}, "score": "74.18524"}
{"text": "Iterate GLAD algorithm on labeled training data only .Iterate GLAD algorithm on labeled and unlabeled training data .Compare model accuracy on test data across generated populations of models .In these experiments , GLAD was run for 100 iterations with a population size of 5000 , and a subset size of 3 features .", "label": "", "metadata": {}, "score": "74.23802"}
{"text": "( i )Converting all words to lowercase .( ii ) Removing stopwords : removing all common function words like \" is \" \" the \" \" in \" , ... and so forth .( iii )Performing word stemming using Porter stemming algorithm [ 25 ] .", "label": "", "metadata": {}, "score": "74.42153"}
{"text": "In each row , the best of the four classifier results are displayed in bold .If another 's performance is not significantly different from the best , it is also highlighted , but if the differences between all four classifies are not statistically significant , then none of them is highlighted .", "label": "", "metadata": {}, "score": "74.76282"}
{"text": "The UniProt set is composed of 119,016 proteins and 2826 GO terms , which is approximately 17 times larger than Fungi in proteins and 7 times larger in GO terms ( Table 4 ) .In a similar manner , we prepared three more taxon - specific datasets representing the taxonomic groups Bacteria , Viridiplantae , and Vertebrata .", "label": "", "metadata": {}, "score": "75.11574"}
{"text": "View Article PubMed .Whorwood CB , Donovan SJ , Flanagan D , Phillips DI , Byrne CD : Increased glucocorticoid receptor expression in human skeletal muscle cells may contribute to the pathogenesis of the metabolic syndrome .Diabetes 2002 , 51 : 1066 - 1075 .", "label": "", "metadata": {}, "score": "75.34982"}
{"text": "Two ambiguous gene symbol lists were formed as a result of the comparisons : a gene - English list ( containing gene symbols ambiguous with general English words ) and a gene - UMLS list ( containing gene symbols ambiguous with biomedical terms ) .", "label": "", "metadata": {}, "score": "75.662056"}
{"text": "Sensitivity is the proportion of GO term annotations in the training dataset that were correctly annotated by the classifier , and specificity is the proportion of available GO term annotations not assigned to the proteins that were also not assigned to the protein by the classifier .", "label": "", "metadata": {}, "score": "75.77799"}
{"text": "To demonstrate the extent of the ambiguity problem in MEDLINE we searched MEDLINE abstracts to determine how many abstracts contained gene symbols that were ambiguous with general English words or biomedical terms .We repeated the same procedure for the fly and yeast organisms as well .", "label": "", "metadata": {}, "score": "76.019"}
{"text": "In the biomedical domain , word sense ambiguity is a widely spread problem with bioinformatics research effort devoted to it being not commensurate and allowing for more development .This paper presents and evaluates a learning - based approach for sense disambiguation within the biomedical domain .", "label": "", "metadata": {}, "score": "76.16385"}
{"text": "with the highest MI value , and the second entry represents the context word with the second highest MI value and so on .Table 2 shows the top 10 context words with the ten highest MI values for the ambiguous word \" cold \" in the NLM - WSD benchmark corpus explained in Section 3 .", "label": "", "metadata": {}, "score": "76.25426"}
{"text": "In 2000 , the UMLS Metathesaurus [ 6 ] , a comprehensive resource that specifies and categorizes biomedical concepts , contained 9,416 ambiguous terms , and in 2004 , the number increased to 21,295 , an increase of 126 % within 4 years [ 7 ] .", "label": "", "metadata": {}, "score": "76.38987"}
{"text": "In principle , BC - OM is a structure - extension - based algorithm .In BC - OM , we essentially extend the structure of TAN by relaxing the parent set of each attribute node .Thus , the resulting structure is more complex than TAN , but more simple than BAN .", "label": "", "metadata": {}, "score": "76.42024"}
{"text": "Nutch is in fact a full featured web serach engine that anyone can use or modify .Inspired in some famous papers from Google about Map Reduce and the Google Filesystem , new features to distribute the index where added to Nutch and , eventually , those features became a project by them own : Hadoop .", "label": "", "metadata": {}, "score": "76.76485"}
{"text": "For each of the 30 runs we estimated the standard error using the formula : .The estimate of the standard error was then obtained by averaging the above values over the 30 runs .Gene ambiguity for mining MEDLINE .To determine the extent of the gene ambiguity problem in MEDLINE , we searched MEDLINE abstracts to determine how many abstracts contained gene symbols that were ambiguous with general English words or biomedical terms .", "label": "", "metadata": {}, "score": "76.81352"}
{"text": "Join Us .With 1,240,600 monthly unique visitors and over 500 authors we are placed among the top Java related sites around .Constantly being on the lookout for partners ; we encourage you to join us .So If you have a blog with unique and interesting content then you should check out our JCG partners program .", "label": "", "metadata": {}, "score": "76.83939"}
{"text": "Afari N , Buchwald D : Chronic fatigue syndrome : a review .Am J Psychiatry 2003 , 160 : 221 - 236 .View Article PubMed .Reeves WC , Wagner D , Nisenbaum R , Jones JF , Gurbaxani B , Solomon L , Papanicolaou DA , Unger ER , Vernon SD , Heim C : Chronic fatigue syndrome -- a clinically empirical approach to its definition and study .", "label": "", "metadata": {}, "score": "77.194084"}
{"text": "View at Scopus .G. Forman , \" An Extensive Empirical study of feature selection metrics for text classification , \" Journal of Machine Learning Research , vol .3 , pp .1289 - 1305 , 2003 .View at Google Scholar .", "label": "", "metadata": {}, "score": "77.613434"}
{"text": "View Article PubMed .Lin E , Hwang Y , Liang KH , Chen EY : Pattern - recognition techniques with haplotype analysis in pharmacogenomics .Pharmacogenomics 2007 , 8 : 75 - 83 .View Article PubMed .Lin E , Hwang Y , Chen EY : Gene - gene and gene - environment interactions in interferon therapy for chronic hepatitis C. Pharmacogenomics 2007 , 8 : 1327 - 1335 .", "label": "", "metadata": {}, "score": "77.8392"}
{"text": "Department of Biomedical Informatics , Columbia University .Department of Biostatistics , Bioinformatics and Biomathematics , Georgetown University Medical Center .References .Krallinger M , Valencia A : Text - mining and information - retrieval services for molecular biology .Genome Biol 2005 , 6 : 224 .", "label": "", "metadata": {}, "score": "77.994354"}
{"text": "Acknowledgements .This work was supported by part by Grants R01 LM7659 , R01 LM8635 from the National Library of Medicine , and Grants NSF - DMS-0504957 , NSF- IIS-0430743 from the National Science Foundation .We would like to thank Lyudmila Shagina for providing technical support .", "label": "", "metadata": {}, "score": "78.663895"}
{"text": "Performance comparison of GO annotation methods using 71 randomly selected proteins .The evaluation was performed using 71 ( 1 % of the original training dataset ) randomly selected proteins that were held out of the training dataset .All GO terms annotated to the evaluation proteins were considered when computing the performance metrics .", "label": "", "metadata": {}, "score": "79.17077"}
{"text": "JCGs ( Java Code Geeks ) is an independent online community focused on creating the ultimate Java to Java developers resource center ; targeted at the technical architect , technical team lead ( senior developer ) , project manager and junior developers alike .", "label": "", "metadata": {}, "score": "79.20238"}
{"text": "Its main task is to solve the mathematical programming .Moreover , just as other constraint based algorithms , the main cost of BC - OM is the number of conditional independence tests for computing the dependence coefficients of any two variables in step 2 .", "label": "", "metadata": {}, "score": "79.28586"}
{"text": "Mixture of experts - our approach Our approach to learning a mixture of experts model takes into account the global similarity between biomolecular sequences in a data set .Comparison of Precision - Recall curves for Logistic Regression , mixture of Logistic Regression and ensemble of Logistic Regression models on the non - redundant DNA - protein data set at 30 % identity cutoff .", "label": "", "metadata": {}, "score": "79.341255"}
{"text": "In the first evaluation of GLAD performance , test data classification accuracy was compared between models identified using only labeled data and models using both labeled and unlabeled data .Figure 1 shows the results for three cancer groups .The top 5 % of the model populations were used to generate these histograms .", "label": "", "metadata": {}, "score": "79.75603"}
{"text": "Offline example .Now I 'll show you a simple program that I think is a pretty obvious classification example .We are going to classify mail into spam and not - spam ( that is called ham by people that researches it ) .", "label": "", "metadata": {}, "score": "79.814316"}
{"text": "VAT Registration No : 842417633 .Registered Data Controller No : Z1821391 .Registered office : Venture House , Cross Street , Arnold , Nottingham , Nottinghamshire , NG5 7PJ .Affiliated with .Abstract .Background .In the studies of genomics , it is essential to select a small number of genes that are more significant than the others for the association studies of disease susceptibility .", "label": "", "metadata": {}, "score": "80.03595"}
{"text": "Eleventh Conf . on Uncertainty in Artificial Intelligence .Morgan Kaufmann .pp .338 - 345 .Affiliated with .Affiliated with .Abstract .The growing body of DNA microarray data has the potential to advance our understanding of the molecular basis of disease .", "label": "", "metadata": {}, "score": "80.06769"}
{"text": "Furthermore , in species disambiguation , the term c - myc is a gene , but it can be either in a human gene ( homo sapiens ) or mouse gene ( mus musculus ) depending on the context [ 9 - 11 , 14 - 16 ] .", "label": "", "metadata": {}, "score": "80.81746"}
{"text": "Department of Psychiatry , National Taiwan University Hospital Yun - Lin Branch .Graduate Institute of Medicine , Kaohsiung Medical University .Department of Psychiatry , Chi Mei Medical Center .Vita Genomics , Inc .References .Griffith JP , Zarrouf FA : A systematic review of chronic fatigue syndrome : do n't assume it 's depression .", "label": "", "metadata": {}, "score": "81.90021"}
{"text": "In each of them we are going to put a spam directory and a ham directory . test . ham . spam . train . ham . spam .We manually take about 80 % of the ham and put it in train / ham , the rest int test / ham , and the same with the spam in train / spam and test / ham ( it has never been easier to prepare the test set ! ! ! )", "label": "", "metadata": {}, "score": "82.3876"}
{"text": "For each distribution pattern , 4 different total sample sizes were used : 30 , 60 , 120 and 180 .Error rates for each combination of sense distribution and sample size were averaged using 30 runs .Statistical methodology .To quantify the effects of sample size , sense distribution and difficulty of the task on the error rate , appropriate statistical methods were used .", "label": "", "metadata": {}, "score": "82.6558"}
{"text": "Conclusion Identification of functionally important sites in biomo- lecular sequences has broad applications ranging from rational drug design to the analysis of metabolic and sig- nal transduction networks .With the rapid increase in the amount of data ( e.g. , protein sequences ) there is a grow- ing need for reliable procedures to accurately identify such sites .", "label": "", "metadata": {}, "score": "83.75482"}
{"text": "However , application of genomics in routine clinical practice will become a reality after a prospective clinical trial has been conducted to validate genetic markers .Declarations .Acknowledgements .The authors extend their sincere thanks to Vita Genomics , Inc. for funding this research .", "label": "", "metadata": {}, "score": "84.50425"}
{"text": "A number of natural language processing systems in the biomedical domain reported decreased precision due to the ambiguity problem [ 3 , 4 ] .Weeber [ 5 ] found that in order to replicate Swanson 's literature - based discovery of the involvement of magnesium deficiency in migraine , it was important to resolve the ambiguity of an abbreviation mg , which can denote either magnesium or milligram .", "label": "", "metadata": {}, "score": "84.525154"}
{"text": "View Article PubMed .Lin E , Hwang Y , Tzeng CM : A case study of the utility of the HapMap database for pharmacogenomic haplotype analysis in the Taiwanese population .Mol Diagn Ther 2006 , 10 : 367 - 370 .PubMed .", "label": "", "metadata": {}, "score": "85.14751"}
{"text": "Blood 2003 , 102 : 3871 - 9 .View Article PubMed .Copyright .\u00a9 Harris and Ghaffari .This article is published under license to BioMed Central Ltd.About Emmanuel Espina .Something quite interesting has happened with Lucene .It started as a library , then its developers began adding new projects based on it .", "label": "", "metadata": {}, "score": "86.45279"}
{"text": "We demonstrated that our approach is a promising method to assess the associations between CFS and SNPs .Background .Chronic fatigue syndrome ( CFS ) affects at least 3 % of the population , with women being at higher risk than men [ 1 ] .", "label": "", "metadata": {}, "score": "87.60993"}
{"text": "InterPro .InterPro terms [ 18 ] are defined in the InterPro database which is a curated protein domain database that acts as a central reference for several protein family and functional domain databases , including Prosite , Prints , Pfam , Prodom , SMART , TIGRFams and PIR SuperFamily .", "label": "", "metadata": {}, "score": "88.7874"}
{"text": "You give the machine a lot of things , and the machine makes groups of similar items .Recommendation : It is exactly what IMDb or Amazon does with the recommended movies or books at the bottom of the page .Based on other users likes ( which are measured through the ranking stars that the user vote )", "label": "", "metadata": {}, "score": "90.668686"}
{"text": "bin / mahout prepare20newsgroups -p examples / bin / work / spam / train -o examples / bin / work / spam / prepared - train -a org.apache.mahout.vectorizer.DefaultAnalyzer -c UTF-8 bin / mahout prepare20newsgroups -p examples / bin / work / spam / test -o examples / bin / work / spam / prepared - test -a org.apache.mahout.vectorizer.", "label": "", "metadata": {}, "score": "93.26376"}
{"text": "Copyright .\u00a9 Huang et al .2009 .This article is published under license to BioMed Central Ltd.Copyright \u00a9 2013 Sanyang Liu et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "94.66048"}
{"text": "Copyright .\u00a9 Jung et al .2010 .This article is published under license to BioMed Central Ltd.A Learning - Based Approach for Biomedical Word Sense Disambiguation .Copyright \u00a9 2012 Hisham Al - Mubaid and Sandeep Gungu .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "95.57289"}
{"text": "Thus , this significant association strongly suggests that NR3C1 may be involved in biological mechanisms with CFS .The NR3C1 gene encodes the protein for the glucocorticoid receptor , which is expressed in almost every cell in the body and regulates genes that control a wide variety of functions including the development , energy metabolism , and immune response of the organism [ 36 ] .", "label": "", "metadata": {}, "score": "98.23384"}
{"text": "130 - 137 , 1980 .View at Google Scholar", "label": "", "metadata": {}, "score": "100.10532"}
{"text": "Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .Publisher conditions are provided by RoMEO .", "label": "", "metadata": {}, "score": "101.71884"}
{"text": "All trademarks and registered trademarks appearing on Java Code Geeks are the property of their respective owners .Java is a trademark or registered trademark of Oracle Corporation in the United States and other countries .Examples Java Code Geeks is not connected to Oracle Corporation and is not sponsored by Oracle Corporation .", "label": "", "metadata": {}, "score": "103.18873"}
{"text": "If you are the original writer of this essay and would like it removed from UKEssays please email the URL of this essay to us via the link below .Copyright \u00a9 2003 - 2016 - UK Essays is a trading name of All Answers Ltd , a company registered in England and Wales .", "label": "", "metadata": {}, "score": "107.669464"}
{"text": "i .t .h .c .o .r .r .e . c . t . a .s .s .i . g .n .e . d .s .e . n .s .", "label": "", "metadata": {}, "score": "107.79027"}
{"text": "t .o .t . a .l .n .o . . .o .f .t .e . s .t .e . d .i .n .s .t . a .n .", "label": "", "metadata": {}, "score": "108.56323"}
{"text": "A .c .c . u .r . a .c .y .n .o . . .o .f .i .n .s .t . a .n .c .e . s .", "label": "", "metadata": {}, "score": "112.62909"}
