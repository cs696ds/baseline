{"text": "Results .In addition to a 45 % increase in parsing efficiency , we find that the best approach , incorporating information from a domain part - of - speech tagger , offers a statistically significant 10 % relative decrease in error .", "label": "", "metadata": {}, "score": "30.837646"}
{"text": "In this paper , we quantify the effect of parser accuracy on these systems ' performance , and examine the question of whether a flatter \" chunked \" representation of the input can be as effective for the purposes of semantic role identification . .", "label": "", "metadata": {}, "score": "32.46838"}
{"text": "We further separately evaluate overall performance and performance for the subset of sentences where no timeouts occurred in parsing .Default values were used for other parameters .The statistical significance of differences between the original parser and each of the modifications is assessed using the Wilcoxon signed - ranks test [ 30 ] for overall first linkage performance , using the Bonferroni correction for multiple comparisons , following the recent recommendation of Dem\u0161ar [ 31 ] .", "label": "", "metadata": {}, "score": "32.491272"}
{"text": "Unfortunately , existing algorithms are both computationally intensive and difficult to implement .Previous algorithms are expensive due to two factors : the exponential number of rules that mus ... \" .Excellent results have been reported for DataOriented Parsing ( DOP ) of natural language texts ( Bod , 1993c ) .", "label": "", "metadata": {}, "score": "33.55993"}
{"text": "Even more puzzling is the lack of any serious attempt to build a P&P - style parser that is able to learn from unannotated input ( as Klein and Manning 's systems do ) .It seems to us that if the claims on behalf of P&P approaches are to be taken seriously , it is an obvious requirement that someone provide a computational learner that incorporates P&P mechanisms , and uses it to demonstrate learning of the grammar of a natural language .", "label": "", "metadata": {}, "score": "33.68027"}
{"text": "We observe that this assumption holds only partially because of the presence of foreign words in specialized texts and argue that a minimal morphological study of the corpus is necessary .Such studies have been performed , on the biomedical domain by Spyns [ 20 ] and Aubin et al .", "label": "", "metadata": {}, "score": "36.637184"}
{"text": "This may reflect structural ambiguity in the language and suggest a limit on how much ambiguity can be controlled through these lexical adaptation approaches .Performance .The evaluation results are presented in Table 4 .We find that in addition to increased efficiency , all of the extensions offer an increase in overall parsing performance compared to the original LGP for both the first and best linkages .", "label": "", "metadata": {}, "score": "36.704063"}
{"text": "It could play a key role in NLP tasks like Information Extraction , Question Answering and Summarization .We propose a machine learning algorithm for semantic role parsing , extending the work of Gildea and Jurafsky ( 2002 ) , Surdeanu et al .", "label": "", "metadata": {}, "score": "37.794197"}
{"text": "Surprisingly , one approach to grammar that is not represented in work on robust parsing is the Principles and Parameters model , or what has evolved over the last ten years into the ' ' Minimalist Program ' ' ( MP ) .", "label": "", "metadata": {}, "score": "38.125214"}
{"text": "Thus , if the phrases were included , automatic comparison against a reference corpus containing phrase - internal structure would find missing links for the terms .Morphological clues .Morphological clues can be exploited by LGP to predict the morpho - syntactic classes ( and hence syntactic behaviour ) of unknown words .", "label": "", "metadata": {}, "score": "38.989105"}
{"text": "Traditionally such approaches have been limited by the brittleness of the existing parsers .However , recent advances in probabilistic - based parsing allow to overcome such limitations and render such approaches competitive .We discuss below a few systems that make use of full parsing approaches for the analysis of biomedical literature .", "label": "", "metadata": {}, "score": "39.297913"}
{"text": "Typically such systems make use of external resources , such as domain Ontologies , in order to detect the most likely combination of the constituents of the sentences , based on their semantic types .Some examples are [ 23 - 26 ] .", "label": "", "metadata": {}, "score": "39.557175"}
{"text": "They apply a pattern extraction algorithm to induce rules from a development corpus that are then applied to a test corpus .The results are relatively good ( 33 % F - Measure ) for an approach which aims at avoiding manual construction of rules .", "label": "", "metadata": {}, "score": "39.93129"}
{"text": "Given the complexity of the task , typically only a few semantic relations are output , for which the confidence is very high , based on the analysis of large quantities of documents .Our aim is to show how a deep - linguistic approach can be used in a Text Mining application , offering high - precision relation extraction , while at the same time retaining a high recall .", "label": "", "metadata": {}, "score": "40.344204"}
{"text": "There has also been significant progress in the realm of hand - built parsers that adopt certain grammatical frameworks .For example , the PARC LFG parser , developed by Ron Kaplan and colleagues over the past twenty years , with intensive manual labor , performs at a level comparable to current statistical parsers on Penn Treebank data ( Riezler et al .", "label": "", "metadata": {}, "score": "40.49221"}
{"text": "More generally , an adaptive language model seeks to maintain an adequate representation of the current task domain under changing conditions involving potential variations in vocabulary , syntax , content , and style .This paper presents an overview of the major approaches proposed to address this issue , and offers some perspectives regarding their comparative merits and associated tradeoffs .", "label": "", "metadata": {}, "score": "40.563404"}
{"text": "Examples of quite sophisticated patterns have been illustrated .The approach is validated by an evaluation based on the GENIA corpus .The parser described in this paper , the relation mining system , and the evaluation dataset , can be obtained by contacting the authors .", "label": "", "metadata": {}, "score": "40.62818"}
{"text": "The separation of lexical and syntactic analysis often allows us to simplify at least one of these tasks .For example , a parser that had to deal with comments and white space as syntactic units would be .Considerably more complex than one that can assume comments and white space have already been removed by the lexical analyzer .", "label": "", "metadata": {}, "score": "40.901024"}
{"text": "In this paper , we will focus on the extraction of semantic case roles from texts .After setting the essential theoretical framework ... \" .If information extraction wants to make its results more accurate , it will have to resort increasingly to a coherent implementation of natural language semantics .", "label": "", "metadata": {}, "score": "41.056625"}
{"text": "An integrative formulation is proposed for this purpose , in which the latent semantic information is used to adjust the standard n - gram probability .The performance of the resulting multispan language models , as measured by perplexity , compares favorably with the corresponding n - gram performance .", "label": "", "metadata": {}, "score": "41.430325"}
{"text": ".. by Rebecca Hwa , Philip Resnik , Amy Weinberg , Clara Cabezas , Okan Kolak - Natural Language Engineering , 2005 . \" ...Broad coverage , high quality parsers are available for only a handful of languages .A prerequisite for developing broad coverage parsers for more languages is the annotation of text with the desired linguistic representations ( also known as \" treebanking \" ) .", "label": "", "metadata": {}, "score": "41.48371"}
{"text": "The results obtained are comparable to other parsers [ 16 - 18 ] .For the second result , we use a random set from the GENIA corpus in order to assess its performance on the biomedical domain .We have randomly selected 100 sentences from the GENIA corpus , which we have manually annotated for the syntactic relations that the parser can detect .", "label": "", "metadata": {}, "score": "42.137657"}
{"text": "Previous algorithms are expensive due to two factors : the exponential number of rules that must be generated and the use of a Monte Carlo p arsing algorithm .In this paper we solve the first problem by a novel reduction of the DOP model toga small , equivalent probabilistic context - free grammar .", "label": "", "metadata": {}, "score": "42.35148"}
{"text": "Finally , the time required for full parsing is also a problem for IE systems .However , the biomedical IE community now faces limitations in pattern - matching [ 5 ] and shallow parsing [ 6 ] methods that are inefficient in the processing of long distance dependencies and complex sentences .", "label": "", "metadata": {}, "score": "42.362125"}
{"text": "In this paper , we study lexical adaptation , that is , adaptation addressing the specialized vocabulary .This is an important part of the process of customizing a general parser to a sublanguage .Among other issues , the unknown word rate increases dramatically when moving from general language to increasingly technical domains such as that of biomedicine [ 3 ] .", "label": "", "metadata": {}, "score": "42.66719"}
{"text": "The words that are replaced or repeated are no longer part of the intended utterance , and so need to be identified .Segmenting turns and resolving repairs are strongly intertwined with a third task : identifying discourse markers .Because of the interactions , and interactions with POS tagging and speech recognition , we need to address these tasks together and early on in the processing stream .", "label": "", "metadata": {}, "score": "43.017754"}
{"text": "We note that a comparable 14 % reduction was also achieved by Lease and Charniak through POS adaptation for a statistical constituency parser [ 3 ] .This further enforces our conclusion on the value of accurate POS tags in support of the parsing process .", "label": "", "metadata": {}, "score": "43.09341"}
{"text": "This partitions local subtrees of depth one ( corresponding to CFG rules ) into left and right contexts ( relative to head ) .The annotation al .. \" ...Interactive spoken dialogue provides many new challenges for natural language understanding systems .", "label": "", "metadata": {}, "score": "43.1606"}
{"text": "We have designed the search algorithm so that a few basic syntactic patterns are expanded by default .This includes for example the case of conjunctions , as it can be seen in one of the examples shown in figure 2 .", "label": "", "metadata": {}, "score": "43.307938"}
{"text": "Among the systems that participated , the experience of [ 30 ] shows that an approach based on syntactic information can deliver very good results .A different approach , based on learning simple surface patterns ( which encode only lexical information , word order and PoS tags ) is followed by [ 31 ] .", "label": "", "metadata": {}, "score": "43.505405"}
{"text": "In fact many robust parsers map Penn Tree Bank analyses into alternative formal representations .All that is required is that the designer of the parser also produce code that converts from the P&P parser 's syntactic structures back into appropriate treebank structures , so that proper evaluation of its output is possible .", "label": "", "metadata": {}, "score": "43.683628"}
{"text": "By extrapolation we get the approximative recall results in table 3 .Related work .The task of relation extraction can be performed at different levels of complexity .The systems that deal with this task can be broadly classified in three categories , according to the amount of linguistic information brought to bear on the problem .", "label": "", "metadata": {}, "score": "43.709457"}
{"text": "Surely it is long past time to ask for some substantive evidence in the way of a robust grammar induction system that this view of grammar induction is computationally viable .Most other major theoretical models of grammar have succeeded in yielding robust parsers in far less time , despite the fact that they do not , as far we know , make analogous claims about the nature of language learning .", "label": "", "metadata": {}, "score": "43.75759"}
{"text": "Table 1 .Evaluation on Carroll 's test suite on subj , obj , PP - attachment and subordinate clause relations .We have observed that verbs and prepositions , which are especially important for the lexicalized disambiguation , vary far less between general text and the biomedical domain than nouns .", "label": "", "metadata": {}, "score": "43.7612"}
{"text": "In more detailed evaluation , we found that the automatic dictionary extension and the use of a general English POS tagger can reduce performance , while the morpho - guessing approach and the use of a domain - specific POS tagger had only positive effects .", "label": "", "metadata": {}, "score": "44.02398"}
{"text": "In this way it is immediately obvious to the user whether the tools have done a proper job , or a mistake has been introduced at some stage of processing ( see figure 2 ) .When the coverage is satisfactory , it is possible to proceed to an evaluation , like the one described in this section , which however refers to a particular ' snapshot ' of the system at a given point in time .", "label": "", "metadata": {}, "score": "44.323265"}
{"text": "They are not even up to the task of parsing arbitrary Dr. Seuss books , let alone the ' ' Wall Street Journal ' ' .For example , Fong 's English parser , which is arguably the best piece of work of this kind , handles , in its current incarnation , just the example sentences in Lasnik and Uriagereka 's textbook ( 1988 ) .", "label": "", "metadata": {}, "score": "44.50537"}
{"text": "Relative word error rate reductions of between 2 and 7 % over the baseline are achieved in N - best rescoring experiments on the Wall Street Journal corpus .The largest improvement is obtained with a model using automatically determined categories .", "label": "", "metadata": {}, "score": "44.779964"}
{"text": "Although , having said that , you might want to mention if a technology falls down when it comes to having to rewrite a grammar for performance reasons .Please give me an idea of the size and complexity of grammars you have worked with , when answering this question .", "label": "", "metadata": {}, "score": "44.825367"}
{"text": "The extension of the lexicon with external domain - specific knowledge is the most frequent approach to adaptation , provided that the resources are available for the domain .This can be done either manually or with automatic mapping methods .Here , we evaluate the heuristic lexicon mapping proposed by Szolovits [ 13 ] .", "label": "", "metadata": {}, "score": "45.086147"}
{"text": "Unlike ( Collins , 1999 ; Johnson , 2002 ) , in our approach resolution of LDDs is done at f - structure ( attribute - value structure representations of basic predicate - argument or dependency structure ) without empty productions , traces and coindexation in CFG parse trees . ... tation .", "label": "", "metadata": {}, "score": "45.1696"}
{"text": "By contrast , the MG and POS - map methods contribute to the recognition of a great number of types ( particularly in transcript ) but few tokens .In addition , the discrepancy in types between the two corpora for the dictionary method in all versions reflects the increasing presence of low - frequency non - canonical words with the growing size of the corpus .", "label": "", "metadata": {}, "score": "45.220486"}
{"text": "However , with an increasing number of unknown words in a sentence , the approach leads to a combinatorial explosion in the number of possible linkages and a rapid increase in parsing time and decrease in parsing performance .The parser is also time - limited : when a sentence can not be parsed within a user - specified time limit , LGP attempts parses using more efficient , but restricted settings , leading to reduced parse quality .", "label": "", "metadata": {}, "score": "45.265335"}
{"text": "The use of heuristic methods for lexicon expansion carries the risk of mapping errors and should be accompanied by an evaluation of the effect on parsing performance .Conversely , surface clues can provide remarkably good coverage and performance when tuned to the domain , here using as few as 23 new rules .", "label": "", "metadata": {}, "score": "45.411568"}
{"text": "On the task of assigning semantic labels to the PropBank ( Kingsbury , Palmer , & Marcus , 2002 ) corpus , our final system has a precision of 84 % and a recall of 75 % , which are the best results currently reported for this task .", "label": "", "metadata": {}, "score": "45.546967"}
{"text": "Table 1 .Biomedical suffixes involved in the extension of the morpho - guessing rules .POS tagging .Finally , we propose to provide the parser with an input sentence enriched with POS tags .In order to retain the decision - making power of the parser and to avoid inconsistencies between tagged words and their entry in the parser lexicon ( see Grover et al .", "label": "", "metadata": {}, "score": "46.15154"}
{"text": "Proceedings of the Workshop on Adaptive Text Extraction and Mining at the 17th International Joint Conference on Artificial Intelligence ( IJCAI'01 ) ( Edited by : Nebel B ) .Seattle , USA 2001 .Lease M , Charniak E : Parsing Biomedical Literature .", "label": "", "metadata": {}, "score": "46.252922"}
{"text": "There are a number of treebank corpora , of which the Penn Treebank , based largely on ' ' Wall Street Journal ' ' text , and available from the Linguistic Data Consortium , is the most widely used .More impressively , there has been recent work by Dan Klein and Chris Manning on machine learning procedures ( Klein & Manning 2002 , Klein & Manning 2004 ) that infer parsers in an unsupervised fashion from raw text annotated with part - of- speech tags .", "label": "", "metadata": {}, "score": "46.385723"}
{"text": "It does not always deliver a parse spanning the entire sentence , however it never fails completely , always delivering at least partial structures .Table 1 shows a comparison of two evaluations performed using the parser .For the first result , we apply the standard 500 sentence test set for dependency parsers , GREVAL [", "label": "", "metadata": {}, "score": "46.4199"}
{"text": "Corney DPA , Buxton BF , Langdon WB , Jones D :BioRAT : Extracting Biological Information from Full - Length Papers .Bioinformatics 2004 , 20 ( 17 ) : 3206 - 13 .View Article PubMed .Leroy G , Chen H , Martinez JD : A Shallow Parser Based on Closed - Class Words to Capture Relations in Biomedical Text .", "label": "", "metadata": {}, "score": "46.443703"}
{"text": "The antecedents for this general approach to grammar and language acquisition go back to ' ' Syntactic Structures ' ' ( 1957 ) and ' 'Aspects of the Theory of Syntax ' ' ( 1964 ) .The P&P view replaced a model of an innate language faculty consisting of a grammar evaluation metric applied to a set of grammars generated by a universal schema of grammar .", "label": "", "metadata": {}, "score": "46.458664"}
{"text": "Methods .We evaluate three approaches to lexical adaptation : lexicon extension , morphological clues , and POS tagging .The approaches primarily involve open - class words and use linking requirements from the original LGP .Closed - class words , such as prepositions , are considered domain - independent and expected to appear in the original lexicon , and we have chosen not to perform any modification of the existing linking requirements ( grammar adaptation ) in this study .", "label": "", "metadata": {}, "score": "46.698174"}
{"text": "Parsing time is immediately relevant to applications of the parser to systems where large corpora must be parsed .Linkage numbers are a more direct measure of the ambiguity of parsing a sentence .For each sentence , the parser enumerates the total number of linkages allowed by the grammar .", "label": "", "metadata": {}, "score": "46.706306"}
{"text": "Tsivtsivadze E , Pahikkala T , Pyysalo S , Boberg J , Myll\u00e4ri A , Salakoski T : Regularized Least - Squares for Parse Ranking .Proceedings of the 6th International Symposium on Intelligent Data Analysis ( IDA'05 ) ( Edited by : Famili AF , Kok JN , Pe\u00f1a JM , Siebes A , Feelders AJ ) .", "label": "", "metadata": {}, "score": "46.708027"}
{"text": "This paper investigates the role of resource allocation as a source of processing difficulty in human sentence comprehension .The paper proposes a simple informationtheoretic characterization of processing difficulty as the work incurred by resource reallocation during parallel , incremental , probabi ... \" .", "label": "", "metadata": {}, "score": "46.85006"}
{"text": "Broad coverage , high quality parsers are available for only a handful of languages .A prerequisite for developing broad coverage parsers for more languages is the annotation of text with the desired linguistic representations ( also known as \" treebanking \" ) .", "label": "", "metadata": {}, "score": "47.00344"}
{"text": "Nevertheless , as the size of the dictionary does not significantly penalize the parsing time with LGP , even a generic resource that contributes relatively little can be beneficial .Ambiguity .The results of measuring the effect of the various extensions on ambiguity are given in Table 3 .", "label": "", "metadata": {}, "score": "47.082947"}
{"text": "Here , we consider the lexical adaptation of a full parser , the Link Grammar Parser ( LGP ) of Sleator and Temperley [ 10 , 11 ] .The choice of parser addresses the recent interest in LGP in the biomedical IE community [ 12 - 15 ] .", "label": "", "metadata": {}, "score": "47.146114"}
{"text": "We reformulate the task as a combined chunking and classification problem , thus allowing our algorithm to be applied to new languages or genres of text for which statistical syntactic parsers may not be available . \" ...Probabilistic Context - Free Grammars ( PCFGs ) and variations on them have recently become some of the most common formalisms for parsing .", "label": "", "metadata": {}, "score": "47.192596"}
{"text": "Removing the P&P component must seriously degrade performance .Second , the particular choice of parameters and their possible settings , must conform to some recognized version of a P&P theory proposed in the literature .We recognize that it may be necessary to augment the set of accepted parameters with additional conditions that are motivated by particular problems in learning grammatical structures .", "label": "", "metadata": {}, "score": "47.244766"}
{"text": "After setting the essential theoretical framework , we will argue that it is possible to detect case roles on the basis of morphosyntactic and lexical surface phenomena .We will give a concise overview of our methodology and of a preliminary test that seems to confirm our hypotheses . by Jason Michael Eisner , Jason Michael Eisner , Supervisor Professor , Mitch Marcus , 2001 . \" ...", "label": "", "metadata": {}, "score": "47.319733"}
{"text": "Conclusion .We have studied three lexical adaptation approaches addressing biomedical domain vocabulary not found in the lexicon of the Link Grammar Parser : automatic lexicon expansion , surface clue based morpho - guessing , and the use of a POS tagger .", "label": "", "metadata": {}, "score": "47.595474"}
{"text": "By solving these simultaneously , we obtain better results on each task than addressing them separately .Our model is able to identify 72 % of turn - internal intonational boundaries with a precision of 71 % , 97 % of discourse markers with 96 % precision , and detect and correct 66 % of repairs with 74 % precision . .", "label": "", "metadata": {}, "score": "47.661396"}
{"text": "And they do not naturally produce a syntactic structure ( such as parse - trees ) that is convenient to derive the semantics of the program , i.e. to generate the compiled code .There are a number of reasons why the analysis portion of a compiler is normally separated into lexical analysis and parsing ( syntax analysis ) phases .", "label": "", "metadata": {}, "score": "47.87909"}
{"text": "Third , we recognize that the assumptions about syntactic structure used by the Penn Treebank ( and other treebanks ) differ in many details from those of the P&P tradition .In particular , P&P work generally assumes a far more articulated syntactic structure than is generally employed in other frameworks .", "label": "", "metadata": {}, "score": "48.023666"}
{"text": "Reply : Certainly this is true .The obvious question here is why this has been the case .Positing a theory that makes such far reaching claims about mechanisms underlying language learning would seem to us to commit the adherents of such a theory to the task of demonstrating its viability through implementation of a large scale model .", "label": "", "metadata": {}, "score": "48.228657"}
{"text": "Results .We describe and evaluate an environment supporting the extraction of domain - specific relations , such as protein - protein interactions , from a richly - annotated corpus .We use full , deep - linguistic parsing and manually created , versatile patterns , expressing a large set of syntactic alternations , plus semantic ontology information .", "label": "", "metadata": {}, "score": "48.254776"}
{"text": "We report the per - sentence averages of both parsing time and linkage number ratios .To determine the parsing performance of the extensions of LGP , we used each of the extensions to parse the interaction corpus sentences and compared the produced linkages against the reference corpus .", "label": "", "metadata": {}, "score": "48.270603"}
{"text": "Our algorithm is based on Support Vector Machines which we show give large improvement in performance over earlier classifiers .We show performance improvements through a number of new features designed to improve generalization to unseen data , such as automatic clustering of verbs .", "label": "", "metadata": {}, "score": "48.358482"}
{"text": "On the second level we combine various patterns into a single semantic rule , which normalizes many possible syntactic variants ( e.g. active , passive , nominalizations ) .On the third level we combine semantic rules with lexical and ontological constraints to obtain very specialized queries that can detect a given domain - specific relation , as specified by the user .", "label": "", "metadata": {}, "score": "48.401463"}
{"text": "A Course in GB Syntax : Lectures on Binding and Empty Categories .MIT Press .Roark , Brian and Johnson , Mark .Efficient probabilistic top - down and left - corner parsing .In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics , pages 421 - 428 .", "label": "", "metadata": {}, "score": "48.421738"}
{"text": "The aim of language model adaptation is to exploit specific , albeit limited , knowledge about the recognition task to compensate ... \" .Speech recognition performance is severely affected when the lexical , syntactic , or semantic characteristics of the discourse in the training and recognition tasks differ .", "label": "", "metadata": {}, "score": "48.50966"}
{"text": "Chomsky sketched this view in ' ' Some Notes on Economy of Derivation and Representation ' ' in 1991 , and then presented a detailed account in his book ' 'The Minimalist Program ' ' in 1995 .Much subsequent theoretical work has been done within the MP .", "label": "", "metadata": {}, "score": "48.613075"}
{"text": "One notable exception is Brill 's TransformationBased Error Driven system ( Brill , 1993 ) , which induces a set of transformations designed to maximize the Consistent ... . by Aoife Cahill , Michael Burke , Josef Van Genabith , Andy Way - In Proceedings of the 42nd Meeting of the ACL , 2004 . \" ...", "label": "", "metadata": {}, "score": "48.67479"}
{"text": "I found that it greatly simplified the program .My main motivation was to get the auto - correcting aspect .That just works .It 's practically free !Also , I much preferred writing my parser in an applicative style as opposed to the monadic style of Parsec .", "label": "", "metadata": {}, "score": "48.924274"}
{"text": "The reason is 2-fold , speed and flexibility .When processing large multi - Gigabyte output files , parser speed becomes the limiting factor .When performing multiple analyses , the availability of a fast parser library tool that can be plugged into a program suited to one particular task is an important factor .", "label": "", "metadata": {}, "score": "49.14418"}
{"text": "While we found that the considered approaches can significantly improve efficiency and parsing performance , our results also indicate some limitations for lexical adaptation .As future work , complementary approaches addressing multi - word expressions , grammar adaptation , text preprocessing , handling of complex terms , improved parse ranking and named entity recognition can be considered to further improve the applicability of LGP to the biomedical domain .", "label": "", "metadata": {}, "score": "49.24789"}
{"text": "This paper compares various category - based language models when used in conjunction with a word - based trigram by means of linear interpolation .Categories corresponding to parts - of - speech as well as automatically clustered groupings are considered .", "label": "", "metadata": {}, "score": "49.258884"}
{"text": "This paper compares various category - based language models when used in conjunction with a word - based trigram by means of linear interpolation .Categories corresponding to parts - of - speech as well as automatically clustered groupings are considered .", "label": "", "metadata": {}, "score": "49.258884"}
{"text": "Context - free grammars are well - known to parse , so they are widely used for describing programming languages ' syntax .But there 's more .Sometimes a more general grammar is needed -- when you have more things to count at the same time , independently .", "label": "", "metadata": {}, "score": "49.372997"}
{"text": "The best setup correctly identifies 79 % of breaks in the test corpus .\u00a9 1998 Academic Press Limited 1 . ... cause syntactic parses themselves are unhelpful .These have been shown to significantly outperform rule - driven parsers .", "label": "", "metadata": {}, "score": "49.51236"}
{"text": "Usually it 's only one big tree for the whole document / source file , because the whole document / source file is a proper sentence for them .But there are n't any reasons why parser could n't produce a series of syntax trees on its output .", "label": "", "metadata": {}, "score": "49.54974"}
{"text": "The traditional use of these probabilities is to improve the probabilities of grammar rules .In this thesis we show that these values are useful for solving many other problems in Statistical Natural Language Processing .We give a framework for describing parsers .", "label": "", "metadata": {}, "score": "49.603844"}
{"text": "Until recently , most Information Extraction ( IE ) systems for mining semantic relationships from texts of technical sublanguages avoided full syntactic parsing .The quality of parsing has a well - established effect on the performance of IE systems , and the accuracy of general parsers in technical domains is comparatively low .", "label": "", "metadata": {}, "score": "49.632774"}
{"text": "In the absence of a gold standard , only approximative recall values can be reported .In [ 2 ] we report a value of 40 % for a measure that we call \" worst - case recall \" , which basically implies that our actual recall is at least as good as this value .", "label": "", "metadata": {}, "score": "49.637367"}
{"text": "Tsivtsivadze E , Pahikkala T , Boberg J , Salakoski T : Locality - Convolution Kernel and Its Application to Dependency Parse Ranking .Proceedings of the The 19th International Conference on Industrial , Engineering & Other Applications of Applied Intelligent Systems ( Edited by : Ali M , Dapoigny R ) .", "label": "", "metadata": {}, "score": "49.649498"}
{"text": "1 , pp .35 - 42 .Klein , Dan and Manning , Christopher .Corpus - Based Induction of Syntactic Structure : Models of Dependency and Constituency . ' ' Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ( ACL 2004 ) .", "label": "", "metadata": {}, "score": "49.717587"}
{"text": "The experiments show that our approach described is capable of delivering high - precision results , while maintaining sufficient levels of recall .The high level of abstraction of the rules used by the system , which are considerably more powerful and versatile than finite - state approaches , allows speedy interactive development and validation .", "label": "", "metadata": {}, "score": "49.75416"}
{"text": "To estimate these probabilities for words that were poorly ob - served during training , this thesis assumes the existence of arbitrarily powerful transfor - mations ( also known to linguis ... \" .Probabilistic parsing requires a lexicon that specifies each word 's syntactic preferences in terms of probabilities .", "label": "", "metadata": {}, "score": "49.79808"}
{"text": "Note that a LR(0 ) parser would not be able to make this decision , as it only considers the core of the items , and would thus report a shift / reduce conflict .Tools . by Srinivas Bangalore , Aravind K. Joshi - Computational Linguistics , 1999 . \" ... this paper , we have proposed novel methods for robust parsing that integrate the flexibility of linguistically motivated lexical descriptions with the robustness of statistical techniques .", "label": "", "metadata": {}, "score": "50.123375"}
{"text": "This proposal subsumes and clarifies findings that high - constraint contexts can facilitate lexical processing , and connects these findings to well - known models of parallel constraint - based comprehension .In addition , the theory leads to a number of specific predictions about the role of expectation in syntactic comprehension , including the reversal of locality - based difficulty patterns in syntactically constrained contexts , and conditions under which increased ambiguity facilitates processing .", "label": "", "metadata": {}, "score": "50.124413"}
{"text": "This paper presents an algorithm for automatically assigning phrase breaks to unrestricted text for use in a text - to - speech synthesizer .Text is first converted into a sequence of part - of - speech tags .Next a Markov model is used to give the most likely sequence of phrase breaks for the input part - of ... \" .", "label": "", "metadata": {}, "score": "50.26693"}
{"text": "Such discovery relies on a parsimonious vector representation of each word and each document in a suitable , common vector space .Since in this space familiar clustering techniques can be applied , it becomes possible to derive several families of large - span language models , with various smoothing properties .", "label": "", "metadata": {}, "score": "50.274208"}
{"text": "5 ] LALR(1 ) parsers have been the most common implementations of the LR Parser .Recently , some parser generators are offering minimal LR(1 ) parsers , which not only solve the memory requirement problem , but also the mysterious - conflict - problem inherent in LALR(1 ) parser generators .", "label": "", "metadata": {}, "score": "50.40409"}
{"text": "partial parsing technique .In this paper we present two approaches : contextual models , which exploit a variety of features in order to improve supertag performance , and class - based models , which assign sets of supertags to words in order to substantially improve accuracy with only a slight increase in ambiguity . by B. Srinivas , Christine Doran , Beth Ann Hockey , Aravind Joshi - In Proceedings of the Eight European Summer School In Logic , Language and Information , 1996 . \" ...", "label": "", "metadata": {}, "score": "50.457077"}
{"text": "Note that for connected , acyclic dependency graphs , precision equals recall : for each missing link , there is exactly one extra link .While there are some exceptions to connectedness and acyclicity in both LGP linkages and the annotation , we believe recall can be used as a fair estimate of overall performance .", "label": "", "metadata": {}, "score": "50.472923"}
{"text": "Most of today 's state - of - the - art speech recognition systems can recognize only words that belong to some predefined finite word vocabulary .When encountering an OOV word , a speech reco ... \" .This thesis concerns the problem of unknown or out - of - vocabulary ( 00V ) words in continuous speech recognition .", "label": "", "metadata": {}, "score": "50.545975"}
{"text": "Head - Driven Statistical Models for Natural Language Parsing .PhD Dissertation , University of Pennsylvania .Fong , Sandiway .Computational Properties of Principled - Based Grammatical Theories , AI Laboratory , MIT .Fong , Sandiway .Computation with Probes and Goals : A Parsing Perspective . ' '", "label": "", "metadata": {}, "score": "50.55125"}
{"text": "Such patterns can be manually written , or , more frequently , automatically induced from a manually annotated corpus .An example of this approach is given by [ 22 ] .While surface patterns are easy to learn and computationally efficient , they fail to generalize on even the most obvious linguistic variations .", "label": "", "metadata": {}, "score": "50.642338"}
{"text": "On the basis of this comparison and the reported performance of GENIA Tagger , we estimate that for the subset of words that are handled by the POS - mapping method , the tagging accuracy is 81 % for the Brill tagger and 97 % for GENIA Tagger .", "label": "", "metadata": {}, "score": "50.716827"}
{"text": "It may be organized as a hack in some compilers , but it does not have to be .Also it is not just that CS parsers ( in the sense used in other answers here ) are hard to build , and less efficient .", "label": "", "metadata": {}, "score": "50.745995"}
{"text": "Minnen G , Carroll J , Pearce D : Applied morphological processing of English .Natural Language Engineering 2001 , 7 ( 3 ) : 207 - 223 .View Article .Mikheev A : Automatic rule induction for unknown word guessing .", "label": "", "metadata": {}, "score": "50.844234"}
{"text": "We are only asking for supervised grammar induction , when , in fact , unsupervised learning on the basis of parameterized principles would be the more reasonable test of the model 's viability .P&P advocates have long eschewed the existence of negative evidence in the learning process , and insisted that grammar induction takes place with very little external data .", "label": "", "metadata": {}, "score": "50.949554"}
{"text": "We evaluated all possible combinations of the three extensions .In these experiments we only used GENIA Tagger for the POS extension .The results are given in Tables 5 and 6 .On ambiguity , we observe small advantages for many of the combinations , but rarely more than a 10 % reduction for either metric compared to the simple extensions .", "label": "", "metadata": {}, "score": "50.977203"}
{"text": "One of the ideas is to enhance this dictionary by adding certain functions , in order to capitalize on the data .Rather than being a . \" ...A speaker or writer has to find words for expressing his thoughts .", "label": "", "metadata": {}, "score": "51.22229"}
{"text": "For psycholinguistics , these problems include the practical problem of which frequencies to use for norming psychological experiments , as well as the more theoretical issue of which frequencies are represented in the mental lexicon and how those frequencies are learned .", "label": "", "metadata": {}, "score": "51.260162"}
{"text": "For both arguments the exact results [ Y ] are above 50 % .When we slightly relax the precision criteria and include the cases [ A ] where the argument has been correctly identified , but incorrectly expanded , precision jumps to about 90 % .", "label": "", "metadata": {}, "score": "51.26661"}
{"text": "In this article , we explore using parallel text to help solving the problem of creating syntactic annotation in more languages .The central idea is to annotate the English side of a parallel corpus , project the analysis to the second language , and then train a stochastic analyzer on the resulting noisy annotations .", "label": "", "metadata": {}, "score": "51.373077"}
{"text": "Conclusions and future work .In this paper we have presented an approach aimed at supporting the process of extraction of core relational information from scientific literature in the biomedical domain .We have based our experiments on an extended version of the manually - annotated GENIA corpus .", "label": "", "metadata": {}, "score": "51.41049"}
{"text": "3.3.3 Questions about Word Identities .Instead , we view the word identities as a further refinement of the POS tags .We start the clustering algorithm wit ... . ... ssible values of P w i c(w i i\\Gamman+1 ) are bucketed .", "label": "", "metadata": {}, "score": "51.541286"}
{"text": "Besides , there might be a significant time lag between the publication of a result and its introduction into such databases .Relevant articles have to be selected and accurately read by human experts looking for the core information .This process is usually referred to as curation of the article .", "label": "", "metadata": {}, "score": "51.54142"}
{"text": "They infer structure from distributional patterns in a more or less unannotated sequence of tokens .The Klein - Manning procedures do not yet perform as well on held out test data as the supervised systems , but they are quickly converging on supervised results .", "label": "", "metadata": {}, "score": "51.55652"}
{"text": "They are syntactically marked because they can have several PP arguments .Biomedical relational nouns like overexpression or transcription are absent from the Penn Treebank or rare .We use an unsupervised approach based on [ 19 ] to learn relational nouns from Medline .", "label": "", "metadata": {}, "score": "51.613388"}
{"text": "This process entails identifying groups of words in a sentence ... \" .The natural language processing community has recently experienced a growth of interest in domain independent shallow semantic parsing - the process of assigning a WHO did WHAT to WHOM , WHEN , WHERE , WHY , HOW etc . structure to plain text .", "label": "", "metadata": {}, "score": "51.615303"}
{"text": "Park J , Kim H , Kim J : Bidirectional Incremental Parsing for Automatic Pathway Identication with Combinatory Categorial Grammar .Proceedings of the 6th Pacific Symposium on Biocomputing ( PSB'01 ) 2001 , 396 - 407 .Clegg A , Shepherd A : Evaluating and Integrating Treebank Parsers on a Biomedical Corpus .", "label": "", "metadata": {}, "score": "51.695766"}
{"text": "Vocabulary coverage .Figure 2 shows the proportion of vocabulary covered by each method on the interaction and transcript corpora .Coverage for the POS adaptation is shown only for GENIA Tagger as the coverage of the Brill tagger was essentially identical .", "label": "", "metadata": {}, "score": "51.82566"}
{"text": "Using ithe optimizations , experiments yield a 97 % crossing brackets rate and 88 % zero crossing brackets rate .This differs significantly from the results reported by Bod , and is compara- ble to results from a duplication of Pereira and Schabes 's ( 1992 ) experiment on the same data .", "label": "", "metadata": {}, "score": "51.967567"}
{"text": "They may be unified by deciding to use \" parsing \" technology to recognize \" words \" , as is currently explored by so - called scannerless GLR parsers .That has a runtime cost , as you are applying more general machinery to what is often a problem that does n't need it , and usually you pay for that in overhead .", "label": "", "metadata": {}, "score": "52.023613"}
{"text": "They are evaluated according to their user - friendliness , analysis features and high - throughput data processing capabilities .Canonical LR parser .[ 1 ] It can handle all deterministic context - free languages .[ 1 ] In the past this LR(k ) parser has been avoided because of its huge memory requirements in favor of less powerful alternatives such as the LALR and the LL(1 ) parser .", "label": "", "metadata": {}, "score": "52.081505"}
{"text": "Therefore for this experiment we use an existing manually annotated corpus .However , in [ 2 ] we describe how our system can cope with an automatically annotated corpus using an external tool for the detection of the domain entities and terminology .", "label": "", "metadata": {}, "score": "52.141743"}
{"text": "Proceedings of the 7th Pacific Symposium on Biocomputing ( PSB'02 ) ( Edited by : Altman RB , Dunker AK , Hunter L , Lauderdale K , Klein TE ) .Yakushiji A , Tateisi Y , Miyao Y , Tsujii J : Event Extraction from Biomedical Papers Using a Full Parser .", "label": "", "metadata": {}, "score": "52.185688"}
{"text": "\u0394 columns give relative decrease in error with respect to the original LGP , and p values are for \" All , first linkage \" performance .The positive effect of the extensions on parsing performance is linked to the reduced number of timeouts that occurred when parsing .", "label": "", "metadata": {}, "score": "52.210747"}
{"text": "For example , in a LR(1 ) grammar , all of the following rules transition to a different state in spite of being based on the same state sequence .The same would not be true if a lookahead terminal was not being taken into account .", "label": "", "metadata": {}, "score": "52.238586"}
{"text": "trivial use of the assumptions of the P&P approach to syntax .Again , this is the point of the challenge , given that P&P makes very strong claims about how these grammatical assumptions are essential to language learning .Objection 2 : There have been very few people working in P&P parsing .", "label": "", "metadata": {}, "score": "52.309196"}
{"text": "[ 4 ] .We chose to evaluate the version of the dictionary extension that does not include multi - word terms [ 18 ] for the following reasons .First , Szolovits observed that many of the phrases included in the extension \" bear no specific lexical information in Specialist that is not obvious from their component words \" , suggesting that it is sufficient to include the component words in the parser lexicon separately .", "label": "", "metadata": {}, "score": "52.31985"}
{"text": "Statistical systems have been trained to automatically label semantic roles from the output of statistical parsers on unannotated text .In this paper , we quantify the ef ... \" .Broad - coverage corpora annotated with semantic role , or argument structure , information are becoming available for the first time .", "label": "", "metadata": {}, "score": "52.450905"}
{"text": "Grammars are models of competence , parsers are models of performance .Reply : No we are not .Please note that we have been careful to impose no requirements on algorithms for learning or for the resulting parser .Thus we make no claims and set no expectations on mode of implementation ( i.e. performance ) .", "label": "", "metadata": {}, "score": "52.559624"}
{"text": "Rindflesch T , Fiszman M , Libbus B : Semantic Interpretation for the Biomedical Literature .Medical Informatics : Advances in Knowledge Management and Data Mining in Biomedicine ( Edited by : Chen H , Fuller WHS , Friedman C ) .", "label": "", "metadata": {}, "score": "52.5934"}
{"text": "Abstractly , the proposed \" transformation models \" are probability distributions that arise from graph random walks with a log - linear parameterization .A domain expert con - structs the parameterized graph , and a vertex is likely according to whether random walks . ... is less likely to get stuck in a poor local maximum .", "label": "", "metadata": {}, "score": "52.595543"}
{"text": "Text is first converted into a sequence of part - of - speech tags .Next a Markov model is used to give the most likely sequence of phrase breaks for the input part - of - speech tags .In the Markov model , states represent types of phrase break and the transitions between states represent the likelihoods of sequences of phrase types occurring .", "label": "", "metadata": {}, "score": "52.89382"}
{"text": "Zerg is being used in our laboratory as an intermediate step in building contigs from 700000 ESTs ( Camargo et al . , 2001 ) .In this case , all sequences are compared to each other using BLASTN , thus generating a 60 GB output file .", "label": "", "metadata": {}, "score": "53.059288"}
{"text": "POSSIBLE OBJECTIONS .We outline here some possible objections to our challenge that might be raised by proponents of P&P approaches to grammar .These objections are anticipated , in part , on the basis of the experience of one of the authors with a prior debate on the scientific foundations of Minimalism .", "label": "", "metadata": {}, "score": "53.07639"}
{"text": "The parser uses a hand - written grammar expressing linguistic competence and a statistical language model that calculates lexicalized attachment probabilities , thus expressing linguistic performance .The parser expresses distinctions that are especially important for a predicate - argument based deep syntactic representation , as far as they are expressed in the Penn Treebank training data [ 15 ] .", "label": "", "metadata": {}, "score": "53.215996"}
{"text": "This is not the complete item set 0 , though .The resulting item set is called the closure of the item set we began with .For LR(1 ) for each production rule an item has to be included for each possible lookahead terminal following the rule .", "label": "", "metadata": {}, "score": "53.25937"}
{"text": "Kim JD , Ohta T , Tateisi Y , Tsujii J : GENIA Corpus - a semantically annotated corpus for bio - textmining .Bioinformatics 2003 , 19 : i180 - 182 .View Article PubMed .Kulick S , Bies A , Liberman M , Mandel M , McDonald R , Palmer M , Schein A , Ungar L : Integrated Annotation for Biomedical Information Extraction .", "label": "", "metadata": {}, "score": "53.291317"}
{"text": "Parsing the corpus .We use a robust , deep - syntactic , broad - coverage probabilistic Dependency Parser [ 11 ] , which identifies grammatical relations between the heads of chunks , chunk - internal dependencies , and the majority of long - distance dependencies [ 12 ] .", "label": "", "metadata": {}, "score": "53.585976"}
{"text": "REFERENCES Altschul , S. Madden , T. et al .( 1997 )Gapped BLAST and PSI- BLAST : a new generation of protein database search programs .Nucleic Acids Res ., 25 , 3389 - 3402 .Burke , J. , Davison , D. and Hide , W. ( 1999 ) d2 cluster : a validated method for clustering EST and full - length cDNAsequences .", "label": "", "metadata": {}, "score": "53.645775"}
{"text": "The reduction in the number of unknown words for the UMLS and xMG extensions is coupled with a roughly 30 % reduction in both parsing time and linkage numbers .Although the POS extension essentially eliminates unknown words , it only gives a decrease in parsing time and linkage numbers that roughly mirrors the effect of the UMLS and xMG extensions .", "label": "", "metadata": {}, "score": "53.77745"}
{"text": "We describe how to estimate the rates of the transformations from a sample of lexical entries .More deeply , we learn which properties of a transformation increase or decrease its rate in the language .As a result , we can smooth the probabilities of lexical entries .", "label": "", "metadata": {}, "score": "53.77838"}
{"text": "We present the contribution of each method ( dictionary , morpho - guessing , POS - mapping and unknown words ) implemented in LGP to handle vocabulary .Results are given separately for types ( i.e. distinct forms ) and tokens ( i.e. occurrences ) in the corpus .", "label": "", "metadata": {}, "score": "53.833153"}
{"text": "Recently , two approaches addressing unknown words in applying LGP to the biomedical domain have been proposed .Szolovits [ 13 ] introduced a method for heuristically mapping terminology between lexicons and applied this mapping to augment the LGP dictionary with terms from the UMLS Specialist Lexicon [ 16 ] .", "label": "", "metadata": {}, "score": "53.874214"}
{"text": "For example , in figure 2 it can be seen that each result bears the name of the rule that generated it ( last argument of the third column ) .This allows immediate detection of problems and their quick correction .", "label": "", "metadata": {}, "score": "53.978676"}
{"text": "Background .In applying general parsers to specific domains , adaptation is often necessary to achieve high parsing performance ( see e.g. [ 1 ] ) .Sublanguage is defined by Grishman [ 2 ] as a specialized form of a natural language that is used within a particular domain or subject matter .", "label": "", "metadata": {}, "score": "54.03649"}
{"text": "This section describes the approach taken in analyzing the input corpus .The tools that we use for such processing steps are organized into a Natural Language Processing pipeline including a fast , deep - linguistic statistical dependency parser .The pipeline and the parser are described separately below .", "label": "", "metadata": {}, "score": "54.108566"}
{"text": "Knowing that , you can now probably recognize a grammar for a regular expression ( that is , regular grammar ) as one which can be expressed in a single EBNF production consisting only from terminal symbols .More generally , you can recognize regular grammars when you see productions similar to these : .", "label": "", "metadata": {}, "score": "54.3499"}
{"text": "First , the system must use P&P in a non - trivial way .So for example , using a standard machine learning algorithm to extract a statistical parser like those in existence , supplemented by a transducer that maps Penn Tree Bank structures into P&P annotations would not satisfy the challenge .", "label": "", "metadata": {}, "score": "54.45929"}
{"text": "The annotated interaction corpus is also used as the reference corpus for the evaluation of parsing performance .Aubin et al .[17 ] used the transcript corpus in defining the MG extension rules .By contrast , the interaction corpus , used here to evaluate performance , is a blind test set with respect to all evaluated extensions .", "label": "", "metadata": {}, "score": "54.55136"}
{"text": "For large sets of data , valuable information can be gained by processing BLAST reports automatically , usually with the help of a BLAST parser .Several BLAST parser libraries and parsing programs are available , including a recently published one ( Xing and Brendel , 2001 ) .", "label": "", "metadata": {}, "score": "54.704296"}
{"text": "17 ] .While many POS taggers employ morphological features to tag unknown words , domain extension of a rule - based approach such as the LGP morpho - guessing system can be preferable in lexical adaptation to domains where resources such as tagged corpora are not available for training taggers .", "label": "", "metadata": {}, "score": "54.742996"}
{"text": "Schneider G , Rinaldi F , Dowdall J : Fast , Deep - Linguistic Statistical Minimalist Dependency Parsing .COLING-2004 workshop on Recent Advances in Dependency Grammars , August 2004 , Geneva , Switzerland 2004 .Schneider G : Extracting and Using Trace - Free Functional Dependencies from the Penn Treebank to Reduce Parsing Complexity .", "label": "", "metadata": {}, "score": "54.74939"}
{"text": "This reformulation is important because it could allow the techniques of qualitative reasoning to be harnessed for natural language understanding and it expands the range of phenomena that can be described in NL semantics .We show that these ideas can account for a large percentage of a small corpus of explanatory text , and that they support the construction of QP models from such texts . .", "label": "", "metadata": {}, "score": "54.804817"}
{"text": "When available , a high - quality domain part - of - speech tagger is the best solution to unknown word issues in the domain adaptation of a general parser .In the absence of such a resource , surface clues can provide remarkably good coverage and performance when tuned to the domain .", "label": "", "metadata": {}, "score": "54.834763"}
{"text": "A ] cases can be considered almost correct , as it easy ( by simply examining the highlighted arguments ) to detect the correct boundaries of the argument , should that be required .Unresolved pronouns [ P ] need a reader to deal with a substantially larger context ( e.g. \" this protein \" , referring to a protein mentioned in the previous sentence ) .", "label": "", "metadata": {}, "score": "54.897133"}
{"text": "After spending two months in countries where he could n't speak the language , Peter became fascinated by language , and so decided to give computational linguistics a try . by T.R. Niesler , E. W. D. Whittaker , P.C. Woodland - Proc .", "label": "", "metadata": {}, "score": "54.925774"}
{"text": "High - quality domain entity recognition is therefore key to successful parsing in the biomedical domain , as we show in [ 20 ] .Methods : Relation mining .Our approach to relation mining is based on 3 levels of rules .", "label": "", "metadata": {}, "score": "54.940475"}
{"text": "Further , each lexical item is associated with as many supertags as the number of different syntactic contexts in which the lexical item can appear .This makes the number of different descriptions for each lexical item much larger , than when the descriptions are less complex ; thus increasing the local ambiguity for a parser .", "label": "", "metadata": {}, "score": "54.996056"}
{"text": "4 The parallel corpus is aligned at the word level using the GIZA++ implementation of the IBM statistical translation models ( Brown et al . ... . by Sameer Pradhan , Kadri Hacioglu , Valerie Krugler , Wayne Ward , James H. Martin , Daniel Jurafsky , 2005 . \" ...", "label": "", "metadata": {}, "score": "55.049774"}
{"text": "For example , the above rule will substitute R into S , but only when it 's in between A and B , leaving those A and B themselves unchanged .This kind of syntax is really hard to parse , because it needs a full - blown Turing machine .", "label": "", "metadata": {}, "score": "55.116074"}
{"text": "Grammar understood by lexers : regular grammar ( Chomsky 's level 3 ) .Grammar understood by parsers : context - free grammar ( Chomsky 's level 2 ) .They attach semantics ( meaning ) to the language pieces they find .", "label": "", "metadata": {}, "score": "55.13569"}
{"text": "Two corpora are used for the present evaluation : \" interaction \" and \" transcript \" , both built in the context of IE from biomedical texts .Both corpora were tokenized and cleared of bibliographic references in a preprocessing step .", "label": "", "metadata": {}, "score": "55.396133"}
{"text": "Despite significant improvements in parsing performance , the best performance achieved by any LGP extension is 88 % .This may again suggest a limit on what performance can be achieved through the lexical adaptation approaches .Combinations of the extensions .", "label": "", "metadata": {}, "score": "55.428425"}
{"text": "Item set 5 ( ' ( ' ) : .From item sets 2 , 4 and 5 several more item sets will be produced .The complete list is quite long and thus will not be stated here .Detailed LR(k ) treatment of this grammar can e.g. be found in [ 1 ] .", "label": "", "metadata": {}, "score": "55.464928"}
{"text": "Note that in comparing taggers trained on different resources , we observe both effects relating to the training corpus and effects relating to the performance of the tagger .A detailed evaluation and error analysis of GENIA Tagger is given in [ 24 ] , finding 98 % accuracy on two biomedical corpora .", "label": "", "metadata": {}, "score": "55.54463"}
{"text": "Link grammar parsing .The lexical adaptation approaches we evaluate require only a light linguistic analysis of domain language , facilitating their application to domain adaptation .Similarly , as Link Grammar is rule - based and its parser makes no use of statistical methods , LGP is a good candidate for adaptation to new domains where annotated corpus data is rarely available .", "label": "", "metadata": {}, "score": "55.59453"}
{"text": "THE CHALLENGE .We challenge someone to produce , by May of 2008 , a working P&P parser that can be trained in a supervised fashion on a standard treebank , such as the Penn Treebank , and perform in a range comparable to state - of - the - art statistical parsers .", "label": "", "metadata": {}, "score": "55.71512"}
{"text": "IEEE Computer Society , Los Alamitos , CA 2003 , 467 - 471 .View Article .Szolovits P : Adding a Medical Lexicon to an English Parser .Proceedings of the 2003 AMIA Annual Symposium ( Edited by : Musen M ) .", "label": "", "metadata": {}, "score": "55.736588"}
{"text": "LR(1 ) parsers have the requirement that each rule should be expressed in a complete LR(1 ) manner , i.e. a sequence of two states with a specific lookahead .That makes simple rules such as .requiring a great many artificial rules that essentially enumerate the combinations of all the possible states and lookahead terminals that can follow .", "label": "", "metadata": {}, "score": "55.81241"}
{"text": "It makes it easy to describe parsers that compute a wide variety of interesting quantities , including the inside and outside probabilities , as well as related quantities such as Viterbi probabilities and n - best lists .We also present three novel uses for the inside and outside probabilities .", "label": "", "metadata": {}, "score": "55.90814"}
{"text": "We present a system for identifying the semantic relationships , or semantic roles , filled by constituents of a sentence within a semantic frame .We use frame semantics as a level of representation intermediate between task - specific templates commonly used in information extraction and complete theor ... \" .", "label": "", "metadata": {}, "score": "56.125763"}
{"text": "The effect of the proposed extensions on parsing performance against an annotated reference corpus was not evaluated in these two studies .Here we analyze the effect of these lexical extensions using an annotated biomedical corpus .We further propose , implement and evaluate in detail a third approach to resolving unknown words in LGP using information from a part - of - speech ( POS ) tagger .", "label": "", "metadata": {}, "score": "56.27829"}
{"text": "Szolovits applied the introduced mapping to extend the lexicon of LGP with terms from the UMLS Specialist Lexicon and observed that the mapping heuristic chose poor definitions for some smaller sets , for which the definitions were manually modified .The created dictionary extension contains 121,120 words that do not appear in the original LGP dictionary .", "label": "", "metadata": {}, "score": "56.304974"}
{"text": "But there are natural languages where plural agreement depends on the actual semantic meaning of words , so that it does not fit well with syntax .Many definitions of programming languages in denotational semantics place declarations and type checking in the semantics .", "label": "", "metadata": {}, "score": "56.74468"}
{"text": "LNAI 3581 .Huang M , Zhu X , Payan DG , Qu K , Li M : Discovering Patterns to Extract Protein - Protein Interactions from Full Texts .OUP Bioinformatics 2004 , 20 ( 18 ) : 3604 - 3612 .", "label": "", "metadata": {}, "score": "56.78392"}
{"text": "We have implemented patterns and rules that can cope with these cases , but they have not been evaluated yet , and therefore for the present study they are not further considered .Ontology - based queries .If a domain Ontology is available , our system can make use of it in the query process , by using the types as restrictions for the arguments .", "label": "", "metadata": {}, "score": "56.816864"}
{"text": "Bioinformatics 2005 , 22 ( 6 ) : 645 - 650 .View Article PubMed .Daraselia N , Egorov S , Yazhuk A , Novichkova S , Yuryev A , Mazo I : Extracting Protein Function Information from MEDLINE Using a Full - Sentence Parser .", "label": "", "metadata": {}, "score": "56.88923"}
{"text": "Compiler efficiency is improved .A separate lexical analyzer allows us to apply specialized techniques that serve only the lexical task , not the job of parsing .In addition , specialized buffering techniques for reading input characters can speed up the compiler significantly .", "label": "", "metadata": {}, "score": "56.927185"}
{"text": "It is optimized for speed , being especially useful for large - scale genomic analysis .Benchmark tests show that Zerg is over two orders of magnitude faster than some widely used BLAST parsers . nih.gov/Genbank/ ) .The most used sequence search tool is BLAST ( Altschul et al . , 1997 ) , which generates a user- friendly alignment output that highlights identities and discrepancies in aligned sequences .", "label": "", "metadata": {}, "score": "56.977127"}
{"text": "E.g. when you have an expression x+3 and in one context this x could be a name of a variable , and in other context it could be a name of a function etc . .Level 1 : Context - sensitive grammars .", "label": "", "metadata": {}, "score": "57.090164"}
{"text": "EPILOGUE .We will close by noting that we are in no way suggesting that the construction of a trainable wide - coverage P&P - based parser is impossible .Since no one has attempted this , and no one has even sketched a proposal for how to do it , we simply do not know if it is possible .", "label": "", "metadata": {}, "score": "57.205917"}
{"text": "We use frame semantics as a level of representation intermediate between task - specific templates commonly used in information extraction and complete theories of language understanding using complex semantic structures .The system is based . ... erring on the side of being excessive in [ Gen Judge his ] praise . \" ...", "label": "", "metadata": {}, "score": "57.434868"}
{"text": "Hakenberg J , Plake C , Leser U , Kirsch H , Rebholz - Schuhmann D : LLL'05 Challenge : Genie Interaction Extraction - Identification of Language Patterns Based on Alignment and Finite State Automata .Romacker M , Grandjean N , Parisot P , Kreim O , Cronenberger D , Vachon T , Peitsch M : The UltraLink : An Expert System for Contextual Hyperlinking in Knowledge Management .", "label": "", "metadata": {}, "score": "57.518806"}
{"text": "Table 2 shows the results obtained on a subset of the relations extracted by the system .We asked the domain experts to evaluate each relation and each argument of the relation , and mark them according to the following guidelines : .", "label": "", "metadata": {}, "score": "57.533844"}
{"text": "View Article PubMed .Blaschke C , Andrade MA , Ouzounis CA , Valencia A : Automatic Extraction of Biological Information from Scientific Text : Protein - Protein Interactions .Proceedings of the 7th International Conference on Intelligent Systems for Molecular Biology ( ISMB'99 ) ( Edited by : Lengauer T , Schneider R , Bork P , Brutlag DL , Glasgow JI , Mewes HW , Zimmer R ) .", "label": "", "metadata": {}, "score": "57.718727"}
{"text": "Turku Centre for Computer Science ( TUCS ) and University of Turku .LIPN , Universit\u00e9 Paris 13 & CNRS UMR 7030 .References .Sekine S : The Domain Dependence of Parsing .Proceedings of the 5th ACL Conference on Applied Natural Language Processing ( ANLP'97 ) Washington D.C. , USA 1997 , 96 - 102 .", "label": "", "metadata": {}, "score": "57.98867"}
{"text": "where all the possible lookaheads must be enumerated .That is the reason why LR(1 ) parsers can not be practically implemented without significant memory optimizations .[ 6 ] .LR(1 ) parsing tables are constructed in the same way as LR(0 ) parsing tables with the modification that each Item contains a lookahead terminal .", "label": "", "metadata": {}, "score": "58.09539"}
{"text": "The work presented here studies the performance of vari ... . \" ...In previous work , supertag disambiguation has been presented as a robust .partial parsing technique .In this paper we present two approaches : contextual models , which exploit a variety of features in order to improve supertag performance , and class - based models , which assign sets of supertags ... \" .", "label": "", "metadata": {}, "score": "58.194267"}
{"text": "Programming languages have complex grammars , but you can expect fairly small files .As for data file formats it really behoves the designer of the format to design it in such a way that it allows efficient parsing .For combinator parsers you should n't need many advanced features for a data format file - if you do , either the format is badly designed ( this sometimes happens unfortunately ) or your parser is .", "label": "", "metadata": {}, "score": "58.209877"}
{"text": "Why bother ?Reply : This is exactly the case that we exclude as not satisfying the challenge .The P&P approach makes claims not only about the nature of syntactic representation but the way in which grammar is acquired .Because it purports to be first and foremost a learning theory , it is necessary to show that this model can yield a robust grammar learning device in order for the framework to sustain any credibility .", "label": "", "metadata": {}, "score": "58.215675"}
{"text": "Better in this context being faster - not just ByteString vs. Char , but I think Attoparsec does less work regarding error handling / source location tracking so the parsers should run faster as they are doing less work per input element .", "label": "", "metadata": {}, "score": "58.250015"}
{"text": "These analyses demonstrate the importance of closely related genomic sequence for correctly identifying and classifying bona fide endogenous DNA fragments .We show that more accurate genome divergence estimates from ancient DNA sequence can be attained using at least two outgroup genomes and appropriate filtering .", "label": "", "metadata": {}, "score": "58.356056"}
{"text": "Symbols for the parser : the particular tokens , which are terminal symbols of their grammar .They analyse these symbols and try to match them with the grammar of the language they understood .And here 's where the real difference usually lies .", "label": "", "metadata": {}, "score": "58.36966"}
{"text": "New rules can make use of rules defined at lower levels , some of which remain stable across different applications .In order to simplify the process of evaluation and shorten the development cycle , we have created visualization tools ( based on XML , CSS and CGI scripts ) , that can display the results in a browser .", "label": "", "metadata": {}, "score": "58.370026"}
{"text": "Such complex rules can be designed by listing all the syntactic and lexical constraints , or alternatively can be constructed combining syntactic and semantic rules , as in the example below : .We refer to relations defined at this level as domain relations as they rely on lexical constraints which are typical of a given domain .", "label": "", "metadata": {}, "score": "58.407608"}
{"text": "It is based on the notion of typed links connecting words .The result of parsing is one or more ordered parses , termed linkages .A linkage consists of a set of links connecting the words of a sentence so that links do not cross , no two links connect the same two words , and the types of the links satisfy the linking requirements given to each word in the lexicon .", "label": "", "metadata": {}, "score": "58.528023"}
{"text": "We have implemented and evaluated the extension of the LGP morpho - guessing rules proposed by Aubin et al .[17 ] .This extension of 23 new suffixes for the biomedical domain is presented in Table 1 .Aubin et al .", "label": "", "metadata": {}, "score": "58.533146"}
{"text": "We extract LFG subcategorisation frames and paths linking LDD reentrancie ... \" .This paper shows how finite approximations of long distance dependency ( LDD ) resolution can be obtained automatically for wide - coverage , robust , probabilistic Lexical - Functional Grammar ( LFG ) resources acquired from treebanks .", "label": "", "metadata": {}, "score": "58.818756"}
{"text": "Rinaldi F , Schneider G , Kaljurand K , Hess M , Andronis C , Konstanti O , Persidis A : Mining of Functional Relations between Genes and Proteins over Biomedical Scientific Literature using a Deep - Linguistic Approach .Journal of Artificial Intelligence in Medicine 2006 , in press .", "label": "", "metadata": {}, "score": "58.91761"}
{"text": "The lookahead can help avoid reducing a specific rule if the lookahead is not valid , which would probably mean that the current state should be combined with the following instead of the previous state .That means that in the following example .", "label": "", "metadata": {}, "score": "59.12985"}
{"text": "Hours on wikipedia and google did n't help , but you explained Chomsky 's grammars in 3 minutes .Thank you . - enrey Mar 20 ' 13 at 15:26 .Lexers are used to recognize \" words \" that make up language elements , because the structure of such words is generally simple .", "label": "", "metadata": {}, "score": "59.155487"}
{"text": "Even for the best linkage in sentences where no timeouts occurred , the performance with the xMG extension and the POS extension with GENIA Tagger is better than that of the original LGP .These extensions can thus assign more appropriate linking requirements for some words than the unknown word system of LGP .", "label": "", "metadata": {}, "score": "59.342728"}
{"text": "To assign a lexical description to a word w not in the target lexicon , the mapping finds words that have the exact same lexical description as w in the source lexicon , and that further have a description in the target lexicon .", "label": "", "metadata": {}, "score": "59.437702"}
{"text": "On the task of extracting human protein interactions they report 91 % precision and 21 % recall .GENIES [29 ] is a system , based on a DCG grammar , which processes biomedical literature in order to detect information about cellular pathways .", "label": "", "metadata": {}, "score": "59.54293"}
{"text": "We defined such a mapping , presented in Table 2 , for Penn tagset POS categories corresponding to content words .FW ( foreign words ) and SYM ( symbols ) tags were not mapped due to their syntactic heterogeneity .Existing LGP rules were used to define the behaviour of POS - mapped words , and the most generic applicable rule was chosen in each case .", "label": "", "metadata": {}, "score": "59.580708"}
{"text": "When these probabilities are multiplied together and normalized , they produce the probabili ... \" .Probabilistic Context - Free Grammars ( PCFGs ) and variations on them have recently become some of the most common formalisms for parsing .It is common with PCFGs to compute the inside and outside probabilities .", "label": "", "metadata": {}, "score": "59.60457"}
{"text": "Two linkages for an example sentence are shown in Figure 1 .LGP has three different methods applied in a cascade to handle vocabulary : dictionary lookup , morpho - guessing and unknown word guessing .The LGP dictionary enumerates all words , including inflected forms , and grammar rules are encoded through the linking requirements associated with the words .", "label": "", "metadata": {}, "score": "59.77011"}
{"text": "Proc of EACL 03 , Budapest , Hungary 2003 , 291 - 296 .Rinaldi F , Schneider G , Kaljurand K , Hess M , Andronis C , Persidis A , Konstanti O : Relation Mining over a Corpus of Scientific Literature .", "label": "", "metadata": {}, "score": "59.858612"}
{"text": "this paper , we have proposed novel methods for robust parsing that integrate the flexibility of linguistically motivated lexical descriptions with the robustness of statistical techniques .Our thesis is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions ( Supertags ) that impose complex constraints in a local context .", "label": "", "metadata": {}, "score": "59.87436"}
{"text": "Rules : . the state sequence can be reduced to .A , A2 . instead of .A1 , C . if the lookahead after the parser went to state B was n't acceptable , i.e. no transition rule existed .", "label": "", "metadata": {}, "score": "60.073925"}
{"text": "While statistical n - gram modeling can readily take local constraints into account , global constraints have been more difficult to handle within a data - driven formalism .In this work , they are captured via a paradigm first formulated in the context of information retrieval , called latent semantic analysis ( LSA ) .", "label": "", "metadata": {}, "score": "60.109936"}
{"text": "Sleator DD , Temperley D : Parsing English with a Link Grammar .Tech Rep CMU - CS-91 - 196 Department of Computer Science , Carnegie Mellon University , Pittsburgh , PA 1991 .Ding J , Berleant D , Xu J , Fulmer AW : Extracting Biochemical Interactions from MEDLINE Using a Link Grammar Parser .", "label": "", "metadata": {}, "score": "60.17057"}
{"text": "It takes a parser to determine that phrase structure is wrong ( in English grammar ) .-Alan May 24 ' 10 at 15:16 .i guess a parser is to a lexer as a tree walker is to a parser .", "label": "", "metadata": {}, "score": "60.271244"}
{"text": "Because \" amino_acid \" is a supertype of \" protein_molecule \" , according to the given ontology ( although this might appear incorrect to a domain expert ) , the results of the latter include ( and expand ) the results of the former .", "label": "", "metadata": {}, "score": "60.333412"}
{"text": "INTRODUCTION Language models based on n - grams of word - categories 1 are intrinsically able to generalise to unseen word sequences , and hence offer improved robustness to novel or rare word combinations .In isolation , such models represent a c .. d robustness to novel or rare word combinations .", "label": "", "metadata": {}, "score": "60.452858"}
{"text": "This paper describes issues surrounding the planning and design of GermanFrameNet ( GFN ) , a counterpart to the English - based FrameNet project .The goals of GFN are ( a ) to create lexical entries for German nouns , verbs , and adjectives that correspond to existing FrameNet entries , and ( b ) to link the parallel lexicon fragments by means of common semantic frames and numerical indexing mechanisms .", "label": "", "metadata": {}, "score": "60.5853"}
{"text": "The theory is different , because it has been proposed by many different people and use different terminology and algorithms .But if you look them closely , you can spot the similarities .For example , the problem of left recursion is very similar to the problem of non - determinism in NFAs , and removing left recursion is similar to removing non - determinism and converting NFA into DFA .", "label": "", "metadata": {}, "score": "60.602806"}
{"text": "Wilcoxon F : Individual Comparisons by Ranking Methods .Biometrics 1945 , 1 : 80 - 83 .View Article .Dem\u0161ar J : Statistical Comparisons of Classifiers over Multiple Data Sets .Journal of Machine Learning Research 2006 , 7 : 1 - 30 .", "label": "", "metadata": {}, "score": "60.608055"}
{"text": "I do n't deny the differences ( Chomsky levels ) , but similarities help a lot in design . -SasQ Feb 19 ' 12 at 18:24 .My officemate was into category theory .He showed how the categorical theory notion of sheaves covered all kinds of pattern matching , and was able to derive LR parsing from an abstract categorical specification .", "label": "", "metadata": {}, "score": "60.61207"}
{"text": "The parallel lexicon fragments represent an important step towards capturing valuable information about the different syntactic realizations of frame semantic concepts across languages , which is relevant for information retrieval , machine translation , and language generation .By ... . \" ...", "label": "", "metadata": {}, "score": "60.699417"}
{"text": "Many people try to use regular expressions when context - free parsing is needed .They always fail .And they blame regular expression technology .That 's much like complaining that your hammer is a crummy saw .True , but you wo n't get a lot of sympathy . -", "label": "", "metadata": {}, "score": "60.74923"}
{"text": "A fundamental point in programming is that a system component should be buit with the most appropriate technology , so that it is easy to produce , to understand and to maintain .The technology should not be overkill ( using techniques much more complex and costly than needed ) , nor should it be at the limit of its power , thus requiring technical contortions to achieve the desired goal .", "label": "", "metadata": {}, "score": "60.856007"}
{"text": "Proceedings of the COLING NLPBA / BioNLP Workshop ( Edited by : Collier N , Ruch P , Nazarenko A ) .Geneva , Switzerland 2004 , 43 - 49 .Aubin S , Nazarenko A , N\u00e9dellec C : Adapting a General Parser to a Sublanguage .", "label": "", "metadata": {}, "score": "60.91967"}
{"text": "REFERENCES .Berwick , Robert .Locality Principles and the Acquisition of Syntactic Knowledge .PhD Dissertation , MIT .Charniak , Eugene .Statistical parsing with a context - free grammar and word statistics ' ' , Proceedings of the Fourteenth National Conference on Artificial Intelligence AAAI Press / MIT Press , Menlo Park .", "label": "", "metadata": {}, "score": "60.977463"}
{"text": "By choosing a parsing algorithm appropriate for the evaluation metric , better performance can be achieved .We present two new algorithms : the \" Labelled Recall Algorithm , \" which maximizes the expected Labelled Recall Rate , and the \" Bracketed Recall Algorithm , \" which maximizes the Bracketed Recall Rate .", "label": "", "metadata": {}, "score": "61.17563"}
{"text": "1 Introduction In this paper , we present a robust parsing approach called supertagging that integrates the flexibility of linguistically motivated lexical descriptions with the robustness of statistical techniques .The idea underlying the approach is that the ... . \" ...", "label": "", "metadata": {}, "score": "61.20154"}
{"text": "Oh yeah ?So what are those \" words or tokens \" ?They 're just sentences in the regular language , consisting of letters of the alphabet .And what are those \" constructs \" or \" trees \" in the parser ?", "label": "", "metadata": {}, "score": "61.236267"}
{"text": "Of course , the answer to this question may depend on the domain , in which case , I 'd be happy to learn this fact .Many good questions generate some degree of opinion based on expert experience , but answers to this question will tend to be almost entirely based on opinions , rather than facts , references , or specific expertise .", "label": "", "metadata": {}, "score": "61.282883"}
{"text": "All this information is represented as a set of predicates and stored into the KB of the system , which can then be queried using the methodology described in section \" Relation Mining \" .Example of Dependency Tree .Tree of dependencies for a GENIA sentence , along with other linguistic annotations .", "label": "", "metadata": {}, "score": "61.40808"}
{"text": "or PrB\u00f0wqjhq\u00de , and the particular method selected for estimation and/or smoothing .A large body of work has also experimented with various hybrids , for example by combining n - grams with probabilistic finite - state automata ( e.g. , Galescu and All ... . \" ...", "label": "", "metadata": {}, "score": "61.491196"}
{"text": "They read symbols of some alphabet from their input .Hint :The alphabet does n't necessarily have to be of letters .But it has to be of symbols which are atomic for the language understood by parser / lexer .", "label": "", "metadata": {}, "score": "61.815598"}
{"text": "In 1965 Donald Knuth invented the LR(k ) parser ( L eft to right , R ightmost derivation parser ) a type of shift - reduce parser , as a generalization of existing precedence parsers .This parser has the potential of recognizing all deterministic context - free languages and can produce both left and right derivations of statements encountered in the input file .", "label": "", "metadata": {}, "score": "61.880447"}
{"text": "We present our extensive experiments on real data sets to evaluate the technique , and show the significant performance improvements on three existing algorithms .Section 6 .Our VGRAM technique can be used by these algorithms to improve their performance .", "label": "", "metadata": {}, "score": "61.900818"}
{"text": "Institute of Computational Linguistics , IFI , University of Zurich .Novartis Pharma AG .References .Jensen LJ , Saric J , Bork P : Literature mining for the biologist : from information retrieval to biological discovery .Nature Reviews Genetics 2006 , 7 : 119 - 129 .", "label": "", "metadata": {}, "score": "61.98949"}
{"text": "While all combinations outperform the original LGP , combinations involving the UMLS extension appear to perform worse than those that do not , while combinations involving the xMG and POS extensions perform better .For sentences where no timeouts occurred the effect is simple : for the best linkage , all combinations involving the UMLS extension perform worse than the original LGP ; only the combination of the xMG and POS extensions is better .", "label": "", "metadata": {}, "score": "62.058884"}
{"text": "However , most parsing algorithms , including the Viterbi algorithm , attempt to optimize the same metric , namely the probability of getting th ... \" .Many different metrics exist for evaluating parsing results , including Viterbi , Crossing Brackets Rate , Zero Crossing Brackets Rate , and several others .", "label": "", "metadata": {}, "score": "62.096687"}
{"text": "The interaction with researchers who work on pharmaceutical topics will clearly provide very valuable feedback .This will help us to better customize our rules and to evaluate the quality of our approach in an iterative manner .A long - term goal is the combination of the results into complex pathway networks , which can then be presented graphically to the users .", "label": "", "metadata": {}, "score": "62.119125"}
{"text": "Affiliated with .Affiliated with .Abstract .Background .We study the adaptation of Link Grammar Parser to the biomedical sublanguage with a focus on domain terms not found in a general parser lexicon .Using two biomedical corpora , we implement and evaluate three approaches to addressing unknown words : automatic lexicon expansion , the use of morphological clues , and disambiguation using a part - of - speech tagger .", "label": "", "metadata": {}, "score": "62.17954"}
{"text": "Schneider G : A broad - coverage , representationally minimal LFG Parser : chunks and F - structures are sufficient .The 10th international LFG Conference ( LFG 2005 ) ( Edited by : Butt M , King TH ) .Bergen , Norway : CSLI 2005 .", "label": "", "metadata": {}, "score": "62.230934"}
{"text": "Eve ... \" .Interactive spoken dialogue provides many new challenges for natural language understanding systems .One of the most critical challenges is simply determining the speaker 's intended utterances : both segmenting a speaker 's turn into utterances and determining the intended words in each utterance .", "label": "", "metadata": {}, "score": "62.27717"}
{"text": "Camargo , A Samaia , H. et al .( 2001 )The contribution of 700000 ' ORF sequence tags ' to the definition of the human transcrip- tome .Proc .Natl Acad .Sci .USA , 98 , 12103 - 12108 .", "label": "", "metadata": {}, "score": "62.45832"}
{"text": "Abstract - A new framework is proposed to construct multispan language models for large vocabulary speech recognition , by exploiting both local and global constraints present in the language .While statistical n - gram modeling can readily take local constraints into account , global constraints have b ... \" .", "label": "", "metadata": {}, "score": "62.535667"}
{"text": "The latter is a standalone program having a default output that may contain more information than required for specific tasks , thus wasting valuable computer time .Zerg parsing engine is based on a single regular expression that matches an entire BLAST report .", "label": "", "metadata": {}, "score": "62.990845"}
{"text": "Reynar JC , Ratnaparkhi A : A Maximum Entropy Approach to Identifying Sentence Boundaries .Proceedings of the Fifth Conference on Applied Natural Language Processing Washington , D.C. : University of Pennsylvania 1997 .Ratnaparkhi A : A Maximum Entropy Part - Of - Speech Tagger .", "label": "", "metadata": {}, "score": "63.02002"}
{"text": "Nothing more advanced above these , then you 're sure it 's a regular syntax and you can go with just lexer for that .But when your syntax uses recursion in a non - trivial way , to produce tree - like , self - similar , nested structures , like the following one : .", "label": "", "metadata": {}, "score": "63.093784"}
{"text": "The point of category theory is you can often abstract \" all the way up \" ; I 'm sure you could build a category theory parser that erased the differences .But any practical uses of it have to instantiate down to the specific problem domain , and then the differences show up as real . -", "label": "", "metadata": {}, "score": "63.1336"}
{"text": "21 ] ) , we restrict the use of POS tags to unknown words only .We modified LGP so that POS information can be passed to the parser by appending POS tags to input words ( e.g. actin / NN ) .", "label": "", "metadata": {}, "score": "63.13822"}
{"text": "Many algorithms are developed using fixed - length grams , which are subs ... \" .Many applications need to solve the following problem of approximate string matching : from a collection of strings , how to find those similar to a given string , or the strings in another ( possibly the same ) collection of strings ?", "label": "", "metadata": {}, "score": "63.1476"}
{"text": "In our example , the starting symbol requires the nonterminal ' E ' which in turn requires ' T ' , thus all production rules will appear in item set 0 .At first , we ignore the problem of finding the lookaheads and just look at the case of an LR(0 ) , whose items do not contain lookahead terminals .", "label": "", "metadata": {}, "score": "63.15827"}
{"text": "Parsers are used to recognize \" structure \" of a language phrases .Such structure is generally far beyond what \" regular expressions \" can recognize , so one needs \" context sensitive \" parsers to extract such structure .Context - sensitive parsers are hard to build , so the engineering compromise is to use \" context - free \" grammars and add hacks to the parsers ( \" symbol tables \" , etc . ) to handle the context - sensitive part .", "label": "", "metadata": {}, "score": "63.383682"}
{"text": "Starting from the production rules of a language , at first the item sets for this language have to be determined .In plain words , an item set is the list of production rules , which the currently processed symbol might be part of .", "label": "", "metadata": {}, "score": "63.555954"}
{"text": "So what 's all about these \" Chomsky 's grammar levels \" ?Well , Noam Chomsky classified grammars into four levels depending on their complexity : .Level 3 : Regular grammars They use regular expressions , that is , they can consist only of the symbols of alphabet ( a , b ) , their concatenations ( ab , aba , bbb etd . )", "label": "", "metadata": {}, "score": "63.563072"}
{"text": "When encountering an OOV word , a speech recognizer erroneously substitutes the OOV word with a similarly sounding word from its vocabulary .Furthermore , a recognition error due to an OOV word tends to spread errors into neighboring words ; dramatically degrading overall recognition performance . \" ...", "label": "", "metadata": {}, "score": "63.58793"}
{"text": "3 Answers 3 .It really depends what you start with and what you want to do .There is n't a one size fits all .If have an LR grammar ( e.g. you are working from a Yacc grammar ) , it is a good deal of work to turn it into an LL one suitable for Parsec or uu - parsinglib .", "label": "", "metadata": {}, "score": "63.64828"}
{"text": "Items sets will be generated by analog to the procedure for LR(0 ) parsers .The item set 0 which represents the initial state will be created from the starting rule : .The expected lookahead terminal to apply this rule is noted after the comma .", "label": "", "metadata": {}, "score": "63.831474"}
{"text": "For many projects , new sequencing technologies and increased database sizes will increase the BLAST output significantly .Frequently , this output is so large that it is no longer able to be processed manually .As BLAST users are increasingly recruited from mainstream biology without any bioinformatic background , user - friendly programs capable of BLAST output visualization , analysis and post - processing are in demand .", "label": "", "metadata": {}, "score": "64.0914"}
{"text": "The POS extension , as expected , reduces the part of unknown words to almost null .The nature of the words that remain unknown varies depending on the extension .Quite surprisingly , UMLS Specialist lacks a great number of species names ( numerous in transcript ) and frequent gene or protein names ( e.g.", "label": "", "metadata": {}, "score": "64.27026"}
{"text": "They both are associated with fairly simple computational models , the finite state automaton and the push - down stack automaton .Regular languages are a special case of context - free languages , so that lexers could be produced with the somewhat more complex CF technology .", "label": "", "metadata": {}, "score": "64.30725"}
{"text": "Thus , the adapted parser is faster and more accurate than the unmodified LGP in parsing biomedical texts both when used as such and when used together with a domain POS tagger .Further , both extensions are implemented so that defining other morpho - guessing rules and POS - mappings is straightforward , facilitating adaptation of the modified parser to other domains .", "label": "", "metadata": {}, "score": "64.333725"}
{"text": "Simple parsing tables , like those used by the LR(0 ) parser represent grammar rules of the form . which means that if we go from state A to state B then we will go to state A1 .After parameterizing such a rule with a lookahead we have : . which means that the transition will now be performed only if the lookahead terminal is a .", "label": "", "metadata": {}, "score": "64.35361"}
{"text": "For example , . can be declared an error , causing the parser to stop .This means that the lookahead information can also be used to catch errors , as in the following example : .In this case A , B will be reduced to A1 when the lookahead is a , b or c and an error will be reported when the lookahead is d. .", "label": "", "metadata": {}, "score": "64.55552"}
{"text": "Hence using the simpler regular expression based formnalism for lexer does not increase the complexity of syntactic structures of the more complex parser formalisms .This is an absolutely major modularity issue when defining structure and semantics of languages , happily ignored by the high voted answers . - babou Dec 27 ' 14 at 11:39 .", "label": "", "metadata": {}, "score": "64.59333"}
{"text": "The difference is not what you 've said , but in the COMPLEXITY OF THE LANGUAGE USED .Confront your -1 with any handbook about the parsing theory . -SasQ Feb 19 ' 12 at 18:20 .@SasQ Would it be fair to say that both Lexers and Parsers take some grammar and a series of tokens as input ? -", "label": "", "metadata": {}, "score": "64.62152"}
{"text": "Results : Evaluation .The approach followed for creating rules starts from a set of relations that are of particular interest in this domain , such as : activate , bind , block , regulate , control , express .The rule developer is offered a view over all the sentences that might include one of the selected relations ( detected using as keywords the verbs that express such relation and all their grammatical inflections ) .", "label": "", "metadata": {}, "score": "64.63119"}
{"text": "MedScan [ 28 ] makes use of a syntactic parser ( which typically yields a large number of analyses for each sentence ) and a semantic processor which transforms each syntactic tree into a corresponding semantic tree .Information extraction rules are then used to prune the large number of trees and extract from them the information of interest .", "label": "", "metadata": {}, "score": "64.65959"}
{"text": "The first step is the identification of all biological relevant entities ( genes , proteins , diseases , etc . ) .The task is made particularly difficult by the high ambiguity of the entity names in this domain : in addition to a high degree of polysemy and synonymy , very common words can be used as names of entities [ 1 ] .", "label": "", "metadata": {}, "score": "64.763794"}
{"text": "Treebanks : Building and Using Parsed Corpora ( Edited by : Abeill\u00e9 A ) .Dordrecht : Kluwer 2003 , 299 - 316 .Lin D : Dependency - based Evaluation of MINIPAR .Workshop on the Evaluation of Parsing Systems , Granada , Spain 1998 .", "label": "", "metadata": {}, "score": "64.83082"}
{"text": "This kind of grammar is called context - sensitive .You can recognize it by that it has more than one symbol on the left ( before the arrow ) .For example : .You can think of these additional symbols on the left as a \" context \" for applying the rule .", "label": "", "metadata": {}, "score": "64.83685"}
{"text": "You state that EBNF is \" just a convenience / shortcut notation / \" syntactic sugar \" over the standard Chomsky 's Normal Form ( CNF ) grammar rules \" .But CNF has hardly anything to do with the topic at hand .", "label": "", "metadata": {}, "score": "64.87863"}
{"text": "Canonical LR(1 ) parsers have the practical disadvantage of having enormous memory requirements for their internal parser - table representation .In 1969 , Frank DeRemer suggested two simplified versions of the LR parser called LALR and SLR .These parsers require much less memory than Canonical LR(1 ) parsers , but have slightly less language - recognition power .", "label": "", "metadata": {}, "score": "65.08705"}
{"text": "View Article PubMed .Yakushiji A , Miyao Y , Tateisi Y , Tsujii J : Biomedical Information Extraction with Predicate - Argument Structure Patterns .Proceedings of the First International Symposium on Semantic Mining in Biomedicine 2005 , 60 - 69 .", "label": "", "metadata": {}, "score": "65.159134"}
{"text": "We are currently setting up a framework for an intensive collaboration , which will allow us to apply the approach described in this paper to non - annotated corpora , using term recognition tools at Novartis .Since 2001 , Novartis has information extraction and text mining applications in place that are used by hundreds of associates [ 32 ] .", "label": "", "metadata": {}, "score": "65.456856"}
{"text": "This suggest that some errors have occurred in the automatic mapping process .An example of one such error is in the mapping of abbreviations ( e.g. MHC ) to countable nouns , leading to failures to parse in the absence of determiners .", "label": "", "metadata": {}, "score": "65.569214"}
{"text": "\u00a9 Pyysalo et al .2006 .This article is published under license to BioMed Central Ltd.Natural Language Parsing as Statistical Pattern Recognition ( 1994 ) .Tools . by Joshua Goodman - IN PROCEEDINGS OF THE 34TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS , 1996 . \" ...", "label": "", "metadata": {}, "score": "65.69412"}
{"text": "Additionally , the Computational Knowledge Management and Text Mining unit at Novartis supports a number of custom tailored text mining solutions for disease areas and pipelines .One of the core components is an annotator that we intend to apply for the entity recognition task .", "label": "", "metadata": {}, "score": "65.88429"}
{"text": "Sorry , what was your name again , or how to overcome the tip - of - the tongue problem with the help of a computer ?A speaker or writer has to find words for expressing his thoughts .Yet , knowing a word does not guarantee its access .", "label": "", "metadata": {}, "score": "65.937645"}
{"text": "Sorry , what was your name again , or how to overcome the tip - of - the tongue problem with the help of a computer ?A speaker or writer has to find words for expressing his thoughts .Yet , knowing a word does not guarantee its access .", "label": "", "metadata": {}, "score": "65.937645"}
{"text": "Who has n't experienced the problem of looking for a word he knows , yet is unable to access ( in time ) ?Work done by psychologists reveals that people being in this so called tip ... \" .A speaker or writer has to find words for expressing his thoughts .", "label": "", "metadata": {}, "score": "66.1133"}
{"text": "PhD thesis University of Pennsylvania , Philadelphia , USA 1999 .Marcus M , Santorini B , Marcinkiewicz M : Building a Large Annotated Corpus of English : the Penn Treebank .Computational Linguistics 1993 , 19 : 313 - 330 .", "label": "", "metadata": {}, "score": "66.142456"}
{"text": "Bioinformatics 2003 , 19 ( 13 ) : 1699 - 1706 .View Article PubMed .Friedman C , Kra P , Krauthammer MH , Rzhetsky A : GENIES : a Natural - Language Processing System for the Extraction of Molecular Pathways from Journal Articles .", "label": "", "metadata": {}, "score": "66.162895"}
{"text": "Another reason not to use CF formalism for lexers is that it might then be tempting to use the full CF power .But that might raise sructural problems regarding the reading of programs .Fundamentally , most of the structure of program text , from which meaning is extracted , is a tree structure .", "label": "", "metadata": {}, "score": "66.29603"}
{"text": "Information overload is one of the most widely felt problems in our modern society .Individuals have access to a previously unimaginable flood of new information and professionals are confronted in their daily activities with a cornucopia of relevant results .Especially for biomedical scientific literature , there is a pressing need for an efficient approach to access and extract information , in a format that can be easily assimilated by humans or further processed by other automated tools .", "label": "", "metadata": {}, "score": "66.336395"}
{"text": "Who has n't experienced the problem of looking for a word he knows , yet is unable to access ( in time ) ?Work done by psychologists reveals that people being in this so called tip - of - the - tongue state ( TOT ) know a lot about the word : meaning , number of syllables , origine , etc .", "label": "", "metadata": {}, "score": "66.540146"}
{"text": "If you process a lot of text , then the overhead does matter and classical regular expression parsers will continue to be used .Nice explanation , Ira .Adding to your analogy : While lexers are about getting the words right , parsers are about getting the sentences right . \"", "label": "", "metadata": {}, "score": "66.78638"}
{"text": "UG and External Systems .Amsterdam : John Benjamins .Klein , Dan and Manning , Christopher .Natural Language Grammar Induction using a Constituent - Context Model . ' 'In Thomas G. Dietterich , Suzanna Becker , and Zoubin Ghahramani ( eds ) , Advances in Neural Information Processing Systems 14 ( NIPS 2001 ) .", "label": "", "metadata": {}, "score": "66.82389"}
{"text": "This system is termed morpho - guessing ( MG ) .Finally , words that are neither found in the parser dictionary nor recognized by its morpho - guessing rules are assigned all possible combinations of the generic verb , noun and adjective linking requirements .", "label": "", "metadata": {}, "score": "66.96612"}
{"text": "Specifically , we describe how qualitative process theory can be recast in terms of frame semantics , as used in the Berkeley FrameNet project .This reformulation is important because it could allow t ... \" .We propose that qualitative physics can provide an important component of natural language semantics .", "label": "", "metadata": {}, "score": "67.016594"}
{"text": "PEG parsers are clearly a very interesting technology and they have been very popular in other languages after Bryan Ford 's work .My own feeling is that Pappy was much less \" industrial strength \" than Parsec so it never took off in Haskell .", "label": "", "metadata": {}, "score": "67.04856"}
{"text": "Words are mapped from a source lexicon ( e.g. the domain lexicon ) to a target lexicon ( e.g. the parser lexicon ) based on their lexical descriptions .As these descriptions typically differ between lexicons , they can not be transferred directly from one lexicon to another .", "label": "", "metadata": {}, "score": "67.13194"}
{"text": "To determine lookhead terminals , so - called FIRST and FOLLOW sets are used .The FIRST sets can be determined directly from the closures of all nonterminals in the language , while the FOLLOW sets are determined from the items under usage of the FIRST sets .", "label": "", "metadata": {}, "score": "67.21442"}
{"text": "From this the full item set 0 for an LR(1 ) parser can be created , by creating for each item in the LR(0 ) item set one copy for each terminal in the follow set of the LHS nonterminal .Each element of the follow set may be a valid lookahead terminal : . create the closure of the new item set .", "label": "", "metadata": {}, "score": "67.21455"}
{"text": "So CF is not the appropriate tool for lexers , even though it can be used .One of the major differences between regular and CF is that regular languages ( and transducers ) compose very well with almost any formalism in various ways , while CF languages ( and transducers ) do not , not even with themselves ( with a few exceptions ) .", "label": "", "metadata": {}, "score": "67.610214"}
{"text": "The pipeline [ 6 ] performs a sequence of processing tasks , described below .In the case of GENIA , some of these steps ( e.g. tagging , terminology detection ) are not necessary - and are automatically skipped - because the relevant information is already provided in the Corpus .", "label": "", "metadata": {}, "score": "67.659424"}
{"text": "This is a format which is well suited for storage in a relational DB or for analysis with Data Mining algorithms .The dependency relations , together with intermediate results of the pipeline ( tokens , terms , chunks , sentences ) are stored in a Knowledge Base ( KB ) , which can then be queried by a separate module , described later in section \" Relation Mining \" .", "label": "", "metadata": {}, "score": "67.68681"}
{"text": ".. le to estimate the necessary probabilities from relatively sparse text data bases .This imposes an artificially local horizon to the language model and thereby limits its predictive power .Consider , for instance , predicting the word \" fell \" from the word \" stocks \" in the two equival ... . by Peter Anthony Heeman - Department of Computer Science , University of Rochester , 1997 . \" ...", "label": "", "metadata": {}, "score": "67.77141"}
{"text": "It is a fundamental algebraic tool to define the semantics of mathematical formalisms .Hence it is a good intermediate representation , as shown by the success of Abstract Syntax Trees ( AST ) .Note that AST are often different from parse tree because the parsing technology used by many professionals ( Such as LL or LR ) applies only to a subset of CF grammars , thus forcing grammatical distorsions which are later corrected in AST .", "label": "", "metadata": {}, "score": "67.88893"}
{"text": "The UMLS extension provides the most frequent domain - specific lexical items while the xMG extension has the advantage of being able to handle non - canonical ( e.g. mutation / deletion , DNA - regions ) and rare words and misspellings .", "label": "", "metadata": {}, "score": "67.92973"}
{"text": "Section \" Related Work \" surveys related work .We conclude by describing plans for future work in section \" Conclusions and Future Work \" .Methods : Corpus analysis .The base abstracts were selected from Medline using the keywords \" Human \" , \" Blood Cells \" , and \" Transcription Factors \" .", "label": "", "metadata": {}, "score": "68.18071"}
{"text": "2002 ' ' Parsing the Wall Street Journal using a lexical- functional grammar and discriminative estimation techniques . ' ' Proceedings 40th Meeting Association for Computational Linguistics , Philadelphia .Linguistic Field(s ) : Computational Linguistics Discipline of Linguistics Language Acquisition Syntax Text / Corpus Linguistics Tools . \" ...", "label": "", "metadata": {}, "score": "68.27787"}
{"text": "A.C.M.Paquola et al .Table 1 .All tests were performed using a 1GHz Pentium - III with Linux .Average fold slower is the ratio between each observed mean time and the mean time taken by Zerg - C , the test program for the Zerg C library .", "label": "", "metadata": {}, "score": "68.3286"}
{"text": "In overall performance , the UMLS extension and the POS extension with the Brill tagger are roughly equal .The xMG extension outperforms both , and the POS extension with GENIA Tagger has the best performance of all considered extensions .First linkage denotes the linkage ordered first by the parser heuristics and best linkage the best performance achieved by any linkage returned by the parser .", "label": "", "metadata": {}, "score": "68.36598"}
{"text": "After briefly introducing the GENIA corpus in section \" Corpus Analysis \" , we detail the processing steps that have been adopted in order to extract a rich set of linguistic and domain - specific information .Section \" Relation Mining \" shows in particular how the intermediate results of data analysis are used in the Relation Mining task .", "label": "", "metadata": {}, "score": "68.52818"}
{"text": "Here the effects of the extensions diverge : for the first linkage , performance with the UMLS extension and the POS extension with the Brill tagger essentially matches that of the unmodified LGP , while performance with xMG and GENIA Tagger remains better .", "label": "", "metadata": {}, "score": "68.709435"}
{"text": "EBNF really does n't add much to the power of grammars .It 's just a convenience / shortcut notation / \" syntactic sugar \" over the standard Chomsky 's Normal Form ( CNF ) grammar rules .For example , the EBNF alternative : . you can achieve in CNF by just listing each alternative production separately : .", "label": "", "metadata": {}, "score": "68.718254"}
{"text": "Three methods will be presented , the first one being implemented .1 The context or starting point I 'm currently involved in a project ( PA - PILLON ) 1 whose goal is to build a huge multilingual lexical data - base ( English - French - Japanese , Thai ) from which one can extract digital bilingual dictionaries .", "label": "", "metadata": {}, "score": "68.93077"}
{"text": "Most parser technologies are trying to handle context - free languages to some degree ( some do only part , e.g. , LALR , some do it all , e.g. , GLR ) .Most lexer technologies only try to do regular expressions . -", "label": "", "metadata": {}, "score": "68.97393"}
{"text": "Korea : Springer 2005 , 58 - 69 .Pyysalo S , Ginter F , Pahikkala T , Boberg J , J\u00e4rvinen J , Salakoski T : Evaluation of Two Dependency Parsers on Biomedical Corpus Targeted at Protein - Protein Interactions .", "label": "", "metadata": {}, "score": "69.02362"}
{"text": "In addition , we propose alternate metrics for evaluation of partial parsers that can also serve to evaluate full parsers . ...T i ) ?\" Pleasant \" meaning , for example : you can write grammars in a \" natural \" way without having to rewrite them in a convoluted way , and without having to introduce boring boilerplate .", "label": "", "metadata": {}, "score": "69.04683"}
{"text": "As the set of rules is gradually enriched , so are the possible lexico - syntactic variants that can be captured .For example in figure 2 , the last of the examples shown is a case of a complex rule designed to capture the pattern \" A triggers the H of B \" , where H represent a nominalized verb ( activation , regulation , etc . ) .", "label": "", "metadata": {}, "score": "69.10721"}
{"text": "Input - device - specific peculiarities can be restricted to the lexical analyzer . resource _ _ _ Compilers ( 2nd Edition ) written by-Alfred V. Abo Columbia University Monica S. Lam Stanford University Ravi Sethi Avaya Jeffrey D. Ullman Stanford University Full - text .", "label": "", "metadata": {}, "score": "69.119865"}
{"text": "But they 're usually tokens ( lexical classes ) because tokens are a good abstraction : you can change the actual lexemes ( strings ) they stand for , and parser does n't see the change . -SasQ Aug 2 ' 12 at 1:02 .", "label": "", "metadata": {}, "score": "69.24147"}
{"text": "We use separate buckets for each n - gram model being interpolated .In performing this bucketing , we create an array containing how many n - grams occur for each value of P w i c(w i i\\Gamman+1 ) up to ... . \" ...", "label": "", "metadata": {}, "score": "69.25313"}
{"text": "Using S. mansoni homologs , we have employed a parsimonious rationale to compute the total gene losses / gains in nematodes , arthropods and deuterostomes under either the Coelomata or the Ecdysozoa evolutionary hypotheses ; our results show a lower losses / gains number under the latter hypothesis .", "label": "", "metadata": {}, "score": "69.43463"}
{"text": "A if the relation is correct and biologically significant , but includes too much or too little information ( for example because an informative PP is not highlighted or a non informative PP is highlighted ) , treat as correct .P if the relation appears correct , but an anaphora needs to be resolved , treat as incorrect .", "label": "", "metadata": {}, "score": "69.44477"}
{"text": "- stephen tetley Nov 3 ' 10 at 18:52 .@gawi : Yes , it looks good on paper , but I found a paper once which said that the claimed advantages of PEG parsers are largely illusory - ca n't remember which one it was now .", "label": "", "metadata": {}, "score": "69.54765"}
{"text": "I am starting to pick up some speed with antlr , thankfully .A lot of lexing is context - free and sometimes even context dependent also by the way .-Naveen May 25 ' 10 at 5:22 .One fundamental aspect of the lexer vs parser issue is that lexers are based on finite automata ( FSA ) , or more precisely finite transducers ( FST ) .", "label": "", "metadata": {}, "score": "69.57062"}
{"text": "Ahmed ST , Chidambaram D , Davulcu H , Baral C : IntEx : A Syntactic Role Driven Protein - Protein Interaction Extractor for Bio - Medical Text .Proceedings of the ACL - ISMB Workshop on Linking Biological Literature , Ontologies and Databases : Mining Biological Semantics Detroit , USA 2005 , 54 - 61 .", "label": "", "metadata": {}, "score": "69.64978"}
{"text": "An optional convenience package ( Zerg - Perl2 ) is provided that creates a Perl object repre- senting an entire BLAST report for each of the FASTA sequences analyzed in a multi FASTA BLAST output .In order to test if Zerg was indeed a fast engine , we benchmark tested it along with other publicly available parsers and with MuSeqBox , a Blast pars- ing program written in C++ that generates alignment statistics ( Xing and Brendel , 2001 ) .", "label": "", "metadata": {}, "score": "69.7936"}
{"text": "Quite so .They both take a series of symbols from the alphabet they recognize .For lexer , this alphabet consists just of plain characters .For parser , the alphabet consists of terminal symbols , whatever they are defined .", "label": "", "metadata": {}, "score": "69.95679"}
{"text": "( 1999 ) .Processing this same file with BioPerl , a widely - used parser library , would take over 4 days .MuSeqBox would take over 2 hours .In comparison , when using Zerg to parse this BLAST output , the task was completed in approximately 25 min .", "label": "", "metadata": {}, "score": "70.475266"}
{"text": "We have explored these ideas in the context of Lexicalized Tree - Adjoining Grammar ( LTAG ) framework .The supertags in LTAG combine both phrase structure information and dependency information in a single representation .Supertag disambiguation results in a representation that is effectively a parse ( almost parse ) , and the parser needs ' only ' combine the individual supertags .", "label": "", "metadata": {}, "score": "70.58641"}
{"text": "And these \" English Words \" could be tokens ( symbols of the alphabet ) for some higher - level parser which understands \" English Sentences \" language .And all these languages differ only in the complexity of the grammar .", "label": "", "metadata": {}, "score": "71.03152"}
{"text": "Syntactic queries .We have written a set of syntactic rules that capture some of the most important syntactic phenomena , as in the example below , which encodes the passive case : .synRel(passive , [ X1 , X2 , X3 ] , .", "label": "", "metadata": {}, "score": "71.57097"}
{"text": "Work done by psychologists reveals that people being in this so called tip - of - the - tongue state ( TOT ) know a lot about the word : meaning , number of syllables , origine , etc .Speakers are generally able to recognize the word , and if they produce an erroneous word , that token shares many things with the target word ( initial / final letter / phoneme , part of speech , semantic field , etc . ) .", "label": "", "metadata": {}, "score": "71.683266"}
{"text": "dep(prep , X3 , By ) , pos(X2 , ' VBN ' ) , .lemma(By , [ ' by ' , ' through ' , ' via ' ] ) ] ) .Syntactic rules capture general linguistic phenomena and as such are highly reusable across different domains .", "label": "", "metadata": {}, "score": "71.83113"}
{"text": "They can be implemented as state automaton with stack .This stack is used to represent the nesting level of the syntax .In practice , they 're usually implemented as a top - down , recursive - descent parser which uses machine 's procedure call stack to track the nesting level , and use recursively called procedures / functions for every non - terminal symbol in their syntax .", "label": "", "metadata": {}, "score": "72.08971"}
{"text": "Zerg - Perl2 is an optional convenience package that performs additional functions described in the text .In contrast , MuSeqBox ( v. 1.1 ) is a standalone C++ program in which the parser is an integral part .Besides parsing , MuSeqBox performs additional calculations such as coverage of the matching sequences and generates its own default output .", "label": "", "metadata": {}, "score": "72.28245"}
{"text": "Parsers attach meaning by classifying strings of tokens from the input ( sentences ) as the particular nonterminals and building the parse tree .They can attach some additional meaning ( data ) to the recognized elements .E.g. when a lexer recognizes a character sequence constituting a proper number , it can convert it to its binary value and store with the \" number \" token .", "label": "", "metadata": {}, "score": "72.303"}
{"text": "Objection 3 : The MP is a research program , not a fully developed theory .Therefore it ca n't be expected to yield a model that can be implemented as a broad coverage processing device .Reply : This is a remarkable dodge .", "label": "", "metadata": {}, "score": "72.31638"}
{"text": "In this paper we develop a novel technique , called VGRAM , to improve the performance of these algorithms .Its main idea is to judiciously choose high - quality grams of variable lengths from a collection of strings to support queries on the collection .", "label": "", "metadata": {}, "score": "72.4669"}
{"text": "Borovets , Bulgaria 2005 , 89 - 93 .Tsuruoka Y , Tateishi Y , Kim JD , Ohta T , McNaught J , Ananiadou S , Tsujii J : Developing a Robust Part - of - Speech Tagger for Biomedical Text .", "label": "", "metadata": {}, "score": "72.57268"}
{"text": "First one is left recursion ( which usually should be avoided , because Top - Down Recursive Descent parsers can not parse it ) : .Knowing that it generates just an empty string ( ultimately ) followed by zero or more A s , the same string ( but not the same language ! ) can be expressed using right - recursion : .", "label": "", "metadata": {}, "score": "72.60501"}
{"text": "In fact , we would be delighted if someone succeeds in meeting our challenge .Such success would convince us that the P&P enterprise is , after all , a testable theory with genuine scientific content .Richard Sproat , Department of Linguistics Department of Electrical and Computer Engineering Beckman Institute University of Illinois at Urbana - Champaign .", "label": "", "metadata": {}, "score": "73.44216"}
{"text": "Acknowledgements .The work of Sampo Pyysalo has been supported by Tekes , the Finnish Funding Agency for Technology and Innovation .This article has been published as part of BMC Bioinformatics Volume 7 , Supplement 3 , 2006 : Second International Symposium on Semantic Mining in Biomedicine .", "label": "", "metadata": {}, "score": "73.472725"}
{"text": "The choice for me was what I start with , LR grammar - Frown or Happy ( now Happy as Frown is n't maintained ) , otherwise usually Parsec ( as I said uu_parse is nice but lacks the convenience of LanguageDef ) .", "label": "", "metadata": {}, "score": "73.67281"}
{"text": "Regular grammars ca n't handle with nested syntax , e.g. properly nested / matched parentheses ( ( ) ( ) ( ( ) ( ) ) ) , nested HTML / BBcode tags , nested blocks etc .It 's because state automata to deal with it should have to have infinitely many states to handle infinitely many nesting levels .", "label": "", "metadata": {}, "score": "73.87038"}
{"text": "Statement about the fact that programming languages are context - sensitive ( CS ) rather than CF are arbitrary and disputable .The problem is that the separation of syntax and semantics is arbitrary .Checking declarations or type agreement may be seen as either part of syntax , or part of semantics .", "label": "", "metadata": {}, "score": "74.01811"}
{"text": "Semantic queries .The next step is then to combine different syntactic patterns to yield a semantic rule .A generic relation between two arguments ( A and B ) , mediated by a verb or an equivalent relational noun ( H ) , is most commonly expressed by one of the following patterns : . semRel(xrel([H , A , B ] ) , active([A , H , B ] ) ) . semRel(xrel([H , A , B ] ) , passive([B , H , A ] ) ) . semRel(xrel([H , A , B ] ) , nominalization([H , B , A ] ) ) .", "label": "", "metadata": {}, "score": "74.021996"}
{"text": "Period .It is syntactic sugar for standard BNF . - babou Jun 11 ' 14 at 12:35 .To answer the question as asked ( without repeating unduly what appears in other answers ) .Lexers and parsers are not very different , as suggested by the accepted answer .", "label": "", "metadata": {}, "score": "74.15228"}
{"text": "They all produce on their output a proper sentences of the language they recognize .Lexers produce tokens , which are sentences of the regular language they recognize .Each token can have an inner syntax ( though level 3 , not level 2 ) , but that does n't matter for the output data and for the one which reads them .", "label": "", "metadata": {}, "score": "74.16488"}
{"text": "Each item contains a marker , to note at which point the currently processed symbol appears in the rule the item represents .For LR(1 ) parsers , each item is specific to a lookahead terminal , thus the lookahead terminal has also been noted inside each item .", "label": "", "metadata": {}, "score": "74.219986"}
{"text": "Acknowledgements .We are indebted to the creators of the GENIA corpus for providing such a valuable resource .Special thanks to Manfred Klenner for very important comments and suggestions .This article has been published as part of BMC Bioinformatics Volume 7 , Supplement 3 , 2006 : Second International Symposium on Semantic Mining in Biomedicine .", "label": "", "metadata": {}, "score": "74.22919"}
{"text": "This being so , one might want to take advantage of the situation and build a program that assists the speaker / writer by revealing the word that 's on his / her mind ( tongue / pen ) .yes .", "label": "", "metadata": {}, "score": "74.22966"}
{"text": "The equivalence rules expressed above allow the user to formulate powerful queries which capture all the defined variants of the given configuration .For example , the query below returns all the sentences containing a control relation , where A and B are instantiated respectively by the agent and the target of the relation : . applyRel(xrel(['control ' , A , B ] ) ) .", "label": "", "metadata": {}, "score": "74.35669"}
{"text": "In addition , the version of the dictionary extension used here contains no multi - word terms , which prevents the detection of words like vitro and vivo used in the frequent terms in vitro and in vivo .The evaluated xMG extension can not handle gene / protein names either , and also misses frequent technical terms that have no specific morphological features , such as sigma , mutant and plasmid .", "label": "", "metadata": {}, "score": "74.71388"}
{"text": "The design goal when writing Zerg was to provide a fast BLAST output parser library that could be used by a wide variety of programs .The lexical scanner generated by Flex is a C program with a fast regular expression matching engine and an efficient input - buffering scheme .", "label": "", "metadata": {}, "score": "74.73898"}
{"text": "Reference ...Affiliated with .Affiliated with .Affiliated with .Abstract .Background .The biomedical domain is witnessing a rapid growth of the amount of published scientific results , which makes it increasingly difficult to filter the core information .", "label": "", "metadata": {}, "score": "75.03447"}
{"text": "But it is not an absolute rule .To summarize , the simpler structure of token is better analyzed with the simpler technology of regular languages , while the tree oriented structure of the language ( of program syntax ) is better handled by CF grammars .", "label": "", "metadata": {}, "score": "75.867966"}
{"text": "Wiley 2006 , in press .Copyright .\u00a9 Rinaldi et al .2006 .This article is published under license to BioMed Central Ltd.Over the past fifteen years there has been significant progress in the field of statistical parsing .", "label": "", "metadata": {}, "score": "75.87177"}
{"text": "For LL combinator parsing , uu - parsinglib and it predecessor uu - parsing are nice but they are lacking something like Parsec 's Token and Language modules so are perhaps less convenient .Some people like Malcolm Wallace 's Parselib because they have a different model to Parsec for backtracking but I 've no experience of them .", "label": "", "metadata": {}, "score": "76.91066"}
{"text": "Or you can define it as just ' \\n ' to end the instruction with the end of line , like in Python .But the syntax of instruction ( and the parser ) stays unchanged :-)Only lexer needs to be changed . -", "label": "", "metadata": {}, "score": "77.18325"}
{"text": "Bioinformatics , 17 , 744- 745 .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .", "label": "", "metadata": {}, "score": "77.24805"}
{"text": "Pisa , Italy : ECML / PKDD 2004 , 11 - 18 .Kaljurand K , Rinaldi F , Schneider G : Prolog - based query interface to syntactic dependencies extracted from biomedical literature .Tech rep IFI , University of Zurich 2006 .", "label": "", "metadata": {}, "score": "77.3355"}
{"text": "He attended the University of Waterloo where he re - ceived a Bachelors of Mathematics with a joint degree in Pure Mathematics and Com - puter Science in the spring of 1987 .After working two years for a software engineering company , which supposedly used artificial intelligence techniques to automate COBOL and CICS programming , Peter was ready for a change .", "label": "", "metadata": {}, "score": "77.85336"}
{"text": "600 sentences were initially selected randomly from Pubmed with the condition that they contain at least two proteins for which a known interaction was entered into the DIP database [ 27 ] .Each sentence was separately annotated by two annotators , and differences were resolved by discussion .", "label": "", "metadata": {}, "score": "78.02004"}
{"text": "Now you can have a token with the same name associated with it , generated by the lexer .But you can change the actual lexeme it stands for .Eg .you can define STMT_END as ; to have C / C++-like source code .", "label": "", "metadata": {}, "score": "78.02954"}
{"text": "This query returns all the relations where \" NF - kappa B \" is involved as a target ( e.g. \" In T cells , NF - kappa B is activated upon cellular treatment by phorbol esters and the cytokine tumor necrosis factor alpha . \" )", "label": "", "metadata": {}, "score": "78.20347"}
{"text": "A production in a form like the last one B above is called \" erasure \" , because it can erase whatever it stands for in other productions ( product an empty string instead of something else ) .Zero - or - more repetiton from EBNF : . you can obtan by using recursive production , that is , one which embeds itself somewhere in it .", "label": "", "metadata": {}, "score": "78.45358"}
{"text": "how to handle inconsistencies in Blast output files .This is a feature not found in scanners that rely on separate regular expression matches to conclude about each token type and value .Zerg contemplates the existence of single or multiple HSPs in a BLAST output .", "label": "", "metadata": {}, "score": "79.29412"}
{"text": "So it 'll tokenize the SGML document into a series of tokens : [ TXT][TAG][TAG][TXT][TAG][TXT ] ... .As you can see , parsers and tokenizers have much in common .One parser can be a tokenizer for other parser , which reads its input tokens as symbols from its own alphabet ( tokens are simply symbols of some alphabet ) in the same way as sentences from one language can be alphabetic symbols of some other , higher - level language .", "label": "", "metadata": {}, "score": "79.530945"}
{"text": "In a nominalization ( e.g. \" The inhibition of B by A \" ) the relation is expressed by a relational noun , while the two arguments are expressed by prepositional - phrase attachments .The argument A will be referred to as the agent , B as the target , adopting the terminology used in [ 21 ] .", "label": "", "metadata": {}, "score": "79.87221"}
{"text": "For LR parsing , I found Ralf Hinze 's Frown to be nicer than Happy - better error support and a nicer format for grammar files but Frown is not actively maintained and is n't on Hackage .I think it is LR(k ) rather LR(1 ) which means it is more powerful w.r.t . lookahead .", "label": "", "metadata": {}, "score": "79.92092"}
{"text": "BNF is just a specific syntax for presenting CF grammars .EBNF is a syntactic sugar for BNF , using the facilities of regular notation to give terser version of BNF grammars .It can always be transformed into an equivalent pure BNF .", "label": "", "metadata": {}, "score": "79.960754"}
{"text": "An overview is given of the XTAG system in which this technique is being developed .In addition , we ... \" .In this paper , we present a new technique called LightweightDependency Analysis which in conjunctionwith Supertag disambiguation provides a method for Robust Partial Parsing , called Almost Parsing .", "label": "", "metadata": {}, "score": "80.18234"}
{"text": "A special token code ( UNMATCHED ) is provided for text not matching any other lexical rule of the scanner , permitting a program that uses Zerg to decide Bioinformatics 19(8 ) c ?Oxford University Press 2003 ; all rights reserved .", "label": "", "metadata": {}, "score": "80.21246"}
{"text": "A total of 14,242 links were annotated in these sentences .The transcript corpus is made of 16,989 sentences ( 438,390 tokens ) consisting of the result for the query \" Bacillus subtilis transcription \" on Pubmed .It was not annotated .", "label": "", "metadata": {}, "score": "81.676285"}
{"text": "Though they can do a lot , they sometimes require very unreadable coding to achieve it , not to mention the fact that various extensions and restrictions in implementation somewhat reduce their theoretical simplicity .Lexers do not usually do that , and are usually a simple , efficient , and appropriate technology to parse token .", "label": "", "metadata": {}, "score": "82.08406"}
{"text": "Zerg - Perl2 op- tional convenience package was one order of magnitude faster than BioPerl .Zerg - C was over five times faster than MuSeqBox .Zerg - MSB is a program that uses Zerg and does the same calculations as MuSeqBox with default options , being three times faster than MuSeqBox itself .", "label": "", "metadata": {}, "score": "82.10234"}
{"text": "The philosophy of the Propbank project can be likened to FrameNet without frames .Wh ... . \" ...This paper describes issues surrounding the planning and design of GermanFrameNet ( GFN ) , a counterpart to the English - based FrameNet project .", "label": "", "metadata": {}, "score": "82.66405"}
{"text": "Semantics is derived by compositional techniques ( homomorphism for the mathematically oriented ) from the way syntax rules are composed to build the parse tree .Hence the tree structure is essential .The fact that tokens are identified with a regular set based lexer does not change the situation , because CF composed with regular still gives CF ( I am speaking very loosely about regular transducers , that transform a stream of characters into a stream of token ) .", "label": "", "metadata": {}, "score": "82.78963"}
{"text": "Interestingly , SmINSIG showed a 10-fold higher expression in adult females as opposed to males , in accordance with its possible role in regulating egg production .SmIRF has a DNA binding domain , a tryptophan - rich N - terminal region and several predicted phosphorylation sites , usually important for IRF activity .", "label": "", "metadata": {}, "score": "83.64212"}
{"text": "Given their known functions in Deuterostomia , it is possible that some of them have been co - opted to perform functions related ( directly or indirectly ) to host adaptation or interaction with host signaling processes .[ Show abstract ] [ Hide abstract ] ABSTRACT : High - throughput sequencing technologies have opened up a new avenue for studying extinct organisms .", "label": "", "metadata": {}, "score": "83.7442"}
{"text": "Instead he was born in London Ontario , where he grew up on a strawberry farm .He attended the University of Waterloo where he re - ceived a Bachelors of Mathematics with a joint degree in Pu ... \" .Peter Heeman was born October 22 , 1963 , and much to his dismay his parents had already moved away from Toronto .", "label": "", "metadata": {}, "score": "83.885315"}
{"text": "I was able to build a syntax highlighter using pygments really fast .But antlr is taking much longer ...I have n't seen a lot of cross pollination between the two tools .-Naveen May 16 ' 10 at 9:32 .", "label": "", "metadata": {}, "score": "84.24091"}
{"text": "One of the advantages of the Novartis annotator is that it is built on a huge terminology with more than 1 Million terms .The terms contain gene names , targets , modes of action , diseases , geographic locations , products and companies .", "label": "", "metadata": {}, "score": "85.912415"}
{"text": "In this work we found 427 genes conserved in the Deuterostomia group that have orthologs in S. mansoni and no members in any nematodes and insects so far sequenced .Among these genes we have identified Insulin Induced Gene ( INSIG ) , Interferon Regulatory Factor ( IRF ) and vasohibin orthologs , known to be involved in mammals in mevalonate metabolism , immune response and angiogenesis control , respectively .", "label": "", "metadata": {}, "score": "89.82459"}
{"text": "- Robin Green Nov 4 ' 10 at 8:17 .It is true that at present you need to do a little more on the tokenizing side of things , but for us that 's a small point relative to the fundamental strengths of the library .", "label": "", "metadata": {}, "score": "90.10326"}
{"text": "For example , the following restrictions can be used in a query in order to limit the type of the agent to be \" protein_molecule \" : . applyRel(xrel(['control ' , type : ' G#protein_molecule ' , _ ] ) ) .", "label": "", "metadata": {}, "score": "103.54761"}
{"text": "Differing provisions from the publisher 's actual policy or licence agreement may be applicable .[ Show abstract ] [ Hide abstract ] ABSTRACT : Schistosoma mansoni is a blood helminth parasite that causes schistosomiasis , a disease that affects 200 million people in the world .", "label": "", "metadata": {}, "score": "110.11924"}
