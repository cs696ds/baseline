{"text": "An alternative approach , using a k - truncated suffix tree deserves consideration , due to reduction in both memory requirements and running time [ 11 ] .L - Words Frequencies .with length L - W L -determined a priori , following the method of Sims et al .", "label": "", "metadata": {}, "score": "32.122475"}
{"text": "Different types of features for the SVM - based and CRF - based NER systems were investigated .For the SVM - based NER system , we used 1 ) words ; 2 ) POS tags ; 3 ) morphological features ; 4 ) orthographies of words ; 5 ) semantic tags determined by MedEx ; and 6 ) history features .", "label": "", "metadata": {}, "score": "34.287865"}
{"text": "Here , we present a new approach that determines a single optimal word length , L , and generates L - words frequency profiles using suffix tree theory .The algorithm was applied to a variety of mtDNA sequences that are particularly difficult to handle by automated alignment methods and the performance was compared to the available word counting alignment - free methodologies .", "label": "", "metadata": {}, "score": "36.853645"}
{"text": "Effect of each feature on system performance I. The first column shows the values when all features were used in the SVM learning ( word , POS , orthography ( orth . ) , prefix ( pre . ) , suffix ( suf . ) , dictionary matching ( dic . ) , and preceding class ( pc . ) )", "label": "", "metadata": {}, "score": "38.32157"}
{"text": "3 is a table showing results of an experiment utilizing the system of .FIG .1 .FIG .4 is a block diagram of a system for building a translation lexicon according to another embodiment .FIG .5 is a suffix tree .", "label": "", "metadata": {}, "score": "38.40587"}
{"text": "Our method starts by a computation of a generalized suffix tree of all sequences , which is completed in linear time .Using this tree , the frequency of all possible words with a preset length L - L - words -in each sequence is rapidly calculated .", "label": "", "metadata": {}, "score": "38.73952"}
{"text": "This vector can be translated into the other language , since we already know the translations of the seed words are already known .The lexicon builder 125 can search for the best matching context vector in the target language , and decide upon the corresponding word to construct a word mapping .", "label": "", "metadata": {}, "score": "38.819633"}
{"text": "No .11/315,043 ( hereinafter Cancedda , et al . ) discloses a computer implemented system and method for translating source text from a first language to target text in a second language different from the first language and to a method of training such a translation system .", "label": "", "metadata": {}, "score": "39.320515"}
{"text": "The time spent by the user between each step , although highly time consuming , was not included .Final Remarks .The algorithm described here has demonstrated to be an improvement of word counting alignment - free methods for sequence clustering , showing to be computationally very fast , particularly with large datasets , while still producing good quality results .", "label": "", "metadata": {}, "score": "39.5319"}
{"text": "Feature sets were extracted from common lexical features as described in [ 3 , 5 , 7 , 25 ] and semantic features from MedEx .Evaluation for this setting was done using 10-fold cross - validation .In the second setting , we compared our system with the system proposed by Patrick and Li [ 10 ] , the top - ranked system in the 2009 i2b2 challenge .", "label": "", "metadata": {}, "score": "39.939434"}
{"text": "The construction of a generalized suffix tree is based on Ukkonen 's algorithm , described with detail by Gusfield [ 10 ] .Function GST in the Supplementary Algorithm 1 automates the construction of this structure .Generalized suffix trees are potent structures , having the useful property that each prefix of paths leading from the root to any internal node points to all occurrences of this prefix in the data set [ 10 ] .", "label": "", "metadata": {}, "score": "40.708168"}
{"text": "Features for recognizing named entities were proposed in these investigations , e.g. word , part - of - speech ( POS ) , and orthography .Task 1 .A of BioCreAtIvE was a competition involving automated gene / protein name recognition .The system described here was developed for that competition .", "label": "", "metadata": {}, "score": "41.216347"}
{"text": "3 shows results of the English - German implementation .\" Entries \" indicate the number of correct lexicon entries that were added to a seed lexicon of 1337 identically spelled words , and \" Corpus \" indicates how well the resulting translation lexicon performs compared to the actual word - level translations in a parallel corpus .", "label": "", "metadata": {}, "score": "41.665253"}
{"text": "The method of . claim 13 , further comprising weighting the matching scores .A non - transitory computer readable medium having embodied thereon a program , the program being executable by a processor for performing a method for building a translation lexicon from non - parallel corpora , the method comprising : . generating a seed lexicon by the machine translation system , the seed lexicon including identically spelled words ; and .", "label": "", "metadata": {}, "score": "41.798073"}
{"text": "Note that the parallel corpus belongs to a different domain than the comparable corpus .Also the parallel corpus is extremely small .For low density languages , such a corpus can be built manually .When given as input the comparable corpora described above and the bilingual lexicon of 6,900 entries , the algorithm 1000 found 33,926 parallel sequences , with length between three and seven words .", "label": "", "metadata": {}, "score": "41.965492"}
{"text": "As already stated , two choices are possible to accomplish the word compacting operation : .( 1 ) Input the word compacter with the complete variable - length px / sx step code and successively compute the length information through a combining network ( as illustrated in FIG .", "label": "", "metadata": {}, "score": "42.318787"}
{"text": "In order to filter out such cases , the system 400 uses two simple heuristics : length and word content .The translation candidate must also be an open - class word .The algorithm 1000 for learning translations of unknown words is summarized in .", "label": "", "metadata": {}, "score": "42.427902"}
{"text": "From these , some high - quality lexical entries can be learned , but there will always be many words that are missing .These may be learned using the described methods .FIG .4 shows a system 400 for building a translation lexicon according to another embodiment .", "label": "", "metadata": {}, "score": "42.507996"}
{"text": "The words with the code attached are compacted into constant length packets at the transmission end and are successively extracted at the receive end .Variable length code and devices for high frequency transmission US 4937573 A .Abstract .A variable - length prefix / suffix step code is combined with words for high frequency transmission .", "label": "", "metadata": {}, "score": "42.52421"}
{"text": "In another embodiment , a system may align text segments in comparable , non - parallel corpora , matching strings in the corpora , and using the matched strings to build a parallel corpus .The system may build a Bilingual Suffix Tree ( BST ) and traverse edges of the BST to identify matched strings .", "label": "", "metadata": {}, "score": "43.0091"}
{"text": "In one approach , the context vector for each word in the lexicon may consist of co - occurrence counts in respect to a number of peripheral tokens ( basically , the most frequent words ) .These counts may be collected for each position in an n - word window around the word in focus .", "label": "", "metadata": {}, "score": "43.121395"}
{"text": "Note that here verbs precede propositions .Calzolari and Bindi uses mutual information for extracting lexical information from an Italian corpus .They used a measure , dispersion , to show how the second word is distributed within the window under consideration .A machine translation method includes receiving source text in a first language and retrieving text fragments in a target language from a library of bi - fragments to generate a target hypothesis .", "label": "", "metadata": {}, "score": "43.15269"}
{"text": "10 is psuedocode describing an algorithm for learning translations of unknown words .DETAILED DESCRIPTION .FIG .1 shows a system 100 for building a translation lexicon 105 according to an embodiment .The system may use non - parallel monolingual corpora 110 , 115 in two languages to automatically generate one - to - one mapping of words in the two languages .", "label": "", "metadata": {}, "score": "43.168594"}
{"text": "Yeh A : More accurate tests for the statistical significance of result differences . 18thInternational Conference on Computational Linguistics ( COLING 2000 ) 2000 , 947 - 953 .Ohta T , Tateisi Y , Kim JD : The GENIA Corpus : an Annotated Research Abstract Corpus in Molecular Biology Domain .", "label": "", "metadata": {}, "score": "43.60399"}
{"text": "No .6,304,841 , log - linear features are used to score word hypotheses depending on their lexical context .The following references relate to phrase - based statistical machine translation methods .U.S. Pat .No . 6,182,026 by Tillmann , et al . , entitled \" METHOD AND DEVICE FOR TRANSLATING A SOURCE TEXT INTO A TARGET USING MODELING AND DYNAMIC PROGRAMMING , \" discloses a method and device for translating a source text into a target using modeling and dynamic programming .", "label": "", "metadata": {}, "score": "43.64929"}
{"text": "A of BioCreAtIvE , a competition for automated gene / protein name recognition .Results .In the work presented here , our recognition system uses the feature set of the word , the part - of - speech ( POS ) , the orthography , the prefix , the suffix , and the preceding class .", "label": "", "metadata": {}, "score": "43.67787"}
{"text": "Annual Meeting of the ACL Assoc . for Computational Linguistics , Morristown , NJ , 597 - 604 .Fox , H. , \" Phrasal Cohesion and Statistical Machine Translation \" Proceedings of the Conference on Empirical Methods in Natural Language Processing , Philadelphia , Jul. 2002 , pp .", "label": "", "metadata": {}, "score": "43.777832"}
{"text": "The fact that n has outgoing edge e indicates there is a mismatch on the subsequent words of those two sequences .Thus , in order to extract all aligned substrings , the system 400 traverses the BST on edges labeled with word pairs , and extract all paths that end either at the leaves or at nodes that have outgoing edges labeled only with source language words .", "label": "", "metadata": {}, "score": "43.904945"}
{"text": "Shen et al .[ 7 ] suggested that a POS tagger should be trained using this domain .They trained their tagger using the GENIA corpus [ 17 ] .They reported that using the POS feature greatly increased the f - score .", "label": "", "metadata": {}, "score": "44.25518"}
{"text": "Training data ( 7500 sentences ) and development test data ( 2500 sentences ) were prepared for system development in Task 1 .A of the BioCreAtIvE competition .In both data sets , the gene / protein names were tagged with NEWGENE .", "label": "", "metadata": {}, "score": "44.493797"}
{"text": "In addition to the two features described above , the log linear model may include analogous features to those described in Cancedda , et al , along with their associated heuristics .These may include one or more of : .A \" compositional bi - fragment \" feature function h comp illustrated at 36 .", "label": "", "metadata": {}, "score": "44.578785"}
{"text": "Word features : words only .POS features : Part - of - Speech tags of words .To obtain POS information , we used a generic POS tagger in the NLTK package [ 24 ] .Morphologic features : suffix / prefix of up to 3 characters within a word .", "label": "", "metadata": {}, "score": "44.612198"}
{"text": "The difference between using and not using semantic tags was significant according to the approximate randomization test described above .Similar results ( not shown ) were observed for the CRF - based system .Table 4 .Performance of the SVM - based system for different feature combinations in 10-fold cross - validation .", "label": "", "metadata": {}, "score": "44.899704"}
{"text": "We can improve these results by using heuristic : pass through the candidate phrases through a part - of - speech filter which only allows those patterns that are likely to be phrases .Juteson and Katz have introduced a part - of - speech filter that uses the patterns adjective - noun , noun - noun , etc to decide which pattern should be allowed to let through .", "label": "", "metadata": {}, "score": "44.952644"}
{"text": "The bi - fragments may be learned from a large aligned bilingual corpus comprising source text and its translation into target text .The statistics of bi - phrases can be established through observation of a corpus .It is to be appreciated that direct observation of a bi - phrase in a given sentence pair is not necessary , but rather the presence of such a bi - phrase can be indirectly induced through phrase - level alignment mechanisms .", "label": "", "metadata": {}, "score": "45.087692"}
{"text": "Accordingly , it is appropriate to ignore it .The model presupposes that , for each bi - phrase , the empirical statistics of its observed gap sizes in the training corpus are available .In the exemplary embodiment , a static library of bi - chunks constructed according to the method of Cancedda , et al . is used as the information source for obtaining these statistics .", "label": "", "metadata": {}, "score": "45.274406"}
{"text": "J .d .K . )i .J . log .Pr .t .j .t .j .N .j .\" Word - count \" and \" bi - fragment \" count feature functions h wc and h bc , illustrated at 40 and 42 , respectively .", "label": "", "metadata": {}, "score": "45.294525"}
{"text": "2 shows a flowchart describing a method 200 for building a translation lexicon from non - parallel corpora .A word comparator 120 may be used to collect pairs of identical words ( block 205 ) .In the English German implementation described above , 977 identical words were found .", "label": "", "metadata": {}, "score": "45.363655"}
{"text": "To use it , first we need to calculate a few frequencies for each word : its overall frequency and its frequency within each class .This is done with a FreqDist for overall frequency of words , and a ConditionalFreqDist where the conditions are the class labels .", "label": "", "metadata": {}, "score": "45.50737"}
{"text": "9 ( ii ) shows the reverse BST 910 , and in bold , the path we are interested in .When d and y are surrounded by aligned sequences , we hypothesize that they are translations of each other .For a pair of words from the two corpora , we use the terms \" right alignment \" and \" left alignment \" to refer to the aligned sequences that precede and respectively succeed the two words in each corpus .", "label": "", "metadata": {}, "score": "45.513527"}
{"text": "In this way , rule - based morphological , syntactic and/or semantic information is combined with knowledge extracted from bilingual texts which is then re - used in the translation process .Such methods are often collectively referred to as \" phrase - based methods \" .", "label": "", "metadata": {}, "score": "45.559914"}
{"text": "Additional variables can be introduced in such a log - linear model , so as to account for selected characteristics , and the feature functions can be extended accordingly .For example , if the translation t 1 J of s 1 I is produced using bi - fragments as described here , the model can be modified to take into account the actual set of decisions that lead to t 1 J .", "label": "", "metadata": {}, "score": "45.713425"}
{"text": "International Conference on Computational Linguistics ( COLING'2000 ) 2000 , 201 - 207 .Shen D , Zhang J , Zhou G , Su J , Tan CL : Effective Adaptation of a Hidden Marcov Model - based Named Entity Recognizer for Biomedical Domain .", "label": "", "metadata": {}, "score": "45.83621"}
{"text": "In this paper , for the sake of convenience , we refer to the term \" named entities \" or \" entities \" as fields which have the same meaning as [ 10 , 13 ] .The first task was an NER task , for which both the Sydney and the Wisconsin teams used CRF to detect fields , while Halgrim et al .", "label": "", "metadata": {}, "score": "45.847347"}
{"text": "A recent development in statistical machine translation has entailed the step from word - based models to phrase - based models .While in traditional word - based statistical models , the atomic unit that translation operates on is the word , phrase - based methods acknowledge the significant role played in language by multi - word expressions , thus incorporating , in a statistical framework , the insight behind Example - Based Machine Translation .", "label": "", "metadata": {}, "score": "45.8871"}
{"text": "We present an improvement to word counting alignment - free approaches for sequence comparison , by determining a single optimal word length and combining suffix tree structures to the word counting tasks .Our approach is , thus , a fast and simple application that proved to be efficient and powerful when applied to mitochondrial genomes .", "label": "", "metadata": {}, "score": "46.07248"}
{"text": "The source language word that corresponds to the \" well - aligned \" unknown is considered to be a possible translation .A suffix tree stores in linear space all suffixes of a given string .Such succinct encoding exposes the internal structure of the string , providing efficient ( usually linear - time ) solutions for many complex string problems , such as exact and approximate string matching , finding the longest common substring of multiple strings , and string compression .", "label": "", "metadata": {}, "score": "46.101376"}
{"text": "Patterns describing compounds come as a . separate input resource that can refer to high - level properties of . constituent parts ( e.g. the number of syllables , affix flags , and .containment of hyphens ) .The patterns are matched against potential . segmentations of compounds to assess wellformedness .", "label": "", "metadata": {}, "score": "46.160767"}
{"text": "The non - contiguous bi - fragments are expressed in terms of elastic bi - phrases .Each elastic bi - phrase is considered to be a pair of gapped phrases , one in the source language and one in the target language .", "label": "", "metadata": {}, "score": "46.45016"}
{"text": "For example , it may be distinguished by a special notation for convenience .In order to determine \u03bc for a gap size on the source side , consider s , and observe all sentence pairs in the training corpus which use a bi - phrase of the form ( s , t ) .", "label": "", "metadata": {}, "score": "46.64186"}
{"text": "In a GST of a set of strings , each path from the root to a leaf represents a suffix in one or more strings from the set .FIG .6 shows the GST 600 for a corpus of two sentences .The numbers at the leaves 605 of the tree show which sentences contain the suffix that ends there .", "label": "", "metadata": {}, "score": "46.884125"}
{"text": "View Article PubMed .Kudo T , Matsumoto Y : Chunking with Support Vector Machines .Proceedings of Second Meeting of North American Chapter of the Association for Computational Linguistics(NAACL ) 2001 , 192 - 199 .Brill E : Some advances in transformation - based part of speech tagging .", "label": "", "metadata": {}, "score": "47.032627"}
{"text": "At step S 100 , source text to be decoded is input to the system 10 .At step S 110 , the processing component 16 identifies a string of the source text to be translated , such as a sentence .This step may include a tokenizing procedure , in which the processing component identifies words in the text , as well as punctuation marks .", "label": "", "metadata": {}, "score": "47.169468"}
{"text": "Each of the retrieved text fragments is linked in a bi - phrase in the library to a text fragment from the source text .At least one target hypothesis is generated .Each of the target hypotheses comprises text fragments selected from the second language .", "label": "", "metadata": {}, "score": "47.17335"}
{"text": "\" full(B ) \" means using all features and the POS tagger with trained on GENIA corpus 3.02p The parenthesized values are p - values .We compare two cases : \" word+POS(A)+pc .\" vs. \" word+POS(B)+pc . \" and \" full(A ) \" vs. \" full(B ) \" .", "label": "", "metadata": {}, "score": "47.19367"}
{"text": "[ 10 ] also used an SVM - based system to evaluate the effects of feature sets and found a range of -1 + 1 was better than -3 + 3 , which is the opposite of our findings .The optimal window size is thus corpus dependent .", "label": "", "metadata": {}, "score": "47.219543"}
{"text": "The lexicon builder 125 extracts potential translation word pairs based on one or more clues .These clues may include similar spelling , similar context , preserving word similarity , and word frequency .When words are adopted into another language , their spelling might change slightly in a manner that can not be simply generalized in a rule , e.g. , \" website \" and \" Webseite .", "label": "", "metadata": {}, "score": "47.35313"}
{"text": "After the training , the accuracy of the POS tagging increased from 79.95 to 92.81 % on the GENIA corpus .Table 11 shows the effect of training on different corpora on the POS tagger .The \" word+POS(A)+pc .\" column shows the case using the original POS tagger .", "label": "", "metadata": {}, "score": "47.3702"}
{"text": "Accordingly , the word comparator 120 may restrict the word length to be able to increase the accuracy of the collected word pairs .For instance , by relying only on words at least of length six , 622 word pairs were collected with 96 % accuracy .", "label": "", "metadata": {}, "score": "47.459015"}
{"text": "In one embodiment , a measure of reordering is used which relies on the \" source coverage vector \" V of the sequence of decisions d 1 . . .d K .The coverage vector can be computed using the procedure of Cancedda , et al .", "label": "", "metadata": {}, "score": "47.51709"}
{"text": "Running Time .Our algorithm takes a linear execution time to determine the words frequencies and a quadratic time to compute the pairwise distances , an improvement to previous word counting alignment - free methodologies .Our approach was compared to the method developed by Costa et al .", "label": "", "metadata": {}, "score": "47.55812"}
{"text": "The exemplary embodiment may differ in this respect from the method disclosed in Cancedda , et al . .A gap size scoring feature ( h ELAST ) , illustrated at 34 , corresponding to the probability of the gap sizes assigned to ( s , t ) in the translation , relative to the distribution dist associated with ( s , t ) in the training phase .", "label": "", "metadata": {}, "score": "47.7709"}
{"text": "As described above , the system we developed for automated gene / protein name recognition uses the SVM algorithm and an SVM - based chunker , YamCha .YamCha performs pre - processing and set - up for the SVM .We evaluated our system in the BioCreAtIvE competition using various parameters for SVM learning , i.e. degree of the polynomial kernel , range of the window , cost of constraint violation , and method for solving multi - class problems .", "label": "", "metadata": {}, "score": "47.8071"}
{"text": "Verbs , adjectives , adverbs and other part of speech may be handled in a similar way .They might also provide useful context information that is beneficial to building a noun lexicon .These methods may be also useful given a different starting point .", "label": "", "metadata": {}, "score": "47.95988"}
{"text": "11/315,043 , filed Dec. 22 , 2005 , entitled MACHINE TRANSLATION USING NON - CONTIGUOUS FRAGMENTS OF TEXT , by Nicola Cancedda , et al . , the disclosure of which is incorporated herein by reference in its entirety .BACKGROUND .The present exemplary embodiment is directed to the field of machine translation .", "label": "", "metadata": {}, "score": "48.00431"}
{"text": "Their features are specific , which allowed them to achieve good performance in the i2b2 challenge , but they are not common features used for NER in the biomedical domain and may not be generalizable to other tasks .Combining classifiers ' output in ensemble classifiers .", "label": "", "metadata": {}, "score": "48.02504"}
{"text": "The distribution dist is used to model the conditional probability of getting specific sizes for each of the k source and l target gaps conditional on the actual use of the given gapped bi - phrase in a ( sentence - level ) translation .", "label": "", "metadata": {}, "score": "48.35794"}
{"text": "We used a Wilcoxon signed - ranks test with exact tests .A data sample for a test is the result of interest from one of the 10 trials in a 10-fold cross validation .Each sample was the difference between a trial 's result for the case being compared and the corresponding result for the \" base \" case ( a matched pair ) .", "label": "", "metadata": {}, "score": "48.36543"}
{"text": "An apparatus comprising : . a lexicon builder operative to be executed to expand the seed lexicon by identifying possible translations of words in the first and second corpora using one or more clues .The apparatus of .claim 24 , wherein the lexicon builder is configured to use the identically spelled words in the seed lexicon as accurate translations .", "label": "", "metadata": {}, "score": "48.397438"}
{"text": "In particular it can be used to model the empirical distribution of gaps for a given bi - phrase , without any smoothing / generalization , by just recording a histogram of the observed gap sizes in the training corpus .It also allows the modeling of conditional dependencies between gaps .", "label": "", "metadata": {}, "score": "48.518585"}
{"text": "When given a new segment of text to translate , these systems search the database to extract all relevant bi - fragments , i.e. , items in the database whose source - language fragment matches some portion of the new input .A subset of these matching bi - fragments is then searched for , such that each word of the input text is covered by exactly one bi - fragment in the subset , and that the combination of the target - language fragments produces a coherent translation .", "label": "", "metadata": {}, "score": "48.595715"}
{"text": "( 1 ) e 1 and e 2 are already placed in the target sequence , in which case the value of the gap is known , and its contribution to h ELAST can be directly evaluated .This computation is performed when e 2 has just been moved from a suffix in the buffer to the sequence , using the sequence index of e 1 , which it is assumed has been maintained on the suffix .", "label": "", "metadata": {}, "score": "48.611458"}
{"text": "Additionally , we consider the features of matching against dictionaries to be external resource features .We investigated and evaluated the effect of these features as well as the effect of tuning the parameters of the SVM algorithm .We found that the dictionary matching features contributed slightly to the improvement in the performance of the f - score .", "label": "", "metadata": {}, "score": "48.6965"}
{"text": "Recently , supervised machine learning methods have proven to be effective in clinical NLP as well .However , combining different classifiers to further improve the performance of clinical entity recognition systems has not been investigated extensively .Combining classifiers into an ensemble classifier presents both challenges and opportunities to improve performance in such NLP tasks .", "label": "", "metadata": {}, "score": "48.71736"}
{"text": "For a gap size on the target side , an analogous procedure may be used .One further simplification may be made , namely to assume that all the components in a gapped phrase are of length one , that is , correspond exactly to one single word .", "label": "", "metadata": {}, "score": "48.774582"}
{"text": "Or the text may be input from a database or word document .The text may include one or more sentences , such as a paragraph or an entire document comprising multiple paragraphs .The translation system 10 includes a processing component 16 and a memory component 18 .", "label": "", "metadata": {}, "score": "48.830166"}
{"text": "In one aspect , it has the ability to make use of elastic fragments of source and/or target language text .In another aspect , it includes components within a statistical translation model to model variable gap sizes .In yet another aspect , it includes procedures for efficiently computing the potential of partial translations with discontinuities with regard to the statistical model .", "label": "", "metadata": {}, "score": "48.835117"}
{"text": "The system includes a processor which executes instructions for receiving the source text in the first language , accessing the library to retrieve text fragments from the second language , scoring hypotheses according to a plurality of features including the gap scoring feature .", "label": "", "metadata": {}, "score": "48.866302"}
{"text": "We investigated ensemble classifiers that used different voting strategies to combine outputs from three individual classifiers : a rule - based system , a support vector machine ( SVM ) based system , and a conditional random field ( CRF ) based system .", "label": "", "metadata": {}, "score": "48.884655"}
{"text": "To avoid this , the system 400 appends an end - of - string marker \" $ \" that appears nowhere else in the string .For clarity , the drawings only show the $ marker when necessary .Each monolingual corpus given as input to the system 400 may be divided into a set of sentences .", "label": "", "metadata": {}, "score": "48.896553"}
{"text": "This feature may be computed as in equation ( 7 ) : .Pr . t . s .s .t .t .t . s .s .Pr . t .s . )A \" target language \" feature function h tl illustrated at 38 .", "label": "", "metadata": {}, "score": "48.976776"}
{"text": "For each bi - fragment identified from the corpus , a probability distribution ( or a mean of the probability distribution ) representing the statistical probabilities of number of gaps in the target fragment for each observed number of gaps in the source may be stored and used to develop distributions .", "label": "", "metadata": {}, "score": "49.00741"}
{"text": "10 .An advantage of the algorithm over previous approaches is that we do not provide as input to the algorithm a list of unknown words .Instead , the system automatically learns from the corpus both the unknown words and their translation , upon discovery of appropriate context alignments .", "label": "", "metadata": {}, "score": "49.030525"}
{"text": "There are many approaches to find collocations in a text corpus .The important ones are : .Frequency 2 .Mean and Variance 3 .Hypothesis Testing 4 .Mutual Information .Frequency .Frequency is the simplest method for finding collocations in a text corpus .", "label": "", "metadata": {}, "score": "49.060646"}
{"text": "Using this convention , contiguous and discontinuous phrases can be treated under a single type , with has the advantage of avoiding the need to learn separately different combinations of contiguous / non - contiguous components with the associated sparseness issues .The model may include other variants .", "label": "", "metadata": {}, "score": "49.268738"}
{"text": "Kazama J , Makino T , Ohta Y , Tsujii J : Tuning Support Vector Machines for Biomedical Named Entity Recognition .Proceedings of the Natural Language Processing in the Biomedical Domain ( ACL2002 ) 2002 , 1 - 8 .Lee KJ , Hwang YS , Rim HC : Two - Phase Biomedical NE Recognition based on SVMs .", "label": "", "metadata": {}, "score": "49.397175"}
{"text": "Each of the target hypotheses includes text fragments selected from the second language .The target hypothesis is evaluated with a translation scoring function which scores the target hypothesis according to a plurality of feature functions .At least one of the feature functions includes a gap size scoring feature which favors hypotheses with statistically more probable gap sizes over hypotheses with statically less probable gap sizes .", "label": "", "metadata": {}, "score": "49.400005"}
{"text": "The two semantic schemas are different but compatible .When the Vanderbilt team applied MedEx to the i2b2 challenge , they customized and extended MedEx to label medication - related fields as required by i2b2 [ 11 ] .There are three main customizations : 1 ) developing dedicated rules to combine entities recognized by MedEx into i2b2 fields , 2 ) adding a new section tagger and a spell checker , and 3 ) developing a post - processing program to convert MedEx outputs into the i2b2 challenge outputs .", "label": "", "metadata": {}, "score": "49.410423"}
{"text": "We thus investigated and evaluated the performance of our system when using an additional feature of making partial dictionary pattern matches .The gene / protein name dictionaries were made by collecting gene and protein names from the SWISS - PROT [ 13 ] and the TrEMBL [ 13 ] databases .", "label": "", "metadata": {}, "score": "49.412186"}
{"text": "Collier et al .[ 6 ] and Shen et al .[ 7 ] investigated the automated recognition of biomedical named entities based on the hidden Markov model .Kazama et al .[ 8 ] , Lee et al .[ 9 ] , and Takeuchi et al .", "label": "", "metadata": {}, "score": "49.458862"}
{"text": "Using the test data in the challenge , Doan and Xu [ 14 ] investigated using output from the MedEx rule - based system as features for SVM algorithms and showed that those features could substantially improve an SVM - based NER system .", "label": "", "metadata": {}, "score": "49.469223"}
{"text": "applying transformation rules to words in the first corpora to form transformed words ; and . comparing said transformed words to words in the second corpora .The non - transitory computer readable medium of . claim 15 , wherein said one or more clues includes similar spelling .", "label": "", "metadata": {}, "score": "49.484985"}
{"text": "Local CRF - based voting .In this model , duration and reason mentions are identified by the CRF , while the remaining mentions come from the SVM .Essentially , for a given word , if the CRF - based system predicts duration or reason then use its label for the word ; otherwise , use the SVM - based prediction .", "label": "", "metadata": {}, "score": "49.485416"}
{"text": "Based on these alignments , the system 400 may generate a parallel corpus 420 and identify translations 425 of words from the source language which are not in the lexicon .For example , consider the following two sentences where the only unknown French word is \" raison \" : .", "label": "", "metadata": {}, "score": "49.542324"}
{"text": "The translated vector can be compared to other vectors in the second language .The lexicon builder 125 may perform a greedy search for the best matching similarity vectors and add the corresponding words to the lexicon .Another clue is based on the assumption that in comparable corpora , the same concepts should occur with similar frequencies .", "label": "", "metadata": {}, "score": "49.60965"}
{"text": "[ 3 ] demonstrated the automated extraction of PPIs using a context - free grammar .In each of these studies , protein name recognition was the first step .Next , protein name dictionaries were constructed .Finally , protein name recognition was performed based on pattern matching using the dictionaries .", "label": "", "metadata": {}, "score": "49.749565"}
{"text": "The system 400 may use a suffix tree data structure in order to identify the alignments .The suffix tree of a string uniquely encodes all the suffixes of that string ( and thus , implicitly , all its substrings too ) .The system 400 may first build such a tree of the target language corpus , and then add to each substrings all the substrings from the source language corpus that align to it .", "label": "", "metadata": {}, "score": "49.931923"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a block diagram of a system for building a translation lexicon according to an embodiment .FIG .2 is a flowchart describing a method for building a translation lexicon from non - parallel corpora .", "label": "", "metadata": {}, "score": "50.02543"}
{"text": "A practical solution is to utilize a convenient variable length code intrinsically containing the desired information about the word length ( WL ) , thus permitting the receive end to logically and physically separate the extracting an decoding operations ( FIG .5b ) and to connect them in cascade .", "label": "", "metadata": {}, "score": "50.038452"}
{"text": "For each occurrence of a target word , the counts may be collected over how often certain context words occur in the two positions directly ahead of the target word and the two following positions .The counts may be collected separately for each position and then entered into a context vector with a dimension for each context word in each position .", "label": "", "metadata": {}, "score": "50.045174"}
{"text": "It is preferred , therefore , that the present invention be limited not by the foregoing text , but only by the appended claims . \"Using Google 's enormous bigram dataset , I produced a series of visualizations that explore word associations .", "label": "", "metadata": {}, "score": "50.11338"}
{"text": "A method for building a translation lexicon from non - parallel corpora by a machine translation system , the method comprising : . generating a seed lexicon by the machine translation system , the seed lexicon including identically spelled words ; and .expanding the seed lexicon by the machine translation system by identifying possible translations of words in the first and second corpora using one or more clues .", "label": "", "metadata": {}, "score": "50.147003"}
{"text": "3 is a block diagram showing the serial compacting of words ; .FIG .4 is a block diagram showing the parallel compacting of words ; .FIGS .5a and 5b show , respectively , the receive end with paralleling in the case of a general variable length code and the receive end with paralleling in the case of [ px . . .", "label": "", "metadata": {}, "score": "50.267727"}
{"text": "Genome Biol 2008 , 9 ( Suppl 2 ) : S2 .PubMed View Article .Takeuchi K , Collier N : Bio - medical entity extraction using Support Vector Machines .Proceedings of the ACL 2003 workshop on Natural language processing in biomedicine 2003 , 57 - 64 .", "label": "", "metadata": {}, "score": "50.28504"}
{"text": "It suggests that simple strategies that can be easily implemented , such as majority voting , could have the potential to significantly improve clinical entity recognition .Further combinations of classifiers will be investigated in the future .Abbreviations .SVM : .Support vector machine .", "label": "", "metadata": {}, "score": "50.297405"}
{"text": "Assoc . for Computational Linguistics , Morristown , NJ , 160 - 167 .Taskar , B. , et al . , \" A Discriminative Matching Approach to Word Alignment , \" In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing ( Vancouver , BC , Canada , Oct. 6 - 8 , 2005 ) .", "label": "", "metadata": {}, "score": "50.36848"}
{"text": "Algorithm .We present here a new algorithm representing an improvement of word counting alignment free methodologies .Suffix Tree Approach .The first step of the method is the construction of a generalized suffix tree , T , of n sequences , . , where every suffix in the data set is represented only once .", "label": "", "metadata": {}, "score": "50.452312"}
{"text": "Working on a string of contiguous words in the source language , such as a sentence of the input text , the translation module 22 accesses the library 20 to retrieve fragments in the target language corresponding to input fragments in the source language text string .", "label": "", "metadata": {}, "score": "50.509953"}
{"text": "In other respects , the decoding procedure may be analogous to the procedure outlined in Cancedda , et al .Specifically , the current stack is traversed from top to bottom , then the decoder moves to the next stack .Extending Hypotheses in the Beam Search Procedure .", "label": "", "metadata": {}, "score": "50.556507"}
{"text": "The features and parameters we used in the BioCreAtIvE competition are shown in Tables 1 and 4 .We tested three methods for the dictionary matching ( 1 st , 2 nd , and 3 rd runs ) .Table 4 .Parameters of YamCha .", "label": "", "metadata": {}, "score": "50.565742"}
{"text": "pa : Parts of the compound words .Output fields of morphological analysis for stemming .dp : Planned : derivational prefix .ip : Planned : inflectional prefix .tp : Planned : terminal prefix .Twofold suffix stripping .Ispell\u00e2\u20ac \u2122 s original algorithm strips only one suffix .", "label": "", "metadata": {}, "score": "50.586742"}
{"text": "Also , the heuristics described herein may be combined with the alignment method described herein .Accordingly , other embodiments are within the scope of the following claims .Document conversion system including data monitoring means that adds tag information to hyperlink information and translates a document when such tag information is included in a document retrieval request .", "label": "", "metadata": {}, "score": "50.721016"}
{"text": "The other parameters did not have much effect on the results .We also carried out a Wilcoxon signed - ranks tests ( two - sided ) between the \" base \" and other cases .Statistical analysis was performed using commercial software ( SPSS for Windows , version 11.0J , SPSS Inc. ) .", "label": "", "metadata": {}, "score": "50.784225"}
{"text": "FIG .2 , a block diagram of an automated natural language translation system 10 for translating text comprising elastic bi - fragments is illustrated .Text is input to the system by an input device 12 .Input text may be directly input into the natural language translation system 10 ( for example , as with a person typing sentences into a computer using a keyboard ) .", "label": "", "metadata": {}, "score": "50.873226"}
{"text": "As described above , we used uni- , bi- , and tri - gram ( in tokens ) matching for gene / protein name descriptions in the dictionary .The effect of dictionary matching feature was significant by itself .But when the features were combined , the effect was not so significant .", "label": "", "metadata": {}, "score": "50.90796"}
{"text": "Our experimental results using the 2009 i2b2 challenge datasets showed that ensemble classifiers that combine individual classifiers into a voting system could achieve better performance than a single classifier in recognizing medication information from clinical text .It suggests that simple strategies that can be easily implemented such as majority voting could have the potential to significantly improve clinical entity recognition .", "label": "", "metadata": {}, "score": "50.989967"}
{"text": "A machine translation system may use non - parallel monolingual corpora to generate a translation lexicon .The system may identify identically spelled words in the two corpora , and use them as a seed lexicon .Building a translation lexicon from comparable , non - parallel corpora US 8234106 B2 .", "label": "", "metadata": {}, "score": "51.060764"}
{"text": "Typical NER systems use dictionary lookup methods to determine semantic categories of a word ( e.g. , gene names in a dictionary ) .In this study , we used MedEx , the best rule - based medication extraction system in the 2009 i2b2 challenge , to assign medication specific categories into words .", "label": "", "metadata": {}, "score": "51.087025"}
{"text": "Alternatively , many alignment - free methods have also been proposed [ 5 , 7 - 9 ] which , being based on word frequencies or on match lengths , are algorithmically simple and computationally faster than alignment methods .The basis of word frequency tasks is the determination of the optimal word length , L , which should be computed a priori .", "label": "", "metadata": {}, "score": "51.134216"}
{"text": "^ .arg .max .t .J . m .M . m .h .m .s .I . t .J . )Exemplary Features Suitable for Treatment of Elastic Bi - Phrases .For example , the present model can include the following feature functions as illustrated in .", "label": "", "metadata": {}, "score": "51.138947"}
{"text": "The correctness of word mappings acquired in this fashion may depend highly on word length .While identical three - letter words were only translations of each other 60 % of the time , this was true for 98 % of ten - letter words .", "label": "", "metadata": {}, "score": "51.1874"}
{"text": "\u00c9.Gaussier , Flow Network Models for Word Alignment and Terminology Extraction from Bilingual Corpora , In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th Intl Conference on Computational Linguistics , pp .444 - 450 , San Francisco , CA , 1998 .", "label": "", "metadata": {}, "score": "51.322334"}
{"text": "The resulting chunking representation of the above sample phrase is \" translocation / O of / O the / O NF - kappaB / B transcription / I factor / I,/O \" .POS : Part of speech of the current token .POS and NEWGENE were tagged in the training and test data for development .", "label": "", "metadata": {}, "score": "51.33471"}
{"text": "Here we report the performance of our system in the BioCreAtIvE competition , analyze its features , and discuss the effect of the parameters on SVM learning .Results .System description .The concept of our system is shown in Figure 1 .", "label": "", "metadata": {}, "score": "51.423634"}
{"text": "As in the word compacter , the x side develops as a function , besides the RDIN / RDOUT signals , of the EOW register contents and of the ROT combining network ( FIG .9e ) .The output information format coincides with the information format at the input of the word compacter WC .", "label": "", "metadata": {}, "score": "51.43463"}
{"text": "Such models use probability functions to identify a target language string with maximum probability , i.e. , a string which optimizes one or more functions which model statistically probable translations .Using elastic bi - fragments in phrase - based translation methods raises a number of issues for the statistical translation model , which the present method addresses by incorporation of \" feature functions \" into a log - linear statistical translation model .", "label": "", "metadata": {}, "score": "51.485924"}
{"text": "We then put these words into a set , and use a set membership test in our feature selection function to select only those words that appear in the set .Now each file is classified based on the presence of these high information words .", "label": "", "metadata": {}, "score": "51.64917"}
{"text": "Smith et al .[ 4 ] showed that most of the top NER systems in the BioCreAtIvE II challenge for gene mention tagging combined results from multiple classifiers using simple heuristic rules .In a similar way , Torii et al .[ 6 ] used a majority voting scheme to combine recognition results from four systems into a single system called BioTagger - GM and reported a higher F - score than the first - place system in the BioCreAtIvE II challenge .", "label": "", "metadata": {}, "score": "51.704994"}
{"text": "Significance tests .In order to compare performance between different systems , we used an approximate randomization approach for testing significance as described in [ 9 ] .We then combined A and B to a superset C .Then we randomly drew j entries from C without resampling and created the pseudo set of entries A i ; the remainder of C forms the pseudo set of entries B i .", "label": "", "metadata": {}, "score": "51.84825"}
{"text": "FIG .5 illustrates , by way of example , how the stacks utilized in the beam search procedure are developed .The string 60 to be translated is matched to the bi - phrase library 20 .It will be appreciated that only some of the possible library matches are illustrated .", "label": "", "metadata": {}, "score": "51.914192"}
{"text": "one - level architecture is that there is no way to render lexical .licensing of particular prefixes and suffixes interdependent , and .+ v\u00c3 \u0192 \u00c2 \u00a9 n \u00e2\u20ac\u02dcold\u00e2\u20ac \u2122 .Until the introduction of clusters , a special treatment . of the superlative had to be hardwired in the earlier HunSpell code .", "label": "", "metadata": {}, "score": "51.937656"}
{"text": "p is ' NEWGENE ' if t is part of a gene / protein name , otherwise , p gives the part - of - speech for t : .Table 6 .Overlap of gene / protein names between any two data items .", "label": "", "metadata": {}, "score": "51.98532"}
{"text": "8a , 8b , and 8c are , respectively , an example of circuitry for implementing the word compacter , the combining network \" ROT \" and accompanying I / O table , and the combining networks \" DEC \" and \" FDEC \" I / O table ; and .", "label": "", "metadata": {}, "score": "51.988464"}
{"text": "We evaluated the effect of training a POS tagger with a corpus that is specific to the biomedical domain , as opposed to training the tagger on newswire .There was surprisingly a drop in the balanced f - score when switching from the original POS tagger to the GENIA trained POS tagger .", "label": "", "metadata": {}, "score": "51.99993"}
{"text": "First , the lexicon builder 125 searches for the highest score for any word pair .This is added to the lexicon ( block 230 ) , and word pairs that include either the German and English word are dropped from further search .", "label": "", "metadata": {}, "score": "52.07464"}
{"text": "PubMed View Article .Doan S , Xu H : Recognizing medication related entities in hospital discharge summaries using support vector machine .Proceedings of the 23thConference on Computational Linguistics 2010 , 259 - 266 .Uzuner \u00d6 , Solti I , Xia F , Cadag E : Community annotation experiment for ground truth generation for the i2b2 medication challenge .", "label": "", "metadata": {}, "score": "52.087303"}
{"text": "This , however , is still insufficient to handle the . intricate patterns of compounding , not to mention idiosyncratic ( and .language specific ) norms of hyphenation .The Hunspell algorithm currently allows any affixed form of words , . which are lexically marked as potential members of compounds .", "label": "", "metadata": {}, "score": "52.138245"}
{"text": "In one embodiment , the decoder performs as follows .The current partial translation is represented as : ( 1 ) a partial coverage of the words of the source sentence , and ( 2 ) a partial target sentence representation .As an example , .", "label": "", "metadata": {}, "score": "52.145706"}
{"text": "5 illustrates the development of hypothesis stacks for a partial translation of the sentence illustrated in .FIG .4 . DETAILED DESCRIPTION .Aspects of the exemplary embodiment relate to a method for translating source text from a first language to target text in a second language .", "label": "", "metadata": {}, "score": "52.183056"}
{"text": "In order to confirm that the algorithm was also able to produce a correct phylogeny with closely related sequences we tested it with mtDNA sequences from the same species , in which the sequence length is more homogeneous .The observed clusterings are in general agreement with those published in the literature , grouping mtDNA genomes in the same clades previously published methodologies ( Supplementary Material ) .", "label": "", "metadata": {}, "score": "52.208115"}
{"text": "The method of .claim 1 , wherein bi - fragments comprising contiguous text fragments are modeled as elastic bi - phrases .The method of .claim 1 , wherein the generation of a target hypothesis includes generating a partial hypothesis comprising a sequence of words without gaps from the text fragments selected from the second language and storing any unconsumed words of the text fragments used in generating the sequence in a buffer .", "label": "", "metadata": {}, "score": "52.305954"}
{"text": "A \" reordering \" feature function h reord ( s 1 I , t 1 J , d 1 K ) , illustrated at 46 , measures the difference in order between source and target fragments .Such feature functions are a standard component in most existing phrase - based machine translation systems .", "label": "", "metadata": {}, "score": "52.374825"}
{"text": "As will be appreciated , at step S 112 A , the library 20 may identify an elastic bi - fragment which is retrieved by the processing component and which may ultimately used in translation of the text string .The library may also include contiguous bi - fragments ( fragments with a gap size of 0 ) , one or more of which may be utilized in combination with one or more elastic bi - fragments in translation of the source language text string .", "label": "", "metadata": {}, "score": "52.47637"}
{"text": "language , and the second is an \" affix \" file that defines the meaning . of special flags in the dictionary .dic ) contains a list of words , one per line .The . first line of the dictionaries ( except personal dictionaries ) contains .", "label": "", "metadata": {}, "score": "52.564396"}
{"text": "3 is a flow diagram of a method for machine translation of text which utilizes elastic bi - fragments according to one aspect of the exemplary embodiment ; .FIG .4 is an example of the combination of bi - fragments to produce a translation ; .", "label": "", "metadata": {}, "score": "52.655174"}
{"text": "View Article .Zhou G , Shen D , Zhang J , Su J , Tan S : Recognition of protein / gene names from text using an ensemble of classifiers .BMC Bioinformatics 2005 , 6 ( Suppl 1 ) : S7 .", "label": "", "metadata": {}, "score": "52.734737"}
{"text": "Given an initial bilingual lexicon 405 and two texts 410 , 415 in each of the languages , the system 400 may identify parts of the texts which can be aligned ( i.e. , are mutual translations of each other according to the lexicon ) .", "label": "", "metadata": {}, "score": "52.794865"}
{"text": "a processor which executes the instructions .A machine translation system for translating source text from a first language to target text in a second language , comprising : .The machine translation system of . claim 17 , wherein translation scoring function further includes at least one of : . a second feature function which evaluates bi - fragment discontinuities ; and .", "label": "", "metadata": {}, "score": "52.845337"}
{"text": "Where the mean has already been exceeded , the h ELAST feature favors consuming the next buffered word immediately .In this description , a conceptually simple model may be used which assumes that there are gaps between any two words .In an alternative embodiment , a minor adaptation of the decoder allows the second word to be consumed as soon as the first word has been consumed , which is more efficient .", "label": "", "metadata": {}, "score": "52.945335"}
{"text": "2004 , 172 - 175 .Tsuruoka Y , Tsujii J : Boosting Precision and Recall of Dictionary - Based Protein Name Recognition .Proceedings of the ACL 2003 Workshop on NLP in Biomedicine 2003 , 41 - 48 .Boeckmann B , Bairoch A , Apweiler R , Blatter MC , Estreicher A , Gasteiger E , Martin MJ , Michoud K , O'Donovan C , Phan I , Pilbout S , Schneider M : The SWISS - PROT protein knowledgebase and its supplement TeEMBL in 2003 .", "label": "", "metadata": {}, "score": "52.99179"}
{"text": "The scoring may include maximizing a log - linear scoring function in which weights are assigned to each of the feature functions .In another aspect , a machine translation system translates source text from a first language to target text in a second language .", "label": "", "metadata": {}, "score": "53.018883"}
{"text": "Table 1 : Comparison of the running times between our approach ( Linux and Windows x32 operative systems ) and Costa et al .2011 methodology ( Linux platform ) [ 8 ] .The first column lists the number of sequences and species used in each comparison ; the second and third summarize the running times of each algorithm for each set of sequences , in seconds .", "label": "", "metadata": {}, "score": "53.03804"}
{"text": "FIGS .6a and 6b , respectively , show the formatting of information in the case where M is a multiple of ST and in the case where M is not a multiple of ST ; .FIGS . 7a and 7b are , respectively , block diagrams of a word compacter and word expander circuits ; .", "label": "", "metadata": {}, "score": "53.04576"}
{"text": "Results and Discussion .Phylogenetic Reconstructions .The developed algorithm was tested in different datasets of mtDNA sequences , proving to be a simple and fast way to identify phylogenetic relationships in the different sets of mitochondrial genomes .The algorithm was first tested in a dataset composed of 29 complete primate mtDNA sequences representing genomes of different families , ranging from 15467 bp to 17036 bp long .", "label": "", "metadata": {}, "score": "53.164726"}
{"text": "This decoding stage can be done in an efficient way using the Viterbi algorithm .In this study , we used the CRF++ tool which was developed at NAIST and is freely available [ 23 ] .Below we describe the features of the CRF and SVM models .", "label": "", "metadata": {}, "score": "53.170547"}
{"text": "Otherwise , if no instance of a target gap of a given size is observed , translations using this configuration will not be generated automatically , even though instances with smaller and larger gaps exist in the training corpus .In the present exemplary embodiment , the gaps can assume different sizes with certain probabilities .", "label": "", "metadata": {}, "score": "53.189583"}
{"text": "1 auxiliary bit ( P / S7 ) .in addition to the VALID DATA bit , which is supplied by source ( S ) bypassing coder ( C ) because the information rate is not constant .The length of the words is mapped according to the algorithm : # # EQU1 # # .", "label": "", "metadata": {}, "score": "53.244926"}
{"text": "[ 1 ] and Blaschke et al .[ 2 ] demonstrated the automated extraction of protein - protein interactions ( PPIs ) from biomedical literature .They identified key words that express these interactions , and demonstrated automated extraction based on these key words and some heuristic rules .", "label": "", "metadata": {}, "score": "53.320595"}
{"text": "As for the method of Cancedda , et al . , the beam search may proceed as for a conventional beam search except as otherwise noted .Hypotheses deemed equivalent may be merged together .With elastic bi - fragments , one conditions is verified before adding an edge from a hypothesis H : .", "label": "", "metadata": {}, "score": "53.32115"}
{"text": "The training data is a set of feature vectors with a binary value ( +1 for a positive example and -1 for a negative example ) .The algorithm finds an optimal classification function that divides the positive and negative examples .We report on the features that we used in our system to recognize gene / protein names .", "label": "", "metadata": {}, "score": "53.406616"}
{"text": "FIG .9 .FIG .9 ( i ) shows a branch 905 of the BST corresponding to the comparable corpus in the same figure .The path defined by the bold edges shows that sequences xyz and abc are aligned , and diverge ( i.e. , have a mismatch ) at characters y and d , respectively .", "label": "", "metadata": {}, "score": "53.49737"}
{"text": "\" TSST-1 \" is marked as part of a gene / protein name in test set sentence 11506 , but not in sentence 10931 .Similarly , \" PTH \" is marked as part of a gene / protein name in sentence 14477 , but not in sentence 12212 .", "label": "", "metadata": {}, "score": "53.50885"}
{"text": "For example , in an implementation , an English - German translation lexicon was generated from a 1990 - 1992 Wall Street Journal corpus on the English side and a 1995 - 1996 German news wire ( DPA ) on the German side .", "label": "", "metadata": {}, "score": "53.56138"}
{"text": "Rule - based method .MedEx was originally developed at Vanderbilt University for extracting medication information from clinical text [ 16 ] .It has two main components : a semantic tagger which uses a lexicon and rules to recognize entities , and a parser which uses a semantic grammar to output structured medication information .", "label": "", "metadata": {}, "score": "53.582123"}
{"text": "( 2 ) Input the word compacter with the x bits and , in parallel , complete the word length information and successively compute the ps bits through a combining network .The input bits have the following meaning : . 8 x bits ( INXY ) .", "label": "", "metadata": {}, "score": "53.61884"}
{"text": "Vector comparison is done by adding all absolute differences of all components .Alternatively , the lexicon builder 125 may count how often another word occurs in the same sentence as the target word .The counts may then be normalized by a using the tf / idf method , which is often used in information retrieval .", "label": "", "metadata": {}, "score": "53.715397"}
{"text": "For example , \" translocation \" , \" of \" , \" the \" , \" NF - kappaB \" , \" transcription \" , \" factor \" and \" , \" are the tokens in above sample phrase .BIO representation .We used a BIO representation for chunking , using the following three tags .", "label": "", "metadata": {}, "score": "53.717564"}
{"text": "In another embodiment , two h ELAST features 34 A , 34 B may be utilized , one for the target side , and the other for the source side .Considering only a target side h ELAST feature may not be beneficial as it would not penalize \" spurious \" versions of source side phrases with unlikely gap sizes .", "label": "", "metadata": {}, "score": "53.882816"}
{"text": "Each bi - fragment includes a text fragment from the first language and a corresponding text fragment from the second language .Some of the bi - fragments are modeled as elastic bi - fragments where a gap between words is able to assume a variable size corresponding to a number of other words to occupy the gap .", "label": "", "metadata": {}, "score": "53.940025"}
{"text": "claim 3 , wherein said identifying substantially identical words comprises .applying transformation rules to words in the first corpora to form transformed words ; and . comparing said transformed words to words in the second corpora .The method of .claim 1 , wherein said one or more clues includes similar spelling .", "label": "", "metadata": {}, "score": "53.95578"}
{"text": "In order to perform the matching operation , all paths that correspond to an exhaustive traversal of one of the trees ( the source tree ) are traversed in the other ( the target tree ) , until a mismatch occurs .In the process , the target tree is augmented with information about the alignments between its paths and those of the source , thus becoming a bilingual suffix tree .", "label": "", "metadata": {}, "score": "53.98821"}
{"text": "The first and second text fragments may be a word or a phrase .The first and second fragments are associated in a word - aligned corpora , such as a library stored in memory , whereby a target fragment corresponding to an input source fragment may be retrieved .", "label": "", "metadata": {}, "score": "53.992584"}
{"text": "Simple and easy to implement , majority voting provides an effective way to combine classifiers and has been shown to deliver good performance in a number of applications , for example , in recognizing protein / gene names from research articles [ 8 ] .", "label": "", "metadata": {}, "score": "53.99462"}
{"text": "The shaded area in Figure 2 shows the elements of the feature vectors for the current word , i.e. \" NF - kappaB \" .The information from the two preceding and two following tokens is used for each vector .YamCha counts the number of features , and changes each feature into a unique positive integer .", "label": "", "metadata": {}, "score": "54.00071"}
{"text": "A machine translation system may use non - parallel monolingual corpora to generate a translation lexicon .The system may identify identically spelled words in the two corpora , and use them as a seed lexicon .The system may use various clues , e.g. , context and frequency , to identify and score other possible translation pairs , using the seed lexicon as a basis .", "label": "", "metadata": {}, "score": "54.00807"}
{"text": "Suffix : Uni- , bi- , and tri - grams ( in letters ) of the ending letters of the current token .Dictionary matching : Matching gene / protein names dictionary entries against uni- , bi- , and tri - grams ( in tokens ) of words starting at the current token .", "label": "", "metadata": {}, "score": "54.011024"}
{"text": "This indication would become stronger if , for example , the sequences following d and y in the two corpora would also be aligned .One way to verify this is to reverse both strings , build a BST for the reversed corpora ( a reverse BST ) , and look for a common path that diverges at the same d and y. .", "label": "", "metadata": {}, "score": "54.037575"}
{"text": "High Information Feature Selection .Using the same evaluate_classifier method as in the previous post on classifying with bigrams , I got the following results using the 10000 most informative words : .The accuracy is over 20 % higher when using only the best 10000 words and pos precision has increased almost 24 % while neg recall improved over 40 % .", "label": "", "metadata": {}, "score": "54.0531"}
{"text": "We measured Precision , Recall , and F - score metrics using the standard CoNLL evaluation script ( the Perl program conlleval.pl ) [ 28 ] .For the whole system , we used micro - averaging of the Precision , Recall , and F - score .", "label": "", "metadata": {}, "score": "54.140182"}
{"text": "Note II : For command line spell checking , set WORDCHARS parameters : .WORDCHARS - -- ( see tests / break .COMPOUNDRULE number_of_compound_definitions .COMPOUNDRULE compound_pattern .Define custom compound patterns with a regex - like syntax .The . first COMPOUNDRULE is a header with the number of the following .", "label": "", "metadata": {}, "score": "54.24026"}
{"text": "PubMed View Article .Kazama J , Makino T , Ohta Y , Tsujii T : Tuning Support Vector Machines for biomedical named entity recognition .Proceedings of the ACL-02Workshop on Natural Language Processing in the Biomedical Domain 2002 , 1 - 8 .", "label": "", "metadata": {}, "score": "54.260693"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a simulated distribution of gaps in a target phrase of a bi - phrase for a selected number of gaps in the corresponding source phrase .FIG .2 is a block diagram of a system for machine translation of text which utilizes non - contiguous bi - fragments according to one aspect of the exemplary embodiment ; .", "label": "", "metadata": {}, "score": "54.2672"}
{"text": "FIG .7a shows a practical example of how to implement a WC operation : the \" length evaluation \" circuit is a simple combining network which looks only at N / ST bits , a convenient delay sufficient to compact the corresponding word .", "label": "", "metadata": {}, "score": "54.29445"}
{"text": "This new hypothesis is then pushed onto a stack of hypotheses in need of being extended .To reduce the search space , partial translation hypotheses are scored , and the stack is periodically pruned based on these scores , i.e. , only the most promising hypotheses are retained on the stack .", "label": "", "metadata": {}, "score": "54.304226"}
{"text": "In order to find a value applicable to all sequences under analysis , we choose m as the length of the greater sequence and L as the smaller integer greater than .Genetic Distance .The generated frequencies matrix may then be used to assign a pairwise correlation or a metric distance between each pair or sequences .", "label": "", "metadata": {}, "score": "54.325294"}
{"text": "The decoder may buffer the parts of elastic phrases in the target text which are not yet consumed , and may use a heuristic cost function that takes into account these buffered parts in assessing the value of a partial translation hypothesis .In another aspect , a statistical translation model is provided that deals with such phrases .", "label": "", "metadata": {}, "score": "54.422276"}
{"text": "The availability of monolingual corpora has been enhanced greatly due to the digital revolution and widespread use of the World Wide Web .Methods for processing such resources can therefore greatly benefit the field .SUMMARY .In an embodiment , a system may be able to build a translation lexicon from comparable , non - parallel corpora .", "label": "", "metadata": {}, "score": "54.438354"}
{"text": "Introduction .During the last decades many sequence comparison methods have been developed in order to recover evolutionary and phylogenetic signals as well as for the discovery of pathogenic mutations [ 1 , 2 ] .The most common approaches are based on sequence alignments [ 3 , 4 ] .", "label": "", "metadata": {}, "score": "54.44628"}
{"text": "A variable length step code for use in a device which compacts words of digital data for high frequency transmission , comprising : .( b ) a suffix for signalling the end of a word , the only exception being for words of said maximum length N , which need not end with a suffix .", "label": "", "metadata": {}, "score": "54.44851"}
{"text": "These scores were higher than those of the two single classifiers CRF and SVM .According to randomization tests , the local CRF - based voting system performed significantly better than the single CRF system for overall , dosage and was significantly less accurate than the single CRF system in recognizing duration .", "label": "", "metadata": {}, "score": "54.47312"}
{"text": "Conditional random field .NER : .Named entity recognition .POS : .Part - of - speech .NLP : .Natural language processing .Declarations .Acknowledgments .De - identified clinical records used in this research were provided by the i2b2 National Center for Biomedical Computing , funded by U54LM008748 , and were originally prepared for the Shared Tasks for Challenges in NLP for Clinical Data organized by Dr. \u00d6zlem Uzuner , i2b2 and SUNY .", "label": "", "metadata": {}, "score": "54.484013"}
{"text": "For example , the left alignment xyzabc , the right alignment xzy - acb and the words y and d in .FIG .9 ( iii ) make up a context alignment 915 .Given a comparable corpus , this procedure will yield many context alignments which correspond to incorrect translations , such as that between the words \" canadien \" and \" previous \" : . tout canadien serieux .", "label": "", "metadata": {}, "score": "54.522125"}
{"text": "In the decoder of Cancedda , et al . , the states ( sometimes called \" merged hypotheses \" ) are organized in stacks , where two states are put in the same stack if they have the same number of source words covered .", "label": "", "metadata": {}, "score": "54.570847"}
{"text": "The translation system includes a library of bi - fragments .Each of the bi - fragments includes a text fragment from the first language and a text fragment from the second language .At least some of the bi - fragments are modeled as elastic bi - fragments in which words of a fragment are spaced by a gap which is able to assume a variable size corresponding to a number of other words which are to occupy the gap .", "label": "", "metadata": {}, "score": "54.725044"}
{"text": "The numbers are the overlap between the row / column items .@@11506 With / IN a / DT cutoff / NN level / NN for / IN TSST-1/NEWGENE of / IN ... were / VBD positive / JJ for / IN TSST-1/NEWGENE .", "label": "", "metadata": {}, "score": "54.898094"}
{"text": "In cases involving length codes of considerable maximum length , the implementing hardware was very complex and had to operate at very high frequencies .SUMMARY OF THE INVENTION .The object of the present invention is to provide a system which extracts word length ( WL ) information by examining a minimum number of bits , the bits contain the desired word length information .", "label": "", "metadata": {}, "score": "54.974743"}
{"text": "1a is a block diagram of a typical prior art transmission system and FIG .1b is a simplified sketch of a sequence of code words in accordance with the invention ; .FIGS .2a and 2b are diagrams showing , respectively , a buffer containing non - compacted data and a buffer containing compacted data ; .", "label": "", "metadata": {}, "score": "55.06961"}
{"text": "The first column shows the values when only the word and preceding class features were used in the SVM learning .The other columns shows the values when the word and preceding class features plus one other feature were used in the learning .", "label": "", "metadata": {}, "score": "55.075214"}
{"text": "The word expander .Therefore two counters ( EOW / LASTEOW ) are necessary and , at the same time , two registers ( REGA , REGB ) must be simultaneously examined through the EOW / LASTEOW registers contents and the DEC ( FIG .", "label": "", "metadata": {}, "score": "55.113174"}
{"text": "Unknown word .Circumfix .Conditional affixes implemented by a continuation class are not enough for circumfixes , because a circumfix is one affix in morphology .We also need CIRCUMFIX option for correct morphological analysis .PFX B Y 1 PFX B 0 legesleg / X .", "label": "", "metadata": {}, "score": "55.169014"}
{"text": "The other columns have a similar meaning .The suffix ( preceding class ) feature greatly affected recall ( precision ) .The other features had little effect .Table 9 showed the effect of adding the other features to the \" base \" .", "label": "", "metadata": {}, "score": "55.24728"}
{"text": "The content of the buffer may vary during the extension of a hypothesis as new suffixes are added and consumed suffixes are removed .Where a suffix includes more than one word , the words may be removed from the buffer one at a time .", "label": "", "metadata": {}, "score": "55.28013"}
{"text": "As shown , using all features , CRF and SVM give significantly higher F - scores ( the differences are significant according to randomization tests ) than the customized MedEx system which served as the baseline in this experiment .This can be explained because CRF and SVM can harness the advantages both from the rule - based system ( i.e. , features from MedEx ) and from machine - learning algorithms .", "label": "", "metadata": {}, "score": "55.29818"}
{"text": "In many translation systems , the quality of the resulting translation is assessed by means of a statistical translation model , which estimates the probability of observing some target - language segment of the text as the translation of the given source - language input .", "label": "", "metadata": {}, "score": "55.318172"}
{"text": "@@14477 ... the / DT secretion / NN of / IN PTH / NEWGENE and / CC CT / NEWGENE ... ./CD 59/CD,/ , p / NN .Effects of tuning parameters and features .We analyzed the effects of the tuning parameters and features on system performance .", "label": "", "metadata": {}, "score": "55.38327"}
{"text": "REP number_of_replacement_definitions REP what replacement We can define language - dependent phonetic information in the affix file ( . aff ) by a replacement table .First REP is the header of this table and one or more REP data line are following it .", "label": "", "metadata": {}, "score": "55.420837"}
{"text": "If the monolingual corpora are somewhat comparable , it can be assumed that a word that occurs in a certain context should have a translation that occurs in a similar context .The context may be defined by the frequencies of context words in surrounding positions .", "label": "", "metadata": {}, "score": "55.488525"}
{"text": "In the following section we describe the use of SVM and CRF for assigning a label to each token ( word ) from the discharge summaries .Support vector machines .A Support Vector Machine ( SVM ) is a machine - learning method that is widely used in many NLP tasks such as phrase chunking , Part - of - Speech ( POS ) tagging , and NER .", "label": "", "metadata": {}, "score": "55.548542"}
{"text": "The method of .claim 1 , wherein the translation scoring function utilizes a log - linear scoring model of the form : .Pr .t .J .d .K .s .I . )Z .f .I . exp .", "label": "", "metadata": {}, "score": "55.54889"}
{"text": "One way to harness the advantages of both these approaches is to combine them into an ensemble classifier [ 4 , 6 , 8 ] .Zhou et al .[ 8 ] investigated the combination of three classifiers , including one SVM and two discriminative Hidden Markov Models , into an ensemble classifier with a simple majority voting strategy .", "label": "", "metadata": {}, "score": "55.550438"}
{"text": "Fukuda et al .[ 4 ] and Frenz\u00e9n et al .[5 ] developed automated recognition systems based on hand - crafted rules .They identified key terms for recognizing protein names , which they termed \" core terms \" ( e.g. capital letters and special symbols ) and \" feature terms \" ( e.g. \" protein \" and \" receptor \" ) .", "label": "", "metadata": {}, "score": "55.565903"}
{"text": "While rule - based approaches use existing biomedical knowledge / resources , supervised machine learning based approaches rely heavily on annotated training data and domain dictionaries .The advantage of rule - based approaches is that they are easily customized to new vocabulary and author styles , while supervised machine learning approaches often report better results when the task domain does not change and training data is plentiful .", "label": "", "metadata": {}, "score": "55.620964"}
{"text": "4 , no . 1 , pp .81 - 95 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. A. Carrigan , O. Uryasev , R. P. Davis , L. Zhai , T. D. Hurley , and S. A. Benner , \" The natural history of class I primate alcohol dehydrogenases includes gene duplication , gene loss , and gene conversion , \" PLoS ONE , vol .", "label": "", "metadata": {}, "score": "55.70347"}
{"text": "Settles B : Biomedical named entity recognition using conditional random fields and rich feature sets .Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications ( NLPBA / BioNLP )2004 , 104 - 107 .View Article .", "label": "", "metadata": {}, "score": "55.721603"}
{"text": "33 , No . 2 , pp . 111 - 124 , 2005 .K.Papineni , et al . , Bleu : A Method for Automatic Evaluation of Machine Translation , Proc . of the 40th Annual Meeting of the Assn . for Computational Linguistics ( ACL ) , Philadelphia , pp . 311 - 318 , Jul. 2002 .", "label": "", "metadata": {}, "score": "55.87536"}
{"text": "We tagged using the Brill tagger in the training and two test data sets because we wanted to use POS as a feature .Orthography : Table 2 shows the orthographic features .If the token has more than one feature , then we used the feature listed first in Table 2 ( left side comes before the right side in the table ) .", "label": "", "metadata": {}, "score": "55.884907"}
{"text": "claim 1 , wherein said identifying comprises identifying cognates .The method of .claim 1 , wherein said identifying comprises identifying word pairs having a minimum longest common subsequence ratio .The method of .claim 1 , wherein said one or more clues includes similar context .", "label": "", "metadata": {}, "score": "55.931366"}
{"text": "To evaluate the performance of the various methods and features we used two experimental settings .In the first setting , 268 annotated discharge summaries from the 2009 i2b2 challenge were used ( 17 from the training set and 251 from the test set ) .", "label": "", "metadata": {}, "score": "55.969692"}
{"text": "A search for the optimal combination may be performed by means of a specially adapted , multiple - stack beam search .Within this search procedure , the potential of each candidate translation is evaluated by means of a statistical model of translation .", "label": "", "metadata": {}, "score": "55.97682"}
{"text": "claim 14 , wherein the translation scoring function outputs a translation for which the log - linear scoring model is maximized .A machine translation system for translating source text from a first language to target text in a second language , comprising : . memory which stores instructions for performing the method of .", "label": "", "metadata": {}, "score": "56.022797"}
{"text": "Some gene / protein names are compound tokens .The average number of tokens per name was 2.131 tokens in the training data .In the first run , the average number of tokens per name were 1.998 ( TP ) , 2.406 ( FP ) , and 2.298 tokens ( FN ) .", "label": "", "metadata": {}, "score": "56.07646"}
{"text": "Temkin JM , Gilder MR : Extraction of protein interaction information from unstructured text using a context - free grammar .Bioinformatics 2003 , 19 ( 16 ) : 2046 - 2053 .View Article PubMed .Fukuda K , Tamura A , Tsunoda T , Takagi T : Toward Information Extraction : Identifying protein names from biological papers .", "label": "", "metadata": {}, "score": "56.128162"}
{"text": "5 shows the suffix tree 500 of string xyzyxzy .Note that if a suffix of a string is also a prefix of another suffix ( as would be the case for suffix zy of string xyzyxzy ) , a proper suffix tree can not be built for the string .", "label": "", "metadata": {}, "score": "56.148083"}
{"text": "We ran this procedure ten times ; each time we picked a different subset for testing and the nine remaining subsets for training .Each time we built a classifier with the training sets and evaluated on the testing set .Reported results for SVM in this paper use the same parameter settings of SVM .", "label": "", "metadata": {}, "score": "56.229652"}
{"text": "In the DIC column , the first three items show the results ( Y or N ) of the uni- , bi- , and tri - gram ( in token ) matching for the protein names in the dictionary .The last item shows the result of the uni - gram ( in token ) matching for the gene names in the dictionary .", "label": "", "metadata": {}, "score": "56.264465"}
{"text": "The best F - score is underlined .Second , we compared the performance of MedEx , CRF - based , and SVM - based NER systems ( the CRF - based and SVM - based systems used all six types of features ) .", "label": "", "metadata": {}, "score": "56.374107"}
{"text": "We also show the case in which the stop words were not ignored in the dictionary matching .A statistically significant difference was seen in this case , so stop words should be ignored in dictionary matching .Effect of POS tagger .As mentioned above , we used the Brill tagger [ 15 ] for POS tagging .", "label": "", "metadata": {}, "score": "56.478596"}
{"text": "As a consequence , the model is able to consider an extended and more representative class of potential translations and to evaluate them more accurately .The exemplary embodiment introduces the notion of elastic bi - phrase , and provides a decoding mechanism for producing translations using the resulting model .", "label": "", "metadata": {}, "score": "56.54724"}
{"text": "However , if there is a imbalance in the uses , the word is drawn towards the more frequently related term .This process is repeated for thousands of other word combinations , creating a spectrum of word associations .Font size is based on a inverse power function ( uniquely set for each visualization , so you ca n't compare across pieces ) .", "label": "", "metadata": {}, "score": "56.558887"}
{"text": "156 - 163 , Philadelphia , 2002 .S.Kumar , W.Byrne , A Weighted Finite State Transducer Implementation of the Alignment Template Model for Statistical Machine Translation , In HLT - NAACL 2003 , Main Papers , pp .63 - 70 , Edmonton , Canada , May - Jun .", "label": "", "metadata": {}, "score": "56.568226"}
{"text": "In practice , it is to be expected that contiguous bi - fragments ( the gap size is 0 ) are somewhat more reliable than non - contiguous ones .Therefore , one aspect that the translation scoring function may take into account is the amount of \" non - contiguity \" that goes into any given translation .", "label": "", "metadata": {}, "score": "56.57134"}
{"text": "The sequence 52 is a contiguous string of target words , and the buffer 46 comprises a set of target phrase suffixes 54 .Each target phrase suffix 54 constitutes the non - consumed portion of a target phrase for which the ongoing hypothesis has established that a gap exists between a first portion and a second portion of the target phrase .", "label": "", "metadata": {}, "score": "56.580357"}
{"text": "For all tables , \" ALL \" means the set of all named entities with values corresponding to micro - averaged Precision / Recall / F - score .Table 4 shows that the best F - score achieved was 90.54 % when using all features for the SVM - based NER system .", "label": "", "metadata": {}, "score": "56.583332"}
{"text": "The pooled estimates can than replace standard estimates , or they can be used as a back - off when too few occurrences of a bi - phrase are observed , and the standard estimates are likely to be unreliable .Gaps on the target side can be modeled analogously .", "label": "", "metadata": {}, "score": "56.608612"}
{"text": "Uzuner \u00d6 , Solti I , Cadag E : Extracting medication information from clinical text .J Am Med Inform Assoc 2010 , 17 ( 5 ) : 514 - 518 .PubMed View Article .Patrick J , Li M : High accuracy information extraction of medication information from clinical notes : 2009 i2b2 medication extraction challenge .", "label": "", "metadata": {}, "score": "56.713272"}
{"text": "In aspects of the exemplary embodiment , gaps in source and target phrases are modeled utilizing one or more of the following simplifying assumptions : .For a given bi - phrase ( s , t ) , the gap sizes ( source and/or target ) are mutually independent .", "label": "", "metadata": {}, "score": "56.72558"}
{"text": "If the lexicon is probabilistic , each matching between two words will be weighted by the corresponding translation probability .The paths in the resulting bilingual tree will also have weights associated with them , defined as the product of the matching probabilities of the words along the path .", "label": "", "metadata": {}, "score": "56.801975"}
{"text": "claim 1 wherein said expanding comprises using the identically spelled words in the seed lexicon as accurate translations .The method of .claim 1 , further comprising : . identifying substantially identical words in the first and second corpora ; and . adding said substantially identical words to the seed lexicon .", "label": "", "metadata": {}, "score": "56.8293"}
{"text": "Marcu , Daniel , \" Building Up Rhetorical Structure Trees , \" 1996 , Proc . of the National Conference on Artificial Intelligence and Innovative Applications of Artificial Intelligence Conference , vol .2 , pp .1069 - 1074 .Och , F. , \" Minimum Error Rate Training in Statistical Machine Translation , \" In Proceedings of the 41st Annual Meeting on Assoc . for Computational Linguistics - vol . 1 ( Sapporo , Japan , Jul. 7 - 12 , 2003 ) .", "label": "", "metadata": {}, "score": "56.880768"}
{"text": "Machine learning - based methods .In the case of named entity recognition , the labels incorporate two concepts : the type of the entity and the position of the token within the entity .In this project , we used a simple representation for token position called BIO .", "label": "", "metadata": {}, "score": "56.963432"}
{"text": "In order to better focus on the problem to which the present invention is directed , reference is first made to the block diagram of FIG .1a .Examining the diagram from left to right , we have the following functional blocks : .", "label": "", "metadata": {}, "score": "56.966167"}
{"text": "We performed a 10-fold cross validation using 90 % of the combined data set as training data and the remainder as test data .This combined data set was also used in the analyses shown in Tables 8 , 9 , 10 , 11 .", "label": "", "metadata": {}, "score": "56.978935"}
{"text": "FIG .3 ): .Buffer consumption : one word from a buffered suffix ( step S 112 E ) and appending it to the end of the sequence ( step S 112 G ) .The process ends when both the coverage of the source is complete and the buffer is empty .", "label": "", "metadata": {}, "score": "57.04059"}
{"text": "Instead , we ran an algorithm that pulls dots with edges between them closer together .Then we labeled each cluster by the key words that are common to the reports in that cluster , and colored each report / dot by the \" incident type , \" as entered by military personnel .", "label": "", "metadata": {}, "score": "57.04351"}
{"text": "The 0 stack , by convention contains a null hypothesis .Stack 1 ( identified as 62 ) contains hypotheses in which the source projection is a string of one word , such as Je and danser .The beam search starts with an hypothesis in the first stack and adds a bi - phrase or consumes a buffered word using the principles outlined above .", "label": "", "metadata": {}, "score": "57.08106"}
{"text": "This algorithm has achieved good performance in many classification tasks , and we have previously showed that it performs well for protein name recognition [ 11 ] .Gazetteers have often been used for the named entity recognition task on newswire corpora .However , as Tsuruoka et al .", "label": "", "metadata": {}, "score": "57.149193"}
{"text": "+ COMPARATIVE SFX C 0 obb / AX .+ SUPERLATIVE SFX C 0 obb / BX .Compounds .Allowing free compounding yields decrease in precision of recognition , not to mention stemming and morphological analysis .Although lexical switches are introduced to license compounding of bases by Ispell , this .", "label": "", "metadata": {}, "score": "57.199703"}
{"text": "MAP number_of_map_definitions MAP string_of_related_chars We can define language - dependent information on characters that should be considered related ( i.e. nearer than other chars not in the set ) in the affix file ( . aff ) by a character map table .With this table , Hunspell can suggest the right forms for words , which incorrectly choose the wrong letter from a related set more than once in a word .", "label": "", "metadata": {}, "score": "57.315006"}
{"text": "] sx ) code meets this requirement .Thus , in FIG .1b , since word 4 does not have a suffix sx , the maximum code length must be 4 steps .Both prefixes and suffixes are convenient combinations of bits of fixed length ST referred to as \" steps \" : it is evident that any word length will be a multiple of the step length ST . .", "label": "", "metadata": {}, "score": "57.33189"}
{"text": "We used the orthographic features described in [ 25 ] and modified some specifically for medication information such as \" digit \" and \" percent . \" In total , we had 21 labels for orthographic features .History features ( or preceding class feature ) : class assignment of the preceding word .", "label": "", "metadata": {}, "score": "57.40065"}
{"text": "The apparatus of 26 , the apparatus comprising : . an alignment module operative to be executed to align text segments in two nonparallel corpora , the corpora including a source language corpus and a target language corpus .The apparatus of .claim 27 , wherein the alignment module is operative to build a Bilingual Suffix Tree from a text segment from one of said two non - parallel corpora .", "label": "", "metadata": {}, "score": "57.43396"}
{"text": "The system also found translations for thirty unknown French words .Of these , nine were correct , which means a precision of 30 % .For each of the two corpora , building the monolingual GST took only 1.5 minutes .The matching operation that yields the BST is the most time - consuming : it lasted 38 hours for the forward BST and 60 hours for the reverse BST .", "label": "", "metadata": {}, "score": "57.59422"}
{"text": "claim 1 , wherein said identifying comprises : . identifying a plurality of context words ; and . identifying a frequency of context words in an n - word window around a target word .The method of .claim 9 , further comprising generating a context vector .", "label": "", "metadata": {}, "score": "57.67188"}
{"text": "SYLLABLENUM flags .Need for special compounding rules in Hungarian .OPTIONS FOR AFFIX CREATION .PFX flag cross_product number PFX flag stripping prefix condition [ morphological_fields ... ]SFX flag cross_product number SFX flag stripping suffix condition [ morphological_fields ... ]An affix is either a prefix or a suffix attached to root words to make other words .", "label": "", "metadata": {}, "score": "57.737846"}
{"text": "In previous work , various strategies have been proposed to integrate multiple classifiers , e.g. simple majority voting [ 6 , 8 ] , bootstrapping [ 26 ] and boosting [ 27 ] .In this paper , ensembles were constructed using simple voting strategies .", "label": "", "metadata": {}, "score": "57.748436"}
{"text": "This is a complex task , because the number of possible translations typically grows exponentially with the size of the input , and so not all solutions can be examined in practice .INCORPORATION BY REFERENCE .The following references , the disclosures of which are incorporated herein in their entireties by reference , are mentioned : .", "label": "", "metadata": {}, "score": "57.78151"}
{"text": "Compound patterns consist compound .flags and star or question mark meta characters .A flag followed . signed with this compound flag .A flag followed by a \u00e2\u20ac\u02dc?\u00e2\u20ac \u2122 .matches a word sequence of 0 or 1 matches of a word signed with .", "label": "", "metadata": {}, "score": "57.81197"}
{"text": "Named Entity Recognition ( NER ) is an important step in natural language processing ( NLP ) .It has many applications in the general language domain such as identifying person names , locations , and organizations .NER is crucial for biomedical literature mining as well [ 1 , 2 ] ; many studies have focused on biomedical entities , such as gene / protein names .", "label": "", "metadata": {}, "score": "57.86576"}
{"text": "They correspond to the 3 rd run in Table 5 .\" GDP1-stop words \" means the results when the stop words were not ignored in dictionary matching on the 1 st run .The parenthesized values are p - values .", "label": "", "metadata": {}, "score": "57.92012"}
{"text": "The search terminates when all remaining hypotheses on the stack are complete , i.e. , they cover all the source words .Existing decoding procedures assume bi - fragments to be contiguous .The following method adapts a beam search procedure to handle elastic bi - fragments .", "label": "", "metadata": {}, "score": "57.938385"}
{"text": "The whole circuit is developed only if single RDOUT ( i.e. request of data by the output ) is present .An analogous signal RDIN ( i.e. request of data to the input ) is generated as a function of the RDOUT signal and of combining networks RC1 , RC2 ( FIG .", "label": "", "metadata": {}, "score": "57.967678"}
{"text": "I . t .J .d .K . ) k .K . log .Pr . target .d . k . ) source .d . k . )( 2 ) a gap size scoring feature ( h ELAST ) , of the general form : . h .", "label": "", "metadata": {}, "score": "57.98324"}
{"text": "Franz\u00e9n K , Eriksson G , Asker FOL , Lid\u00e9n P , C\u00f6ster J : Protein names and how to find them .International Journal of Medical Informatics 2002 , 67 : 49 - 61 .View Article PubMed .Collier N , Nobata C , Tsujii J : Extracting the Names of Genes and Gene Production with a Hidden Marcov Model .", "label": "", "metadata": {}, "score": "58.006363"}
{"text": "No .5,477,451 by Brown , et al .entitled \" METHOD AND SYSTEM FOR NATURAL LANGUAGE TRANSLATION , \" and U.S. Pat .No .6,304,841 by Berger , et al . , entitled \" AUTOMATIC CONSTRUCTION OF CONDITIONAL EXPONENTIAL MODELS FROM ELEMENTARY FEATURES \" describe word - based statistical machine translation methods and systems for natural language translation .", "label": "", "metadata": {}, "score": "58.08784"}
{"text": "This is because , as with the method of Cancedda , et al ., the stacks are generally pruned to remove the lowest ( highest cost ) states , once they reach a preselected number of states .In the elastic decoder , source coverage may not be the best way to place a hypothesis in the stack .", "label": "", "metadata": {}, "score": "58.221886"}
{"text": "Duration and reason are those from the SVM model , whereas the remaining mentions are those from the CRF outputs .Specifically , for a given word , if the SVM predicts duration or reason then use its label for the word ; otherwise , use the CRF prediction .", "label": "", "metadata": {}, "score": "58.23478"}
{"text": "Unlike most Many Eyes visualizations , the word tree starts with a blank slate instead of a full visualization of the data .You must choose a search term to display a word tree .After a word or phrase is typed , the computer finds all the occurrences of that term , along with the phrases that appear after it .", "label": "", "metadata": {}, "score": "58.25686"}
{"text": "Since the training and testing data in the two experimental settings are different , it is difficult to choose the best voting method for all data .Conclusions .In this study , we investigated the combination of NER outputs from a rule - based system and two supervised machine learning systems into an ensemble classifier using different voting methods to improve recognition of medication entities from discharge summaries .", "label": "", "metadata": {}, "score": "58.322296"}
{"text": "Building a GST for a set of strings takes time and space linear in the sum of the lengths of all strings in the set .A Bilingual Suffix Tree ( BST ) is the result of matching a source language GST against a target language GST .", "label": "", "metadata": {}, "score": "58.558975"}
{"text": "ELAST .s .I . t .J .d .K . ) k .K .EL . target .d . k . ) source .d . k . ) where EL may be a function of the probabilities of gaps in the target and source fragments for a bi - fragment .", "label": "", "metadata": {}, "score": "58.5765"}
{"text": "Morphological analysis .Optional data fields .Default morphological and other IDs ( used in suggestion , stemming and morphological generation ) : ph : Alternative transliteration for better suggestion .It\u00e2\u20ac \u2122 s useful for words with foreign pronunciation .( Dictionary based phonetic suggestion . )", "label": "", "metadata": {}, "score": "58.654213"}
{"text": "reord .s .I . t .J .d .K . ) k .K .i .i .d . k . )I .V .i . k . )Beam Search Procedure .Beam - search procedures are described , for example , in Cancedda , et al . , incorporated herein by reference .", "label": "", "metadata": {}, "score": "58.764717"}
{"text": "The lexicon builder 125 may combine different clues by adding up the matching scores .The scores can be weighted .For example , when using the spelling clue in combination with others , it may be useful to define a cutoff .If two words agree in 30 % of their letters , this is generally as bad as if they do not agree in any , i.e. , the agreements are purely coincidental .", "label": "", "metadata": {}, "score": "58.805656"}
{"text": "The non - transitory computer readable medium of .claim 15 wherein said expanding comprises using the identically spelled words in the seed lexicon as accurate translations .The non - transitory computer readable medium of . claim 15 , further comprising : . identifying substantially identical words in the first and second corpora ; and . adding said substantially identical words to the seed lexicon .", "label": "", "metadata": {}, "score": "58.821648"}
{"text": "In this figure , two possible separating patterns are shown : a small margin and a large margin .The two dashed lines and margin d are given by .An SVM finds the values for the variables w and b which maximizes the margin for the training data .", "label": "", "metadata": {}, "score": "58.824036"}
{"text": "It is often convenient to make use of a variable length code ; in fact , by adapting the code to the probability distribution of the messages ( Me ) coming from source ( S ) , a considerable bit rate saving may be obtained .", "label": "", "metadata": {}, "score": "58.87393"}
{"text": "Torii M , Hu Z , Wu CH , Liu H : BioTagger - GM : a gene / protein name recognition system .J Am Med Inform Assoc 2009 , 16 : 247 - 255 .PubMed View Article .Yamamoto K , Kudo T , Konagaya A , Matsumoto Y : Protein name tagging for biomedical annotation in text .", "label": "", "metadata": {}, "score": "58.982468"}
{"text": "The word and preceding class features were also used in both cases .The f - score using GENIA trained POS tagger was worse than that using the original POS tagger .The \" full(A ) \" and \" full(B ) \" columns show the cases using the original and GENIA trained POS tagger , respectively .", "label": "", "metadata": {}, "score": "58.983307"}
{"text": "Bioinformatics 2001 , 17 ( 2 ) : 155 - 161 .View Article PubMed .Blaschke C , Valencia A : Can bibliographic pointers for known biological data be found automatically ?Protein interactions as a case study .Comparative and Functional Genomics 2001 , 2 : 196 - 206 .", "label": "", "metadata": {}, "score": "59.06682"}
{"text": "Optional : default stem is the dictionary item in morphological analysis .Stem field is useful for virtual stems ( dictionary words with NEEDAFFIX flag ) and morphological exceptions instead of new , single used morphological rules .A dictionary item is the stem of its allomorphs .", "label": "", "metadata": {}, "score": "59.06927"}
{"text": "Translating with Elastic Bi - Fragments .The translation of a source sentence f is produced by combining together bi - fragments so as to entirely cover the source sentence , and produce a well - formed target - language sentence , i.e. , a sequence without gaps .", "label": "", "metadata": {}, "score": "59.162876"}
{"text": "Heuristics .In adopting the h ELAST feature 34 discussed above , only a few adaptations to the admissible heuristics described in Cancedda , et al .need be made .One adaptation may include lower - bounding the value of h ELAST based on a consideration of the buffer .", "label": "", "metadata": {}, "score": "59.180847"}
{"text": "The dictionary was constructed based on the gene / protein names from the SWISS - PROT and TrEMBL databases .The SWISS - PROT database is a protein knowledge base including amino acid sequences and other properties currently known about the proteins .It is manually annotated .", "label": "", "metadata": {}, "score": "59.212906"}
{"text": "A limit may be placed on the number of uncovered source language words to the left of the last covered word .Note that if the constraint completely disallows uncovered source language words to the left of the last covered word , the decoder works as a monotone decoder , meaning that reorderings are not allowed between the source and the target .", "label": "", "metadata": {}, "score": "59.40838"}
{"text": "As such , it ignores the source language sentence and the decomposition of the target into bi - phrases , to focus on the actual sequence of target - language words produced by the combination of bi - phrases : . h .u . s .", "label": "", "metadata": {}, "score": "59.417"}
{"text": "Other ensembles were constructed based on characteristics of NE fields and our results of single CRF - based or SVM - based NER systems for individual fields in the first experimental setting ( described below ) , especially for duration and reason .Therefore , it is difficult for one single machine learning model to perform well on all NE classes .", "label": "", "metadata": {}, "score": "59.632225"}
{"text": "word form , when the misspelled word contains f instead of ph and vice .versa .SET UTF-8 .TRY esianrtolcdugmphbyfvkwzESIANRTOLCDUGMPHBYFVKWZ\u00e2\u20ac \u2122 .REP 2 .REP f ph .REP ph f .PFX A Y 1 .PFX A 0 re .", "label": "", "metadata": {}, "score": "59.658577"}
{"text": "The two single CRF - based , SVM - based systems as well as two local CRF - based and SVM - based voting systems are not significantly different , except for some variations in F - scores for the duration field .The two experimental settings showed empirical evidence that the ensemble classifiers outperformed single classifiers .", "label": "", "metadata": {}, "score": "59.777557"}
{"text": "claim 1 , wherein said identifying comprises identifying frequencies of occurrence of words in the first and second first corpora .The method of .claim 1 , further comprising : generating matching scores for each of a plurality of clues .The method of .", "label": "", "metadata": {}, "score": "59.84415"}
{"text": "2677 - 2682 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . D. Gusfield , Algorithms on Strings , Trees , and Sequences : Computer Science and Computer Biology , Cambridge University Press , New York , NY , USA , 1997 .", "label": "", "metadata": {}, "score": "59.854507"}
{"text": "At least some of the bi - fragments are modeled as elastic bi - fragments in which words of a fragment are spaced by a gap which is able to assume a variable size corresponding to a number of other words which are to occupy the gap .", "label": "", "metadata": {}, "score": "59.93646"}
{"text": "At least some of the bi - fragments are modeled as elastic bi - fragments in which words of a fragment are spaced by a gap which is able to assume a variable size corresponding to a number of other words which are to occupy the gap .", "label": "", "metadata": {}, "score": "59.93646"}
{"text": "At least some of the bi - fragments are modeled as elastic bi - fragments in which words of a fragment are spaced by a gap which is able to assume a variable size corresponding to a number of other words which are to occupy the gap .", "label": "", "metadata": {}, "score": "59.93646"}
{"text": "A further reduction of hardware ( WC / WE circuits ) complexity occurs when the packet length M is a multiple of the step length ST , simultaneously satisfying of the following two requirements : .In other words , the step length ST must be a submultiple of the packet length M ( often a given parameter ) .", "label": "", "metadata": {}, "score": "59.939026"}
{"text": "The percentages of names over 4 or more tokens long in the FP and FN were higher than the one for TP , suggesting that recognizing longer names is more difficult than recognizing shorter ones .Percentage of n - grams of gene / protein names in test data for evaluation and TP , FP , and FN datasets .", "label": "", "metadata": {}, "score": "59.952377"}
{"text": "You will notice that in the words following \" word \" there are many repeated phrases .For instance , \" tree \" follows \" word \" five times , and \" or phrase \" follows three times .To create a word tree , the computer merges all the matching phrases .", "label": "", "metadata": {}, "score": "60.168846"}
{"text": "According to these authors , there is an optimal resolution range in which any integer value should be considered as the length of L .Any value inside this interval is equally good .So , in order to increase the speed of the process we start by considering only the lower limit of resolution , which is given by the expression .", "label": "", "metadata": {}, "score": "60.196552"}
{"text": "I . t .J .d .K . ) k .K . log .Pr . target .d . k . ) source .d . k . )The h bf feature estimates the log of the probability of observing the bi - phrase configuration ( s , t ) given the source phrase configuration s in the training corpus through the ratio of respective counts of these configurations .", "label": "", "metadata": {}, "score": "60.1998"}
{"text": "Bi - Fragment Library .To produce translations , the method relies on a collection of bi - fragments , which is referred to as a bi - fragment library 20 .An Adapted Translation Method .It will be appreciated that a source string may be translated as multiple different target strings where multiple alternative bi - fragments exist .", "label": "", "metadata": {}, "score": "60.20323"}
{"text": "Still , these words , often called \" cognates , \" maintain a very similar spelling .This can be defined as differing in very few letters .This measurement can be formalized as the number of letters common in sequence between the two words , divided by the length of the longer word .", "label": "", "metadata": {}, "score": "60.211693"}
{"text": "In the electrical diagrams , conventional symbols have been used ; an ad - hoc combining network is described using logic tables : in any case , the analysis is shown in such a way that any skilled person may easily utilize the data in order to simulate the described functions .", "label": "", "metadata": {}, "score": "60.282883"}
{"text": "Conclusion .We participated in Task 1A of the BioCreAtIvE competition using the SVM algorithm .We evaluated the effect of several features on SVM learning .We also introduced information from external resources ( gene / protein name databases ) as a feature .", "label": "", "metadata": {}, "score": "60.35471"}
{"text": "The results in Table 5 were for the evaluation test data ; cross validation was not used . \"GPD1 \" means the results using GPD1 in dictionary matching .They correspond to the 1 st run in Table 5 . \"GPD1 with regexp . \" means the results using GPD1 with regular expressions in dictionary matching .", "label": "", "metadata": {}, "score": "60.37378"}
{"text": "When considering each field separately , significant differences in performance between the two systems have been observed for the dosage , frequency , and duration fields : the SVM - based system performed better for dosage and frequency while the CRF - based system performed better for duration .", "label": "", "metadata": {}, "score": "60.40985"}
{"text": "7 shows two corpora 705 , 710 , a bilingual lexicon 715 , and the corresponding BST 720 .Edges drawn with dotted lines mark ends of alignment paths through the tree .Their labels are ( unaligned ) continuations of the source language substrings from the respective paths .", "label": "", "metadata": {}, "score": "60.44975"}
{"text": "But just selecting the most frequently occurring bigrams ( sequence of two adjacent words ) does not always yield the better results .Following are a few bigrams resulted from an experiment . of the in the to the as a has been New York is a for a .", "label": "", "metadata": {}, "score": "60.569458"}
{"text": "A CRF assigns probabilities to possible class labels y of input sequences x .For the problem at hand , x is the sequence of tokens and y is the corresponding label sequence .In a linear chain CRF , which is used for sequence modeling tasks , the label y i at position i depends on its predecessor y i -1 and successor y i +1 .", "label": "", "metadata": {}, "score": "60.67234"}
{"text": "16 , no . 1 , pp . 8 - 28 , 2000 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .G. E. Sims , S. R. Jun , G. A. Wu , and S. H. Kim , \" Alignment - free genome comparison with feature frequency profiles ( FFP ) and optimal resolutions , \" Proceedings of the National Academy of Sciences of the United States of America , vol .", "label": "", "metadata": {}, "score": "60.673756"}
{"text": "b .i . )n .n .The result is a matrix with similarity scores between all German words , and a second matrix with similarity scores between all English words .For a new word , the lexicon builder 125 may look up its similarity scores to seed words , thus creating a similarity vector .", "label": "", "metadata": {}, "score": "60.698227"}
{"text": "We note that these features are different from those of the Sydney team when they used CRF - based methods .The Sydney team used six features corresponding to six NE classes and a window size of five .In order to extract those features , they used heuristic methods such as dictionary or gazetteer look - up for NE phrases [ 10 ] .", "label": "", "metadata": {}, "score": "60.733204"}
{"text": "None of the features affected precision much , while all of them affected recall .Effect of dictionary matching methods .Table 10 shows the effect of each dictionary matching method .We used the features and parameters shown in Tables 1 and 4 .", "label": "", "metadata": {}, "score": "60.73498"}
{"text": "BACKGROUND OF THE INVENTION .Field of the Invention .The invention relates generally to variable length code words for high frequency digital transmission systems and , more particularly , to a system which compacts variable length code words at the transmission end into constant length packets and successively extracts them at the reception end .", "label": "", "metadata": {}, "score": "60.736008"}
{"text": "YamCha is a general purpose SVM - based chunker .YamCha takes in the training and test data and formats it for the SVM .The format of YamCha for a sample phrase is shown in Figure 2 .The phrase is written vertically in the WORD column .", "label": "", "metadata": {}, "score": "60.96028"}
{"text": "( 2 ) e 1 and e 2 are both still in the buffer .In this case , the mode ( maximum ) of the distribution for the corresponding gap is known a priori .The mode can be used as the basis for the optimistic evaluation of the contribution of the gap to the h ELAST feature . log .", "label": "", "metadata": {}, "score": "60.985554"}
{"text": "To the best of our knowledge , this is the first study on investigating ensemble classifiers in recognizing medication relevant entities in clinical text .Ensemble classifiers are built based on different combination methods and are evaluated using the challenge data set .Our studies provide valuable insights into the NER task for medical entities in clinical text .", "label": "", "metadata": {}, "score": "61.049164"}
{"text": "A second way is to type a pattern with two asterisks for the \" slots \" of the pattern .Note that you need exactly two asterisks for the pattern to work .Finally , there 's an advanced programmers - only option , which is to use a \" regular expression \" with two capturing groups .", "label": "", "metadata": {}, "score": "61.238014"}
{"text": "The method of .The method of .claim 1 , wherein the generating of a target hypothesis includes performing a multiple stack beam - search .The method of .claim 1 , wherein the generating of at least one target hypothesis includes generation of a plurality of partial translation hypotheses , scoring the partial hypotheses , and optionally pruning partial translation hypotheses according to their scores .", "label": "", "metadata": {}, "score": "61.26777"}
{"text": "In Table 8 , one feature is removed at a time .As shown in the table , except for the suffix and preceding class features , removing any one feature did not have a large effect .In Table 9 , the evaluations were performed by using each feature one at a time in addition to the word and preceding class features .", "label": "", "metadata": {}, "score": "61.283455"}
{"text": "s .I . t .J .d .K . ) k .K .EL . target .d . k . ) source .d . k . ) where EL represents a logarithm of a probability of observing a certain configuration of gap sizes in the target and source fragments of a bi - fragment .", "label": "", "metadata": {}, "score": "61.33952"}
{"text": "U.S. Published Application No . 2004/0024581 by Koehn , et al . , entitled \" STATISTICAL MACHINE TRANSLATION , \" discloses a phrase - based statistical machine translation method using syntactic markers for contiguous phrases .U.S. Published Application No .2004/0030551 by Marcu , et al . , entitled \" PHRASE TO PHRASE JOINT PROBABILITY MODEL FOR STATISTICAL MACHINE TRANSLATION \" discloses a phrase to phrase joint probability model for statistical machine translation .", "label": "", "metadata": {}, "score": "61.359554"}
{"text": "PubMed View Article .Doan S , Bastarache L , Klimkowski S , Denny JC , Xu H : Integrating existing natural language processing tools for medication extraction from discharge summaries .J Am Med Inform Assoc 2010 , 17 ( 5 ) : 528 - 531 .", "label": "", "metadata": {}, "score": "61.381145"}
{"text": "Methods .The support vector machine ( SVM ) , introduced by Vapnik [ 18 ] , is a learning algorithm for solving two - class pattern recognition problems and is known for its good performance .SVM is used for many types of natural language processing ( e.g. text classification and named entity recognition ) .", "label": "", "metadata": {}, "score": "61.44245"}
{"text": "( ii )Compacting the variable length words ( W ) supplied by the coder ( C ) into constant length ( M ) packets ( P ) and subsequent parallel buffering , referred to as \" parallel mode \" ( see FIG .", "label": "", "metadata": {}, "score": "61.52488"}
{"text": "You can add a full alphabet conversion and other rules for conversion of special letter sequences .html / Phonetic - Code . html .Note : Multibyte UTF-8 characters have .not worked with bracket expression yet .Dash expression has . signed bytes and not UTF-8 characters yet .", "label": "", "metadata": {}, "score": "61.568672"}
{"text": "Note II : Use makealias utility in Hunspell distribution to compress aff and dic files .AM number_of_morphological_aliases AM morphological_fields Hunspell can substitute also morphological data with ordinal numbers in affix rules ( alias compression ) .OPTIONS FOR SUGGESTION .Suggestion parameters can optimize the default n - gram , character swap and deletion suggestions of Hunspell .", "label": "", "metadata": {}, "score": "61.60192"}
{"text": "M . m .h .m .s .I . t .J .d .K . )I is a normalization constant and where at least one of the feature functions h m is selected from : .( 1 ) a \" bi - fragment \" feature h bf , of the general form : . h . bf .", "label": "", "metadata": {}, "score": "61.628857"}
{"text": "The non - transitory computer readable medium of . claim 15 , wherein said identifying comprises identifying word pairs having a minimum longest common subsequence ratio .The non - transitory computer readable medium of . claim 15 , wherein said one or more clues includes similar context .", "label": "", "metadata": {}, "score": "61.711998"}
{"text": "\" I then used a Cluster Map to plot my issuecrawl result as a spring map . \"\" I call my diagrams Directed Sentence Drawings because the direction of the line segments are a function of their topic .As before , each sentence is assigned a topic or remains neutral based on the vocabulary it contains .", "label": "", "metadata": {}, "score": "61.805946"}
{"text": "Where a decision results in consumption of a buffered word , the sequence remains in the same stack .Provided that this new hypothesis is not pruned , it is reconsidered in that stack .Eventually , one or more of the stacks may reach or exceed its maximum beam size and is culled by eliminating hypotheses which are statistically less favored to bring the number of hypotheses to the maximum permitted by the beam .", "label": "", "metadata": {}, "score": "61.82808"}
{"text": "In non - UTF-8 character . encodings Hunspell works with the original 8-bit strings .In UTF-8 . encoding , affixes and words are stored in UTF-8 , during the analysis . are handled in mostly UTF-8 , under condition checking and suggestion . are converted to UTF-16 .", "label": "", "metadata": {}, "score": "61.863964"}
{"text": "6 is a Generalized Suffix Tree ( GST ) .FIG .7 is a Bilingual Suffix Tree ( BST ) .FIG .8 is a portion of a BST showing example alignments .FIG .9 are portions of a BST describing left and right alignments .", "label": "", "metadata": {}, "score": "61.989395"}
{"text": "A difference is labeled statistically significant when the p - value is less than 0.05 on the Wilcoxon signed - ranks sum test ( two - sided ) .Table 7 shows the effects of tuning the parameters on precision , recall , and the balanced f - score .", "label": "", "metadata": {}, "score": "62.05774"}
{"text": "2 : .A \" bi - fragment \" feature h bf , illustrated at 32 .It represents the probability of producing t 1 J using some set of bi - fragments , under the assumption that each source fragment produces a target fragment independently of the others : . h . bf .", "label": "", "metadata": {}, "score": "62.0819"}
{"text": "For German to English , this includes replacing the letters k and z by c and changing the ending -t\u00e4t to -ty .Both these rules can be observed in the word pair Elektrizitat and electricity .The lexicon builder 125 may utilize these rules to expand the seed lexicon .", "label": "", "metadata": {}, "score": "62.11734"}
{"text": "this character set contrary to the fact that it is not only the . official symbol to delimit parenthetic clauses in the language , but it . can be in compound words as a special \u00e2\u20ac \u2122 big\u00e2\u20ac \u2122 hyphen .MySpell has got some 8-bit encoding tables , but there are languages .", "label": "", "metadata": {}, "score": "62.16417"}
{"text": "There are four features : gene name dictionary match for the uni - gram ( 1 ) , and protein name dictionary match for the uni - gram ( 2 ) , bi - gram ( 3 ) and tri - gram ( 4 ) .", "label": "", "metadata": {}, "score": "62.24674"}
{"text": "Decoding , as this procedure is called , is done by expanding a search graph on the fly .Each node H in the graph is uniquely defined by the sequence of decisions d 1 k that connect it to an initial \" null hypothesis \" node H 0 ( a starting hypothesis in which there are no words translated ) .", "label": "", "metadata": {}, "score": "62.414017"}
{"text": "For each position , the tokens are compared in frequency and the frequency count is replaced by the frequency rank , e.g. , the most frequent token count is replaced with 1 and the least frequent by n. R . a .b . ) a .", "label": "", "metadata": {}, "score": "62.526836"}
{"text": "BREAK number_of_break_definitions BREAK character_or_character_sequence Define break points for breaking words and checking word parts separately .Rationale : useful for compounding with joining character or strings ( for example , hyphen in English and German or hyphen and n - dash in Hungarian ) .", "label": "", "metadata": {}, "score": "62.55694"}
{"text": "is : plur Test file : works Test : $ hunspell -d test -m .Prefix -- suffix dependencies .An interesting side - effect of multi - step stripping is , that the appropriate treatment of circumfixes now comes for free .For instance , in Hungarian , superlatives are formed by simultaneous prefixation of leg- and suffixation of -bb to the adjective base .", "label": "", "metadata": {}, "score": "62.589172"}
{"text": "Halgrim S , Xia F , Solti I , Cadag E , Uzuner \u00d6 : Statistical extraction of medication information from clinical records .Proceedings of AMIA Summit on Translational Bioinformatics 2010 , 10 - 12 .Halgrim S , Xia F , Solti I , Cadag E , Uzuner \u00d6 : A cascade of classifiers for extracting medication information from discharge summaries .", "label": "", "metadata": {}, "score": "62.59076"}
{"text": "In this project , we used the 145 notes from the Sydney training data to customize the MedEx system .The changes were 1 ) adding new phrases for NEs from the Sydney training data into MedEx 's dictionary , and 2 ) extending the post - processing program used in the 2009 i2b2 challenge .", "label": "", "metadata": {}, "score": "62.745934"}
{"text": "Experiments were run in a Linux machine with 4 GB RAM and 4 cores of Intel Xeon 2.0GHz .Results for the first setting : 10-fold cross - validation .First , we evaluated the effectiveness of the features as well as their combinations .", "label": "", "metadata": {}, "score": "62.823788"}
{"text": "A buffer 46 , illustrated herein as located in volatile memory 30 , stores unconsumed portion(s ) of a target phrase in a partial translation .FIG .3 illustrates steps in an exemplary method for translation of text comprising non - contiguous bi - fragments .", "label": "", "metadata": {}, "score": "62.826424"}
{"text": "A difference is labeled statistically significant when the p - value is less than 0.05 on the Wilcoxon signed - ranks sum test ( two - sided ) .Effect of trained POS tagger on biomedical literature .POS(A ) means the original , newswire trained POS tagger .", "label": "", "metadata": {}, "score": "62.83738"}
{"text": "The darker the word , the more often it appears in the first position .DefiningpatternsMatching different patterns gives different views of the text .Each text is unique , so it is worth experimenting .Sometimes there is a special pattern that will provide information on a particular document .", "label": "", "metadata": {}, "score": "62.87603"}
{"text": "In determining whether to add a feature , consideration should be given to balancing the modeling precision gained by adding new features with the increase in the size of the evaluation set on which the weights of the features are trained .In current log - linear ( maxent )", "label": "", "metadata": {}, "score": "62.942696"}
{"text": "BUG : UTF-8 flag type doesn\u00e2\u20ac \u2122 t work on ARM platform .COMPLEXPREFIXES Set twofold prefix stripping ( but single suffix stripping ) for agglutinative languages with right - to - left writing system .LANG langcode Set language code .In Hunspell may be language specific codes enabled by LANG code .", "label": "", "metadata": {}, "score": "63.013237"}
{"text": "FIG .8 shows some alignments we can extract from the BST in .FIG .7 , a portion of which is shown in .FIG .8 .As can be seen in .For alignment extraction , we are interested in edges of the third type , because they mark ends of alignments .", "label": "", "metadata": {}, "score": "63.098274"}
{"text": "Such a distribution favors small gaps over large gaps .Another aspect of the modeling of the gap distribution may include the handling of outliers .Outliers are gap sizes for which an unusually large or unusually small number of instances are observed in the training corpus .", "label": "", "metadata": {}, "score": "63.130478"}
{"text": "The vast majority of methods available for sequence comparison rely on a first sequence alignment step , which requires a number of assumptions on evolutionary history and is sometimes very difficult or impossible to perform due to the abundance of gaps ( insertions / deletions ) .", "label": "", "metadata": {}, "score": "63.16133"}
{"text": "Each of the k gaps allows one word from another phrase to be inserted between two of the words of the elastic phrase .Similarly each target phrase includes l gaps and l+1 components .Both k and l can independently assume a positive natural number , including 0 , such as 0 , 1 , 2 , 3 , 4 , 5 etc .", "label": "", "metadata": {}, "score": "63.18209"}
{"text": "If that pattern of distance is relatively predictable then we have evidence for a collocation of variable phrases like cement ... relations .Hypothesis Testing .Hypothesis testing is used to check whether two words co - occur more often than a chance .", "label": "", "metadata": {}, "score": "63.217148"}
{"text": "Each binary classifier has one vote and the final output is the class with the maximum number of votes .These parameters have been used in many biomedical NER tasks such as [ 3 , 5 , 7 ] .Conditional random field .", "label": "", "metadata": {}, "score": "63.242065"}
{"text": "COMPOUNDLAST flag .Words signed with COMPOUNDLAST ( or with a signed affix ) may be .last elements in compound words .COMPOUNDMIDDLE flag .Words signed with COMPOUNDMIDDLE ( or with a signed affix ) may be .middle elements in compound words .", "label": "", "metadata": {}, "score": "63.259342"}
{"text": "Exploratoryvisualizations typically do n't havean already - known story .Affiliated with .Affiliated with .Affiliated with .Abstract .Background .Automated information extraction from biomedical literature is important because a vast amount of biomedical literature has been published .Recognition of the biomedical named entities is the first step in information extraction .", "label": "", "metadata": {}, "score": "63.267365"}
{"text": "Each of the clues provides a matching score between two words ( block 220 ) , e.g. , a German word and an English word .The likelihood of these two words being actual translations of each other may correlate to these scores .", "label": "", "metadata": {}, "score": "63.294735"}
{"text": "For example , whenever buffer ( B ) becomes too full , the feedback forces source ( S ) to decrease the bit rate of the messages ( Me ) , hence the source signal quality .( 5 )The dotted block , referred to as \" coder / buffer interface \" , functions to change the incoming information format to the buffer ( B ) dimensions .", "label": "", "metadata": {}, "score": "63.32267"}
{"text": "Additional constraints can be imposed to reduce the search - space .Here are some examples : .A limit may be placed on the number of gaps in any partial translation t(H ) .Note that a constraint which imposes that partial translation t(H ) may not contain gaps at all amounts to translating exclusively with contiguous bi - fragments .", "label": "", "metadata": {}, "score": "63.33215"}
{"text": "FIG .1 .In one embodiment , outliers are ignored in determining the distribution .As will be appreciated , this occurs because the alignments are constructed , and not directly observed .In such cases , it may be appropriate to discard the few suspect instances and force the distribution to have mean 0 .", "label": "", "metadata": {}, "score": "63.361115"}
{"text": "[ 7 ] could not be tested because it has not been made available ) .These last two algorithms must be tested in increasingly longer windows until a conserved correlation matrix is obtained .Our approach was designed to be run in Windows x32 operative system but it was also tested in a Linux platform in order to be compared to the alternative methodology under the same operative system .", "label": "", "metadata": {}, "score": "63.422733"}
{"text": "See germancompounding example in the tests directory of the Hunspell distribution .LEMMA_PRESENT flag Not used in Hunspell 1.2 .Use \" st : \" field instead of LEMMA_PRESENT .NEEDAFFIX flag This flag signs virtual stems in the dictionary .Only affixed forms of these words will be accepted by Hunspell .", "label": "", "metadata": {}, "score": "63.429935"}
{"text": "Combining this with the Table 8 results suggests that the features ' effects usually overlapped with each other when the features were combined .Takeuchi et al .[ 10 ] reached to the same conclusion from their results .As noted above , Tsuruoka et al .", "label": "", "metadata": {}, "score": "63.708633"}
{"text": "Steps S 112 A , 112 B , 112 C , 112 D , 112 E may be repeated multiple times in the process of generating a target language text string .The target language text string corresponding to the highest scoring complete hypothesis is then output at Step S 114 .", "label": "", "metadata": {}, "score": "63.723145"}
{"text": "Function Distance described in Supplementary Material automates this procedure .Software .The algorithm was written in Python , version 2.5.2 , and tested on a Windows 7 x32 system and on a Linux platform with a processor Intel ( R ) Pentium ( R )", "label": "", "metadata": {}, "score": "63.782333"}
{"text": "8-bit character and the UTF-8 FLAG types .Note II : COMPOUNDRULE flags haven\u00e2\u20ac \u2122 t been compatible with the .COMPOUNDFLAG , COMPOUNDBEGIN , etc . compound flags yet ( use these .flags on different words ) .COMPOUNDMIN num .", "label": "", "metadata": {}, "score": "63.8963"}
{"text": "The translations may be produced by means of a beam - search decoder or other suitable optimizing function which takes into account the probabilities of various hypothetical translations being found in practice .The exemplary translation method translates natural language text , such as French to English , using as primary resource a collection of bi - fragments , i.e. , matching pairs of source - target fragments of text .", "label": "", "metadata": {}, "score": "63.928276"}
{"text": "The Hansard Corpus includes parallel texts in English and Canadian French , drawn from official records of the proceedings of the Canadian Parliament .A small bilingual lexicon of 6,900 entries was built using 5,000 sentences pairs ( 150,000 words for each language ) .", "label": "", "metadata": {}, "score": "64.04532"}
{"text": "These packets must be prepared by an appropriate word compacting ( WC ) circuit , which , in order to operate correctly , should know the word length ( WL ) of the incoming words to be compacted .This information may be supplied directly by the coder ( C ) in parallel with the words .", "label": "", "metadata": {}, "score": "64.129944"}
{"text": "Compounds form a bridge between collocations and idioms as they are quite invariable but need not be semantically opaque .Flexible Word Pairs : Flexible word pairs include collocations between subject and verb , or verb and object .Any number of intervening words may occur between the words of the collocation .", "label": "", "metadata": {}, "score": "64.190674"}
{"text": "Such a decision produces a new state , which is placed on its proper stack , at a position determined by its heuristic cost , which can be an optimistic estimate of the best complete sequence of decisions passing through this state .In the decoder of Cancedda , et al .", "label": "", "metadata": {}, "score": "64.24991"}
{"text": "Other features are optionally included that calibrate certain dependencies between gap sizes ignored by the simple model of equation ( 6 ) .For example , a feature computing the ratio of the sum of gap sizes on the target side to the sum of gap sizes on the source side .", "label": "", "metadata": {}, "score": "64.28827"}
{"text": "Bookworm uses that information to let you search for trends in any corpus you can create out of the library metadata , and to link to the underlying books so you can read them . \"Reports with similar key words have edges drawn between them .", "label": "", "metadata": {}, "score": "64.43465"}
{"text": "Note : COMPOUNDRULE is better ( or will be better ) for handling dashes . and other compound joining characters or character strings .Use BREAK , .if you want check words with dashes or other joining characters and .there is no time or possibility to describe precise compound rules with .", "label": "", "metadata": {}, "score": "64.47273"}
{"text": "Three training sessions were done in a pair - wise fashion , i.e. ( B vs. I ) , ( B vs. O ) , and ( I vs. O ) , and three hyperplanes were formed .In the test data , the optimal class of each token was the class that had the maximum value in the three hyperplane functions .", "label": "", "metadata": {}, "score": "64.53645"}
{"text": "Given a set of training samples , the SVM training phase tries to find the optimal hyperplane , which maximizes the distance of the training samples nearest to it ( called support vectors ) .SVM takes as input a vector and maps it into a feature space using a kernel function [ 18 , 19 ] .", "label": "", "metadata": {}, "score": "64.58181"}
{"text": "The c -value controls the tradeoff between errors of the SVM on training data and margin maximization .10-fold cross - validation was implemented as follows .All 268 discharge summaries were randomly divided into ten subsets of almost equal size .", "label": "", "metadata": {}, "score": "64.79745"}
{"text": "For the sake of comparison , the results from the Sydney team , the customized MedEx , the single classifiers based on SVMs and CRFs , and the three combination methods are shown in Table 7 .We also present the results of statistical significance tests for differences in performance between the methods in Table 8 .", "label": "", "metadata": {}, "score": "64.80464"}
{"text": "The \" one - vs .-rest \" method was used for solving multi - class problems .The parenthesized values are the p - values .The values in bold font have a statistically significant difference from the base value .A difference is labeled statistically significant when the p - value is less than 0.05 on the Wilcoxon signed - ranks sum test ( two - sided ) .", "label": "", "metadata": {}, "score": "64.82959"}
{"text": "For example , using COMPOUNDWORDMAX , COMPOUNDSYLLABLE , .COMPOUNDROOT , SYLLABLENUM options can be set the noteworthy Hungarian . \u00e2\u20ac\u02dc6 - 3\u00e2\u20ac \u2122 rule .Further example in Hungarian , derivate suffixes often . modify compounding properties .Hunspell allows the compounding flags on .", "label": "", "metadata": {}, "score": "64.9825"}
{"text": "is : past_1 SFX D 0 ed .is : past_2 Typical example of the terminal suffix is the zero morpheme of the nominative case . sp : Surface prefix .Temporary solution for adding prefixes to the stems and generated word forms .", "label": "", "metadata": {}, "score": "65.083084"}
{"text": "The experiments were run on a Linux \u00ae system 400 with an Intel \u00ae Pentium \u00ae 3 processor of 866 Mhz .A number of embodiments have been described .Nevertheless , it will be understood that various modifications may be made without departing from the spirit and scope of the invention .", "label": "", "metadata": {}, "score": "65.098656"}
{"text": "gaps .s .I . t .J .d .K . )i .I .gapCount .b .d .i . ) where gapCount(b ) counts the number of gaps in the source and target fragments of b. .", "label": "", "metadata": {}, "score": "65.18419"}
{"text": "Morphological generation depends on the order of the suffix fields . feet st : foot is : plural ts : Terminal suffix(es ) .Terminal suffix fields are inflectional suffix fields \" removed \" by additional ( not terminal ) suffixes .Useful for zero morphemes and affixes removed by splitting rules .", "label": "", "metadata": {}, "score": "65.203156"}
{"text": "When your classification model has hundreds or thousands of features , as is the case for text categorization , it 's a good bet that many ( if not most ) of the features are low information .These are features that are common across all classes , and therefore contribute little information to the classification process .", "label": "", "metadata": {}, "score": "65.25541"}
{"text": "# compound flags .COMPOUNDBEGIN U .COMPOUNDMIDDLE V .COMPOUNDEND W .# Prefixes are allowed at the beginning of compounds , .# suffixes are allowed at the end of compounds by default : . # ( prefix ) ?( root)+(affix ) ? # Affixes with COMPOUNDPERMITFLAG may be inside of compounds .", "label": "", "metadata": {}, "score": "65.42644"}
{"text": "A.Kempe , J.M.Champarnaud , J.Eisner , A Note on Join and Auto - Intersection of n - ary Rational Relations , In B. Watson and L. Cleophas , editors , Proceedings Eindhoven FASTAR Days , No . 04- 40 in TU / e CS TR , pp .", "label": "", "metadata": {}, "score": "65.603935"}
{"text": "251 notes were randomly picked by the organizers as the test data set and were annotated by participating teams , as well as the organizers , and they served as the gold standard for evaluating the performance of systems [ 9 , 15 ] .", "label": "", "metadata": {}, "score": "65.69614"}
{"text": "A \" non - contiguous phrase \" refers to two or more words in either the source or target language wherein two of the words are separated by a gap of at least one word .Each non - contiguous phrase includes a first portion comprising at least one word , which is separated from a second portion , comprising at least one word , by a gap of at least one word .", "label": "", "metadata": {}, "score": "65.73448"}
{"text": "If such branch does not exist , we conclude that w does not occur in the data set .Otherwise , we must always skip from a node to its descendant until the end of w .The indexes of all descendant leafs from the last node reached , or from its descendant nodes , are used to determine the sequences in the data set which contain w as well as the number of occurrences of w in each sequence .", "label": "", "metadata": {}, "score": "65.7697"}
{"text": "x i is the feature vector of the i - th sample and has a dimension of n .k is the total number of vectors .The y i is the class of the vector ; it is either a positive example ( +1 ) or negative example ( -1 ) .", "label": "", "metadata": {}, "score": "65.81961"}
{"text": "As a consequence of utilizing the above - described code with the above - described hardware , a dramatic increase in operating speed is obtained .BRIEF DESCRIPTION OF THE DRAWINGS .These and other features and advantages of the invention will become apparent when the following text is read in conjunction with the accompanying drawings , in which : .", "label": "", "metadata": {}, "score": "65.98741"}
{"text": "The problems raised in relation to 8-bit ASCII encoding have long been .recognized by proponents of Unicode .It is clear that trading .efficiency for encoding - independence has its advantages when it comes a . truly multi - lingual application .", "label": "", "metadata": {}, "score": "66.02644"}
{"text": "But the differences may depend on your particular data , so do n't assume these observations are always true .Improving Feature Selection .The big lesson here is that improving feature selection will improve your classifier .Reducing dimensionality is one of the single best things you can do to improve classifier performance .", "label": "", "metadata": {}, "score": "66.23291"}
{"text": "claim 3 , wherein the generation of a hypothesis includes expanding an existing partial hypothesis by at least one of : . adding a word of a new text fragment to the sequence of words ; and . retrieving an unconsumed word from the buffer to the sequence of words .", "label": "", "metadata": {}, "score": "66.29695"}
{"text": "NEEDAFFIX works also with prefixes and prefix + suffix combinations ( see tests / pseudoroot5 .PSEUDOROOT flag Deprecated .( Former name of the NEEDAFFIX option . )SUBSTANDARD flag SUBSTANDARD flag signs affix rules and dictionary words ( allomorphs ) not used in morphological generation ( and in suggestion in the future versions ) .", "label": "", "metadata": {}, "score": "66.368355"}
{"text": "Dictionary file : drink / X Test file : drink drinkable drinkables Test : $ hunspell -m -d test .Extended affix classes .Hunspell can handle more than 65000 affix classes .There are three new syntax for giving flags in affix and dictionary files .", "label": "", "metadata": {}, "score": "66.46965"}
{"text": "( i ) Parallel - to - serial conversion ( P / S ) and subsequent serial buffering of the variable length words ( W ) supplied by the coder ( C ) , referred to as \" serial mode \" ( See FIG .", "label": "", "metadata": {}, "score": "66.47095"}
{"text": "Semantic Collocations : They are lexically restricted word pairs , for which only a subset of the synonym of the collocator can be used in the same lexical context .Collocations are also categorized into compounds and flexible word pairs .Compounds : Compounds include word pairs that occur consecutively in language and typically are immutable in function .", "label": "", "metadata": {}, "score": "66.53586"}
{"text": "FLAG long .SFX Y1 Y 1 .SFX Y1 0 s 1 .Dictionary record with the Y1 , Z3 , F ? flags : . foo / Y1Z3F ?FLAG num command sets numerical flags separated by comma : .FLAG num .", "label": "", "metadata": {}, "score": "66.70505"}
{"text": "After you specify a pattern , the program creates a network diagram of the words it finds as matches .Two words are connected if they occur in the same phrase .The size of a word is proportional to the number of times it occurs in a match ; the thickness of an arrow between words tells you how many times those two words occur in the same phrase .", "label": "", "metadata": {}, "score": "66.83747"}
{"text": "There is a growing interest in genome research , and a vast amount of biomedical literature related to it has been published .Collecting and maintaining various databases of this information in computer accessible format require automatically extracting information .Various automated information extraction systems for biomedical literature have been reported .", "label": "", "metadata": {}, "score": "66.84088"}
{"text": "Many eyes phrase net\"Phrase net analyzes a text by looking for pairs of words that fit particular patterns .You can specify this pattern by using asterisks as wildcard characters .\" Punctuation matters , so it will not match \" left , and then \" .", "label": "", "metadata": {}, "score": "66.92548"}
{"text": "P . k . ) k . k . which is fully determined by a single parameter of the distribution , its mean \u03bc , as illustrated in .FIG .1 .In this way , gap sizes for which no observed examples are found in the corpus may nevertheless be assigned a non - zero probability of being found in a translation .", "label": "", "metadata": {}, "score": "66.93473"}
{"text": "The method proved to be efficient and powerful when applied to complete mitochondrial genomes , either from different species or intraspecifically , being able to quickly cluster the sequences in accordance to acknowledged phylogenetic relationships .Authors ' Contribution . I. Soares developed the algorithm , performed the tests , and wrote the paper . A. Goios participated in the design of the study and wrote the paper . A. Amorim conceived the study , and participated in its design and coordination and wrote the paper .", "label": "", "metadata": {}, "score": "67.009224"}
{"text": "The orthographic feature is Greek .The prefix features are N , NF , and NF- .The suffix features are B , aB , and paB. The value for uni - gram ( NF - kappaB ) matching with the protein name dictionary is Y. The value for bi - gram ( NF - kappaB transcription ) matching is N. The value for tri - gram ( NF - kappaB transcription factor ) matching is N. The value for uni - gram ( NF - kappaB ) matching with the gene name dictionary is N. The preceding class features are \" O \" for \" the \" ( preceding first ) and \" O \" for \" of \" ( preceding second ) .", "label": "", "metadata": {}, "score": "67.10475"}
{"text": "The machine translation system of .claim 18 , wherein the second feature function counts gaps in the target text of the hypothesis and corresponding source text .The machine translation system of . claim 17 , wherein the library associates each of a plurality of elastic bi - fragments with a corresponding parameter representative of a probability distribution of gaps in at least one of the source text fragment and the target text fragment .", "label": "", "metadata": {}, "score": "67.117516"}
{"text": "Church and Hanks made use of mutual information ( MI ) to evaluate the correlation between a pair of words .They take a window size of five words for co - occurrence and conduct experiments based on a corpus .They were able to extract interesting pairs of related words such as doctors and nurses doctors and treating .", "label": "", "metadata": {}, "score": "67.17323"}
{"text": "And it 's especially recommended when that data is actually making your model worse .Abstract .Background .Extraction of clinical information such as medications or problems from clinical text is an important task of clinical natural language processing ( NLP ) .", "label": "", "metadata": {}, "score": "67.21849"}
{"text": "BRIEF DESCRIPTION .Aspects of the exemplary embodiment relate to a machine translation method and system for machine translation .In one aspect , a machine translation method is provided for translating source text from a first language to target text in a second language .", "label": "", "metadata": {}, "score": "67.30585"}
{"text": "( 3 ) e 1 is already in the sequence but e 2 is still in the buffer .In this case , the minimum size m of the gap between e 1 and e 2 is known ( namely , the number of words in the sequence which are to the right of e 1 .", "label": "", "metadata": {}, "score": "67.37892"}
{"text": "Translated strings of text and the entire text , once translated , may be stored in volatile or non - volatile memory 30 .Alternatively , the processing component 16 accesses a remote database which stores the bi - fragment library , for example , via the internet or via a network link .", "label": "", "metadata": {}, "score": "67.41489"}
{"text": "More recently , the i2b2 organizers used a maximum entropy ( ME ) model on the same training data as the Sydney team and reported that their results were comparable to the top systems in the challenge [ 12 , 13 ] .Table 1 .", "label": "", "metadata": {}, "score": "67.41911"}
{"text": "Due to cultural exchange , a large number of words that originate in one language may be adopted by others .Recently , this phenomenon can be seen with words such as \" Internet U or \" Aids u. \" These terms may be adopted verbatim or changed by well - established rules .", "label": "", "metadata": {}, "score": "67.461334"}
{"text": "The different types of information were called fields and are described in Table 1 .Note that fields might include phrases without noun phrases such as \" as long as needed \" or \" until the symptom disappears \" .The challenge asked that participating systems be used to extract the text corresponding to each of the fields for each medication mention .", "label": "", "metadata": {}, "score": "67.51225"}
{"text": "As mentioned in the Background section , the corpus includes six types of fields , i.e. , medication , dosage , mode , frequency , duration , and reason .The number of fields and descriptions of the corpus are shown in Table 1 and statistics summarizing the corpus are shown in Table 3 .", "label": "", "metadata": {}, "score": "67.527466"}
{"text": "The twofold suffix stripping is a significant improvement in handling of immense number of suffixes , that characterize agglutinative languages .A second \u00e2\u20ac\u02dcs\u00e2\u20ac \u2122 suffix ( affix class Y ) will be the continuation class of the suffix \u00e2\u20ac\u02dcable\u00e2\u20ac \u2122 in the following example : SFX Y Y 1 SFX Y 0 s .", "label": "", "metadata": {}, "score": "67.57538"}
{"text": "8c ) .The VALID DATA output bit is determined directly by the carry out of the modulus 8 adder updating the EOW counter ; it is used also to decide whether to recirculate the contents of REGQ or not .Through combining rotary ( ROT : FIG . 8b ) , decoding ( FDEC : FIG .", "label": "", "metadata": {}, "score": "67.588585"}
{"text": "s .t . )i . k . log .Poisson .[ . i . ] gs .i . ) j .l . log .Poisson .[ .j . ] gt .j . )This feature estimates the log of the probability of observing certain values of the gap sizes as the sum of the logs of the individual Poisson distributions associated with each gap .", "label": "", "metadata": {}, "score": "67.636185"}
{"text": "The method of .claim 1 , wherein the evaluation of the at least one hypothesis includes selecting a hypothesis from a plurality of hypotheses which maximizes a log - linear scoring function in which weights are assigned to each of the feature functions .", "label": "", "metadata": {}, "score": "67.64821"}
{"text": "Each word . may optionally be followed by a slash ( \" / \" ) and one or more flags , . which represents affixes or special attributes .Dictionary words can . contain also slashes with the \" \" syntax .Default flag format is a . single ( usually alphabetic ) character .", "label": "", "metadata": {}, "score": "67.71191"}
{"text": "Takeuchi K , Collier N : Bio - Medical Entity Extraction using Support Vector Machine .Proceedings of the ACL 2003 Workshop on NLP in Biomedicine 2003 , 57 - 64 .Mitsumori T , Fation S , Murata M , Doi K , Doi H : Boundary Correction of Protein Names Adapting Heuristic Rules .", "label": "", "metadata": {}, "score": "67.714615"}
{"text": "1 st run : Exact pattern matching between GPD1 and words in the training and test data .2 nd run : Regular expression pattern matching between GPD1 and words in the training and test data .We ignored non - alphabetical letters in the strings by using a regular expression in Perl . \" \\W \" matches any character except a letter , numeric digit or \" _ \" .", "label": "", "metadata": {}, "score": "67.73925"}
{"text": "To better achieve a even distribution , I normalized the frequencies of bigrams based on total primary term frequency .So , for example , in the case of war vs. peace , there are 81,839,381 bigrams starting with war and 31,263,375 bigrams starting with peace .", "label": "", "metadata": {}, "score": "67.82392"}
{"text": "The code permits the two operations of extraction and decoding to be separated at the receive end ; this is essential in high speed applications where these operations can not be performed simultaneously within one clock cycle .The code also permits the extraction operation to be simplified by considerably reducing the size of the necessary hardware .", "label": "", "metadata": {}, "score": "67.82774"}
{"text": "Thus , different gap sizes can result in different hypotheses , each one being separately analyzed .For example , the bi - phrase : .As will be appreciated , where there are gaps on both the source and target sides , a substantial number of potential hypotheses may be generated corresponding to different numbers of gaps on both the source and target sides .", "label": "", "metadata": {}, "score": "67.85022"}
{"text": "440 - 447 , XP002279144Hong Kong , China Retrieved from the Internet : retrieved on May 6 , 2004 ! abstract .Gildea , D. , \" Loosely Tree - based Alignment for Machine Translation , \" In Proceedings of the 41st Annual Meeting on Assoc . for Computational Linguistics - vol . 1 ( Sapporo , Japan , Jul. 7 - 12 , 2003 ) .", "label": "", "metadata": {}, "score": "67.85933"}
{"text": "It shows that collocations play a key role in understanding sentences .Collocations are recursive so collocational phrase may contain more than two words .Types of Collocations .Grammatical Collocations : Contain prepositions , including paired syntactic categories , such as verb+preposition ( e.g come to , put on ) , adjective+preposition ( e.g. afraid that , fond of ) , and noun+preposition ( e.g by accident , witness to ) .", "label": "", "metadata": {}, "score": "67.95561"}
{"text": "8a ( and also in FIGS . 9aa and 9ab ) is represented with standard symbols , among which : # # STR1 # # .The general operation of the circuitry is as follows : .The upper part of the circuitry shown in FIG .", "label": "", "metadata": {}, "score": "67.98482"}
{"text": "In the illustrated embodiment , at extension step S 201 , the consumed portion of a target phrase do is highlighted .In the buffer , the non - consumed portion want of the phrase is stored along with the index I 2 , indicating that the last word of the consumed portion of the phrase is in the second position of the sequence .", "label": "", "metadata": {}, "score": "68.07718"}
{"text": "CROSS - REFERENCE TO RELATED APPLICATIONS .This application is a Continuation of U.S. patent application Ser .No .10/401,124 , filed on Mar. 26 , 2003 , now U.S. Pat .No .7,620,538 , which claims priority to U.S. Provisional Application Ser .", "label": "", "metadata": {}, "score": "68.0856"}
{"text": "Where the decoder allows relatively large stacks , it may be reasonable to ignore the problem .However , there are various ways for accounting for the buffer consumption .One alternative is to allow the stack to increase in size , beyond its predetermined maximum number of hypotheses , where a consumption decision would otherwise result in the hypothesis being expelled from the stack .", "label": "", "metadata": {}, "score": "68.131584"}
{"text": "Hunspell source distribution contains more than 80 examples for option usage .SET encoding Set character encoding of words and morphemes in affix and dictionary files .Possible values : UTF-8 , ISO8859 - 1 - ISO8859 - 10 , ISO8859 - 13 - ISO8859 - 15 , KOI8-R , KOI8-U , microsoft- cp1251 , ISCII - DEVANAGARI .", "label": "", "metadata": {}, "score": "68.42512"}
{"text": "Table 5 .NS means \" not significant different \" .Among the six NE fields , duration and reason proved to be the most difficult , with F - scores not exceeding 69 % and 58 % respectively by all experimented methods .", "label": "", "metadata": {}, "score": "68.45513"}
{"text": "The effects of each feature on our system are shown in Tables 8 and 9 .The parameters are shown in Table 4 .The definition of \" base \" is the same as in Table 7 .In Table 8 , we demonstrate the ability of SVM learning to be mostly unaffected when ignoring one of the features .", "label": "", "metadata": {}, "score": "68.54707"}
{"text": "Of the various types of kernels available , we used a d - th polynomial kernel : .Authors ' Affiliations .Graduate School of Information Science , Nara Institute of Science and Technology .National Institute of Information and Communications Technology .References .", "label": "", "metadata": {}, "score": "68.76764"}
{"text": "For uniformity of the notation here , it is retained .When solving the machine translation problem ( Eqn . 1 ) with this type of model , the value of Z f i . 1 need not be computed explicitly , because it depends only on s 1 I , and so the problem reduces to : . t .", "label": "", "metadata": {}, "score": "68.95949"}
{"text": "The results without dictionary matching are shown as case 2 in Table 5 .The score went up about 2.5 % when dictionary matching was used .Table 5 .Evaluation results .Case 1 is using the dictionary feature .Case 2 is not using the dictionary feature . \" TP \" , \" FP \" , and \" FN \" are the numbers of true - positives , false - positives , and false - negatives .", "label": "", "metadata": {}, "score": "69.20587"}
{"text": "Methods .Data sets .At the beginning of the 2009 i2b2 challenge , a data set of 696 notes was provided by the organizers .In that set , 17 notes were annotated by the i2b2 organizers , based on annotation guidelines ( see Table 1 for examples of medication information provided ) , and the rest were un - annotated .", "label": "", "metadata": {}, "score": "69.3086"}
{"text": "Here 's the full code I used to get these results , with an explanation below .inc(word.lower ( ) ) label_word_fd['pos'].inc(word.lower ( ) ) for word in movie_reviews .inc(word.lower ( ) ) label_word_fd['neg'].Calculating Information Gain .", "label": "", "metadata": {}, "score": "69.31723"}
{"text": "Dizziness , \" \" Dizzy , \" \" Fever , \" \" Diabetes , \" \" frequent PVCs , \" \" rare angina \" .The medical reason for which the medication is stated to be given .From the perspective of supervised machine learning , the medication extraction task in the 2009 i2b2 challenge can be divided into two steps : 1 ) identifying fields , and 2 ) determining the relationships between the detected medication names and the other fields .", "label": "", "metadata": {}, "score": "69.53087"}
{"text": "The values in bold have a statistically significant difference from the base value .A difference is labeled statistically significant when the p - value is less than 0.05 on the Wilcoxon signed - ranks sum test ( two - sided ) .Effect of dictionary matching .", "label": "", "metadata": {}, "score": "69.56993"}
{"text": "This shows that bigrams do n't matter much when using only high information words .In this case , the best way to evaluate the difference between including bigrams or not is to look at precision and recall .With the bigrams , you we get more uniform performance in each class .", "label": "", "metadata": {}, "score": "69.58455"}
{"text": "; \" and .\" It is for this reason that the party has proposed . . . \" .Since \" Ce est pour cette \" can be aligned with \" It is for this \" and \" que le \" with \" that the , \" it is a reasonable assumption that \" raison \" can be translated by \" reason .", "label": "", "metadata": {}, "score": "69.684906"}
{"text": "Information gain for classification is a measure of how common a feature is in a particular class compared to how common it is in all other classes .A word that occurs primarily in positive movie reviews and rarely in negative reviews is high information .", "label": "", "metadata": {}, "score": "69.75806"}
{"text": "4 illustrates this with the example sentence Je ne veux plus danser le tango .In .FIG .4 , words in bold correspond to word of the source sentence which are covered in the decision and words of the target added to the sequence or buffer .", "label": "", "metadata": {}, "score": "69.76616"}
{"text": "4 illustrates the partial coverage of the source sentence Je ne veux plus danser le tango and the corresponding partial coverage of the target sentence in a series of hypothesis extension steps S 201 , S 202 , S 203 , S 204 , S 206 .", "label": "", "metadata": {}, "score": "70.00112"}
{"text": "Second suffix .can be added to the words terminated with an \u00e2\u20ac\u02dcy\u00e2\u20ac \u2122 .( See later . )The . following dictionary file uses these affix classes .hello . try / B . work / AB .All accepted words with this dictionary : \" hello \" , \" try \" , \" tried \" , . \" work \" , \" worked \" , \" rework \" , \" reworked \" .", "label": "", "metadata": {}, "score": "70.13771"}
{"text": "The circuit providing this kind of processing will be referred to as \" word compacter \" ( WC ) and is , along with its corresponding receiving circuit ( \" word expander WE ) providing the opposite function , the implementing device of the present invention .", "label": "", "metadata": {}, "score": "70.17811"}
{"text": "Our final result in the BioCreAtIvE competition is shown as case 1 in Table 5 .The best \" balanced f - score \" was that for the 2 nd run .The differences between the three runs were less than 1 % .", "label": "", "metadata": {}, "score": "70.18061"}
{"text": "N N .Chief .Executive .A N .next . year .A N . real . estate .A N .Where A stands for adjective , N for noun and P for propositon .Note that the bigrams , last week and last year can not be regarded as non - compositional phrases .", "label": "", "metadata": {}, "score": "70.273056"}
{"text": "With BREAK , Hunspell can check both side of these compounds , breaking the words at dashes and n - dashes : BREAK 2 BREAK - BREAK -- # n - dash .Breaking are recursive , so foo - bar , bar - foo and foo - foo -- bar - bar would .", "label": "", "metadata": {}, "score": "70.524216"}
{"text": "For example , for medication names , we define the B class as \" B - m , \" and the I class as \" I - m . \"Therefore , we have 13 possible labels for each token ( including the O ) .", "label": "", "metadata": {}, "score": "70.629654"}
{"text": "As shown in the example in .FIG .5 , not all of the phrases in the library which include two or more words need to be modeled as elastic bi - phrases , such as the phrases danser le tango and to tango .", "label": "", "metadata": {}, "score": "70.71695"}
{"text": "Statistical Model .Many existing machine translation systems are based on probability models , that assign to any target language sequence t 1 J a probability of being a translation of a source language sequence s 1 I .The general approach in statistical machine translation is to find the most probable translation for s 1 I : . t .", "label": "", "metadata": {}, "score": "70.77409"}
{"text": "A lexicon builder 125 may expand the seed lexicon into the larger translation lexicon 105 by applying rules based on clues which indicate probable translations .The lexicon builder 125 may use seed lexicon to bootstrap these methods , using the word pairs in the seed lexicon as correct translations .", "label": "", "metadata": {}, "score": "70.797844"}
{"text": "To zoom into a particular branch , clicking on a word in the tree .If you control - click on a word , the diagram will use that new word as the main search term .And if you wish to see the context occurring before rather than after a phrase , select End .", "label": "", "metadata": {}, "score": "70.91717"}
{"text": "The best balanced f - score was the case where all features were used .This suggests that the effect of each feature was small when the features were combined .Kudo et al .[14 ] suggested that an SVM has a high generalization performance independent of the dimension of the feature vectors .", "label": "", "metadata": {}, "score": "71.010025"}
{"text": "Competing interests .The authors declare that they have no competing interests .Authors ' contributions .SD , XH , and TMP developed the idea for this study .The project was supervised by XH , TMP , and NC .SD designed and carried out the experiments .", "label": "", "metadata": {}, "score": "71.03066"}
{"text": "Gildea , D. , \" Loosely Tree - based Alignment for Machine Translation , \" In Proceedings of the 41st Annual Meeting on Assoc . for Computational Linguistics - vol . 1 ( Sapporo , Japan , Jul. 7 - 12 , 2003 ) .", "label": "", "metadata": {}, "score": "71.08194"}
{"text": "COMPOUNDMIN 1 .WORDCHARS - .# compound settings and fogemorpheme for \u00e2\u20ac\u02dcArbeit\u00e2\u20ac \u2122 .SFX A Y 3 .SFX A 0 s / UPX .SFX A 0 s / VPDX .SFX A 0 0/WXD .SFX B Y 2 .", "label": "", "metadata": {}, "score": "71.15013"}
{"text": "Dash hasn\u00e2\u20ac \u2122 t got special meaning , but circumflex ( ^ ) next the first brace sets the complementer character set . )( 5 ) Optional morphological fields separated by spaces or tabulators .OTHER OPTIONS .CIRCUMFIX flag Affixes signed with CIRCUMFIX flag may be on a word when this word also has a prefix with CIRCUMFIX flag and vice versa .", "label": "", "metadata": {}, "score": "71.37955"}
{"text": "The memory component stores a library of bi - fragments 20 , including non - contiguous bi - fragments .The processing component 16 executes instructions for performing the method of .FIG .3 , which may be stored in an article of manufacture comprising a program storage medium readable by a computer comprising instructions for executing the method , such as memory 18 .", "label": "", "metadata": {}, "score": "71.498795"}
{"text": "Results for the second setting : The 2009 i2b2 challenge with Sydney training data .In order to compare our results to the first - ranked system ( the Sydney team from the 2009 i2b2 challenge ) , we used the same training dataset from their system and applied it to the standard test set .", "label": "", "metadata": {}, "score": "71.535095"}
{"text": "The statistical models may be trained on parallel corpora .Parallel corpora contain large amounts of text in one language along with their translation in another .Unfortunately , such corpora are available only in limited amounts and cover only in specific genres ( Canadian politics , Hong Kong laws , etc ) .", "label": "", "metadata": {}, "score": "71.544495"}
{"text": "SFX 65000 0 s 1 .Dictionary example : . foo/65000,12,2756 .The third one is the Unicode character flags .Homonyms .Hunspell\u00e2\u20ac \u2122 s dictionary can contain repeating elements that are homonyms : work / A po : verb work / B po : noun An affix file : SFX A Y 1 SFX A 0 s .", "label": "", "metadata": {}, "score": "71.641815"}
{"text": "Association for Computational Linguistics .Franz Josef Och , Hermann Ney : \" Improved Statistical Alignment Models \" ACLOO :Proc . abstract .Franz Josef Och , Hermann Ney : \" Improved Statistical Alignment Models \" ACLOO :Proc . of the 38th Annual Meeting of the Association for Computational Lingustics , ' Online !", "label": "", "metadata": {}, "score": "71.64606"}
{"text": "Proposed flag for vulgar and obscene words ( see also SUBSTANDARD ) .MAXNGRAMSUGS num Set number of n - gram suggestions .Value 0 switches off the n- gram suggestions .NOSPLITSUGS Disable split - word suggestions .SUGSWITHDOTS Add dot(s ) to suggestions , if input word terminates in dot(s ) .", "label": "", "metadata": {}, "score": "71.66818"}
{"text": "NS means \" not significant different \" .As in the first experimental setting , customized MedEx was behind the machine learning and ensemble systems and received the lowest overall F - score of 87.17 % ( column \" All \" in table 7 ) .", "label": "", "metadata": {}, "score": "71.72818"}
{"text": "Dimension of polynomial kernel ( natural number ) : We can use only a polynomial kernel in YamCha .Range of window ( integer ) : The SVM can use the information on tokens surrounding the token of interest as illustrated in Figure 2 .", "label": "", "metadata": {}, "score": "71.79899"}
{"text": "]The only exception to this rule is for words having the maximum code length .Any word length will be a multiple of the step length ST . .The device for implementing this special code has , at the transmission end , a \" word compacter \" ( WC ) inserted as an interface between a coder ( C ) and a buffer ( B ) .", "label": "", "metadata": {}, "score": "72.06981"}
{"text": "The sequences are not yet represented in the SWISS - PROT database .The TrEMBL database also contains protein sequences extracted from the literature and protein sequences submitted directly by the user community .We collected 96,195 protein names and 115,663 gene names from the SWISS - PROT database and 76,596 protein names and 31,414 gene names from the TrEMBL database .", "label": "", "metadata": {}, "score": "72.23651"}
{"text": "Assoc . for Computational Linguistics , Morristown , NJ .Collocation or lexical collocation means two or more words co - occur in a sentence more frequently than by chance .A collocation is an expression that forms a specific meaning .It may be noun phrase like large house , verbal phrase like pick up , idioms , cliches or technical terms .", "label": "", "metadata": {}, "score": "72.25634"}
{"text": "CHECKCOMPOUNDPATTERN number_of_checkcompoundpattern_definitions .CHECKCOMPOUNDPATTERN endchars beginchars .Forbid compounding , if first word in compound ends with . endchars , and next word begins with beginchars .COMPOUNDSYLLABLE max_syllable vowels .Need for special compounding rules in Hungarian .First . parameter is the maximum syllable number , that may be in a . compound , if words in compounds are more than COMPOUNDWORDMAX .", "label": "", "metadata": {}, "score": "72.326866"}
{"text": "76 names overlapped between the training data and FP of the test data , which was 8.1 % of the names in the FP data .50 names overlapped between the TP and FP of the test data , which was 5.3 % of the names in the FP data .", "label": "", "metadata": {}, "score": "72.46056"}
{"text": "Default value is 3 . letters .COMPOUNDFLAG flag .Words signed with COMPOUNDFLAG may be in compound words ( except .when word shorter than COMPOUNDMIN ) .Affixes with COMPOUNDFLAG . also permits compounding of affixed words .COMPOUNDBEGIN flag .Words signed with COMPOUNDBEGIN ( or with a signed affix ) may be .", "label": "", "metadata": {}, "score": "72.50546"}
{"text": "An example is the following : \" translocation / NN of / IN the / DT NF - kappaB / NEWGENE transcription / NEWGENE factor / NEWGENE,/ , \" , where NN is a noun or singular mass , IN is a preposition or subordinating conjunction , and DT is a determiner .", "label": "", "metadata": {}, "score": "72.51779"}
{"text": "For example , a lot of African .languages have non - latin or extended latin characters .Similarly , using the original spelling of certain foreign names like \u00c3 \u0192 ngstr\u00c3 \u0192 \u00c2 \u00b6 m or Moli\u00c3 \u0192 \u00c2 \u00a8 re is encouraged by the Hungarian spelling norm , . and , since characters \u00e2\u20ac \u2122 \u00c3\u0192\u00e2\u20ac \u2122 and \u00e2\u20ac \u2122 \u00c3\u0192\u00c2\u00a8\u00e2\u20ac \u2122 are not part of ISO 8859 - 2 , when .", "label": "", "metadata": {}, "score": "72.59395"}
{"text": "PubMed View Article .Xu H , Stenner SP , Doan S , Johnson KB , Waitman LR , Denny JC : MedEx : a medication information extraction system for clinical narratives .J Am Med Inform Assoc 2010 , 17 ( 1 ) : 19 - 24 .", "label": "", "metadata": {}, "score": "72.598145"}
{"text": "SFX B 0 ed [ ^y ] .SFX B y ied y .There are two affix classes in the dictionary .Class A defines a \u00e2\u20ac\u02dcre - \u00e2\u20ac \u2122 . prefix .Class B defines two \u00e2\u20ac\u02dc-ed\u00e2\u20ac \u2122 suffixes .First suffix can be added .", "label": "", "metadata": {}, "score": "72.790886"}
{"text": "Affix classes are signed with affix flags .The first line of an affix class definition is the header .The fields of an affix class header : ( 0 ) Option name ( PFX or SFX ) ( 1 ) Flag ( name of the affix class ) ( 2 ) Cross product ( permission to combine prefixes and suffixes ) .", "label": "", "metadata": {}, "score": "72.982285"}
{"text": "The score of majority voting was significantly higher than any single method including the method from the Sydney team , as determined by the statistical tests ( Table 8 ) .When considering each field separately , majority voting consistently outperformed the single methods in recognizing duration and reason .", "label": "", "metadata": {}, "score": "73.00096"}
{"text": "M . m .h .m .s .I . t .J .d .K . ) 1 I is a normalization constant .The h m are thus real - valued features representing different aspects of a translation hypothesis , and the \u03bb m are weights associated with these features .", "label": "", "metadata": {}, "score": "73.364426"}
{"text": "We defined the null hypothesis as the case where there was no statistically significant difference between two values .The alternative hypothesis was defined as the opposite case .We set the statistical significance level at 0.05 .The null hypotheses of the \" deg . \" rest \" cases were rejected .", "label": "", "metadata": {}, "score": "73.45531"}
{"text": "PHONE is for languages with not pronunciation based orthography .KEY characters_separated_by_vertical_line_optionally Hunspell searches and suggests words with one different character replaced by a neighbor KEY character .Not neighbor characters in KEY string separated by vertical line characters .The parameter of TRY is case sensitive .", "label": "", "metadata": {}, "score": "73.52099"}
{"text": "Simple majority voting .The system assigns to each word the label that receives the most votes from the three individual systems ( i.e. if at least two individual systems output the same label y for a given word x , y will be chosen as the final label for x ) .", "label": "", "metadata": {}, "score": "73.53555"}
{"text": "Both Ispell and Myspell use 8-bit ASCII character encoding , which is a .major deficiency when it comes to scalability .Although a language .like Hungarian has a standard ASCII character set ( ISO 8859 - 2 ) , it . fails to allow a full implementation of Hungarian orthographic . conventions .", "label": "", "metadata": {}, "score": "73.59943"}
{"text": "It\u00e2\u20ac \u2122 s useful to add a TRY option with the characters of the dictionary .with frequency order to set edit distance suggestions : .SEE ALSO . hunspell ( 1 ) , ispell ( 1 ) , ispell ( 4 ) .", "label": "", "metadata": {}, "score": "74.028076"}
{"text": "Useful for languages with .\u00e2\u20ac\u02dccompound friendly\u00e2\u20ac \u2122 orthography .CHECKCOMPOUNDCASE .Forbid upper case characters at word bound in compounds .CHECKCOMPOUNDTRIPLE .Forbid compounding , if compound word contains triple letters .Bug : missing multi - byte character .support in UTF-8 encoding ( works only for 7-bit ASCII .", "label": "", "metadata": {}, "score": "74.07762"}
{"text": "WORDCHARS characters WORDCHARS extends tokenizer of Hunspell command line interface with additional word character .For example , dot , dash , n - dash , numbers , percent sign are word character in Hungarian .CHECKSHARPS SS letter pair in uppercased ( German ) words may be upper case sharp s ( \u00c3\u0192 ) .", "label": "", "metadata": {}, "score": "74.099266"}
{"text": "A \" non - contiguous bi - fragment , \" as used herein , refers to a bi - fragment in which at least one of the text fragments comprises a non - contiguous phrase .It should be noted that in many cases discussed herein , both fragments of a bi - fragment are phrases ( i.e. , a bi - phrase ) although they need not be so .", "label": "", "metadata": {}, "score": "74.19278"}
{"text": "This may be used to determine a cost function to a given hypothesis in a scoring model .In general , the cost decreases as the hypothesis moves toward a number of gaps which corresponds to the statistically determined most likely number of gaps .", "label": "", "metadata": {}, "score": "74.30881"}
{"text": "For example : . # affix file .COMPOUNDFLAG X .foo / X .bar / X .With this resource , foobar and barfoo also are accepted words .This has been improved upon with the introduction of direction- .sensitive compounding , i.e. , lexical features can specify separately .", "label": "", "metadata": {}, "score": "74.39476"}
{"text": "There are two words in between in the third sentence .Moreover the words between cement and relations may vary and the distance between the two words also can vary .But there is a regularity in the patterns so that we can determine that cement is the right verb to use for this situation .", "label": "", "metadata": {}, "score": "74.47415"}
{"text": "Acknowledgments .The authors want to thank to Ant\u00f3nio Guedes de Oliveira and Pedro Silva for their helpful suggestions and the three anonymous reviewers for helpful comments that greatly improved the manuscript .I. Soares has a doctoral Grant ( SFRH / BD/38171/2007 ) and A. Goios has a postdoctoral Grant ( SFRH / BPD/43646/2008 ) from Funda\u00e7\u00e3o para a Ci\u00eancia e Tecnologia .", "label": "", "metadata": {}, "score": "74.83391"}
{"text": "( class P ) .PFX P Y 1 .PFX P 0 un .[ prefix_un]+ .SFX S Y 1 .SFX S 0 s .+ PL .SFX Q Y 1 .SFX Q 0 s .+3SGV .SFX R Y 1 .", "label": "", "metadata": {}, "score": "75.21678"}
{"text": "Each line shows one vector .A +1(-1 ) means a positive example ( negative example ) .The positive integer on the left side of the colon is the unique number of each feature .A \" 1 \" on the right side of the colon shows that the vector includes the feature presented by the unique number .", "label": "", "metadata": {}, "score": "75.25853"}
{"text": "Suffixes signed with ONLYINCOMPOUND flag may be only inside of . compounds ( Fuge - elements in German , fogemorphemes in Swedish ) .ONLYINCOMPOUND flag works also with words ( see . tests / onlyincompound .COMPOUNDPERMITFLAG flag .Prefixes are allowed at the beginning of compounds , suffixes are . allowed at the end of compounds by default .", "label": "", "metadata": {}, "score": "75.32553"}
{"text": "An article of manufacture comprising a program storage medium readable by a computer comprising instructions for executing the method of . claim 1 .Description .CROSS REFERENCE TO RELATED PATENTS AND APPLICATIONS .Cross - reference is made to U.S. application Ser .", "label": "", "metadata": {}, "score": "75.409454"}
{"text": "Qualitatively Visual Tony HirstDept of Communication & Systems , blog.ouseful.info The Open University @psychemedia .Explanatory visualizationData visualizations that are used totransmit information or a point ofview from the designer to thereader .Explanatory visualizationstypically have a specific \" story \" orinformation that they are intendedto transmit .", "label": "", "metadata": {}, "score": "75.43944"}
{"text": "Results .Evaluation on 268 manually annotated discharge summaries from the i2b2 challenge showed that the local CRF - based voting method achieved the best F - score of 90.84 % ( 94.11 % Precision , 87.81 % Recall ) for 10-fold cross - validation .", "label": "", "metadata": {}, "score": "75.45883"}
{"text": "claim 1 , wherein the gap size scoring feature models gap sizes observed in a training corpus as a distribution which is expressed in terms of a parameter of the distribution .The method of . claim 5 , wherein the distribution comprises a Poisson distribution and the parameter of the distribution comprises a mean value of the Poisson distribution .", "label": "", "metadata": {}, "score": "75.594574"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus NAME .hunspell - format of Hunspell dictionaries and affix files .DESCRIPTION .Hunspell ( 1 ) requires two files to define the language that it is spell . checking .", "label": "", "metadata": {}, "score": "75.896164"}
{"text": "Preceding class : Class ( i.e. B , I , or O ) of the token(s ) preceding the current token .The number of preceding tokens is dependent on the window size ( described later on ) .For example , the features of \" NF - kappaB \" in the sample phrase in Figure 2 are as follows .", "label": "", "metadata": {}, "score": "76.26111"}
{"text": "To compensate , I scale down all of war 's bigrams so that the overall frequencies are even . \" \" it shows the relative weight of the phrases starting with ' business ' that get used in books , in a way so that all the lines add up to 100 % for any given year .", "label": "", "metadata": {}, "score": "76.549385"}
{"text": "Conversion of aspell dictionaries .Aspell dictionaries can be easily converted into hunspell .preunzip xx.cwl .If the affix file exists , copy it : . cp xx_affix . dat xx.aff .If not , create it with the suitable character encoding ( see xx.dat ) .", "label": "", "metadata": {}, "score": "76.833466"}
{"text": "Conclusion .During SVM learning , each feature alone had a marginally positive effect on system performance .This supports the fact that the SVM algorithm is robust on the high dimensionality of the feature vector space and means that feature selection is not required .", "label": "", "metadata": {}, "score": "77.17756"}
{"text": "Then , the use frequency of words that follow these two terms are analyzed .For example , \" war memorial \" occurs 531,205 times , while \" peace memorial \" occurs only 25,699 .A position for each word is generated by looking at the ratio of the two frequencies .", "label": "", "metadata": {}, "score": "77.18919"}
{"text": "REP . sets a replacement table for multiple character corrections in .suggestion mode .PFX and SFX defines prefix and suffix classes named .with affix flags .The following affix file example defines UTF-8 character encoding .\u00e2\u20ac\u02dcTRY\u00e2\u20ac \u2122 suggestions differ from the bad word with an English letter or an . apostrophe .", "label": "", "metadata": {}, "score": "77.63654"}
{"text": "Data Mining and Knowledge Discovery 1998 , 2 ( 2 ) : 121 - 167 .View Article .Pre - publication history .Copyright .\u00a9 Doan et al ; licensee BioMed Central Ltd. 2012 .This article is published under license to BioMed Central Ltd.", "label": "", "metadata": {}, "score": "77.7242"}
{"text": "# Hint : ONLYINCOMPOUND is not required everywhere , but the .# checking will be a little faster with it .ONLYINCOMPOUND X .# forbid uppercase characters at compound word bounds .CHECKCOMPOUNDCASE .# for handling Fuge - elements with dashes ( Arbeits- ) .", "label": "", "metadata": {}, "score": "77.83755"}
{"text": "ds : Derivational suffix(es ) .Stemming doesn\u00e2\u20ac \u2122 t remove derivational suffixes .Morphological generation depends on the order of the suffix fields .In affix rules : SFX Y Y 1 SFX Y 0 ly .ds : ly_adjIn the dictionary : ably st : able ds : ly_adj able al : ably is : Inflectional suffix(es ) .", "label": "", "metadata": {}, "score": "78.02031"}
{"text": "SFX B 0 0/VWXDP .# a suffix for \u00e2\u20ac\u02dcComputer\u00e2\u20ac \u2122 .SFX C Y 1 .SFX C 0 n / WD .FORBIDDENWORD Z .# dash prefix for compounds with dash ( Arbeits - Computer ) .PFX - Y 1 .", "label": "", "metadata": {}, "score": "78.089676"}
{"text": "The parenthesized values are the p - values .The values in bold have a statistically significant difference from the base value .A difference is labeled statistically significant when the p - value is less than 0.05 on the Wilcoxon signed - ranks sum test ( two - sided ) .", "label": "", "metadata": {}, "score": "78.197105"}
{"text": "In simple words , here , the prefix un- is legitimate only if the base drink is suffixed with -able .If . both these patters are handled by on - line affix rules and affix rules . are checked against the base only , there is no way to express this . dependency and the system will necessarily over- or undergenerate .", "label": "", "metadata": {}, "score": "78.273254"}
{"text": "\" The lexicon builder 125 may measure the spelling similarity between every German and English word , and sort possible word pairs accordingly .This may be done in a greedy fashion , i.e. , once a word is assigned to a word pair , the lexicon builder 125 does not look for another match .", "label": "", "metadata": {}, "score": "78.42238"}
{"text": "\" Bookworm demonstrates a new way of interacting with the millions of recently digitized library books .The Harvard Cultural Observatory already collaborated with Google Books on the Google ngramsviewerthat has data for years .Bookworm does n't work so closely with Google Books : instead , it uses texts in the public domain , in this case , books from the Open Library and Internet Archive .", "label": "", "metadata": {}, "score": "78.433075"}
{"text": "morphological field ids , see also Optional data fields ) .Personal dictionaries are simple word lists .Asterisk at the first . character position signs prohibition .A second word separated by a . slash sets the affixation . foo .Foo / Simpson .", "label": "", "metadata": {}, "score": "78.581085"}
{"text": "( like elative -b\u00c3 ... l , allative -t\u00c3 ... l or delative -r\u00c3 ... l with double acute ) , . these result in words ( like \u00c3 \u0192 ngstr\u00c3 \u0192 \u00c2 \u00b6 mr\u00c3 ... l or Moli\u00c3 \u0192 \u00c2 \u00a8 re - t\u00c3 ...", "label": "", "metadata": {}, "score": "78.81317"}
{"text": "# circumfix for positioning in compounds .PFX D Y 29 .PFX D A a / PX A .PFX D Y y / PX Y .PFX D Z z / PX Z .Example dictionary : .Arbeit / A- .", "label": "", "metadata": {}, "score": "78.850586"}
{"text": "BACKGROUND .Machine translation ( MT ) concerns the automatic translation of natural language sentences from a first language ( e.g. , French ) into another language ( e.g. , English ) .Systems that perform MT techniques are said to \" decode \" the source language into the target language .", "label": "", "metadata": {}, "score": "79.41916"}
{"text": "Eliminating low information features gives your model clarity by removing noisy data .It can save you from overfitting and the curse of dimensionality .When you use only the higher information features , you can increase performance while also decreasing the size of the model , which results in less memory usage along with faster training and classification .", "label": "", "metadata": {}, "score": "79.49786"}
{"text": "CMUP was funded by the European Regional Development Fund through the programme COMPETE and by the Portuguese Government through the FCT under the Project PEST - C / MAT / UI0144/2011 .The funding sources had no involvement in any part of this study .", "label": "", "metadata": {}, "score": "79.53408"}
{"text": "60/368,070 , filed on Mar. 26 , 2002 , and U.S. Provisional Application Ser .No .60/368,447 , filed on Mar. 27 , 2002 , the disclosures of which are incorporated by reference .ORIGIN OF INVENTION .The research and development described in this application were supported by Defense Advanced Research Project Agency ( DARPA ) under grant number N66001 - 00 - 1 - 8914 .", "label": "", "metadata": {}, "score": "79.95439"}
{"text": "Mutual Information .By the chain rule for entropy , .Therefore , . where H represents entropy and X and Y are random variables .This difference is called the mutual information between X and Y. It is the amount of information one random variable contains about another .", "label": "", "metadata": {}, "score": "80.13467"}
{"text": "Our system based on majority voting achieved a better F - score of 89.65 % ( 93.91 % Precision , 85.76 % Recall ) than the previously reported F - score of 89.19 % ( 93.78 % Precision , 85.03 % Recall ) by the first - ranked system in the challenge .", "label": "", "metadata": {}, "score": "80.15216"}
{"text": "( COMPOUNDFORBIDFLAG ) to permit or prohibit compounding of the . derivations .Suffixes with this flag forbid compounding of the affixed word .We also need several Hunspell features for handling German compounding : . # German compounding .# set language to handle special casing of German sharp s .", "label": "", "metadata": {}, "score": "80.382675"}
{"text": "Two dashed lines are the boundaries between the positive and negative examples .An SVM finds the optimal hyperplane , which is the one with the maximum margin .The two dashed lines in Figure 4 are the boundaries between the positive and negative examples .", "label": "", "metadata": {}, "score": "80.459854"}
{"text": "^ .arg .max .t .J .Pr .t .J .s .I . )Pr .t .J .d .K .s .I . )Z .f .I . exp .", "label": "", "metadata": {}, "score": "80.49435"}
{"text": "It will be appreciated that various of the above - disclosed and other features and functions , or alternatives thereof , may be desirably combined into many other different systems or applications .Also that various presently unforeseen or unanticipated alternatives , modifications , variations or improvements therein may be subsequently made by those skilled in the art which are also intended to be encompassed by the following claims .", "label": "", "metadata": {}, "score": "80.60814"}
{"text": "However , they span different time periods and have a different orientation : the World Street Journal covers mostly business news , the German news wire mostly German politics .The system 100 may use clues to find translations of words in the monolingual corpora .", "label": "", "metadata": {}, "score": "81.45354"}
{"text": "+ POS \" cases , instead of an expected increase , there was surprisingly a drop ( in this case , not statistically significant ) in the balanced f - score when switching from the original POS tagger to the GENIA trained POS tagger .", "label": "", "metadata": {}, "score": "81.98692"}
{"text": "When used for matching , each of these dictionaries is divided into 2 ( sub-)dictionaries , one with the protein names and the other with the gene names .PubMed is a service of the National Library of Medicine that can be used to search for articles from over 15 million citations for biomedical articles .", "label": "", "metadata": {}, "score": "82.35777"}
{"text": "recognized with affixes of Simpson ( Foo\u00e2\u20ac \u2122 s etc . ) and bar is a forbidden .word . aff ) may contain a lot of optional attributes .For . example , SET is used for setting the character encodings of affixes and . dictionary files .", "label": "", "metadata": {}, "score": "82.86238"}
{"text": "x10 days , \" \" 10-day course , \" \" For ten days , \" \" For a month , \" \" During spring break , \" \" Until the symptom disappears , \" \" As long as needed \" .Expressions that indicate for how long the medication is to be administered .", "label": "", "metadata": {}, "score": "83.20085"}
{"text": "For the State of the Union diagrams produced below I used the four topics Government , Domestic , Economy , and Security . \"Rather than using arcs to connect identical patterns within a document I 'm connecting instead segments that contain similar words .", "label": "", "metadata": {}, "score": "83.29294"}
{"text": "In consequence , once the current stack has been traversed , it is never seen again and the decoder can move to the next stack .However this addition , for an admissible heuristics , is positioned in the stack below the current state , because the heuristic cost of the new state will be larger than that of other states in the current stack .", "label": "", "metadata": {}, "score": "83.98181"}
{"text": "In this figure , triangles are positive examples and black dots are negative examples .The hyperplane is given by .Two possible hyper planes and margins between positive and negative examples .White triangles are positive examples .Black dots are negative examples .", "label": "", "metadata": {}, "score": "84.22094"}
{"text": "That makes \" magnificent \" a high information word .Notice that the most informative features above did not change .That makes sense because the point is to use only the most informative features and ignore the rest .One of the best metrics for information gain is chi square .", "label": "", "metadata": {}, "score": "84.97868"}
{"text": "The exemplary scoring module 24 includes instructions for computing a plurality of features 32 , 34 , 36 , 37 , 38 , 40 , 42 , 44 .It is to be appreciated that the scoring module may employ fewer , more , or different features than the features shown .", "label": "", "metadata": {}, "score": "85.3324"}
{"text": "References .Hirschman L , Morgan AA , Yeh AS : Rutabaga by any other name : extracting biological names .J Biomed Inform 2002 , 35 : 247 - 259 .PubMed View Article .Krauthammer M , Nenadic G : Term identification in the biomedical literature .", "label": "", "metadata": {}, "score": "85.44848"}
{"text": "IGNORE characters Ignore characters from dictionary words , affixes and input words .Useful for optional characters , as Arabic diacritical marks ( Harakat ) .AF number_of_flag_vector_aliases AF flag_vector Hunspell can substitute affix flag sets with ordinal numbers in affix rules ( alias compression , see makealias tool ) .", "label": "", "metadata": {}, "score": "85.66445"}
{"text": "Effects of tuning parameters on system performance .The \" base \" parameters are shown in Table 4 .The \" deg . \" means the degree of the polynomial kernel , the \" win .\" is the window range , and \" cv \" is the cost of constraint violation .", "label": "", "metadata": {}, "score": "85.90171"}
{"text": "-rest method .In the latter , the B , I , and O classes are learned as ( B vs. other ) , ( I vs. other ) , and ( O vs. other ) .Cost of constraint violation ( floating number ) : There is a trade - off between the training error and the soft margin of the hyper plane .", "label": "", "metadata": {}, "score": "85.92343"}
{"text": "Zero stripping or affix are indicated by zero .Zero condition is indicated by dot .Condition is a simplified , regular expression - like pattern , which must be met before the affix can be applied .( Dot signs an arbitrary character .", "label": "", "metadata": {}, "score": "86.53523"}
{"text": "COMPOUNDPERMITFLAG may be inside of compounds .COMPOUNDFORBIDFLAG flag .Suffixes with this flag forbid compounding of the affixed word .COMPOUNDROOT flag .COMPOUNDROOT flag signs the compounds in the dictionary ( Now it . is used only in the Hungarian language specific code ) .", "label": "", "metadata": {}, "score": "87.191315"}
{"text": "la vaisselle \" in the sentence \" On peut faire beaucoup d'argent en important en france de la vaisselle chinoise \" ) .However , other features could be utilized to account for such unlikely gap sizes .As will be appreciated , an object of any translation model is to provide accurate translations and each added feature may contribute to this accuracy to greater or lesser extents .", "label": "", "metadata": {}, "score": "88.4441"}
{"text": "For example , the phrase \" take the train . . .from . . .to \" is considered as take . . .the . . .train . . .from . . .to , where it is assumed that gaps exist between all the words .", "label": "", "metadata": {}, "score": "88.760254"}
{"text": "Vapnik VN : The Nature of Statistical Learning Theory Springer 1995 .Copyright .\u00a9 Mitsumori et al 2005 .This article is published under license to BioMed Central Ltd.", "label": "", "metadata": {}, "score": "89.323"}
{"text": "Because affixed forms are also forbidden , we can subtract a subset from set of the accepted affixed and compound words .KEEPCASE flag Forbid uppercased and capitalized forms of words signed with KEEPCASE flags .Useful for special orthographies ( measurements and currency often keep their case in uppercased texts ) and writing systems ( e.g. keeping lower case of IPA characters ) .", "label": "", "metadata": {}, "score": "89.683624"}
{"text": "The manuscript was prepared by SD with additional contributions by all authors .All authors read and approved the final manuscript .Authors ' Affiliations .National Institute of Informatics , Hitotsubashi .Department of Biomedical Informatics , School of Medicine , Vanderbilt University .", "label": "", "metadata": {}, "score": "89.7562"}
{"text": "\" Prn , \" \" As needed , \" \" Three times a day as needed , \" \" As needed three times a day , \" \" x3 before meal , \" \" x3 a day after meal as needed \" .Terms , phrases , or abbreviations that describe how often each dose of the medication should be taken .", "label": "", "metadata": {}, "score": "90.27545"}
{"text": "Mean and Variance .Collocations are not always of fixed phrases .Consider the following sentences .Obama cemented relations with the East .Jill cemented his relations with Jack .John cemented Mark Taylor 's relations with Tom .While cement and relations occur together frequently cement does not follow relations immediately always .", "label": "", "metadata": {}, "score": "90.575455"}
{"text": "Set maximum word count in a compound word .( Default is . unlimited . )CHECKCOMPOUNDDUP .Forbid word duplication in compounds ( e.g. foofoo ) .CHECKCOMPOUNDREP .Forbid compounding , if the ( usually bad ) compound word may be a .", "label": "", "metadata": {}, "score": "92.01535"}
{"text": "+ DER_V_ADJ_ABLE .Dictionary : . drink / RQ [ verb ] .drink / S [ noun ] .Morphological analysis : . drink[verb ] .drink[noun ] .drink[verb]+3SGV .drink[noun]+PL .drink[verb]+DER_V_ADJ_ABLE .drink[verb]+DER_V_ADJ_ABLE+PL .[ prefix_un]+drink[verb]+DER_V_ADJ_ABLE .[ prefix_un]+drink[verb]+DER_V_ADJ_ABLE+PL .", "label": "", "metadata": {}, "score": "93.34755"}
{"text": "Collocational windows are used to capture bigrams at a specific distance .Let us use a three word collocational window for the following sentence .Plane crashed as climate worsened .We get the following bigrams .Plane crashed plane as plane climate . crashed as crashed climate crashed worsened as climate as worsened . climate worsened .", "label": "", "metadata": {}, "score": "93.42836"}
{"text": "Arbeits . arbeits .ComputerArbeit .ComputerArbeits .Arbeitcomputer .ArbeitsComputer .Computerarbeitcomputer .ComputerArbeitcomputer .ComputerArbeitscomputer .Arbeitscomputerarbeits .Computerarbeits - computer .Arbeitsnehmer .This solution is still not ideal , however , and will be replaced by a . pattern - based compound - checking algorithm which is closely integrated .", "label": "", "metadata": {}, "score": "93.911224"}
{"text": "Both systems used a similar volume of training data : 145 notes for the Sydney team and 147 notes for the Wisconsin team , respectively .The difference between those training data was that the Sydney team chose the 145 longest notes while the Wisconsin team randomly selected 147 notes from the training data [ 10 ] .", "label": "", "metadata": {}, "score": "94.90233"}
{"text": "Default type is the extended ASCII ( 8-bit ) character .\u00e2\u20ac\u02dcUTF-8\u00e2\u20ac \u2122 parameter sets UTF-8 encoded Unicode character flags .The \u00e2\u20ac\u02dclong\u00e2\u20ac \u2122 value sets the double extended ASCII character flag type , the \u00e2\u20ac\u02dcnum\u00e2\u20ac \u2122 sets the decimal number flag type .", "label": "", "metadata": {}, "score": "95.32008"}
{"text": "-/W .Arbeitsnehmer / Z .Accepted compound compound words with the previous resource : .Computer .Computern .Arbeit . Arbeits- .Computerarbeit . Computerarbeits- .Arbeitscomputer .Arbeitscomputern .Computerarbeitscomputer .Computerarbeitscomputern .Arbeitscomputerarbeit .Computerarbeits - Computer .Computerarbeits - Computern .", "label": "", "metadata": {}, "score": "101.12367"}
{"text": "Standard robust statistics may be used for treating \" atypical \" instances as outliers .For example , the target sentence \" He did not catch the train to Paris this week because he had no desire to travel by train anymore \" may be observed as including the non - contiguous phrase not_anymore with a gap size of 16 .", "label": "", "metadata": {}, "score": "103.160515"}
{"text": "Received 15 June 2012 ; Accepted 5 August 2012 .Academic Editors : J.-C. Aude , Y. Muto , and T. Roegnvaldsson .Copyright \u00a9 2012 In\u00eas Soares et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "104.174194"}
{"text": "For example , .He is known for his fair and square dealings and everybody trusts his work .Here fair and square means honest but if we take the individual words though the word fair gives somewhat closer meaning as it means just the word square confuses us .", "label": "", "metadata": {}, "score": "104.42754"}
{"text": "The best word matches may be collected in a greedy fashion .Another clue is based on the assumption that pairs of words that are similar in one language should have translations that are similar in the other language .For instance , Wednesday is similar to Thursday as Mittwoch is similar to Donnerstag .", "label": "", "metadata": {}, "score": "122.85074"}
