{"text": "This paper explores the role of lexicalization and pruning of grammars for base noun phrase identification .We modify the original framework of Cardie & Pierce ( 1998 ) to extract lexicalized treebank grammars that assign a score to each potential noun phrase based upon both the part - of - speech tag sequence and the word sequence of the phrase .", "label": "", "metadata": {}, "score": "47.344284"}
{"text": "It provides detailed features for each NP annotation , with DET ( determiner ) , MOD / MOD2 ( pre / post - head modifiers ) , and HEAD noun slots , as well as ( optional ) text offset information .", "label": "", "metadata": {}, "score": "49.008347"}
{"text": "This method , however , does not work for manual data , such as documents or written text data with specific types of data content that have set relationships .Prior studies have pointed out that a set of lexico - syntactic patterns indicate hypernym relations between noun phrases ( NP ) .", "label": "", "metadata": {}, "score": "49.994946"}
{"text": "This means that its performance can be evaluated in a straightforward way by using a set of questions and correct answers .Given a correct noun phrase answer , it is generally easy to judge whether a noun phrase hypothesized by the system is correct or not .", "label": "", "metadata": {}, "score": "50.29127"}
{"text": "These enable phrase recognition to be done .Phrases are specified by regular expressions in the finite - state calculus ( Hopcroft and Ullman , supra ) .Noun phrases are identified solely by part - of - speech categories , but more generally categories and words are used to define lexico - syntactic patterns against which text is matched .", "label": "", "metadata": {}, "score": "50.453842"}
{"text": "( [ [ : s np vp ] ] ( noun - phrase np ) ( verb - phrase vp ) ) ) .Defining facts .Sometimes it 's useful to create a list of facts that you want to run queries over .", "label": "", "metadata": {}, "score": "51.899727"}
{"text": "Rules may be recursive in that the output of one rule application may be the input to another rule .[0073 ] .The NP - resolution rule constructions of an embodiment , while not dependent on the particular syntax or format of the rules , can be easily specified for a given new device and encapsulated with the device .", "label": "", "metadata": {}, "score": "51.99685"}
{"text": "[ 0078 ] .The method of an embodiment further comprises retrieving at least one object referenced by object descriptions from the dialogue contribution from at least one database in response to the query .The object descriptions of an embodiment include noun - phrases .", "label": "", "metadata": {}, "score": "52.22945"}
{"text": "In its second phase of processing MURAX embodies the method of the present invention .Answer extraction begins by finding all simple noun phrases contained in the match sentences of the primary documents , that is , in those sentences that caused or helped to cause the primary documents to be retrieved .", "label": "", "metadata": {}, "score": "52.468185"}
{"text": "Phrases of the input string that appear in context with the hypothesis can likewise be emphasized .Additionally , the answer extraction subsystem can provide further information about verification , linking , and scoring .In short , the answer extraction subsystem provides results that tell the user what the best answer hypothesis is , where it occurs in the documents , and why this answer was selected .", "label": "", "metadata": {}, "score": "52.468254"}
{"text": "MURAX uses the various phrase matching procedures in concert to provide a ranked list of answer hypotheses .It does this by providing several intermediate layers of scoring and preference criteria .A list of criteria for partially ordering hypotheses is given below , in order of precedence .", "label": "", "metadata": {}, "score": "52.618816"}
{"text": "These include the encyclopedia and the IR system for accessing it .Shallow linguistic analysis is done using a part - of - speech tagger and finite - state recognizers for matching lexico - syntactic patterns .Section 4 describes the analysis of a question by considering an example and illustrates the system output .", "label": "", "metadata": {}, "score": "52.85234"}
{"text": "Let 's take a look at what it 's learned , by using its unigram tagger to assign a tag to each of the part - of - speech tags that appear in the corpus : .It has discovered that most punctuation marks occur outside of NP chunks , with the exception of # and $ , both of which are used as currency markers .", "label": "", "metadata": {}, "score": "53.199833"}
{"text": "\" .6.1.2 Predicate / Argument Match .This operation associates answer hypotheses and other noun phrases in a match sentence that satisfy a verb relation implied in a question .Verbs are simply assumed to be monotransitive and patterns accounting for active and passive alternation are applied .", "label": "", "metadata": {}, "score": "53.30071"}
{"text": "NP3 ?For robustness , MURAX layers phrase matching on top of co - occurrence matching .Accordingly , if the input is not a question ( or is a question beginning with \" how \" or \" why \" ) , MURAX provides output that is typical of co - occurrence based search methods .", "label": "", "metadata": {}, "score": "53.57217"}
{"text": "[ 0069 ] .The RNDS DM 100 uses the NPRSs 104 to translate NPs into Java objects implementing constraint - based KB - queries ( referred to herein as a \" noun phrase - query \" or \" NP - query \" ) .", "label": "", "metadata": {}, "score": "53.77154"}
{"text": "For example , a thesaurus can be made available to the answer extraction subsystem , either as part of the subsystem itself or as an external resource connected to the subsystem by channels .The thesaurus can be used to generate synonyms and hyponyms ( e.g. , for type phrase word replacement ) that can in turn be used for generating hypotheses , matching sentences during verification , or both .", "label": "", "metadata": {}, "score": "54.131256"}
{"text": "Its analysis capitalizes on the information available in a question and profits from treating the encyclopedia as a lexical resource .MURAX also demonstrates that natural language analysis can add to the quality of the information retrieval process , providing text to the user that confirms phrase relations and not just word matches .", "label": "", "metadata": {}, "score": "54.214687"}
{"text": "In still other such alternative embodiments the step of hypothesis verification can be included but without secondary queries , or without linking of equivalent hypotheses .PART III .MURAX .Organization of Part III .Part III of the description focuses on MURAX , a system that embodies the method of the present invention in the context of a larger two - phase method for answering a natural - language question .", "label": "", "metadata": {}, "score": "54.22384"}
{"text": "MURAX operates on closed - class questions .A closed - class question is a direct question whose answer is assumed to lie in a set of objects and is expressible as a noun phrase .Put another way , a closed - class question is a question , stated in natural language , that assumes some definite answer typified by a noun phrase rather than by a procedural answer .", "label": "", "metadata": {}, "score": "54.43498"}
{"text": "0079 ] .The method of an embodiment further comprises adapting at least one of the noun phrase - resolution rules for use across at least one of a plurality of different domains and a plurality of different applications via reprogramming of the NPRS .", "label": "", "metadata": {}, "score": "54.625473"}
{"text": "\" and \" What NP . . . \" .The noun phrase at the start of such questions is called the question 's type phrase and it indicates what type of thing the answer is .The encyclopedia can be searched to try to find evidence that an answer hypothesis is an instance of the type phrase ( details are presented in section 6.1.1 below ) .", "label": "", "metadata": {}, "score": "54.638397"}
{"text": "4.1 Primary Query Construction .In its first phase of processing MURAX embodies the method of co - pending application entitled METHOD FOR COMPUTERIZED INFORMATION RETRIEVAL USING SHALLOW LINGUISTIC ANALYSIS as incorporated hereinabove by reference .Simple noun phrases and main verbs are first extracted from the input question , as illustrated in Table 7 .", "label": "", "metadata": {}, "score": "54.809597"}
{"text": "For example , MURAX could be extended to include a comprehensive evaluation phase that takes account of not only the rank of correct hypotheses , but also the suitability of the match sentences that are presented to the user to verify phrase relations .", "label": "", "metadata": {}, "score": "54.865402"}
{"text": "This section describes in further detail how MURAX performs primary query construction .In accordance with the method of the co - pending application entitled METHOD FOR COMPUTERIZED INFORMATION RETRIEVAL USING SHALLOW LINGUISTIC ANALYSIS as incorporated hereinabove by reference , MURAX translates phrases from a question into Boolean queries with proximity and order constraints .", "label": "", "metadata": {}, "score": "54.996994"}
{"text": "Accordingly , to try to confirm an answer hypothesis as a person 's name , MURAX makes a secondary query to see if the answer hypothesis is present as an article title , and then decides whether the article is about a person .", "label": "", "metadata": {}, "score": "55.066948"}
{"text": "The ontological learning component 104 in .FIG .1 uses the term features and lexico - syntactic patterns to identify ontological relations among the candidate terms .A term feature could be a special word in the domain or domain - related term , and may be characterized by containing capital words or marking the beginning of a sentence .", "label": "", "metadata": {}, "score": "55.11534"}
{"text": "Note .Remember that our program samples assume you begin your interactive session or your program with : import nltk , re , pprint .Next , in named entity detection , we segment and label the entities that might participate in interesting relations with one another .", "label": "", "metadata": {}, "score": "55.284294"}
{"text": "Each noun phrase found becomes an answer hypothesis that is distinguished by its component words and the article and match sentence in which it occurs .Answer hypotheses are scored on a per - article basis according to the sum of the scores of the articles in which they occur .", "label": "", "metadata": {}, "score": "55.389305"}
{"text": "In some embodiments , such as those described up to this point , information retrieval is additionally based on an input string .If there is an input string , the answer hypotheses can include phrases or words not present in the input string .", "label": "", "metadata": {}, "score": "55.472847"}
{"text": "Accordingly , a secondary query typically seeks the co - occurrence of an answer hypothesis and one or more phrases of the input string , such as the type phrase ( if one is present ) , a main verb or verb phrase , or a title phrase .", "label": "", "metadata": {}, "score": "55.602455"}
{"text": "The tagger uses both suffix information and local context to predict the categories of words for which it has no lexicon entries .The HMM used for tagging the encyclopedia text was also trained using the encyclopedia .A benefit of such training is that the tagger can adapt to certain characteristics of the domain .", "label": "", "metadata": {}, "score": "55.877235"}
{"text": "An example pattern and text match is shown in Table 9 .For convenience , copies of expressions can be included by naming them in other expressions .In Table 9 , the expression NP1 refers to a noun phrase whose pattern is defined elsewhere .", "label": "", "metadata": {}, "score": "55.883938"}
{"text": "Thus a linguistic relation can be verified by filling in the template with the hypothesis and matching the filled - in template to text in a document .For a question that has a type phrase , the answer extraction subsystem generates templates that incorporate the head word of the type phrase .", "label": "", "metadata": {}, "score": "55.936153"}
{"text": "After scoring , the relevant articles are ranked according to their scores .A subset of the ranked articles is made available for the second phrase of processing .MURAX assumes that these articles , which are called the primary documents , contain the answer to the user 's question . 4.2", "label": "", "metadata": {}, "score": "55.962196"}
{"text": "The RNDS DM 100 uses a rule - based language for specifying how an NP ( regardless of format ) maps to constraint - based query objects , making use of generic or device - specific frame - construction operations .Such rules are used for handling synonyms ( i.e. by mapping multiple nouns into the same query - type ) as well as specifying the construction of complex query objects from complex NPs .", "label": "", "metadata": {}, "score": "56.04463"}
{"text": "Then we reap the benefits of powerful query tools such as SQL .This method of getting meaning from text is called Information Extraction .Information Extraction has many applications , including business intelligence , resume harvesting , media analysis , sentiment detection , patent search , and email scanning .", "label": "", "metadata": {}, "score": "56.20683"}
{"text": "At the outset a strict ordering is imposed on the component words of phrases .For Example 3 , the first query is : .The IR system receives this Boolean query and searches for documents that match .Depending on the number of hits , new Boolean queries may be generated with the purposes of : .", "label": "", "metadata": {}, "score": "56.26714"}
{"text": "Therefore the hypothesis is most probably a person 's name .Another example of a non - lexico - syntactic verification technique that can be used in step 260 involves queries that can be called secondary co - occurrence queries .Such queries are performed during verification to seek co - occurrences of an answer hypothesis with any input string phrases that do not appear in any recognized relations and are thus not incorporated into any templates .", "label": "", "metadata": {}, "score": "56.653732"}
{"text": "Including the main verb in the query for Example 3 gives : .Another way that MURAX achieves narrowing is by reducing the co - occurrence scope of terms in the query .This constrains phrases to be closer together , and thus indirectly increases the probability of the phrases ' being in some syntactic relation with each other .", "label": "", "metadata": {}, "score": "56.696426"}
{"text": "It will further be observed in Example 1 that the answer hypotheses developed according to the method typically appear nowhere in the user 's question .Glossary .The following terms are intended to have the following general meanings : .Answer : The actual , correct answer to a given question .", "label": "", "metadata": {}, "score": "57.028954"}
{"text": "In one embodiment in which results are to be presented to the user , the highest - ranked answer hypothesis is selected for presentation .This hypothesis is highlighted in the contexts in which it appears in primary and secondary documents , for example by displaying the document titles and the match sentences that confirm the linguistic relations implied by the user 's question .", "label": "", "metadata": {}, "score": "57.03185"}
{"text": "Given a particular company , we would like to be able to identify the locations where it does business ; conversely , given a location , we would like to discover which companies do business in that location .If our data is in tabular form , such as the example in 1.1 , then answering these queries is straightforward .", "label": "", "metadata": {}, "score": "57.198036"}
{"text": "These features are packaged so as to facilitate a programming API that enables dynamic \" plug - and - play \" of new devices into the RNDS DM 100 .[0075 ] .[ 0076 ] .The method of an embodiment further comprises adapting the dialogue move for use across at least one of a plurality of different domains and a plurality of different applications via reprogramming of the DMS .", "label": "", "metadata": {}, "score": "57.348106"}
{"text": "In particular , it can be used in a two - phase method that accepts a user 's question in natural - language form and responds by not only producing relevant documents , but by also generating answer hypotheses and finding these hypotheses within the documents .", "label": "", "metadata": {}, "score": "57.35811"}
{"text": "For each of the linguistic relations detected in step 261 , step 262 is performed .In step 262 the answer extraction subsystem constructs or otherwise generates one or more templates for the linguistic relation under consideration .A template is a lexico - syntactic pattern , typically not one present in the input string , that when instantiated ( filled in ) can be searched for in the documents .", "label": "", "metadata": {}, "score": "57.467896"}
{"text": "The first , primary query construction , finds articles that are relevant to the question .The second phase ( called answer extraction ) analyzes these articles to find noun phrases ( called answer hypotheses ) that are likely to be the answer .", "label": "", "metadata": {}, "score": "57.523514"}
{"text": "More generally , instead of or in addition to lexico - syntactic pattern analysis , hypothesis verification in step 260 can incorporate more sophisticated or powerful linguistic analysis , such as can be provided by various natural language parsing techniques , including techniques that employ semantic information .", "label": "", "metadata": {}, "score": "57.60327"}
{"text": "( It can also be applied if there is no type phrase in the question . )The second criterion is an empirical one that is designed to increase the scores of hypotheses appearing in documents that are on the topic of the user 's original question .", "label": "", "metadata": {}, "score": "57.62652"}
{"text": "In this step , we search for mentions of potentially interesting entities in each sentence .Finally , we use relation detection to search for likely relations between different entities in the text .Figure 1.1 : Simple Pipeline Architecture for an Information Extraction System .", "label": "", "metadata": {}, "score": "57.9386"}
{"text": "It derives its answers to questions from a database comprising an on - line encyclopedia .The rest of Part III is organized as follows : In Section 2 the motivation for MURAX 's question - answering task is given , along with a description of the kind of questions that are its concern and their characteristics .", "label": "", "metadata": {}, "score": "58.053593"}
{"text": "This can be broken down into two sub - tasks : identifying the boundaries of the NE , and identifying its type .While named entity recognition is frequently a prelude to identifying relations in Information Extraction , it can also contribute to other tasks .", "label": "", "metadata": {}, "score": "58.067375"}
{"text": "In practice it is not necessary to provide elaborate ranking criteria and documents are ranked simply by the number of terms they have in common with the user 's question .Answer Extraction .This section describes in further detail how MURAX performs answer extraction in accordance with the method of the present invention .", "label": "", "metadata": {}, "score": "58.16093"}
{"text": "As we have seen , each sentence is represented using multiple lines , as shown below : . he PRP B - NP accepted VBD B - VP the DT B - NP position NN I - NP ... .A conversion function chunk.conllstr2tree ( ) builds a tree representation from one of these multi - line strings .", "label": "", "metadata": {}, "score": "58.17234"}
{"text": "Furthermore , some title phrase words , such as short function words , need not be capitalized .Thus , the correct extent of the title phrase can be ambiguous and alternative possibilities must be accommodated .In MURAX the most likely alternative is chosen after phrase matching has been done and the alternatives compared , based on the matches and frequency of the alternative interpretations .", "label": "", "metadata": {}, "score": "58.211952"}
{"text": "Method for extracting from a text corpus answers to questions stated in natural language by using linguistic analysis and hypothesis generation US 5519608 A .Abstract .A computerized method for organizing information retrieval based on the content of a set of primary documents .", "label": "", "metadata": {}, "score": "58.29187"}
{"text": "Although the above is a complete description of certain embodiments and aspects of the invention , various alternatives , modifications , and equivalents can be used .For example , in the context of the MURAX system -- which itself is but one of many possible embodiments of the method of the invention -- enhancements can be made to improve performance within the scope of the present invention .", "label": "", "metadata": {}, "score": "58.373325"}
{"text": "We demonstrate this approach using an example sentence that has been part - of - speech tagged in 2.2 .In order to create an NP -chunker , we will first define a chunk grammar , consisting of rules that indicate how sentences should be chunked .", "label": "", "metadata": {}, "score": "58.384773"}
{"text": "This is done by matching the filled - in templates generated in step 263 against the primary documents .In other words , sentences in which the hypothesis appears in the context of a template are sought in the primary documents .", "label": "", "metadata": {}, "score": "58.394615"}
{"text": "The sequence continues until some threshold on either the proximity or the resulting number of hits is reached .By dropping one or more whole phrases from the Boolean query .Query terms , each corresponding to a phrase , are dropped to get more hits .", "label": "", "metadata": {}, "score": "58.47352"}
{"text": "Once the noun phrases are determined , the method looks at the sentences in which these noun phrases appear in the retrieved documents .These sentences are analyzed to detect additional noun phrases that appear in conjunction with the noun phrases of the original question .", "label": "", "metadata": {}, "score": "58.50634"}
{"text": "An initial Boolean query that comprises all the noun phrases derived from the user 's question is first constructed and executed .Broadening and narrowing are then performed .The following partial order can be used : .Co- occurrence scope is increased before terms are dropped .", "label": "", "metadata": {}, "score": "58.713356"}
{"text": "The stored results represent the completed analysis of the input string .The results can be stored , for example , in a list of 3-tuples , one 3-tuple for each noun phrase , main verb , and title phrase detected during steps 310 , 315 , and 320 .", "label": "", "metadata": {}, "score": "58.7581"}
{"text": "For example , if the input question calls for a person 's name as an answer , and the text corpus comprises encyclopedia articles , the following is one possible non - lexico - syntactic technique to verify that a given hypothesis is in fact a person 's name .", "label": "", "metadata": {}, "score": "58.865337"}
{"text": "The basic code for the classifier - based NP chunker is shown in 3.2 .It consists of two classes .The first class is almost identical to the ConsecutivePosTagger class from 1.5 .The only two differences are that it calls a different feature extractor and that it uses a MaxentClassifier rather than a NaiveBayesClassifier .", "label": "", "metadata": {}, "score": "58.90995"}
{"text": "The subset can be output directly to the user via the user interface .Alternatively or additionally it can stored in a storage device for later use , or made available for further processing .In some embodiments one or more answer hypotheses can be highlighted in the documents in which they appear for ease of reference .", "label": "", "metadata": {}, "score": "59.00022"}
{"text": "Adverbs 9 .Noun Phrase 9.1 .Structure of simple NPs 9.2 .Structure of complex NPs 9.3 .Articles 9.4 .Mataqali \" kind of \" 9.5 .Lexical modifiers 9.6 .Grammatical modifiers and adverbs 10 .Possession 10.1 .", "label": "", "metadata": {}, "score": "59.15737"}
{"text": "A single lexico - syntactic pattern can imply multiple relations .A type phrase is a phrase in a question that indicates the nature of the appropriate answer to the question .In questions of the form , \" What is X ? \" , or , \" Who is X ? \" , the type phrase is X. To determine the type phrase for such a question , the answer extraction subsystem seeks one of the words \" who \" or \" what , \" followed by the verb \" to be , \" followed by a noun phrase .", "label": "", "metadata": {}, "score": "59.158527"}
{"text": "The system responds to user queries simply by accessing the appropriate cell of the array .Prior art IR systems and methods do not automatically perform a sequence of queries designed to include the optimal query or queries needed to answer a user 's natural - language question .", "label": "", "metadata": {}, "score": "59.303566"}
{"text": "The heuristic involves looking for an article that has the noun phrase in its title ; thus if the article does not share any phrases with the question , it would not be part of any primary document .Secondary queries are used as an alternative means to confirm phrase relations .", "label": "", "metadata": {}, "score": "59.30931"}
{"text": "Noun phrase : A phrase consisting of a noun , its modifiers ( e.g. , adjectives and other nouns ) and possibly an article .Noun phrase inclusion : The name of a particular lexicosyntactic pattern .Operators : kleene - plus , sequence , optionality , union : Functions in the finite - state calculus , used in finite - state recognizers .", "label": "", "metadata": {}, "score": "59.317024"}
{"text": "[0017 ] .The RNDS of an embodiment implements the information - state update approach to dialogue management through the use of the DMS .The DMS includes a combination of generic dialogue processes with an ability to easily extend or customize \" dialogue moves \" , which handle dialogue contributions from the user , to a new domain .", "label": "", "metadata": {}, "score": "59.793793"}
{"text": "Further alternatives will be apparent to those of skill in the art . 8.1 Alternative Techniques for Method Step .Alternative techniques can be used to carry out the input string analysis in question processing step 220 .For example , a parser based on a context - free grammar can be used .", "label": "", "metadata": {}, "score": "59.805763"}
{"text": "6.3 Equivalent Hypotheses .Answer hypotheses are identified by the article and match sentence in which they occur .Generally , the same answer is expressed by several hypotheses .This can happen , for example , when an answer hypothesis refers to a person , because often different word sequences are used to refer to the same person .", "label": "", "metadata": {}, "score": "59.831284"}
{"text": "Alternatively , adjectives , nouns and their combinations with prepositions can also be used .In block 206 , all patterns in the CME framework are included to identify ontological relations .FIG .3 is a flowchart that illustrates the steps of learning ontological relations for noun - phrases in a document , under an embodiment .", "label": "", "metadata": {}, "score": "59.848705"}
{"text": "The noun phrase resolver of an embodiment uses the NPRS to access the rules and translate the recognized description in order to generate a query that corresponds to at least one of the device and application .[ 0089 ] .The rules of an embodiment are adapted for use across at least one different domain and application via reprogramming of the NPRS .", "label": "", "metadata": {}, "score": "59.87751"}
{"text": "The method of claim 1 in which said phrase is present in each of a plurality of documents of said set of documents .The method of claim 1 further comprising the step of : . using a processor in conjunction with an output device to output a set of results , said set of results being organized according to said answer hypothesis .", "label": "", "metadata": {}, "score": "59.987137"}
{"text": "For an input question that includes a type phrase , the highest ranking answer hypotheses are those with minimum mismatch to the type phrase .Answer hypotheses are ranked according to the number of question phrases with which they co - occur .", "label": "", "metadata": {}, "score": "60.037148"}
{"text": "In embodiments that do not include a primary query construction subsystem , the input question and set of documents for answer extraction can be supplied by the user via user interface 7 , or , alternatively , retrieved from optional storage device 8 .", "label": "", "metadata": {}, "score": "60.25436"}
{"text": "Note .Your Turn : Try adding different features to the feature extractor function npchunk_features , and see if you can further improve the performance of the NP chunker .4 Recursion in Linguistic Structure .4.1 Building Nested Structure with Cascaded Chunkers .", "label": "", "metadata": {}, "score": "60.32988"}
{"text": "[ 0053 ] .The DMS of an embodiment also supports selection of dialogue moves via semantic templates .The \" Input \" section of a DMS includes the list of input items that would trigger this particular dialogue move .Parsed forms may be normalized or processed in any way ( e.g. , using an ontology , or via rewrite rules ) before being matched against \" Input \" templates .", "label": "", "metadata": {}, "score": "60.347023"}
{"text": "Analysis involving prepositional phrases or other coordination is applied subsequently as part of more detailed matching procedures .Word - initial capitalization turns out to be useful for splitting noun phrases appropriately .Thus \" New York City borough \" is split into \" New York City \" and \" borough \" .", "label": "", "metadata": {}, "score": "60.471413"}
{"text": "The chunking rules are applied in turn , successively updating the chunk structure .Once all of the rules have been invoked , the resulting chunk structure is returned . 2.3 shows a simple chunk grammar consisting of two rules .The first rule matches an optional determiner or possessive pronoun , zero or more adjectives , then a noun .", "label": "", "metadata": {}, "score": "60.55727"}
{"text": "In some embodiments , such as those described up to this point , the answer hypotheses are verified and can be ranked based on their verification evidence .If verification is performed , a text corpus can be used to provide verification evidence not present in the set of documents .", "label": "", "metadata": {}, "score": "60.646965"}
{"text": "In particular , such processes may be dependent on the selected device , while the device - recognition itself uses NP - resolution .[ 0020 ] .The RNDS therefore provides a combination of powerful practical core dialogue management processes with easy scriptable definitions of domain - specific information , such as dialogue - moves and NP - resolution mappings .", "label": "", "metadata": {}, "score": "60.669075"}
{"text": "Lexico - syntactic patterns in the input string can be seen as clues used by the answer extraction subsystem to help it determine what kinds of answer hypotheses are likely to be the most appropriate responses to the input string .For example , if the input string is a question , the interrogative words and syntactic structure of the question provide clues about the kind of answer that is expected .", "label": "", "metadata": {}, "score": "60.82177"}
{"text": "Different templates can also be assigned different importances according to the linguistic relations to which they correspond .The second and third criteria can be folded in with the first criterion in a weighted sum , rather than being used only to break ties as in the specific embodiment above .", "label": "", "metadata": {}, "score": "60.902836"}
{"text": "Conversely , a dialogue management infrastructure based on VXML allows flexible implementation of speech - based dialogue systems for new domains , but provides only shallow solutions to many issues in dialogue modeling .[ 0000 ] .Incorporation By Reference .", "label": "", "metadata": {}, "score": "60.98321"}
{"text": "( It will be observed that secondary queries themselves can generate false matches . )A single secondary query can sometimes serve to gather evidence for multiple relations .For example , a secondary query that seeks the co - occurrence of a hypothesis with the head noun of a type phrase can serve to retrieve documents from which any of the relations IS - A , apposition , list inclusion , or noun phrase inclusion can be satisfied .", "label": "", "metadata": {}, "score": "61.024887"}
{"text": "Turning to an example involving operations of the NPRS 104 , .FIG .4 is a flow diagram for using an NPRS to generate a database query ( noun phrase - query ) that corresponds to a device , under an embodiment .", "label": "", "metadata": {}, "score": "61.06894"}
{"text": "It should be noted that the various components disclosed herein may be described and expressed ( or represented ) as data and/or instructions embodied in various computer - readable media .[ 0103 ] .Words using the singular or plural number also include the plural or singular number respectively .", "label": "", "metadata": {}, "score": "61.226227"}
{"text": "In another such alternative embodiment , no input string is supplied and the steps of question processing and hypothesis verification both are skipped .Presented with a set of documents , this embodiment attempts to develop a hypothesis about what the documents have in common .", "label": "", "metadata": {}, "score": "61.324806"}
{"text": "Queries made during the first phase are called primary queries , and only involve phrases from the question .The second phase creates secondary queries which MURAX generates to verify specific phrase relations .Secondary queries involve both answer hypotheses and phrases from the question .", "label": "", "metadata": {}, "score": "61.330612"}
{"text": "6.1 Phrase Matching .Phrase matching is done with lexico - syntactic patterns which are described using regular expressions .The expressions are translated into finite - state recognizers , which are determinized and minimized ( Hopcroft and Ullman , supra ) so that matching is done efficiently and without backtracking .", "label": "", "metadata": {}, "score": "61.35721"}
{"text": "The NPRS 104 is effectively context - free grammars that allow the user to define how NP objects are mapped to knowledge - base queries for a specific device , in the context of the current dialogue information state and input semantic form .", "label": "", "metadata": {}, "score": "61.428627"}
{"text": "As we can see , NP -chunks are often smaller pieces than complete noun phrases .For example , the market for system - management software for Digital 's hardware is a single noun phrase ( containing two nested noun phrases ) , but it is captured in NP -chunks by the simpler chunk the market .", "label": "", "metadata": {}, "score": "61.443092"}
{"text": "These databases can then be used to find answers for specific questions .The typical architecture for an information extraction system begins by segmenting , tokenizing , and part - of - speech tagging the text .The resulting data is then searched for specific types of entity .", "label": "", "metadata": {}, "score": "61.455437"}
{"text": "The documents retrieved in response to secondary queries contain sentences that include both the input string phrase or phrases and the hypothesis .Secondary queries are formulated in a query language that expresses Boolean , proximity , and ordering or sequence relationships between search terms ( individual words or other queries ) in a form understandable by the IR subsystem .", "label": "", "metadata": {}, "score": "61.55213"}
{"text": "If this attempt at verification fails , MURAX runs a secondary query .If a title in the resulting matches is equivalent to the hypothesis and the title can be verified as a person 's name , then the hypothesis is linked to the title .", "label": "", "metadata": {}, "score": "61.572083"}
{"text": "Phrase matching operations are conducted first , followed by a procedure for constructing secondary queries to get secondary documents .Generally , several hypotheses can represent the same answer , so they must be linked together and their various phrase matches combined .", "label": "", "metadata": {}, "score": "61.639328"}
{"text": "( S ( NP Alice ) ( VP chased ( NP the rabbit ) ) ) .5 Named Entity Recognition .At the start of this chapter , we briefly introduced named entities ( NEs ) .Named entities are definite noun phrases that refer to specific types of individuals , such as organizations , persons , dates , and so on .", "label": "", "metadata": {}, "score": "61.66764"}
{"text": "This implementation is faster than miniKanren under Racket and seems to be close to performnace of miniKanren recorded by the original designers when running under Chez Scheme .Multi - lingual Noun Phrase Extractor ( MuNPEx ) .Overview .The Multi - Lingual Noun Phrase Extractor ( MuNPEx ) is a noun phrase ( NP ) chunker component developed for the GATE architecture , implemented in JAPE .", "label": "", "metadata": {}, "score": "61.6756"}
{"text": "A loop is executed for each such linguistic relation .In step 262 at least one template is constructed for the linguistic relation under consideration .At this point a loop is executed for each of the answer hypotheses .In step 263 templates are filled in using the hypothesis under consideration .", "label": "", "metadata": {}, "score": "61.71547"}
{"text": "Part I is an introduction that includes an overview of the invention , an example of how it works , and a glossary of terms .Part II describes the method of the present invention in one embodiment .Part III describes MURAX , a system designed to embody the method of the present invention in the context of a larger two - phase method of which the method of the present invention is used to carry out the second phase .", "label": "", "metadata": {}, "score": "61.72389"}
{"text": "Apposition : A grammatical construction in which two ( usually adjacent ) noun phrases refer to the same thing .Co- occurrence queries : A secondary query that contains phrases , other than the type phrase , from a user 's question .", "label": "", "metadata": {}, "score": "61.786854"}
{"text": "For each answer hypothesis the system tries to verify phrase relations implied by the question .For the question in Table 7 , it will be observed that the answer is likely to be a person ( indicated by \" who \" ) .", "label": "", "metadata": {}, "score": "61.831345"}
{"text": "The NPRS of an embodiment includes KnowledgeBase - query construction rules that are programmable to define how noun phrase objects are mapped to the query for each of the devices .[ 0091 ] .The system of an embodiment further comprises at least one database , wherein the knowledge manager transfers the query to the database .", "label": "", "metadata": {}, "score": "61.95417"}
{"text": "Words using the singular or plural number also include the plural or singular number respectively .Additionally , the words \" herein , \" \" hereunder , \" \" above , \" \" below , \" and words of similar import refer to this application as a whole and not to any particular portions of this application .", "label": "", "metadata": {}, "score": "61.965096"}
{"text": "Finally , the winning answer hypothesis can be presented to the user in conjunction with the documents and sentences in which it was found and the noun phrases that were used to verify it .In this way , the method shows not only what the answer is but why it was chosen .", "label": "", "metadata": {}, "score": "62.008842"}
{"text": "The patterns are assumed to correspond to particular linguistic relations .For example , if the user 's question begins , \" Who was the Chief Justice who presided over . . .\" , then the answer to the question can be in the form \" The Chief Justice was . . . \" .", "label": "", "metadata": {}, "score": "62.012115"}
{"text": "Syntactic Overview II - Verbs 5.1 .Syntactic orientation of verbs - A and O types 5.2 .Verbs with two transitive forms 5.3 .The principles of verbal syntax 5.3.1 .Passive 5.3.2 .Reduplication 5.3.3 .Object incorporation 5.3.4 .", "label": "", "metadata": {}, "score": "62.186302"}
{"text": "Language modeling : Computational modeling of natural language .Lexico - syntactic : Having to do with words , syntactic patterns , or both .Lexico - syntactic analysis is used in the invention to verify linguistic relations .List inclusion : The name of a particular lexico - syntactic pattern in which a noun is included in a list of related nouns .", "label": "", "metadata": {}, "score": "62.26627"}
{"text": "6.1.1 Verifying Type Phrases .The following relations are used by MURAX to try to verify answer hypotheses as instances of type phrases : .Apposition .This is exemplified by the match between the type phrase of the following question and the match sentence below it : .", "label": "", "metadata": {}, "score": "62.446327"}
{"text": "Another contemplated addition to MURAX , again within the scope of the invention , involves using alternate grammar formalisms for linguistic analysis .The linguistic analysis in the version of MURAX described above is based on an underlying regular grammar formalism , both in the HMM tagger and the phrase recognizers .", "label": "", "metadata": {}, "score": "62.482643"}
{"text": "Among the retrieved secondary documents , the answer extraction seeks a document that has the hypothesis as its title .If such a document is found , its content is examined to see , for example , whether it mentions birth and death dates and whether it contains a large number of personal pronouns such as \" he \" or \" she .", "label": "", "metadata": {}, "score": "62.490517"}
{"text": "A gazetteer can be used to provide information about place names .Step 280 can be performed using any number of different scoring techniques .The fact that a particular template is matched against a document for a particular hypothesis is assigned importance and adds to the score of the hypothesis .", "label": "", "metadata": {}, "score": "62.573242"}
{"text": "However , verification of other relations requires other question phrases to be included in the secondary query , as will now be described more fully .In all these secondary queries , answer hypotheses are included verbatim .6.2.1 Type Phrase Queries .", "label": "", "metadata": {}, "score": "62.638367"}
{"text": "The natural language processing system 100 takes as input the manual data ( e.g. , text ) 102 and identifies certain terms within the text through dialog system 108 .In one embodiment , the ontological determination component 104 assumes that candidate terms for recognition by the dialog system are noun phrases in the manual text 102 .", "label": "", "metadata": {}, "score": "62.784214"}
{"text": "The most general answer hypothesis in an equivalence class ( usually the one that serves as a title ) is assigned the cumulative score of all the members and used as the representative of the set .When a document title can be used as the representative , it usually provides the best description for the user .", "label": "", "metadata": {}, "score": "62.84117"}
{"text": "A narrowed version of the main verb query for Example 3 is shown below : . 5.2 Broadening .Broadening is performed to attempt to increase the number of hits .It is achieved in three ways in MURAX : .By increasing the co - occurrence scope of words within phrases , while at the same time dropping the requirement for strict ordering of the words .", "label": "", "metadata": {}, "score": "62.85535"}
{"text": "This provides the minimal necessary constraint on document matches .The detailed matching of all words in the type phrase is done by considering the degree of mismatch with the type phrase ( as in section 6.1.3 above ) .6.2.2 Co - Occurrence Queries .", "label": "", "metadata": {}, "score": "62.89277"}
{"text": "Embodiments of an ontological determination method for use in natural language systems are described .These methods learn ontological relations ( e.g. , hypernym and part - whole relations ) from manual data using lexico - syntactic patterns .In an embodiment , ontological relations in a noun - phrase utterance are extracted by using the term features and shallow / generalized lexico - syntactic patterns .", "label": "", "metadata": {}, "score": "62.935883"}
{"text": "The highest - ranked hypotheses are considered the best answers .Any number of scoring methods can be used .Scoring can be based in whole or in part on the verification evidence collected in step 260 .FIG .6 illustrates the component steps of hypothesis ranking .", "label": "", "metadata": {}, "score": "63.032528"}
{"text": "The mapping of an embodiment further comprises recognizing at least one parameter of the dialogue contribution .[ 0084 ] .The method of an embodiment further comprises scoring matches between variables of the description and the dialogue move components .[", "label": "", "metadata": {}, "score": "63.03318"}
{"text": "It would be left to the user to piece together the various documents thus retrieved to determine the correct answer .Attempts have been made in the prior art to allow users to formulate queries in natural language .One such attempt is found in systems called question - answering systems .", "label": "", "metadata": {}, "score": "63.099586"}
{"text": "A method of operating a processor - based computer system for computerized information retrieval to respond to an input string , the method comprising the steps of : . using a subsystem of said system to accept the input string ; . using a subsystem of said system to accept a set of primary documents ; . using a subsystem of said system to detect phrases in the primary documents ; . using a subsystem of said system to generate preliminary hypotheses based on phrases so detected ; . using a subsystem of said system to select preliminary hypotheses as answer hypotheses for verification , each of said answer hypotheses comprising a phrase detected in a document of said primary documents ; . using a subsystem of said system to determine linguistic relations implied by the input string ; . using a subsystem of said system to gather verification evidence for answer hypotheses ; and . using a subsystem of said system to rank answer hypotheses .", "label": "", "metadata": {}, "score": "63.121635"}
{"text": "However , doing this blindly runs into problems , as shown in 5.1 .Figure 5.1 : Location Detection by Simple Lookup for a News Story : Looking up every word in a gazetteer is error - prone ; case distinctions may help , but these are not always present .", "label": "", "metadata": {}, "score": "63.179558"}
{"text": "Each type of query can be handled by a different dialogue move ( corresponding to different devices or knowledge sources ) , but each set of \" Inputs \" can be inherited from a single \" Query \" dialogue move .[ 0052 ] .", "label": "", "metadata": {}, "score": "63.23327"}
{"text": "Add these patterns to the grammar , one per line .Test your work using some tagged sentences of your own devising .( Note that most chunking corpora contain some internal inconsistencies , such that any reasonable rule - based approach will produce errors . )", "label": "", "metadata": {}, "score": "63.349255"}
{"text": "For example , both tasks will make use of the information that nouns tend to follow adjectives ( in English ) .It would appear that the same information is being maintained in two places .Is this likely to become a problem as the size of the rule sets grows ?", "label": "", "metadata": {}, "score": "63.42474"}
{"text": "PART I. INTRODUCTION .Overview of the Invention .The present invention provides a method for answer extraction .A system operating according to this method accepts a natural - language input string such as a user - supplied question and a set of relevant documents that are assumed to contain the answer to the question .", "label": "", "metadata": {}, "score": "63.432755"}
{"text": "One approach to this problem involves building a very general representation of meaning ( 10 . )In this chapter we take a different approach , deciding in advance that we will only look for very specific kinds of information in text , such as the relation between organizations and locations .", "label": "", "metadata": {}, "score": "63.572502"}
{"text": "Information Extraction Architecture . 1.1 shows the architecture for a simple information extraction system .It begins by processing a document using several of the procedures discussed in 3 and 5 .: first , the raw text of the document is split into sentences using a sentence segmenter , and each sentence is further subdivided into words using a tokenizer .", "label": "", "metadata": {}, "score": "63.639626"}
{"text": "As you can see , the \" Be \" and \" As \" are no longer in the set of strings to be matched .The \" lead \" as a verb in the third example is also taken care of .", "label": "", "metadata": {}, "score": "63.67469"}
{"text": "Linking strategies can be adapted to the text corpus used in a particular embodiment .For example , if the corpus comprises encyclopedia articles , a hypothesis that appears in an article title is likely to refer to the article 's subject .", "label": "", "metadata": {}, "score": "63.727036"}
{"text": "Templates are so called because they contain one or more placeholders that can be filled in with hypotheses .When a hypothesis appears with other words in a sentence or phrase of a document in such a way as to satisfy the lexico - syntactic pattern of a template , that hypothesis is assumed to relate to the other words according to the linguistic relation to which the template corresponds .", "label": "", "metadata": {}, "score": "63.793587"}
{"text": "Additionally , it was confirmed that the answers to these questions were present in the encyclopedia -- that is , given a question and its answer , a person could find text in the encyclopedia from which the answer could be inferred using common sense .", "label": "", "metadata": {}, "score": "63.850075"}
{"text": "If this query is successful , then in step 266 it is determined whether the hypothesis and noun phrase are properly connected by the verb \" to be \" in one or more of the match sentences in which they appear .", "label": "", "metadata": {}, "score": "63.859848"}
{"text": "ya'i / ya'ina \" all over the place \" 17.2 .Prefix va'a- , causative , etc 17.3 .Prefix + i- deverbal 17.4 .A computerized method for organizing information retrieval based on the content of a set of primary documents .", "label": "", "metadata": {}, "score": "63.936386"}
{"text": "IS - A : The name of a particular lexico - syntactic pattern and linguistic relation .The IS - A relation uses forms of the verb \" to be \" to denote or assert the identity of or a characteristic of an object .", "label": "", "metadata": {}, "score": "64.024536"}
{"text": "Additional kinds of phrases can be detected as well .Step 220 is analyzed in more detail in section 4 below .The result of step 220 is an analysis of the input string .Step 220 can be performed by the answer extraction subsystem after receiving the input string .", "label": "", "metadata": {}, "score": "64.062004"}
{"text": "In some tasks it is useful to also consider indefinite nouns or noun chunks , such as every student or cats , and these do not necessarily refer to entities in the same way as definite NP s and proper names .", "label": "", "metadata": {}, "score": "64.10316"}
{"text": "Thus , in block 307 , the process differentiates the processing path for these two types of characteristics .Each processing path then operates on short - distant patterns to increase reliability .In general , it is not possible or highly impractical to enumerate all possible patterns .", "label": "", "metadata": {}, "score": "64.202705"}
{"text": "The goal of this chapter is to answer the following questions : .How can we build a system that extracts structured data , such as tables , from unstructured text ?What are some robust methods for identifying the entities and relationships described in a text ?", "label": "", "metadata": {}, "score": "64.23956"}
{"text": "In NLTK , we create a tree by giving a node label and a list of children : .We can incorporate these into successively larger trees as follows : .Here are some of the methods available for tree objects : .", "label": "", "metadata": {}, "score": "64.242966"}
{"text": "The short - distance coordinate relations are then generated , block 314 .This processing path finds the commonalities that provide some measure of back - off if an exact match of the two patterns does not occur , thus allowing the identification of one pattern as a more general version of the other .", "label": "", "metadata": {}, "score": "64.244644"}
{"text": "Confirming an answer hypothesis as a person 's name is important .In the encyclopedia , a reliable property of peoples ' names is that they have word - initial capital letters .This simple consideration significantly reduces the number of answer hypotheses that require further consideration .", "label": "", "metadata": {}, "score": "64.27925"}
{"text": "In a preferred embodiment the first phase is performed according to the method of the copending application entitled METHOD FOR COMPUTERIZED INFORMATION RETRIEVAL USING SHALLOW LINGUISTIC ANALYSIS , U.S. patent application Ser .No .08/085,446 , Xerox Docket No . D93183 , which is by the same inventor as the subject application , is filed concurrently with the subject application , and is incorporated herein by reference as if set out in full .", "label": "", "metadata": {}, "score": "64.35787"}
{"text": "This rule says that an NP chunk should be formed whenever the chunker finds an optional determiner ( DT ) followed by any number of adjectives ( JJ ) and then a noun ( NN ) .Using this grammar , we create a chunk parser , and test it on our example sentence .", "label": "", "metadata": {}, "score": "64.48277"}
{"text": "We find that this feature does indeed improve the chunker 's performance , by about 1.5 percentage points ( which corresponds to about a 10 % reduction in the error rate ) .Finally , we can try extending the feature extractor with a variety of additional features , such as lookahead features , paired features , and complex contextual features .", "label": "", "metadata": {}, "score": "64.53261"}
{"text": "So I decided to replace my SentenceAnnotator ( which annotated the text with sentence annotation markers ) with a NounPhraseAnnotator .This one also first splits the input text into sentences using the SentenceDetector , then for each sentence it tokenizes it into words using the Tokenizer , then find POS tags for each token using the POSTagger .", "label": "", "metadata": {}, "score": "64.629265"}
{"text": "This dialogue system can also include connections to external application - specific components such as ontologies or knowledge bases ( \" KB \" ) , as well as dialogue - enabled devices .[ 0003 ] .The DM of a dialogue system is an oversight module that facilitates the interaction between dialogue participants .", "label": "", "metadata": {}, "score": "64.71527"}
{"text": "Finally , the AE descriptor for the NounPhraseAnnotator .This is also pretty vanilla , the only non - standard block is the resource manager configuration which relates the OpenNLP model files with symbolic names used by the annotator .One other thing that you may notice is the reference to the TextAnnotator - as mentioned above , the ultimate goal is to replace the SentenceAnnotator which consumes TextAnnotations - that s why its here .", "label": "", "metadata": {}, "score": "64.737526"}
{"text": "These embodiments for use in a natural language processing system , as described herein can be used in various different applications , industries or industry segments , such as computing devices , industrial equipment , automobiles , airplanes , hand - held devices , cell - phones , and the like .", "label": "", "metadata": {}, "score": "64.7754"}
{"text": "They simply match text .SUMMARY OF THE INVENTION .The present invention provides a method for organizing information retrieval based on the content of a set of documents .The method generates answer hypotheses based on text found in the documents of the set and , typically , a natural - language input string such as a question .", "label": "", "metadata": {}, "score": "64.782486"}
{"text": "Somewhat surprisingly , we also find that error - driven pruning improves the performance of the probabilistic , lexicalized base noun phrase grammars by up to 1.0 % recall and 0.4 % precision , and does so even using the original pruning strategy that fails to distinguish the effects of lexicalization .", "label": "", "metadata": {}, "score": "64.908585"}
{"text": "The interrogative words that introduce a question are an important source of information .They indicate particular expectations about the answer and some of these are illustrated below in Table 6 .TABLE 6______________________________________Question Words and Expectations______________________________________Who / Whose : PersonWhat / Which : Thing , Person , LocationWhere : LocationWhen : TimeHow Many : Number _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "64.91676"}
{"text": "Phrase matching : Finding phrases that satisfy a lexicosyntactic pattern or other linguistic pattern .Predicate / argument match : Matching a particular lexicosyntactic pattern that represents argument structure .The pattern relates a verb and one or more associated nouns .", "label": "", "metadata": {}, "score": "64.92439"}
{"text": "Techniques other than template matching can be used for detecting lexico - syntactic patterns ; for example a rule set can be used .Sophisticated linking techniques , for example techniques involving heuristics and rule sets , can be used .Also in step 260 , non - lexico - syntactic approaches to hypothesis verification can be used in place of or in addition to lexico - syntactic hypothesis verification .", "label": "", "metadata": {}, "score": "64.95158"}
{"text": "The tree structure of the DMT 108 specifically supports multi - threaded , multi - topic conversations , where a new conversation topic spawns a new branch ( see Lemon , O. , A. Gruenstein , S. Peters ( 2002 ) . \"", "label": "", "metadata": {}, "score": "65.003494"}
{"text": "Consequently , any prepositional phrases or subordinate clauses that modify a nominal will not be included in the corresponding NP -chunk , since they almost certainly contain further noun phrases .One of the most useful sources of information for NP -chunking is part - of - speech tags .", "label": "", "metadata": {}, "score": "65.09325"}
{"text": "If you read through ( 1 ) , you will glean the information required to answer the example question .But how do we get a machine to understand enough about ( 1 ) to return the answers in 1.2 ?This is obviously a much harder task .", "label": "", "metadata": {}, "score": "65.14391"}
{"text": "As shown in .FIG .3 , the short - distance patterns for both the coordinate terms and ontological relations are generalized in steps 310 and 311 , respectively .FIG .4 is a flowchart that illustrates a method of generalizing patterns in an ontological learning process , under an embodiment .", "label": "", "metadata": {}, "score": "65.157295"}
{"text": "Arguments that are marked as \" required \" may generate sub - dialogues when a user - command is given with missing arguments .[0044 ] .The device - encapsulation approach , and in particular the dialogue move scripting language and NP - resolution rules described here , may be applied to an initial domain , controlling an MP3 music player and accessing a music database , for example .", "label": "", "metadata": {}, "score": "65.23378"}
{"text": "The method of .claim 3 , wherein generating the query includes translating a noun phrase of the description into the object .The method of .claim 1 , wherein the description is a structured language - based description that includes at least one of a semantic description , a syntactic description , phonological information , utterance - level information , and topic - classification of the dialogue contribution .", "label": "", "metadata": {}, "score": "65.33188"}
{"text": "A \" How many . . .\"question calls for a number .Put another way , lexico - syntactic patterns inform the answer extraction subsystem about the kind of evidence that must be gathered in order to verify the hypotheses .", "label": "", "metadata": {}, "score": "65.34478"}
{"text": "Before the activity can actually be sent to the device for execution , the RNDS 200 attempts to fully \" resolve \" it , e.g. resolving all referring NPs or spawning a sub - dialogue to elicit further information .Revisions and corrections ( e.g. \" I meant / said . . .", "label": "", "metadata": {}, "score": "65.37427"}
{"text": "Along the way , we 'll apply techniques from the last two chapters to the problems of chunking and named - entity recognition .1 Information Extraction .Information comes in many shapes and sizes .One important form is structured data , where there is a regular and predictable organization of entities and relationships .", "label": "", "metadata": {}, "score": "65.375824"}
{"text": "Still more sophisticated strategies , including strategies not limited to the three criteria described above , can be used .Such strategies can include the use of semantic information .8.2 Omitting Certain Method Steps .The method of the present invention is a method for organizing information retrieval based on the content of a set of documents .", "label": "", "metadata": {}, "score": "65.390625"}
{"text": "This strategy however does not necessarily resolve all device - ambiguities ; for example an address - book may be used by both a phone - device ( \" get John on the phone \" ) as well as a navigation service ( \" how do I get to John 's house ? \" ) [", "label": "", "metadata": {}, "score": "65.424515"}
{"text": "A noun phrase is a word sequences that consists of a noun , its modifiers such as adjectives and other nouns , and possibly a definite or indefinite article .Step 310 comprises steps 311 and 312 .In step 311 the tagged input string is analyzed to detect the maximal - length simple noun phrases that it contains .", "label": "", "metadata": {}, "score": "65.47318"}
{"text": "FIG .3 uses the term features and shallow / generalized lexico - syntactic patterns to identify ontological relations between the noun phrases in the document .Features and patterns are used in the CME framework to identify coordinate relations and short - distance hypernym / part - whole relations .", "label": "", "metadata": {}, "score": "65.49025"}
{"text": "When a phrase match is verified , this is evidence that the relation holds ; that is , text has been found in the corpus that supports the existence of the relation .PART II .AN EMBODIMENT OF THE METHOD .", "label": "", "metadata": {}, "score": "65.490585"}
{"text": "However , this still requires incoming forms to be mapped to the internal representation .[ 0047 ] .The dialogue - scripting language for writing the DMS 102 of an embodiment promotes re - use of dialogue moves , enhances extensibility , and copes with semantic variation across domains .", "label": "", "metadata": {}, "score": "65.519646"}
{"text": "Further , using off - the - shelf parsers with wide - coverage grammars , or corpus - trained statistical parsers , required the dialogue manager to be able to handle new input semantic forms .The requirement of broad coverage dictated that the mapping from input to correct dialogue move be easily extensible .", "label": "", "metadata": {}, "score": "65.5334"}
{"text": "Note .This cascading process enables us to create deep structures .However , creating and debugging a cascade is difficult , and there comes a point where it is more effective to do full parsing ( see 8 . )Also , the cascading process can only produce trees of fixed depth ( no deeper than the number of stages in the cascade ) , and this is insufficient for complete syntactic analysis . 4.2 Trees .", "label": "", "metadata": {}, "score": "65.6003"}
{"text": "The description of an embodiment is a structured language - based description that includes at least one of a semantic description , a syntactic description , phonological information , utterance - level information , and topic - classification of the dialogue contribution .", "label": "", "metadata": {}, "score": "65.82391"}
{"text": "[0058 ] .The dialogue scripting language of an embodiment provides a mechanism for specifying attachment rules .These attachment rules determine the types of dialogue moves that can attach to existing active nodes in the DMT .Dialogue move information can be scripted \" in place \" inside one of these specifications ( as done for the \" WhQuestion : fill : play \" move ) .", "label": "", "metadata": {}, "score": "65.83817"}
{"text": "In general , multiple matches are possible , since there are generally multiple scripted dialogue moves and multiple entries in each move 's \" Input \" section .The RNDS DM 100 of an embodiment scores each possible match using generic criteria ( e.g. applicability to current context ; minimizing unresolved information ) .", "label": "", "metadata": {}, "score": "65.869736"}
{"text": "This fact can be used to advantage because various heuristics can be applied to verify whether a noun phrase is a person 's name .A question introduced by \" what \" may or may not refer to a person ; however , other characteristics can be exploited .", "label": "", "metadata": {}, "score": "65.90323"}
{"text": "It has other shortcomings too .Let 's see what happens when we apply this chunker to a sentence having deeper nesting .Notice that it fails to identify the VP chunk starting at .The solution to these problems is to get the chunker to loop over its patterns : after trying all of them , it repeats the process .", "label": "", "metadata": {}, "score": "65.95439"}
{"text": "When the primary documents do not provide sufficient evidence to verify a hypothesis , the method attempts to find such evidence elsewhere in the database .Specifically , the method constructs additional IR queries called secondary queries and executes the secondary queries to retrieve additional documents called secondary documents .", "label": "", "metadata": {}, "score": "65.986145"}
{"text": "This structure description may include one or more of syntactic , semantic , and phonological information , as well as utterance - wide information such as topic classification .A DMS is selected for use in identifying 304 the description and at least one parameter of the description .", "label": "", "metadata": {}, "score": "66.100784"}
{"text": "The apparatus of . claim 10 , wherein the natural language processing system is selected from the group consisting of a reasoning system , a question and answer system , an information retrieval system , a machine translation system , and a semantic inference system .", "label": "", "metadata": {}, "score": "66.173706"}
{"text": "For each chunk , it checks its type and only noun - phrases ( NP ) are annotated .The SentenceDetector , Tokenizer , POSTagger and Chunker are all OpenNLP components , each backed by their own maximum entropy based models .", "label": "", "metadata": {}, "score": "66.381134"}
{"text": "1 ) .DETAILED DESCRIPTION .[ 0015 ] .Representation - neutral dialogue systems and methods are described that include multi - application , multi - device spoken - language dialogue systems based on the information - state update approach .", "label": "", "metadata": {}, "score": "66.57455"}
{"text": "Higher frequency phrases are dropped before lower frequency ones .Title phrases are tried before any of their component noun phrases .Complete phrases are used before their subphrases .The iterative process of broadening and narrowing terminates when either a threshold on the number of hits has been reached , or no further useful queries can be made .", "label": "", "metadata": {}, "score": "66.70349"}
{"text": "If linking is performed in step 270 then equivalent linked hypotheses are eliminated prior to sorting .For each set of linked hypotheses , a representative member is selected , for example , the hypothesis containing the greatest number of words .", "label": "", "metadata": {}, "score": "66.83406"}
{"text": "Section 6 explains the answer extraction phase , which is carried out in MURAX according to the method of the present invention .Section 7 presents a performance evaluation of MURAX .Task Selection .MURAX 's task is to answer certain general - knowledge questions using a text corpus that comprises an encyclopedia .", "label": "", "metadata": {}, "score": "66.86047"}
{"text": "For convenience , there is also a text format for specifying trees : .( S ( NP Alice ) ( VP ( V chased ) ( NP ( Det the ) ( N rabbit ) ) ) ) .Although we will focus on syntactic trees , trees can be used to encode any homogeneous hierarchical structure that spans a sequence of linguistic forms ( e.g. morphological structure , discourse structure ) .", "label": "", "metadata": {}, "score": "66.88457"}
{"text": "Most verbs come in both transitive and intransitive forms , and nouns can be build up regularly from verbal parts and verbs from nouns .The language is also marked by a highly developed pronoun system and by a vocabulary rich in areas of social significance .", "label": "", "metadata": {}, "score": "66.91731"}
{"text": "Primary query : A query that is based only on phrases from the user 's question .Query : An expression involving words , Boolean operators and proximity constraints that is used by an information retrieval system to search a corpus and return text that matches the expression .", "label": "", "metadata": {}, "score": "66.939835"}
{"text": "The dialogue context is then used to interpret incoming utterances ( including fragments and revisions ) , resolve noun phrases ( \" NPs \" ) , construct salient responses , track issues , etc .[ 0041 ] .The two central RNDS DM 100 components of the dialogue information state are the DMT 108 and the AT 110 .", "label": "", "metadata": {}, "score": "67.1182"}
{"text": "The generalization step identifies the patterns that share common elements and hooks onto these common patterns and ignores the patterns that are different .This results in short - distance pattern generalization .In block 312 , the short - distance coordinate terms are identified based on the original and generalized patterns .", "label": "", "metadata": {}, "score": "67.14231"}
{"text": "Stress 2.5 .Intonation 2.6 .Diachronic change 3 .Word 3.1 .Phonological word 3.2 .Grammatical word 3.2.1 .Roots 3.2.2 .Affixes 3.2.3 .Function items 3.2.4 .Pronouns 4 .Syntactic Overview I - Clause and Phrase Structure 4.1 .", "label": "", "metadata": {}, "score": "67.17467"}
{"text": "[ 0018 ] .The RNDS scripts are combined with other information from the core dialogue management architecture ( e.g. , Activity Models ( \" AM \" ) ) to provide a plug - and - play capability in the RNDS .", "label": "", "metadata": {}, "score": "67.18909"}
{"text": "Named entity recognition is a task that is well - suited to the type of classifier - based approach that we saw for noun phrase chunking .In particular , we can build a tagger that labels each word in a sentence using the IOB format , where chunks are labeled by their appropriate type .", "label": "", "metadata": {}, "score": "67.24696"}
{"text": "Question Processing .This section examines step 220 , question processing , in detail .In one embodiment question processing comprises shallow linguistic analysis of the natural language input string , which is typically ( but not necessarily ) in the form of a question .", "label": "", "metadata": {}, "score": "67.26366"}
{"text": "Now let 's try a naive regular expression chunker that looks for tags beginning with letters that are characteristic of noun phrase tags ( e.g. CD , DT , and JJ ) .As you can see , this approach achieves decent results .", "label": "", "metadata": {}, "score": "67.27698"}
{"text": "For the short - distance coordinate relations , the process executes block 506 in which , within each sentence , coordinate terms X and Y are inserted into the same group when they are short distance coordinate terms and X , Z and Z , Y are short term coordinate terms .", "label": "", "metadata": {}, "score": "67.32395"}
{"text": "If a tag pattern matches at overlapping locations , the leftmost match takes precedence .For example , if we apply a rule that matches two consecutive nouns to a text containing three consecutive nouns , then only the first two nouns will be chunked : .", "label": "", "metadata": {}, "score": "67.33787"}
{"text": "Non - relation terms are those terms that have never been involved in any relation .A lexico - syntactic pattern consists of term features of two target terms and word strings between the two target terms .A generalized pattern is the maximum common sub - string from a set of patterns with the same verb .", "label": "", "metadata": {}, "score": "67.36444"}
{"text": "CONCLUSION .The present invention provides a method for information retrieval based on the content of documents .In one embodiment of the invention , a natural - language input string and primary documents are accepted and analyzed by an answer extraction subsystem .", "label": "", "metadata": {}, "score": "67.38127"}
{"text": "The dialogue - scripting language of an embodiment also defines direct mappings of input semantic forms to appropriate dialogue moves .Further , the dialogue - scripting language provides attachment rules for information update .Additionally , the dialogue - scripting language provides other dialogue move - specific information , such as specification of output to be generated for disambiguation , requests for required information , to name a few .", "label": "", "metadata": {}, "score": "67.43394"}
{"text": "The \" information - state model \" is a modeling approach that models a context - dependent method of interpreting every contribution by participants to a conversation ( objects and other knowledge introduced into the conversation by the participants make up the context ) .", "label": "", "metadata": {}, "score": "67.452484"}
{"text": "The NPRS of an embodiment includes KnowedgeBase - query construction rules that are programmable to define how noun phrase objects are mapped to the query for each of a plurality of devices .[0081 ] .Generating the query of an embodiment includes translating a noun phrase of the description into the object .", "label": "", "metadata": {}, "score": "67.490105"}
{"text": "In step 263 , which is executed for each hypothesis , the templates are filled in with the hypothesis under consideration .That is , the hypothesis under consideration is substituted for a placeholder or placeholders in the template .6.5 Matching Templates Against Primary Documents .", "label": "", "metadata": {}, "score": "67.5007"}
{"text": "For example , in a document match , a relation may not be verified because such verification requires more sophisticated analysis than is feasible with a simple finite - state grammar .However , the relation may be expressed in several places in the encyclopedia and thus more simply in some places , which improves the chances that it can be verified .", "label": "", "metadata": {}, "score": "67.540054"}
{"text": "RegexpParser .Discuss any tag sequences that are difficult to chunk reliably .Develop a chunker that starts by putting the whole sentence in a single chunk , and then does the rest of its work solely by chinking .Determine which tags ( or tag sequences ) are most likely to make up chinks with the help of your own utility program .", "label": "", "metadata": {}, "score": "67.54775"}
{"text": "If you wish to work through The Reasoned Schemer with core.logic make sure to look over this first .Roadmap .The following are tentative current and future directions : .Environment Trimming - Definite Clause Grammars ( DCGs ) are quite slow in miniKanren .", "label": "", "metadata": {}, "score": "67.59354"}
{"text": "We will begin by considering the task of noun phrase chunking , or NP - chunking , where we search for chunks corresponding to individual noun phrases .For example , here is some Wall Street Journal text with NP -chunks marked using brackets : .", "label": "", "metadata": {}, "score": "67.7082"}
{"text": "Logic variables are instances of LVar not vectors as they are in Scheme .The goal and goal constructor portion has been written from scratch on top of the protocols and makes liberal use of lazy sequences to prevent stack overflow .", "label": "", "metadata": {}, "score": "67.71954"}
{"text": "We can also add a feature for the previous part - of - speech tag .Adding this feature allows the classifier to model interactions between adjacent tags , and results in a chunker that is closely related to the bigram chunker .", "label": "", "metadata": {}, "score": "67.721115"}
{"text": "d ? n ] ] ( det ?d ) ( noun ?n ) ) ) .( [ [ : vp ?v ? np ] ] ( verb ?v ) ( noun - phrase ? np ) ) ) .", "label": "", "metadata": {}, "score": "67.72393"}
{"text": "This is because too few words are involved in the relation in comparison to other phrase matches , so the appropriate sentence does not rank high enough to be in the selected primary documents .It is also possible that appropriate verification information is not expressed in any primary document and depends only on the answer hypothesis .", "label": "", "metadata": {}, "score": "67.88606"}
{"text": "a first processor identifying relations by extracting terms from the noun phrase portions to distinguish relation terms from non - relation terms , .a second processor identifying coordinate relations for every pair of adjacent terms , .The apparatus of .", "label": "", "metadata": {}, "score": "67.89616"}
{"text": "Such patterns represent a kind of \" back - off \" condition .In block 308 , the short - distance pattern is generated for coordinate terms .This comprises essentially the pure extraction of certain patterns .The short - distance patterns are then generalized for the coordinate terms , block 310 .", "label": "", "metadata": {}, "score": "67.92035"}
{"text": "The method of claim 1 further comprising the step of using the processor to consult at least one reference document .The method of claim 1 in which said phrase contains a single word .The method of claim 1 in which said phrase contains a plurality of words .", "label": "", "metadata": {}, "score": "67.920654"}
{"text": "Note .We have added a comment to each of our chunk rules .These are optional ; when they are present , the chunker prints these comments as part of its tracing output . 2.4 Exploring Text Corpora .In 2 we saw how we could interrogate a tagged corpus to extract phrases matching a particular sequence of part - of - speech tags .", "label": "", "metadata": {}, "score": "67.92177"}
{"text": "Match sentences in secondary documents are a supplementary means of confirming phrase relations .Secondary documents are found via secondary queries that are constructed by MURAX and passed to the IR system .Broadening is applied as necessary to secondary queries , but terms are never dropped because they are required in the resulting matches .", "label": "", "metadata": {}, "score": "67.93099"}
{"text": "In lexico - syntactic analysis for this example , the answer extraction subsystem constructs or generates one or more appropriate match templates based on word patterns in the input string .To do so it uses part - of - speech information about these words , such as that generated during question processing .", "label": "", "metadata": {}, "score": "67.987366"}
{"text": "It will be appreciated that in some embodiments two or more of the processes described above can be integrated into a single process as modules of that process .For example , the primary query construction subsystem and IR subsystem can be implemented as modules of a single process in some embodiments , or the primary query construction subsystem and an answer extraction subsystem can be implemented as modules of a single process in some embodiments .", "label": "", "metadata": {}, "score": "68.002594"}
{"text": "The answer hypotheses for \" Where . . .\" questions are likely to be locations , which often appear with locative prepositions or as arguments to verbs of motion .Questions of the form \" When . . .\" often expect answer hypotheses that are dates or times and the expectation of questions beginning \" How many . . .", "label": "", "metadata": {}, "score": "68.08438"}
{"text": "The use of multiple criteria for the determination of the final score leads to more robust system performance than would be obtained with single criteria used in isolation .Through the use of multiple scoring criteria , the system can determine one or two best possible answer hypotheses in the context of articles that are most likely to be relevant . 7.2 Merging Scores .", "label": "", "metadata": {}, "score": "68.09814"}
{"text": "\" or \" Whose . . .\" often calls for a person 's name as an appropriate answer .A \" Where . . .\" question typically calls for a location or place name , and a \" When . . .", "label": "", "metadata": {}, "score": "68.12529"}
{"text": "It is assumed that the IR system can process the following kinds of primitive queries , as well as compound queries constructed of these primitives : .The Boolean AND of terms , denoted here as : .[ term 1 term 2 . . .", "label": "", "metadata": {}, "score": "68.17074"}
{"text": "In other words , we can build a chunker using a unigram tagger ( 4 ) .But rather than trying to determine the correct part - of - speech tag for each word , we are trying to determine the correct chunk tag , given each word 's part - of - speech tag .", "label": "", "metadata": {}, "score": "68.17298"}
{"text": "In some embodiments , step 287 incorporates selecting which documents to present from numerous documents containing the best answer hypothesis .For example , if many documents match the best answer hypothesis , the one or two documents having the shortest matching sentences containing the hypothesis can be selected for presentation .", "label": "", "metadata": {}, "score": "68.187645"}
{"text": "claim 3 , further comprising retrieving at least one object referenced by object descriptions from the dialogue contribution from at least one database in response to the query .The method of .claim 4 , wherein the object descriptions include noun - phrases .", "label": "", "metadata": {}, "score": "68.20024"}
{"text": "Exact matching of the overall noun phrase is done after all match sentences are found .When comparing type phrases with answer hypotheses , the minimum degree of mismatch is considered best .This is illustrated by considering the first question in section 6.1.1 above and the associated match sentences ( 1 ) and ( 2 ) .", "label": "", "metadata": {}, "score": "68.20066"}
{"text": "Now that we can access a chunked corpus , we can evaluate chunkers .We start off by establishing a baseline for the trivial chunk parser cp that creates no chunks : .The IOB tag accuracy indicates that more than a third of the words are tagged with O , i.e. not in an NP chunk .", "label": "", "metadata": {}, "score": "68.20074"}
{"text": "The rules that make up a chunk grammar use tag patterns to describe sequences of tagged words .Tag patterns are similar to regular expression patterns ( 3.4 ) .Now , consider the following noun phrases from the Wall Street Journal : . another / DT sharp / JJ dive / NN trade / NN figures / NNS any / DT new / JJ policy / NN measures / NNS earlier / JJR stages / NNS Panamanian / JJ dictator / NN Manuel / NNP Noriega / NNP .", "label": "", "metadata": {}, "score": "68.26897"}
{"text": "After scoring and ranking the preliminary hypotheses , the method selects the top - ranked preliminary hypotheses and attempts to verify them .For each selected hypothesis , the method attempts to gather additional evidence to support the conclusion that the hypothesis is the correct answer .", "label": "", "metadata": {}, "score": "68.35266"}
{"text": "The queries are used to search the encyclopedia to find a list of relevant articles .The relevant articles are heuristically scored according to the degree and number of matches with the phrases of the input question .Matching head words in a noun phrase receive double the score of other matching words in a phrase .", "label": "", "metadata": {}, "score": "68.36125"}
{"text": "Your Turn : Try to come up with tag patterns to cover these cases .Test them using the graphical interface nltk.app.chunkparser ( ) .Continue to refine your tag patterns with the help of the feedback given by this tool . 2.3 Chunking with Regular Expressions .", "label": "", "metadata": {}, "score": "68.368546"}
{"text": "HMM 's are probabilistic and their parameters can be estimated by training on a sample of ordinary untagged text .Once trained , the Viterbi algorithm is used for tagging .This gave an overall error rate of 4 % ( corresponding to an error rate of 11.2 % on words that can assume more than one part - of - speech category ) .", "label": "", "metadata": {}, "score": "68.38905"}
{"text": "The term features in the noun phrases are then extracted to distinguish the domain terms , block 304 .The term features are used distinguish domain and non - domain related terms .In block 306 , the process generates sentences labeled with NP chunks and term features .", "label": "", "metadata": {}, "score": "68.422455"}
{"text": "Each NP can comprise domain terms and domain - related terms .A domain - related term is a concrete concept that represents a general device ( e.g. computer ) , that is not a specific domain - specific item ( e.g. , a particular computing device ) .", "label": "", "metadata": {}, "score": "68.4898"}
{"text": "The user does not have to piece together the answer by hunting through the documents .Instead , the invention highlights the answer hypothesis , in this case \" Key Largo , \" in the retrieved documents for the user 's convenience .", "label": "", "metadata": {}, "score": "68.50834"}
{"text": "In succeeding chapters , he examines a number of grammatical topics in greater detail , including clause and phrase structure , verbal syntax , deictics , and anaphora .The volume also includes a full vocabulary of all forms treated in discussion and three of the fifteen texts recorded from monolingual village elders on which the grammar is based .", "label": "", "metadata": {}, "score": "68.6155"}
{"text": "Typically the nouns of the list indicate objects of the same type , and are separated within the list by commas or semicolons .Match sentences : Sentences in a document that cause or help cause the document to be retrieved in response to a query .", "label": "", "metadata": {}, "score": "68.670395"}
{"text": "A method of operating a processor - based computer system including at least one processor to organize information retrieval based on the content of a set of documents , the method comprising the steps of : . using a processor to accept an input string comprising an ordered set of words ; . using a processor to accept the set of documents ; . using a processor to analyze the content of at least one document of the set ; . using a processor to generate automatically an answer hypothesis likely to be relevant to said input string , said answer hypothesis being generated responsively to said document content thus analyzed , said answer hypothesis comprising a phrase ; . using a processor to verify the answer hypothesis by gathering evidence for a plurality of answer hypotheses ; and . using a processor to determine a best answer hypothesis from among said plurality of answer hypotheses according to the evidence thus gathered .", "label": "", "metadata": {}, "score": "68.700836"}
{"text": "The answer hypotheses can include phrases or words not present in the input string .Answer hypotheses are verified and ranked based on their verification evidence .A text corpus can be queried to provide verification evidence not present in the primary documents .", "label": "", "metadata": {}, "score": "68.74386"}
{"text": "These should be self - explanatory , except for \" Facility \" : human - made artifacts in the domains of architecture and civil engineering ; and \" GPE \" : geo - political entities such as city , state / province , and country .", "label": "", "metadata": {}, "score": "69.00255"}
{"text": "( Obtain some raw Treebank or CoNLL data from the NLTK Corpora , save it to a file , and then use for line in open(filename ) to access it from Python . )Investigate other models of the context , such as the n-1 previous part - of - speech tags , or some combination of previous chunk tags along with previous and following part - of - speech tags .", "label": "", "metadata": {}, "score": "69.0067"}
{"text": "The third criterion is the preliminary hypothesis score developed in step 240 , which is based on the scores of the primary document match sentences from which the hypothesis derives .In one specific embodiment the scoring of an answer hypothesis can be performed as follows : The first criterion -- that is , scoring based on verification evidence -- is applied when the input string is a question having a type phrase .", "label": "", "metadata": {}, "score": "69.01438"}
{"text": "As the dialogue manager was applied to new applications , new dialogue moves were implemented as appropriate to the applications , or existing dialogue moves refined to apply to the new application .Multiple applications were implemented in this way .[ 0046 ] .", "label": "", "metadata": {}, "score": "69.032455"}
{"text": "Simple noun phrase : A noun phrase that does not contain prepositional phrases or conjunctions .Tagging :The assignment of part - of - speech categories to words .Type phrase : A phrase in a question that indicates the nature of the answer , e.g. , \" What river . . .", "label": "", "metadata": {}, "score": "69.0325"}
{"text": "Here , NP(Justice ) means a noun phrase containing \" Justice .When a question has no type phrase associated with it , lexico - syntactic analysis is performed , although not of the type - phrase variety .For example , the template \" X ( won , wins ) twenty Oscars \" can be generated and matched for the input string \" Who won twenty Oscars ? \"", "label": "", "metadata": {}, "score": "69.03622"}
{"text": "[0097 ] .[ 0098 ] .[0099 ] .The generic dialogue scripts of an embodiment include dialogue move scripts ( DMS ) and noun phrase - resolution scripts ( NPRS ) .[ 0100 ] .The method of an embodiment further comprises receiving additional ones of the generic dialogue scripts , wherein the additional ones extend at least one of the domains , device , and applications that interact with the dialogue management system .", "label": "", "metadata": {}, "score": "69.07026"}
{"text": "Interaction with external devices is mediated by Activity Models ( \" AMs \" ) , i.e. declarative specifications of device capabilities and their relationships to linguistic processes .[ 0004 ] .The conventional dialogue management systems range from the commercially widely - used yet more constrained dialogue - modeling mechanisms based on voice extensible markup language ( \" VXML \" ) , to semantic models based on the TrindiKit approach to information - state update .", "label": "", "metadata": {}, "score": "69.1806"}
{"text": "The parse method takes a tagged sentence as its input , and begins by extracting the part - of - speech tags from that sentence .It then tags the part - of - speech tags with IOB chunk tags , using the tagger self.tagger that was trained in the constructor .", "label": "", "metadata": {}, "score": "69.23015"}
{"text": "[0002 ] .Dialog includes language of a conversation between participants as well as a shared central context constructed by the participants to a conversation ( e.g. , references later in a conversation to \" it \" refer to something described earlier in the conversation ) .", "label": "", "metadata": {}, "score": "69.25687"}
{"text": "If you 're interested in using core.logic from ClojureScript look here .Contributing .Immediate Roadmap .The following are avenues we are interesting in pursuing now : .Fair Conjunction - currently many finite programs diverge if recursive goals are not carefully ordered .", "label": "", "metadata": {}, "score": "69.29703"}
{"text": "However , there are indirect clues that can be used to verify that an answer hypothesis is a name .Encyclopedia articles about a person generally have the person 's name as the title and typically mention birth and/or death dates , which can easily be identified , at the beginning of the article .", "label": "", "metadata": {}, "score": "69.31313"}
{"text": "Cues other than or in addition to text formatting can be used to detect title phrases .Most generally , any technique can be used that converts the natural language input string into phrases -- that is , contiguous , relatively short sequences of words .", "label": "", "metadata": {}, "score": "69.32666"}
{"text": "NLTK provides a classifier that has already been trained to recognize named entities , accessed with the function nltk.ne_chunk ( ) .6 Relation Extraction .Once named entities have been identified in a text , we then want to extract the relations that exist between them .", "label": "", "metadata": {}, "score": "69.33977"}
{"text": "Predicate / argument matches are used to produce preferences among different answer hypotheses .For who questions , an answer hypothesis that is verified as a person takes precedence .Answer hypotheses are ranked in terms of their co - occurrence with question phrases .", "label": "", "metadata": {}, "score": "69.39284"}
{"text": "Somewhat better results can be expected if sentence or paragraph level matching is done .However , the resulting text matches do not have the benefit of being correlated in terms of a particular answer , and they muddle information for different answer hypotheses .", "label": "", "metadata": {}, "score": "69.4398"}
{"text": "In this case a completed analysis of the input string is supplied to the answer extraction subsystem as additional input along with the input string and primary documents in step 200 .In step 240 the answer extraction subsystem generates preliminary hypotheses from the analyzed input string and the primary documents .", "label": "", "metadata": {}, "score": "69.44145"}
{"text": "Rather , the scope of the invention is defined by the appended claims along with the full scope of equivalents to which such claims are entitled .# # SPC1 # # Performance is a central concern of this project .Anything that makes it slower will probably not be adopted .", "label": "", "metadata": {}, "score": "69.44843"}
{"text": "The template matching procedure can incorporate the construction and execution of secondary queries .Step 260 is described in more detail in section 5 below .The result of step 260 is a set of verification evidence and optional linking information for each hypothesis .", "label": "", "metadata": {}, "score": "69.451416"}
{"text": "[ 0086 ] .The plurality of dialogue moves of an embodiment is adapted for use across at least one different domain and application via reprogramming of the DMS .[ 0087 ] .The dialogue manager of an embodiment further comprises a noun phrase resolver coupled to a plurality of noun phrase - resolution scripts ( NPRSs ) and a plurality of rules , wherein each NPRS corresponds to at least one of the device and the application .", "label": "", "metadata": {}, "score": "69.48046"}
{"text": "Finally , it uses conlltags2tree to convert the result back into a chunk tree .Now that we have UnigramChunker , we can train it using the CoNLL 2000 corpus , and test its resulting performance : .evaluate(test_sents ) )ChunkParse score : IOB Accuracy : 92.9 % Precision : 79.9 % Recall : 86.8 % F - Measure : 83.2 % .", "label": "", "metadata": {}, "score": "69.55173"}
{"text": "The above is quite slow since we have to walk the data structure and replace the logic var symbols .It 's more efficient to prep the expressions before hand if you 're going to be unifying the same expressions over and over again .", "label": "", "metadata": {}, "score": "69.56412"}
{"text": "This is a four - stage chunk grammar , and can be used to create structures having a depth of at most four .( \" sit \" , \" VB \" ) , ( \" on \" , \" IN \" ) , ( \" the \" , \" DT \" ) , ( \" mat \" , \" NN \" ) ] .", "label": "", "metadata": {}, "score": "69.584564"}
{"text": "[ 0060 ] .Much of the RNDS output is automatically generated , e.g. encoded in general - purpose dialogue moves .However , applications may call for domain- and device - specific outputs .These domain- and device - specific outputs can also be encoded in the DMS 102 of an embodiment ; since these outputs will be system responses , these are encoded inside \" System \" dialogue moves .", "label": "", "metadata": {}, "score": "69.628586"}
{"text": "In some embodiments certain steps of the method , such as verification , can be omitted .In some embodiments the input string can be omitted .In another aspect the present invention is used in the context of a larger , two - phase method for information retrieval in response to a user - supplied natural - language input string such as a question .", "label": "", "metadata": {}, "score": "69.634346"}
{"text": "The following example searches for strings that contain the word in .The special regular expression ( ? !\\b.+ing\\b ) is a negative lookahead assertion that allows us to disregard strings such as success in supervising the transition of , where in is followed by a gerund .", "label": "", "metadata": {}, "score": "69.79627"}
{"text": "The association of hypotheses with match sentences implies a further association between hypotheses and the match sentence scores determined in step 245 .Each preliminary hypothesis can be assigned a preliminary score based on the scores of the match sentences with which it is associated .", "label": "", "metadata": {}, "score": "69.844986"}
{"text": "Other methods have used hypernym relations as semantic constrains to extract part - whole relations .Another prior art method has combined coordinate term identification and dependency path methods to automatically find hypernym relations in large documents , such as a large news corpus .", "label": "", "metadata": {}, "score": "69.84596"}
{"text": "Verification is accomplished by lexico - syntactic analysis which looks for certain patterns in the user 's question and attempts to find corresponding or related patterns in documents .If the corresponding or related patterns are found in conjunction with a hypothesis , this is considered evidence in favor of the hypothesis .", "label": "", "metadata": {}, "score": "69.89797"}
{"text": "The input , question processing , and preliminary hypothesis generation , and output steps are performed .The hypothesis ranking step collapses into the steps of ranking and selecting of preliminary hypotheses , and the hypotheses ' preliminary scores become their final scores .", "label": "", "metadata": {}, "score": "69.93868"}
{"text": "Longer distances are defined as greater than trigram , such as A , D. .Two terms that share the same hypernym / holonym parent semantically are coordinate terms .Syntactically , for a pattern such as \" A includes X and Y \" , X and Y are coordinate terms .", "label": "", "metadata": {}, "score": "69.969345"}
{"text": "These have the benefit that each chunk is a constituent that can be manipulated directly .An example is shown in 2.6 .NLTK uses trees for its internal representation of chunks , but provides methods for reading and writing such trees to the IOB format .", "label": "", "metadata": {}, "score": "70.08887"}
{"text": "Regular expression : A specification of functions in the finitestate calculus .Relation ; phrase relation : A linguistic relation between words or phrases , or between a word or phrase and a certain property ( e.g. , the property of being a person 's name ) .", "label": "", "metadata": {}, "score": "70.112946"}
{"text": "Now you have a taste of what chunking does , but we have n't explained how to evaluate chunkers .As usual , this requires a suitably annotated corpus .We begin by looking at the mechanics of converting IOB format into an NLTK tree , then at how this is done on a larger scale using a chunked corpus .", "label": "", "metadata": {}, "score": "70.14022"}
{"text": "The relative pronoun indicates that the answer also \" ran for mayor of New York City \" .Phrase matching procedures ( detailed in section 6 ) perform the verification using the answer hypotheses and the primary documents .Verification is not limited to primary documents .", "label": "", "metadata": {}, "score": "70.38711"}
{"text": "Consequently , the RNDS DM 100 relates the processes of device - selection and NP - resolution as co - dependent processes because information about the resolution of NPs provides important clues about the device being referred to , but NP - resolution may actually be quite device - specific , as described below .", "label": "", "metadata": {}, "score": "70.3889"}
{"text": "In general , ontological relations comprise such relations as hypernym and meronym relations between two terms .Ontological relations are very important for natural language processing ( NLP ) applications such as question answering , information retrieval , dialogue systems , semantic inference , machine translation and other similar applications .", "label": "", "metadata": {}, "score": "70.54988"}
{"text": "2 is a high - level flow chart diagramming the method of the present invention ; .FIG .3 flowcharts the component steps of question processing in one embodiment of the method ; .FIG .4 flowcharts the component steps of preliminary hypothesis generation in one embodiment of the method ; .", "label": "", "metadata": {}, "score": "70.6685"}
{"text": "Vector - space search using full - length documents is not as well suited as MURAX 's approach to the task that MURAX performs .For the example question , a vector - space search was done using a typical similarity measure and the bag of content words of the question .", "label": "", "metadata": {}, "score": "70.67149"}
{"text": "The present invention relates to computerized information - retrieval ( IR ) systems and methods , and more particularly to computerized information - retrieval systems and methods used with textual databases .The user is responsible for modifying or refining the query and typically receives little or no help from the system in query construction or refinement .", "label": "", "metadata": {}, "score": "70.718864"}
{"text": "We will see regular expression and n - gram approaches to chunking , and will develop and evaluate chunkers using the CoNLL-2000 chunking corpus .We will then return in ( 5 ) and 6 to the tasks of named entity recognition and relation extraction .", "label": "", "metadata": {}, "score": "70.87319"}
{"text": "This reduces the need to drop several words successively from a noun phrase in order to produce a match .3.1 Title Phrases .A title phrase is a multi - word phrase that is the title of a film , book , play , etc .", "label": "", "metadata": {}, "score": "70.95538"}
{"text": "Look for other examples of correctly chunked noun phrases with incorrect tags .Study its errors and try to work out why it does n't get 100 % accuracy .Experiment with trigram chunking .Are you able to improve the performance any more ?", "label": "", "metadata": {}, "score": "70.98723"}
{"text": "After all linguistic relations and hypotheses have been processed , in step 270 equivalent hypotheses are optionally linked .The procedure of step 260 can be expressed as pseudocode , for example as follows : .The nesting order of these loops can be reversed , depending on the particular implementation . sup . sup .", "label": "", "metadata": {}, "score": "71.075554"}
{"text": "You can also download the install package manually ( but the recommended way of installation is to use the GATE plugin manager through the GATE Developer GUI ) .This Sentence Annotator is used in my TGNI application to split a block of text into sentences , which are then further split up into shingles and matched against the Lucene / Neo4j representation of the taxonomy .", "label": "", "metadata": {}, "score": "71.14081"}
{"text": "An analogous path is performed for the ontological relations .Thus , in block 309 , the short - distance pattern is generated for the ontological relations .The short - distance patterns are then generalized for the ontological relations , block 311 .", "label": "", "metadata": {}, "score": "71.142525"}
{"text": "The foregoing embodiment of the method is only one possible embodiment among many .Moreover , variations of the method fall within the scope of the invention .A few alternative embodiments will now be briefly described .Some of these involve alternative techniques for executing certain method steps .", "label": "", "metadata": {}, "score": "71.146416"}
{"text": "If verification is performed , a text corpus can be used to provide verification information not present in the set of documents .The documents can be present in the text corpus , but need not be .In the alternative embodiments that will now be described , certain steps described for the embodiments described up to this point are omitted .", "label": "", "metadata": {}, "score": "71.15811"}
{"text": "One way that we can incorporate information about the content of words is to use a classifier - based tagger to chunk the sentence .Like the n - gram chunker considered in the previous section , this classifier - based chunker will work by assigning IOB tags to the words in a sentence , and then converting those tags to chunks .", "label": "", "metadata": {}, "score": "71.160385"}
{"text": "[ 0056 ] .When an input form matches an entry in a dialogue move 's \" Input \" section , this may cause variables to be bound ; in particular , a variable may be bound that corresponds to one from the AM .", "label": "", "metadata": {}, "score": "71.3432"}
{"text": "One way of approaching this task is to initially look for all triples of the form ( X , \u03b1 , Y ) , where X and Y are named entities of the required types , and \u03b1 is the string of words that intervenes between X and Y .", "label": "", "metadata": {}, "score": "71.35042"}
{"text": "The method of claim 1 in which the step of using a processor to generate automatically an answer hypothesis comprises using a processor to generate the plurality of answer hypotheses from among which the best answer hypothesis is to be determined .", "label": "", "metadata": {}, "score": "71.418564"}
{"text": "If sufficient template matches are found among the primary documents , then the linguistic relation is considered verified .In this case it is unnecessary to run secondary queries and steps 265 and 266 are skipped for this linguistic relation and hypothesis . 6.6 Secondary Queries .", "label": "", "metadata": {}, "score": "71.55188"}
{"text": "This allows us to devise patterns that are sensitive to these tags , as shown in the next example .The method clause ( ) prints out the relations in a clausal form , where the binary relation symbol is specified as the value of parameter relsym .", "label": "", "metadata": {}, "score": "71.60251"}
{"text": "( It is assumed that at least some of the primary documents match the queries . )Alternatively , if question processing is carried out ahead of time by a primary query construction process , match sentences can also be detected by the primary query construction process and made available to answer extraction subsystem as additional input in step 200 .", "label": "", "metadata": {}, "score": "71.73972"}
{"text": "The goal of this step is to rank highest the answer hypothesis or hypotheses most likely to be responsive to the input string .Step 280 is analyzed in more detail in section 5 below .The result of step 280 is an ordered list of answer hypotheses .", "label": "", "metadata": {}, "score": "71.758286"}
{"text": "1 , the method of the current invention can be embodied in a system suitable to the two - phase method for answering a natural - language question .Answer extraction subsystem 15 is coupled with primary query construction subsystem 10 via channel 16 and with information retrieval subsystem 11 via channel 17 .", "label": "", "metadata": {}, "score": "71.838974"}
{"text": "using the processor to score the hypotheses .The method of claim 47 further comprising the steps of : . using the processor to construct and execute queries based on the hypotheses to retrieve a set of secondary documents ; and .", "label": "", "metadata": {}, "score": "71.86447"}
{"text": "These hypotheses need not appear anywhere in the input string .Hypotheses are verified based on linguistic information from the input string , text from the primary documents , and text from secondary documents retrieved from a text corpus in response to secondary queries based on the hypotheses .", "label": "", "metadata": {}, "score": "71.961876"}
{"text": "Using a cutoff of five guesses , answers are thus considered to be found for 74 percent of the questions and the mean rank of the correct hypothesis is 1.44 .The examples given in Table 5 above are typical of the questions that were used for the evaluation .", "label": "", "metadata": {}, "score": "71.97392"}
{"text": "Other strategies can be used in other embodiments .For example , all sentences can be assigned the same score ( e.g. , 1 ) in some embodiments .In step 250 the match sentences retained for further processing in step 245 are analyzed to detect phrases they contain .", "label": "", "metadata": {}, "score": "72.007164"}
{"text": "However , the complexity of natural language can make it very difficult to access the information in that text .The state of the art in NLP is still a long way from being able to build general - purpose representations of meaning from unrestricted text .", "label": "", "metadata": {}, "score": "72.02648"}
{"text": "Section 8 describes some variations of the method .System Overview .FIG .1 illustrates a system suitable to implement the method of the present invention .A user 's question and a set of relevant documents is fed to answer extraction subsystem 15 whose software operates on supporting hardware comprising a computing node 4 further comprising a processor 5 and memory 6 coupled to the processor 5 .", "label": "", "metadata": {}, "score": "72.03932"}
{"text": "Accordingly , the inventors reserve the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the RNDS .Extracting Information from Text .For any given question , it 's likely that someone has written the answer down somewhere .", "label": "", "metadata": {}, "score": "72.08673"}
{"text": "Answer hypotheses are shown to the user to focus his or her attention on likely answers and how they relate to other phrases in the question .The text presented is not necessarily from documents that have high similarity scores , but rather from documents that confirm phrase relations that lend evidence for an answer .", "label": "", "metadata": {}, "score": "72.11753"}
{"text": "[ 0074 ] .The RNDS 200 described herein provides management of multi - device conversations , dialogue - move scripting that facilitates greater portability to new domains and also enables multi - device dialogue , and scripting functionality to extend other core dialogue processes ( such as NP - resolution ) so as to cover domain - specific phenomena .", "label": "", "metadata": {}, "score": "72.14329"}
{"text": "The DMT 108 also serves as context for interpreting fragments , multi - utterance constructs , and revisions , and provides discourse structure for tasks such as NP - resolution .[ 0042 ] .The AT 110 manages activities relevant to a dialogue .", "label": "", "metadata": {}, "score": "72.21742"}
{"text": "As an example of the process illustrated in .FIG .5 , suppose the input sentence is \" X includes A , B , C and D \" .The input of block 502 contains two lists , coordinate relations and ontological ( part - whole ) relations .", "label": "", "metadata": {}, "score": "72.29887"}
{"text": "The list can be stored in the processor 's memory .Alternatively or additionally it can be stored in a storage device coupled to the processor .Preliminary Hypothesis Generation .This section examines step 240 , preliminary hypothesis generation , in detail .", "label": "", "metadata": {}, "score": "72.338745"}
{"text": "Blogger messes up the formatting so its hard to read .From a quick look I do n't see anything glaring ( but I did n't look that hard ) .I suspect the problems may be with your models .I have written a JUnit test ( which you can convert to a main almost 1 to 1 if you need ) that produces results that seem more believable .", "label": "", "metadata": {}, "score": "72.357056"}
{"text": "Constructions 10.3 .Alternative realisations 10.4 .NP ni NP 10.5 .Bound nouns 10.6 .Existential constructions of \" having \" 11 .Clausal NPs 11.1 .Structure 11.2 .Function 12 .Classifiers 12.1 .With nouns 12.2 .With adjectives 12.3 .", "label": "", "metadata": {}, "score": "72.53255"}
{"text": "Alternatively , the functional blocks of system 100 can be implemented in a single computer that represents a unitary dialog system , or in any type of device , such as appliances , machinery , and other type of computer - controlled or automated apparatus .", "label": "", "metadata": {}, "score": "72.689026"}
{"text": "FIG .2 is a flow diagram that illustrates the main functional tasks of the ontological learning system , according to an embodiment .FIG .3 is a flowchart that illustrates the steps of learning ontological relations for noun - phrases in a document , under an embodiment .", "label": "", "metadata": {}, "score": "72.711655"}
{"text": "As mentioned above in section 4.2 , a relevant phrase match can be missed because the primary document in which it occurs has too low a score in comparison to other primary documents .Creating secondary queries with individual question phrases allows the relevant phrase match to be found by bringing documents excluded during primary query construction back into consideration .", "label": "", "metadata": {}, "score": "72.727264"}
{"text": "The system of .claim 14 , wherein the NPRS includes KnowledgeBase - query construction rules that are programmable to define how noun phrase objects are mapped to the query for each of the devices .The system of .claim 14 , further comprising at least one database , wherein the knowledge manager transfers the query to the database .", "label": "", "metadata": {}, "score": "72.72958"}
{"text": "Further Reading .The popularity of chunking is due in great part to pioneering work by Abney e.g. , ( Church , Young , & Bloothooft , 1996 ) .The IOB format ( or sometimes BIO Format ) was developed for NP chunking by ( Ramshaw & Marcus , 1995 ) , and was used for the shared NP bracketing task run by the Conference on Natural Language Learning ( CoNLL ) in 1999 .", "label": "", "metadata": {}, "score": "72.760284"}
{"text": "Scoring : The assignment of values to answer hypotheses , reflecting their likelihood as being the correct answer .Secondary documents : Documents from a text corpus that are retrieved in response to a secondary query .Secondary query : A query that is based on an answer hypothesis and that additionally may be based on other phrases .", "label": "", "metadata": {}, "score": "72.784035"}
{"text": "Here 's an example of a tree ( note that they are standardly drawn upside - down ) : .We use a ' family ' metaphor to talk about the relationships of nodes in a tree : for example , S is the parent of VP ; conversely VP is a child of S .", "label": "", "metadata": {}, "score": "72.84036"}
{"text": "The elements and acts of the various embodiments described above can be combined to provide further embodiments .These and other changes can be made to the ontology learning method in light of the above detailed description .In general , in the following claims , the terms used should not be construed to limit the disclosed method to the specific embodiments disclosed in the specification and the claims , but should be construed to include all operations or processes that operate under the claims .", "label": "", "metadata": {}, "score": "72.884285"}
{"text": "The result of step 270 is a set of linking information for the hypotheses , or , viewed differently , a smaller set of hypotheses .The linking information tells which hypotheses are to be considered equivalent to which other hypotheses .", "label": "", "metadata": {}, "score": "73.005135"}
{"text": "The method of claim 1 wherein said input string comprises a user question , and wherein said phrase represents an answer to said user question .The method of claim 1 in which at least one word of the answer hypothesis is not present in the input string .", "label": "", "metadata": {}, "score": "73.02106"}
{"text": "1 is a block diagram of a natural language processing system that includes an ontological leaning component , according to an embodiment .System 100 illustrated in .FIG .1 acts on manual data 102 to provide an improved knowledge base 106 to a dialog system 108 through the use of ontological learning system 104 .", "label": "", "metadata": {}, "score": "73.02394"}
{"text": "FIG .8 is an example of noun phrase - resolution ( \" NP - resolution \" ) rules 800 , under an embodiment .These NP - resolution rules 800 are taken from the NP - resolution script for an MP3 device , but are not so limited .", "label": "", "metadata": {}, "score": "73.02701"}
{"text": "Part II of the description sets forth the method of the present invention in one embodiment .Section 2 provides an overview of a system suitable to implement the method .Section 3 outlines the major , high - level steps of the method .", "label": "", "metadata": {}, "score": "73.115555"}
{"text": "In the following description , numerous specific details are introduced to provide a thorough understanding of , and enabling description for , embodiments of the RNDS .One skilled in the relevant art , however , will recognize that these embodiments can be practiced without one or more of the specific details , or with other components , systems , etc .", "label": "", "metadata": {}, "score": "73.13401"}
{"text": "[0105 ] .The elements and acts of the various embodiments described above can be combined to provide further embodiments .These and other changes can be made to the RNDS in light of the above detailed description .[ 0106 ] .", "label": "", "metadata": {}, "score": "73.240845"}
{"text": "Scoring and ranking of hypotheses is based in part on verification evidence obtained for the hypotheses and can integrate information obtained from multiple documents .The method can be used either by itself or in the context of other , larger methods .", "label": "", "metadata": {}, "score": "73.33801"}
{"text": "Do these changes adversely affect the performance of many useful programs ?Is this a non - concern with constraint programming facilities ?Environment Trimming - Definite Clause Grammars ( DCGs ) are quite slow in miniKanren .This may be due to a lack of groundness analysis or it may be because we are not trimming the environment of needless logic variables .", "label": "", "metadata": {}, "score": "73.41054"}
{"text": "The third scoring criterion -- the preliminary scores that were obtained during the step of generating hypotheses , that is , step 240 - -is applied in the specific embodiment as a tie - breaker if the first two criteria do not suffice to distinguish among the hypotheses .", "label": "", "metadata": {}, "score": "73.48657"}
{"text": "Of course we could omit such locations from the gazetteer , but then we wo n't be able to identify them when they do appear in a document .It gets even harder in the case of names for people or organizations .", "label": "", "metadata": {}, "score": "73.50021"}
{"text": "Hypothesis Ranking .This section describes step 280 , hypothesis ranking , in detail .The goal of hypothesis ranking is to determine which answer hypotheses are most relevant or responsive to the input string .If the input string is a question , for example , the purpose of hypothesis ranking is to decide which hypothesis is likely to be the best answer to the question .", "label": "", "metadata": {}, "score": "73.50443"}
{"text": "Sequences which end in a logic variables can be represented by using lcons .( lcons ' a ( lvar ' b ) ) ; ( a .Logic variables are instances of LVar not vectors as they are in Scheme .", "label": "", "metadata": {}, "score": "73.52929"}
{"text": "In a user- or speaker - initiated system , the DM directs the processing of an input utterance from one component to another through interpretation and back - end system response .In the process , the DM detects and handles information inputs of an input utterance , and generates system output , for example .", "label": "", "metadata": {}, "score": "73.54454"}
{"text": "The RNDS supports substitution of specific semantic representations and associated routines , and clean interfaces to external components for language - understanding ( i.e. , speech - recognition and parsing ) and language - generation , and to domain - specific knowledge sources , thereby reducing or eliminating any requirement to recode any core software components .", "label": "", "metadata": {}, "score": "73.58358"}
{"text": "The detected phrases typically comprise noun phrases and can further comprise title phrases or other kinds of phrases .The phrases detected in the match sentences are called preliminary hypotheses .Each preliminary hypothesis is associated with the document in which it was detected .", "label": "", "metadata": {}, "score": "73.678986"}
{"text": "Linguistic relations and corresponding lexico - syntactic patterns other than those described above can be used both to analyze the input string and to generate additional templates .For example , relative clauses such as \" Who is the king who sat at the water 's edge . . . ?", "label": "", "metadata": {}, "score": "73.879105"}
{"text": "The questions in Table 5 appear in the general - knowledge \" Trivial Pursuit \" game and typify the form of question that is the concern of the MURAX task .These questions have the virtue of being created independently of the retrieval task ( that is , they are unbiased ) and have a consistent and simple stylized form .", "label": "", "metadata": {}, "score": "73.940094"}
{"text": "( [ [ : d ' the ] ] ' [ the ] ) .( [ [ : d ' a ] ] ' [ a ] ) ) .( [ [ : np d n ] ] ( det d ) ( noun n ) ) ) .", "label": "", "metadata": {}, "score": "74.03415"}
{"text": "The apparatus of .claim 7 , wherein the long - distance ontological relations comprise ontological relations between terms separated by at least two terms .The apparatus of .claim 7 , further comprising a natural language processing system functionally coupled to the database and utilizing words stored in the knowledge base .", "label": "", "metadata": {}, "score": "74.037834"}
{"text": "Particular classifier contrasts 13 .Numbers 13.1 .The number system 13.2 .Syntax 13.2.1 .As predicate head 13.2.2 .In a noun phrase 13.2.3 .In a prepositional NP 13.2.4 .With time and distance words 13.2.5 .Lewe 13.3 .", "label": "", "metadata": {}, "score": "74.0602"}
{"text": "Entity recognition is often performed using chunkers , which segment multi - token sequences , and label them with the appropriate entity type .Common entity types include ORGANIZATION , PERSON , LOCATION , DATE , TIME , MONEY , and GPE ( geo - political entity ) .", "label": "", "metadata": {}, "score": "74.08651"}
{"text": "FIG .4 , in block 402 the process inputs all the short - distance patterns generated in steps 308 or 310 of .FIG .3 .The patterns are then grouped by verbs or prepositions , block 404 .The longest common substring within each group of pattern strings is then extracted , block 406 .", "label": "", "metadata": {}, "score": "74.09592"}
{"text": "Apply the same method to determine an upper bound on the performance of an n - gram chunker .Write functions to do the following tasks for your chosen type : .List all the tag sequences that occur with each instance of this chunk type .", "label": "", "metadata": {}, "score": "74.13394"}
{"text": "The RNDS of an embodiment also supports multi - device dialogue management by extending the existing dialogue - management infrastructure in DMs .The extended dialogue management under the RNDS extends the pertinent data structures so as to simultaneously manage multiple dialogue - enabled devices .", "label": "", "metadata": {}, "score": "74.22124"}
{"text": "These dependency paths resemble lexico - syntactic patterns but cover long - distance dependencies .These present prior art ideas share the same limitation of only using complete lexico - syntactic patterns .They do not use partial or generalized patterns , as well as complete patterns .", "label": "", "metadata": {}, "score": "74.35432"}
{"text": "( use ' clojure.core.logic ) .( defna findo [ x l o ] .( [ _ [ [ ?y : - o ] ._ ] _ ] .( project [ x ?y ) true ) ) ) .", "label": "", "metadata": {}, "score": "74.40257"}
{"text": "Major Steps of the Method .This section of the description explains how these steps work together in the context of the method as a whole .Subsequent sections examine the steps of question processing , hypothesis generation , hypothesis verification , and hypothesis ranking in greater detail .", "label": "", "metadata": {}, "score": "74.43666"}
{"text": "The system of an embodiment further comprises at least one of a speech recognition module and a language understanding module coupled to an input of the dialogue manager .[ 0095 ] .The system of an embodiment further comprises at least one of a language generation module and a text - to - speech module coupled to an output of the dialogue manager .", "label": "", "metadata": {}, "score": "74.44732"}
{"text": "For example , an MP3 device will need to handle qualifiers such as \" by artist \" , and know to translate this construct into an appropriate constraint on the \" artist \" field of the KB .[0070 ] .", "label": "", "metadata": {}, "score": "74.47953"}
{"text": "3 flowcharts the component steps of question processing in an embodiment of the method that uses shallow linguistic analysis .In step 300 the input string is analyzed to determine what part of speech each word of the string is .Each word of the string is tagged to indicate whether it is a noun , verb , adjective , etc .", "label": "", "metadata": {}, "score": "74.565056"}
{"text": "In either case , part - of - speech tags are often a very important feature when searching for chunks .Although chunkers are specialized to create relatively flat data structures , where no two chunks are allowed to overlap , they can be cascaded together to build nested structures .", "label": "", "metadata": {}, "score": "74.80581"}
{"text": "Each dialogue contribution is classified as a \" dialogue move \" ( e.g. \" Command \" , \" WhQuestion \" , \" WhAnswer \" , etc . ) , and is interpreted in context by attaching itself to an appropriate \" active \" node on the DMT 108 .", "label": "", "metadata": {}, "score": "74.80989"}
{"text": "Sentences nearby the match sentences can be used for verification , in addition to the match sentences themselves .Secondary queries can be used to generate additional hypotheses beyond those obtained from the primary documents .Secondary queries can be nested and run iteratively to generate still better answer hypotheses .", "label": "", "metadata": {}, "score": "74.826385"}
{"text": "Constraint Logic Programming - Constraint Handling Rules ( CHR ) is particularly inspiring .William Byrd and Daniel Friedman are working on CLP(FD ) and CLP(X ) extensions to miniKanren .We should incorporate this .Groundness Analysis - Initial research on feasibility done .", "label": "", "metadata": {}, "score": "74.83992"}
{"text": "For example , in order to answer the question above the answer extraction subsystem does not need to refer to a table of prime ministers . 6.2 Component Steps of Hypothesis Verification .FIG .5 flowcharts the component steps of hypothesis verification step 260 in one embodiment of the method .", "label": "", "metadata": {}, "score": "74.85842"}
{"text": "The method of claim 7 in which said phrase is generated by determining a match phrase , said match phrase being a phrase common to at least two documents of said set , said match phrase satisfying said linguistic relation implied by said input string .", "label": "", "metadata": {}, "score": "74.87347"}
{"text": "It 's more efficient to prep the expressions before hand if you 're going to be unifying the same expressions over and over again .Definite Clause Grammars .core.logic has Prolog - type DCG syntax for parsing : .( [ [ : v ' eats ] ] ' [ eats ] ) ) .", "label": "", "metadata": {}, "score": "74.90349"}
{"text": "ChunkParse score : IOB Accuracy : 93.3 % Precision : 82.3 % Recall : 86.8 % F - Measure : 84.5 % .3.3 Training Classifier - Based Chunkers .Both the regular - expression based chunkers and the n - gram chunkers decide what chunks to create entirely based on part - of - speech tags .", "label": "", "metadata": {}, "score": "74.91197"}
{"text": "claim 3 , further comprising adapting at least one of the noun phrase - resolution rules for use across at least one of a plurality of different domains and a plurality of different applications via reprogramming of the NPRS .The method of .", "label": "", "metadata": {}, "score": "74.9169"}
{"text": "Use the chunkscore.missed ( ) and chunkscore.incorrect ( ) methods to identify the errors made by your chunker .Discuss .Compare the performance of your chunker to the baseline chunker discussed in the evaluation section of this chapter .Use any combination of rules for chunking , chinking , merging or splitting .", "label": "", "metadata": {}, "score": "74.921875"}
{"text": "In block 204 , the process performs pattern generalization .Patterns ( i.e. , strings that contain the same verbs ) may share a common sub - string that represents the word sequence shared among these patterns .The pattern generalization step finds the common sub - string .", "label": "", "metadata": {}, "score": "74.92854"}
{"text": "Components .An on - line version of Grolier 's Academic American Encyclopedia ( The Academic American Encyclopedias , Danbury , Conn. : Grolier Electronic Publishing , 1990 ) serves as the text corpus for MURAX .The on - line encyclopedia contains approximately 27,000 articles , which are accessed via the Text Database ( D. R. Cutting , J. Pedersen , and P.-K. The components responsible for linguistic analysis in MURAX are a part - of - speech tagger and a lexico - syntactic pattern matcher .", "label": "", "metadata": {}, "score": "74.9483"}
{"text": "Combine these with the existing baseline chunker and re - evaluate it , to see if you have discovered an improved baseline .The format uses square brackets , and we have encountered it several times during this chapter .The Treebank corpus can be accessed using : for sent in nltk.corpus.treebank_chunk.chunked_sents(fileid ) .", "label": "", "metadata": {}, "score": "75.00833"}
{"text": "The method of the present invention is to be used in conjunction with a text corpus , which is a corpus ( body ) of information stored in the form of natural language text .Typically the corpus is a collection of articles or documents .", "label": "", "metadata": {}, "score": "75.048645"}
{"text": "If sufficient matches are found , this attempt succeeds and processing continues with the next hypothesis .However , if no matches or only a few are found , the attempt fails and processing continues at step 265 .In step 265 at least one secondary query is constructed and executed .", "label": "", "metadata": {}, "score": "75.096756"}
{"text": "claim 1 , wherein the mapping further comprises recognizing at least one parameter of the dialogue contribution .The method of .claim 1 , further comprising scoring matches between variables of the description and the dialogue move components .A system comprising : . a knowledge manager coupled to the dialogue manager and to at least one database ; and .", "label": "", "metadata": {}, "score": "75.11772"}
{"text": "The method of claim 9 in which said linguistic relation is selected from the group consisting of a lexical relation , a syntactic relation , a lexico - syntactic relation , a semantic relation , a grammatical relation , and a parsed relation .", "label": "", "metadata": {}, "score": "75.22356"}
{"text": "5 flowcharts the steps of hypothesis verification in one embodiment of the method ; and .FIG .6 flowcharts the component steps of hypothesis ranking in one embodiment of the method .DESCRIPTION OF SPECIFIC EMBODIMENTS .The disclosures in this application of all articles and references , including patent documents , are incorporated herein by reference .", "label": "", "metadata": {}, "score": "75.265465"}
{"text": "[0008 ] .FIG .3 is a flow diagram for mapping a description of a dialogue contribution to a dialogue move using a Dialogue Move Script ( \" DMS \" ) , under an embodiment .[ 0009 ] .", "label": "", "metadata": {}, "score": "75.47711"}
{"text": "In the present invention , the answer hypotheses generated are used in new queries that the system constructs without user aid .These secondary queries are based on guesses - words that in the vast majority of cases are not present in the user 's original question .", "label": "", "metadata": {}, "score": "75.4831"}
{"text": "The method of .claim 1 , wherein the document comprises a plurality of terms characterized by syntactic relationships among the terms .The method of .claim 1 , wherein at least one ontological relation of the ontological relations is selected from the group consisting of : hypernym , part - whole , synonym , antonym , coordinate , entailment , troponym , and causal relations .", "label": "", "metadata": {}, "score": "75.67499"}
{"text": "One important things to note are that the chunk spans report its start and end offsets in terms of token ( not character positions ) .Another thing to note is that the NounPhrase annotation start and end offsets are character offsets relative to the start of the incoming block of text .", "label": "", "metadata": {}, "score": "75.74838"}
{"text": "For English , MuNPEx works with the ANNIE ( Hepple ) tagger that comes as part of the ANNIE system with GATE .French , German , and Spanish are based on the TreeTagger .Please read the included documentation ( or source code ) for more details .", "label": "", "metadata": {}, "score": "75.98424"}
{"text": "Its just a regular Annotation without any extra properties .Here it is .Annotator .I have already described what the annotator does above .Ultimately , it will replace the SentenceAnnotator , so it should consume TextAnnotation objects placed by the upstream TextAnnotator .", "label": "", "metadata": {}, "score": "76.0015"}
{"text": "4 is a flow diagram for using a noun phrase - resolution script ( \" NPRS \" ) to generate a database query ( noun phrase - query ) that corresponds to a device , under an embodiment .[0010 ] .", "label": "", "metadata": {}, "score": "76.0838"}
{"text": "Activity - execution is monitored on the AT 110 and changes may result in a notification message being generated , e.g. on failure or successful completion of a task .[ 0043 ] .The AT 110 is coupled to AMs 230 of Devices 250 of the RNDS 200 via the Device Manager 220 and Device API 222 , as described above .", "label": "", "metadata": {}, "score": "76.13693"}
{"text": "Like surnames , the pronouns he and she often refer to the article 's title ( if the title is a person 's name ) or to an immediately preceding name .For the example output shown in Table 8 , in the document displayed for Norman Mailer , the same answer hypothesis Mailer is used in both sentences ; however , if he had been referred to instead as he , the result would be the same .", "label": "", "metadata": {}, "score": "76.17708"}
{"text": "Any match sentences determined in step 266 to satisfy the template are retained in association with the hypothesis as verification evidence for use in later processing steps .Secondary queries can be of particular importance when the number of primary documents is limited .", "label": "", "metadata": {}, "score": "76.422386"}
{"text": "[ 0064 ] .Device - specific implementations of dialogue management processes can also be added , or used to overwrite generic implementations , by including new Java classes in the encapsulated information as appropriate to the device .For example , a dialogue - move that handles a new form of interaction introduced by a new device could be added .", "label": "", "metadata": {}, "score": "76.438354"}
{"text": "New organizations come into existence every day , so if we are trying to deal with contemporary newswire or blog entries , it is unlikely that we will be able to recognize many of the entities using gazetteer lookup .Another major source of difficulty is caused by the fact that many named entity terms are ambiguous .", "label": "", "metadata": {}, "score": "76.45415"}
{"text": "After generalization , the longest common pattern string ( except X and Y in the string ) is \" include \" .This represents the generalized pattern .In the above cases , the wildcard corresponds to null , \" not only , \" and the NP .", "label": "", "metadata": {}, "score": "76.5585"}
{"text": "Each Device API 222 includes an AM 230 , device - specific DMS 232 , device - specific NPRS 234 ( also referred to as NP - resolution grammar ) , and dialogue manager process extensions ( \" DM process extensions \" ) , but is not so limited .", "label": "", "metadata": {}, "score": "76.59312"}
{"text": "YourKit , LLC is the creator of innovative and intelligent tools for profiling Java and .NET applications .Take a look at YourKit 's leading software products : . Notes .I stayed pretty true to the ideas of the original implementation .", "label": "", "metadata": {}, "score": "76.626465"}
{"text": "[ 0016 ] .Scripts of the RNDS , which include Dialogue Move Scripts ( \" DMS \" ) , Activity Models , and Noun Phrase Resolution Scripts ( \" NPRS \" ) , provide the capability for easy customization of the RNDS to new dialogue domains and applications .", "label": "", "metadata": {}, "score": "76.74623"}
{"text": "Pronouns 6.1 .Meanings 6.2 .Functions 6.3 .Forms 6.4 .Analysis 6.5 .Third person singular 7 .Deictics 7.1 .Demonstratives 7.1.1 .Forms 7.1.2 .Function and meaning 7.2 .Deictic verbs 7.3 .Deictic noun 8 .", "label": "", "metadata": {}, "score": "76.750885"}
{"text": "Unification uses protocols in order leverage the full speed of the host .Clojure 's cons operator differs significantly from Scheme 's so I added the LConsSeq protocol .Sequences which end in a logic variables can be represented by using lcons .", "label": "", "metadata": {}, "score": "76.752655"}
{"text": "This will show you the actual words that intervene between the two NEs and also their left and right context , within a default 10-word window .With the help of a Dutch dictionary , you might be able to figure out why the result VAN ( ' annie_lennox ' , ' eurythmics ' ) is a false hit . 7 Summary .", "label": "", "metadata": {}, "score": "76.76886"}
{"text": "The method of claim 47 further comprising the step of using the processor to link equivalent hypotheses .The method of claim 47 further comprising the step of using the processor to output the scored hypotheses .A method of operating a computer system for computerized information retrieval to process an input string supplied by a user , the method comprising the steps of : . in a first phase , using the system to construct and execute a series of primary queries based on shallow linguistic analysis of the input string in order to retrieve primary documents ; and .", "label": "", "metadata": {}, "score": "76.83067"}
{"text": "The method of claim 5 additionally comprising the step of using a processor to analyze the input string .The method of claim 6 in which the step of using a processor to analyze the input string comprises using a processor to determine a linguistic relation implied by the input string .", "label": "", "metadata": {}, "score": "76.902664"}
{"text": "A further understanding of the nature and advantages of the present invention may be realized by reference to the remaining portions of the specification and the drawings .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 illustrates a system suitable for an embodiment of the present invention ; .", "label": "", "metadata": {}, "score": "76.97484"}
{"text": "4 is a flowchart that illustrates a method of generalizing patterns in an ontological learning process , under an embodiment .FIG .5 is a flowchart that illustrates a method of identifying long - distance ontological relations , under an embodiment .", "label": "", "metadata": {}, "score": "76.994095"}
{"text": "Most of the code in this class is simply used to convert back and forth between the chunk tree representation used by NLTK 's ChunkParserI interface , and the IOB representation used by the embedded tagger .The class defines two methods : a constructor which is called when we build a new UnigramChunker ; and the parse method which is used to chunk new sentences .", "label": "", "metadata": {}, "score": "77.08522"}
{"text": "Defining facts .Sometimes it 's useful to create a list of facts that you want to run queries over .Use defrel and fact .( defrel man p ) .( fact man ' Bob ) .( fact man ' John ) .", "label": "", "metadata": {}, "score": "77.127625"}
{"text": "Most QA systems take the documents returned by standard Information Retrieval , and then attempt to isolate the minimal text snippet in the document containing the answer .Now suppose the question was Who was the first President of the US ? , and one of the documents that was retrieved contained the following passage : .", "label": "", "metadata": {}, "score": "77.130356"}
{"text": "Predicate structure 4.3 .Noun phrase structure 4.4 .Clausal NPs 4.5 .Other subordinate clauses 4.6 .Semi - auxiliary verbs \" not , \" \" can , \" etc 4.7 .Peripheral clause constituents 4.8 .Fronting 4.9 .Relative clauses 4.10 .", "label": "", "metadata": {}, "score": "77.25384"}
{"text": "We also define an example sentence to be chunked , and run the chunker on this input .( \" her \" , \" PP$ \" ) , ( \" long \" , \" JJ \" ) , ( \" golden \" , \" JJ \" ) , ( \" hair \" , \" NN \" ) ] .", "label": "", "metadata": {}, "score": "77.29937"}
{"text": "( : use clojure.core.logic ) ) .( defna findo [ x l o ] .( [ _ [ [ y : - o ] ._ ] _ ] .( [ _ [ _ .c ] _ ] ( findo x c o ) ) ) .", "label": "", "metadata": {}, "score": "77.4709"}
{"text": "In step 200 the answer extraction subsystem accepts as input a natural - language input string ( e.g. , a question ) and a set of documents assumed to contain an appropriate response to the input string ( e.g. , the answer to the question ) .", "label": "", "metadata": {}, "score": "77.49281"}
{"text": "The method of claim 37 in which the step of using a subsystem of said system to rank answer hypotheses comprises using a subsystem of said system to take into account at least some of the verification evidence gathered for answer hypotheses .", "label": "", "metadata": {}, "score": "77.504654"}
{"text": "Uca \" to do what \" ; va'a- cava \" to do how \" 17 .Word Derivations 17.1 .Prefix vei - , collective 17.1.1 .With nouns and time words 17.1.2 .With kin terms 17.1.3 .With verbs 17.1.4 .", "label": "", "metadata": {}, "score": "77.58301"}
{"text": "TaggerI ) : def _ _ init _ _ ( self , train_sents ) : . train_set . append ( ( featureset , tag ) ) .history.append(tag ) .history.append(tag ) .return zip(sentence , history ) class ConsecutiveNPChunker ( nltk .", "label": "", "metadata": {}, "score": "77.638824"}
{"text": "( defne appendo [ x y z ] .( [ ( ) _y ] ) .( [ [ a .d ] _ [ a .r ] ] ( appendo d y r ) ) ) .Here 's a simple type inferencer for the simply typed lambda calculus based on a version originally written in Prolog : .", "label": "", "metadata": {}, "score": "77.747894"}
{"text": "9 Exercises .Why are three tags necessary ?What problem would be caused if we used I and O tags exclusively ?Try to do this by generalizing the tag pattern that handled singular noun phrases .Inspect the CoNLL corpus and try to observe any patterns in the POS tag sequences that make up this kind of chunk .", "label": "", "metadata": {}, "score": "77.799545"}
{"text": "[ 0023 ] .FIG .1 is a block diagram of a representation - neutral dialogue system ( \" RNDS \" ) Dialogue Manager ( \" DM \" ) ( \" RNDS DM \" ) 100 , under an embodiment .", "label": "", "metadata": {}, "score": "77.81257"}
{"text": "[ 0092 ] .The code of an embodiment implementing further device - specific functionality includes device - specific dialogue moves .The activity model of an embodiment includes variables that correspond to DMS variables .[0093 ] .In response to coupling of the device to the device manager the dialogue manager of an embodiment receives and stores information of the activity model , device - specific DMS , device - specific NPRS , and device - specific dialogue moves from the device API .", "label": "", "metadata": {}, "score": "77.88899"}
{"text": "NET applications .Take a look at YourKit 's leading software products : . Notes .I stayed pretty true to the ideas of the original implementation .There are however several key differences .Unification uses protocols in order leverage the full speed of the host .", "label": "", "metadata": {}, "score": "77.92065"}
{"text": "Thanks Ravi , that is a good idea .Hi Satya , the NounPhraseAnnotation is autogenerated by UIMA from the XML descriptor .If you have UIMA installed , you should be able to do this from the XML descriptor NounPhrase.xml - as you can see , its actually a vanilla annotation that has no other purpose than to give the annotation a name .", "label": "", "metadata": {}, "score": "77.93192"}
{"text": "The main tasks in CME modeling include feature generation , feature selection , which chooses from a feature space a subset of good features to be included in the model , and a parameter estimation process that estimates the weighting factors for each selected feature in the exponential model .", "label": "", "metadata": {}, "score": "77.93948"}
{"text": "The relationships among the data items are determined by the ontological learning system 104 to inform the knowledge base 106 , which provides terms to the dialog system 108 .The dialog system 108 that makes use of the knowledge base 106 generated by the ontological learning component 104 can be any type of dialog system or similar application , such as a reasoning system , a question and answer system , machine translation , or similar system .", "label": "", "metadata": {}, "score": "77.954346"}
{"text": "Proximity of a strict sequence of terms , separated by up to p other terms denoted here as : .Proximity of an unordered list of terms , separated by up to p other terms denoted here as : .( p term 1 , term 2 , . . .", "label": "", "metadata": {}, "score": "78.01865"}
{"text": "Currently the Substitutions deftype uses clojure.lang.PersistentHashMap internally .This may be replaced with something that provides better performance for triangular substitutions .Goals .Simplicity .Optimizations should not destroy the ideas behind the original design .Any person willing to take take the time to understand the original Scheme implementation should have little trouble understanding how core.logic is put together .", "label": "", "metadata": {}, "score": "78.03736"}
{"text": "In the context of the automobile industry , for example , this allows new devices for the automobile to be sold as dialogue - enabled entities , with the new devices then be added into an existing dialogue system in a vehicle like a car or truck .", "label": "", "metadata": {}, "score": "78.03999"}
{"text": "claim 14 , wherein the noun phrase resolver uses the NPRS to access the rules and translate the recognized description in order to generate a query that corresponds to at least one of the device and application .The system of .", "label": "", "metadata": {}, "score": "78.18344"}
{"text": "FIG .1 and elsewhere herein .The SR module 202 and TTS module 212 are included only in spoken dialog systems .The RNDS 200 may also include an application manager ( not shown ) .[ 0027 ] .The SR module 202 receives acoustic signals at one or more inputs and outputs a sequence or a lattice of words with additional labels , such as confidence scores .", "label": "", "metadata": {}, "score": "78.26712"}
{"text": "[ 0032 ] .As one example involving operations of the DMS 102 , .FIG .3 is a flow diagram for mapping 300 a description of a dialogue contribution to a dialogue move using a DMS , under an embodiment .", "label": "", "metadata": {}, "score": "78.40794"}
{"text": "A classic AI program : .( ns classic - ai - example .( : use clojure.core.logic ) ) .( defne moveo [ before action after ] .( [ [ : middle : onbox : middle : hasnot ] : grasp .", "label": "", "metadata": {}, "score": "78.437485"}
{"text": "In step 315 main verbs are detected .Main verbs are any words that are tagged in step 300 as verbs and that are not auxiliary verbs .Typically there is one main verb in the input string , but there can also be none , or two or more .", "label": "", "metadata": {}, "score": "78.43798"}
{"text": "Degree of mismatch : A quantified measure of similarity between two phrases .Document match : The situation where a document satisfies a query .Domain : A broad area that characterizes an information retrieval task , e.g. , general knowledge , medicine , etc . .", "label": "", "metadata": {}, "score": "78.51582"}
{"text": "The coordinate term group is ( A , B , C , D ) , which means A , B , C and D are under the same level .In this case , the ontological relation generation block 510 outputs the following part - whole relations : ( X , A ) , ( X , B ) , ( X , C ) and ( X , D ) .", "label": "", "metadata": {}, "score": "78.621056"}
{"text": "Unification .core.logic comes with a unifier that can be used much like core.unify : .( unifier ' ( ? x ?y ?z ) ' ( 1 2 ?y ) ) ; ( 1 2 _ .0 ) .", "label": "", "metadata": {}, "score": "78.69098"}
{"text": "Note . 2.5 Chinking .Sometimes it is easier to define what we want to exclude from a chunk .We can define a chink to be a sequence of tokens that is not included in a chunk .In the following example , barked / VBD at / IN is a chink : .", "label": "", "metadata": {}, "score": "78.72564"}
{"text": "Modifiers 8.3.1 .Stance - aspect 8.3.2 .Finish and start 8.3.3 .Locational markers 8.3.4 .Directional comparatives 8.3.5 .Modal modifiers 8.3.6 .Markers of intensity 8.3.7 .\" All \" and \" alone \" 8.3.8 .Other modifiers 8.3.9 .", "label": "", "metadata": {}, "score": "78.76274"}
{"text": "FIG .3 , the long - distance ontological relations are identified using both the short - distance coordinate terms and the short - distance ontological relations .FIG .5 is a flowchart that illustrates a method of identifying long - distance ontological relations , under an embodiment .", "label": "", "metadata": {}, "score": "78.82582"}
{"text": "A token is tagged as B if it marks the beginning of a chunk .Subsequent tokens within the chunk are tagged I .All other tokens are tagged O .The B and I tags are suffixed with the chunk type , e.g. B - NP , I - NP .", "label": "", "metadata": {}, "score": "78.870804"}
{"text": "Inspect the high - frequency tag sequences .Use these as the basis for developing a better chunker .For example , the phrase : [ every / DT time / NN ] [ she / PRP ] sees / VBZ [ a / DT newspaper / NN ] contains two consecutive chunks , and our baseline chunker will incorrectly combine the first two : [ every / DT time / NN she / PRP ] .", "label": "", "metadata": {}, "score": "78.93502"}
{"text": "Here is an example that reads the 100th sentence of the \" train \" portion of the corpus : .As you can see , the CoNLL 2000 corpus contains three chunk types : NP chunks , which we have already seen ; VP chunks such as has already delivered ; and PP chunks such as because of .", "label": "", "metadata": {}, "score": "78.978836"}
{"text": "Embodiments of an ontological determination method for use in natural language processing applications are described .Method and system for learning ontological relations from documents US 7630981 B2 .Zusammenfassung .Embodiments of an ontological determination method for use in natural language processing applications are described .", "label": "", "metadata": {}, "score": "79.01898"}
{"text": "In English , the head word is generally the noun that appears rightmost in the type phrase .For example , in the type phrase , \" Chief Justice , \" the head word is \" Justice .\"Templates based on head words are constructed by substituting the head word from the type phrase and a placeholder for the hypothesis in a lexico - syntactic pattern corresponding to one of the linguistic relations IS - A , list inclusion , apposition , or noun phrase inclusion .", "label": "", "metadata": {}, "score": "79.17343"}
{"text": "E.g. if the tag DT ( determiner ) often occurs at the start of a chunk , it will be tagged B ( begin ) .Evaluate the performance of these chunking methods relative to the regular expression chunking methods covered in this chapter .", "label": "", "metadata": {}, "score": "79.260864"}
{"text": "More sophisticated schemes can be used .As an example , suppose that there are six hypotheses and two links as follows : .The first three hypotheses are linked together , and the fourth and fifth hypotheses are linked together .", "label": "", "metadata": {}, "score": "79.28441"}
{"text": "Natural language processing ( NLP ) systems attempt to reproduce human interpretation of language .NLP methods assume that the patterns in grammar and the conceptual relationships between words can be articulated scientifically .NLP systems require the determination of ontological relations among words or terms in a document .", "label": "", "metadata": {}, "score": "79.36145"}
{"text": "Head noun : The main noun in a noun phrase which may be modified by other words in the phrase .In English , the head noun is usually the rightmost word in the noun phrase .Indexing : The association of a word with all the different places the word exists in a corpus .", "label": "", "metadata": {}, "score": "79.476364"}
{"text": "The DMT 108 of an embodiment is coupled to the AT 110 .The NP - resolver 112 is also coupled to the DMT 108 and the output processor 114 .[ 0025 ] .The DMS 102 and NPRS 104 of an embodiment function to recognize input commands to the RNDS DM 100 and to translate the command into a query in order to retrieve the object of the command .", "label": "", "metadata": {}, "score": "79.55652"}
{"text": "Here is the code for the NounPhraseAnnotator .// Source : src / main / java / com / mycompany / tgni / uima / annotators / nlp / NounPhraseAnnotator.java package com .mycompany .tgni .uima . annotators . closeQuietly ( cmis ) ; IOUtils . closeQuietly ( pmis ) ; IOUtils . closeQuietly ( tmis ) ; IOUtils . sentPosDetect", "label": "", "metadata": {}, "score": "79.72689"}
{"text": "getEnd ( ) ) ; annotation .The various OpenNLP components are all initialized ( once at startup ) in the initialize ( ) method - as you can see , the code pattern is quite repetitive .The process ( ) method splits the text into sentences , sentences into tokens , POS tags the tokens , then uses the tokens and tags to chunk each sentence .", "label": "", "metadata": {}, "score": "79.774414"}
{"text": "The method of claim 37 further comprising the step of using a subsystem of said system to link sets of equivalent answer hypotheses .The method of claim 37 in which the verification evidence comprises evidence that supports the linguistic relations implied by the input string with respect to at least one of the answer hypotheses .", "label": "", "metadata": {}, "score": "79.788315"}
{"text": "In step 281 scores are assigned to the ( unlinked ) hypotheses .In one embodiment each hypothesis score is based on three criteria .The first criterion is verification evidence obtained through template matching in primary and secondary documents in step 260 .", "label": "", "metadata": {}, "score": "79.847824"}
{"text": "Predicate head 8.1.1 .Verbs and adjectives as predicate head 8.1.2 .Noun phrase as predicate head 8.1.3 .Pronoun as predicate head 8.2 .Prefatory material 8.2.1 .Subject pronouns 8.2.2 .Tense - apart markers 8.2.3 .Discourse markers 8.2.4 .", "label": "", "metadata": {}, "score": "79.872604"}
{"text": "Trees consist of tagged tokens , optionally grouped under a chunk node such as NP .However , it is possible to build chunk structures of arbitrary depth , simply by creating a multi - stage chunk grammar containing recursive rules .", "label": "", "metadata": {}, "score": "79.97547"}
{"text": "The RNDS DM 100 , with reference to .FIGS . 1 and 2 , can be used with different components for parsing , NL generation ( NLG ) , etc .Embodiments of the RNDS DM 100 may also use a third - party statistical parser , returning only weakly normalized semantic forms .", "label": "", "metadata": {}, "score": "80.04855"}
{"text": "claim 18 , wherein in response to the query the dialogue manager receives at least one object of the dialogue contribution from the database .The system of .The system of .claim 20 , wherein the code implementing further device - specific functionality includes device - specific dialogue moves .", "label": "", "metadata": {}, "score": "80.079315"}
{"text": "This section presents an overview of the two - phase operation of the MURAX system , along with an example of the output of the system .The context is the example question presented Table 7 below .TABLE 7______________________________________Example Question and Component Noun Phrases______________________________________\"Who was the Pulitzer Prize - wining novelist that ran formayor of New York City ? \"", "label": "", "metadata": {}, "score": "80.10657"}
{"text": "Robust analysis is needed for the task because the encyclopedia is composed of a significant quantity of unrestricted text .General knowledge is a broad domain , which means that it is impractical to manually provide detailed lexical or semantic information for the words of the vocabulary ( the encyclopedia contains over 100,000 word stems ) .", "label": "", "metadata": {}, "score": "80.12016"}
{"text": "getEnd ( ) + \" ): \" + annotation .And here are some test inputs and the associated noun phrases that were annotated .The annotation consists of the start and end character positions and the actual string covered .[ junit ] text : Be that as it may , the show must go on .", "label": "", "metadata": {}, "score": "80.17795"}
{"text": "[ 0024 ] .The RNDS DM 100 of the example embodiment includes an input processor 106 that receives inputs from one or more systems external to the RNDS DM .The input processor 106 is coupled to the DMS 102 , DMT 108 , and the NP - resolver 112 .", "label": "", "metadata": {}, "score": "80.216125"}
{"text": "That is to say , the answer extraction subsystem looks specifically for the names of various prime ministers who are answer hypotheses in the same context as the name \" Shastri . \"These secondary queries turn up the document that was previously discarded .", "label": "", "metadata": {}, "score": "80.226364"}
{"text": "Match sentences having the highest scores are retained for further processing .The scores of the match sentences and their locations within their respective primary documents are recorded as well .The number of match sentences retained at this step is determined by a parameter set by default or in advance by the user .", "label": "", "metadata": {}, "score": "80.35572"}
{"text": "[0065 ] .In providing multi - device dialogue management , the RNDS DM 100 of an embodiment extends the DMT infrastructure so as to allow new devices to be dynamically added or plugged in to the RNDS 200 .Once added , the new dialogue - enabled devices register themselves with the RNDS DM 100 , and nodes in the DMT 108 are associated with specific devices where appropriate .", "label": "", "metadata": {}, "score": "80.37294"}
{"text": "In step 255 the preliminary hypotheses developed in step 250 are heuristically scored and are ranked in order from highest score to lowest .The heuristic scoring of step 255 is based on the match sentence scores determined in step 245 .", "label": "", "metadata": {}, "score": "80.37426"}
{"text": "ChunkParserI ) : def _ _ init _ _ ( self , train_sents ) : . return nltk.chunk.conlltags2tree(conlltags ) .The constructor expects a list of training sentences , which will be in the form of chunk trees .It first converts training data to a form that is suitable for training the tagger , using tree2conlltags to map each chunk tree to a list of word , tag , chunk triples .", "label": "", "metadata": {}, "score": "80.396286"}
{"text": "( ( fresh [ z ] .( arco x z ) .( patho z y ) ) ) ) ) ) ; ; ( : b : a : d ) .Disequality .core.logic supports disequality constraints .( fresh [ x y ] .", "label": "", "metadata": {}, "score": "80.51286"}
{"text": "See J. E. Hopcroft and J. D. Ullman , Introduction to Automata Theory , Languages , and Computation ( Addison - Wesley , 1979 ) .In step 312 case - splitting is performed wherein maximal length noun phrases detected in step 311 can be split into short noun phrases according to initial word capitalization .", "label": "", "metadata": {}, "score": "80.52048"}
{"text": "By dropping one or more words from within multiple - word phrases in a query to produce a query that is composed of sub - phrases of the original .To increase the number of hits in Example 3 , president could be dropped , and so might Lincoln .", "label": "", "metadata": {}, "score": "80.560425"}
{"text": "These three possibilities are illustrated in 2.1 . 2.6Representing Chunks : Tags vs Trees .As befits their intermediate status between tagging and parsing ( 8 . ) , chunk structures can be represented using either tags or trees .The most widespread file representation uses IOB tags .", "label": "", "metadata": {}, "score": "80.707"}
{"text": "The DMS also encodes which adjacent moves close a dialogue move ( i.e. inactivate it so no other move can attach to it ) , in the \" CloseOn \" field .Closing a node for attachment effectively closes the corresponding thread of conversation ( revisions may reopen a \" Command \" or \" Query \" node ) .", "label": "", "metadata": {}, "score": "80.76195"}
{"text": "Examples .A classic AI program : .( use ' clojure.core.logic ) .( defne moveo [ before action after ] .( [ [ : middle : onbox : middle : hasnot ] : grasp .[ : middle : onbox : middle : has ] ] ) .", "label": "", "metadata": {}, "score": "80.769424"}
{"text": "The system of .claim 12 , wherein at least one of the plurality of dialogue moves is adapted for use across at least one different domain and application via reprogramming of the DMS .The system of .claim 12 , wherein the dialogue manager further comprises a noun phrase resolver coupled to a plurality of noun phrase - resolution scripts ( NPRSs ) and a plurality of rules , wherein each NPRS corresponds to at least one of the device and the application .", "label": "", "metadata": {}, "score": "80.84458"}
{"text": "FIG .1 is a block diagram of a representation - neutral dialogue system ( \" RNDS \" ) Dialogue Manager ( \" DM \" ) ( \" RNDS DM \" ) , under an embodiment .[0007 ] .FIG .", "label": "", "metadata": {}, "score": "80.88713"}
{"text": "Eddy N B - PER Bonte N I - PER is V O woordvoerder N O van Prep O diezelfde Pron O Hogeschool N B - ORG .Punc O .In this representation , there is one token per line , each with its part - of - speech tag and its named entity tag .", "label": "", "metadata": {}, "score": "80.90703"}
{"text": "The scripting also allows for encapsulation of device information in support of the plug - and - play capability of the RNDS 200 .Consequently , the RNDS DM 100 and RNDS 200 provide a framework in which new devices , or dialogue - capability for existing devices , can easily be added to a host system without disruption to an existing infrastructure .", "label": "", "metadata": {}, "score": "80.93114"}
{"text": "To find out whether an answer hypothesis is a \" novelist \" , for example , a query comprising the answer hypothesis and the word \" novelist \" is constructed and executed to yield a list of relevant articles .Documents whose match sentences contain co - occurrences of an answer hypothesis and a question phrase are called secondary documents .", "label": "", "metadata": {}, "score": "81.0875"}
{"text": "In these cases , the draw method can be very useful .It opens a new window , containing a graphical representation of the tree .The tree display window allows you to zoom in and out , to collapse and expand subtrees , and to print the graphical representation to a postscript file ( for inclusion in a document ) .", "label": "", "metadata": {}, "score": "81.09351"}
{"text": "The query once generated is provided to a database or knowledge base of the RNDS in order to retrieve an object ( or multiple objects ) corresponding to the dialogue contribution from the database .[ 0034 ] .Components of the RNDS DM 100 and/or the RNDS 200 may couple to other components not shown in the figures herein .", "label": "", "metadata": {}, "score": "81.134926"}
{"text": "The following JUnit test runs the NounPhraseAnnotator primitive AE against some input sentences .// Source : src / test / java / com / mycompany / tgni / uima / annotators / nlp / NounPhraseAnnotatorTest.java package com .mycompany .tgni .", "label": "", "metadata": {}, "score": "81.16464"}
{"text": "[ ?pos2 : onfloor ? box ? has ] ] ) ) .( defne cangeto [ state out ] .( [ [ _ _ _ : has ] true ] ) .( [ _ _ ] ( fresh [ action next ] .", "label": "", "metadata": {}, "score": "81.25636"}
{"text": "In general , the depth of inheritance is unbounded ( e.g. a sub - move of the \" play \" command move may be defined that is applicable in very specific contexts ) .[ 0051 ] .One type of move for which the inheritance of the DMS is particularly useful is information - query moves across devices .", "label": "", "metadata": {}, "score": "81.26025"}
{"text": "The functions nltk.tree.pprint ( ) and nltk.chunk.tree2conllstr ( ) can be used to create Treebank and IOB strings from a tree .Write functions chunk2brackets ( ) and chunk2iob ( ) that take a single chunk tree as their sole argument , and return the required multi - line string representation .", "label": "", "metadata": {}, "score": "81.2695"}
{"text": "2 Chunking .The basic technique we will use for entity detection is chunking , which segments and labels multi - token sequences as illustrated in 2.1 .The smaller boxes show the word - level tokenization and part - of - speech tagging , while the large boxes show higher - level chunking .", "label": "", "metadata": {}, "score": "81.36943"}
{"text": "The NLU module 204 outputs a structured meaning representation that may be based on statistical models trained on in - domain linguistic data and the available knowledge base .The RNDS DM 100 is coupled to the NLU module 204 and receives the structured meaning representations at one or more inputs .", "label": "", "metadata": {}, "score": "81.38776"}
{"text": "Holonyms are the opposite of meronyms in which , for the above examples , Y would be a meronym of X. .Term features could be a word or a word sequence or pattern in a domain .Term features are usually two set of words in which one set of words occurs more often in relation terms and seldom in non - relation terms , while the other set of words occurs more often in non - relation terms and seldom in relation terms .", "label": "", "metadata": {}, "score": "81.46492"}
{"text": "The method of claim 1 in which the step of using a processor to verify the answer hypothesis comprises using the processor to perform lexico - syntactic analysis automatically .The method of claim 19 which the lexico - syntactic analysis comprises lexico - syntactic pattern matching .", "label": "", "metadata": {}, "score": "81.46676"}
{"text": "FIG .2 is a flow diagram that illustrates the main functional tasks of the ontological learning system , according to an embodiment .In block 202 , the ontological learning component performs a pattern generation process using CME or similar method to identify coordinate relations and extract terms .", "label": "", "metadata": {}, "score": "81.50978"}
{"text": "claim 1 wherein the terms from the noun - phrases in the document are extracted using Conditional Maximum Entropy modeling .Beschreibung .FIELD .Embodiments of the invention relate generally to natural language processing , and more specifically to learning ontological relations from documents .", "label": "", "metadata": {}, "score": "81.53535"}
{"text": "An example of this scheme is shown in 2.5 .IOB tags have become the standard way to represent chunk structures in files , and we will also be using this format .Here is how the information in 2.5 would appear in a file : .", "label": "", "metadata": {}, "score": "81.54318"}
{"text": "Introduction 1.1 Political organisation 1.2 .Language and life in Boumaa 1.3 .Linguistic profile of Fijian 1.4 .Fijian within the Austronesian language family 1.5 .Data base for this study 2 .Phonology 2.1 .Consonants 2.2 .Vowels and diphthongs 2.3 .", "label": "", "metadata": {}, "score": "81.54712"}
{"text": "The RNDS 200 therefore provides a combination of powerful practical core dialogue management processes with easy scriptable definitions of domain - specific information , such as dialogue - moves and NP - resolution mappings .The RNDS 200 is thus customizable to new domains and applications , and also provides the means for plug - and - play multi - device dialogue management as described above .", "label": "", "metadata": {}, "score": "81.61564"}
{"text": "Dialog Management includes interpretation of speaker utterances with respect to the shared context , as well as techniques and strategies for managing the interaction between the dialog participants .Activity - oriented dialogue systems have been in development for applications such as multimodal control of robotic devices , speech - enabled tutoring systems , and conversational interaction with in - car devices .", "label": "", "metadata": {}, "score": "81.693436"}
{"text": "The input character string represents a sequence of one or more natural language words .Although the input string is typically in the form of a natural language question , this is not always the case ; for example , an input string can be a statement , a paragraph , or even an entire article or other document .", "label": "", "metadata": {}, "score": "81.74419"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .Embodiments of the present invention are illustrated by way of example and not limitation in the figures of the accompanying drawings , in which like references indicate similar elements and in which : .FIG .", "label": "", "metadata": {}, "score": "81.74423"}
{"text": "Questions that begin with \" why \" or \" how \" typically expect a procedural answer rather than a noun phrase answer ( e.g. , \" How do you make a loaf of bread ?The expectations established by the interrogative words can be used to filter various answer hypotheses .", "label": "", "metadata": {}, "score": "82.06784"}
{"text": "PersistentHashMap internally .This may be replaced with something that provides better performance for triangular substitutions .Goals .Simplicity .Optimizations should not destroy the ideas behind the original design .Any person willing to take take the time to understand the original Scheme implementation should have little trouble understanding how core.logic is put together .", "label": "", "metadata": {}, "score": "82.12366"}
{"text": "Such manual data may be exemplified by user manuals , organizational charts , catalogs , operational instructions , field manuals , scientific papers , or any other similar document .Such documents are characterized by the fact that they typically involve descriptions of data or certain content items , and are indexed or otherwise cataloged .", "label": "", "metadata": {}, "score": "82.22917"}
{"text": "This input includes a set of relevant documents and questions input to user interface 7 , which are routed to answer extraction subsystem 15 from user interface 7 via primary query construction subsystem 10 .Primary query construction subsystem 10 sends queries via channel 14 to information retrieval subsystem 11 , which sends back documents or document identifiers retrieved from text corpus 12 .", "label": "", "metadata": {}, "score": "82.3033"}
{"text": "Typically the primary documents are documents that are retrieved from the text corpus in response to IR queries executed in advance of step 200 .The primary documents can also be supplied from other sources .They can be , for example , documents provided by a clipping service , documents produced during litigation in response to a document production request , or documents obtained during a previous information retrieval session using a different corpus .", "label": "", "metadata": {}, "score": "82.312454"}
{"text": "[ pos2 : onfloor box has ] ] ) ) .( defne cangeto [ state out ] .( [ [ _ _ _ : has ] true ] ) .( [ _ _ ] ( fresh [ action next ] .", "label": "", "metadata": {}, "score": "82.36656"}
{"text": "Plug - and - play typically involves adding new components that provide enhanced functionality to the RNDS 200 without disrupting the existing framework .The RNDS 200 of an embodiment implements the plug - and - play environment through the use of a specification language by which components advertise their capabilities , as well as encapsulation of the implementation of the component . [", "label": "", "metadata": {}, "score": "82.36888"}
{"text": "Broadening can be accomplished , for example , by relaxing order or proximity constraints .Secondary queries are performed in step 265 if in step 264 no template matches are found among the primary documents or only a few template matches are found .", "label": "", "metadata": {}, "score": "82.42908"}
{"text": "About me .I am a programmer interested in Semantic Search , Ontology , Natural Language Processing and Machine Learning .My programming languages of choice are Java , Scala , and Python .I love solving problems and exploring different possibilities with open source tools and frameworks .", "label": "", "metadata": {}, "score": "82.478325"}
{"text": ", \" which supports Mrs. Gandhi as the best answer hypothesis .6.7 Linking Equivalent Hypotheses .Once template matching is complete for all relations and hypotheses , different hypotheses that are likely to refer to the same answer can be linked in step 270 .", "label": "", "metadata": {}, "score": "82.57418"}
{"text": "The last hypothesis , ( \" John Kennedy \" doc30 ) , is not linked to any other and so retains its previous score .7.3 Ranking Hypotheses and Organizing Results .In step 285 the hypotheses are ranked according to their scores from highest to lowest .", "label": "", "metadata": {}, "score": "82.575806"}
{"text": "In FIG .1 , answer extraction subsystem 15 executes on a computing node 4 that comprises processor 5 and memory 6 .Computing node , processor , memory , user interface , and optional storage device ( 4 , 5 , 6 , 7 , 8) .", "label": "", "metadata": {}, "score": "82.681526"}
{"text": "They do not generally make use of the terms available in certain documents , such as manuals .In general , present ontological determination systems do not attempt to identify both hypernym and part - whole relations from documents or any type of manual text .", "label": "", "metadata": {}, "score": "82.71958"}
{"text": "using the answer extraction subsystem to verify the additional phrases as answer hypotheses .The method of claim 28 in which the step of using the answer extraction subsystem to verify the additional phrases as answer hypotheses further comprises the step of using the answer extraction subsystem to generate secondary queries to retrieve secondary documents .", "label": "", "metadata": {}, "score": "82.73065"}
{"text": "The method of .claim 28 , wherein the generic dialogue scripts include dialogue move scripts ( DMS ) and noun phrase - resolution scripts ( NPRS ) .The method of .claim 28 , further comprising receiving additional ones of the generic dialogue scripts , wherein the additional ones extend at least one of the domains , device , and applications that interact with the dialogue management system .", "label": "", "metadata": {}, "score": "82.877075"}
{"text": "Like tokenization , which omits whitespace , chunking usually selects a subset of the tokens .Also like tokenization , the pieces produced by a chunker do not overlap in the source text .Figure 2.1 : Segmentation and Labeling at both the Token and Chunk Levels .", "label": "", "metadata": {}, "score": "82.90134"}
{"text": "The hypothesis \" Earl Warren \" has associated with it sentences for which templates based on the type phrase were matched ; the maximum number of type phrase words matched within any such sentence is 2 . \"Kennedy \" appears in sentences for which a maximum of 1 word of the type phrase was matched .", "label": "", "metadata": {}, "score": "82.927734"}
{"text": "Performance is a central concern of this project .Anything that makes it slower will probably not be adopted .Anything that makes it faster without overly complicating the implementation will be considered .It would be interesting to see how we fare on the standard Prolog benchmarks .", "label": "", "metadata": {}, "score": "82.95455"}
{"text": "( fun y ) .( likes x y ) .It 's important to index relationships so that the time to run queries does n't grow linearly with the number of facts .You can create indexes for any element of the fact tuple .", "label": "", "metadata": {}, "score": "83.04147"}
{"text": "claim 1 , wherein the long - distance ontological relations are used in a natural language processing system to build a knowledge base for use with a natural language processing system .An apparatus , comprising : . an input stage for inputting noun phrase portions of sentences in the document ; . a database functionally coupled to the input stage and configured to store a knowledge base including words from the document ; and .", "label": "", "metadata": {}, "score": "83.150536"}
{"text": "It looks like the original Kanren paper may have some good approaches .Constraint Logic Programming - Constraint Handling Rules ( CHR ) is particularly inspiring .William Byrd and Daniel Friedman are working on CLP(FD ) and CLP(X ) extensions to miniKanren .", "label": "", "metadata": {}, "score": "83.19084"}
{"text": "Seems to close many performance gaps between SWI - Prolog and miniKanren .However maintaining correctness seems difficult .Perhaps limit optimization to DCGs and pattern matching sugar .Again , the original Kanren paper may have insights here .Future Things .", "label": "", "metadata": {}, "score": "83.197266"}
{"text": "The documents of the set are called the primary documents .The method then analyzes the question to detect the noun phrases that it contains .In this example , the noun phrases are \" Pulitzer Prize , \" \" novelist , \" \" mayor , \" and \" New York City . \" The method assumes that the documents contain some or all these noun phrases .", "label": "", "metadata": {}, "score": "83.20337"}
{"text": "N is a parameter determined , for example , by default or by the user in advance .For example , N can be set equal to a fixed , predetermined number , such as 30 .Hypothesis Verification .This section examines step 260 , hypothesis verification , in detail .", "label": "", "metadata": {}, "score": "83.214554"}
{"text": "Title phrases are word sequences that represent titles of books , motion pictures , or other works .They can in some cases include or even be the same as noun phrases detected in step 310 .In other cases they can include verbs or other parts of speech that are not noun phrase components .", "label": "", "metadata": {}, "score": "83.24568"}
{"text": "[ 0066 ] .The RNDS DM 100 also performs device selection ( i.e. , determining with which device an utterance is associated ) as a component process of multi - device dialogue management .The device selection decision process of the RNDS DM 100 involves lexical and semantic information , dialogue move classification , and discourse structure , as well as bias towards the \" current device \" .", "label": "", "metadata": {}, "score": "83.24972"}
{"text": "The method of claim 37 further comprising the step of using a subsystem of said system to generate at least one query .The method of claim 45 in which the evidence gathered during the step of using a subsystem of said system to gather verification evidence comprises the content of at least one document retrieved in response to the query .", "label": "", "metadata": {}, "score": "83.32362"}
{"text": "[ 0104 ] .The above description of illustrated embodiments of the RNDS is not intended to be exhaustive or to limit the RNDS to the precise form disclosed .While specific embodiments of , and examples for , the RNDS are described herein for illustrative purposes , various equivalent modifications are possible within the scope of the RNDS , as those skilled in the relevant art will recognize .", "label": "", "metadata": {}, "score": "83.32434"}
{"text": "core.logic has Prolog - type DCG syntax for parsing : .( [ [ : v ' eats ] ] ' [ eats ] ) ) .( [ [ : n ' bat ] ] ' [ bat ] ) .", "label": "", "metadata": {}, "score": "83.41469"}
{"text": "( [ : a : b ] ) .( [ : b : a ] ) .( [ : b : d ] ) ) .( def patho .( tabled [ x y ] .( conde .", "label": "", "metadata": {}, "score": "83.499855"}
{"text": "( [ : a : b ] ) .( [ : b : a ] ) .( [ : b : d ] ) ) .( def patho .( tabled [ x y ] .( conde .", "label": "", "metadata": {}, "score": "83.499855"}
{"text": "A term like Yankee will be ordinary modifier in some contexts , but will be marked as an entity of type ORGANIZATION in the phrase Yankee infielders .Further challenges are posed by multi - word names like Stanford University , and by names that contain other names such as Cecil H. Green Library and Escondido Village Conference Service Center .", "label": "", "metadata": {}, "score": "83.54635"}
{"text": "claim 1 , wherein identifying short - distance coordinate terms comprises performing statistical classification on the coordinate terms .The method of .claim 1 , wherein identifying short - distance ontological relations comprises performing statistical classification on the ontological relations .", "label": "", "metadata": {}, "score": "83.68384"}
{"text": "While it contains two occurrences of Washington , named entity recognition should tell us that neither of them has the correct type .How do we go about identifying named entities ?One option would be to look up each word in an appropriate list of names .", "label": "", "metadata": {}, "score": "83.69295"}
{"text": "FIG .2 is a block diagram of a representation - neutral dialogue system ( \" RNDS \" ) 200 , under an embodiment .The RNDS 200 includes a RNDS DM 100 coupledd to one or more other components as appropriate to a configuration of the RNDS 200 and/or a system hosting or including the RNDS 200 .", "label": "", "metadata": {}, "score": "83.69732"}
{"text": "Representation - neutral dialogue systems and methods ( \" RNDS \" ) are described that include multi - application , multi - device spoken - language dialogue systems based on the information - state update approach .The RNDS also allows seamless interaction with a community of devices . receiving an input pattern generated from an acoustic signal that includes a description of a dialogue contribution from a speaker ; . identifying the description and at least one parameter of the description using a dialogue move script ( DMS ) , wherein the DMS corresponds to at least one of a device and an application ; and . mapping the description to a dialogue move using the DMS , the dialogue move corresponding to the identified parameter and independent of the device and application .", "label": "", "metadata": {}, "score": "83.75418"}
{"text": "He found in Boumaa Fijian a wealth of striking features unknown in commonly studied languages and on the basis of his fieldwork prepared this grammar .Fijian is an agglutinating language , one in which words are formed by the profligate combining of morphemes .", "label": "", "metadata": {}, "score": "83.86618"}
{"text": "[ 0035 ] .While one of each of the components comprising the RNDS DM 100 and/or RNDS 200 are shown , various alternative embodiments include any number and/or combination of each of these components coupled in various configurations known in the art .", "label": "", "metadata": {}, "score": "83.98607"}
{"text": "( defne appendo [ x y z ] .( [ ( ) _y ] ) .( [ [ ? a .d ] _ [ ? a .r ] ] ( appendo ?d y ? r ) ) ) .", "label": "", "metadata": {}, "score": "84.12944"}
{"text": "The TTS module 212 receives the organized content from the LG module 210 ( e.g. , word sequence with tagged features ) and produces speech waveforms .[ 0030 ] .Components of the RNDS DM 100 also couple to one or more Devices 250 using a Device Manager 220 and one or more respective Device APIs 222 .", "label": "", "metadata": {}, "score": "84.13161"}
{"text": "The result produced by step 300 is a tagged input string .After step 300 is complete , steps 310 , 315 , and 320 are performed either in series or , as illustrated in FIG .3 , in parallel .", "label": "", "metadata": {}, "score": "84.174164"}
{"text": "4 flowcharts the component steps of preliminary hypothesis generation in one embodiment of the method .In step 241 match sentences are located in the primary documents .Sentences are found in the primary documents that contain phrases from the input string or parts of such phrases .", "label": "", "metadata": {}, "score": "84.31619"}
{"text": "We can use the NLTK corpus module to access a larger amount of chunked text .The CoNLL 2000 corpus contains 270k words of Wall Street Journal text , divided into \" train \" and \" test \" portions , annotated with part - of - speech tags and chunk tags in the IOB format .", "label": "", "metadata": {}, "score": "84.373505"}
{"text": "( cangeto next out ) ) ) ) .( run 1 [ q ] .( cangeto [ : atdoor : onfloor : atwindow : hasnot ] q ) ) ; ( true ) .A classic Prolog program : . append ( [ ] , Y , Y ) .", "label": "", "metadata": {}, "score": "84.48162"}
{"text": "( cangeto next out ) ) ) ) .( run 1 [ q ] .( cangeto [ : atdoor : onfloor : atwindow : hasnot ] q ) ) ; ( true ) .A classic Prolog program : . append ( [ ] , Y , Y ) .", "label": "", "metadata": {}, "score": "84.48162"}
{"text": "For \" Kennedy , \" there are sentences that includes both the word \" Kennedy \" and the word \" Justice . \"Since the phrase \" racial justice \" shares only one word with the type phrase \" Chief Justice , \" the maximum number of matching words for is 1 for this hypothesis .", "label": "", "metadata": {}, "score": "84.48442"}
{"text": "Each of the steps 261 , 262 , 263 , 264 , 265 , 266 , and 270 will now be more fully described .6.3 Linguistic Relations .In step 261 the input string is analyzed to determine the linguistic relations that are to be verified in subsequent steps .", "label": "", "metadata": {}, "score": "84.57756"}
{"text": "Sujit , If you are processing the entire text , have you thought about discarding the co - references so that you will not have to worry about you , his , me etc which come up as nouns .Generally they show up as [ NP his / PRP$ first / JJ ] or [ NP whose / WP$ father / NN ] or [ NP I / PRP ] or [ NP the / DT process / NN ] in the chunker output ( as it does shallow parsing including pronouns and determinants as NPs ) .", "label": "", "metadata": {}, "score": "84.638916"}
{"text": "FIG .6 is a sample Dialogue Move Script ( \" DMS \" ) 602 for a \" play \" Command for an MP3 device , under an embodiment .Variables in the DMS 602 correspond to variables in the AM for the corresponding device .", "label": "", "metadata": {}, "score": "84.648384"}
{"text": "Instead of passing in a JCas , pass in your text directly ( the process ( ) method gets the text using JCas.getDocumentText ( ) ) .i use OpenNLP without UIMA.I created a function for each tool , but my Chunking function does not work .", "label": "", "metadata": {}, "score": "84.66957"}
{"text": "The program has been demonstrated on a Sun Workstation , although it will be apparent to those of skill in the art that a wide variety of programming languages and hardware configurations can readily be used based on this disclosure without departing from the scope of the invention .", "label": "", "metadata": {}, "score": "84.69926"}
{"text": "While certain aspects of the ontology learning method are presented below in certain claim forms , the inventors contemplate the various aspects of the methodology in any number of claim forms .For example , while only one aspect may be recited as embodied in machine - readable medium , other aspects may likewise be embodied in machine - readable medium .", "label": "", "metadata": {}, "score": "84.761795"}
{"text": "If secondary documents are retrieved in response to the secondary queries in step 265 , step 266 is performed .In step 266 the secondary documents retrieved in step 265 are analyzed to determine whether their match sentences do in fact satisfy the template .", "label": "", "metadata": {}, "score": "84.775665"}
{"text": "The DMS maps 306 the description to a dialogue move , where the dialogue move is independent of the device and application and corresponds to the recognized parameter .The dialogue moves are customizable or adaptable for use across numerous domains and/or applications via reprogramming of the DMS .", "label": "", "metadata": {}, "score": "84.811844"}
{"text": "The described methods can be used in a particular learning method , such as the maximum entropy framework , or they can be used in other learning methods .Some other possibilities for implementing aspects include : microcontrollers with memory ( such as EEPROM ) , embedded microprocessors , firmware , software , etc .", "label": "", "metadata": {}, "score": "84.83751"}
{"text": "Other things being equal , an answer hypothesis having more instances of a match is preferred .However , it is less likely that spurious matches for an answer hypothesis will occur for several different phrase relations that appear in different places in the encyclopedia .", "label": "", "metadata": {}, "score": "84.95729"}
{"text": "For example , if in step 311 the noun phrase \" New York City borough \" is detected , then in step 312 it can be split as .New York City borough .because the initial letters of the words of \" New York City \" are capitalized while the initial letter of \" borough \" is not .", "label": "", "metadata": {}, "score": "85.03583"}
{"text": "Step 240 can likewise be carried out using alternative techniques for analyzing match sentences .Also , different approaches to the scoring and ranking of preliminary hypotheses can be used .Sentences that appear nearby ( e.g. , adjacent to or in the same paragraph as ) the match sentences in the primary documents can be analyzed in addition to the match sentences themselves in order to detect phrases to be used as preliminary hypotheses .", "label": "", "metadata": {}, "score": "85.03755"}
{"text": "The RNDS DM 100 therefore formulates a query that includes information of the type of object a user has requested ( song ) , along with any specified constraints ( e.g. , name , artist , etc . ) .[ 0026 ] .", "label": "", "metadata": {}, "score": "85.14103"}
{"text": "Chinking is the process of removing a sequence of tokens from a chunk .If the matching sequence of tokens spans an entire chunk , then the whole chunk is removed ; if the sequence of tokens appears in the middle of the chunk , these tokens are removed , leaving two chunks where there was only one before .", "label": "", "metadata": {}, "score": "85.19602"}
{"text": "claim 1 , further comprising adapting the dialogue move for use across at least one of a plurality of different domains and a plurality of different applications via reprogramming of the DMS .The method of .claim 1 , further comprising : . identifying at least one of the device and application to which the description corresponds using a noun phrase of the description ; . selecting a noun phrase - resolution script ( NPRS ) that corresponds to at least one of the identified device and application and accessing noun phrase - resolution rules via the selected NPRS ; and . translating the description and generating a query that corresponds to at least one of the device and the description using the noun phrase - resolution rules .", "label": "", "metadata": {}, "score": "85.27017"}
{"text": "Step 240 is analyzed in more detail in section 5 below .The result of step 240 is a set of selected hypotheses .In step 260 the answer extraction subsystem verifies hypotheses from the set of selected hypotheses produced in step 240 .", "label": "", "metadata": {}, "score": "85.30381"}
{"text": "The IR subsystem is a process that executes on one or more computing nodes ( not shown ) .Typically the IR subsystem executes on a node or nodes distinct from the node or nodes on which the answer extraction subsystem executes , but this need not be the case .", "label": "", "metadata": {}, "score": "85.34851"}
{"text": "5 is a portion of a sample Activity Model ( \" AM \" ) 530 for an MP3 device , under an embodiment .The \" required \" argument position of this AM 530 includes \" Playable \" , which corresponds to a class from the associated ontology of objects associated with this application ; \" playable - object \" is a variable name filled by matching a dialogue move , as described below .", "label": "", "metadata": {}, "score": "85.389465"}
{"text": "The DMS 102 thus allows dialog moves to be used in a new application or to command a new device without changes to the core Java code of the dialog move .The DMS 102 similarly allows for efficient generation of new applications for new devices as well .", "label": "", "metadata": {}, "score": "85.453735"}
{"text": "The text of the encyclopedia is written in an impersonal style and the word is most often used in phrases like \" King George I \" and \" World War I \" .The tagger trained on encyclopedia text assigned \" I \" appropriately ( as a proper noun ) whereas the tagger trained on the Brown corpus ( a mixture of different kinds of text ) assigned such instances as a pronoun .", "label": "", "metadata": {}, "score": "85.49065"}
{"text": "The computerized database can be implemented on any suitable hardware ; typically such hardware comprises one or more mass storage devices such as hard disks or CD - ROMs .Channels ( 14 , 16 , 17 ) .In a system suitable to the method of the present invention the various processes communicate with one another through communications channels .", "label": "", "metadata": {}, "score": "85.50167"}
{"text": "\" the word \" succeeded \" is a verb .The answer extraction subsystem recognizes this and further recognizes that questions that begin with \" who \" often call for answers that are persons ' names .Accordingly , the answer extraction subsystem constructs a template of the form \" X succeeded Shastri \" and tries to find a document containing a phrase that matches this template .", "label": "", "metadata": {}, "score": "85.555435"}
{"text": "The method of claim 28 further comprising the step of using the answer extraction subsystem to output at least one of the additional phrases .The method of claim 28 in which the step of using the answer extraction subsystem to verify the additional phrases as answer hypotheses includes using the answer extraction subsystem to determine linguistic relations based on the phrases detected in the input string .", "label": "", "metadata": {}, "score": "85.6031"}
{"text": "( fresh [ x y ] .( fresh [ x y ] .Unification .core.logic comes with a unifier that can be used much like core.unify : .( unifier ' ( ? x ?y ?z ) ' ( 1 2 ?", "label": "", "metadata": {}, "score": "85.80493"}
{"text": "[ 0101 ] .Some other possibilities for implementing aspects of the RNDS include : microcontrollers with memory ( such as electronically erasable programmable read only memory ( EEPROM ) ) , embedded microprocessors , firmware , software , etc .Furthermore , aspects of the RNDS may be embodied in microprocessors having software - based circuit emulation , discrete logic ( sequential and combinatorial ) , custom devices , flizzy ( neural ) logic , quantum devices , and hybrids of any of the above device types .", "label": "", "metadata": {}, "score": "85.82015"}
{"text": "In response to these queries information retrieval subsystem 11 retrieves documents from text corpus 12 and sends these back to answer extraction subsystem 15 .The output of answer extraction subsystem 15 is presented to the user via user interface 7 .", "label": "", "metadata": {}, "score": "85.919624"}
{"text": "Representation - neutral dialogue systems and methods ( \" RNDS \" ) are described that include multi - application , multi - device spoken - language dialogue systems based on the information - state update approach .11142196 , 142196 , US 2006/0271351 A1 , US 2006/271351 A1 , US 20060271351 A1 , US 20060271351A1 , US 2006271351 A1 , US 2006271351A1 , US - A1 - 20060271351 , US - A1 - 2006271351 , US2006/0271351A1 , US2006/271351A1 , US20060271351", "label": "", "metadata": {}, "score": "85.99335"}
{"text": "In this case , the scores assigned to the three preliminary hypotheses are as follows : .The preliminary hypothesis \" John Kennedy \" is treated likewise ; however , since it appears only in sentences that received low match scores , it receives a lower overall score .", "label": "", "metadata": {}, "score": "86.04443"}
{"text": "Veimaamaa \" half \" and fractions 13.5 .Distributives 14 .Prepositions 14.1 .Form 14.2 .Functions of i and mai 14.3 . 'Ei \" together with \" 14.4 .The grammaticisation of baleta 14.4.1 .Preposition baleta - baleti \" concerning \" 14.4.2 .", "label": "", "metadata": {}, "score": "86.151436"}
{"text": "Furthermore , unawareness seems to be related to difficulties in daily life functioning , increased caregiver burden , and deterioration in global dementia severity .Factors that may be of influence on the inconclusive data are discussed , as are future directions of research .", "label": "", "metadata": {}, "score": "86.218475"}
{"text": "0048 ] .The use of easily - extensible DMS 102 is consistent with using other approaches to achieve broad semantic coverage , such as use of an ontology or knowledge - base as mentioned above .However , it additionally provides a general approach for supplying application - specific information to the RNDS DM 100 , for customizing it to new domains , as well as enabling the plug and play multi - device infrastructure of the RNDS 200 described herein .", "label": "", "metadata": {}, "score": "86.554245"}
{"text": "getAE ( \" conf / descriptors / NounPhraseAE . out .runAE ( ae , input , UimaUtils . getAnnotationIndex ( NounPhraseAnnotation . iterator ( ) ; it .next ( ) ; System . out . println ( \" ...( \" + annotation .", "label": "", "metadata": {}, "score": "86.56169"}
{"text": "Answer extraction subsystem 15 is coupled via channel 17 to an information retrieval subsystem 11 that operates on a text corpus 12 .In response to questions input by the user at a user interface 7 and a set of relevant documents known to be present in text corpus 12 that is received via channel 16 , answer extraction subsystem 15 generates and verifies answer hypotheses .", "label": "", "metadata": {}, "score": "86.661446"}
{"text": "One skilled in the relevant art , however , will recognize that these embodiments can be practiced without one or more of the specific details , or with other components , systems , etc .In other instances , well - known structures or operations are not shown , or are not described in detail , to avoid obscuring aspects of the disclosed embodiments .", "label": "", "metadata": {}, "score": "86.82814"}
{"text": "[ 0063 ] .Referring to .FIG .2 , new devices that register with the RNDS DM 100 encapsulate all information required for use by the RNDS DM 100 in managing dialogue with these new devices .This encapsulated information includes four components in an embodiment , where the four components include the DMS 232 , as described above , the AM 230 describing any device functionality accessible by the dialogue , device - specific ontology and/or knowledge base , and rules for device - specific NP - resolution 234 .", "label": "", "metadata": {}, "score": "87.035095"}
{"text": "c ] _ ] ( findo x ?c o ) ) ) .( defn typedo [ c x t ] .( conda .( ( lvaro x ) ( findo x c t ) ) .( ( matche [ c x t ] .", "label": "", "metadata": {}, "score": "87.07756"}
{"text": "Reducing the number of hits ( narrowing ) .Increasing the number of hits ( broadening ) .5.1 Narrowing .Narrowing is performed to attempt to reduce the number of hits .It can also serve to refine the ranking of the documents .", "label": "", "metadata": {}, "score": "87.0999"}
{"text": "In step 315 the tagged input string is further analyzed to detect main verbs .In step 320 the input string is analyzed to detect title phrases .Each of steps 310 , 315 , and 320 will now be further described .", "label": "", "metadata": {}, "score": "87.119026"}
{"text": "An appendix comprising 168 pages is included as part of this application .The appendix provides thirteen files of a source code software program for implementation of an embodiment of the method of the invention on a digital computer .The files include seven source code files that provide the principal functionality of the embodiment plus six additional support files .", "label": "", "metadata": {}, "score": "87.18074"}
{"text": "Suppose further that there are four answer hypotheses , namely , \" Oswald , \" \" Earl Warren , \" \" Kennedy , \" and \" Warren Earl .TABLE 2______________________________________Scoring Measures for Example 2Hypothesis Type phrase words matches______________________________________Oswald 0EarlWarren 2Kennedy 1Warren Earl 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "87.226395"}
{"text": "( arco x y ) ] .[ ( fresh [ z ] .( arco x z ) .( patho z y ) ) ] ) ) ) ; ; ( : b : a : d ) .Disequality .", "label": "", "metadata": {}, "score": "87.2346"}
{"text": "In other embodiments , the user interface can run on a processor other than processor 5 , or can be implemented on hardware that is at a location remote from processor 5 and memory 6 .Persons of skill in the art will appreciate that a vast range of hardware and software can be used to implement node 4 , processor 5 , memory 6 , user interface 7 , and optional storage device 8 within the scope of the present invention .", "label": "", "metadata": {}, "score": "87.26174"}
{"text": "In the Humphrey Bogart example above , the method of the present invention would generate the answer hypothesis \" Key Largo \" and find that hypothesized term in one or more documents previously retrieved from an IR system or subsystem .The present invention can , in the context of a question that asks for a specific answer , provide an answer that is nowhere to be found in the question .", "label": "", "metadata": {}, "score": "87.2947"}
{"text": "1 will now be described in greater detail .Answer extraction subsystem ( 15 ) .The answer extraction subsystem is a process that executes on one or more computing nodes .By \" process \" is meant a software entity that comprises one or more threads of execution and possibly one or more input / output streams .", "label": "", "metadata": {}, "score": "87.30937"}
{"text": "The method of claim 28 additionally comprising the step of using the answer extraction subsystem to score the additional phrases thus verified as answer hypotheses .The method of claim 31 additionally comprising the step of using the answer extraction subsystem to rank the additional phrases thus verified as answer hypotheses according to their scores .", "label": "", "metadata": {}, "score": "87.341286"}
{"text": "In Table 8 , the first two sentences are from primary documents .The last sentence confirming Norman Mailer as a novelist is a from a secondary document .The sentence was confirmed by a lexico - syntactic pattern which identifies the answer hypothesis as being in a list - inclusion relationship with the type phrase .", "label": "", "metadata": {}, "score": "87.365364"}
{"text": "In the drawings , the same reference numbers identify identical or substantially similar elements or acts .To easily identify the discussion of any particular element or act , the most significant digit or digits in a reference number refer to the Figure number in which that element is first introduced ( e.g. , element 100 is first introduced and discussed with respect to .", "label": "", "metadata": {}, "score": "87.36656"}
{"text": "The DMS 102 and NPRS 104 of the RNDS DM 100 therefore enhance extensibility , customization , and reuse of the RNDS DM 100 , as well as provide the basis of the multi - device plug - and - play RNDS 200 .", "label": "", "metadata": {}, "score": "87.57855"}
{"text": "claim 30 , wherein the additional ones are received from at least one of new devices and new applications that couple to the dialogue management system .Description .TECHNICAL FIELD .[ 0001 ] .The disclosure herein relates generally to dialogue management and , more particularly , to management of multi - application , multi - device spoken - language dialogue systems .", "label": "", "metadata": {}, "score": "87.84563"}
{"text": "5 is a portion of a sample Activity Model ( \" AM \" ) for an MP3 device , under an embodiment .[ 0011 ] .FIG .6 is a sample DMS for a \" play \" Command for an MP3 device , under an embodiment .", "label": "", "metadata": {}, "score": "87.852615"}
{"text": "Time Expressions 15.1 .Time words 15.2 .Other time expressions 16 .Interrogatives 16.1 .Cei \" who \" 16.2 .Cava \" what , which \" 16.3 .Vei \" where \" 16.4 .Vica \" how many / much , some \" 16.5 .", "label": "", "metadata": {}, "score": "88.00296"}
{"text": "Further details on the properties of the dialogue move scripting language follow .While this sample DMS 602 is for a particular command used with a particular type of device , the embodiments described herein are not limited to this command or this device .", "label": "", "metadata": {}, "score": "88.046455"}
{"text": "In this representation there is one token per line , each with its part - of - speech tag and chunk tag .This format permits us to represent more than one chunk type , so long as the chunks do not overlap .", "label": "", "metadata": {}, "score": "88.110214"}
{"text": "In step 265 secondary queries are constructed and executed .Documents retrieved in response to secondary queries are called secondary documents .If secondary documents are successfully retrieved in step 265 , then in step 266 the filled - in templates generated in step 263 are matched against the secondary documents in the same manner as they were matched against the primary documents in step 264 .", "label": "", "metadata": {}, "score": "88.11317"}
{"text": "MuNPEx in GATE Developer : Screenshot of MuNPEx running on a German text .Installation .If you have GATE 7 or better , you can install MuNPEx directly from within GATE using the CREOLE Plugin Manager by selecting our Semantic Software Lab repository .", "label": "", "metadata": {}, "score": "88.243866"}
{"text": "( fresh [ x y ] .( typedo [ ] .Tabling .core.logic as of version 0.5.4 supports tabling .Certain kinds of logic programs that would not terminate in Prolog will terminate in core.logic if you create a tabled goal .", "label": "", "metadata": {}, "score": "88.29051"}
{"text": "( fresh [ x y ] .( typedo [ ] .Tabling .core.logic as of version 0.5.4 supports tabling .Certain kinds of logic programs that would not terminate in Prolog will terminate in core.logic if you create a tabled goal .", "label": "", "metadata": {}, "score": "88.29051"}
{"text": "[0068 ] .Much of the NP - resolution process can be seen as fairly domain - independent ( e.g. anaphora resolution ) .However , aspects of NP - resolution are both domain- and device - dependent .For example , the phrase \" What 's this \" is interpreted differently in the context of music playing over an MP3 player than when using a touch - screen multimodal interface .", "label": "", "metadata": {}, "score": "88.38877"}
{"text": "Suppose further that the scores of the individual hypotheses are as follows : .If the scores for linked hypotheses are merged through summation , the resulting scores are as follows : .In this example each hypothesis receives a merged score based on its own individual score and the individual scores of all hypotheses to which it is linked .", "label": "", "metadata": {}, "score": "88.39527"}
{"text": "( \" Robert Kennedy \" doc1 ) .( \" Robert Kennedy \" doc2 ) .In other embodiments , preliminary hypotheses that comprise the same phrase -- that is , preliminary hypotheses that include the same exact sequences of words -- can be distinguished based on subdivisions of documents , such as sections , paragraphs , or sentences .", "label": "", "metadata": {}, "score": "88.43035"}
{"text": "The dialogue move scripting language of an embodiment allows hierarchical specification and refinement of dialogue moves .The sample DMS 602 corresponds to a \" play \" command , and inherits from a more generic \" Command \" dialogue move .The \" Command \" dialogue move is implemented in Java for example , where the corresponding DMS has a field that names the Java class that implements the dialogue move .", "label": "", "metadata": {}, "score": "88.55977"}
{"text": "However , it is easy to find many more complicated examples which this rule will not cover : . his / PRP$ Mansion / NNP House / NNP speech / NN the / DT price / NN cutting / VBG 3/CD % /NN to / TO 4/CD % /NN more / JJR than / IN 10/CD % /NN the / DT fastest / JJS developing / VBG trends / NNS ' s / POS skill / NN .", "label": "", "metadata": {}, "score": "88.69802"}
{"text": "The availability of these new or upgraded devices should not require owners of vehicles with built - in DMs to upgrade their systems .Consequently , the dynamic plug - and - play multi - device dialogue management of the RNDS is an essential component to realizing the addition of new dialogue - enabled devices , or enhancements to existing dialogue capabilities of devices within the conventional dialogue management infrastructure .", "label": "", "metadata": {}, "score": "88.84305"}
{"text": "Accordingly , the RNDS is not limited by the disclosure , but instead the scope of the RNDS is to be determined entirely by the claims .[ 0107 ] .While certain aspects of the RNDS are presented below in certain claim forms , the inventors contemplate the various aspects of the RNDS in any number of claim forms .", "label": "", "metadata": {}, "score": "89.21945"}
{"text": "Here is my main function : .Most inconsistencies were found with regard to an association between depression and higher levels of awareness .Dysthymia , but not major depression , is probably related to higher levels of awareness .Anxiety also appears to be related to higher levels of awareness .", "label": "", "metadata": {}, "score": "89.313675"}
{"text": "Groundness Analysis - Initial research on feasibility done .It does in fact give significant performance boosts ( 2 - 3X ) .Seems to close many performance gaps between SWI - Prolog and miniKanren .However maintaining correctness seems difficult .", "label": "", "metadata": {}, "score": "89.453445"}
{"text": "This number becomes the basis for scoring according to the first criterion .For instance , if the type phrase is \" big blue truck , \" and one hypothesis is \" truck \" and another is \" blue truck , \" then the latter hypothesis is to be preferred because it matches more type phrase words .", "label": "", "metadata": {}, "score": "89.459045"}
{"text": "1 , answer extraction subsystem 15 communicates with IR subsystem 11 through channel 17 .Where two communicating processes execute on a single node , the communications channels comprise interprocess communication links that also execute on the node .Where two communicating processes execute on different nodes , the communications channel comprises hardware links and software protocols through which the processes can communicate with one another .", "label": "", "metadata": {}, "score": "89.60803"}
{"text": "[ 0038 ] .Consequently , the DMS 102 is analogous to a programming language for writing dialog moves .The DMS 102 provides a way of efficiently adapting dialog moves for use across different domains or applications by adapting the Java code of a dialog move at a level higher than the actual Java code in order to use the dialog move across numerous devices .", "label": "", "metadata": {}, "score": "89.97622"}
{"text": "Our focus throughout will be on expanding the coverage of a chunker .3.1 Reading IOB Format and the CoNLL 2000 Corpus .Using the corpus module we can load Wall Street Journal text that has been tagged then chunked using the IOB notation .", "label": "", "metadata": {}, "score": "90.11182"}
{"text": "using the answer extraction subsystem to score the hypotheses .Description .COPYRIGHT NOTIFICATION .A portion of the disclosure of this patent document contains material which is subject to copyright protection .The copyright owners have no objection to the facsimile reproduction , by anyone , of the patent document or the patent disclosure , as it appears in the patent and trademark office patent file or records , but otherwise reserve all copyright rights whatsoever .", "label": "", "metadata": {}, "score": "90.21686"}
{"text": "In this manner the RNDS DM 100 is representation - neutral because use of a different NLG component ( using a different representation ) in the dialogue system results only in modification of the DMS 102 , and requires no modification to the core of the RNDS DM 100 .", "label": "", "metadata": {}, "score": "90.2375"}
{"text": "claim 12 , further comprising at least one of a speech recognition module and a language understanding module coupled to an input of the dialogue manager .The system of .claim 12 , further comprising at least one of a language generation module and a text - to - speech module coupled to an output of the dialogue manager .", "label": "", "metadata": {}, "score": "90.38599"}
{"text": "The identification 402 uses a noun phrase of the description but is not so limited .A noun phrase - resolution script ( NPRS ) is selected 404 that corresponds to the identified device and/or application , and the NPRS is used to access noun phrase - resolution rules .", "label": "", "metadata": {}, "score": "90.44489"}
{"text": "[0054 ] .[ 0055 ] .The RNDS DM 100 is representation neutral in that the form of the templates and the corresponding matching algorithm can be replaced without affecting the RNDS DM infrastructure .This enables easy replacement of the parser or NLG component to ones using different representations .", "label": "", "metadata": {}, "score": "90.51384"}
{"text": "Some examples illustrate .One heuristic is to treat as equivalent hypotheses that are different forms of the same proper name if these hypotheses occur close to one another in a single document .For example , \" Kennedy \" is likely to refer to the same person as \" Robert Kennedy \" if both appear in the same paragraph or document , especially if \" Robert Kennedy \" appears first in the text and \" Kennedy \" appears thereafter .", "label": "", "metadata": {}, "score": "90.565674"}
{"text": "nltk.chunk.tree2conlltags(sent ) ] for sent in train_sents ] . return nltk.chunk.conlltags2tree(conlltags ) .The only piece left to fill in is the feature extractor .We begin by defining a simple feature extractor which just provides the part - of - speech tag of the current token .", "label": "", "metadata": {}, "score": "90.96975"}
{"text": "Other lexico - syntactic patterns can also give rise to type phrases .For example , in the question , \" What river does the Hoover Dam dam ? \" the type phrase is \" river .\" The pattern here is the word \" what \" followed immediately by a noun phrase .", "label": "", "metadata": {}, "score": "91.053276"}
{"text": "In step 283 the linking information generated in step 270 is used to merge the scores of linked hypotheses .Each hypothesis in a set of linked hypotheses receives a merged score that is computed using the evidence gathered for all the hypotheses of the set .", "label": "", "metadata": {}, "score": "91.258804"}
{"text": "( fresh [ l ] .( conso [ ?x : - ? s ] c l ) .( typedo l ? a ? t ) ) ) .( [ _ [ : apply ? a ?b ] _ ] .", "label": "", "metadata": {}, "score": "91.50905"}
{"text": "For example , consider the following two statements : .These two sentences have the same part - of - speech tags , yet they are chunked differently .In the first sentence , the farmer and rice are separate chunks , while the corresponding material in the second sentence , the computer monitor , is a single chunk .", "label": "", "metadata": {}, "score": "91.57587"}
{"text": "[ ? pos : onbox ? pos ? has ] ] ) .( [ [ ?pos1 : onfloor ?pos1 ? has ] : push .[ ?pos2 : onfloor ?pos2 ? has ] ] ) .( [ [ ?", "label": "", "metadata": {}, "score": "91.59428"}
{"text": "During training , this second class maps the chunk trees in the training corpus into tag sequences ; in the parse ( ) method , it converts the tag sequence provided by the tagger back into a chunk tree . class ConsecutiveNPChunkTagger", "label": "", "metadata": {}, "score": "91.956635"}
{"text": "6.1 Lexico - Syntactic Analysis .Hypotheses are verified in step 260 through lexico - syntactic analysis .Lexico - syntactic analysis is illustrated by the following example .Suppose that the input string is the question , \" Who succeeded Shastri as Indian prime minister ? \" , and that there are numerous primary documents , most of which contain the term \" prime minister .", "label": "", "metadata": {}, "score": "92.02652"}
{"text": "Lists are often used to enumerate objects of the same type .Examples are seen in Tables 8 and 9 .Noun Phrase Inclusion .Type phrases are often related to answer hypotheses by being included in them .In the question and corresponding match sentence shown below , the type phrase river is in the same noun phrase as the answer hypothesis Colorado River : . \" What river does the Hoover Dam dam ? . . .", "label": "", "metadata": {}, "score": "92.08775"}
{"text": "means for mapping the description to a dialogue move using the DMS , the dialogue move corresponding to the identified parameter and independent of the device and application .Computer - readable medium including executable instructions , which when executed in a processing system , manage dialogue by : . receiving an input pattern generated from an acoustic signal that includes a description of a dialogue contribution from a speaker ; . identifying the description and at least one parameter of the description using a dialogue move script ( DMS ) , wherein the DMS corresponds to at least one of a device and an application ; and . mapping the description to a dialogue move using the DMS , the dialogue move corresponding to the identified parameter and independent of the device and application .", "label": "", "metadata": {}, "score": "92.13877"}
{"text": "For example , the question , \" Who won twenty Oscars ? \" has no type phrase associated with it .This is because the word \" won \" does not establish a type phrase relation .Also , even for questions having type phrases , it can be beneficial to seek additional kinds of relations .", "label": "", "metadata": {}, "score": "92.40892"}
{"text": "claim 20 , wherein the activity model includes variables that correspond to DMS variables .The system of .claim 12 , wherein in response to coupling of the device to the device manager the dialogue manager receives and stores information of the activity model , device - specific DMS , device - specific NPRS , and device - specific dialogue moves from the device API .", "label": "", "metadata": {}, "score": "92.513664"}
{"text": "( [ [ : n ' cat ] ] ' [ cat ] ) ) .( [ [ : d ' the ] ] ' [ the ] ) .( [ [ : d ' a ] ] ' [ a ] ) ) .", "label": "", "metadata": {}, "score": "93.166626"}
{"text": "This implementation is faster than miniKanren under Racket and seems to be close to performnace of miniKanren recorded by the original designers when running under Chez Scheme .A Grammar of Boumaa Fijian .The people who live in the Boumaa region of the Fijian island of Taveuni speak a dialect of Fijian that is mutually intelligible with Standard Fijian , the two differing as much perhaps as do the American and British varieties of English .", "label": "", "metadata": {}, "score": "93.329315"}
{"text": "Then the result of step 270 is linking information that can be expressed as ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( link1 ( \" Robert Kennedy \" doc1 ) ( \" Kennedy \" doc1 ) ( \" Robert F. Kennedy \" doc2))(link2 ( \" Robert Kennedy \" doc20 ) ( \" Robert M. Kennedy \" doc37 ) ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "93.40915"}
{"text": "Having built a unigram chunker , it is quite easy to build a bigram chunker : we simply change the class name to BigramChunker , and modify line in 3.1 to construct a BigramTagger rather than a UnigramTagger .The resulting chunker has slightly higher performance than the unigram chunker : .", "label": "", "metadata": {}, "score": "93.58354"}
{"text": "The short - distance ontological relations are then generated , block 315 .These short - distance coordinate term and ontological relation processing streams could be executed in parallel or sequentially depending upon the processing implementation .The short - distance coordinate terms generated in processing blocks 308 , 310 , 312 and 314 , and the short - distance ontological relation generated in processing blocks 309 , 311 , 313 , and 315 are used together to identify the long - distance ontological relations , as shown in block 316 .", "label": "", "metadata": {}, "score": "93.78488"}
{"text": "Domain - specific hypernym and part - whole relations are essential in building domain ontologies .Accurately identifying hypernym and part - whole relations is a time consuming task .Embodiments can be used to automatically identify domain - specific hypernym and part - whole relations .", "label": "", "metadata": {}, "score": "94.200424"}
{"text": "( fact likes ' Ricky ' Lucy ) .( defrel fun p ) .( fact fun ' Lucy ) .( fresh [ x y ] .( fun y ) .( likes x y ) .It 's important to index relationships so that the time to run queries does n't grow linearly with the number of facts .", "label": "", "metadata": {}, "score": "94.28087"}
{"text": "Each publication and/or patent application mentioned in this specification is herein incorporated by reference in its entirety to the same extent as if each individual publication and/or patent application was specifically and individually indicated to be incorporated by reference .BRIEF DESCRIPTION OF THE DRAWINGS .", "label": "", "metadata": {}, "score": "94.36334"}
{"text": "The IR subsystem 11 is coupled to the text corpus 12 in such a way that the IR subsystem 11 , acting in response to an input query , can search the text corpus 12 for documents that match the query .", "label": "", "metadata": {}, "score": "94.813"}
{"text": "The results are shown in Table 10 below .TABLE 10______________________________________MURAX Evaluation ResultsRank of Correct Hypothesis Number of Questions______________________________________Top 37Top 3 49Top 5 52Not in Top 5 18 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "94.88668"}
{"text": "( conda .[ ( lvaro x ) ( findo x c t ) ] .[ ( matche [ c x t ] .( fresh [ l ] .( conso [ y : - s ] c l ) .", "label": "", "metadata": {}, "score": "94.9018"}
{"text": "The RNDS also provides explicit multi - device dialogue management processes , extending the core dialogue management infrastructure for information - state update dialogue management so as to manage simultaneous interaction with multiple devices .[ 0021 ] .Of practical importance in the context of automobile applications , conversational dialogue with a vehicle requires interaction with many devices , and natural interaction requires seamless dialogue management with the different devices .", "label": "", "metadata": {}, "score": "95.11874"}
{"text": "The plug - and - play multi - device dialogue management supports the addition of new devices to the RNDS 200 that function with the RNDS DM 100 without having to load new software or otherwise modify the RNDS DM 100 .", "label": "", "metadata": {}, "score": "95.33381"}
{"text": "One class of false positives are words such as \" Be \" or \" As \" which you would normally expect to be stopworded out , but which match the chemical name synonyms for the elements Berrylium and Arsenic respectively .Another class consisted of words used in an incorrect context , for example \" lead \" in the sense \" lead a team \" rather than the metal .", "label": "", "metadata": {}, "score": "95.40947"}
{"text": "A UIMA primitive Analysis Engine ( AE ) consists of an annotation descriptor ( specified as XML ) , an annotator ( specified as a Java class ) and its associated AE descriptor ( also specified as XML ) .Annotation XML Descriptor .", "label": "", "metadata": {}, "score": "95.78549"}
{"text": "Note that this has implications for memory usage . ; Clojure 1.3.0 .( defrel likes ^:index p1 ^:index p2 ) ; Clojure 1.2.0 .YourKit .YourKit has has given me a free license for their profiler , greatly simplifying the profiling of core.logic performance .", "label": "", "metadata": {}, "score": "96.222946"}
{"text": "An instance of this is seen in Example 1 above ( \" What Pulitzer Prize - winning novelist ran for mayor of New York City ?In Example 1 , not all the information needed to determine the best answer hypothesis appears in any one document .", "label": "", "metadata": {}, "score": "97.35019"}
{"text": "For example , consider the question \" What Pulitzer Prize - winning novelist ran for mayor of New York City ? \" WordNet indicates that novelist is a hyponym of writer , author and also person .This means that the answer to the question is likely to be a person 's name even though the question starts with \" what \" .", "label": "", "metadata": {}, "score": "97.76255"}
{"text": "[ 0036 ] .[ 0037 ] .The RNDS DM 100 and/or the RNDS 200 may couple among any combination of other components under program or algorithmic control , these other components including processors , memory devices , buses , controllers , input / output devices , communication systems , and displays to name a few .", "label": "", "metadata": {}, "score": "97.98806"}
{"text": "[ 0028 ] .The RNDS DM 100 also updates and synchronizes the current knowledge base among different modules .[ 0029 ] .The LG module 210 , also referred to as a natural language generator ( \" NLG \" ) 210 is coupled to the output processor 114 of the RNDS DM 100 , for example , and receives at one or more inputs the output from the RNDS DM 100 .", "label": "", "metadata": {}, "score": "98.12048"}
{"text": "Then this augmented version of the table is used to apply the second scoring criterion .The hypothesis \" Norman Mailer \" is now treated as appearing in conjunction with four rather than three input string phrases , namely , \" Pulitzer Prize , \" \" winning novelist , \" \" mayor , \" and \" New York City . \"", "label": "", "metadata": {}, "score": "98.664185"}
{"text": "The computing node 4 can in some embodiments further comprise a storage device 8 , such as a hard disk , coupled to the processor 5 .The user interface 7 comprises hardware , such as an input keyboard and display screen , and associated software to permit a user to communicate with the answer extraction subsystem .", "label": "", "metadata": {}, "score": "98.8307"}
{"text": "Lexico - syntactic analysis of these documents verifies that Norman Mailer is a \" novelist \" as well as a \" writer .After all verification attempts are complete , the method rescores the hypotheses according to the degree to which they were successfully verified .", "label": "", "metadata": {}, "score": "99.13292"}
{"text": "This section presents an evaluation of MURAX 's performance for questions beginning with \" who \" and \" what \" that have simple noun phrase answers .( Questions having conjoined noun phrases such as \" Richard Nixon and Nikita Khrushchev \" are not included . )", "label": "", "metadata": {}, "score": "99.60519"}
{"text": "A title phrase need not be a noun phrase .For example , the title \" Play Misty for Me \" contains the verb \" play \" .Title phrases are readily identified when marked typographically by enclosing quotes or italics .", "label": "", "metadata": {}, "score": "99.60598"}
{"text": "( [ _ [ : apply a b ] _ ] .( fresh [ s ] .( typedo c b s ) ) ) ) ] ) ) .( fresh [ f g a b t ] .( typedo [ [ f : - a ] [ g : - b ] ] [ : apply f g ] t ) .", "label": "", "metadata": {}, "score": "99.618004"}
{"text": "In such an embodiment it is possible for a document that contains the answer to the user 's question to be found by the primary query construction subsystem but then discarded because it is not considered sufficiently relevant .For example , suppose that in the example above concerning Indira Gandhi the document containing the sentence \" Indira Gandhi succeeded Shastri . . .", "label": "", "metadata": {}, "score": "100.04719"}
{"text": "For example , given a document that indicates that the company Georgia - Pacific is located in Atlanta , it might generate the tuple ( [ ORG : ' Georgia - Pacific ' ] ' in ' [ LOC : ' Atlanta ' ] ) .", "label": "", "metadata": {}, "score": "100.27832"}
{"text": "It would be interesting to see how we fare on the standard Prolog benchmarks .Currently , on my machine , solving the classic Zebra puzzle 1000 times takes SWI - Prolog about 6 seconds , it takes core.logic running under Clojure 1.3.0 less than 2s without occurs - check .", "label": "", "metadata": {}, "score": "100.48098"}
{"text": "It was built in honor of George Washington , who led the country to independence and then became its first President .Analysis of the question leads us to expect that an answer should be of the form X was the first President of the US , where X is not only a noun phrase , but also refers to a named entity of type PERSON .", "label": "", "metadata": {}, "score": "101.62667"}
{"text": "( 11,13 ) : it [ junit ] ... ( 19,27 ) : the show [ junit ] text : As I was telling you , he will not attend the meeting .[ junit ] ...( 0,4 ) : Lead [ junit ] ... ( 8,22 ) : the lead cause [ junit ] ...", "label": "", "metadata": {}, "score": "101.72543"}
{"text": "7 is a sample noun phrase - query ( \" NP - query \" ) object 700 for \" the song Vertigo by U2 \" , under an embodiment .Rules of the RNDS DM 100 specify how to translate NPs specified in the input semantic form into such objects .", "label": "", "metadata": {}, "score": "101.95745"}
{"text": "Thus in the example , the hypotheses ( \" Robert Kennedy \" doc10 ) and ( \" Robert Kennedy doc200 \" ) receive scores of 3 and the hypothesis ( \" John Kennedy \" doc30 ) receives a score of 4 in such an embodiment .", "label": "", "metadata": {}, "score": "102.379234"}
{"text": "It is helpful to present an illustrative example of answer extraction as performed according to the method of the invention in one embodiment .In this example , which will be called Example 1 , the user 's question is , \" What Pulitzer Prize - winning novelist ran for mayor of New York City ? \" The method begins by accepting as input the user 's question and a set of documents that are assumed to contain the answer to the question .", "label": "", "metadata": {}, "score": "102.50211"}
{"text": "( typedo [ [ f : - a ] [ g : - : int ] ] [ : apply f g ] t ) .( fresh [ f g a t ] .[ : apply f g ] t ) .", "label": "", "metadata": {}, "score": "102.834"}
{"text": "( typedo [ [ f : - a ] [ g : - : int ] ] [ : apply f g ] t ) .( fresh [ f g a t ] .[ : apply f g ] t ) .", "label": "", "metadata": {}, "score": "102.834"}
{"text": "( defrel likes ^:index p1 ^:index p2 ) ; Clojure 1.2.0 .YourKit .YourKit has has given me a free license for their profiler , greatly simplifying the profiling of core.logic performance .YourKit is kindly supporting open source projects with its full - featured Java Profiler .", "label": "", "metadata": {}, "score": "102.92374"}
{"text": "The method of claim 14 in which the text corpus comprises the documents of the set of documents .The method of claim 14 in which the text corpus comprises documents not in the set of documents .The method of claim 14 in which the text corpus comprises the documents of the set and additional documents not in the set .", "label": "", "metadata": {}, "score": "103.26371"}
{"text": "( typedo c ?( typedo c ?b s ) ) ) ) ) ) ) .( fresh [ f g a b t ] .( typedo [ [ f : - a ] [ g : - b ] ] [ : apply f g ] t ) .", "label": "", "metadata": {}, "score": "103.68381"}
{"text": "For example , suppose that : . 1 ) Document doc10 contains the phrase \" Robert Kennedy \" twice , in match sentences whose scores are 120 and 60 respectively .2 ) Document doc30 contains the phrase \" John Kennedy \" four times , in match sentences whose scores are 10 , 10 , 40 , and 50 respectively .", "label": "", "metadata": {}, "score": "104.43355"}
{"text": "( [ [ pos : onfloor pos has ] : climb .[ pos : onbox pos has ] ] ) .( [ [ pos1 : onfloor pos1 has ] : push .[ pos2 : onfloor pos2 has ] ] ) .", "label": "", "metadata": {}, "score": "104.77252"}
{"text": "In step 283 scores of linked hypotheses are merged .In step 285 the hypotheses are ranked based on their scores .In step 287 results are organized for presentation .Each of these steps will now be more fully described .", "label": "", "metadata": {}, "score": "105.03878"}
{"text": "At this point information from secondary documents is integrated .TABLE 4______________________________________Expanded input phrase co - occurences for Example 1 \" Pulitzer \" winning \" New YorkHypothesis Prize \" novelist \" \" mayor \" City\"______________________________________Edith Wharton X X XWilliam Faulkner X X XNorman", "label": "", "metadata": {}, "score": "105.30473"}
{"text": "\" to match phrases such as \" Chief Justices Warren , Burger , Rehnquist . . .\" .If the apposition relation is considered , templates can be generated of the form \" X , NP(Justice ) \" to match phrases such as \" Earl Warren , Chief Justice . . .", "label": "", "metadata": {}, "score": "105.77232"}
{"text": "The fourth Wells account moving to another agency is the packaged paper - products division of Georgia - Pacific Corp. , which arrived at Wells only last fall .Like Hertz and the History Channel , it is also leaving for an Omnicom - owned agency , the BBDO South unit of BBDO Worldwide .", "label": "", "metadata": {}, "score": "106.944405"}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 .( \" Robert F. Kennedy \" doc2)2 .", "label": "", "metadata": {}, "score": "107.08131"}
{"text": "Step 270 is optional and is omitted in some embodiments .As an example , consider the hypotheses ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( \" Robert Kennedy \" doc1)(\"Kennedy \" doc1)(\"Robert F. Kennedy \" doc2)(\"Robert Kennedy \" doc20)(\"Robert M. Kennedy \" doc37 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "107.1145"}
{"text": "FIG .7 is a sample noun phrase - query ( \" NP - query \" ) object for \" the song Vertigo by U2 \" , under an embodiment .[ 0013 ] .FIG .8 is an example of noun phrase - resolution rules , under an embodiment .", "label": "", "metadata": {}, "score": "107.96915"}
{"text": "( \" Robert Kennedy \" doc1 paragraph10 ) .( \" Robert Kennedy \" doc2 paragraph14 ) .In still other embodiments preliminary hypotheses can be treated as equivalent regardless of their textual source .Each preliminary hypothesis is also associated with the particular match sentences that gave rise to it .", "label": "", "metadata": {}, "score": "109.14598"}
{"text": "A relation has syntactic , semantic , contextual and other aspects .For example , in the sentence , \" George Washington was the first president , \" a relation exists between the phrases \" first president \" and \" George Washington .", "label": "", "metadata": {}, "score": "109.16431"}
{"text": "The maximum number of words matched in any of these sentences is 2 ( the two words \" Chief Justice \" ) .Thus in this example , the first scoring criterion leads to a tie .\" Earl Warren \" and \" Warren Earl \" tie for highest score with 2 type phrase words matched apiece . \" Kennedy \" is next with 1 type phrase word matched , and \" Oswald \" scores the lowest with 0 words matched .", "label": "", "metadata": {}, "score": "109.17608"}
{"text": "Suppose that in Example 1 all three hypotheses are selected for verification .The primary documents indicate that Norman Mailer was from New York City , won a Pulitzer Prize , and ran for mayor , but do not indicate that he was a novelist .", "label": "", "metadata": {}, "score": "109.37589"}
{"text": "In other words , the maximum number of phrases from the question that appear in any one primary document along with the hypothesis \" Edith Wharton \" is three .Similarly , the hypothesis \" William Faulkner \" appears in at least one primary document with \" Pulitzer Prize , \" \" novelist , \" and \" New York City . \"", "label": "", "metadata": {}, "score": "109.86921"}
{"text": "\" The representative member is used in the ranking .As an example , suppose once again that the linked hypotheses are ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( link1 ( \" Robert Kennedy \" doc1 ) ( \" Kennedy \" doc1 ) ( \" Robert F. Kennedy \" doc2))(link2 ( \" Robert Kennedy \" doc20 ) ( \" Robert M. Kennedy \" doc37 ) ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "110.56147"}
{"text": "( \" Robert M. Kennedy \" doc20 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "111.385635"}
{"text": "Thus the following input string fragments would be recognized as title phrases : . \"Gone With the Wind \" .Gone With the Wind .Typically the input string contains zero or one title phrases , but it is also possible for it to contain two or more .", "label": "", "metadata": {}, "score": "111.87486"}
{"text": "For example , in the question , \" Who was the first President of the United States ? \" , the phrase \" the first President of the United States \" is the type phrase .As another example , in the question , \" What river does the Hoover Dam dam ? \" the type phrase is \" river .", "label": "", "metadata": {}, "score": "112.368195"}
{"text": "getCoveredText ( text ) .getCoveredText ( sentence ) .equals ( chunk .setBegin ( start + tokSpans [ chunk .getStart ( ) ] .getStart ( ) ) ; annotation .setEnd ( start + tokSpans [ chunk .", "label": "", "metadata": {}, "score": "112.583954"}
{"text": "TABLE 3______________________________________Input phrase co - occurences for Example 1 \" Pulitzer \" winning \" New YorkHypothesis Prize \" novelist \" \" mayor \" City\"______________________________________Edith Wharton X X XWilliam Faulkner X X XNormanMailer X X X _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "112.8409"}
{"text": "In particular , the information that \" Norman Mailer \" is a \" novelist , \" which appears in a secondary document , must be integrated with the information that \" Norman Mailer \" was a mayoral candidate , which appears in a primary document .", "label": "", "metadata": {}, "score": "112.86583"}
{"text": "As another example , if in step 311 the noun phrase \" last Apache warrior chief \" is detected , then in step 312 this phrase is split according to its initial capitalization as .last Apache warrior chief .and the noun phrases \" Apache \" and \" warrior chief \" are used in further processing while the original noun phrase \" last Apache warrior chief \" is discarded .", "label": "", "metadata": {}, "score": "112.90087"}
{"text": "For question 10 , the answer \" forget - me - not \" was not found because MURAX does not consider references involving impersonal pronouns .Such a reference is necessary to infer the answer from the sentence \" It is the state flower of Alaska .", "label": "", "metadata": {}, "score": "113.173454"}
{"text": "In certain articles of the encyclopedia , so does Kennedy ; the usage can be disambiguated in such articles by reference to the articles ' titles .In the document titled Kennedy , John F. , mention of Kennedy refers to the title , whereas other members of the family are named explicitly ( e.g. , Joseph P. Kennedy ) so as not to confuse the reader .", "label": "", "metadata": {}, "score": "113.480576"}
{"text": "TABLE 5______________________________________Example questions______________________________________1 What U.S. city is at the junction of the Allegheny andMonongahela rivers ?Who wrote \" Across the River and into the Trees \" ?Who married actress Nancy Davis ?What 's the capital of the Netherlands ?", "label": "", "metadata": {}, "score": "113.79897"}
{"text": "All rights reserved .Copyright protection claimed includes all forms and matters of copyrightable material and information now allowed by statutory or judicial law or hereafter granted , including without limitation , material generated from the software programs which are displayed on the screen such as icons , screen display looks , etc . .", "label": "", "metadata": {}, "score": "114.24275"}
{"text": "What chief justice headed the commission that declared:\"Lee Harvey Oswald . . .acted alone .What famed falls are split in two by Goat Island ?What is November 's birthstone9 .Who 's won the most Oscars for costume design ?", "label": "", "metadata": {}, "score": "115.099304"}
{"text": "Consider an example that will be called Example 2 .Suppose that the input string is the question , \" What Chief Justice led the commission that investigated the assassination of John F. Kennedy ? \" The type phrase here is \" Chief Justice \" and the head word is \" Justice .", "label": "", "metadata": {}, "score": "116.17085"}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( \" Robert F. Kennedy \" doc2 ) ( \" Robert M. Kennedy \" doc20 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . are selected to represent the hypotheses of link1 and link2 respectively .", "label": "", "metadata": {}, "score": "116.89102"}
{"text": "Continuing with Example 1 , suppose that the retrieved documents contain the following additional noun phrases in proximity to the noun phrase \" New York City \" : . \"Edith Wharton \" ( who was born in New York City ) .", "label": "", "metadata": {}, "score": "117.37372"}
{"text": "Therefore this document would not be supplied to the answer extraction subsystem as a primary document , and so in step 263 no primary documents would be found that contain matches to the template , \" X succeeded Shastri . \"In other words , as of step 264 , the only point in Mrs. Gandhi 's favor would be the same as that for Mr. Churchill or Ms. Meir , namely , that all were \" prime ministers . \"", "label": "", "metadata": {}, "score": "118.65227"}
{"text": "For the question given in Table 7 MURAX produces the output shown in Table 8 . \"Next best : Edith Wharton , William Faulkner _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "119.30343"}
{"text": "( defrel woman p ) .( fact woman ' Mary ) .( fact woman ' Martha ) .( fact woman ' Lucy ) .( defrel likes p1 p2 ) .( fact likes ' Bob ' Mary ) .", "label": "", "metadata": {}, "score": "120.52609"}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( These Trivial Pursuit questions are Copyright Horn Abbott Ltd.", "label": "", "metadata": {}, "score": "121.60841"}
{"text": "Norman Mailer \" ( who lived in New York City ) .Then \" Edith Wharton , \" \" William Faulkner , \" and \" Norman Mailer \" become the preliminary hypotheses for Example 1 .The preliminary hypotheses are scored and then ranked according to their scores .", "label": "", "metadata": {}, "score": "122.27548"}
{"text": "Suppose that the documents containing the names \" Edith Wharton \" and \" William Faulkner \" refer to these persons as \" novelists , \" but that the document containing the name \" Norman Mailer \" refers to Mr. Mailer as a \" writer . \"", "label": "", "metadata": {}, "score": "123.36452"}
{"text": "However , \" Harold \" is ( correctly ) preferred because the match is exact , whereas a longer match is involved for \" Saint Edward the Confessor \" ( namely , he was the \" next to last Anglo - Saxon king of England \" ) .", "label": "", "metadata": {}, "score": "123.78894"}
{"text": "( defrel likes p1 p2 ) .( fact likes ' Bob ' Mary ) .( fact likes ' John ' Martha ) .( fact likes ' Ricky ' Lucy ) .( defrel fun p ) .( fact fun ' Lucy ) .", "label": "", "metadata": {}, "score": "124.34929"}
{"text": "( defrel man p ) .( fact man ' Bob ) .( fact man ' John ) .( fact man ' Ricky ) .( defrel woman p ) .( fact woman ' Mary ) .( fact woman ' Martha ) .", "label": "", "metadata": {}, "score": "126.893936"}
{"text": "1022 , was defeated and killed at . . . \" .The IS - A Relation .This is demonstrated by the following match sentence : . 2 ) \" Saint Edward the Confessor , b. between 1002 and 1005 , d. Jan. 5 , 1066 , was the next to last Anglo - Saxon king of England ( 1042 - 66 ) .", "label": "", "metadata": {}, "score": "129.03693"}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( \" Robert Kennedy \" doc1)(\"Kennedy \" doc1)(\"Robert F. Kennedy \" doc2)(\"Robert Kennedy \" doc20)(\"Robert M. Kennedy \" doc37 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "130.19066"}
{"text": "\" The type phrase is \" winning novelist \" and its head noun is \" novelist .\" The answer hypotheses are \" Edith Wharton , \" \" William Faulkner , \" and \" Norman Mailer . \" Suppose that each of the hypotheses matches the type phrase \" winning novelist \" with a maximum of one word , \" novelist , \" so that the first criterion does not distinguish among the hypotheses .", "label": "", "metadata": {}, "score": "130.32141"}
{"text": "In the example , the sentence \" Indira Gandhi succeeded Shastri . . .\" provides much stronger support for the answer hypothesis \" Indira Gandhi \" than the mere co - occurrence of the names \" Shastri \" and \" Indira Gandhi \" in a sentence or document .", "label": "", "metadata": {}, "score": "130.46097"}
{"text": "The overall process is illustrated with an example question , which will be called Example 3 below : . \" Who shot President Lincoln ?The question is first tagged and the noun phrases and main verbs are found .In Example 3 the only noun phrase is President Lincoln and the main verb is shot .", "label": "", "metadata": {}, "score": "132.55573"}
{"text": "As another example , if the template is \" X succeeded Shastri \" and the hypothesis is \" Indira Gandhi , \" the filled - in template is \" Indira Gandhi succeeded Shastri .\" The answer extraction subsystem seeks one or more primary documents that contain sentences conforming to this filled - in template , for example , \" Indira Gandhi succeeded Shastri . . . . \" .", "label": "", "metadata": {}, "score": "134.3779"}
{"text": "This can be useful for ranking alternative answer hypotheses in the absence of other differentiating phrase matches .It is illustrated in the following question and primary document match sentences : . \" What film pits Humphrey Bogart against gangsters in the Florida Keys ? . . .", "label": "", "metadata": {}, "score": "135.80106"}
{"text": "Who succeeded Shastri as prime minister ? . . .Shastri was succeeded by Indira Gandhi as Indian prime minister . . .\" .6.1.3 Minimum Mismatch .For reliable identification , simple noun phrases are extracted from match sentences of primary documents .", "label": "", "metadata": {}, "score": "138.97964"}
{"text": "\" This is because Earl Warren figures prominently in the history of the investigation of the Kennedy assassination .The hypothesis \" Warren Earl \" scores lower , because the documents in which Chief Justice Warren Earl Burger 's name appears are for the most part not related to the Kennedy assassination .", "label": "", "metadata": {}, "score": "140.70944"}
{"text": "Some of his most popular films were The Maltese Falcon ( 1941 ) ; Casablanca ( 1942 ) , with Ingrid Bergman ; The Big Sleep ( 1946 ) costarring his wife , Lauren Bacall ; The Treasure of Sierra Madre ( 1948 ) ; . . . \" .", "label": "", "metadata": {}, "score": "140.79013"}
{"text": "If document doc1 primarily concerns John F. Kennedy , it is not immediately apparent whether the \" Kennedy \" in doc1 refers to John or Robert .Similarly , it is not immediately apparent whether the \" Robert Kennedy \" in doc1 is the same as that in doc20 , or whether either of these refers to the \" Robert F. Kennedy \" of doc2 or the \" Robert M. Kennedy \" of doc37 .", "label": "", "metadata": {}, "score": "143.44675"}
