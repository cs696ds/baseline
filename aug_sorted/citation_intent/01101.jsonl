{"text": "Both sub - modules will be able to access and update the discourse model 720 .A task understanding module may be utilized for understanding the non - communicative actions taken by the user ( for example , recognizing that the user is attempting to plug in their laptop or is interrupting her conversation with the character to respond to a second human ) .", "label": "", "metadata": {}, "score": "25.530197"}
{"text": "In another alternative , state information could easily be passed on to the reaction module which , in addition to acting on the information , could be entirely responsible for updating the dynamic knowledge base .Still further , the understanding module may be configured to ' inform ' the input manager 's perceptual tasks .", "label": "", "metadata": {}, "score": "28.0513"}
{"text": "Therefore , if a user is ( 1 ) looking at the character , and ( 2 ) speaking , the understanding module infers that the character is being spoken to .In addition , a process referred to as semantic fusing , may be applied where a meaning of a gesture and speech may be combined to determine a meaning to an entire communication .", "label": "", "metadata": {}, "score": "28.57186"}
{"text": "The data collection module 22 , in co - ordinating the collection of utterance data also , as will be described in detail later , causes visual prompts to be generated to aid a user to ensure the data captured is suitable for subsequent processing .", "label": "", "metadata": {}, "score": "28.947758"}
{"text": "The reasoning facility includes a goal - directed rule - based inference engine .The rules in this system specify how to make particular script calls in order to achieve specific goals .Through means - end analysis , the inference engine of the reasoning facility finds rules that can achieve the initial goal of processing the utterance , and then proceeds to create and pursue subgoals that will enable it to apply those rules .", "label": "", "metadata": {}, "score": "29.270567"}
{"text": "In other applications , a system designer may want a speech solution to be speaker - independent and to recognize the speech of different users , provided the users are speaking in the language the application is designed to understand and uttering phrases associated with the application .", "label": "", "metadata": {}, "score": "29.572777"}
{"text": "In effect , a deployed speech recognition system may be tuned to better recognize the specific words and/or phrases that give the system difficulties .Similarly , if a deployed system has an acceptable recognition rate for certain utterances , those utterances may be exempted from additional tuning - helping to protect those utterances that enjoy an acceptable recognition rate from inadvertent recognition rate degradation .", "label": "", "metadata": {}, "score": "29.750385"}
{"text": "In particular , the reasoning facility is configured to identify ambiguous information in the utterance representation , and to generate a response based on the analysis of the ambiguous information .In one aspect the reasoning facility applies a goal - directed reasoning analysis based on the set of goal - directed rules to clarify the ambiguous information .", "label": "", "metadata": {}, "score": "30.217583"}
{"text": "The reasoning facility also has access to a conversational record that includes a record of previous utterances and a semantic analysis for each utterance .The reasoning facility processes a representation of the utterance by using the goal - directed rules .", "label": "", "metadata": {}, "score": "30.313675"}
{"text": "Such a construction would likely be utilized anytime a gesture is combined with an ambiguous referring expression ( noun phrase ) .The understanding module 610 outputs one or more frames to the reactive module describing the inputs , and updates the discourse model .", "label": "", "metadata": {}, "score": "30.469744"}
{"text": "Moreover , the noise tolerance module may filter out environmental and non - human noise to further reduce a likelihood of confusion .In one implementation , the noise tolerance module may cooperate with other modules and features to filter out words that do not fit into an identified context .", "label": "", "metadata": {}, "score": "30.584234"}
{"text": "A user then causes the control module 20 ( S 3 - 3 ) to invoke the model generation module 25 to generate a speech model comprising a set of word models using the utterances stored within the speaker database 24 .", "label": "", "metadata": {}, "score": "30.596697"}
{"text": "A language understanding monitoring system that operates in a task classification system , comprising .a task classification processor that is adapted to determine whether a task classification decision can be made based on an understanding of a user 's input communication ; . a dialog manager that is adapted to conduct a dialog with the user ; and .", "label": "", "metadata": {}, "score": "30.676876"}
{"text": "In one implementation , noise tolerance module 250 may cooperate with other modules and features to filter out words that do not fit into a context .For example , one or more contexts may be identified , and words that have no meaning with respect to system capabilities , random human utterances without meaning and other noise may be filtered out .", "label": "", "metadata": {}, "score": "30.84784"}
{"text": "The significance of this observation is that it implies that the language for a domain can be incrementally extended without the concomitant need for restructuring the entire grammar as its complexity increases .It further raises the possibility that language components may be reused from application to application , provided that the sub - domains in question are substantially the same .", "label": "", "metadata": {}, "score": "31.441055"}
{"text": "For example , the utterance may include a request to perform an action , and output 140 may include a conversational response reporting success or failure , as well as an execution of the action .Referring to .FIG .2 , an exemplary block diagram is provided illustrating a conversational speech engine 215 according to one aspect of the invention .", "label": "", "metadata": {}, "score": "31.645924"}
{"text": "Other speech recognition systems typically treat interactions with a user as a form - filling exercise , or treat conversation as a script or decision tree walk .In a form - filling system , the system can accept utterances and respond to the user as long as the user speaks utterances that match the predetermined layout of the form .", "label": "", "metadata": {}, "score": "31.742218"}
{"text": "The utterance may be passed to speech module 86 , which may act as a speech recognition engine and assign an utterance type to the utterance .Speech module 86 may also include logic that makes a call routing and/or a call response decision based at least partially upon the assigned utterance type .", "label": "", "metadata": {}, "score": "31.774021"}
{"text": "Various peripheral hardware is provided to allow inputs for determination of equipment locations ( video cameras and recognition software , and sensor based systems , for example ) .The discourse model 720 contains state information about the dialogue with the user ( a history of semantic representations of utterances ) and is used primarily in natural language understanding and generation .", "label": "", "metadata": {}, "score": "31.905123"}
{"text": "However it has been noted that unit selection synthesis is often better when the utterance to be synthesized is closer to the domain of the database .The result offers very high quality synthesis that sounds almost human .The techniques used for this are more fully described in [ 4 ] .", "label": "", "metadata": {}, "score": "32.063095"}
{"text": "In the natural language understanding monitoring system 100 , the dialog history database 170 serves as a database for storing each dialog exchange for a particular dialog .The training database 165 stores NLU errors collected from interactions with human users and models built based on those errors , the NLU features identified from the collected dialogs , and the NLU rules generated from the dialogs and the NLU features .", "label": "", "metadata": {}, "score": "32.36564"}
{"text": "For example , the utterance may include a request to perform an action , and the output may include a conversational response reporting success or failure , as well as an execution of the action .According to another aspect of the invention , an exemplary conversational speech engine may generate an adaptive conversational response to a request or series of requests .", "label": "", "metadata": {}, "score": "32.462883"}
{"text": "This provides advantages over existing systems that attempt to assign meaning to every component of an utterance ( i.e. , including out - of - context words and noise words ) , which results in nearly infinite possible combinations and greater likelihood of confusion .", "label": "", "metadata": {}, "score": "32.504307"}
{"text": "In another approach described earlier , speech processing systems typically treat interactions as a form - filling exercise , or treat conversation as a script or decision tree walk .The approach of the present invention differs in that a system configured according to the present invention can be said to have an understanding of what has been said to it and have an awareness of what it is doing .", "label": "", "metadata": {}, "score": "32.7219"}
{"text": "The conversational language processor may therefore use various techniques to identify a conversation type , interpret utterances , identify requests , or perform other tasks , such as those described in the aforementioned U.S. Patent Applications and U.S. Patents , which are hereby incorporated by reference in their entirety .", "label": "", "metadata": {}, "score": "32.747288"}
{"text": "Furthermore , the conversational interaction may take various forms , including query - based conversations , didactic conversations , exploratory conversations , or other types of conversations .For example , the conversational language processor may identify a type of conversation , and information may be extracted from the utterance accordingly to identify the one or more requests in operation 310 .", "label": "", "metadata": {}, "score": "32.973305"}
{"text": "By taking advantage of human presumptions about utterances that humans rely upon , both as speakers and listeners , a Human - to - Machine interface may be analogous to everyday human - to - human conversation .In one implementation , the exemplary cooperative conversation model may take incoming data ( shared knowledge ) to inform a decision ( intelligent hypothesis building ) , and then may refine the decision and generate a response ( adaptive response building ) .", "label": "", "metadata": {}, "score": "33.04527"}
{"text": "Many speech solutions , such as speech - enabled applications and speech recognition systems , utilize a computing device to \" listen \" to a user utterance and to interpret that utterance .Depending upon design considerations , a speech solution may be tasked with accurately recognizing a single user 's utterances .", "label": "", "metadata": {}, "score": "33.13073"}
{"text": "Depending upon earlier design considerations , the system may , for example , perform \" whole word \" recognition and/or sub - word recognition like \" phonetic recognition . \" In some cases , the system may or may not be capable of finding a match and/or assigning an interpretation .", "label": "", "metadata": {}, "score": "33.221096"}
{"text": "The initial segments of these dialogs can be used to predict that a problem is likely to occur .The ability to predict language understanding errors will allow the system 's dialog manager 190 to apply more sophisticated strategies to repairing problems , and even perhaps , to prevent them .", "label": "", "metadata": {}, "score": "33.38972"}
{"text": "A computer system is provided including a control module 20 and data collection module 22 which generate user interfaces enabling a user to identify a vocabulary and a number of speakers from whom utterances are to be obtained .A computer system is provided including a control module 20 and data collection module 22 which generate user interfaces enabling a user to identify a vocabulary and a number of speakers from whom utterances are to be obtained .", "label": "", "metadata": {}, "score": "33.462776"}
{"text": "FIG .4 , their functions may be performed by a single unit within the spirit and scope of the invention .FIG .5 is a flowchart of a possible automated task classification process using the natural language understanding monitoring system 100 of the invention .", "label": "", "metadata": {}, "score": "33.534855"}
{"text": "Thus , accuracy in identifying meaning may be enhanced by eliminating out - of - context words and noise words when searching for relevant combinations .In contrast , existing systems attempt to assign meaning to every component of an utterance ( e.g. , including out - of - context words and noise words ) , which results in nearly infinite possible combinations and greater likelihood of confusion .", "label": "", "metadata": {}, "score": "33.712914"}
{"text": "In addition , the use of rules in this interpretation phase provides a much more modular representation of the actions available to the system and their preconditions and effects , so that these actions can be used automatically as needed anywhere in the response process .", "label": "", "metadata": {}, "score": "33.73021"}
{"text": "establishing the intended meaning within the identified context , wherein the conversational speech engine establishes the intended meaning within the identified context to disambiguate an intent that the user had in speaking the one or more words that have the different meanings in the different contexts ; and .", "label": "", "metadata": {}, "score": "33.739517"}
{"text": "In another implementation , common alternatives for nouns and verbs may be recognized to reflect variations in usage patterns according to various criteria .Thus , variations in expression may be supported because word order is unimportant or unanticipated , and nouns and/or verbs may be represented in different ways to give simplistic , yet representative , examples .", "label": "", "metadata": {}, "score": "33.913467"}
{"text": "Sentence Simplification for Spoken Language Understanding - Sentence simplification may be provided .A spoken phrase may be received and converted to a text phrase .An intent associated with the text phrase may be identified .The text phrase may then be reformatted according to the identified intent and a task may be performed according to the reformatted text phrase .", "label": "", "metadata": {}, "score": "34.072605"}
{"text": "Frames representing ambiguity and partial frames will also be forwarded , for example , when a sentence is received but has more than one meaning and when the user does not complete a sentence , respectively .While the responsiveness of the understanding module is important for responding to the user in a reasonable amount of time , its outputs will not be tightly coupled to the character animation update cycle , preferably permitting runtimes times of up to one or two seconds .", "label": "", "metadata": {}, "score": "34.108208"}
{"text": "In yet another example , when the current utterance contains a threshold amount of information needed to complete a request or task , data in the Session Input Accumulator may be relied upon to tune a degree of certainty .According to another aspect of the invention , Intelligent Hypothesis Builder 310 may use long - term shared knowledge to generate one or more implicit hypotheses of a user 's intent when an utterance is missing qualifiers or other information needed to complete a request or task .", "label": "", "metadata": {}, "score": "34.143124"}
{"text": "The samples may , for example , be collected from actual deployed speech applications and/or purchased as pre - recorded samples of people uttering the expected phrases in a phonetically balanced American English or other appropriate language / dialect .At step 18 , the speech module may be deployed into a live environment .", "label": "", "metadata": {}, "score": "34.158485"}
{"text": "The technique may also include accessing information representing a collection of recorded utterances and an indication of how each of the recorded utterances was interpreted by the speech recognition module .The assigned interpretations may be compared to accurate interpretations , and a separate accuracy value may be determined for each of the plurality of utterance types .", "label": "", "metadata": {}, "score": "34.206646"}
{"text": "While it has recently become possible to build spoken dialog systems that interact with users in real - time in a range of domains , systems that support conversational natural language are still subject to a large number of language understanding errors .", "label": "", "metadata": {}, "score": "34.273407"}
{"text": "Other features represent other aspects of the NLU unit 130 processing of the utterance .The inconsistency feature is an intra - utterance measure of semantic diversity , according to a task model of the domain .Some task classes occur together quite naturally within a single statement or request .", "label": "", "metadata": {}, "score": "34.292892"}
{"text": "Several hundred systems that support system - initiative dialogs are currently being field - tested and deployed .However , systems that support mixed - initiative , conversational , natural language interaction are still subject to a large number of language understanding errors , which have a large impact on the system 's performance .", "label": "", "metadata": {}, "score": "34.35663"}
{"text": "Moreover , the context determination process may infer intended operations and/or context based on previous utterances and/or requests , whereas existing systems consider each utterance independently , potentially making the same errors over and over again .The context determination process may provide advantages over existing voice user interfaces by continually updating one or more models of an existing context and establishing context as a by - product of a conversation , which can not be established a priori .", "label": "", "metadata": {}, "score": "34.394493"}
{"text": "This was improved to 6.5 % coverage error ( 3.3 % for in - domain ) .The structure of a semantic grammar is such that , once a concept hierarchy is created , addition to language variants is a simple process .", "label": "", "metadata": {}, "score": "34.47332"}
{"text": "This may be a significant advantage over existing voice user interfaces with incongruous input and output , where the input is \" conversational \" and the output is \" computerese .\" The following examples may demonstrate how a response may adapt to a user 's input word choices and manner of speaking : .", "label": "", "metadata": {}, "score": "34.498455"}
{"text": "No .09/342,937 , filed Jun. 29 , 1999 , entitled \" Method and Apparatus for Translation of Common Language Utterances into Computer Application Program Commands , \" the entire teachings of which are incorporated herein by reference .When these functions are executed , they build frames within the semantic analysis module 50 which serve as an initial semantic representation of the utterance 15 .", "label": "", "metadata": {}, "score": "34.571564"}
{"text": "When a satisfactory set of utterances have been collected the utterances are passed to a model generation module 25 which generates a speech model using the utterances .The speech model is stored by the model generation module 25 in a model database 26 .", "label": "", "metadata": {}, "score": "34.576347"}
{"text": "Automatic speech recognition is performed on ones of the utterance data not having a corresponding manual transcription to produce automatically transcribed utterances .A model is trained using all of the manually transcribed data and the automatically transcribed utterances .A predetermined number of utterances not having a corresponding manual transcription are intelligently selected and manually transcribed .", "label": "", "metadata": {}, "score": "34.626358"}
{"text": "Additionally , the control module 20 and the data collection module 22 are utilized to identify the vocabulary to be collected and the speakers from whom utterances are to be obtained .This data is stored by the data collection module 22 in the word database 23 and the speaker database 24 respectively .", "label": "", "metadata": {}, "score": "34.737595"}
{"text": "In some embodiments , tuning engine 100 may take the necessary steps to avoid feeding other utterance types to speech module 86 .Though the various engines and components of system 80 and subsystem 82 are depicted as independent blocks , many of the features could be combined and/or further separated .", "label": "", "metadata": {}, "score": "34.901028"}
{"text": "Several evaluations were performed , showing that stochastic generation produces output equivalent to , and in some cases judged better than , handcrafted templates .LIMITED - DOMAIN SYNTHESIS .The quality of speech output in a dialog system is important to a user 's perception of the system .", "label": "", "metadata": {}, "score": "34.922085"}
{"text": "If this is determined not to be the case the model generation module 25 prevents selection of that speaker .The model generation module 25 then ( S 7 - 32 ) determines whether the selection of speakers is sufficient to generate models of the selected words .", "label": "", "metadata": {}, "score": "34.99314"}
{"text": "Description .Published .SYSTEM AND METHOD OF SPOKEN LANGUAGE UNDERSTANDING USING WORD CONFUSION NETWORKS - Word lattices that are generated by an automatic speech recognition system are used to generate a modified word lattice that is usable by a spoken language understanding module .", "label": "", "metadata": {}, "score": "35.0686"}
{"text": "By identifying all relevant information for completing one or more tasks from a single utterance , advantages may be provided over existing voice user interfaces , such as Command and Control systems that use verbal menus to restrict information that a person can provide at a given point .", "label": "", "metadata": {}, "score": "35.107452"}
{"text": "It will also be appreciated that the results of testing generated speech models could also be of different forms .Instead of merely identifying correct and incorrect recognitions , confidence scores or the like for recognitions could be included in a testing report .", "label": "", "metadata": {}, "score": "35.16269"}
{"text": "METHOD FOR BUILDING A NATURAL LANGUAGE UNDERSTANDING MODEL FOR A SPOKEN DIALOG SYSTEM - A method of generating a natural language model for use in a spoken dialog system is disclosed .The method comprises using sample utterances and creating a number of hand crafted rules for each call - type defined in a labeling guide .", "label": "", "metadata": {}, "score": "35.233677"}
{"text": "According to another aspect of the invention , an exemplary cooperative conversational model may build upon free form voice search , noise tolerance , and context determination to implement a conversational Human - to - Machine interface that reflects human interaction and normal conversational behavior .", "label": "", "metadata": {}, "score": "35.260925"}
{"text": "For example , users often can not directly issue a request for a system to retrieve information or perform an action without having to memorize specific syntaxes , words , phrases , concepts , semantic indicators , or other keywords / qualifiers .", "label": "", "metadata": {}, "score": "35.318504"}
{"text": "According to an aspect of the invention , an exemplary system architecture for implementing a cooperative conversational voice user interface is provided .The system may receive an input , which may include a human utterance received by an input device , where the utterance may include one or more requests .", "label": "", "metadata": {}, "score": "35.368053"}
{"text": "Instead , many existing speech interfaces force users to use a fixed set commands or keywords to communicate requests in ways that systems can understand .Using existing voice user interfaces , there is virtually no option for dialogue between the user and the system to satisfy mutual goals .", "label": "", "metadata": {}, "score": "35.57732"}
{"text": "While processing the utterance , the reasoning facility attempts to resolve any ambiguities in the representation of the utterance and to fill in any missing information that is needed to achieve its goal .The reasoning facility then generates a response to the utterance , which can be a question to the user or a command to the application program based on the utterance .", "label": "", "metadata": {}, "score": "35.60098"}
{"text": "The understanding module 610 performs both communicative and non - communicative ( task ) action understanding .Communicative understanding attempts to understand a communicative action taken by the user , and is performed by two sub - modules , the propositional understanding module and the interactional understanding module .", "label": "", "metadata": {}, "score": "35.61006"}
{"text": "a conversational speech engine , wherein the conversational speech engine includes one or more processors configured to : . accumulate short - term shared knowledge about the current conversation , wherein the short - term shared knowledge includes knowledge about the utterance received during the current conversation ; . accumulate long - term shared knowledge about the user , wherein the long - term shared knowledge includes knowledge about one or more past conversations with the user ; . identify a context associated with the utterance from the short - term shared knowledge and the long - term shared knowledge ; . establish an intended meaning for the utterance within the identified context to disambiguate an intent that the user had in speaking the one or more words that have the different meanings in the different contexts ; and .", "label": "", "metadata": {}, "score": "35.82994"}
{"text": "This voice was built in under a week .The stages involved in building such limited domain synthesizers are as follows .First we constructed a set of sentences for recording which adequately covered the desired domain .For Communicator we analyzed the utterances from logs of the most recent three months and sorted them by frequency .", "label": "", "metadata": {}, "score": "35.875393"}
{"text": "However , these results are also passed on to the reaction module which , in addition to acting on the information , may be configured to be entirely responsible for updating the dynamic knowledge base .The task understanding module may be configured to understand the user 's intentions from observing their actions .", "label": "", "metadata": {}, "score": "35.972786"}
{"text": "No .10/452,147 , the system 100 may include a speech recognition engine ( e.g. , an Automatic Speech Recognizer 110 ) that may recognize words and phrases in an utterance using entries in one or more dictionary and phrase tables .", "label": "", "metadata": {}, "score": "36.04316"}
{"text": "The deliberative component 510 performs functions such as uni - modal ( speech only , for example ) and multi - modal understanding of input data ( perception ) , action / response , and action generation .FIG .6 illustrates the deliberative functions expanded into the understanding , response planning , and generation modules 610 , 620 , and 630 , respectively .", "label": "", "metadata": {}, "score": "36.120705"}
{"text": "For example and as mentioned above , a given system may maintain a historical record of its own performance .The record may include , for example , recordings of received utterances and system assigned interpretations for each of the received utterances .", "label": "", "metadata": {}, "score": "36.269455"}
{"text": "For example , the Session Input Accumulator may accumulate inputs including recognition text for each utterance , a recorded speech file for each utterance , a list - item selection history , a graphical user interface manipulation history , or other input data .", "label": "", "metadata": {}, "score": "36.347214"}
{"text": "For example , in various implementations , the output may include a voice - based or otherwise audible response .In another example , when an associated device includes a display mechanism , the output may be displayed on the display device .", "label": "", "metadata": {}, "score": "36.357906"}
{"text": "Instead , existing speech interfaces force users to dumb down their requests to match simple sets of instructions in simple languages in order to communicate requests in ways that systems can understand .Using existing speech interfaces , there is virtually no option for dialogue between the user and the system to satisfy mutual goals .", "label": "", "metadata": {}, "score": "36.404297"}
{"text": "At step 14 , utterance types to be recognized may be selected , and the speech module may be initially trained at step 16 .In a speaker - independent system , thousands of speech samples from many people may be considered in an effort to develop a profile for expected utterances .", "label": "", "metadata": {}, "score": "36.534195"}
{"text": "There are several different types of speech recognition systems currently available which can be categorised in several ways .For example , some systems are speaker dependent , whereas others are speaker independent .Some system can only recognise isolated words / phrases whereas others can recognise continuous speech compromise comprising a series of connected phrases or words .", "label": "", "metadata": {}, "score": "36.539238"}
{"text": "a conversational speech engine , wherein the conversational speech engine includes one or more processors configured to : . accumulate short - term shared knowledge about the current conversation , wherein the short - term shared knowledge includes knowledge about the utterance received during the current conversation ; . accumulate long - term shared knowledge about the user , wherein the long - term shared knowledge includes knowledge about one or more past conversations with the user ; . identify a context associated with the utterance from the short - term shared knowledge and the long - term shared knowledge ; . infer additional information about the utterance from the short - term shared knowledge and the long - term shared knowledge in response to determining that the utterance contains insufficient information to complete a request in the identified context ; . establish an intended meaning for the utterance within the identified identify a context based on the additional information inferred about the utterance ; and .", "label": "", "metadata": {}, "score": "36.591026"}
{"text": "Method and apparatus for converting utterance representations into actions in a conversational system US 7127402 B2 .Abstract .A conversation manager processes a spoken utterance from a user of a computer that is directed to an application program hosted on the computer .", "label": "", "metadata": {}, "score": "36.665672"}
{"text": "build both syntactically and semantically right sentences , in a very . natural fashion , by using pronouns and context information available .at the moment of the natural language generation .The system uses a graphic interface that now is useful but simple .", "label": "", "metadata": {}, "score": "36.667027"}
{"text": "Conversational language processor 120 may build long - term and/or short - term shared knowledge in one or more knowledge source .For example , shared knowledge sources may include information about previous utterances , requests , and other user interactions to inform generating an appropriate response to a current utterance .", "label": "", "metadata": {}, "score": "36.784416"}
{"text": "Short - term knowledge may accumulate during a single conversation , where input received during a single conversation may be retained .The shared knowledge may include cross - modality awareness , where in addition to accumulating input relating to user utterances , requests , locations , etc . , the shared knowledge may accumulate a current user interface state relating to other modal inputs to further build shared knowledge models .", "label": "", "metadata": {}, "score": "36.798622"}
{"text": "Existing systems suffer from these and other problems .SUMMARY OF THE INVENTION .According to various embodiments and aspects of the invention , a cooperative conversational voice user interface may understand free form human utterances , freeing users from being restricted to a fixed set of commands and/or requests .", "label": "", "metadata": {}, "score": "36.80582"}
{"text": "Thus for example a tree listing speakers as a set of expandable nodes could be utilized with each of the utterances collected for a particular speaker be shown as leaf modes .In such a way the exact number of utterances for each word captured for a particular speaker could be displayed and indicated utterances selected for deletion or review .", "label": "", "metadata": {}, "score": "36.86936"}
{"text": "The context determination process may identify one or more context domains for an utterance by defining a collection of related functions that may be useful for users in various context domains .Moreover , each context domain may have relevant vocabularies and thought collections to model word groupings , which when evaluated together , may disambiguate one context domain from another .", "label": "", "metadata": {}, "score": "36.91147"}
{"text": "Such a technique may improve the accuracy of a question answering system and may decrease the length of answers for enabling voice interface to a question answering system .Discriminating Between Natural Language and Keyword Language Items - This disclosure pertains to a classification model , and to functionality for producing and applying the classification model .", "label": "", "metadata": {}, "score": "36.954792"}
{"text": "11 .The Understanding Module .The understanding module 610 is responsible for fusing all input modalities into a coherent understanding of the world , including what the user is doing .The understanding module then applies a set of rules about how the inputs relate to each other in context with the current discourse and knowledge of the domain .", "label": "", "metadata": {}, "score": "37.04187"}
{"text": "That is , existing speech interfaces are unable to bridge the gap between archaic Human - to - Machine interfaces and conversational speech that would make interaction with systems feel normal .Users should be able to directly request what they want from a system in a normal , conversational fashion , without having to memorize exact words or phrases .", "label": "", "metadata": {}, "score": "37.125637"}
{"text": "The interactional understanding module has access to the same inputs , but is responsible for determining non - propositional content , such as information about turn - taking or back - channel communication ( communications not in a main channel , head nodding during a conversation , for example ) .", "label": "", "metadata": {}, "score": "37.1499"}
{"text": "New operations can be added to the speech center 20 by providing a definition of the function in script , and a set of domain rules that describe the prerequisites and effects of the operation .By providing the speech center system 20 with what is in effect \" machine readable documentation \" on its functions , the speech center 20 can choose which functions to call in order to achieve its goals .", "label": "", "metadata": {}, "score": "37.22046"}
{"text": "The stochastic language generation process described earlier is not a problem for this technique , reformulating similar sentence forms is dealt with adequately .Of course although we have coupled the synthesis closely to the generation it is still possible that some words are generated which do not appear in the recorded database .", "label": "", "metadata": {}, "score": "37.2277"}
{"text": "A machine - implemented method to build a library of reusable components for use in building a natural language spoken dialog system may include storing a dataset in a database .The dataset may include a group of reusable components for building a spoken dialog system .", "label": "", "metadata": {}, "score": "37.28629"}
{"text": "Using long - term knowledge may be substantially similar to using short - term shared knowledge , except that information may be unconstrained by a current session , and an input mechanism may include information from additional sources other than conversational sessions .", "label": "", "metadata": {}, "score": "37.369263"}
{"text": "The reasoning facility 52 still must determine which column to operate upon , for example .Conversational speech is full of implicit and explicit references back to people and objects that were mentioned earlier .To understand these sentences , the speech center system 20 looks at the conversational record 60 , and finds the missing information .", "label": "", "metadata": {}, "score": "37.3955"}
{"text": "The non - transitory computer readable medium of . claim 13 , wherein to accumulate the short - term shared knowledge about the current conversation , the computer - executable instructions are further operable when executed to populate a short - term context stack with information about the utterance received during the current conversation .", "label": "", "metadata": {}, "score": "37.49232"}
{"text": "Thus , the responses may conform to a cooperative nature of human dialog and a natural human tendency to \" parrot \" what was just heard as part of a next utterance .Moreover , knowledge of current context may enhance responses to generate more meaningful conversational responses .", "label": "", "metadata": {}, "score": "37.49912"}
{"text": "At least one of sanitizing or anonymizing the natural language input may be performed to form a clean output .The clean output may be stored .Library of Existing Spoken Dialog Data for Use in Generating New Natural Language Spoken Dialog Systems - A machine - readable medium may include a group of reusable components for building a spoken dialog system .", "label": "", "metadata": {}, "score": "37.519276"}
{"text": "The system of .claim 1 wherein the language understanding monitor is further adapted to prompt the dialog manager to route the user to a human for assistance if the first threshold is not exceeded .The system of .claim 1 wherein the language understanding monitor is further adapted to prompt the dialog manager to conduct further dialog with the user using an adapted dialog strategy if the second threshold is not exceeded .", "label": "", "metadata": {}, "score": "37.580772"}
{"text": "09/342,937 , filed Jun. 29 , 1999 , entitled \" Method and Apparatus for Translation of Common Language Utterances into Computer Application Program Commands , \" the teachings of which are incorporated herein by reference .Systems using this approach typically have no other representation for the utterance or the actions that they are taking , and thus they effectively may not have an understanding of what they are doing or why they are doing it .", "label": "", "metadata": {}, "score": "37.60138"}
{"text": "Thus , by storing and analyzing multiple utterances , utterances from earlier in a conversation may be corrected as the conversation progresses .According to another aspect of the invention , Adaptive Response Builder 315 may generate multi - modal , or cross - modal , responses to a user .", "label": "", "metadata": {}, "score": "37.660576"}
{"text": "Once a matching rule 86 has been found , the rule 's 86 conditions must be satisfied .These become new goals for the inference engine 96 of the reasoning facility 52 to achieve , based on the content of the memory and the conversational record .", "label": "", "metadata": {}, "score": "37.692978"}
{"text": "In one embodiment , the communication generation module can be implemented as a template based system ( sentences formed based on sentences with slots for filling in words derived from other sources such as the discourse model ) .A high - level representation of one embodiment of the generation module is illustrated in FIG .", "label": "", "metadata": {}, "score": "37.75889"}
{"text": "According to another aspect of the invention , the intelligent responses may adapt to a user 's manner of speaking by using contextual signifiers and grammatical rules to generate one or more sentences that may cooperate with the user .By taking advantage of shared knowledge about how a user utters a request , the responses may be modeled using similar techniques used to recognize requests .", "label": "", "metadata": {}, "score": "37.81743"}
{"text": "The multi - modal inputs may preferably feed a combination of deliberative and reactive processing that controls the synthetic character .The present invention also includes a method for operating a device , including the steps of displaying a virtual space ; retrieving user inputs from a user in a physical space ; and combining both deliberative and reactive processing on said inputs to formulate a response .", "label": "", "metadata": {}, "score": "37.85359"}
{"text": "As a result , if the user 's input communication can be satisfactorily recognized and understood , the NLU unit 130 routes and/or processes the user 's input communication , which may include the request , comment , etc .However , if the NLU monitor 180 recognizes errors in the understanding of the user 's input communication such that it can not be satisfactorily recognized and understood , dialog with the user may need to be conducted .", "label": "", "metadata": {}, "score": "37.867935"}
{"text": "In one aspect , active learning is employed to selectively sample the data to be re - used .A query click graph may be used to assist in determining candidate pairs for the SMT training data .All / portion of the candidate pairs may be used to train the SMT model .", "label": "", "metadata": {}, "score": "37.905586"}
{"text": "Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance .In one implementation , misrecognitions may be tolerated , and conversational course may be corrected based on subsequent utterances and/or responses .", "label": "", "metadata": {}, "score": "38.127884"}
{"text": "If the performance of the model is unsatisfactory further or different utterances can be used to generate new models for storage within the model database 26 .When a speech model is determined to be satisfactory the control module 20 can invoke the output module 28 to output a copy of the model .", "label": "", "metadata": {}, "score": "38.13509"}
{"text": "The salience - coverage feature measures the proportion of the utterance that is covered by the salient grammar fragments .For example , this may include the whole of a phone or card number if it occurs within a fragment .The context - shift feature is an inter - utterance measure of the extent of a shift of context away from the current task focus , caused by the appearance of salient phrases that are incompatible with it , according to a task model of the domain .", "label": "", "metadata": {}, "score": "38.18019"}
{"text": "It is often , in fact common , that selections for a single word come different instances of that word joined at appropriate parts of the speech .The common prompts are invariably rendered from the original full prompts , thus preserving the original quality exactly .", "label": "", "metadata": {}, "score": "38.185684"}
{"text": "If successful , this inference procedure achieves the goal of processing the utterance , and , in the course of doing so , the proper script calls have been made .In one aspect of the present invention , an apparatus and method is provided for converting an utterance representation into a response .", "label": "", "metadata": {}, "score": "38.19774"}
{"text": "LANGUAGE GENERATION .To date , most of the research in natural language generation ( NLG ) has focused on generating text using template - based or rule - based ( linguistic ) techniques .In order to overcome some of the difficulties in using the current NLG technologies for spoken dialogue systems , we investigated a corpus - based approach to NLG [ 7 ] .", "label": "", "metadata": {}, "score": "38.230927"}
{"text": "A computer can include a speech recognition or natural language processing system that receives or recognizes utterances and decides what to do with them .Traditionally , a number of such processing systems transform an utterance directly into script commands .For command and control systems , these utterances typically represent commands that require the system to take some form of action .", "label": "", "metadata": {}, "score": "38.233917"}
{"text": "The generation module is a linear process that takes a high - level semantic representation as input , and outputs a packet containing a string of words to be spoken and corresponding non - verbal behaviors to be performed .The process starts by matching the semantic representation against a set of templates 1510 .", "label": "", "metadata": {}, "score": "38.39112"}
{"text": "a response generation module configured to implement each real time response and complex action formulated by said reactive component .The interface according to . claim 17 , wherein : . said deliberative processing component includes a relation module configured to relate at least one of the additional user inputs to said speech stream .", "label": "", "metadata": {}, "score": "38.46"}
{"text": "The motivation for these NLU features is to make use of in - formation that the NLU unit 130 has as a result of processing the output of recognizer 120 and the current discourse context .For example , for utterances that follow the first utterance , the NLU unit 130 knows what task it believes the user is trying to complete .", "label": "", "metadata": {}, "score": "38.634678"}
{"text": "The one or more preliminary interpretations may then be provided to a conversational speech engine for further processing , where the conversational speech engine may communicate with one or more databases to generate an adaptive conversational response , which may be returned to the user as an output .", "label": "", "metadata": {}, "score": "38.662785"}
{"text": "One advantage of pre - scripting is that the integration of verbal and non - verbal behaviors need not be calculated at runtime , thereby avoiding complicated on - the - fly planning of motor controls in the animation model .Scripted characters , on the other hand , are limited in their ability to interact with users and react to multimodal user inputs .", "label": "", "metadata": {}, "score": "38.74341"}
{"text": "The speech center 20 has at its disposal a set of actions that it can perform itself .These are a subclass of the class of all actions that the speech center 20 knows about , and are known as operations .", "label": "", "metadata": {}, "score": "38.764717"}
{"text": "Embodiments discussed below focus on the tuning of a deployed speech recognition system .Though the following discussions focus on this implementation of the teachings , the teachings may be applied in other circumstances as well .Although certain embodiments are described using specific examples , it will be apparent to those skilled in the art that the invention is not limited to these few examples .", "label": "", "metadata": {}, "score": "38.784897"}
{"text": "Speech interfaces avoid some of the pitfalls of text - only NLP systems , but fail to utilize information in the non - verbal channels , such as gestures , as well as some of the information in the speech wave itself , such as the meaning carried by the speaker 's intonation .", "label": "", "metadata": {}, "score": "38.820396"}
{"text": "All context domains may be accessible , allowing the user to switch contexts at any time without confusion .Thus , just as in human - to - human conversation , context domains may be rapidly selected , without menu - driven dead ends , when an utterance is unambiguous .", "label": "", "metadata": {}, "score": "38.875183"}
{"text": "FIG .1 is a block diagram of a preferred embodiment of the present invention in a computer system .FIG .2 is a block diagram of the components of the speech center system illustrated in .FIG .1 .", "label": "", "metadata": {}, "score": "38.880993"}
{"text": "The invention also relates to nucleic acids encoding the variants of TNF family ligands , vectors and host cells comprising the nucleic acid and methods for the treatment of diseases associated with aberrant signalling through a TNF receptor .A conversation manager processes a spoken utterance from a user of a computer that is directed to an application program hosted on the computer .", "label": "", "metadata": {}, "score": "38.911972"}
{"text": "The use of running tallies and percentages is based on showing that normalized features are more likely to produce generalized predictors .FIG .2 is a flowchart of an exemplary natural language understanding monitoring process .The process begins its step 2000 and goes to step 2100 where the NLU monitor 180 receives recognition and understanding data from the recognizer 120 and the NLU unit 130 , respectively , based on an input communication from a user .", "label": "", "metadata": {}, "score": "38.969093"}
{"text": "a co - ordination unit , said co - ordination unit being operable : . to generate a third user interface to enable user input of speaker identifiers for storage in said speaker database ; . to generate a second user interface to enable user input of word identifiers for storage in said vocabulary database ; and .", "label": "", "metadata": {}, "score": "38.98523"}
{"text": "These are summarized in the paragraphs below .Spoken Language Processing .Table 1 illustrates the comparative language capabilities of the autonomous character systems under consideration .The Ymir architecture does not integrate dialogue planning into its mostly reactive processing , and consequently , spoken output is canned ( i.e. pre - planned ) .", "label": "", "metadata": {}, "score": "39.062042"}
{"text": "In a preferred embodiment , the language generation module 54 takes advantage of the knowledge stored in the syntax manager 62 , domain model 70 , lexicon 66 , and conversational record 60 in order to generate natural language output .In one embodiment , the language generation module 54 generates language from the same syntax templates used for recognition , or from additional templates provided specifically for language generation .", "label": "", "metadata": {}, "score": "39.103012"}
{"text": "The system of . claim 1 further comprising .a recognizer that is adapted to recognize the user 's input communication ; and .a language understanding unit that is adapted to apply a confidence function to the recognized portions of the user 's input communication and to provide an input to the language understanding monitor .", "label": "", "metadata": {}, "score": "39.14948"}
{"text": "The non - transitory computer readable medium of . claim 13 , wherein the computer - executable instructions are further operable when executed to : . identify a conversational goal associated with the utterance , roles associated with the user and one or more other participants in the current conversation , and an information allocation among the user and the one or more other participants in the current conversation ; and .", "label": "", "metadata": {}, "score": "39.19946"}
{"text": "By identifying a context , capabilities within the context , vocabularies within the context , what tasks are done most often historically in the context , what task was just completed , etc . , the context determination process may establish intent from rather meager phonetic clues .", "label": "", "metadata": {}, "score": "39.27572"}
{"text": "Conversational speech engine 215 may generate an adaptive conversational response to one or more requests , where the requests may depend on unspoken assumptions , incomplete information , context established by previous utterances , user profiles , historical profiles , environmental profiles , or other information .", "label": "", "metadata": {}, "score": "39.315224"}
{"text": "By modeling what contextual signifiers , qualifiers , or other information may be required to perform a task in an identified context , an adaptive response may be generated , such as prompting a user for missing contextual signifiers , qualifiers , or other information .", "label": "", "metadata": {}, "score": "39.391953"}
{"text": "Deep Linking From Task List Based on Intent - Task list linking may be provided .Upon receiving an input from a user , the input may be translated into at least one actionable item .The at least one actionable item may be linked to a data source and displayed to the user .", "label": "", "metadata": {}, "score": "39.679573"}
{"text": "For example , a single device may include multiple microphones , or multiple devices may each include one or more microphones , and the noise tolerance module may collate inputs and cooperatively filter out sound by comparing a speech signal from the various microphones .", "label": "", "metadata": {}, "score": "39.72491"}
{"text": "This approach is summarized in Table 2 .Thus , speech may convey different interactional information ; it may be interpreted as taking turn , giving turn , or holding turn depending on the conversational state and what is conveyed by the other modalities .", "label": "", "metadata": {}, "score": "39.75228"}
{"text": "1 presents a flow diagram for providing targeted speech solution tuning in accordance with the teachings of the present disclosure .Technique 10 of .FIG .1 may begin with designing a speech module as indicated at step 12 .In one embodiment , a to - be - deployed speech recognition system may be designed to be speaker - independent and to recognize utterance types that include several different action requests .", "label": "", "metadata": {}, "score": "39.78105"}
{"text": "At step 5200 , the recognizer 420 attempts to recognize portions of the user 's input communication , including grammar fragments , meaningful words / phrases / symbols , morphemes , actions , gestures , or any other communication signal .At step 5300 , based on the understanding received from the NLU unit 430 , the NLU monitor 180 determines whether the user 's input communication can be correctly understood so that the task can be classified .", "label": "", "metadata": {}, "score": "39.813698"}
{"text": "Translating Natural Language Utterances to Keyword Search Queries - Natural language query translation may be provided .A statistical model may be trained to detect domains according to a plurality of query click log data .Upon receiving a natural language query , the statistical model may be used to translate the natural language query into an action .", "label": "", "metadata": {}, "score": "39.93207"}
{"text": "The speech center system 20 also includes a rule base 84 and goal - directed rules 86 used by the reasoning facility 52 .The output 16 consists of one or more commands or other output based on the recognized spoken utterance 15 and which is directed to the speech enabled external application 26 ( see .", "label": "", "metadata": {}, "score": "40.029575"}
{"text": "Further , when a particular feature , structure , or characteristic is described in connection with an aspect or implementation , it will be apparent to effect such feature , structure , or characteristic in connection with other aspects or implementations whether or not explicitly described .", "label": "", "metadata": {}, "score": "40.04037"}
{"text": "In various implementations , free form search module 245 may include , among other things , a free form utterance feature , a one - step access feature , an inferencing intended operations feature , an alternative expression feature , and/or an imperfect speech feature .", "label": "", "metadata": {}, "score": "40.044872"}
{"text": "The appropriate interpretation may represent a more accurate interpretation of an utterance and may be generated by the tuning application and/or by an entity separate from the tuning application .The application may then begin targeted tuning , which may involve , for example , feeding a collection of one type of utterance into a learning module .", "label": "", "metadata": {}, "score": "40.06485"}
{"text": "Natural language input may be received .At least one of sanitizing or anonymizing the natural language input may be performed to form a clean output .The clean output may be stored .KERNEL DEEP CONVEX NETWORKS AND END - TO - END LEARNING - Data associated with spoken language may be obtained .", "label": "", "metadata": {}, "score": "40.34932"}
{"text": "This provides advantages over existing voice user interfaces where input and output is incongruous , as the input is \" conversational \" and the output is \" computerese . \"According to another aspect of the invention , the intelligent responses may frame responses to influence a user reply utterance for easy recognition .", "label": "", "metadata": {}, "score": "40.35691"}
{"text": "Without this knowledge , it would be limited to providing little more than simplistic menu based command and control services .Instead , the speech center 20 has a detailed model ( e.g. , as part of the domain model 70 ) of what a user might say to a particular application 26 , and how to respond .", "label": "", "metadata": {}, "score": "40.45964"}
{"text": "linguistic level means to consider phenomena such as unnecessary .word repetition , grammatical order change , anaphora , discordances , . context information , grammatical mistakes , etc .We also expect a .learning ability for the system to allow new information ( foods , . drinks , ingredients , etc . ) acquisition from client interaction .", "label": "", "metadata": {}, "score": "40.56436"}
{"text": "The Generation Module .The requested actions may be requested to be performed in parallel .For example , the generation module may request that the character say something , while doing a particular action , while another task is performed ( such as a database function or task requested by the user ) .", "label": "", "metadata": {}, "score": "40.574127"}
{"text": "5 , respectively , and will not be discussed further .However , after step 6400 in .FIG .6 in which the first dialog exchange is stored in the dialog history database 170 , in step 6450 , the NLU monitor 180 determines whether the probability of correctly understanding the user 's input communication exceeds a second threshold .", "label": "", "metadata": {}, "score": "40.746544"}
{"text": "For example : .Acknowledgment of user 's presence - by posture , turning to face the user ; .Turntaking function - The character tracks who has the speaking turn , and only speaks when she holds the turn .In one embodiment , the character always allows verbal interruption , and yields the turn as soon as the user begins to speak .", "label": "", "metadata": {}, "score": "40.77707"}
{"text": "modify previous product orders .Using these patterns the system can .extract most semantic meanings from clients ' utterances .In case the .meaning can not be obtained , clients are asked to help the system .understanding process or to repeat the utterance input differently .", "label": "", "metadata": {}, "score": "40.95375"}
{"text": "Description .Published .Combining active and semi - supervised learning for spoken language understanding - Combined active and semi - supervised learning to reduce an amount of manual labeling when training a spoken language understanding model classifier .The classifier may be trained with human - labeled utterance data .", "label": "", "metadata": {}, "score": "40.992508"}
{"text": "A text - to - speech . interface should transform the system output into synthesized voice .Theoretically the whole system could be part of an .automatic front - end dialogue system for clients in restaurants , . or for those at home who use telephone for ordering .", "label": "", "metadata": {}, "score": "41.011024"}
{"text": "For example , conversational language processor 120 may use context determination module 130 to establish a context for a current utterance by having domain agents 135 competitively generate a context - based interpretation of the utterance ( e.g. , by scoring possible interpretations and selecting a highest scoring interpretation ) .", "label": "", "metadata": {}, "score": "41.038948"}
{"text": "The process then proceeds to step 3800 , where determination is made whether the user 's input communication can be processed based on either the current dialog strategy or the adapted dialog strategy opted for in step 3500 .The process that continues similar to .", "label": "", "metadata": {}, "score": "41.040234"}
{"text": "Using ten - fold cross - validation , the resulting NLU error classifier can correctly identify whether an utterance is an NLU error 86 % of the time , an improvement of 23 % over the majority class baseline .In addition , the most important features are those that the NLU unit 130 can compute , suggesting that it will be straightforward to integrate the NLU monitor 180 into the NLU unit 130 of the system 100 .", "label": "", "metadata": {}, "score": "41.070786"}
{"text": "The utterance component of input 105 may be processed by a speech recognition engine 110 ( which may alternatively be referred to herein as Automatic Speech Recognizer 110 , or as shown in .FIG .1 , ASR 110 ) to generate one or more preliminary interpretations of the utterance .", "label": "", "metadata": {}, "score": "41.103188"}
{"text": "Conversational language processor 120 may generate a domain - specific conversational response , which may be returned to the user as an output 180 .Output 180 may include a multi - modal output ( e.g. , by simultaneously returning a voice - based response and displaying information on a display device ) .", "label": "", "metadata": {}, "score": "41.197563"}
{"text": "According to one aspect of the invention , noise tolerance module 250 may be closely related to the imperfect speech feature , and may operate to discard words or noise that has no meaning in a given context so as not to create confusion .", "label": "", "metadata": {}, "score": "41.274597"}
{"text": "The present invention has been developed to address the difficulties of enabling non - expert users to generate train and test speech recognition models .In accordance with one embodiment of the present invention there is provided an apparatus for generating and testing speech models , said apparatus comprising : . a data collection unit operable to collect and store utterance data indicative of the pronunciation of one or more words by one or more speakers ; . a speech model generation unit operable to generate speech models of words , utterances of which have been collected by said data collection unit ; and .", "label": "", "metadata": {}, "score": "41.37147"}
{"text": "The dialog system understands user requests when multiple users are interacting with each other as well as the dialog system .The dialog system uses multi - human conversational context to improve domain detection .Using interactions between multiple users allows the dialog system to better interpret machine directed conversational inputs in multi - user conversational systems .", "label": "", "metadata": {}, "score": "41.55509"}
{"text": "This process may be cumulative .In particular , the first dialog exchange may be stored in a database .Then , a second dialog exchange is conducted with the user .As a result , a second determination is made as to whether the user 's input communication can be understood can be conducted based on the stored first exchange and the current second exchanges .", "label": "", "metadata": {}, "score": "41.6007"}
{"text": "Giving a prompt list of just over 600 utterances .These were then recorded in the style of a helpful agent .The recordings were autolabelled using a simple alignment technique between the naturally spoken utterances and synthesized equivalents .The utterances were then used to build a unit selection synthesizer using the algorithm first described in [ [ 5 ] ] .", "label": "", "metadata": {}, "score": "41.68733"}
{"text": "In the case of Communicator , destination names and the names of users registering for the service .The latter components can be easily modified to accommodate evolution and do not appear to impact the core language .This is accommodated in language modeling through the use of a class language model .", "label": "", "metadata": {}, "score": "41.740902"}
{"text": "The response planning module 620 synthesizes action sequences that must be executed over time .The generation module 630 elaborates high - level action specifications into primitives that are directly executed in the current execution cycle .FIG .7 illustrates a more detailed view of the architecture showing data stores used in the system .", "label": "", "metadata": {}, "score": "41.762108"}
{"text": "The conversation manager 28 converts the utterance 15 into an intermediate form or utterance representation 21 that is more amenable to processing .The translation process initially converts recognized utterances 15 into sequences of script calls to frame - building functions via a recursive substitution translation facility .", "label": "", "metadata": {}, "score": "41.779182"}
{"text": "In another embodiment , only one behavior can use a given DOF during a single time span .However , the later embodiment gives rise to problems of conflict resolution among behaviors competing for the same DOF which may be resolved through another mechanism ( fixed priorities , or a weighting scheme , for example ) .", "label": "", "metadata": {}, "score": "41.803753"}
{"text": "The method according to .claim 12 , wherein said step of updating comprises : . maintaining a tagged history of speech of said user , including the step of : . identifying said discourse model with at least one of a topic under conversation between said user and said virtual environment and other information received via either of said deliberative and reactive processing .", "label": "", "metadata": {}, "score": "41.87188"}
{"text": "2 , respectively , and will not be further discussed .However , after step 3400 in which the first dialog exchange is stored in the dialog history database 170 , in step 3500 , the NLU monitor 180 determines whether the probability of correctly understanding the user 's input communication exceeds a second threshold .", "label": "", "metadata": {}, "score": "41.897232"}
{"text": "The selected speakers and words are then reviewed .After playback and review of the recorded utterances and any user deletions of utterances the data collection module 22 then causes the control module 20 to once again to once again display the main control screen ( S 7 - 1 ) .", "label": "", "metadata": {}, "score": "41.933937"}
{"text": "A language identifier can initially receive linguistic input and identify the language within which such linguistic input is provided to select an appropriate machine translation component .A hybrid process , comprising machine translation components and linguistic components associated with the anchor language , can also serve as an initiating construct from which a single language process is created over time .", "label": "", "metadata": {}, "score": "41.988194"}
{"text": "By identifying a context , capabilities within the context , vocabularies within the context , what tasks are done most often historically in the context , what task was just completed , etc . , a context domain agent 230 may establish intent from rather meager phonetic clues .", "label": "", "metadata": {}, "score": "42.009995"}
{"text": "FIG .1 presents a flow diagram for providing targeted speech solution tuning in accordance with the teachings of the present disclosure ; .FIG .2 shows one embodiment of a speech - enabled system that incorporates teachings of the present disclosure ; and .", "label": "", "metadata": {}, "score": "42.07854"}
{"text": "Discourse Model .The discourse model is used by the understanding , generation , and response planning modules to track the stack of discourse topics and other information used in processing natural language dialog .In one embodiment , the discourse model includes a tagged history of speech and the topic under discussion .", "label": "", "metadata": {}, "score": "42.133"}
{"text": "Upon receiving an input from a user comprising a plurality of elements , the input may be decoded into a word lattice comprising a plurality of words .A tag may be assigned to each of the plurality of words and a most - likely sequence of word - tag pairs may be identified .", "label": "", "metadata": {}, "score": "42.135788"}
{"text": "In practice , a system 's recognition rate at implementation may be unacceptably low .This recognition rate may be improved through tuning .However , conventional approaches to tuning may be costly in both time and money .Moreover , the effectiveness of conventional tuning approaches is often difficult to quantify and predict .", "label": "", "metadata": {}, "score": "42.15349"}
{"text": "The process then goes to step 5900 and ends .If , in step 5500 , the NLU monitor 180 determines that the probability of correctly understanding the user 's input communication is above the predetermined threshold based on the stored classification model , in step 5600 the first dialog exchange is stored in the dialog history database 170 .", "label": "", "metadata": {}, "score": "42.21173"}
{"text": "For example , Intelligent Hypothesis Builder 310 may evaluate a degree of certainty based on a number of previous requests relevant to the current utterance .In another example , when the current utterance contains insufficient information to complete a request or task , data in the Session Input Accumulator may be used to infer missing information so that a hypothesis can be generated .", "label": "", "metadata": {}, "score": "42.216896"}
{"text": "The computer - readable medium of .The non - transitory computer readable medium of . claim 17 , wherein the conversational speech engine further grammatically or syntactically adapts the response based on conversation type .The non - transitory computer readable medium of . claim 13 , wherein the conversational speech engine grammatically or syntactically adapts more the response to influence a subsequent reply utterance that the conversational speech engine expects from the user during the current conversation .", "label": "", "metadata": {}, "score": "42.28031"}
{"text": "The digital processor hosts and executes a reasoning facility that is configured to generate a goal derived from the utterance representation and to analyze the utterance representation based on the goal and the set of goal - directed rules in the database .", "label": "", "metadata": {}, "score": "42.28911"}
{"text": "The computer method of .claim 1 wherein the step of analyzing the utterance representation comprises applying a goal - directed reasoning analysis based on the set of goal - directed rules to clarify the ambiguous information .The computer method of . claim 2 , wherein the step of analyzing the utterance representation comprises accessing data in a conversational record of related utterances to clarify the ambiguous information .", "label": "", "metadata": {}, "score": "42.317013"}
{"text": "Moreover , knowledge of current context may enhance responses to generate more meaningful conversational responses , such as in the following exchange : .Framing the responses may also deal with misrecognitions according to human models .For example , humans frequently remember a number of recent utterances , especially when one or more previous utterances were misrecognized or unrecognized .", "label": "", "metadata": {}, "score": "42.384018"}
{"text": "methods for such a system , as well as information about the evaluation .for natural language dialogue systems in general ( used techniques , . bibliography , web sites , etc . ) .In order to provide more information , I enclose a short abstract .", "label": "", "metadata": {}, "score": "42.463547"}
{"text": "The method of .The method of . claim 5 , wherein the conversational speech engine further grammatically or syntactically adapts the response based on the conversation type .The method of .claim 1 , wherein the conversational speech engine grammatically or syntactically adapts the response to influence a subsequent reply utterance that the conversational speech engine expects from the user during the current conversation .", "label": "", "metadata": {}, "score": "42.50397"}
{"text": "It is another object of this invention to provide an interface based on construction of a user ally for operation of a computer or other device .It is another object of the present invention to integrate multiple processing techniques and multiple i / o modalities to provide a conversational character operating as a naturalistic , intuitive , and coherent interface .", "label": "", "metadata": {}, "score": "42.517044"}
{"text": "In this classification , the names of a set of classes to be learned , the names and ranges of values of a fixed set of features , and training data specifying the class and feature values for each example in a training set , were input .", "label": "", "metadata": {}, "score": "42.532883"}
{"text": "First , these \" paraverbal \" behaviors can convey semantic content that can not be recovered from the speech alone , such as when a speaker identifies an object by making a pointing gesture .Second , they can signal subtle interactional cues that regulate the flow of information between interlocutors , such as when a speaker 's intonation rises at the end of a phrase in attempting to hold the speaking floor .", "label": "", "metadata": {}, "score": "42.585228"}
{"text": "The system of .claim 25 , wherein to accumulate the short - term shared knowledge about the current conversation , the one or more processors are further configured to populate a short - term context stack with information about the utterance received during the current conversation .", "label": "", "metadata": {}, "score": "42.633232"}
{"text": "2 is an exemplary block diagram of a conversational speech engine according to one aspect of the invention .FIG .3 is an exemplary block diagram of a cooperative conversational model according to one aspect of the invention .DETAILED DESCRIPTION .", "label": "", "metadata": {}, "score": "42.698273"}
{"text": "In operation , the alternative expression feature may allow nouns and/or verbs to be represented in different ways to give simplistic , yet representative , examples .The imperfect speech feature may be able to infer requests from contradictory or otherwise inaccurate information , such as when an utterance includes starts and stops , restarts , stutters , run - on sentences , or other imperfect speech .", "label": "", "metadata": {}, "score": "42.75644"}
{"text": "These utterances are placed in an annotation list along with a type of annotation to be performed for the utterances and an order in which the annotation should proceed .The utterances in the annotation list can be annotated for speech recognition purposes , spoken language understanding purposes , labeling purposes , etc .", "label": "", "metadata": {}, "score": "42.772133"}
{"text": "In accordance with another aspect of the present invention there is provided a method of collecting utterance data comprising the steps of : . displaying a first user interface to enable user input of speaker identifiers and storing said speaker identifiers in a speaker database ; . displaying a second user interface to enable user input of word identifiers and storing said word identifiers in a vocabulary database ; . displaying a series of prompts to prompt the utterance of words corresponding to word identifiers stored in said vocabulary database by speakers identified by speaker identifiers stored in said speaker database ; and . synchronising the collection of utterance data indicative of the pronunciation of words with said series of prompts .", "label": "", "metadata": {}, "score": "42.78998"}
{"text": "The speech center 20 receives the recognized spoken utterance 15 , and the conversation manager 28 of the speech center 20 generates the utterance representation 21 as an internal representation of the recognized spoken utterance 15 .For example , the user selects a message to be opened that is displayed on the screen of a computer , so that the user can read ( or hear ) the full message .", "label": "", "metadata": {}, "score": "42.81546"}
{"text": "In earlier versions of the CMU Communicator we used a general - purpose commercial speech synthesis system .More recently we have begun to experiment with synthesis tailored specifically to this domain .Unit selection synthesis , where appropriate sub - word units are selected from general speech databases , for example AT&T 's NextGen [ 3 ] , can produce very high quality synthesis .", "label": "", "metadata": {}, "score": "42.867935"}
{"text": "As such , there is ever - growing demand for ways to exploit technology in intuitive ways .Voice recognition software may enable a user to exploit applications and features of a device that may otherwise be unfamiliar , unknown , or difficult to use .", "label": "", "metadata": {}, "score": "42.900738"}
{"text": "For example , the requests may include requests to retrieve information , perform tasks , explore or gather information , or otherwise interact with a system or device .For example , a voice - based input to a navigation device may include a request to calculate a route or retrieve location - based information .", "label": "", "metadata": {}, "score": "42.936337"}
{"text": "5 is a flowchart of the process of analyzing an utterance representation according to the present invention .DETAILED DESCRIPTION OF THE INVENTION .A description of preferred embodiments of the invention follows .FIG .1 is an illustration of a preferred embodiment in a computer system 10 .", "label": "", "metadata": {}, "score": "43.002415"}
{"text": "In another aspect of the invention , audio data is mined from at least one source , and a language model is trained for call classification from the mined audio data to produce a language model .Answer Determination for Natural Language Questioning -", "label": "", "metadata": {}, "score": "43.012337"}
{"text": "A second NLU model is built using the sample utterances as new training data and using the hand crafted rules .The second NLU model is tested for performance using a first batch of labeled data .A series of NLU models are built by adding a previous batch of labeled data to training data and using a new batch of labeling data as test data to generate the series of NLU models with training data that increases constantly .", "label": "", "metadata": {}, "score": "43.035957"}
{"text": "In another aspect , the response is a computer application program command based on the utterance representation .BRIEF DESCRIPTION OF THE DRAWINGS .The foregoing and other objects , features and advantages of the invention will be apparent from the following more particular description of preferred embodiments of the invention , as illustrated in the accompanying drawings in which like reference characters refer to the same parts throughout the different views .", "label": "", "metadata": {}, "score": "43.03756"}
{"text": "Individual sounds and/or a collection of individual sounds may be identified and matched to a predefined list of sounds , words , and/or phrases .The complex nature of translating raw audio into discrete pieces and matching the audio to some pre - defined profile often involves a great deal of signal processing and may , in some instances , be performed by a speech recognition ( SR ) engine executing on a given computing system .", "label": "", "metadata": {}, "score": "43.049667"}
{"text": "Otherwise , the full referring expression , \" the vcr , \" would be selected .Words in the fully instantiated utterance are then evaluated with respect to focus rules 1540 that determine which words are most salient .Words are considered to be in \" focus \" ( most salient ) when they occur for the first time ( as determined by consulting the discourse model ) , or if they have n't been mentioned recently .", "label": "", "metadata": {}, "score": "43.07157"}
{"text": "For example , humans frequently remember a number of recent utterances , especially when one or more previous utterances were misrecognized or unrecognized .Another participant in the conversation may limit correction to a part of the utterance that was misrecognized or unrecognized , or over subsequent utterances and/or other interactions , clues may be provided to indicate the initial interpretation was incorrect .", "label": "", "metadata": {}, "score": "43.181664"}
{"text": "At step 20 , the speech module may receive an utterance .An incoming signal may represent the utterance and may be digitized for further manipulation .In practice , the speech module may digitize the incoming speech signal and calculate utterance parameters .", "label": "", "metadata": {}, "score": "43.202377"}
{"text": "For example , a user may sometimes change their mind , and thus alter the request in mid - utterance , and the imperfect speech feature may nonetheless be able to infer a request based on models of human speech .For example , various models may indicate that a last criterion is most likely to be correct , or intonation , emphasis , stress , use of the word \" not , \" or other models may indicate which criterion is most likely to be correct .", "label": "", "metadata": {}, "score": "43.247124"}
{"text": "The reasoning facility , in another aspect , generates a question directed to the provider of the utterance representation to clarify the ambiguous information or request additional information which was not provided .The question emerges from the analysis of the utterance representation based on goal - directed seeking of the information required to achieve the goal of processing the utterance .", "label": "", "metadata": {}, "score": "43.25331"}
{"text": "Work in this area can be further divided into two categories : entertainment / simulation characters , and task - based characters .The former category includes non - human character representations ( e.g. Prior task - based autonomous characters include the following systems : .", "label": "", "metadata": {}, "score": "43.27336"}
{"text": "3 is a block diagram of the components of the conversation manager illustrated in .FIG .2 . FIG .4 is a block diagram of the components of the reasoning facility , according to a preferred embodiment of the invention .", "label": "", "metadata": {}, "score": "43.377396"}
{"text": "FIG .2 below .Conversational speech engine 115 may communicate with one or more databases 130 to generate an adaptive conversational response , which may be returned to the user as an output 140 .In one implementation , output 140 may be a multi - modal output and/or an interaction with one or more applications 145 to complete the request .", "label": "", "metadata": {}, "score": "43.400356"}
{"text": "At each step , the reactive module makes decisions , based on weights and priorities ( the salience of each of a set of rules whose preconditions have been satisfied ) , about which inputs require action and how the actions are to be organized .", "label": "", "metadata": {}, "score": "43.426506"}
{"text": "The present invention utilizes both styles of control in different situations .When commanding a communicative act - a tightly synchronized sequence of utterances , gestures , and expressions - a discrete style of control is preferred .The process style of control is actually more general , since discrete control can be achieved via behaviors which simply perform a discrete action and then do not update their DOFs once it has completed .", "label": "", "metadata": {}, "score": "43.435387"}
{"text": "The present invention also merges reactive and deliberative functionalities , allowing a character to simultaneously plan dialogue while exhibiting appropriate reactive non - verbal behaviors .Because the reactive and deliberative behaviors must work in concert , an adequate architecture is not achieved by simply concatenating reactive and deliberative architectures , but rather an integration of the reactive and deliberative aspects of those architectures .", "label": "", "metadata": {}, "score": "43.489723"}
{"text": "For example , in one implementation , the free form search module may understand specialized jargon and/or slang , tolerate variations in word order , and tolerate verbalized pauses or stuttered speech .For example , formalized English requests , where a verb precedes a noun , may be treated in an equivalent manner to requests where the noun precedes the verb .", "label": "", "metadata": {}, "score": "43.490704"}
{"text": "Some queries may be set aside for testing and the model may be adapted using in - domain sentences that are not annotated .The models may be tested using these implicitly annotated natural - language - like queries in an unsupervised fashion .", "label": "", "metadata": {}, "score": "43.49457"}
{"text": "2 . DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS .Embodiments of the present invention can be implemented in computer hardware , but the embodiment to be described is implemented in software which is run in conjunction with processing hardware such as a personal computer , workstation , or the like .", "label": "", "metadata": {}, "score": "43.50454"}
{"text": "A system and method are disclosed for targeted tuning of a speech recognition system .A method incorporating teachings of the present disclosure may include deploying a speech recognition module to apply an appropriate interpretation to a plurality of utterance types .", "label": "", "metadata": {}, "score": "43.51686"}
{"text": "The reasoning facility , in a further aspect , generates the computer application program command based on the utterance representation and based on the analysis of the ambiguous information .In another aspect , the utterance representation is based on a set of propositions , each proposition comprising an attribute , an object , and a value .", "label": "", "metadata": {}, "score": "43.526222"}
{"text": "However , relevant information from an expired session context may nonetheless be added to user , historical , environmental , cognitive , or other long - term knowledge models .Long - term shared knowledge may generally be user - centric , rather than session - based .", "label": "", "metadata": {}, "score": "43.54638"}
{"text": "This paper describes a variety of techniques we have applied to modeling in acoustic , language , task , generation and synthesis components of the system .INTRODUCTION .System development involves a great deal of knowledge engineering , which is both time - consuming and requires a variety of experts to participate in the process .", "label": "", "metadata": {}, "score": "43.552216"}
{"text": "That is , even though the intelligent responses may be reasonably \" sure , \" the intelligent responses may nonetheless sometimes be incorrect .While existing voice user interfaces tend to fail on average conversational missteps , normal human interactions may expect missteps and deal with them appropriately .", "label": "", "metadata": {}, "score": "43.57132"}
{"text": "That is , even though the intelligent responses may be reasonably \" sure , \" the intelligent responses may nonetheless sometimes be incorrect .While existing voice user interfaces tend to fail on average conversational missteps , normal human interactions may expect missteps and deal with them appropriately .", "label": "", "metadata": {}, "score": "43.57132"}
{"text": "Proper coarticulation may be produced via a blending model .However , this effect may be realizable by simply parameterizing gesture behaviors or some other technique short of true blending of motor controls .The present invention as discussed herein has been described in reference to a conversational and synthetic character interface .", "label": "", "metadata": {}, "score": "43.598557"}
{"text": "Discussion of the Background .Synthetic , animated characters can be divided into two broad categories : characters that are directly controlled by a human user 's actions , and characters that perform behaviors , independent of the user 's actions , either autonomously or through pre - compiled scripts .", "label": "", "metadata": {}, "score": "43.620956"}
{"text": "Noise tolerance module 250 may also filter out non - human environmental noise within the range of the microphones , out - of - vocabulary words , which could be a result of speaker ambiguity or malapropisms , or other noise that may be unrelated to a target request .", "label": "", "metadata": {}, "score": "43.659332"}
{"text": "If the performance is determined not to be satisfactory the user can amend the utterance data 49 used to generate particular word models by utilizing the data collection module 22 and the model generation module 25 by selecting the other options available on the main user interface screen 100 .", "label": "", "metadata": {}, "score": "43.696724"}
{"text": "The input manager also calibrates movements detected in the physical space to corresponding coordinates in the virtual space .Data input from the user and information input about the domain and virtual spaces is placed in a uniform structure to be passed on to other modules .", "label": "", "metadata": {}, "score": "43.72946"}
{"text": "Participating in conversations that continually build and draw upon shared information is a natural and intuitive way for humans to converse .In contrast , complex Human - to - Machine interfaces do not allow users to exploit technology in an intuitive way , which inhibits mass - market adoption for various technologies .", "label": "", "metadata": {}, "score": "43.737244"}
{"text": "By taking advantage of short - term ( from the Session Input Accumulator ) and long - term ( from one or more profiles ) shared knowledge about how a user utters a request , the responses may be modeled using techniques used to recognize requests .", "label": "", "metadata": {}, "score": "43.801376"}
{"text": "The action scheduler of the present invention may synchronize gesture and speech using either absolute time stamps or speech strings with embedded gesture commands .In particular , the API provides for phoneme call backs , which the synthesizer uses to notify an application as each phoneme is produced , and word - boundary call backs , which the synthesizer uses to signal the start of production on each word .", "label": "", "metadata": {}, "score": "43.818237"}
{"text": "15 is a flow chart of a generation module of the deliberative component ; and .FIG .16 is an example plan .DESCRIPTION OF THE PREFERRED EMBODIMENTS .Each of the scripted character systems described above suffers from deficiencies that are addressed by our proposed character architecture .", "label": "", "metadata": {}, "score": "43.83627"}
{"text": "By programming the computer 1 in accordance with programming instructions , the computer 1 effectively becomes configured into a number of functional units for performing processing operations .Examples of such functional units and their interconnections are shown in .FIG .", "label": "", "metadata": {}, "score": "44.020653"}
{"text": "There are unfortunately two difficulties with this approach .Most of the early data captured for training will be from a relatively small pool of developers ; at the same time the rate of data acquisition will be slow .Figure 1 shows the distribution of data across speakers for the CMU Communicator ( through the Fall of 1999 ) .", "label": "", "metadata": {}, "score": "44.02797"}
{"text": "Other objects and advantages of the invention will be apparent based on the following drawings and detailed description .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 illustrates a block diagram of an exemplary system for implementing a voice user interface according to various aspects of the invention .", "label": "", "metadata": {}, "score": "44.053696"}
{"text": "As discussed above , plans represent a sequence of actions ( steps ) that are implemented to achieve a discourse goal .The plans represent future actions and are utilized to influence behavior of the reaction module .FIG .16 illustrates an example plan for the discourse goal of helping a user set up a conference room .", "label": "", "metadata": {}, "score": "44.061977"}
{"text": "As shown in .FIGS . 1 and 4 , the method of this invention may be implemented using one or more programmed processors .In general , any device on which the finite state machine capable of implementing the flowcharts shown in .", "label": "", "metadata": {}, "score": "44.074234"}
{"text": "Although it is possible to do this in an open - loop fashion , using timing estimates etc . , it is much more accurate and straightforward to have the action scheduler notify the Reaction Module when certain pre - defined events occur .", "label": "", "metadata": {}, "score": "44.07454"}
{"text": "The classification subsystem 410 includes a recognizer 420 , an NLU unit 430 and a task classification processor 440 .The natural language understanding monitoring system 100 includes an NLU monitor 180 , a dialog manager 190 , a training database 165 and a dialog history database 170 , as discussed above .", "label": "", "metadata": {}, "score": "44.092728"}
{"text": "The system of .claim 6 wherein the extracted features are derived from recognition , understanding and dialog data .The system of . claim 1 further comprising .The system of . claim 8 wherein the language understanding monitor is further adapted to determine whether the probability of understanding exceeds the first threshold using each of the dialog exchanges conducted .", "label": "", "metadata": {}, "score": "44.104736"}
{"text": "At step 26 , the deployed system , the speech module , and/or some other system or individual may consider a previously received utterance and independently assign an \" appropriate \" interpretation to the utterance .The appropriate interpretation may be compared against the assigned interpretation at step 28 to determine how well the speech module is operating .", "label": "", "metadata": {}, "score": "44.15922"}
{"text": "The reasoning facility 52 is primarily concerned with the determination of how to achieve the goals derived from the user 's questions and commands .In a preferred embodiment , a rule 86 stored in the rules base 84 consists of a number of conditions and a number of actions .", "label": "", "metadata": {}, "score": "44.159534"}
{"text": "In attempting to achieve the prerequisites for making this call , the reasoning facility 52 will find other rules 86 , and make other script calls .When a subgoal can not be achieved by any of the rules 86 in the rules base 84 , the reasoning facility 52 initiates a question to the user .", "label": "", "metadata": {}, "score": "44.217"}
{"text": "a server associated with the speech recognition engine and the conversational language processor , wherein the server is configured to : . deliver an advertisement in the established context associated with the natural language utterance to an electronic device in communication with the server ; . track an interaction pattern associated with the advertisement delivered to the electronic device ; and .", "label": "", "metadata": {}, "score": "44.225334"}
{"text": "Specifically , it will be appreciated that different types of speech model could be created for example continuous or discreet speech models could be created .Similarly , speaker independent or speaker dependent speech models could be created .Further , the speech models themselves could be generated using any conventional algorithms .", "label": "", "metadata": {}, "score": "44.246033"}
{"text": "Large amounts of high quality speech data from many speakers must be collected .The data must then be accurately transcribed and then used to train speech models using computationally intensive algorithms .Some of the speech data is then used to evaluate the recognition accuracy of generated models .", "label": "", "metadata": {}, "score": "44.3649"}
{"text": "FIG .3 , an exemplary cooperative conversational model 300 is illustrated according to an aspect of the invention .Cooperative conversational model 300 may build upon free form voice search 245 , noise tolerance 250 , and context determination 255 to implement a conversational Human - to - Machine interface that reflects how humans interact with each other and their normal behavior in conversation .", "label": "", "metadata": {}, "score": "44.388817"}
{"text": "Method and system for predicting understanding errors in a task classification system US 8095363 B1 .Abstract .A method and system for monitoring an automated dialog system for the automatic recognition of language understanding errors based on a user 's input communications in a task classification system .", "label": "", "metadata": {}, "score": "44.42531"}
{"text": "If the recognized user utterance is not classifiable to a predetermined rejection threshold , then the method transfers the user to a human as this may imply a task - specific utterance .The received and classified user utterance is then used for training the spoken dialog system .", "label": "", "metadata": {}, "score": "44.47991"}
{"text": "The present invention may be conveniently implemented using a conventional general purpose or a specialized digital computer or microprocessor programmed according to the teachings of the present disclosure , as will be apparent to those skilled in the computer art .Appropriate software coding can readily be prepared by skilled programmers based on the teachings of the present disclosure , as will be apparent to those skilled in the software art .", "label": "", "metadata": {}, "score": "44.494286"}
{"text": "In this iteration , the NLU monitor 180 is using only the first exchange ( exchange 1 ) .The NLU monitor 180 uses the classification model stored in the dialog training database 165 to determine whether the probability of correctly understanding the user 's input communication exceeds the predetermined threshold .", "label": "", "metadata": {}, "score": "44.537777"}
{"text": "It has been our experience that once the core of the language for a domain is identified , it remains stable as long as the definition of the domain is not significantly altered .This is due in part to the inherent stability of certain sub - languages such as that for dates and times as well as an apparent independence between sub - domains comprising the full domain .", "label": "", "metadata": {}, "score": "44.60208"}
{"text": "Method and apparatus for embodied conversational characters with multimodal input / output in an interface device US 6570555 B1 .Abstract .Deliberative and reactive processing are combined to process multi - modal inputs and direct movements and speech of a synthetic character that operates as an interface between a user and a piece of equipment .", "label": "", "metadata": {}, "score": "44.60209"}
{"text": "For example , the utterance may include one or more requests for performing an action , retrieving information , or various combinations thereof .Output 180 may include a conversational response to advance a conversation to service requests by invoking one or more applications 150 , as appropriate .", "label": "", "metadata": {}, "score": "44.61805"}
{"text": "An example of this would be a message from the understanding module to start \" listening \" gaze behavior .If the message is tagged \" immediate complex \" , it gets sent to the generation module ( see 1140 ) .", "label": "", "metadata": {}, "score": "44.66581"}
{"text": "Based on the inquiry , question - answer pairs retrieved from the network are analyzed to determine a response to the inquiry .The QA pairs are not predefined .As a result , the QA pairs have to be analyzed in order to determine whether they are responsive to a particular inquiry .", "label": "", "metadata": {}, "score": "44.679344"}
{"text": "Context determination process 255 may overcome drawbacks of existing systems by continually updating one or more models of an existing context , where establishing context may be a by - product of a conversation , which can not be established a priori .", "label": "", "metadata": {}, "score": "44.69213"}
{"text": "We are about to start the Modification Module set up .This module .will be activated when the desire of modification of previous orders . is detected in client input .Also , the Learning Module needs to be started .", "label": "", "metadata": {}, "score": "44.72292"}
{"text": "Advances in technology , particularly within the convergence space , have resulted in an increase in demand for voice recognition software that can exploit technology in ways that are intuitive to humans .While communication between human beings is most often \" cooperative , \" in that information and/or context is shared to advance mutual conversational goals , existing Human - to - Machine interfaces fail to provide the same level of intuitive interaction .", "label": "", "metadata": {}, "score": "44.73938"}
{"text": "Additional information may be call - related and may include information , such as call time , call duration , calling party number , caller language , etc . .In some cases , platform 68 may assist in interpreting an utterance as a request to speak with an agent .", "label": "", "metadata": {}, "score": "44.769432"}
{"text": "Description .BACKGROUND OF THE INVENTION .Field of the Invention .The present invention relates to a speech processing apparatus and method .In particular , embodiments of the present invention are applicable to speech recognition .Description of Related Art .", "label": "", "metadata": {}, "score": "44.77674"}
{"text": "For example , a computer - readable medium may include a set of instructions embodying the accuracy engine , the targeting engine , and the tuning engine .Moreover , one or more aspects of system 80 may be associated with an automated call router , a voice activated services platform , a call center , and/or some other operational computing system that interacts with a caller .", "label": "", "metadata": {}, "score": "44.79461"}
{"text": "If the speech can not be parsed , a speech - error message 1290 is sent to the reaction module .The Response Planner .The response planner is responsible for formulating sequences of actions , some or all of which will need to be executed during future execution cycles , to carry out desired communicative or task goals .", "label": "", "metadata": {}, "score": "44.887024"}
{"text": "The interface according to . claim 14 , wherein : . said multi - modal input comprises multiple input channels each configured to capture at least one of said user inputs , and an input manager configured to integrate the user inputs from said multiple input channels and provide said integrated user inputs to said deliberative processing component .", "label": "", "metadata": {}, "score": "44.89345"}
{"text": "For example , existing systems tend to have complex human to machine interfaces , which may inhibit mass - market adoption for various technologies .For example , when a user wishes to perform a relatively simple task on a mobile phone , such as purchasing a ring tone , the user often is forced to navigate through a series of menus and press a series of buttons .", "label": "", "metadata": {}, "score": "44.92344"}
{"text": "In response , such characters can speak , make gestures and facial expressions , and direct their gaze appropriately .These characters provide an embodied interface , apparently separate from the underlying system , that the user can simply approach and interact with naturally to gather information or perform some task .", "label": "", "metadata": {}, "score": "44.940445"}
{"text": "The signal processing routines 840 extract relevant information from the data and package it for processing by other modules ( subscribers to the input manager ) .In a case where multiple packets of data can not be validated , the device is re - initialized and the process re - started .", "label": "", "metadata": {}, "score": "44.94876"}
{"text": "Although vision - based approaches can not produce such fine - grained analyses , they provide at least as fine an analysis as that required by Ymir , while at the same time avoiding the encumbrance of body - mounted hardware .", "label": "", "metadata": {}, "score": "44.96157"}
{"text": "Automatic Speech Recognizer 110 may generate one or more preliminary interpretations of the utterance using various techniques .For example , Automatic Speech Recognizer 110 may interpret the utterance using techniques of phonetic dictation to recognize a stream of phonemes .Further , Automatic Speech Recognizer 110 may perform post - processing to enhance the preliminary interpretations .", "label": "", "metadata": {}, "score": "45.01625"}
{"text": "Second , for each feature set , the error rates of the learned classification models are estimated using ten - fold cross - validation , by training on a random 10,608 utterances and testing on a random 1,179 utterances 10 successive times .", "label": "", "metadata": {}, "score": "45.02555"}
{"text": "In contrast , the system of the invention completed the above dialog successfully .Note that after detecting the NLU error in utterance U3 , the system of the invention re - prompts the user to repeat the calling card number in utterance S4 .", "label": "", "metadata": {}, "score": "45.055923"}
{"text": "For example , one behavior may be defined for mouthing a particular phoneme and another for smiling .In the case where both behaviors are simultaneously requested , the behaviors each want to manipulate the mouth DOFs .In one embodiment , behaviors are blended together .", "label": "", "metadata": {}, "score": "45.068413"}
{"text": "9 .A constraint on this module 's implementation is runtime efficiency .While the update frequency need not be as great as the animation update rate ( approx .Since most real - time autonomous system architectures tend to be reaction - based , a flexible forward - chaining rule - based language as a basis upon which various control schemes are built is an option .", "label": "", "metadata": {}, "score": "45.089005"}
{"text": "As a result , Adaptive Response Builder 315 may generate intelligent responses that create conversational feel , adapt to information that accumulates over a duration of a conversation , maintain cross - modal awareness , and keep the conversation on course .", "label": "", "metadata": {}, "score": "45.137405"}
{"text": "The non - transitory computer readable medium of . claim 13 , wherein the user speaks the utterance in a multi - modal input that further includes one or more non - voice inputs relating to the utterance .The non - transitory computer readable medium of . claim 13 , wherein the conversational speech engine generates the response in a multi - modal output that includes one or more non - voice outputs that relate to the utterance or one or more tasks executed to process a request identified from the intended meaning .", "label": "", "metadata": {}, "score": "45.159943"}
{"text": "claim 25 , wherein the one or more processors are further configured to generate the grammatically or syntactically adapted response to influence a subsequent reply utterance expected from the user during the current conversation .The system of .claim 25 , further comprising a speech recognition engine configured to : . generate multiple preliminary interpretations of the utterance , wherein an initial interpretation of the utterance comprises one of the multiple preliminary interpretations having a highest confidence level ; and .", "label": "", "metadata": {}, "score": "45.19814"}
{"text": "The independent accuracy value may effectively indicate how well a speech module is \" recognizing \" a given utterance type .The accuracy value may be based on a single criteria or a combination of criteria such as recognition rates , hits , misses , etc . , for a specific utterance type .", "label": "", "metadata": {}, "score": "45.209305"}
{"text": "In one embodiment , action requests made to the generation module are \" ballistic \" in the sense that they can not be canceled by the reaction module once issued .The generation module has two sub - modules , illustrated in FIG .", "label": "", "metadata": {}, "score": "45.222466"}
{"text": "Unnecessary information in client utterance : Usually , . not all words in a sentence are necessary to obtain its semantic . interpretation , which can be achieved from meaning words only .( keywords ) .To obtain such interpretation , the system uses . keywords and a keyword - lattice analysis .", "label": "", "metadata": {}, "score": "45.287907"}
{"text": "That is , cooperative conversational model 300 incorporates technology and process - flow that takes advantage of human presumptions about utterances that humans rely upon , both as speakers and listeners , thereby creating a Human - to - Machine interface that is analogous to everyday human - to - human conversation .", "label": "", "metadata": {}, "score": "45.296432"}
{"text": "In practice , a recording of the utterance and an assigned utterance type for the call may be communicated via interface 90 to repository 92 .The recording , assigned utterance type , and other call related information may be stored in a table 94 or other structured and searchable information store .", "label": "", "metadata": {}, "score": "45.30168"}
{"text": "For example , giving the avatars some autonomy to make decisions about where to look based on user defined parameters for conversational engagement .Another use of directly controlled characters is for automatically generating animations based on the movements of human actors .", "label": "", "metadata": {}, "score": "45.375854"}
{"text": "Due to planning algorithm complexity and the lack of hard real - time constraints , this module is preferably implemented in a symbolic language such as LISP .In one embodiment , the response planner and the reaction module are implemented in the same software .", "label": "", "metadata": {}, "score": "45.39249"}
{"text": "Table 6 provides an action scheduler command protocol according to the present invention .The command protocol is defined in a manner designed to meet the above - stated requirements .As indicated in Table 6 , a behavior can optionally be labeled with a WORD ( ) .", "label": "", "metadata": {}, "score": "45.399193"}
{"text": "The reactive behaviors are the product not only of the immediately preceding actions , but also of dialogue plans ( produced in by the deliberative language components ) which may require several loop iterations to be executed .For example , the character 's gaze behavior , which is a prominent indicator of turn - taking in dialogue , might be affected by its knowledge that several plan steps must be executed to achieve a particular discourse goal .", "label": "", "metadata": {}, "score": "45.44415"}
{"text": "accessing , from a database , information representing a plurality of utterances for at least one speech - enabled application , the plurality of utterances comprising at least a first type of utterance and a second type of utterance ; . accessing , from the database , interpretive information representing an assigned interpretation for at least a portion of the plurality of utterances ; . determining , by a training tool subsystem , an appropriate interpretation for the portion of the plurality of utterances ; . comparing , by the training tool subsystem , the assigned interpretation for the portion of the plurality of utterances to the appropriate interpretation for the portion of the plurality of utterances ; . determining , by the training tool subsystem , a frequency value for the second type of utterance that represents the percentage of occurrence of the second type of utterance in the plurality of utterances ; . determining , by the training tool subsystem , that the speech - enabled application more accurately responds to the first type of utterance ; and . electing , by the training tool subsystem , to apply a targeted tuning to the speech - enabled application to improve recognition of the second type of utterance when the frequency value for the second type of utterance is greater than a frequency threshold value .", "label": "", "metadata": {}, "score": "45.496223"}
{"text": "One embodiment of the understanding module is illustrated in the flow chart of FIG .12 .This chart shows a simple implementation of an understanding module .It continuously receives inputs 1200 from the input manager , and depending on the input , engages either interactional 1210 and/or propositional 1220 rule sets .", "label": "", "metadata": {}, "score": "45.57692"}
{"text": "FIG .1 , an exemplary system architecture for implementing a cooperative conversational voice user interface is illustrated according to one aspect of the invention .The system may receive an input 105 from a user , where in one implementation , input 105 may be an utterance received by an input device ( e.g. , a microphone ) , where the utterance may include one or more requests .", "label": "", "metadata": {}, "score": "45.58322"}
{"text": "As described earlier , propositions are attribute - object - value triples , the same representation used for representing the semantic content of an utterance .If the reasoning facility 52 determines that the conditions of the rule 86 are satisfied , then the reasoning facility 52 can invoke the rule 86 , and the actions specified by the rule 86 are executed .", "label": "", "metadata": {}, "score": "45.70644"}
{"text": "Action scheduler sends out the primitive commands to the animation renderer and the string to the speech synthesizer .Upon completion it notifies the generation module .Generation module notifies the reaction module of successful completion and updates the discourse model .", "label": "", "metadata": {}, "score": "45.72412"}
{"text": "Two simple solutions are to have behaviors return their DOFs to a canonical resting position before they release control or simply interpolate the position of each DOF from its location at the start of a behavior to the first landmark or keyframe position specified for the behavior .", "label": "", "metadata": {}, "score": "45.74666"}
{"text": "The acoustic models of the known words are determined during a training session in which one or more samples of the known words are used to generate reference patterns therefor .The reference patterns may be acoustic templates of the modelled speech or statistical models , such as Hidden Markov Models .", "label": "", "metadata": {}, "score": "45.759995"}
{"text": "Knowledge bases are maintained for both dynamic ( discourse model , for example ) and static ( e.g. , knowledge about the domain or discourse plans ) information types .A rule based system is utilized against the knowledge bases and selected inputs from said user to determine input meanings , and follow a predetermined discourse plan .", "label": "", "metadata": {}, "score": "45.839653"}
{"text": "The system of .The system of .claim 25 , wherein the one or more processors are further configured to : . identify a conversational goal associated with the utterance , roles associated with the user and one or more other participants in the current conversation , and an information allocation among the user and the one or more other participants in the current conversation ; and .", "label": "", "metadata": {}, "score": "45.9073"}
{"text": "According to another aspect of the invention , the intelligent responses may include multi - modal , or cross - modal , responses to a user .In one implementation , responses may be aware of and control one or more devices and/or interfaces , and users may respond by using whichever input method , or combination of input methods , is most convenient .", "label": "", "metadata": {}, "score": "45.935028"}
{"text": "The predicted queries are used to train a language model , such as a query language model .The query language model may be interpolated other language models , such as a background language model , as well as a feed language model trained using the content used in determining the predicted queries .", "label": "", "metadata": {}, "score": "45.93792"}
{"text": "System and Method of Semi - Supervised Learning for Spoken Language Understanding Using Semantic Role Labeling - A system and method are disclosed for providing semi - supervised learning for a spoken language understanding module using semantic role labeling .The method embodiment relates to a method of generating a spoken language understanding module .", "label": "", "metadata": {}, "score": "45.97811"}
{"text": "For example , a response asking the user to direct an utterance with a \" Yes \" or \" No \" in a multi - modal environment may also display alternatives visually .According to another aspect of the invention , Adaptive Response Builder 315 may correct a course of a conversation without interrupting conversational flow .", "label": "", "metadata": {}, "score": "46.00944"}
{"text": "Further , firmware , software , routines , or instructions may be described in the above disclosure in terms of specific exemplary aspects and implementations of the invention , and performing certain actions .However , it will be apparent that such descriptions are merely for convenience and that such actions in fact result from computing devices , processors , controllers , or other devices executing the firmware , software , routines , or instructions .", "label": "", "metadata": {}, "score": "46.02134"}
{"text": "For exemplary purposes , the classification model is learned using greedy search guided by an information gain metric , and is expressed as an ordered set of if - then rules .In application , the utterances in the corpus must be encoded in terms of a set of classes ( the output classification ) and a set of input features that are used as predictors for the classes .", "label": "", "metadata": {}, "score": "46.05818"}
{"text": "Not only does this potentially leave user requests unresolved , in certain instances , providers of goods and services may lose out on potential business .In an increasingly global marketplace , where marketers are continually looking for new and effective ways to reach consumers , the problems with existing voice user interfaces leaves a large segment of consumer demand unfulfilled .", "label": "", "metadata": {}, "score": "46.09761"}
{"text": "The present invention provides synchronization between speech and gesture .Commands sent to the action scheduler are qualified with an event expression which describes when they are to be executed , rather than explicitly specifying the start time for each ( although , this command style is also supported ) .", "label": "", "metadata": {}, "score": "46.18432"}
{"text": "Other objects and advantages of the invention will be apparent to those skilled in the art based on the following drawings and detailed description .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is an exemplary block diagram of a system architecture according to one aspect of the invention .", "label": "", "metadata": {}, "score": "46.207817"}
{"text": "2 ) selected by the conversation manager 28 .FIG .3 ) .The computer program product 80 may be installed by any suitable software installation procedure , as is well known in the art .In another embodiment , the software instructions may also be downloaded over an appropriate connection .", "label": "", "metadata": {}, "score": "46.213585"}
{"text": "Both the action scheduler and the generation module provide feedback regarding the completion of requested actions .In one embodiment , the reaction module is solely responsible for updating the dynamic knowledge base .The action selection approach taken in the Reaction Module includes caching of plans generated by the response planner with future actions .", "label": "", "metadata": {}, "score": "46.214485"}
{"text": "establishing the intended meaning within the identified context based on the additional information inferred about the utterance ; and .generating a response to the utterance based on the intended meaning established within the identified context .The method of .claim 37 , wherein the established intended meaning comprises an implicit hypothesis having a corresponding degree of certainty about an intent that the user had in speaking the utterance .", "label": "", "metadata": {}, "score": "46.268776"}
{"text": "Interface with Action Scheduler .The generation module can query the action scheduler to obtain a list of all pending actions , along with the priority and deadline for each , thus enabling it to select from primitive action alternatives while taking the current physical actions of the character into account .", "label": "", "metadata": {}, "score": "46.28212"}
{"text": "This implicit model guides the design of the user interface and the functionality of the program .The problem with an implicit model is that it is all in the mind of the designers and developers , and so is often not thoroughly or consistently implemented in the product .", "label": "", "metadata": {}, "score": "46.2957"}
{"text": "In a preferred embodiment , each supported application 26 has its own domain model 70 included in its associated \" application module description \" file ( with extension \" apm \" ) .The speech center 20 has a rudimentary built - in notion of what an \" action \" is .", "label": "", "metadata": {}, "score": "46.29666"}
{"text": "Module , Memory Module , Restaurant - product Knowledge Base , Lexicon , .and Output Interface .At the moment the system takes about 30.000 C++ code lines .Its . inputs and outputs are natural language text sentences .Its Input interface is well developed but still needs to define some . syntactic and semantic rules , since now only product orders and .", "label": "", "metadata": {}, "score": "46.303356"}
{"text": "If there is a deadlock between context domain agents , an adaptive conversational response may prompt the user to assist in disambiguating between the deadlocked agents .For example , a user utterance of \" What about traffic ? \" may have a distinct meaning in various contexts .", "label": "", "metadata": {}, "score": "46.315586"}
{"text": "In addition to the novelty directly related to architectural decisions , several novel features of the present invention have yet to be realized in related systems .These features , which are described below , concern the character 's representation and awareness of the physical environment , and consequently , the encumbrance placed on the user .", "label": "", "metadata": {}, "score": "46.39759"}
{"text": "Thus in this way a user can obtain a qualitative measure of how well the speech model within the model database 26 performs using with live utterances .The testing module 27 then processes each of the items of utterance data 49 from the utterance records 45 to determine how the speech model matches the use utterances and displays the results of processing the utterances to a user .", "label": "", "metadata": {}, "score": "46.44284"}
{"text": "If this is determined to be the case the control module 20 then ( S 7 - 13 ) determines whether a double click operation has been performed .That is to say the control module 20 determines whether the same item of word data or speaker data has been selected twice within a short time period .", "label": "", "metadata": {}, "score": "46.63098"}
{"text": "A reactive architecture gives a character the ability to react immediately to verbal and non - verbal cues without performing any deep linguistic analysis .Such cues allow the character to convincingly signal turn - taking and other regulatory behaviors non - verbally .", "label": "", "metadata": {}, "score": "46.649704"}
{"text": "In the approach of the present invention , the speech center system 20 has an explicit model of the world ( e.g. , domain model 70 ) which will serve as a foundation for language understanding and reasoning .Some of the basic concepts that the speech center system 20 models using the domain model 70 are : .", "label": "", "metadata": {}, "score": "46.702847"}
{"text": "The system of .claim 41 , wherein the established intended meaning comprises an implicit hypothesis having a corresponding degree of certainty about an intent that the user had in speaking the utterance .Description .FIELD OF THE INVENTION .The invention relates to a cooperative conversational model for a human to machine voice user interface .", "label": "", "metadata": {}, "score": "46.749256"}
{"text": "Conversational language processor 120 may use various other techniques as will be apparent , such as those described in U.S. patent application Ser .No .11/200,164 , entitled \" System and Method of Supporting Adaptive Misrecognition in Conversational Speech , \" filed Aug. 10 , 2005 , which issued as U.S. Pat .", "label": "", "metadata": {}, "score": "46.788227"}
{"text": "The reasoning facility 52 makes use of the ontology 64 object , for resolving questions of object classification .The ontology object 64 is also used outside of the reasoning system 52 by the syntax manager 62 and semantics module 50 .", "label": "", "metadata": {}, "score": "46.875217"}
{"text": "1 illustrates an exemplary natural language understanding monitoring system 100 .The natural language understanding monitoring system 100 includes a natural language understanding ( NLU ) monitor 180 , a dialog manager 190 , a training database 165 and a dialog history database 170 .", "label": "", "metadata": {}, "score": "46.889046"}
{"text": "FIG .7 is a block diagram of the architecture of FIG .6 with additional flows that utilize a knowledge base , discourse model , and plans ; .FIG .8 is a flow diagram of operations of an input manager as illustrated in FIG .", "label": "", "metadata": {}, "score": "46.913464"}
{"text": "Each hypothesis may have a corresponding degree of certainty , which may be used to determine a level of unprompted support to provide in a response .For example , a response may include a confirmation to ensure the utterance was not misunderstood or the response may adaptively prompt a user to provide missing information .", "label": "", "metadata": {}, "score": "46.915314"}
{"text": "An apparatus for converting an utterance representation into a response , comprising : . a database storing a set of goal - directed rules ; . a digital processor coupled to the database , the digital processor hosting and executing a reasoning facility that is configured to : . generate an application specific goal derived from the utterance representation , wherein the application specific goal and the utterance representation are propositions comprising attribute - object - value triples , the proposition corresponding to the utterance representation being derived from a frame representation ; . generate a response based on the analysis of the utterance representation if ambiguous information is identified .", "label": "", "metadata": {}, "score": "46.95207"}
{"text": "2 , 3 , 5 and 6 can be used to implement the task classification system and natural language understanding monitoring functions of this invention .While the invention has been described with reference to the above embodiments , it is to be understood that these embodiments are purely exemplary in nature .", "label": "", "metadata": {}, "score": "47.01764"}
{"text": "claim 1 , further comprising storing information representing the plurality of utterances as discrete audio files .The method of .claim 1 , wherein the at least one speech - enabled application comprises an application deployed in an operational environment .", "label": "", "metadata": {}, "score": "47.028915"}
{"text": "Otherwise , the user may be directed to a human for assistance .In another possible embodiment , the method operates as above except that if the probability exceeds a second threshold , then further dialog may be conducted with the user using the current dialog strategy .", "label": "", "metadata": {}, "score": "47.030304"}
{"text": "After any unsatisfactory utterances have been deleted the capture and recordal of further utterances can be resumed whenever the data collection module 22 determines that the record button 410 has been selected ( S 7 - 20 ) .After utterance records 45 have been generated for all of the required utterances in the list of required utterances ( S 7 - 23 ) , the data collection module 22 causes the control module 20 to redisplay the main control screen ( S 7 - 1 ) .", "label": "", "metadata": {}, "score": "47.04131"}
{"text": "Using general topic segmentation methods , as well as the specific domain detector trained with conversational inputs collected by a single user system , allows the dialog system to better determine the relevant context .The use of conversational context helps reduce the domain detection error rate , especially in certain domains , and allows for better interactions with users when the machine addressed turns are not recognized or are ambiguous .", "label": "", "metadata": {}, "score": "47.045544"}
{"text": "The transform result is either stored in a product structure ( for this domain , an itinerary ) or an immediate action taken ( for example , notifying the user of an error ) .ACOUSTIC MODELLING .It is our belief that optimal recognition performance can be obtained most readily using domain - specific data .", "label": "", "metadata": {}, "score": "47.050392"}
{"text": "The multitask learning method aims at training tasks in parallel while using a shared representation .A computing device automatically re - uses the existing labeled data from various applications , which are similar but may have different call - types , intents or intent distributions to improve the performance .", "label": "", "metadata": {}, "score": "47.069077"}
{"text": "Abstract .A cooperative conversational voice user interface is provided .The cooperative conversational voice user interface may build upon short - term and long - term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance .", "label": "", "metadata": {}, "score": "47.11478"}
{"text": "The generation module then sends the action scheduler low - level action requests for directly controlling the character animation or external devices , along with a priority and option time deadline for each .The action scheduler notifies the generation module when a requested action has either been completed or removed from consideration ( e.g. , due to timeout or conflict with a higher priority action , for example ) .", "label": "", "metadata": {}, "score": "47.11669"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .An exemplary embodiment of the invention will now be described with reference to the accompanying drawings in which : .FIG .1 is a schematic view of a computer which may be programmed to operate an embodiment of the present invention ; .", "label": "", "metadata": {}, "score": "47.131172"}
{"text": "When a list of all required utterances has been generated the selected flags 39 ; 44 for all of the word records 35 and speaker records are then reset to unselected .Once a required list of utterances has been determined by the data collection module 22 a record utterance screen is shown on the display of the computer 1 .", "label": "", "metadata": {}, "score": "47.13846"}
{"text": "For example , course correction may result in the following exchange : .The above disclosure has been described in terms of specific exemplary aspects , implementations , and embodiments of the invention .However , those skilled in the art will recognize various changes and modifications that may be made without departing from the scope and spirit of the invention .", "label": "", "metadata": {}, "score": "47.301598"}
{"text": "Integration of Propositional and Interactional Non - verbal Behaviors .As noted in the introduction section , the importance of non - verbal behaviors is twofold : to convey propositional content , and to regulate the flow of information in the interaction .", "label": "", "metadata": {}, "score": "47.36487"}
{"text": "claim 1 , further comprising tuning the speech - enabled application to improve recognition of the second type of utterance by feeding a collection of the second type of utterances into a learning module of the speech - enabled application .The method of . claim 2 , wherein the tuning step comprises avoiding a feeding of the first type of utterances into the learning module .", "label": "", "metadata": {}, "score": "47.36502"}
{"text": "Categorizing and developing conceptual models for various types of exchanges may consistently align user expectations and domain capabilities .One or more intelligent hypotheses may be generated as to a conversation type by considering conversational goals , participant roles , and/or an allocation of information among the participants .", "label": "", "metadata": {}, "score": "47.39418"}
{"text": "On other inputs ( e.g. no speech input ) , the turn - taking rules will send a message to the reaction module to initiate \" idle \" gaze behavior 1260 ( random glances ) .When the understanding module receives inputs containing propositional data , such as a speech stream , it invokes a parser to determine the syntactic structure and semantic content of the message .", "label": "", "metadata": {}, "score": "47.413364"}
{"text": "Interfaces built around the metaphor of face - to - face interaction allow human users to rely on their well established and thoroughly rehearsed social skills , rather than forcing them to learn new \" tools . \" Much research has already been performed in the field of natural language processing ( NLP ) .", "label": "", "metadata": {}, "score": "47.434998"}
{"text": "The method of .claim 1 , further comprising improving recognition of the second type of utterance without degrading recognition of the first type of utterance .The method of .claim 1 , wherein the speech - enabled application executes at an automated call router .", "label": "", "metadata": {}, "score": "47.49366"}
{"text": "The experiments reported here primarily utilize a rule learning program to automatically induce an NLU error classification model from the 11,787 utterances in the corpus .While other learning methods may be used within the spirit and scope of the invention , the experiments and examples discussed below utilized if - then rules that are used to express the learned classification model .", "label": "", "metadata": {}, "score": "47.495422"}
{"text": "Each hypothesis may have a corresponding degree of certainty .For instance , when a conversation begins , short - term knowledge stored in the Session Input Accumulator may be empty , and as the conversation progresses , the Session Input Accumulator may build a history of the conversation .", "label": "", "metadata": {}, "score": "47.54441"}
{"text": "Typically , in view of the expertise required for generating models , generating speech models takes place within an acoustic speech recognition research lab .It is , however , desirable that users lacking in speech recognition expertise could also develop their own speech models for their own applications .", "label": "", "metadata": {}, "score": "47.55425"}
{"text": "A method for selecting and presenting advertisements in response to processing natural language utterances , comprising : . recognizing , at a speech recognition engine that executes on a server , one or more words or phrases in a natural language utterance ; . interpreting the one or more recognized words or phrases at a conversational language processor that executes on the server to establish a context associated with the natural language utterance ; . delivering an advertisement in the established context associated with the natural language utterance from the server to an electronic device in communication with the server ; . tracking , at the server , an interaction pattern associated with the advertisement delivered to the electronic device ; . interpreting a subsequent natural language utterance at the conversational language processor using long - term shared knowledge and short - term shared knowledge derived from the updated information associated with the one or more updated models .", "label": "", "metadata": {}, "score": "47.557735"}
{"text": "For example , context - based interpretations and responses to a voice - based input may be generated using techniques described in U.S. patent application Ser .No . 11/197,504 , entitled \" Systems and Methods for Responding to Natural Language Speech Utterance , \" filed Aug. 5 , 2005 , which issued as U.S. Pat .", "label": "", "metadata": {}, "score": "47.574596"}
{"text": "The results of this testing are displayed to a user as part of the user interface are where the user assesses ( S 3 - 5 ) whether the performance of the speech model stored within the model database 26 is satisfactory .", "label": "", "metadata": {}, "score": "47.64393"}
{"text": "Otherwise , the user may be directed to a human for assistance .In another possible embodiment , the method operates as above except that if the probability exceeds a second threshold , the second threshold being higher than the first , then further dialog is conducted with the user using the current dialog strategy .", "label": "", "metadata": {}, "score": "47.64393"}
{"text": "The interface according to . claim 21 , wherein said response generation module initiates parallel operations of at least one of said responses by said synthetic character .The interface according to .claim 24 , wherein the initiated parallel operations include at least one of speech output by said synthetic character , an action performed by said synthetic character , and task to be performed on said computational system .", "label": "", "metadata": {}, "score": "47.66297"}
{"text": "This has serious consequences for the believability of the character .The present invention addresses this problem by adopting a simple template - based generation scheme that allows flexibility in referring expressions ( the way one refers to objects in the world ) .", "label": "", "metadata": {}, "score": "47.714226"}
{"text": "It is yet another object of the present invention to provide a walk - up interface operable by a user with only basic language and interaction skills .It is yet another object of the present invention to provide a conversational character that interacts within a virtual space of the character and a physical space of the user .", "label": "", "metadata": {}, "score": "47.7265"}
{"text": "Specifically , the testing module 27 displays a menu from which a user can select the type of testing which is to take place .A typical menu might include the following options : .LIVE TESTING .INDEPENDENT IN VOCABULARY .", "label": "", "metadata": {}, "score": "47.832985"}
{"text": "Moreover , the effectiveness of the targeted tuning approach may prove easier to quantify and/or predict - allowing a system administrator to produce recognizable improvements in the deployed system 's overall recognition rate by focusing on specific areas of concern .As mentioned above , .", "label": "", "metadata": {}, "score": "47.886307"}
{"text": "In another embodiment , one or more of the external applications 26 may be hosted and executed by a different digital processor 12 than the digital processor 12 that hosts the speech center 20 .Generally , the speech center 20 ( and its individual components ) may be implemented as hardware or software .", "label": "", "metadata": {}, "score": "47.977654"}
{"text": "Output devices for the present invention include , but are not limited to , the following : .Animation rendering : from ToonFace - style 2D animations in web page to high - end 3D characters in rich simulated environments .For 3D , the best cross - platform choice is something based on openGL .", "label": "", "metadata": {}, "score": "48.101555"}
{"text": "The present invention provides an architecture for building animated , ally character interfaces with task - based , face - to - face conversational abilities ( i.e. , the ability to perceive and produce paraverbal behaviors to exchange both semantic and interactional .", "label": "", "metadata": {}, "score": "48.155037"}
{"text": "In practice , platform 68 may perform speech recognition functions .Platform 68 may receive a verbal communication via network 48 and process the communication in an effort to properly interpret the communication .The communication itself , as well as an assigned interpretation may be captured and saved in repository 72 .", "label": "", "metadata": {}, "score": "48.180595"}
{"text": "By selecting the ADD SPEAKER , ADD WORD and AMEND SET UP options on the project menu a user is therefore able to set initial paramters for collecting utterance data for generating word models .Specifically , by repeatedly selecting the ADD SPEAKER option a set of speaker records 40 identifying speakers from whom utterance data is to be collected are generated and stored within the speaker database .", "label": "", "metadata": {}, "score": "48.23185"}
{"text": "The interface according to .claim 16 , wherein each of said multi - modal input , said deliberative processing , and said reactive processing operate in parallel .The interface according to . claim 17 , wherein said reactive processing provides reactive output to said output mechanism immediately upon receiving a predetermined input from said input device .", "label": "", "metadata": {}, "score": "48.296974"}
{"text": "For example , facial expression commands such as \" smile \" are preferable to FACS ( Facial Action Coding System ) .In one embodiment , the action scheduler receives \" hints \" which serve to bias its choice among realization options .", "label": "", "metadata": {}, "score": "48.308563"}
{"text": "Keyboard : alternative to speech input .Mouse : dragging the character around , dragging objects in the character 's environment around , selecting menu options .Motion detection : if we just want to determine whether something is moving in front of the computer .", "label": "", "metadata": {}, "score": "48.339653"}
{"text": "For example , steps 2 and 3 of a three step plan influence how step 1 would be implemented .Having introduced the components of the architecture , we now describe the individual modules .The Input Manager .The input manager 520 is primarily responsible for obtaining data from input devices , converting it into a form acceptable by the rest of the system ( via algorithmic signal processing routines ) , and routing the results to the understanding module 610 and/or reactive component 500 .", "label": "", "metadata": {}, "score": "48.40085"}
{"text": "Due to the computational complexity of real - time interactions in graphical virtual environments , avatar representations tend to be graphically simplistic and insufficient for representing spontaneous gestures , facial expressions , and other non - verbal behaviors .Moreover , because the input modalities are severely restricted in online virtual worlds , generally confined to the mouse and keyboard , avatar users are forced to exercise fine - grained , conscious control over each gestural movement .", "label": "", "metadata": {}, "score": "48.469162"}
{"text": "The assigned interpretation for each of the plurality of recorded utterances may then be compared to an accurate interpretation for each of the plurality of utterance , and a separate accuracy value may be determined for each of the plurality of utterance types .", "label": "", "metadata": {}, "score": "48.5297"}
{"text": "In addition , the teachings of the present invention apply to any type of animated interface or presentation device ( virtual classroom instructor , or tutor , for example ) or other animated devices or icons .This detailed description includes example portions of code .", "label": "", "metadata": {}, "score": "48.636475"}
{"text": "Figure 2 shows corpus growth over time .In August the Communicator was publicized on the Web and made available for public use , increasing variability .All models are 5-state semi - continuous HMMs , though the number of states differs as noted below .", "label": "", "metadata": {}, "score": "48.645813"}
{"text": "Although in the above embodiment speakers are identified only by name and gender , additional information such as age , region etc . could be added to the speaker entry screen so that speakers could be further sub - divided into separate groups for generating speech models .", "label": "", "metadata": {}, "score": "48.691757"}
{"text": "The name of the grammar ( rg - grammar ) could also be a predictor of NLU errors since it is well known that the larger the grammar , the more likely a recognizer 120 error is to occur .One motivation for the tempo feature is that it has been found that users tend to slow down their communication ( speech , movement , etc . ) when the system 100 has misunderstood them .", "label": "", "metadata": {}, "score": "48.708355"}
{"text": "Conversation emerges from the analysis of the reasoning facility 52 , rather than being pre - programmed in .FIG .5 is a flowchart of the process of analyzing an utterance representation 21 according to the present invention .In step 100 , the user generates a goal from an utterance representation 21 based on a spoken utterance 14 received from a user .", "label": "", "metadata": {}, "score": "48.717567"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .The invention is described in detail with reference to the following drawings wherein like numerals reference like elements , and wherein : .FIG .1 is a block diagram of an exemplary NLU monitoring system ; .", "label": "", "metadata": {}, "score": "48.78433"}
{"text": "Log data associated with a search engine , each associated with a search query , may be received .A domain label for each search query may be identified and the domain label and link data may be provided to a training set for a spoken language understanding model .", "label": "", "metadata": {}, "score": "48.78854"}
{"text": "However , some types of information may be obtained more efficiently , e.g. , the current light settings , on a polled / as - needed basis , rather than sending asynchronous updates through the system and updating the dynamic memory every time it changes state .", "label": "", "metadata": {}, "score": "48.788986"}
{"text": "FIG .2 , a control module 20 processes inputs from the keyboard 3 and the mouse 5 , and also performs overall control and processing for the other functional units .The control module 20 also outputs display instructions that result in the generation of user interface screens on the display screen of the computer 1 as will be described in detail later .", "label": "", "metadata": {}, "score": "48.839962"}
{"text": "Obviously , numerous modifications and variations of the present invention are possible in light of the above teachings .It is therefore to be understood that within the scope of the appended claims , the invention may be practiced otherwise than as specifically described herein .", "label": "", "metadata": {}, "score": "48.967224"}
{"text": "We are developing a gesture classification system to detect the ' beat ' gestures that often indicate emphasis .On the output side , we plan to allow The character to generate emphasis using either modality .These conversational functions are realized as conversational behaviors .", "label": "", "metadata": {}, "score": "48.973167"}
{"text": "Questions of the QA pairs may be repetitive and , without more , will not be useful in determining whether their corresponding answer responds to an inquiry .Preserving Privacy in Natural Language Databases - An apparatus and a method for preserving privacy in natural language databases are provided .", "label": "", "metadata": {}, "score": "49.050922"}
{"text": "Interface with Action Scheduler .The reaction module can send the action scheduler primitive action requests for directly controlling the character animation or external devices , along with a priority and optional time deadline for each .The action scheduler will notify the reaction module when a requested action has either been completed or removed from consideration ( e.g. , due to timeout or conflict with a higher priority action ) .", "label": "", "metadata": {}, "score": "49.059418"}
{"text": "Finally , at the end of her speaking turn she turns to face the user to indicate the end of her turn .She also tracks the user 's gaze direction to pick up an end of turn gaze cue .Other functions have both interactional and propositional content .", "label": "", "metadata": {}, "score": "49.085228"}
{"text": "2 above , and as such , will not be discussed further .FIG .4 illustrates one possible application of the natural language understanding monitoring system 100 .In particular , .FIG .4 shows an exemplary automated task classification system 400 that conducts automated dialog with a user .", "label": "", "metadata": {}, "score": "49.091827"}
{"text": "At step 36 , improving recognition of one type of utterance may occur without degrading recognition of other types of utterances .This objective may be facilitated , for example , by attempting to avoid the feeding of non - targeted utterance types into the learning module .", "label": "", "metadata": {}, "score": "49.128967"}
{"text": "The units and their interconnections illustrated in .FIG .2 are , however , notional and are shown for illustration purposes only to assist understanding .They do not necessarily represent he exact units and connections into which the processor , memory , hard disk etc of the computer 1 becomes configured .", "label": "", "metadata": {}, "score": "49.13253"}
{"text": "Furthermore , the invention may apply to any automated recognition and understanding system that receives communications from external sources , such as users , customers , service providers , associates , etc .Consequently , the method may operate in conjunction with one or more communication networks , including a telephone network , the Internet , an intranet , Cable TV network , a local area network ( LAN ) , a wireless communication network , etc . .", "label": "", "metadata": {}, "score": "49.16411"}
{"text": "12 is a flow diagram of an understanding module of the deliberative component ; .FIG .13 is a block diagram of the generation module ; .FIG .14 is a block diagram of inputs , outputs , and pending actions of the action scheduler ; .", "label": "", "metadata": {}, "score": "49.174053"}
{"text": "In practice , the accuracy value may include or represent one or more of these and/or other values .The methodology may also include determining a frequency value for the given utterance type .An administrator may want to know , for example , how \" important \" an utterance type is .", "label": "", "metadata": {}, "score": "49.19412"}
{"text": "The character generates speech , gesture and facial expressions based on the current conversational state and the conversational function she is trying to convey .For example , when the user first approaches The character ( \" User Present \" state ) , she signals her openness to engage in conversation by looking at the user , smiling , and/or tossing her head .", "label": "", "metadata": {}, "score": "49.217743"}
{"text": "If the message is tagged \" future \" , it gets sent to the response planner for elaboration ( see 1130 ) .An example of this would be a message from the understanding module to plan a subdialogue ( e.g. plan a sequence of actions / utterances to set up a conference call ) .", "label": "", "metadata": {}, "score": "49.22239"}
{"text": "The present invention is unique in integrating language understanding and generation with multimodal inputs and outputs representing non - verbal communicative behaviors in real time .This invention has applications for controlling a wide variety of systems and devices , including copiers , conference facilities , audio - video ( AV ) equipment , and personal computer ( PC ) application software .", "label": "", "metadata": {}, "score": "49.222458"}
{"text": "2 ; .FIG .6 is a schematic representation of an exemplary data structure for speaker records for storing data within the speaker database of the computer of .FIG .2 ; .FIGS .7A-7D comprise a flow diagram of the detailed processing of the computer of .", "label": "", "metadata": {}, "score": "49.223286"}
{"text": "The interactive user interface according to . claim 1 , further comprising multiple input channels , each of said channels configured to transfer at least one of said user inputs to the interface .The interactive user interface according to . claim 2 , wherein said multiple input channels are configured to capture at least one of speech , body position , gaze direction , gesture recognition , keyboard inputs , mouse inputs , user ID , and motion detection of said user .", "label": "", "metadata": {}, "score": "49.24191"}
{"text": "The use of a semantic role labeling approach to the extraction of the answers to an open domain factoid ( Who / When / What / Where ) natural language question that contains a predicate is described .Semantic role labeling identities predicates and semantic argument phrases in the natural language question and the candidate sentences .", "label": "", "metadata": {}, "score": "49.254013"}
{"text": "Thus in this way the accuracy of the word models within the model database 26 can be assessed against pre - recorded utterances .In the case of the independent out of vocabulary data , the testing module 27 selects the utterance data 49 of utterance records 45 for word numbers 47 for which no word model has been generated and stored within the model database 26 .", "label": "", "metadata": {}, "score": "49.266712"}
{"text": "Characters that are not directly controlled by the user can be subdivided into two groups : those whose behaviors are scripted in advance , and those whose behaviors are essentially autonomous , and derived at runtime based on inputs from the user .", "label": "", "metadata": {}, "score": "49.349716"}
{"text": "We can compensate for lack of data and for overfitting by smoothing the state distributions of the models with uniform distributions .This produces a slight improvement in error rate for both test sets ( Model 1b ) .Model 2 : We investigated state tying using a rule - based tying procedure prior to building decision trees .", "label": "", "metadata": {}, "score": "49.438095"}
{"text": "A computing device automatically re - uses the existing labeled data from various applications , which are similar but may have different call - types , intents or intent distributions to improve the performance .An automated intent mapping algorithm operates across applications .", "label": "", "metadata": {}, "score": "49.482773"}
{"text": "Utterances were classified into 29 categories , corresponding to major speech acts ; within each utterance concepts were tagged as belonging to one of 24 classes .For each utterance category , a 5-gram language model was built then used for generation ( the NLG component was provided with a speech act and a set of concepts to transmit to the user ) .", "label": "", "metadata": {}, "score": "49.572186"}
{"text": "The task classification processor 440 determines which task the user is requesting on the basis of the NLU unit 's 430 understanding of recognized language segments , stored in the labeled training communications database 450 , and recognized by the recognizer 420 .", "label": "", "metadata": {}, "score": "49.58471"}
{"text": "The method according to . claim 9 , wherein said step of fusing includes the steps of applying a set of rules that define how said inputs affect each other .The method according to . claim 9 , wherein said step of fusing includes the steps of : . identifying a user gesture captured by said inputs ; and , . determining a meaning of a user speech captured at least one of contemporaneously and in close time proximity of said user gesture .", "label": "", "metadata": {}, "score": "49.587017"}
{"text": "This involves adjusting the alignment of gestural and facial expression peaks so that they co - occur with the \" focused \" words .At this point , an intonation ( i.e. tune ) is assigned to the words , with pitch accents ( i.e. peaks in the fundamental frequency ) also set to occur on focused words .", "label": "", "metadata": {}, "score": "49.592293"}
{"text": "A plurality of log data associated with an intent may be received , and at least one step associated with completing the intent according to the plurality of log data may be identified .An understanding model associated with the intent may be created , including a plurality of queries mapped to the intent .", "label": "", "metadata": {}, "score": "49.593483"}
{"text": "A method for allowing a user to interface with a computer system , comprising : . displaying to the user , using a display device , a visible representation of a computer generated virtual environment , including an animated virtual character therein ; . accepting , using a multi - modal input , data defining a physical space domain distinct from said virtual environment , said physical space domain including the physical space occupied by the user and the visible representation of said virtual environment ; . generating , using a response processor , in response to a user input to the system , an action to be performed by said virtual character , including the substeps of . interpreting said user input data and said physical space information data and generating a user input context associated with said input , . determining a system response in response to said user input and said user input context , . wherein said step of determining a system response includes the steps of formulating real time responses to a predetermined set of said inputs by reactive processing ; and , formulating complex actions based on said inputs by deliberative processing , and . wherein said step of determining an understanding , comprises the steps of : . combining selected of said inputs into a frame providing a coherent understanding of said physical space domain and actions of said user , including the steps of , . accessing a static knowledge base about a physical space domain with reference to said selected inputs ; . accessing at least one of a dynamic knowledge base and a discourse model to infer an understanding of a current discourse between said user and said virtual environment ; . accessing a discourse model to infer an understanding of said current discourse ; and , . combining information from at least one of said static knowledge base , said dynamic knowledge base , and said discourse model to produce said frame .", "label": "", "metadata": {}, "score": "49.595226"}
{"text": "Description .Published .APPARATUS AND METHOD FOR MODEL ADAPTATION FOR SPOKEN LANGUAGE UNDERSTANDING - An apparatus and a method are provided for building a spoken language understanding model .Labeled data may be obtained for a target application .A new classification model may be formed for use with the target application by using the labeled data for adaptation of an existing classification model .", "label": "", "metadata": {}, "score": "49.595234"}
{"text": "5 above , and as such , will not be discussed further .The output of each experiment is a classification model learned from the training data that is stored in the training database 165 .The model is evaluated in several ways .", "label": "", "metadata": {}, "score": "49.623108"}
{"text": "This in turn was used to design a set of 500 sentences densely sampling these triphones and recordings made , totaling 3141 utterances .The addition of such focused supplementary data resulted in a relative reduction in word error rates of less than 5 % on the above test sets .", "label": "", "metadata": {}, "score": "49.623146"}
{"text": "In the original algorithm unit types are simple phones , but in this limited domain synthesizer we constrain this further by defining types as phones plus the word that phone came from .This apparently severe constraint allows the system to produce near perfect synthesis as the phones it selects always come from an instance of the word that is to be synthesized .", "label": "", "metadata": {}, "score": "49.6257"}
{"text": "An architecture is provided for building animated , virtual interface characters that serve as the user 's ally in using a complex computational system , providing assistance in gathering information , executing commands or completing tasks .Traditional user interfaces based on tool metaphors often promote an adversarial relationship between the user and the interface , often creating the impression that the interface is working against , rather that for , the user .", "label": "", "metadata": {}, "score": "49.62628"}
{"text": "A method incorporating teachings of the present disclosure may include deploying a speech recognition module to apply an appropriate interpretation to a plurality of utterance types .System and method for targeted tuning module of a speech recognition system US 7580837 B2 .", "label": "", "metadata": {}, "score": "49.640213"}
{"text": "claim 1 , wherein the user speaks the utterance in a multi - modal input that further includes one or more non - voice inputs relating to the utterance .The method of .claim 1 , wherein the conversational speech engine generates the response in a multi - modal output that includes one or more non - voice outputs that relate to the utterance or one or more tasks executed to process a request identified from the intended meaning .", "label": "", "metadata": {}, "score": "49.70147"}
{"text": "We observed that the triphone coverage of the corpus was rather sparse .For example , while there were 129516 possible triphones in the domain ( computed from the dictionary used for recognition ) , only 15783 were present in the training data .", "label": "", "metadata": {}, "score": "49.714016"}
{"text": "Multimodal asymmetry Characters can \" communicate \" with the user through speech , facial expressions and gestures , but are unable to perceive the same behaviors on the part of the user .User input is restricted to mouse clicks and simple textual commands .", "label": "", "metadata": {}, "score": "49.739967"}
{"text": "The classifier may be changed , via semi - supervised learning , based on the selected ones of the unselected utterance data .Gokhan Tur , Castro Valley , CA US .Patent application number .Description .Published .Multitask Learning for Spoken Language Understanding - A system , method and computer - readable medium provide a multitask learning method for intent or call - type classification in a spoken language understanding system .", "label": "", "metadata": {}, "score": "49.87192"}
{"text": "The voice - based input may include a user utterance , and a request may be identified from the utterance .Appropriate action may be taken to service the request , while one or more advertisements may be selected and presented to the user .", "label": "", "metadata": {}, "score": "49.91538"}
{"text": "This system allows an anthropomorphically correct 3D animated figure to be scripted to give a presentation .The character 's author provides the narrative text which includes annotations describing where , when and what type of gestures should occur .Users simply observe the character 's pre - determined behaviors .", "label": "", "metadata": {}, "score": "49.933544"}
{"text": "The system 100 components that we extracted features from were the recognizer 120 , the NLU unit 130 , and the dialog manager 190 , along with a representation of the discourse history .Below we describe features obtained from each module : .", "label": "", "metadata": {}, "score": "50.01952"}
{"text": "claim 25 , wherein the user speaks the utterance in a multi - modal input that further includes one or more non - voice inputs relating to the utterance .The system of .claim 25 , wherein the grammatically or syntactically adapted response comprises a multi - modal output that includes one or more non - voice outputs that relate to the utterance or one or more tasks executed to process a request identified from the intended meaning .", "label": "", "metadata": {}, "score": "50.038292"}
{"text": "2 is a schematic representation of the configuration of the computer of .FIG .1 into a number of functional modules in accordance with an embodiment of the present invention ; .FIG .3 is a flow diagram of the overall use of the computer of .", "label": "", "metadata": {}, "score": "50.03897"}
{"text": "claim 14 , wherein to accumulate the short - term shared knowledge about the current conversation , the computer - executable instructions are further operable when executed to expire the information about the utterance from the short - term context stack after a psychologically appropriate amount of time .", "label": "", "metadata": {}, "score": "50.04049"}
{"text": "The reaction module sends the generation module frames describing complex actions it would like to have performed immediately , along with priorities and optional time deadlines for completion .The generation module will notify the reaction module when a requested action has either been completed or removed from consideration ( e.g. , due to timeout or conflict with a higher priority action ) .", "label": "", "metadata": {}, "score": "50.16178"}
{"text": "The method according to .claim 29 , wherein said reactive processing includes the steps of : . receiving asynchronous updates of selected of said user inputs and understanding frames concerning said user inputs from said deliberative processing ; . accessing data from a static knowledge base about said physical space domain and a dynamic knowledge base having inferred information about a current discourse between said user , said physical space domain , and said virtual environment ; and , . determining a current action for said virtual environment based on said asynchronous updates , understanding frames , and said data .", "label": "", "metadata": {}, "score": "50.163834"}
{"text": "Given a syntax specification , an ontology 64 , and a lexicon 66 , the syntax manager 62 generates a grammatic specification ( e.g. , BNF grammar ) which can be used by the speech engine 22 to guide recognition of a spoken utterance 14 .", "label": "", "metadata": {}, "score": "50.215046"}
{"text": "User 's body is facing the universe , but user is looking at KUMO .Speech recognizer detects that user has started talking .The above information is available at the input manager ; it forwards it to both the reaction and understanding modules .", "label": "", "metadata": {}, "score": "50.248177"}
{"text": "For example , a system may recognize an action like \" pay bill \" with an acceptable level of accuracy and may not recognize an action like \" transfer to agent \" with an acceptable level of accuracy .As such , an administrator and/or tuning application may elect to apply targeted tuning to the speech system to improve recognition of the second type of utterance .", "label": "", "metadata": {}, "score": "50.262123"}
{"text": "An Input Manager 520 interfaces with all input devices 540 , performs signal processing on input data , and routes the results to the reactive component 500 and the deliberative component 510 when available ( asynchronously ) .An action scheduler 530 interfaces with all output devices 550 , accepts action ( output ) requests ( from reactive and deliberative components ) and attempts to fulfill them , performing conflict resolution when necessary and notifying requesters when a requested action has been completed or canceled .", "label": "", "metadata": {}, "score": "50.287758"}
{"text": "In addition , the intelligent hypotheses may use short - term and/or long - term shared knowledge to proactively build and evaluate interaction with a user as a conversation progresses or over time .The hypotheses may model human - to - human interaction to include a varying degree of certainty for each hypothesis .", "label": "", "metadata": {}, "score": "50.43803"}
{"text": "The one or more contexts may be determined by having one or more context domain agents compete to determine a most appropriate domain for a given utterance .Once a given domain \" wins \" the competition , the winning domain may be responsible for establishing or inferring further contexts and updating short - term and long - term shared knowledge .", "label": "", "metadata": {}, "score": "50.503647"}
{"text": "Greeting and Farewell functions - The character speaks and gestures when greeting and saying goodbye .During the greeting sequence , The character gives her name , and asks the user 's name to add to the propositional database .Emphasis function - people may emphasize particular linguistic items by prosodic means ( pitch accents ) or by accompanying the word with a beat gesture ( short formless wave of the hand ) .", "label": "", "metadata": {}, "score": "50.518547"}
{"text": "Other advantages will be apparent to those skilled in the art .It will be apparent that operation 320 may use various techniques to select advertisements based on voice - based inputs and/or requests included therein .For example , an advertiser may specify a target audience , marketing criteria , campaign strategies , budget constraints , concepts , semantic indicators , related topics , categories , and/or any other suitable information to associate with an advertisement .", "label": "", "metadata": {}, "score": "50.52746"}
{"text": "In various instances , a request may include incomplete , ambiguous , unrecognized , or otherwise insufficient semantic indicators , context , qualifiers , or other information needed to identify the request .In other words , the request may include inadequate information to identify or infer a task to perform , information to retrieve , or a goal for a conversation .", "label": "", "metadata": {}, "score": "50.665436"}
{"text": "As used herein , a \" request \" may be a command , directive , or other instruction for a device , computer , or other machine to retrieve information , perform a task , or take some other action .In one implementation , the input may be a multi - modal input , where at least part of the multi - modal input is an utterance .", "label": "", "metadata": {}, "score": "50.666073"}
{"text": "When a program is embodied in a signal which may be conveyed directly by a cable or other device or means , the carrier may be constituted by such cable or other device or means .Alternatively , the carrier may be an integrated circuit in which the program is embedded , the integrated circuit being adapted for performing , or for use in the performance of , the relevant processes .", "label": "", "metadata": {}, "score": "50.682716"}
{"text": "Specifically , when the back button 408 is selected the details for the previous utterance are displayed and the sound for the utterance output by the computer 1 .Repeated selection of the back button enables a user to cycle backwards through the recently recorded utterances .", "label": "", "metadata": {}, "score": "50.698532"}
{"text": "7,634,409 on Dec. 15 , 2009 , and which is hereby incorporated by reference in its entirety .The one or more preliminary interpretations may be provided to a conversational language processor 120 .Conversational language processor 120 may include a voice search engine 125 , a context determination module 130 , and one or more agents 135 , among other things , to enable cooperative , conversational interaction between the user and system 100 .", "label": "", "metadata": {}, "score": "50.73784"}
{"text": "Using a method of decoding , a scoring technique is used to provide a measure of how well each reference pattern , or each combination of reference patterns , matches the pattern extracted from the input utterance .The unknown utterance is then recognised as the word(s ) associated with the reference pattern(s ) which mast closely match the unknown utterances .", "label": "", "metadata": {}, "score": "50.745216"}
{"text": "SYSTEM AND METHOD OF PROVIDING AN AUTOMATED DATA - COLLECTION IN SPOKEN DIALOG SYSTEMS - The invention relates to a system and method for gathering data for use in a spoken dialog system .An aspect of the invention is generally referred to as an automated hidden human that performs data collection automatically at the beginning of a conversation with a user in a spoken dialog system .", "label": "", "metadata": {}, "score": "50.748734"}
{"text": "Class Command-1 Command .Class Action-1 Make .Action Command-1 Action-1 .Class Thing-1 Column .Patient Action-1 Thing-1 .Destination Action-1 Green .The set of triples generated from the sentence serve as input to the reasoning facility 52 , which is described below .", "label": "", "metadata": {}, "score": "50.78888"}
{"text": "The method of .claim 1 , wherein accumulating the short - term shared knowledge about the current conversation includes populating a short - term context stack with information about the utterance received during the current conversation .The method of . claim 2 , wherein accumulating the short - term shared knowledge about the current conversation further includes expiring the information about the utterance from the short - term context stack after a psychologically appropriate amount of time .", "label": "", "metadata": {}, "score": "50.840958"}
{"text": "One such approach , suitable for use with the invention is described in copending , commonly assigned U.S. patent application Ser .No .10/004,289 filed Oct. 25 , 2001 , entitled \" System and Method for Relating Syntax and Semantics for a Conversational Speech Application \" the teachings of which are incorporated herein by reference .", "label": "", "metadata": {}, "score": "50.87759"}
{"text": "The one or more contexts may be determined by having one or more context domain agents compete to determine a most appropriate domain for a given utterance , as described in U.S. patent application Ser .No . 11/197,504 , entitled \" Systems and Methods for Responding to Natural Language Speech Utterance , \" filed Aug. 5 , 2005 , which issued as U.S. Pat .", "label": "", "metadata": {}, "score": "50.903793"}
{"text": "Table 4 categorizes the multimodal inputs and outputs utilized in the systems most relevant to the architecture of the present invention .As shown in Table 4 , Ymir and the present invention 's architecture account for a much wider range of multimodal inputs than the other systems , which rely mostly on text .", "label": "", "metadata": {}, "score": "50.951553"}
{"text": "Long - term shared knowledge may generally be user - centric , rather than session - based , where inputs may be accumulated over time to build user , environmental , cognitive , historical , or other long - term knowledge models .", "label": "", "metadata": {}, "score": "50.975327"}
{"text": "The GUI manager 40 provides an interface to the speech center 20 .Even though the speech center 20 operates primarily through a speech interface , there will still be some cases of graphical user interface interaction with the user .Recognition feedback , dictation correction , and preference setting are all cases where traditional GUI interface elements may be desirable .", "label": "", "metadata": {}, "score": "51.068794"}
{"text": "By categorizing and developing conceptual models for various types of exchanges , user expectations and domain capabilities may be consistently aligned .Intelligent Hypothesis Builder 310 may generate a hypothesis as to a conversation type by considering conversational goals , participant roles , and/or an allocation of information among the participants .", "label": "", "metadata": {}, "score": "51.08551"}
{"text": "The distributions of the various states of the triphones that were learnt in this manner were then used to build the final decision trees .Since this tends to merge the identity of triphones with similar transitions , the entropy of adjacent states was also considered during the decision tree building process to maintain triphone identities .", "label": "", "metadata": {}, "score": "51.19848"}
{"text": "FIG .2 shows the components of a speech center system 20 configured according to the present invention .FIG .2 also illustrates external applications 26 that communicate with the speech center 20 , a speech engine 22 , and an active accessability module 24 .", "label": "", "metadata": {}, "score": "51.215736"}
{"text": "Intelligent Hypothesis Builder 310 may use an identified conversation type to assist in generating a set of hypotheses as to a user 's intent in an utterance .In addition , Intelligent Hypothesis Builder 310 may use short - term shared knowledge from the Session Input Accumulator to proactively build and evaluate interaction with a user as a conversation progresses , as well as long - term shared knowledge to proactively build and evaluate interaction with the user over time .", "label": "", "metadata": {}, "score": "51.244675"}
{"text": "The alternative expression feature may recognize common alternatives for nouns and verbs to reflect variations in usage patterns according to various criteria .For example , users may vary expression based on age , socio - economics , ethnicity , user whims , or other factors .", "label": "", "metadata": {}, "score": "51.337364"}
{"text": "In one embodiment the response planner is partitioned at the plan operator level into sub - modules for communicative and non - communicative ( task ) planning ( see FIG .10 ) .The two types of planning are coordinated .", "label": "", "metadata": {}, "score": "51.356186"}
{"text": "For example , when a document avatar is dropped on a specific hyperlink , it always displays the same behavior , regardless of other actions that have taken place .Referring again to the drawings , wherein like reference numerals designate identical or corresponding parts throughout the several views , and more particularly to FIG .", "label": "", "metadata": {}, "score": "51.36673"}
{"text": "The utterance 15 is then translated into the appropriate script engine 38 calls and dispatched to the target application 26 .The conversation manager 28 is also responsible for controlling when dictation functionality is active , based on the context determined by the environmental interface 32 .", "label": "", "metadata": {}, "score": "51.45961"}
{"text": "If this is the case the control module 20 invokes the data collection module 22 which initially determines a list of required utterances ( S 7 - 19 ) and then causes a record utterance screen to be displayed .In order to determine the required utterances , the data collection module 22 initially identifies whether any of the speaker records within the speaker database 24 has a selected flag 44 indicating a selected status .", "label": "", "metadata": {}, "score": "51.480473"}
{"text": "The recognized spoken utterance 15 is a spoken utterance 14 that is recognized as a valid utterance by the speech engine 22 .The utterance representation 21 is an internal representation of the recognized spoken utterance produced by the speech center system 20 .", "label": "", "metadata": {}, "score": "51.49135"}
{"text": "SUMMARY OF THE INVENTION .One approach to processing utterances from the user of a computer , as described above , transforms an utterance directly into script commands .One example of such an approach is described in copending , commonly assigned U.S. patent application Ser .", "label": "", "metadata": {}, "score": "51.49507"}
{"text": "EXPLOITING THE SEMANTIC WEB FOR UNSUPERVISED NATURAL LANGUAGE SEMANTIC PARSING - Structured web pages are accessed and parsed to obtain implicit annotation for natural language understanding tasks .Search queries that hit these structured web pages are automatically mined for information that is used to semantically annotate the queries .", "label": "", "metadata": {}, "score": "51.5211"}
{"text": "claim 29 wherein the established intended meaning comprises a hypothesis having a degree of certainty about the intent that the user had in speaking the one or more words in the utterance .The system of .The system of .claim 29 wherein the one or more processors are further configured to generate the grammatically syntactically adapted response based on the conversation type .", "label": "", "metadata": {}, "score": "51.636875"}
{"text": "Device management can involve computationally complex and time - constrained operations such as device initialization , fault detection , and polling .The input manager itself may be implemented as a set of distributed processes in order to facilitate use of input devices on multiple computers .", "label": "", "metadata": {}, "score": "51.64174"}
{"text": "As mentioned above , an assigned accuracy value may be compared at step 32 against a threshold value to determine if a system needs tuning .In accordance with one aspect of the present disclosure , a system administrator and/or a tuner may determine that a specific utterance type recognition rate is too low and elect to use a tuning application at step 34 to improve the system recognition rate .", "label": "", "metadata": {}, "score": "51.722984"}
{"text": "The computer method of .claim 1 , wherein the step of generating the response comprises generating the computer application program command based on the utterance representation and based on the analysis of the ambiguous information .The computer method of .", "label": "", "metadata": {}, "score": "51.72868"}
{"text": "The relation detection model training solution scales to other domains and languages , pushing the burden from natural language semantic parsing to knowledge base population .The relation detection model training solution exhibits performance comparable to supervised solutions , which require design , collection , and manual labeling of natural language data .", "label": "", "metadata": {}, "score": "51.7413"}
{"text": "The training data was observed to contain a large number of triphones with very poor representation .Since the data for these triphones was scarce , distributions learnt for these triphones , and decision trees built based on these distributions , were likely to be poorly estimated .", "label": "", "metadata": {}, "score": "51.769276"}
{"text": "However , in place of a word identifier for the new record a data entry cursor is displayed .If the control module 20 determines that the ADD WORD option has not been selected ( S 7 - 6 ) from the project menu , the control module 20 then determines whether the AMEND SET - UP option has been selected ( S 7 - 8 . )", "label": "", "metadata": {}, "score": "51.84801"}
{"text": "The input received by Adaptive Response Builder 315 may include at least a ranked list of hypotheses , including explicit and/or implicit hypotheses , each of which may have a corresponding degree of certainty .Each degree of certainty may further be classified as explicit or implicit , which may be used to adjust a response .", "label": "", "metadata": {}, "score": "51.935333"}
{"text": "Additional embodiments of the present invention include an idle condition and behavior blending .For example , : when ( idle DOF ) condition , which allows a behavior to be started as soon as a DOF becomes available ( e.g. , to begin execution of idle routines ) .", "label": "", "metadata": {}, "score": "51.938892"}
{"text": "This project uses a planning system to plan tutorials of specified material given a target time duration for the presentation .Presentations are not scripted by human authors , but are instead created by a planning system .Unlike Document Avatars and Microsoft Agent characters , users can not interact with the characters during a presentation .", "label": "", "metadata": {}, "score": "51.969543"}
{"text": "The ability to recognize and predict language understanding errors will endow an automated system with the ability to correct some errors automatically or to interact with users to repair them .U1 : ( silence ) .S2 : Sorry .Please briefly tell me how I may help you ?", "label": "", "metadata": {}, "score": "52.0168"}
{"text": "Tuning engine 100 may recognize the indicator output by targeting engine 98 , and begin tuning system 80 to better recognize the utterance type that is causing system 80 difficulties .In practice , tuning engine 100 may feed speech module 86 with a collection of utterances having a first type if the first type accuracy level is too low .", "label": "", "metadata": {}, "score": "52.049873"}
{"text": "Since gestural events generally occur on word boundaries , the word boundary call backs can be used to tightly synchronize gesture , facial expression , and other animation outputs with speech .Behavior Control .At a low level , control of the animated character consists of individual \" analog \" control knobs , which manipulate the rotations of joints and the locations of objects and features ( such as hands and eyebrows ) .", "label": "", "metadata": {}, "score": "52.087196"}
{"text": "The system of . claim 17 , further comprising a voice activated services platform that comprises the implemented speech - enabled application .A method of tuning a speech - enabled application comprising : . deploying a speech - recognition module to apply an appropriate interpretation to a plurality of utterance types ; . accessing , from a database , information representing a collection of recorded utterances and assigned interpretation for each of the plurality of recorded utterances ; . comparing , by an accuracy engine , the assigned interpretation for each of the plurality of recorded utterances to an accurate interpretation for each of the plurality of utterances ; . determining , by the accuracy engine , a separate accuracy value for each of the plurality of utterance types ; and .", "label": "", "metadata": {}, "score": "52.12398"}
{"text": "If the probability of correctly understanding the user 's input communication determined by the NLU monitor 180 does not exceed a predetermined threshold , for example , the NLU monitor 180 signals the dialog manager 190 to route the user to a human for assistance .", "label": "", "metadata": {}, "score": "52.176674"}
{"text": "As technology advances , consumer electronics devices tend to play larger roles due to increased functionality and mobility .For example , mobile phones , navigation devices , embedded devices , and other such devices provide a wealth of functionality beyond core applications .", "label": "", "metadata": {}, "score": "52.211624"}
{"text": "The present inventors have realized that designing animated character interfaces that explicitly display allegiance with the user through language , personality , and ease of use , minimize undesirable adversarial interactions .The present inventors have also realized that one way to foster feelings of allegiance between the user and a character interface is through the social metaphor of face - to - face conversation involving multiple modalities , including speech , facial expressions , gestures , and other forms of bodily communication .", "label": "", "metadata": {}, "score": "52.22209"}
{"text": "The dialog manager 56 has the responsibility for deciding whether a speech center - generated response should be visible or audible .It also decides whether the response can be presented immediately , or whether it must ask permission first .If an operation is taking more than a few seconds , the dialog manager 60 generates an indication to the user that the operation is in progress .", "label": "", "metadata": {}, "score": "52.23013"}
{"text": "The method of .claim 1 , wherein the speech recognition engine recognizes the one or more words or phrases in the natural language utterance using a plurality of dictionary and phrase entries that are dynamically updated based on a history of a current dialog and one or more prior dialogs .", "label": "", "metadata": {}, "score": "52.26238"}
{"text": "claim 24 , further comprising an action scheduler that controls an animation that displays said interface in a manner that interacts with said user and performs actions requested via said user inputs , wherein : . said user inputs include at least one of speech , gestures , orientation , body position , gaze direction , gesture recognition , keyboard , mouse , user ID , and motion detection ; . said deliberative processing utilizes at least one of said user inputs to implement a complex action ; and , . said reactive processing formulates a real time response to predetermined of said user inputs .", "label": "", "metadata": {}, "score": "52.286575"}
{"text": "An example implementation of the reactive module is illustrated in the flow diagram of FIG .11 .Via a loop 1100 , the Reactive component constantly looks for inputs from the input manager and deliberative modules .A current action for each input ( message ) is determined 1110 .", "label": "", "metadata": {}, "score": "52.3164"}
{"text": "The method of .A speech tuning system , comprising : . a repository comprising a memory to store a sample of captured utterances from an implemented speech - enabled application and an assigned utterance type for each of the captured utterances ; . an accuracy engine communicatively coupled to the repository and operable to determine if an assigned utterance type for a given captured utterance represents an accurate interpretation of the given captured utterance ; . a targeting engine communicatively coupled to the accuracy engine and operable to determine a first accuracy level of the speech - enabled application in identifying a first type of utterance and a second accuracy level of the speech - enabled application in identifying a second type of utterance ; and .", "label": "", "metadata": {}, "score": "52.389763"}
{"text": "7,949,529 on May 24 , 2011 , both of which are hereby incorporated by reference in their entirety .Furthermore , conversational language processor 120 may support adaptive misrecognition to reinterpret a current utterance and/or one or more previous utterances .For example , information contained in a current utterance may indicate that interpretations for one or more previous utterances were incorrect , and therefore , the previous utterances may be reinterpreted to improve subsequent interpretations .", "label": "", "metadata": {}, "score": "52.462227"}
{"text": "The relation detection model training solution mines freely available resources from the World Wide Web to train a relationship detection model for use during linguistic processing .The relation detection model training system searches the web for pairs of entities extracted from a knowledge graph that are connected by a specific relation .", "label": "", "metadata": {}, "score": "52.475243"}
{"text": "The synthetic character interacts with both a virtual space where the character is displayed , and a physical space ( domain ) that includes the user .Real - time reactive processing provides lifelike and engaging responses to user queries and conversations .", "label": "", "metadata": {}, "score": "52.535973"}
{"text": "One embodiment of the input manager is illustrated in the flow diagram of FIG .8 .For each input device , the input manager starts by initializing the device 800 ( i.e. , sets up socket connections , starts the device processing ) .", "label": "", "metadata": {}, "score": "52.542664"}
{"text": "At least one advertisement may be selected and presented to the user based on the identified request .The advertisement may be presented as a natural language response , thereby creating a conversational feel to the presentation of advertisements .The request and the user 's subsequent interaction with the advertisement may be tracked to build user statistical profiles , thus enhancing subsequent selection and presentation of advertisements .", "label": "", "metadata": {}, "score": "52.543762"}
{"text": "claim 3 wherein the adapted dialog strategy includes one of prompting the user with choices and prompting the user to confirm the recognition and understanding data .The system of .claim 1 wherein the language understanding monitor is further adapted to determine the probability using recognition data provided by a recognizer and understanding data provided by a language understanding unit , and the recognition and understanding data is derived from the user 's input communication .", "label": "", "metadata": {}, "score": "52.585274"}
{"text": "Because variables such as stress , distraction , and serendipity are always different and infinitely varied , free form search module 245 may be designed with a goal of understanding that no human will come to the same Human - to - Machine interface situation in the same way twice .", "label": "", "metadata": {}, "score": "52.608643"}
{"text": "FIG .9 is a behavior hierarchy of communicative acts and non - verbal social interaction rules ; .FIG .10 is a block diagram of the response planner module ; .FIG .11 is a flow diagram of operations of the reactive component ; .", "label": "", "metadata": {}, "score": "52.64454"}
{"text": "For example , the recognizer 120 and the NLU unit 130 may use confidence functions to determine whether the user 's input communications have been recognized and understood .The recognition and understanding data from the user 's input communication are also input into the NLU monitor 180 .", "label": "", "metadata": {}, "score": "52.765484"}
{"text": "START ) and ends ( .END ) .The label can also be used to halt the behavior ( using the END command ) .In addition , a labeled speech behavior will generate events of the form .WORDas each word is produced ( where WORD 0 is generated just as the first word is produced ) .", "label": "", "metadata": {}, "score": "52.77214"}
{"text": "The results of testing could be displayed either in the form of a table or in any suitable graphical form for example in a scatter graph .Although the embodiments of the invention described with reference to the drawings comprise computer apparatus and processes performed in computer apparatus , the invention also extends to computer programs , particularly computer programs on or in a carrier , adapted for putting the invention into practice .", "label": "", "metadata": {}, "score": "52.801083"}
{"text": "In various implementations , advertisement selection module 250 may retrieve a predetermined number of advertisements for any given request .Furthermore , the selected advertisements may depend upon a presentation format .For example , advertisements may be selected based on an amount of available space on a display of voice - enabled device 210 and/or a size / shape of the selected advertisements .", "label": "", "metadata": {}, "score": "52.822495"}
{"text": "Once all the required information is assembled , the appointment creation function is called and the appointment scheduled .One of the most important aspects of the domain model 70 is that it is explicitly represented and accessible to the speech center system 20 .", "label": "", "metadata": {}, "score": "52.83712"}
{"text": "2 ; .FIG .4 in a schematic block diagram of an exemplary data structure for storing data within the data set up store of the computer of .FIG .2 ; .FIG .5 is a schematic representation of data structures of word records for storing data within the word database of the computer of .", "label": "", "metadata": {}, "score": "52.852203"}
{"text": "In this embodiment of the present invention data stored within the speaker database 24 is stored in the form of a plurality of speaker records 40 .FIG .6 is a schematic block diagram of a data structure for a speaker record in accordance with this embodiment of the present invention .", "label": "", "metadata": {}, "score": "52.88729"}
{"text": "claim 7 wherein the reasoning facility applies a goal - directed reasoning analysis based on the set of goal - directed rules to clarify the ambiguous information .The apparatus of . claim 8 , wherein the reasoning facility accesses data in a conversational record of related utterances to clarify the ambiguous information .", "label": "", "metadata": {}, "score": "52.906"}
{"text": "The information is eventually purged from the conversational record when it is no longer relevant to active goals and after some predefined period of time has elapsed .For example , after having said , \" Create an appointment with Mark at 3 o'clock tomorrow , \" a user might say , \" Change that to 4 o'clock . \" The speech center system 20 establishes that a time attribute of something is changing , but needs to refer back to the conversational record 60 to find the appointment object whose time attribute is changing .", "label": "", "metadata": {}, "score": "52.989094"}
{"text": "In the former case , it sets up a loop ( or event triggers ) to capture updates .In the latter case , it sets up a loop ( or event triggers ) to determine when to request more data from the input device .", "label": "", "metadata": {}, "score": "53.066372"}
{"text": "Subsequent interaction between the user and the presented advertisements may be monitored in a decisional operation 330 .For instance , when the user elects to interact with the advertisement , action may be taken based on the interaction in an operation 335 .", "label": "", "metadata": {}, "score": "53.091972"}
{"text": "2 illustrates a block diagram of an exemplary advertising system according to various aspects of the invention .FIG .3 illustrates a flow diagram of an exemplary method for selecting and presenting advertisements based on voice - based inputs according to various aspects of the invention .", "label": "", "metadata": {}, "score": "53.10675"}
{"text": "An apparatus for converting an utterance representation into a response , comprising : . means for generating an application specific goal derived from the utterance representation , wherein the application specific goal and the utterance representation are propositions comprising attribute - object - value triples , the proposition corresponding to the utterance representation being derived from a frame representation ; . means for generating a response based on the analysis of the utterance representation if ambiguous information is identified .", "label": "", "metadata": {}, "score": "53.10704"}
{"text": "( and : 1(on : eventBIEND )Do it when the behavior labeled B 1 . : 2(before : event 14:01:32.143 ) ) completes , as long as it is before the specified time .Open Loop vs. Closed - Loop Control .", "label": "", "metadata": {}, "score": "53.134907"}
{"text": "The interactive user interface according to . claim 1 , wherein : . an operation of said display includes an interaction of objects in said physical space with said virtual environment that may include at least one of pointing and gesturing by an object or person in said physical space toward an object in said virtual environment .", "label": "", "metadata": {}, "score": "53.281113"}
{"text": "activated when \" possible \" unknown foods , ingredients , drinks , etc . .are detected in client input .These new products will be learnt , so .they could be recognized the next time they appear in client . sentences .", "label": "", "metadata": {}, "score": "53.307205"}
{"text": "A secondary criteria is the ability to synthesize different voices .Other Devices or Software : characters may need to control software applications or hardware devices in the course of assisting the user to perform a task .The room controls in Kumo can all be commanded via text commands over an RS232 port in the AFX switcher .", "label": "", "metadata": {}, "score": "53.352993"}
{"text": "If the recognized user utterance is not understood or classifiable to a predetermined acceptance threshold , then the method re - prompts the user .If the recognized user utterance is not classifiable to a predetermined rejection threshold , then the method transfers the user to a human as this may imply a task - specific utterance .", "label": "", "metadata": {}, "score": "53.354416"}
{"text": "claim 14 wherein the set of computer instructions comprises further instructions to apply a goal - directed reasoning analysis based on the set of goal - directed rules to clarify the ambiguous information .The computer program product of . claim 15 , wherein the set of computer instructions comprises further instructions to access data in a conversational record of related utterances to clarify the ambiguous information .", "label": "", "metadata": {}, "score": "53.41407"}
{"text": "TRAINING DATA .The testing module 27 then determines which of the options a user selects and then proceeds to test the accuracy of the model stored within the model database 26 .In the case of live testing the testing module 27 then prompts a user to speak a word and detects the spoken word using the microphone 7 which is then processed in a conventional manner utilizing the word models within the model database 26 .", "label": "", "metadata": {}, "score": "53.459293"}
{"text": "FIG .6 is a flowchart of a possible automated task classification process using the natural language understanding monitoring system 100 with the ability to adapt dialog strategy in an effort to conduct successful dialog with the user .Steps 6000 , 6050 , 6100 , 6150 , 6250 , 6300 , 6350 , and 6400 operate similarly to steps 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5800 , and 5600 of .", "label": "", "metadata": {}, "score": "53.536915"}
{"text": "claim 16 , wherein said reactive processing provides reactive output to said output mechanism upon receiving a predetermined input from said deliberative processing .The interface according to . claim 19 , wherein : . said predetermined input is speech by a user ; and , . said reactive output is a command to initiate a conversational gaze on said synthetic character .", "label": "", "metadata": {}, "score": "53.58947"}
{"text": "Over a period of three weeks the system synthesized 18,276 phrases , 459 of which ( 2.5 % ) contained out of vocabulary words ( 71 different words ) .These were all less frequent ( or forgotten ) places names .", "label": "", "metadata": {}, "score": "53.667732"}
{"text": "The tempo feature may also indicate hesitations , pauses , or interruptions , which could also lead to recognizer 120 errors .On the other hand , additional multimodal input such as touchtone ( DTMF ) in combination with the user 's communication , as encoded by the feature dtmf - flag , might increase the likelihood of understanding , since the touchtone input is unambiguous it can constrain language understanding .", "label": "", "metadata": {}, "score": "53.69667"}
{"text": "and commands such as \" print this file \" would be available with no further syntax specification required .The description of a speech - enabled application 26 can also introduce additional grammatical constructs that provide more specialized sentence forms for the new classes introduced .", "label": "", "metadata": {}, "score": "53.769073"}
{"text": "In one embodiment , these script expressions are LotusScript expressions .Thus , the reasoning facilty 52 has the capability to retrieve information from inside or outside of the speech center 20 , and to take action that will impact the world beyond speech center 20 .", "label": "", "metadata": {}, "score": "53.770336"}
{"text": "For example , a given concept may include various semantically equivalent indicators having an identical meaning .Thus , for instance , a voice - based input may be \" Play some tunes ! \" or \" Play some music ! \"", "label": "", "metadata": {}, "score": "53.83258"}
{"text": "generate a response to the utterance based on the intended meaning established within the identified context .The non - transitory computer readable medium of .claim 39 , wherein the established intended meaning comprises an implicit hypothesis having a corresponding degree of certainty about an intent that the user had in speaking the utterance .", "label": "", "metadata": {}, "score": "53.943512"}
{"text": "The semantic representation is used when creating entity - relation patterns that are used to mine natural language ( NL ) examples ( e.g. NL surface forms from the web and search query click logs ) .The structure of the content source ( e.g. semantic graph ) is enriched with the mined NL examples .", "label": "", "metadata": {}, "score": "53.957466"}
{"text": "Finally , by selecting the training data option the testing module 27 selects to test the models within the model database 26 the utterance records 45 used to train the models when the models within the model database 26 were created .", "label": "", "metadata": {}, "score": "53.98201"}
{"text": "At step 24 , information associated with a call may be maintained .The information may include , for example , a recording of a received utterance , an indication of whether an interpretation was made , an indication of what interpretation was made , an utterance receipt time , an indication of whether the assigned interpretation was accurate , etc .", "label": "", "metadata": {}, "score": "54.107395"}
{"text": "In step 2500 , the dialog manager 190 conducts further dialog with the user to obtain clarification of the users initial input communication ( exchange 1 ) .In step 2600 , if the recognizer 120 and NLU unit 130 can recognize and understand the user 's second input communication ( exchange 2 ) so that it can be processed , the process goes to step 2700 and ends .", "label": "", "metadata": {}, "score": "54.155617"}
{"text": "An NL linguistic item expresses an intent using a natural language , while a KL linguistic item expresses the intent using one or more keywords .In a training phase , the functionality produces the classification model based on query click log data or the like .", "label": "", "metadata": {}, "score": "54.163235"}
{"text": "3 which is a flow diagram outlining the use of the computer 1 . Initially ( S 3 - 1 ) a user utilises the control module 20 to set the global parameters for generating speech models which are stored within the data set - up store 29 .", "label": "", "metadata": {}, "score": "54.180267"}
{"text": "Once the response has been recognized and understood , task classification processor 440 determines the task , and the information needed for completing the caller 's request is obtained using the dialog manager 190 .The dialog manager 190 uses sub - modules that are specific for each task .", "label": "", "metadata": {}, "score": "54.199585"}
{"text": "After all the training data is received , at least once , the method comprises building a third NLU model using all the labeling data , wherein the third NLU model is used in generating the spoken dialog service .Gokhan Tur , Parsippany , NJ US .", "label": "", "metadata": {}, "score": "54.209522"}
{"text": "Rules 86 consist of some number of condition propositions and some number of action propositions .Each rule 86 represents a valid inference step that the reasoning facility 52 can take in the associated domain 70 .A rule 86 states that when the condition propositions are satisfied , then the action propositions can be concluded .", "label": "", "metadata": {}, "score": "54.225414"}
{"text": "For example , the input device may include a combination of a microphone and a touch - screen device , and input 105 may include an utterance that includes a request relating to a portion of a display on the touch - screen device that the user is touching .", "label": "", "metadata": {}, "score": "54.22897"}
{"text": "This label will be referred to as the HUMAN LABEL .The NLU unit 130 also logged what it believed to be the correct task category .This label will be referred to as the NLU LABEL .One of the focuses of this invention is on the problem of improving the system 's 100 ability to automatically detect when the NLU LABEL is wrong .", "label": "", "metadata": {}, "score": "54.231995"}
{"text": "The process that continues as stated above .FIG .3 is a flowchart of an exemplary natural language understanding monitoring process that allows the dialog strategy to be adapted between dialog exchanges .Steps 3000 , 3100 , 3200 , 3300 , and 3400 , operate similarly to steps 2000 , 2100 , 2200 , 2300 , and 2400 of .", "label": "", "metadata": {}, "score": "54.276184"}
{"text": "5 is a flowchart illustrating an exemplary task classification process using a NLU monitoring process ; and .FIG .6 is a flowchart illustrating an exemplary task classification process using a NLU monitoring process having dialog strategy adaptation techniques .DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS .", "label": "", "metadata": {}, "score": "54.29664"}
{"text": "The overall accuracy results for detecting NLU errors using the rule - learning program are summarized in .The first line of the above table represents the accuracy from always guessing the majority class ( RCORRECT ) ; this is the BASELINE against which the other results should be compared .", "label": "", "metadata": {}, "score": "54.361385"}
{"text": "Labeled data may be obtained for a target application .A new classification model may be formed for use with the target application by using the labeled data for adaptation of an existing classification model .In some implementations , the existing classification model may be used to determine the most informative examples to label .", "label": "", "metadata": {}, "score": "54.478584"}
{"text": "The June set contains predominantly ( though not exclusively ) developer speech , while the October test set contains a greater proportion of public speech , as well as more challenging data ( e.g. , from cell phones ) .Model 1 : For training this model , we used all transcribed data collected between April 1998 and January 2000 , excluding the data collected during June 1999 and October 1999 .", "label": "", "metadata": {}, "score": "54.491364"}
{"text": "2 ; .FIG .8 is an exemplary illustration of a main user interface control screen of the computer of .FIG .2 ; .FIG .9 is an exemplary illustration of a new speaker data entry screen of the computer of .", "label": "", "metadata": {}, "score": "54.52672"}
{"text": "Description .Published .Multi - Channel Sampling of Pulse Streams at the Rate of Innovation - A method includes accepting an analog input signal including a sequence of pulses of a given pulse shape .The analog input signal is distributed to multiple processing channels ( 40 ) operating in parallel .", "label": "", "metadata": {}, "score": "54.550262"}
{"text": "7,003,459 issued 21 Feb. 2006 .TECHNICAL FIELD .The invention relates to automated systems for communication recognition and understanding .BACKGROUND OF THE INVENTION .Today there are many automated dialog systems in operation that serve many purposes , such as for customer care .", "label": "", "metadata": {}, "score": "54.556953"}
{"text": "Referring to .FIG .1 , an exemplary system 100 for implementing a voice user interface is illustrated according to various aspects of the invention .System 100 may enable users to perform various tasks on a voice - enabled device .", "label": "", "metadata": {}, "score": "54.561172"}
{"text": "Implementations of the invention may be made in hardware , firmware , software , or any combination thereof .The invention may also be implemented as instructions stored on a machine - readable medium , which may be read and executed by one or more processors .", "label": "", "metadata": {}, "score": "54.56903"}
{"text": "Other techniques for enhancing an interpretation of a user utterance may be used , such as those described in U.S. patent application Ser .No .11/513,269 , entitled \" Dynamic Speech Sharpening , \" filed Aug. 31 , 2006 , which issued as U.S. Pat .", "label": "", "metadata": {}, "score": "54.592697"}
{"text": "SUMMARY OF THE INVENTION .This invention concerns a method and system for monitoring an automated dialog system for the automatic recognition of language understanding errors based on a user 's input communications .The method may include determining whether a probability of understanding the user 's input communication exceeds a first threshold .", "label": "", "metadata": {}, "score": "54.67254"}
{"text": "Long - term shared knowledge may include explicit and/or implicit user preferences , a history of recent contexts , requests , tasks , etc . , user - specific jargon related to vocabularies and/or capabilities of a context , most often used word choices , or other information .", "label": "", "metadata": {}, "score": "54.678154"}
{"text": "Process the utterance .Execute the command ( open the message ) .Select the message ( so that it may be opened ) .Get the ID of the message ( so that it may be selected ) .Get the name of the person ( in order to get the message ID ) .", "label": "", "metadata": {}, "score": "54.682144"}
{"text": "Each of these steps are further divided into sub - plans ( GET_USER , for example , which gets the user 's name for future reference ) .The plan provides a basic framework on how the discourse should proceed , absent intervening circumstances , and how the discourse should continue after an intervening circumstance ( an interruption for coffee , for example ) .", "label": "", "metadata": {}, "score": "54.682953"}
{"text": "For example , in one implementation , the speech recognition engine 110 may interpret the utterance using techniques of phonetic dictation to recognize a phoneme stream , as described in U.S. patent application Ser .No .11/513,269 , entitled \" Dynamic Speech Sharpening , \" filed Aug. 31 , 2006 , which issued as U.S. Pat .", "label": "", "metadata": {}, "score": "54.705437"}
{"text": "The dialog manager 56 serves as a traffic cop for information flowing back and forth between the reasoning facility 52 and the user .Questions generated by the reasoning facility 52 as well as answers derived to user questions and unsolicited announcements by the speech center system 20 are all processed by the dialog manager 56 .", "label": "", "metadata": {}, "score": "54.77037"}
{"text": "FIG .3 , an exemplary method for selecting and presenting advertisements based on a voice - based input is illustrated according to various aspects of the invention .The method may begin in an operation 305 , where a voice - based input , including at least a user utterance , may be received at a voice user interface .", "label": "", "metadata": {}, "score": "54.842766"}
{"text": "FIG .3 .As mentioned above , .FIG .3 presents a high - level block diagram of a speech - enabled system 80 incorporating a training tool subsystem 82 in accordance with the teachings of the present disclosure .", "label": "", "metadata": {}, "score": "55.026085"}
{"text": "This result contrasts with a 17.2 % error rate observed for models trained on the much larger Switchboard I corpus and adapted to the Communicator domain ( June 99 test set ) .MODELING LANGUAGE .The basis for the Communicator language is the ATIS language developed previously for a similar domain ( airline schedule information retrieval ) .", "label": "", "metadata": {}, "score": "55.05314"}
{"text": "PROBABILITY - BASED STATE MODIFICATION FOR QUERY DIALOGUES - A device may facilitate a query dialog involving queries that successively modify a query state .However , fulfilling such queries in the context of possible query domains , query intents , and contextual meanings of query terms may be difficult .", "label": "", "metadata": {}, "score": "55.102314"}
{"text": "In other words , the exploratory request may identify a goal for a conversation , instead of a particular task to perform or information to retrieve .As such , in various implementations , an advertisement may be selected in operation 320 in an effort to advance the conversation towards the goal .", "label": "", "metadata": {}, "score": "55.27246"}
{"text": "The candidate variations are scored to assist in determining the variations to include within an understanding model .The variations may also be used when delivering responses and displayed output in the SLU system .For example , instead of using the listed named entity , a popular and/or shortened name may be used by the system .", "label": "", "metadata": {}, "score": "55.28806"}
{"text": "1 .Characters controlled by a user 's actions are often called an \" avatar \" and generally serve as a representation in a virtual environment of the user who controls its behavior .These avatar characters are used in graphical chat - rooms and on - line virtual worlds such as Habitat , the Palace , BodyChat [ Vilhjalmsson97 ] , Oz Virtual , OnLive !", "label": "", "metadata": {}, "score": "55.30293"}
{"text": "For example , if a driver of a car , traveling at 65 miles - per - hour , with windows cracked is 92 % likely to be understood by a passenger , then noise tolerance module 250 may have a similar performance under those conditions .", "label": "", "metadata": {}, "score": "55.303444"}
{"text": "- End of Abstract ------ .I do not know if this short abstract would be enough for you to get . an idea of the system , so in case you need any further information , or .in case you have any comment or remark , please let me know .", "label": "", "metadata": {}, "score": "55.33924"}
{"text": "System 100 may enable users to request voice - enabled devices to retrieve information or perform various tasks , among other things , using natural language voice - based inputs .For example , system 100 may interpret natural language voice - based inputs and generate responses using , among other things , techniques described in U.S. patent application Ser .", "label": "", "metadata": {}, "score": "55.361763"}
{"text": "For the most part , the speech center 20 can operate without any modifications to the applications 26 it controls , but in some circumstances , it may be desirable to allow the applications 26 to communicate information directly back to the speech center 20 .", "label": "", "metadata": {}, "score": "55.3758"}
{"text": "ACTIVE LABELING FOR SPOKEN LANGUAGE UNDERSTANDING - A spoken language understanding method and system are provided .The system includes modules configured to control a processor in the system to perform the steps of the method .Gokhan Tur , Denville , NJ US .", "label": "", "metadata": {}, "score": "55.398033"}
{"text": "Displayed within the prompt window is a list of instructions 420 .The list of instructions comprises on the first line the words SPEAK FREELY ; on the second line the words STAY QUIET on the third line the word SAY and on the fourth line the words STAY QUIET .", "label": "", "metadata": {}, "score": "55.519306"}
{"text": "An aspect of the invention is generally referred to as an automated hidden human that performs data collection automatically at the beginning of a conversation with a user in a spoken dialog system .The method comprises presenting an initial prompt to a user , recognizing a received user utterance using an automatic speech recognition engine and classifying the recognized user utterance using a spoken language understanding module .", "label": "", "metadata": {}, "score": "55.597473"}
{"text": "The supporter 's role may be limited to regulating an overall progression of the conversation and interjecting queries for clarification .In an exploratory conversation , both participants share leader and supporter roles , and the conversation may have no specific goal , or the goal may be improvised as the conversation progresses .", "label": "", "metadata": {}, "score": "55.629944"}
{"text": "One example of a context manager 58 suitable for use with the invention is described in copending , commonly assigned U.S. patent application Ser .No . 09/931,505 , filed Aug. 16 , 2001 , entitled \" System and Method for Determining Utterance Context in a Multi - Context Speech Application , \" the entire teachings of which are incorporated herein by reference .", "label": "", "metadata": {}, "score": "55.648506"}
{"text": "The control module 20 then causes the main control screen to be re - displayed with the name of the new speaker and the gender date appearing at the end of the list of speaker data 110 shown within the speaker window 107 .", "label": "", "metadata": {}, "score": "55.68244"}
{"text": ", this is interpreted as the wanting feedback function .If the user is speaking and issues a declarative sentence and stops speaking and gesturing , or says an imperative or interrogative phrase , their input is interpreted as a giving turn function .", "label": "", "metadata": {}, "score": "55.708405"}
{"text": "If this is the case the control module then invokes the model generation module 25 .The model generation module 25 initially prompts ( S 7 - 30 ) a user to select from the list of words 111 displayed within the word window 108 those words for which models are to be generated .", "label": "", "metadata": {}, "score": "55.714027"}
{"text": "Performance benchmarks for the noise tolerance module may be defined by noise models based on human criteria .For example , if a driver of a car is 92 % likely to be understood by a passenger when traveling at 65 miles - per - hour with windows cracked , then performance benchmarks for the noise tolerance module may have a similar performance under such conditions .", "label": "", "metadata": {}, "score": "55.761883"}
{"text": "( after : event B 2 .END ) ) .: cmd once : content ( notify : i d N 1 ) ) .Action Scheduler Command Performative .While this works as long as synchronization is achieved through absolute time stamps , it makes event - based synchronization specification more difficult .", "label": "", "metadata": {}, "score": "55.884766"}
{"text": "However , many of the common interaction metaphors ( e.g. menus , desktops , windows , etc . ) focus on the computer as a physical tool , something the user must master to use effectively .SUMMARY OF THE INVENTION .", "label": "", "metadata": {}, "score": "55.92479"}
{"text": "The RPARTIAL - MATCH accounts for 109 ( 0.1 % ) of the utterances , and the RMISMATCH class accounts for 4197 ( 35.6 % ) of the utterances .Next , each utterance is encoded in terms of a set of 43 features that have the potential to be used during runtime to alter the course of the dialog .", "label": "", "metadata": {}, "score": "55.95622"}
{"text": "4 is an interactional diagram illustrating interactions between a user and an ally with a physical environment ; .FIG .5 is a block diagram illustrating an architecture supporting integrated deliberative and reactive processing components ; .FIG .6 is a block diagram of the architecture of FIG .", "label": "", "metadata": {}, "score": "55.97223"}
{"text": "The input spoken utterance 14 is a voice command or other audible speech input provided by a user of the computer system 10 ( e.g. , when the user speaks into a microphone connected to the computer system 10 ) based on common language words .", "label": "", "metadata": {}, "score": "56.025326"}
{"text": "Actions can be of three different forms : immediate primitive , immediate complex and future .Immediate primitive actions , which are those that need to be executed immediately and consist only of low - level actions ( e.g. , animation commands ) are sent directly to the action scheduler 530 .", "label": "", "metadata": {}, "score": "56.06731"}
{"text": "A feature called tempo was also calculated by dividing the value of the asr - duration feature by the recog - numwords feature .The motivation for the recognizer 120 features is that any one of them may have impacted recognition performance with a concomitant effect on language understanding .", "label": "", "metadata": {}, "score": "56.145325"}
{"text": "This classifier can identify NLU errors 23 % better than the baseline .The second row of the table , NLU ONLY , shows that the classifier based only on the NLU unit 130 features performs statistically as well as the classifier based on all the features .", "label": "", "metadata": {}, "score": "56.207092"}
{"text": "claim 1 , wherein said understanding module , said response planner , and said generation module are included within a deliberative component .The interface of .claim 31 , wherein said reactive component and said deliberative component are included within a response processor .", "label": "", "metadata": {}, "score": "56.32691"}
{"text": "This template tells the syntax manager 62 how to take this more general syntax specification and turn it into BNF based on the ontological description or information ( i.e. , ontology 64 ) in the domain model 70 .Thus , the grammatical specification is very tightly bound to the domain model ontology 64 .", "label": "", "metadata": {}, "score": "56.327965"}
{"text": "The entire NOTIFY frame is sent to the Reaction Module , allowing arbitrary parameters to be passed as attributes on the NOTIFY frame .Example callback when two labeled behaviors have completed : .( action : when ( and :1 ( after : event B 1 .", "label": "", "metadata": {}, "score": "56.339363"}
{"text": "3 presents a high - level block diagram of speech - enabled system incorporating a training tool in accordance with the teachings of the present disclosure .The use of the same reference symbols in different drawings indicates similar or identical items .", "label": "", "metadata": {}, "score": "56.348045"}
{"text": "The script engine 38 environment also allows the definition of new subroutines and functions that combine the primitive functionality provided by applications 26 into actions that more closely correspond to those that a user might talk about .While the speech center 20 is a script - enabled application , this does not mean that the applications 26 that it controls needs to be script - enabled .", "label": "", "metadata": {}, "score": "56.390266"}
{"text": "The computer program product of .claim 14 , wherein the set of computer instructions comprises further instructions to generate the computer application program command based on the utterance representation and based on the analysis of the ambiguous information .The computer program product of .", "label": "", "metadata": {}, "score": "56.39496"}
{"text": "The Action Scheduler .The action scheduler 530 is the \" motor controller \" for the character , responsible for coordinating action at the lowest level .It takes multiple action requests from multiple requesters ( i.e. , the reaction and generation modules ) and attempts to carry them out .", "label": "", "metadata": {}, "score": "56.412464"}
{"text": "[ 1 ] R. Singh , B. Raj , and R. M. Stern , Domain adduced state tying for cross domain acoustic modelling , Proc .Eurospeech , 1999 .", "label": "", "metadata": {}, "score": "56.45585"}
{"text": "For example , tags that are located on a structured web page that are associated with the search query may be used to annotate the query .The mined search queries may be filtered to create a set of queries that is in a form of a natural language query and/or remove queries that are difficult to parse .", "label": "", "metadata": {}, "score": "56.48185"}
{"text": "Look at user .Raise hands .Paraverbal .( \" umm \" ) .Take turn .Look at user .Raise hands to .begin gesturing .Speak .Reference to Physical Objects .As FIG .4 illustrates , the architecture of the present invention allows the user to interact not only with a virtual animated character , but also with objects in the real world .", "label": "", "metadata": {}, "score": "56.484077"}
{"text": "In addition , Intelligent Hypothesis Builder 310 may model human - to - human interaction by calculating a degree of certainty for each of the hypotheses .That is , just as humans rely on knowledge shared by participants to examine how much and what kind of information was available , Intelligent Hypothesis Builder 310 may leverage the identified conversation type and short - term and long - term shared knowledge to generate a degree of certainty for each hypothesis .", "label": "", "metadata": {}, "score": "56.541748"}
{"text": "Speech enabling mechanisms have been developed that allow a user of a computer system to verbally communicate with the computer system .Examples of speech recognition products that convert speech into text strings that can be utilized by software applications on a computer system include the ViaVoice \u2122 product from IBM \u00ae , Armonk , N.Y. , and NaturallySpeaking Professional from Dragon Systems , Newton , Mass.", "label": "", "metadata": {}, "score": "56.567474"}
{"text": "The character may point to objects in the physical space , or the user may point to objects in a virtual space occupied by the character .In addition , the various inputs allow the interface to track ( via video or sensor based equipment ) , or recognize where equipment is located .", "label": "", "metadata": {}, "score": "56.56958"}
{"text": "Document Avatars [ Bickmore97].These characters are attached to hypertext documents , and can be scripted to perform specific behaviors when certain parts of the document ( e.g. links ) are selected .Document avatars can be used to provide guided tours of a document , representing a particular reader 's viewpoint .", "label": "", "metadata": {}, "score": "56.5902"}
{"text": "Technique 10 may then progress to stop at step 40 .The various steps of technique 10 may be amended , altered , added to , removed , looped , etc . without departing from the spirit of the teachings .Moreover , a single entity and/or a combination of entities may perform steps of technique 10 .", "label": "", "metadata": {}, "score": "56.6071"}
{"text": "Context domain agents 230 may also be self - aware , assigning degrees of certainty to one or more generated hypotheses , where a hypothesis may be developed to account for variations in environmental conditions , speaker ambiguity , accents , or other factors .", "label": "", "metadata": {}, "score": "56.65248"}
{"text": "The function of the dialog manager 190 is to take as input the output of the NLU unit 130 , decide what task the user is trying to accomplish , decide what the system will say next , and update the discourse history .", "label": "", "metadata": {}, "score": "56.73311"}
{"text": "FIGS .7A , B , C and D which together comprise a flow diagram of the processing of the computer 1 in accordance with this embodiment of the present inventions .When the computer 1 is first activated the control module 20 causes ( S 7 - 1 ) a main control user interface to be displayed on the screen of the computer 1 .", "label": "", "metadata": {}, "score": "56.79457"}
{"text": "Apparatus in accordance with . claim 14 , wherein said testing unit is operable to enable user selection of sets of utterances comprising utterance data collected from the speakers from whom utterance data was utilized by said speech model generation unit to generate said speech models being tested .", "label": "", "metadata": {}, "score": "56.80326"}
{"text": "System 50 may take several forms .For example , system 50 may be an integrated solution - including multiple features and capabilities in a single device , having a common housing .System 50 may also take on a more decentralized architecture - where devices and functions are located remote from one another .", "label": "", "metadata": {}, "score": "56.88124"}
{"text": "A voice - enabled device 210 may receive a voice - based input and establish communications with advertising server 230 .Subsequently , advertising server 230 may select one or more advertisements from among the advertisements stored in data repository 260 , and the selected advertisements may be provided to the voice - enabled device for presentation to a user .", "label": "", "metadata": {}, "score": "56.91098"}
{"text": "In one embodiment , a behavior can be sent one of three commands at any given time : .ONCE - The initialization routine is called , after which the behavior will be incrementally updated on each following cycle until it reaches its logical termination , at which time it will begin its wrap - up routine and then terminate ( releasing the DOFs ) .", "label": "", "metadata": {}, "score": "56.918167"}
{"text": "Patent application number .Description .Published .LOW - RATE SAMPLING OF PULSE STREAMS - A method includes accepting an analog input signal that includes a sequence of pulses .The filter output is sampled so as to produce digital samples .", "label": "", "metadata": {}, "score": "56.934803"}
{"text": "The process returns to step 5200 wherein the recognizer 420 attempts to recognize portions of the second exchange with the user .Steps 5300 and 5400 are performed as before using the second exchange .If the probability of conducting a successful dialog does not exceed the predetermined threshold based on exchanges 1 and 2 , in step 5800 , the task classification processor 440 is instructed by the dialog manager 190 to route the user to a human assistant .", "label": "", "metadata": {}, "score": "56.956505"}
{"text": "The continuous style of control involves instructing the animation system at every update cycle ( e.g. , I 10 Hz or better ) which behaviors are to be kept running .For example , to move forward , commands \" WALK FORWARD \" , \" WALK FORWARD \" , etc . , are present over a series of consecutive update cycles until the character has reached its destination , at which time the commands simply stop being issued .", "label": "", "metadata": {}, "score": "56.962807"}
{"text": "In one embodiment , an action request may be an Action - Object request , which may include a statement indicating an action to be taken and an object related to that action .For example , a bill - paying request includes a \" Pay \" action coupled with a \" Bill \" object .", "label": "", "metadata": {}, "score": "56.978897"}
{"text": "ADD SPEAKER .ADD WORD .AMEND SET - UP .SAVE MODELS .After the project menu has been displayed ( S 7 - 3 ) a user then select one of the individual items from the menu using the pointer 109 under the control of the keyboard 3 or mouse 5 .", "label": "", "metadata": {}, "score": "56.989307"}
{"text": "5,675,707 , 5,860,063 and 6,044,337 , and U.S. patent application Ser .Nos .08/943,944 , 09/712,192 and 09/712,194 , as discussed above .In describing the invention , three classes of NLU outcomes are distinguished : RCORRECT , a correctly understood utterance ; RPARTIAL - MATCH , a partially understood utterance ; and RMISMATCH a misunderstood utterance .", "label": "", "metadata": {}, "score": "56.99391"}
{"text": "State information , including application domain knowledge , is logically separated into the static knowledge base 710 a , dynamic knowledge base 710 b , and discourse model 720 .Static Knowledge Base .The static KB encodes the domain knowledge that the character \" brings to the table \" when it starts a new user dialog .", "label": "", "metadata": {}, "score": "57.00228"}
{"text": "These devices can be either logical ( e.g. , a linear interpolator in the animation model representing a single degree of freedom ) or physical ( e.g. , the light settings in a conference room ) .When not performing an action , devices either remain in their current state or return to a default state .", "label": "", "metadata": {}, "score": "57.130558"}
{"text": "3 represents the structure of the conversation manager 28 in a preferred embodiment .Each of the functional modules , such as the semantic analysis module 50 , reasoning facility module 52 , language generation module 54 , and dialog manager 56 , are indicated by plain boxes without a bar across the top .", "label": "", "metadata": {}, "score": "57.160072"}
{"text": "In the automated task classification system 400 , services that the user can access are classified into a plurality of categories by a task classification processor or alternatively , to a category called other for calls that can not be automated and must be transferred to a human operator .", "label": "", "metadata": {}, "score": "57.36689"}
{"text": "Targeting engine 98 may also include logic that compares a calculated accuracy value for one or more utterance types against a threshold or acceptable accuracy level .If an utterance type suffers from an unacceptably low accuracy value , targeting engine 98 may output an indicator informing subsystem 82 of a need to train system 80 on that particular utterance type .", "label": "", "metadata": {}, "score": "57.367905"}
{"text": "The present invention includes a computer program product which is a storage medium ( media ) having instructions stored thereon / in which can be used to program a computer to perform any of the processes of the present invention .Such software may include , but is not limited to , device drivers , peripheral equipment programs , operating systems , and user applications .", "label": "", "metadata": {}, "score": "57.37629"}
{"text": "Existing systems suffer from these and other problems .SUMMARY OF THE INVENTION .According to various aspects of the invention , a system and method for selecting and presenting advertisements based on natural language processing of voice - based inputs is provided .", "label": "", "metadata": {}, "score": "57.424786"}
{"text": "In other embodiments , the script engine 38 is a Visual Basic , Javascript , or any other suitable scripting engine .The task manager 36 controls script execution through the script engine 38 .The task manager 36 provides the capability to proceed with multiple execution requests simultaneously , to queue up additional script commands for busy applications 26 , and to track the progress of the execution , informing the clients when execution of a script is in progress or has completed .", "label": "", "metadata": {}, "score": "57.541325"}
{"text": "Future actions , which are those that involve the planning of a sequence of actions , some or all of which are to be executed during a later update cycle , are sent to the response planner 620 for elaboration .The response planner 620 can return a plan ( sequence of actions ) to the reaction module , which the reaction module then caches for future reference .", "label": "", "metadata": {}, "score": "57.60318"}
{"text": "Fourth , for the classifier trained on all the features , the extent to which the error can be minimized on the error classes RMISMATCH and RPARTIAL - MATCH is examined by manipulating the rule - learning program 's loss ratio parameter .", "label": "", "metadata": {}, "score": "57.605453"}
{"text": "Prior to describing in detail data structures for data stored within the data set - up store 29 ; the word database 23 ; and the speaker database 24 , an overview of the use of the computer 1 to generate word models will be described with reference to .", "label": "", "metadata": {}, "score": "57.64592"}
{"text": "Referring to .FIG .3 , the lexicon 66 implements a dictionary of all the words known to the speech center system 20 .The lexicon 66 provides synonyms and parts of speech information for elements of the ontological description for the domain model 70 .", "label": "", "metadata": {}, "score": "57.66002"}
{"text": "User interfaces , including the above described synthetic characters , often exploit common metaphors , such as the desktop , in an attempt to make computer systems easier and more intuitive to use .These metaphors , however , are not always well understood by users , particularly novices , who often require extensive training .", "label": "", "metadata": {}, "score": "57.703987"}
{"text": "Input Devices .Input devices for the present invention include , but are not limited to , the following : .Speech recognizer : several commercial products exist .Best candidates include Dragon Systems Naturally Speaking , IBM 's ViaVoice , and Hauspie Speech Products ' Voice Xpress .", "label": "", "metadata": {}, "score": "57.70423"}
{"text": "A corpus of 21890 transcriptions ( from June 1998 through February 1999 ) was used for this purpose .This was reduced to 5162 sentences through preprocessing ( essentially replacement of tokens by class type ) then analyzed in order of frequency .", "label": "", "metadata": {}, "score": "57.884224"}
{"text": "Additionally , the model generation module 25 checks whether the gender balanced data 31 within the data set up store 29 identifies the requirement that the speakers be balanced in terms of gender or not .If this is the case , the model generation module 25 additionally checks whether an equal number of male and female speakers as indicated by the gender data 42 of the selected speaker records has been identified as to be used to generate a model .", "label": "", "metadata": {}, "score": "57.943447"}
{"text": "A template that matches the input is selected ( e.g. the template indexed by \" already - on(X ) \" would match the input \" already - on(vcr ) \" . )The empty slots ( e.g. X in the example above ) are filled in by matching against the input form ( X matches vcr ) , consulting the discourse model , and selecting an appropriate instantiation 1530 .", "label": "", "metadata": {}, "score": "57.969276"}
{"text": "10/618,633 , entitled \" Mobile Systems and Methods for Responding to Natural Language Speech Utterance , \" filed Jun. 15 , 2003 , which issued as U.S. Pat .No .7,693,720 on Apr. 6 , 2010 , both of which are hereby incorporated by reference in their entirety .", "label": "", "metadata": {}, "score": "57.97069"}
{"text": "For example , in the present invention 's architecture the user can point to a lighting fixture in a conference room and ask the character to \" turn on this light . \"Alternatively , the character may point to a lighting panel , or other object in the room and perhaps make comments on its use .", "label": "", "metadata": {}, "score": "58.03437"}
{"text": "- - Abstract ---- .The system goal is to simulate the restaurant - clerk behaviour .It . must be able to provide information and ask client questions . similarly to how a human clerk does .In addition we .", "label": "", "metadata": {}, "score": "58.13676"}
{"text": "To the extent that these objects and classes fit into the built - in domain model hierarchy , the existing grammatical constructs apply to them as well .So , if an application 26 provides an operation for , say , printing it could specify : . print is a kind of action .", "label": "", "metadata": {}, "score": "58.213478"}
{"text": "For example , although the cybergloves provide data which describes the current geometry of individual finger joints , Ymir cares only about the position of the hands in space .Similarly , although Ymir 's head - mounted eye tracker makes fine measurements of the user 's direction of gaze , the system is concerned only with gross approximations of where the user is looking .", "label": "", "metadata": {}, "score": "58.324604"}
{"text": "The reaction module 500 is responsible for the \" action selection \" component of the architecture , which determines at each moment in time what the character should be doing .Thus , this module can also be thought of as the \" executive \" of the system , which functions as the locus of control for the entire architecture .", "label": "", "metadata": {}, "score": "58.361984"}
{"text": "The static KB is realized as initialization data for the dynamic KB and domain - specific data for each of the modules .The dynamic KB is the working memory of the reaction module ( e.g. , the fact list in CLIPS / JESS ) ; sharing with the understanding , response planning and generation modules can be accomplished through a request / reply protocol .", "label": "", "metadata": {}, "score": "58.37564"}
{"text": "\" The speech center 20 uses the reasoning facility 52 ( to be described in more detail later ) to search through its available rules 86 to find one that states that it can create an appointment .Examining the rule description , the reasoning facility 52 of the speech center 20 finds that it calls a function which has the following parameters : a person , date , time , and place .", "label": "", "metadata": {}, "score": "58.413734"}
{"text": "claim 25 , further comprising determining a new accuracy value for the given type of utterance .Description .FIELD OF THE INVENTION .The present invention is generally related to speech - enabled applications , and more specifically to a system and method for targeted tuning of a speech recognition system .", "label": "", "metadata": {}, "score": "58.4413"}
{"text": "11/200,164 , an environmental model may be accessed to determine user location , user activity , track user actions , and/or other environmental information to invoke context , domain knowledge , preferences , and/or other cognitive qualities to enhance the interpretation of questions and/or commands .", "label": "", "metadata": {}, "score": "58.44871"}
{"text": "Furthermore , the interaction may be tracked to build statistical profiles of user behavior based on affinities or clusters among advertisements , user profiles , contexts , topics , semantic indicators , concepts , or other criteria .According to various aspects of the invention , advertisers may create advertisements , which may be stored in an advertisement repository .", "label": "", "metadata": {}, "score": "58.488586"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .It will be appreciated that for simplicity and clarity of illustration , elements illustrated in the Figures have not necessarily been drawn to scale .For example , the dimensions of some of the elements are exaggerated relative to other elements .", "label": "", "metadata": {}, "score": "58.60449"}
{"text": "The inferencing intended operations feature may identify an intended request from incomplete or ambiguous requests .Because the utterance includes the origination point and the destination point , a request to calculate a route from the user 's present location to Chicago may be inferred .", "label": "", "metadata": {}, "score": "58.68653"}
{"text": "Multimodal communications involve communications on a plurality of channels , such as aural , visual , etc .However , for ease of discussion , examples and discussions of the method and system of the invention will be discussed below in relation to telephone systems .", "label": "", "metadata": {}, "score": "58.688858"}
{"text": "On every following cycle the behavior will be incrementally updated .( Discrete - style behaviors , such as \" HANDS TO GESTURE SPACE \" will likely maintain their end position until the behavior is canceled . )END - The behavior immediately begins executing its wrap - up routine , after which it will terminate .", "label": "", "metadata": {}, "score": "58.69079"}
{"text": "Finally , selecting the end button 411 causes the details for the most recently recorded utterance to be displayed and sound output by the computer 1 .Thus in this way a user is able to review the waveforms of the recently captured utterances .", "label": "", "metadata": {}, "score": "58.70541"}
{"text": "Returning to .FIG .7A , if the control module 20 determines that the AMEND SET UP option has not been selected ( S 7 - 8 ) the control module ( S 7 - 10 ) determines whether the SAVE MODEL option has been selected .", "label": "", "metadata": {}, "score": "58.90879"}
{"text": "FIG .4 is a block diagram of the components of the reasoning facility 52 , according to a preferred embodiment of the invention .The central component of the reasoning facility 52 is the inference engine 96 .It is the active component in the reasoning system 52 .", "label": "", "metadata": {}, "score": "58.91181"}
{"text": "claim 24 , wherein said deliberative processing component includes , as part of said deliberative processing , . a multi - modal understanding component configured to generate an understanding of speech and associated non - verbal of said user inputs , .", "label": "", "metadata": {}, "score": "58.916054"}
{"text": "From dialogue corpus .we found out that clients usually use a small number of words in . their utterances ( communication client - clerk tends to be telegram- . like ) , therefore a system dictionary can be size - reduced .", "label": "", "metadata": {}, "score": "58.94187"}
{"text": "Dynamic Knowledge Base .The dynamic KB ( aka \" blackboard \" ) is the scratch memory used by the reaction , understanding , response planning and generation modules during a dialog .The dynamic KB maintains information such as a current location of a user , a current location of the character , and information identifying a point in a plan that relates to the current discourse between the user and character .", "label": "", "metadata": {}, "score": "58.941994"}
{"text": "2 ; .FIG .10 is an exemplary illustration of an amend set up data screen of the computer of .FIG .2 ; and .FIG .11 is an exemplary illustration of a record utterance screen of the computer of .", "label": "", "metadata": {}, "score": "59.015083"}
{"text": "Thus , by selecting an advertisement , indicating dissatisfaction with an advertisement , or otherwise interacting with an advertisement , the interaction may be used to build context and shared knowledge for a subsequent course of the conversation .For example , a user may select an advertisement , and an interpretation of a subsequent voice - based input ( e.g. , \" Call them , \" \" What 's the price range ? \" etc . ) may be interpreted with shared knowledge of the advertisement that the voice - based input relates to .", "label": "", "metadata": {}, "score": "59.01922"}
{"text": "The first of these is the rule base 84 , in which the internal representation of the rules are stored .The second is the memory 98 for the inference engine 96 , which stores the current set of beliefs .In one embodiment , the memory 98 is a data storage structure for the inference engine 96 , which is stored in a RAM ( random access memory ) or working memory associated with the digital processor 12 .", "label": "", "metadata": {}, "score": "59.098797"}
{"text": "As mentioned above , .FIG .2 shows one embodiment of a speech - enabled system 46 that incorporates teachings of the present disclosure .A caller from a location , such as location 52 , 54 , and/or 56 , may place a call to system 50 in an effort to receive , for example , information and/or some form of customer service .", "label": "", "metadata": {}, "score": "59.117085"}
{"text": "Gokhan Tur , Morris Plains , NJ US .Patent application number .Description .Published .SYSTEMS AND METHODS FOR REDUCING ANNOTATION TIME - Systems and methods for annotating speech data .The present invention reduces the time required to annotate speech data by selecting utterances for annotation that will be of greatest benefit .", "label": "", "metadata": {}, "score": "59.174572"}
{"text": "The process then proceeds to back to step 6050 , where the recognizer 120 receives the user 's input communication based on either the current dialog strategy or the adapted dialog strategy opted for in step 6450 .The process that continues similar to .", "label": "", "metadata": {}, "score": "59.291534"}
{"text": "Apparatus in accordance with .Apparatus in accordance with . claim 2 , wherein said third user interface is operable to display a waveform indicative of collected utterance data whilst said utterance data is being collected .Apparatus in accordance with .", "label": "", "metadata": {}, "score": "59.39328"}
{"text": "1 is a hierarchical chart of synthetic character types ; .FIG .2 is an interaction diagram illustrating interactions between a user , a system , and an ally ; .FIG .3 is an illustration of an example interaction with a conversational character ; .", "label": "", "metadata": {}, "score": "59.511715"}
{"text": "In another example , global statistical profiles may indicate that an advertisement experiences more click - throughs by users of a particular demographic , and therefore , the advertisement may be more likely to be selected for users falling within the demographic .", "label": "", "metadata": {}, "score": "59.618835"}
{"text": "For example , a user may utter , \" Get me the news \" and a voice user interface response may be \" Which of these categories ?Top news stories , international news , political news , or sports news ? \" The response may be likely to illicit utterances from the user , such as \" Top news stories \" or \" International news , \" which are more likely to result in a completed request .", "label": "", "metadata": {}, "score": "59.71444"}
{"text": "Goals are created in response to user requests , and may also be created by the inference engine 96 itself .A goal is a proposition that may contain a variable for one or more of its elements .The speech center system 20 then attempts to find or derive a match for that proposition , and find values for any variables .", "label": "", "metadata": {}, "score": "59.75183"}
{"text": "Accordingly , the tracking information may be used to bill or invoice advertisers 220 , as well as to improve subsequent performance and relevance of advertisements selected using advertisement selection module 250 .Other techniques and features of selecting and presenting advertisements based on voice - based inputs may suitably be employed , as would be apparent .", "label": "", "metadata": {}, "score": "59.864494"}
{"text": "The specification and drawings are to be regarded as exemplary only , and the scope of the invention is to be determined solely by the appended claims .User query generate search results that rank set of servers where ranking is based on comparing content on each server with user query , frequency at which content on each server is altered using web crawler in a search engine .", "label": "", "metadata": {}, "score": "59.887287"}
{"text": "For example , the reasoning facility 52 can disambiguate the name ( \" Jane \" ) , determine that the information is no longer ambiguous ( see step 104 ) , and fulfill the other goals by proceeding to step 112 .", "label": "", "metadata": {}, "score": "59.907967"}
{"text": "Above this layer of control are atomic procedures - behaviors - which move one or more DOFs incrementally over a number of update cycles to achieve an animation .There are fundamentally two styles of commanding behaviors : discrete and continuous .", "label": "", "metadata": {}, "score": "59.980415"}
{"text": "The interrogating also includes sending at least two probe tones into the optical fiber from another end of the optical fiber , such that a frequency spacing between the probe tones is different from the frequency spacing between the pump tones .", "label": "", "metadata": {}, "score": "60.00245"}
{"text": "claim 23 , further comprising recording the collection of recorded utterances as discrete audio files .The method of .claim 23 , further comprising ensuring that the selection of utterances does not include a different utterance type if the separate accuracy value for the different utterance type is at or above the accuracy threshold value .", "label": "", "metadata": {}, "score": "60.04722"}
{"text": "The system of . claim 17 , further comprising a call center that comprises the implemented speech - enabled application .The system of . claim 17 , further comprising a computer readable medium , wherein a set of instructions embodying the accuracy engine and the tuning engine are stored on the computer readable medium .", "label": "", "metadata": {}, "score": "60.12026"}
{"text": "Patent application number .Description .Published .Linguistic input is directed to machine translation components that translate such input from its language into the anchor language .Those existing linguistic components are then utilized to initiate responsive processing and generate output .", "label": "", "metadata": {}, "score": "60.242954"}
{"text": "The foundation domain model 70 contains a set of grammatical specifications that defines base classes such as numbers , dates , assertions , commands and questions .These specifications are preferably in an annotated form of Backus Naur Form ( BNF ) , that are further processed by the syntax manager 62 rather than being passed on directly to the speech engine interface 30 .", "label": "", "metadata": {}, "score": "60.30905"}
{"text": "Furthermore , additional advertisements may be selected in an operation 340 based on the interaction , using similar techniques as described in connection with operation 320 ( e.g. , advertisements for additional ringtones , similar musicians , etc . may be selected ) .", "label": "", "metadata": {}, "score": "60.32637"}
{"text": "While the training database 165 and the dialog history database 170 are shown as separate databases in the exemplary embodiments , the dialog history and training data may be stored in the same database or memory , for example .This database or memory may be stored external or internal to the system .", "label": "", "metadata": {}, "score": "60.330914"}
{"text": "This complete indicator comprises a check mark adjacent to each item of speaker data corresponding to a speaker record 40 including the required number of utterance records 45 for each of the words identified by word records 35 in the word database 23 .", "label": "", "metadata": {}, "score": "60.363983"}
{"text": "2 is a flowchart illustrating an exemplary NLU monitoring process ; .FIG .3 is a flowchart illustrating another exemplary NLU monitoring process using dialog strategy adaptation techniques ; .FIG .4 is a block diagram of an exemplary task classification system using a NLU monitoring system ; .", "label": "", "metadata": {}, "score": "60.60514"}
{"text": "A second method may include storing at least one set of data .Each one of the at least one set of data may include ones of the reusable components associated with audible data collected during a different collection phase .Method and Apparatus for Responding to an Inquiry - Disclosed is a method and apparatus for responding to an inquiry from a client via a network .", "label": "", "metadata": {}, "score": "60.765594"}
{"text": "Qs : Dead lgs , Natural lg . dialogue systems .We 'd like to remind readers that the responses to queries are usually best posted to the individual asking the question .That individual is then strongly encouraged to post a summary to the list .", "label": "", "metadata": {}, "score": "60.87539"}
{"text": "a confidence measure for all of the possible tasks that the user could be trying to do . salience - coverage , inconsistency , context - shift , top - task , nexttop - task , top - confidence , diff - confidence , confpertime , salpertime Dialog Manager and Discourse History Features . sys - LABEL , utt - id , prompt , reprompt , confirmation , sub - dial , . discourse history : num - reprompts , num - confirms , num - subdials , reprompt % , confirmation % , subdialog % .", "label": "", "metadata": {}, "score": "60.893753"}
{"text": "In various implementations , advertisements may be selected by assigning a score to each advertisement ( e.g. , based on click - through rates , relevance metrics , target audiences , etc . ) .As such , advertisement selection module 250 may correlate the information about the request to select advertisements stored in data repository 260 , and server 230 may communicate the selected advertisements to voice - enabled device 210 .", "label": "", "metadata": {}, "score": "60.97773"}
{"text": "In a frame , data relating to specific aspects of interactions between the user and character ( body position , or gaze direction , for example ) are maintained in a same location for fast access / reference .Slots of the frame are utilized to store the data or reference other frames or data structures holding the data .", "label": "", "metadata": {}, "score": "61.02354"}
{"text": "No .11/580,926 , entitled \" System and Method for a Cooperative Conversational Voice User Interface , \" filed Oct. 16 , 2006 , both of which are hereby incorporated by reference in their entirety .For example , as described in U.S. patent application Ser .", "label": "", "metadata": {}, "score": "61.035046"}
{"text": "Thus , as shown in .FIG .3 , taking action in operation 315 and selecting advertisements in operation 320 may be related operations ( e.g. , advertisements may be selected to help in interpreting incomplete and/or ambiguous requests ) .", "label": "", "metadata": {}, "score": "61.116673"}
{"text": "The modules 52 through 68 of the conversation manager 28 are described below .The message hub 68 includes message queue and message dispatcher submodules .The message hub 68 provides a way for the various modules 30 , 32 , 34 , 36 , 40 , 42 , and 50 through 64 to communicate asynchronous results .", "label": "", "metadata": {}, "score": "61.1532"}
{"text": "The user may then utter \" What about I-5 ? \" and context determination process 255 may know that the current context is Traffic , a traffic report including information about Interstate-5 may be searched for , and the traffic report indicating that Interstate-5 is crowded may be returned as an output .", "label": "", "metadata": {}, "score": "61.189247"}
{"text": "Alternatives in expression based on various criteria or demographics may be loaded into context domain agents 230 and/or vocabularies 235 , and the alternative expression feature may update context domain agents 230 and/or vocabularies 235 based on inferred or newly discovered variations .", "label": "", "metadata": {}, "score": "61.349373"}
{"text": "Acoustic models with 5000 tied states were trained using these trees , and the same data as used by Model 2 .This however did not appear to improve performance .Model 4 : We trained models 6000 state models in a standard fashion , using all Communicator data recorded through April 2000 .", "label": "", "metadata": {}, "score": "61.35362"}
{"text": "User query generate search results that rank set of servers where ranking is based on comparing content on each server with user query , frequency at which content on each server is altered using web crawler in a search engine .Dynamically updated search results based upon continuously - evolving search query that is based at least in part upon phrase suggestion , search engine uses previous result sets performing additional search tasks A system and method for selecting and presenting advertisements based on natural language processing of voice - based inputs is provided .", "label": "", "metadata": {}, "score": "61.38769"}
{"text": "claim 3 wherein accumulating the long - term shared knowledge about the user includes updating one or more long - term profiles associated with the user to include information about the utterance received during the current conversation and relevant data associated with the information expired from the short , term context stack .", "label": "", "metadata": {}, "score": "61.45125"}
{"text": "In a particular embodiment , the pulse analyzer can be configured to compare the ratio with a predetermined value and to identify the electrical pulse as a neutron - induced pulse when the ratio is at least the predetermined value .Gokham Tur , Denville , NJ US .", "label": "", "metadata": {}, "score": "61.54064"}
{"text": "Apparatus in accordance with . claim 1 , wherein said testing unit is operable to generate a user interface to enable a user to identify speech models generated by said speech model generation unit and to select utterance data stored by said utterance store and to test said identified models utilizing said selected utterances .", "label": "", "metadata": {}, "score": "61.545334"}
{"text": "Moreover , advertisement selection module 250 may account for where a request originates from .For instance , a user may request airline reservations via voice - enabled device 210 , and content / action identification module 235 may identify specific words used in the request , a category related to the request ( e.g. , travel , airlines , hotels , etc . ) , or other information .", "label": "", "metadata": {}, "score": "61.54653"}
{"text": "14 , which illustrates the interfaces with the reaction and generation modules , and storage of pending actions to be scheduled .In one embodiment , it is implemented in a procedural language such as C++ or Java .Since most output will be going to the animation rendering engine , the action scheduler and the animation rendering system may be integrated into the same executable .", "label": "", "metadata": {}, "score": "61.636864"}
{"text": "claim 11 wherein the language understanding monitor is further adapted to determine the probability using recognition data from the recognizer and understanding data from the language understanding unit derived from the user 's input communication .Description .CROSS - REFERENCE TO RELATED APPLICATIONS .", "label": "", "metadata": {}, "score": "61.745426"}
{"text": "Long - term and short - term shared knowledge ( collectively , shared knowledge 305 ) may be used simultaneously anytime a user engages in a cooperative conversation 300 .Long - term shared knowledge may include explicit and/or implicit user preferences , a history of most recently used agents , contexts , requests , tasks , etc . , user - specific jargon related to vocabularies and/or capabilities of an agent and/or context , most often used word choices , or other information .", "label": "", "metadata": {}, "score": "61.888702"}
{"text": "In yet another example , the advertisement may be selected based on a topic or category associated with the requested tasks / information ( e.g. , a request to purchase airline tickets may result in an advertisement being selected for a hotel in a destination associated with a reserved flight ) .", "label": "", "metadata": {}, "score": "61.973976"}
{"text": "Furthermore , the user 's subsequent interaction with an advertisement may be tracked using tracking module 255 .For example , tracking module 255 may determine whether a conversion or click - through occurs for each advertisement presented to users .Further , tracking module 255 may maintain accounting and/or billing information associated with advertisers 220 .", "label": "", "metadata": {}, "score": "62.027584"}
{"text": "When the user is speaking and The character wants the turn she looks at the user and utters a paraverbal ( \" umm \" ) .When The character is finished speaking and ready to give the turn back to the user she looks at the user , drops her hands out of gesture space and raises her eyebrows in expectation .", "label": "", "metadata": {}, "score": "62.031364"}
{"text": "For example , user utterances of \" Change it to the Squizz \" and \" You know , um , that Squizz channel , ah , switch it there \" may be treated equivalently ( where Squizz is a channel on XM Satellite Radio ) .", "label": "", "metadata": {}, "score": "62.04403"}
{"text": "Advertisements may be selected in relation to a request based on various criteria .For example , an advertisement may be selected based on words or other content of the request , relevant words or content related to the words or content of the request , etc .", "label": "", "metadata": {}, "score": "62.133102"}
{"text": "Effective date : 20150709 .Free format text : CORRECTIVE ASSIGNMENT TO CORRECT THE CHANGE PATENT 7146987 TO 7149687 PREVIOUSLY RECORDED ON REEL 036009FRAME 0349 .ASSIGNOR(S ) HEREBY CONFIRMS THE ASSIGNMENT;ASSIGNOR : INTERACTIONS LLC;REEL / FRAME:037134/0712 LINGUIST List 8.547 .", "label": "", "metadata": {}, "score": "62.152557"}
{"text": "The apparatus of .claim 7 , wherein the reasoning facility generates the computer application program command based on the utterance representation and based on the analysis of the ambiguous information .The apparatus of .claim 7 , wherein each goal - directed rule comprises a set of conditions and a set of actions , each condition consisting of a first proposition or a first script command and each action consisting of a second proposition or a second script command .", "label": "", "metadata": {}, "score": "62.30136"}
{"text": "\" The reasoning facility receives an utterance representation 21 based on the spoken utterance 14 \" open the message from Jane .\" The reasoning facility 52 sets a goal to open the message and attempts to achieve the prerequisites for making a call to select the message based on the message ID ( identifier ) .", "label": "", "metadata": {}, "score": "62.36662"}
{"text": "claim 1 , wherein the speech - enabled application executes at a voice activated services platform .The method of .claim 1 , wherein the speech - enabled application executes in connection with a call center .The method of .", "label": "", "metadata": {}, "score": "62.47151"}
{"text": "They are free to call upon services provided by other modules ( such as 30 , 32 , 34 , 36 , 40 , 42 , 52 , 54 , 56 , 58 , 60 , 62 , 64 or 66 ) when appropriate .", "label": "", "metadata": {}, "score": "62.51316"}
{"text": "A more complete appreciation of the invention and many of the attendant advantages thereof will be readily obtained as the same becomes better understood by reference to the following detailed description when considered in connection with the accompanying drawings , wherein : .", "label": "", "metadata": {}, "score": "62.640568"}
{"text": "As such , servicing the request may include generating a response and/or communicating with an advertising application to advance a conversation toward a serviceable request .For example , servicing the request in operation 315 and selecting an advertisement in operation 320 may include generating a response and/or selecting an advertisement to frame a subsequent user input , thereby advancing the conversation .", "label": "", "metadata": {}, "score": "62.66707"}
{"text": "The system monitors the frequency and pattern of rejection and uses this information to modify its strategy for interaction .The parse result is treated as a set of concepts that individual handlers on the agenda consume .Once matched , the concepts are either used directly ( i.e. , to set a target value ) or are first transformed through a call to a domain agent .", "label": "", "metadata": {}, "score": "62.689236"}
{"text": "The conversation manager 28 is the central component of the speech center 20 that integrates the information from all the other modules 30 , 32 , 34 , 36 , 38 , 40 , 42 .In a preferred embodiment , the conversation manager 28 is not a separate component , but is the internals of the speech center 20 .", "label": "", "metadata": {}, "score": "62.748596"}
{"text": "The reaction module sends the response planner a frame which represents a request for an action which requires a sequence of future actions to satisfy , along with a priority and time deadline .The Response Planner returns either a plan , represented by a sequence of time - tagged actions , or a notification that a plan could not be formed .", "label": "", "metadata": {}, "score": "62.7499"}
{"text": "The named entities may be obtained from one or more sources and include an initial list of named entities .A search may be performed within one or more search engines to determine common phrases that are used to identify the named entity in addition to the named entity initially included in the named entity list .", "label": "", "metadata": {}, "score": "62.76747"}
{"text": "10/452,147 , entitled \" Systems and Methods for Responding to Natural Language Speech Utterance , \" filed Jun. 3 , 2003 , which issued as U.S. Pat .No .7,398,209 on Jul. 8 , 2008 , and U.S. patent application Ser .", "label": "", "metadata": {}, "score": "63.135483"}
{"text": "3 ) .In alternate embodiments , the propagated signal is an analog carrier wave or digital signal carried on the propagated medium .For example , the propagated signal may be a digitized signal propagated over the Internet or other network .", "label": "", "metadata": {}, "score": "63.22218"}
{"text": "The reasoning facility 52 determines that it must set a subgoal based on a rule 86 of determining the message ID for a person ( e.g. , \" Jane \" ) .In step 104 , the reasoning facility 52 determines that there is ambiguous information ( e.g. , \" Jane \" ) , and in step 106 , the reasoning facility 52 attempts to resolve the ambiguity through records or data available to it .", "label": "", "metadata": {}, "score": "63.30168"}
{"text": "The script engine 38 provides the following capabilities : The script engine 38 supports cross - application scripting via OLE ( Object Linking and Embedding ) automation or through imported DLL 's ( Dynamic Link Libraries ) .It is capable of executing arbitrary strings representing well formed script engine 38 statements .", "label": "", "metadata": {}, "score": "63.34183"}
{"text": "The base syntax specification contained in the foundation domain model 70 defines a class of simple , natural language - like sentences that specify how these classes are linked together to form assertions , questions , and commands .For example , given that classes are defined as basic concepts , a simple form of a command is as follows : . template command(action ) .", "label": "", "metadata": {}, "score": "63.349876"}
{"text": "Frame to attribute - object - value triple translation is mostly a matter of filling in references to containing frames .These triples are stored in memory , and provide the raw material upon which the reasoning facility 52 operates .A sentence such as \" make this column green \" would be translated to a frame structure by a series of calls like these : .", "label": "", "metadata": {}, "score": "63.386692"}
{"text": "Each command will be executed once , or in part , if at all , on the first update cycle in which its event expression evaluates to true .Example event expressions : .IMMEDIATE Do it now .( on : event 14:01:32.143 )", "label": "", "metadata": {}, "score": "63.41176"}
{"text": "1 shows a personal computer 1 Which may be programmed to operate an embodiment of the present invention .A keyboard 3 , a mouse 5 , a microphone 7 and a telephone line 9 are connected to the PC 1 via an interface 11 .", "label": "", "metadata": {}, "score": "63.423298"}
{"text": "5 is a schematic representation of data stored within the word database 23 .In this embodiment of the present invention data within the word database 23 is stored as a plurality of word records 35 .Together the word records identify the potential vocabulary for which utterances may be collected and subsequently for which word models may be generated .", "label": "", "metadata": {}, "score": "63.49158"}
{"text": "Clarisse Tur , Cleveland , OH US .Patent application number .RADIATION DETECTOR AND METHOD OF USING A RADIATION DETECTOR - A radiation detector can include a scintillating material to produce scintillation light in response to receiving neutrons , gamma radiation , potentially other targeted radiation , or any combination thereof .", "label": "", "metadata": {}, "score": "63.802814"}
{"text": "Of the latter three are deemed closed with respect to the domain ( e.g. , holidays , ordinal numbers ) .There is a total of 1573 words in the class component of the language model .A key issue in managing the knowledge base as a whole is coordinating modifications that impact different components of the base .", "label": "", "metadata": {}, "score": "63.825912"}
{"text": "If the stop button 409 is not selected the data collection module 22 then ( S 7 - 23 ) determines whether the utterance which has been recorded is the last utterance on the required list of utterances .The pointer 421 is then caused to be displayed against to the speak freely instruction 420 and the waveform window 407 is cleared .", "label": "", "metadata": {}, "score": "63.90341"}
{"text": "Effective use of corpora , however , requires developing techniques that intelligently make use of ( typically ) limited domain - specific resources .THE CMU COMMUNICATOR .The Carnegie Mellon Communicator [ 8 ] is a telephone - based dialog system that supports planning in a travel domain .", "label": "", "metadata": {}, "score": "64.06477"}
{"text": "The output may indicate a result of the action associated with operation 315 .Furthermore , the output may include advertisements , as selected in operation 320 .For example , the output may include text - based , graphic - based , video - based , audio - based , or other types of advertisements , as would be apparent to those skilled in the art .", "label": "", "metadata": {}, "score": "64.13844"}
{"text": "The goal of finding the date will result in the location of another rule 86 which invokes a function that can calculate a date based on the relative date \" tomorrow \" information .The goal of finding a person results in the location of a rule 86 that will invoke a function which will attempt to disambiguate a person 's full name from their first name .", "label": "", "metadata": {}, "score": "64.19237"}
{"text": "restaurants .It may be considered a rule - based expert . system whose behaviour is decided from a recorded dialogue .corpus obtained at a real restaurant .The system is quite developed .at the moment , though it needs some improvement to enhance the level . of understanding and naturalness .", "label": "", "metadata": {}, "score": "64.20398"}
{"text": "The method and apparatus receive the inquiry from a client via a network .Based on the inquiry , question - answer pairs retrieved from the network are analyzed to determine a response to the inquiry .The QA pairs are not predefined .", "label": "", "metadata": {}, "score": "64.34694"}
{"text": "Model 2 represents a significant improvement in accuracy .Table 1 .WER obtained using different acoustic models .Model 3 : It was observed that the performance of Model 1 on tracking test sets had steadily deteriorated in the Fall of 1999 , due in part to a noisier signal .", "label": "", "metadata": {}, "score": "64.397865"}
{"text": "The microphone 7 converts the acoustic speech signal of the user into an equivalent electrical signal and supplies this to the PC 1 for processing .An internal modem and speech receiving circuit ( not shown ) may be connected to the telephone line 9 so that the computer 1 can communicate with , for example , a remote computer or with a remote user .", "label": "", "metadata": {}, "score": "64.44551"}
{"text": "The data collection module 22 then proceeds to delete all of the utterance records 45 having word numbers 47 corresponding to word numbers 37 of word records 35 including a selected flag 39 indicating a selected status .Finally , the data collection module 22 deletes all the word records 35 from the word database 23 where the word records 35 include a selected flag 39 indicating a selected status .", "label": "", "metadata": {}, "score": "64.49225"}
{"text": "3 , in which the character is explaining how to control the room lighting from a panel display on the podium .Instead of having to read a help menu or other pre - scripted response , the user is interacting with the character which works with the user to solve the problem at hand .", "label": "", "metadata": {}, "score": "64.622116"}
{"text": "The ontology 64 represents the classes of interest in the domain model 70 and their relationships to one another .Classes may be defined as being subclasses of existing classes , for example .Attributes can be defined for particular classes , which associate entities that are members of these classes with other entities in other classes .", "label": "", "metadata": {}, "score": "64.635635"}
{"text": "Apparatus in accordance with . claim 1 , further comprising : . a vocabulary database operable to store word data indicative of one or more words ; and .a speaker database operable to store speaker data indicative of speakers from whom utterance data is to be collected , . wherein said data collection unit is operable : . to generate a first user interface to enable user input of speaker data for storage in said speaker database ; . to generate a second user interface to enable user input of word data for storage in said vocabulary database ; and .", "label": "", "metadata": {}, "score": "64.68087"}
{"text": "claim 1 , wherein determining the intended meaning for the utterance further includes : . identifying a conversational goal associated with the utterance , roles associated with the user and one or more other participants in the current conversation , and an information allocation among the user and the one or more other participants in the current conversation ; and .", "label": "", "metadata": {}, "score": "64.837715"}
{"text": "The method of .The method of .claim 1 , wherein the plurality of utterances comprises an accumulation of utterances received via a deployed speech - enabled application , further wherein the portion of the plurality of utterances comprises all of the accumulation of utterances .", "label": "", "metadata": {}, "score": "65.04476"}
{"text": "The Carnegie Mellon Communicator is a telephone - based dialog system that supports planning in a travel domain .The implementation of such a system requires two complimentary components , an architecture capable of managing interaction and the task , as well as a knowledge base that captures the speech , language and task characteristics specific to the domain .", "label": "", "metadata": {}, "score": "65.117096"}
{"text": "System and method for selecting and presenting advertisements based on natural language processing of voice - based input US 8145489 B2 .Abstract .A system and method for selecting and presenting advertisements based on natural language processing of voice - based inputs is provided .", "label": "", "metadata": {}, "score": "65.14975"}
{"text": "claim 1 , wherein determining that the speech - enabled application more accurately responds to the first type of utterance comprises : . calculating a system hit rate for the first type of utterance , wherein the system hit rate for the first type of utterance reflects how often the at least one speech - enabled application applied a first type interpretation to a received first type utterance ; and . calculating a system hit rate for the second type of utterance .", "label": "", "metadata": {}, "score": "65.1537"}
{"text": "The method of .claim 1 , wherein the updated personalized cognitive model , the updated generalized cognitive model , and the updated environmental model provide statistical profiles to select one or more subsequent advertisements in response to the subsequent natural language utterance .", "label": "", "metadata": {}, "score": "65.197014"}
{"text": "The method further includes communicating a subset of the digitized ultrasound data for at least some of the plurality of transmit events , wherein the subsets of communicated digitized ultrasound data are different for the plurality transmit events .Ronen Tur , Binyamina IL .", "label": "", "metadata": {}, "score": "65.35856"}
{"text": "Microsoft Agent [ Microsoft97].These characters can be scripted to speak a text string , perform specific animation sequences , hide , move and resize .The user interacts with a character by dragging it or selecting commands from a pop - up menu .", "label": "", "metadata": {}, "score": "65.36229"}
{"text": "FIG .2 , an exemplary advertising system 200 is illustrated according to various aspects of the invention .System 200 may include a server 230 for receiving one or more advertisements from an advertiser 220 , wherein the advertisements may be stored in a data repository 260 associated with server 230 .", "label": "", "metadata": {}, "score": "65.4032"}
{"text": "The user may decide at that point to call Rich Kennewick later , and instead , listen to some music .In this example , the later utterance has no contextual connection to the first utterance , yet because request criteria in the utterances are unambiguous , contexts can be switched easily without relying on the context stack .", "label": "", "metadata": {}, "score": "65.41263"}
{"text": "At this point the waveform appearing within the waveform window 407 will comprise a waveform for the complete utterance that has been recorded .By pausing and determining whether the stop button 409 has been selected , the data collection module 22 provides a brief period for a user to review the waveform to determine whether it is satisfactory or unsatisfactory .", "label": "", "metadata": {}, "score": "65.41312"}
{"text": "Accuracy engine 96 may use retrieved information to determine if an assigned utterance type for a given captured utterance represents an accurate interpretation of the given captured utterance .Information representing accuracy engine 96 's analysis may be transferred to targeting engine 98 .", "label": "", "metadata": {}, "score": "65.586205"}
{"text": "The advertisement repository may be associated with a server , where in response to a voice - based input from a user ( e.g. , at a voice - enabled device ) , a communications link may be established with the server .", "label": "", "metadata": {}, "score": "65.58729"}
{"text": "Vicente R. Tur , Barcelona ES .Patent application number .Description .Published .TNF Family Ligand Variants - The present invention relates to variants of TNF family ligands which have been mutated at the ligand trimerisation interface so that they are not capable of assembling into trimers , and either assemble into dimers or remain as monomers .", "label": "", "metadata": {}, "score": "65.5938"}
{"text": "The method of .claim 1 , wherein the tracked interaction pattern associated with the advertisement includes information associated with a subsequent request in which the electronic device interacts with the advertisement .The method of .claim 4 , wherein the subsequent request in which the electronic device interacts with the advertisement includes the electronic device initiating a task or initiating a query relating to the advertisement .", "label": "", "metadata": {}, "score": "65.64635"}
{"text": "EndRule .Rules 86 such as this are effectively machine - readable documentation for the script call that it contains .The rule 86 specifies the prerequisites for making the call , the call to make , and the effects that will result if the call is made .", "label": "", "metadata": {}, "score": "65.742615"}
{"text": "If this is the case the control module 20 then causes ( S 7 - 7 ) the data collection module 22 to generate a new word record 35 which is stored within the word database 23 .Initially the new word record comprises the next available word number 37 , a blank word identifier 38 and a null selected flag 39 .", "label": "", "metadata": {}, "score": "65.83003"}
{"text": "In one embodiment , the domain model 70 is a foundation model including base knowledge common to many applications 26 .In a preferred embodiment , the domain 70 is extended to include application specific knowledge in an application domain model for each external application 26 .", "label": "", "metadata": {}, "score": "65.86008"}
{"text": "Ymir requires users to wear cumbersome hardware , including a body tracking jacket , cybergloves , and a head - mounted eye tracker .These devices detract from the naturalness of the user 's interaction , and also must be recalibrated for each user , a process that can take several minutes .", "label": "", "metadata": {}, "score": "66.10376"}
{"text": "Input device 105 may include any suitable device , or combination of devices , for receiving a voice - based input ( e.g. , a microphone ) .In various implementations , input device 105 may include a multi - modal input , such as a touch - screen interface , keypad , or other input .", "label": "", "metadata": {}, "score": "66.11388"}
{"text": "This interface 34 allows applications 26 to load custom grammars , or define task specific vocabulary .The external application interface 34 also allows applications 26 to explicitly tap into the speech center 20 for speech recognition and synthesis services .The application model interface 42 provides models for applications 26 communicating with the speech center 20 .", "label": "", "metadata": {}, "score": "66.50424"}
{"text": "Examples of such systems are shown in U.S. Pat .Nos .5,675,707 , 5,860,063 , 6,044,337 , and 6,173,261 , and U.S. patent application Ser .Nos .08/943,944 , filed Oct. 3 , 1997 , 09/699,494 , 09/699,495 , and 09/699,496 all filed .", "label": "", "metadata": {}, "score": "66.66353"}
{"text": "U3: It is a wrong number .S4 : What was the number that you dialed ?The sys - label feature is intended to capture the fact that some tasks may be harder than others .The utt - id feature is motivated by the idea that the length of the dialog may be important , possibly in combination with other features like sys - label .", "label": "", "metadata": {}, "score": "66.701355"}
{"text": "The system of .claim 9 , wherein the tracked interaction pattern associated with the advertisement includes information associated with a subsequent request in which the electronic device interacts with the advertisement .The system of .claim 12 , wherein the subsequent request in which the electronic device interacts with the advertisement includes a task that the electronic device initiated or a query that the electronic device initiated in relation to the advertisement .", "label": "", "metadata": {}, "score": "66.73349"}
{"text": "DISCUSSION .The Carnegie Mellon Communicator system has provided a framework for experimenting with domain - specific , corpus - driven knowledge base configuration at different levels of a spoken dialog system .ACKNOWLEDGEMENTS .We would like to thank Maxine Eskenazi and Karin Gregory for their work in managing corpus collection and transcription , as well as lexicon maintenance .", "label": "", "metadata": {}, "score": "66.82639"}
{"text": "Patent application number .Description .Published .Sweep - Free Stimulated Brillouin Scattering - Based Fiber Optical Sensing - Methods and systems used to perform sweep - free stimulated Brillouin scattering - based fiber optical sensing are described .In one aspect , a method includes interrogating different parts of a Brillouin gain spectrum using multiple optical tones in an optical fiber .", "label": "", "metadata": {}, "score": "66.84235"}
{"text": "claim 1 , further comprising : . generating multiple preliminary interpretations of the utterance at a speech recognition engine coupled to the voice input device and the conversational speech engine , wherein an initial interpretation of the utterance comprises one of the multiple preliminary interpretations having a highest confidence level ; and .", "label": "", "metadata": {}, "score": "66.85385"}
{"text": "Gokhan Tur , Fremont , CA US .Patent application number .METHOD AND APPARATUS FOR TAILORING THE OUTPUT OF AN INTELLIGENT AUTOMATED ASSISTANT TO A USER - The present invention relates to a method and apparatus for tailoring the output of an intelligent automated assistant .", "label": "", "metadata": {}, "score": "66.893456"}
{"text": "User advertisement interaction may be tracked in an operation 345 .For example , operation 345 may track historical data about users , conversations , topics , contexts , or other criteria to associate information with the selected advertisement .The tracking information may therefore be used to build statistical profiles defining affinities , click - through or conversion rates , or other information about various advertisements , topics , or other criteria on a user - specific and/or a global - user level .", "label": "", "metadata": {}, "score": "66.949814"}
{"text": "Further , the advertising application may select an appropriate advertisement in operation 320 , where the advertisement may be selected in an attempt to advance the conversation towards the goal .For example , statistical profiles ( e.g. , user profiles , global profiles , topic - based profiles , etc . ) may reflect an affinity between an advertisement for a particular museum and other users sharing similar demographics or other characteristics with the requesting user .", "label": "", "metadata": {}, "score": "67.07822"}
{"text": "The diagram illustrates one example of the interactions between a user , a system , and an ally .Dark lines represent the parts of the system to which the user has direct access .A density of the arrow between the user and the ally indicates the bandwidth of their interactions with respect to the number of modalities they can communicate with .", "label": "", "metadata": {}, "score": "67.29319"}
{"text": "Returning to .If this is the case , in this embodiment , this causes the control module 20 to display ( S 7 - 3 ) a project menu in the form of a drop - down menu beneath the project button 101 .", "label": "", "metadata": {}, "score": "67.40989"}
{"text": "Fax : +34 - 58 - 243230 .Dear LINGUIST colleagues : .I am a PhD student and a researcher in the Department of .Electronics and Computer Technology at the University of Granada .I am working on a natural language dialogue system that aims to .", "label": "", "metadata": {}, "score": "67.43408"}
{"text": "Another candidate is Java3D. An interim candidate for simple 2D rendering which can be overlaid onto any Windows application is Microsoft Agent .Another possibility is Protozoal 's \" Alive \" Real - Time 3-D animation system .Speech synthesizer : candidates include TrueTalk , AccuVoice , and DECTalk .", "label": "", "metadata": {}, "score": "67.482285"}
{"text": "The top hypothesis produced by the decoder is processed by the Phoenix parser using a domain - specific semantic grammar ( based on ATIS [ 2 ] but extended to cover Communicator - specific language ) .The resulting parse is evaluated for coherence then passed to the Agenda dialog manager [ 9 ] .", "label": "", "metadata": {}, "score": "67.49744"}
{"text": "11 is an exemplary illustration of a record utterance screen in accordance with this embodiment of the present invention .The record utterance screen 400 comprises a speaker window 401 ; a word window 402 , a prompt window 403 , a waveform window 407 , a set of control buttons 408 - 413 and a pointer 415 .", "label": "", "metadata": {}, "score": "67.51936"}
{"text": "The recognizer 120 and the NLU unit 130 are shown as separate units for clarification purposes .However , the functions of the recognizer 120 and the NLU unit 130 may be performed by a single unit within the spirit and scope of this invention .", "label": "", "metadata": {}, "score": "67.57332"}
{"text": "Advertisers 220 may upload targeted advertisements to server 230 via advertiser interface 245 , and server 230 may store the advertisements in data repository 260 .The advertisements may include graphically - based advertisements that include banners , images , audio , video , or any suitable combination thereof .", "label": "", "metadata": {}, "score": "67.692"}
{"text": "The system of .claim 9 , wherein the updated personalized cognitive model , the updated generalized cognitive model , and the updated environmental model provide statistical profiles to select one or more subsequent advertisements in response to the subsequent natural language utterance .", "label": "", "metadata": {}, "score": "67.75224"}
{"text": "Field of the Invention .This invention relates to human - computer interfaces ( HCI ) .The invention is more particularly related to the interaction of a user and an animated anthropomorphic character as an HCI .The invention is even more particularly related to architecture for building the anthropomorphic character .", "label": "", "metadata": {}, "score": "67.75807"}
{"text": "7,640,160 on Dec. 29 , 2009 and U.S. patent application Ser .No .11/212,693 , entitled \" Mobile Systems and Methods of Supporting Natural Language Human - Machine Interactions , \" filed Aug. 29 , 2005 , both of which are hereby incorporated by reference in their entirety .", "label": "", "metadata": {}, "score": "68.07682"}
{"text": "Resource contention is handled through command priorities ; a command to start a behavior can specify a priority ( default zero ) which is assigned to the behavior once running .A subsequent command with a higher priority which needs one of the DOFs owned by the running behavior will preempt the running behavior , causing it to terminate .", "label": "", "metadata": {}, "score": "68.260475"}
{"text": "Others with whom I have discussed this matter have assumed that a \" dead language \" is one that is no longer used as an everyday means of communication .Sanskrit thus appears to be not entirely dead .On the other hand , it does n't appear to have an autonomous life of its own , independent of the prescriptive power of experts like the pandits [ behind whom stands , with awesome authority , that great grammarian Panini , our first linguist].", "label": "", "metadata": {}, "score": "68.357796"}
{"text": "Participant roles may broadly include : ( 1 ) a leader that controls a conversation , ( 2 ) a supporter that follows the leader and provides input as requested , and/or ( 3 ) a consumer that uses information .The other participant may hold the information and may support the leader by providing the information .", "label": "", "metadata": {}, "score": "68.36978"}
{"text": "Inputs arrive with absolute time stamps and probabilities ; outputs are formulated with event - based specifications and priorities .Example .The following are example values for a behavior commact/ : output attribute .Action deadlines ( i.e. , if an action can not be performed by a deadline , then it is never performed ) .", "label": "", "metadata": {}, "score": "68.443924"}
{"text": "Features based on information that the dialog manager 190 logged about its decisions or features representing the on - going history of the dialog might also be useful predictors of NLU errors .Some of the potentially interesting dialog manager 190 events arise due to low NLU confidence levels computed by the NLU monitor 180 that lead the dialog manager 190 to reprompt the user or confirm its understanding .", "label": "", "metadata": {}, "score": "68.48577"}
{"text": "At the same time the speech waveform for the signal received from the microphone 7 starts being displayed within the waveform window 417 .After a brief delay the arrow 421 moves next to the instruction say and the speech bubble 422 is updated to display the word identifier of the word and utterance of which is currently being recorded .", "label": "", "metadata": {}, "score": "68.52334"}
{"text": "The model generation module 25 then prompts ( S 7 - 30 ) a user to make a selection of speakers .This is achieved by the user controlling the pointer 109 to select speaker names within the speaker window 107 .", "label": "", "metadata": {}, "score": "68.57138"}
{"text": "Specifically , the items of data corresponding to records containing selected flags 39 ; 44 identifying the record as being selected are highlighted .Thus in this way a user is able to identify one or more items of speaker data which are to be utilized when performing certain other operations as will be described later .", "label": "", "metadata": {}, "score": "68.64388"}
{"text": "END : cmd end content B 2 L ) ] .Speech with deictic gesture : . [( action : i d B 1 : when immediate : cmd once .: content ( speech content \" The tape player is . in the podium . \" ) ) ( action : when B 1 .", "label": "", "metadata": {}, "score": "68.70009"}
{"text": "Technologies include motion capture ( magnetic and resistive , using a body suit , both commercially - available ) and vision - based systems .Gaze direction sensor ( \" eye tracker \" ) : several commercial products exist for fixed - head application ; The MIT Media Lab is working on a vision - based eye - tracking system .", "label": "", "metadata": {}, "score": "68.78631"}
{"text": "In a particular embodiment , the pulse analyzer can be configured to compare the ratio with a predetermined value and to identify the electrical pulse as a neutron - induced pulse when the ratio is at least the predetermined value .Clarisse Tur , Copley , OH US .", "label": "", "metadata": {}, "score": "68.99142"}
{"text": "Simultaneously the waveform appearing within the waveform window 407 is continuously updated to correspond to the captured audio signal to provide a visual feedback that the microphone 7 is indeed capturing the spoken utterance .When the microphone has been operating for the period of time identified by the length of speech data 32 within the data set up store 29 the arrow 421 moves adjacent to the second stay quiet instruction and the speech bubble 422 again is made blank .", "label": "", "metadata": {}, "score": "69.04062"}
{"text": "future we would like to improve it by including product - pictures and .graphics of the \" artificial \" restaurant - clerk face , in order to . improve a friendly communication .We think the integration of the system in a voice - controlled . response system represents its best application .", "label": "", "metadata": {}, "score": "69.296974"}
{"text": "Propositional understanding fuses the speech string with information from the user 's gesture to create a frame for the user 's query ( something like \" ( ASK ( BE JUPITER ) ) \" ) , forwards it to the reaction module and updates the discourse model .", "label": "", "metadata": {}, "score": "69.52747"}
{"text": "Devices 58 , 60 , and 62 may be , for example , POTS telephones , voice over IP telephones , computers , cellular telephones , wireless devices , and/or some other device capable of initiating the communication of information via a network .", "label": "", "metadata": {}, "score": "69.803955"}
{"text": "Reaction module issues an immediate \" attention \" action to the action scheduler to show that KUMO is listening .Action scheduler issues commands to the animation renderer to make KUMO look at the user and raise his eyebrows .The speech recognizer outputs \" Is that Jupiter \" to input manager .", "label": "", "metadata": {}, "score": "70.017365"}
{"text": "To the right of the list of actions 420 is a speech bubble 422 .Initially the speaker window 401 and word window 402 display the speaker name 41 and word identifier 38 of the first speaker and word which is to be recorded .", "label": "", "metadata": {}, "score": "70.13745"}
{"text": "According to one aspect of the invention , shared knowledge 305 includes both short - term and long - term knowledge about incoming data .Short - term knowledge may accumulate during a single conversation , while long - term knowledge may accumulate over time to build user profiles , environmental profiles , historical profiles , cognitive profiles , etc . .", "label": "", "metadata": {}, "score": "70.162506"}
{"text": "In addition to providing interface 245 for advertisers , server 230 may include a content / action identification module 235 , a user profile module 240 , an advertisement selection module 250 , and a tracking module 255 .Users may submit voice - based requests to voice - enabled device 210 , and voice - enabled device 210 may communicate information about the voice - based input to server 230 .", "label": "", "metadata": {}, "score": "70.28942"}
{"text": "Thanks again .Sincerely , .Ramon Lopez - Cozar Delgado .A cooperative conversational voice user interface is provided .The cooperative conversational voice user interface may build upon short - term and long - term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance .", "label": "", "metadata": {}, "score": "70.44998"}
{"text": "( action : when ( before : event 14:01:32.143 ) : cmd once : content ( . . . ) ) ] .( action : i d B 2 R : when ( on : event B 1 .START ) : cmd cont .", "label": "", "metadata": {}, "score": "71.11407"}
{"text": "The detector can be configured to distinguish between neutrons and gamma rays .The scintillating material can extend over a length greater than approximately 1.1 meters .In an embodiment , the radiation detector can be used near a passageway to detect radioactive material passing through the passageway .", "label": "", "metadata": {}, "score": "71.45483"}
{"text": "Description .Published .RADIATION DETECTION SYSTEM AND METHOD OF ANALYZING AN ELECTRICAL PULSE OUTPUT BY A RADIATION DETECTOR - A radiation detection system can include a photosensor to receive light from a scintillator via an input and to send an electrical pulse at an output in response to receiving the light .", "label": "", "metadata": {}, "score": "71.48638"}
{"text": "RELATED APPLICATIONS .This application claims the benefit of U.S. Provisional Application No .60/261,372 , filed Jan. 12 , 2001 .This application is related to U.S. application Ser .The entire teachings of the above applications are incorporated herein by reference .", "label": "", "metadata": {}, "score": "71.62628"}
{"text": "For example , a user may request information about restaurants , and an advertisement may be selected based on a user preference indicating a favorite type of restaurant ( e.g. , a Chinese restaurant may be selected based on a user profile indicating a preference for Chinese ) .", "label": "", "metadata": {}, "score": "71.666855"}
{"text": "claim 9 wherein the conversational language processor is further configured to use the tracked interaction pattern associated with the advertisement to resolve the request in response to the natural language utterance including incomplete or ambiguous information .The system of .The system of .", "label": "", "metadata": {}, "score": "71.72639"}
{"text": "RADIATION DETECTION SYSTEM AND METHOD OF ANALYZING AN ELECTRICAL PULSE OUTPUT BY A RADIATION DETECTOR - A radiation detection system can include a photo sensor to receive light from a scintillator via an input and to send an electrical pulse at an output in response to receiving the light .", "label": "", "metadata": {}, "score": "71.81441"}
{"text": "In another example , various statistical profiles may define affinities between advertisements , topics , users , etc .( e.g. , based on click - through or conversion rates , or other tracking information , as described in more detail below ) .", "label": "", "metadata": {}, "score": "72.08081"}
{"text": "For example , one or more context - appropriate applications may be invoked to service the requests in operation 315 ( e.g. , a voice search engine , a navigation application , an electronic commerce application , or other application may be invoked depending upon the request ) .", "label": "", "metadata": {}, "score": "72.098785"}
{"text": "The resulting kernel deep convex network may also be constructed by stacking one shallow kernel network over another with concatenation of the output vector of the lower network with the input data vector .A probability associated with a slot that is associated with slot - filling may be determined , based on local , discriminative features that are extracted using the kernel deep convex network .", "label": "", "metadata": {}, "score": "72.42333"}
{"text": "( action : i d B 2 L : when ( on : event B 1 .START ) : cmd cont . content ( leftgesture : cmd raise ) .( action : when B 1 .END : cmd end content B 2 R ) .", "label": "", "metadata": {}, "score": "72.47595"}
{"text": "A context of the requested task may be identified ( e.g. , \" Seattle \" ) , yet the identified context may be insufficient to adequately take action to service the request .Additional information may be inferred based on previous utterances in the conversation , profile information , or other information .", "label": "", "metadata": {}, "score": "72.50447"}
{"text": "Shown within the gender balanced window 302 is the word ' yes ' or ' no ' corresponding to the gender balance data 31 within the set - up data stores .Numbers corresponding to the length of speech data 32 and number of repetitions data 34 are displayed within the record duration window 303 and repetitions window 304 respectively .", "label": "", "metadata": {}, "score": "72.56087"}
{"text": "U5 : 800 225 5288 ( touchtone input ) .S6 : Thank you .The conventional dialog system frequently does not detect that an NLU error has occurred .The conventional dialog system misunderstands the user 's utterance in U2 as a request to make a third - number call .", "label": "", "metadata": {}, "score": "72.57054"}
{"text": "Patent application number .Description .Published .CYTOKINE DESIGN -The present invention relates to novel cytokines , which have a modified selectivity / specificity for their cognate receptors .In particular , the invention relates to a variant TRAIL protein , which has superior selectivity for the death receptor 4 ( TRAIL - RI ) over the death receptor 5 ( TRAIL - R2 ) .", "label": "", "metadata": {}, "score": "73.912605"}
{"text": "What is the reason for the credit ?U2 : Miss , uh , Miss , different area code than 1 needed .S3 : Sorry .I need to know whether you need credit for a wrong number , bad connection or a call that was cut off .", "label": "", "metadata": {}, "score": "73.99558"}
{"text": "CROSS - REFERENCE TO RELATED APPLICATIONS .This application is a continuation of U.S. patent application Ser .No .11/671,526 , entitled \" System and Method for Selecting and Presenting Advertisements Based on Natural Language Processing of Voice - Based Input , \" filed Feb. 6 , 2007 , which issued as U.S. Pat .", "label": "", "metadata": {}, "score": "74.00876"}
{"text": "If the character has the turn and is speaking and the user begins to gesture , this is interpreted as the user wanting turn function .If The character has the turn and is speaking and the user begins to speak , this is interpreted as the user taking turn function .", "label": "", "metadata": {}, "score": "74.123726"}
{"text": "6,941,266 issued 6 Sep. 2005 , and is also a continuation - in - part of U.S. patent application Ser .No .09/712,192 filed Nov. 15 , 2000 , now U.S. Pat .No .7,158,935 issued 2 Jan. 2007 , and is also a continuation of U.S. patent application Ser .", "label": "", "metadata": {}, "score": "74.17363"}
{"text": "7,634,409 on Dec. 15 , 2009 , and which is hereby incorporated by reference in its entirety .The one or more preliminary interpretations generated by the speech recognition engine 110 may then be provided to a conversational speech engine 115 for further processing .", "label": "", "metadata": {}, "score": "74.19692"}
{"text": "Mehmet Kemal Tur , Koln DE .Patent application number .The complex allows to influence the growth and the physiology of cells .In particular said complex , nucleic acid molecules encoding it , cells transfected or transformed with these nucleic acid molecules are usable for the preparation of medicaments for the treatment of proliferative diseases , inflammatory diseases , allergies and autoimmune diseases .", "label": "", "metadata": {}, "score": "74.22508"}
{"text": "7,640,160 on Dec. 29 , 2009 , and U.S. patent application Ser .No .11/212,693 , entitled \" Mobile Systems and Methods of Supporting Natural Language Human - Machine Interactions , \" filed Aug. 29 , 2005 , which issued as U.S. Pat .", "label": "", "metadata": {}, "score": "74.481674"}
{"text": "Height is therefore a relation which maps from its domain class , person , to its range class , number .Although the ontology 64 represents the semantic structure of the domain model 70 , the ontology 64 says nothing about the language used to speak about the domain model 70 .", "label": "", "metadata": {}, "score": "75.29466"}
{"text": "Rule \" open a message \" .if an action is an open .and the action of a command is the action .and the patient of the action is a message .and the message is selected .then OpenMessage ( ) .", "label": "", "metadata": {}, "score": "75.51703"}
{"text": "FIG .8 .The user interface 100 comprises a set of control buttons 101 - 106 which in .FIG .8 are shown at the top of the user interface ; a speaker window 107 ; a word window 108 and a pointer 109 .", "label": "", "metadata": {}, "score": "75.60719"}
{"text": "At this stage the waveform window 207 is also empty .The data collection module 22 then determines whether the record button 410 has been selected utilizing the pointer 415 under the control of the keyboard 3 or mouse 5 .If this is the case the arrow within the prompt window next to the words speak freely initially moves to the instruction say quiet .", "label": "", "metadata": {}, "score": "75.71316"}
{"text": "Word data 111 comprising for each of the word records 35 within the word database 23 the word identifier 38 for the record 35 and , a model status are displayed within the word window 108 .The model status comprises an indicator adjacent to each word for which a word model is stored within the model database 26 .", "label": "", "metadata": {}, "score": "75.76832"}
{"text": "a direction input channel connected to said compass .The interactive user interface according to . claim 2 , wherein said input frame synchronizes data from each of said user inputs with a virtual environment containing said character .The interactive user interface according to . claim 2 , wherein said multiple input channels include at least one input channel connected to and configured to transmit data from at least one of a motion detector , cyberglove , cybergloves , and body tracking hardware to said input manager .", "label": "", "metadata": {}, "score": "75.78437"}
{"text": "Patent application number .Description .Published .ORGANIC COMPOUNDS - The present invention relates to human thymic stromal lymphopoietin ( hTSLP ) antibodies and especially those which neutralize hTSLP activity .It further relates to methods for using anti - hTSLP antibody molecules in diagnosis or treatment of hTSLP related disorders , such as asthma , atopic dermatitis , allergic rhinitis , fibrosis , inflammatory bowel disease and Hodgkin 's lymphoma .", "label": "", "metadata": {}, "score": "76.10846"}
{"text": "The importance threshold may be a predefined value and/or importance threshold level decisions may be made on a more ad hoc basis .Similarly , an administrator may set a threshold value for an accuracy value , a hit rate value , a false alarm value , etc .", "label": "", "metadata": {}, "score": "76.3453"}
{"text": "The main control screen is then re - displayed ( S 7 - 1 ) .If this is not the case the control module 20 checks once again whether the project button 101 has been selected ( S 7 - 2 ) .", "label": "", "metadata": {}, "score": "76.6366"}
{"text": "The data collection module 22 then determines whether any of the word records 35 within the word database 23 has a selected flag 39 indicating a selected status .If none of the word records 35 include a selected flag 39 identifying a record 35 as having a selected status the data collection module 22 then sets the selected flag 39 for all the word records 35 to have selected status .", "label": "", "metadata": {}, "score": "76.84368"}
{"text": "If an action can not be performed before its deadline it is discarded ( and the requester is notified ) .If two actions conflict ( require the same device resources ) , the one with higher priority wins ( preemptively ) .", "label": "", "metadata": {}, "score": "76.87582"}
{"text": "Domain information is obtained in real - time from sources on the Web .The system understands about 500 destinations worldwide , chosen on the basis of passenger statistics , with a concentration on North America .Figure 1 Percent of training corpus account for by individual talkers .", "label": "", "metadata": {}, "score": "76.919334"}
{"text": "\" The reasoning facility 52 then determines that it must disambiguate the name , \" Jane . \" In step 108 , the reasoning facility 52 asks a question of the user to resolve the ambiguity .For example , the reasoning facility 52 can then initiate a question to the user to ask the user which \" Jane \" the user is interested in reading a message from .", "label": "", "metadata": {}, "score": "77.21057"}
{"text": "Moreover , context determination process 255 may build context based on user profiles , environmental profiles , historical profiles , or other information to further refine the context .For example , the profiles may indicate that Interstate-5 is a typical route taken Monday through Friday .", "label": "", "metadata": {}, "score": "77.40567"}
{"text": "7,818,176 on Oct. 19 , 2010 , the contents of which are hereby incorporated by reference in their entirety .FIELD OF THE INVENTION .The present invention relates to selecting and presenting advertisements based on natural language processing of voice - based input .", "label": "", "metadata": {}, "score": "77.43709"}
{"text": "Patent application number .Organic Compounds - The present invention relates to human thymic stromal lymphopoietin ( hTSLP ) antibodies and especially those which neutralize hTSLP activity .It further relates to methods for using anti - hTSLP antibody molecules in diagnosis or treatment of hTSLP related disorders , such as asthma , atopic dermatitis , allergic rhinitis , fibrosis inflammatory bowel disease , and Hodgkin 's lymphoma .", "label": "", "metadata": {}, "score": "77.78501"}
{"text": "The reasoning facility 52 can then set a subgoal based on a rule 86 of determining the full name for the first name .In a particular example , the reasoning facility 52 determines that there are two possible full names for \" Jane , \" that is \" Jane Doe \" and \" Jane Smith .", "label": "", "metadata": {}, "score": "78.04391"}
{"text": "FIG .10 is an illustration of an amend set - up data screen in accordance with this embodiment of the present invention .The screen comprises a number of speakers window 301 , a gender balanced window 302 , a record duration window 303 , a repetition window 304 , a done button 305 and a pointer 306 .", "label": "", "metadata": {}, "score": "78.11374"}
{"text": "claim 7 , wherein the plurality of dictionary and phrase entries are further dynamically updated based on one or more dynamic fuzzy set probabilities or prior probabilities derived from the history of the current dialog and the prior dialogs .A system to select and present advertisements in response to natural language utterances , comprising : . a speech recognition engine configured to recognize one or more words or phrases in a natural language utterance that contains a request ; . a conversational language processor configured to interpret the recognized words or phrases to establish a context associated with the natural language utterance ; and .", "label": "", "metadata": {}, "score": "78.127686"}
{"text": "I would be grateful for comments re the term \" dead language \" , etc . , and will post a summary to the list if there is sufficient response and interest .Sincerely .George Thompson .Ramon Lopez - Cozar Delgado Electronics and Computer Technology Dept .", "label": "", "metadata": {}, "score": "78.24725"}
{"text": "Upon completion it notifies the generation module .Generation module notifies the reaction module of successful completion and updates the discourse model .Action scheduler sends a command out to the solar system simulation to display Jupiter .Upon completion it notifies the reaction module .", "label": "", "metadata": {}, "score": "78.53456"}
{"text": "Ymni [ Thorisson96 ] Ymir is an architecture for autonomous characters that display turn - taking and other interactional competencies .The user interacts with Gandalf , an animated character developed in the Ymir architecture , using natural speech and gestures to ask questions about the solar system .", "label": "", "metadata": {}, "score": "78.668655"}
{"text": "FIG .9 is an exemplary illustration of a new speaker data entry screen .In this embodiment the new speaker data entry screen 200 comprises a speaker name window 201 , a gender selection button 202 , a done button 203 and a pointer 204 .", "label": "", "metadata": {}, "score": "78.68712"}
{"text": "FIG .7B , if the control module 20 determines ( S 7 - 18 ) that the record button 103 has not been selected the control module 20 then determines ( S 7 - 27 ) whether the play button 104 has been selected using the pointer 109 .", "label": "", "metadata": {}, "score": "78.69197"}
{"text": "This research was sponsored by the Space and Naval Warfare Systems Center , San Diego , under Grant No . N66001 - 99 - 1 - 8905 .The content of the information in this publication does not necessarily reflect the position or the policy of the US Government , and no official endorsement should be inferred .", "label": "", "metadata": {}, "score": "78.73718"}
{"text": "For example , when an utterance includes a request for a stock quote but not a company name ( e.g. , \" Get me the stock price for \") , the response may be \" What company 's stock quote do you want ? \" The user may then provide an utterance including the company name , and the request may be completed .", "label": "", "metadata": {}, "score": "78.94875"}
{"text": "These characters can respond to typed , free - form questions , and respond with text balloons containing mouse - clickable menu options .Microsoft Persona [ Microsoft97 ] The Persona project allows a user to control a computerized jukebox through an animated character who accepts speech input and produces spoken output with limited spontaneous gestures .", "label": "", "metadata": {}, "score": "79.230896"}
{"text": "4 , 5 and 6 .FIG .4 is a schematic representation of data stored within the data set - up store 29 .In this embodiment the data set - up store 29 is arranged to store global processing parameters for identifying the constraints upon data collection and the data required by the model generation module 25 to generate a model for storage within the model database 26 .", "label": "", "metadata": {}, "score": "79.48444"}
{"text": "claim 7 , wherein the response is a computer application program command based on the utterance representation .A computer program product comprising : . a computer for converting an utterance representation into a response ; and .a set of computer program instructions embodied on the computer readable medium , including instructions to : . generate an application specific goal derived from the utterance representation , wherein the application specific goal and the utterance representation are propositions comprising attribute - object - value triples , the proposition corresponding to the utterance representation being derived from a frame representation ; . generate a response based on the analysis of the utterance representation if ambiguous information is identified ; and wherein the response is a computer application program command based on the utterance representation .", "label": "", "metadata": {}, "score": "79.632996"}
{"text": "Changes in window focus , such as dialogs popping up and being dismissed , and applications 26 launching and exiting , must all be monitored in order to interpret the meaning of voice commands .A preferred embodiment uses Microsoft \u00ae Active Accessibility \u00ae ( MSAA ) from Microsoft Corporation , Redmond , Wash. , to provide this information , but again flexibility to change this or incorporate additional information sources is desirable .", "label": "", "metadata": {}, "score": "79.701126"}
{"text": "The carrier be any entity or device capable of carrying the program .For example , the carrier may comprise a storage medium , such as a ROM , for example a CD ROM or a semiconductor ROM , or a magnetic recording medium , for example a floppy disc or hard disk .", "label": "", "metadata": {}, "score": "79.850624"}
{"text": "DISTRIBUTED AND DYNAMICAL BRILLOUIN SENSING IN OPTICAL FIBERS - A method of distributed and dynamical Brillouin sensing in optical fibers is provided herein .FAST BRILLOUIN OPTICAL TIME DOMAIN ANALYSIS FOR DYNAMIC SENSING - A method for conducting fast Brillouin optical time domain analysis for dynamic sensing of optical fibers is provided herein .", "label": "", "metadata": {}, "score": "80.24585"}
{"text": "Various modifications and alterations can be made thereto without departing from the spirit and scope of the invention .Free format text : ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR : AT&T INTELLECTUAL PROPERTY II , L.P.;REEL / FRAME:034590/0045 .Effective date : 20141210 .", "label": "", "metadata": {}, "score": "81.55553"}
{"text": "A storage medium having computer implementable instructions stored thereon for generating within a programmable computer an apparatus in accordance with any of .claims 1 - 9 and 10 - 16 .A computer - readable medium in accordance with . claim 17 , comprising a disk .", "label": "", "metadata": {}, "score": "81.65364"}
{"text": "Furthermore , in various implementations , voice - based inputs may include multiple requests , multi - modal requests , cross - device requests , cross - application requests , or other types of requests .For example , an utterance received in operation 305 may be : \" Get me a route to Chang 's Restaurant , and call them so I can make a reservation .", "label": "", "metadata": {}, "score": "82.250404"}
{"text": "Apparatus in accordance with .Apparatus in accordance with .Apparatus in accordance with .Apparatus in accordance with . claim 10 , wherein each said item of speaker data is associated with gender data wherein said constraint data comprises data identifying a relationship the gender data associated with items of speaker data is required to fulfill .", "label": "", "metadata": {}, "score": "82.60917"}
{"text": "S3 : What phone number would you like the call billed to ?U3: Um the access number .S4 : Sorry .Could I have that phone number again ?U4 : 1 8 hundred 2 2 5 5 2 8 8 .", "label": "", "metadata": {}, "score": "83.579834"}
{"text": "The dialog ends without completing the user 's task .Sample Successful Dialog .S1 : AT&T How may I help you ?U1 : I need to [ uh ] put a call on my calling card please .S2 : May I have your card number , please ?", "label": "", "metadata": {}, "score": "84.17327"}
{"text": "Directory .Dear List members , I am a Sanskritist presently engaged in an effort to decide whether or not Sanskrit is a \" dead language \" , and I have come to realize that this term \" dead language \" is being used in a variety of ways .", "label": "", "metadata": {}, "score": "84.81431"}
{"text": "The speech engine interface module 30 encapsulates the details of communicating with the speech engine 22 , isolating the speech center 20 from the speech engine 22 specifics .In a preferred embodiment , the speech engine 22 is ViaVoice \u2122 from IBM \u00ae .", "label": "", "metadata": {}, "score": "84.869965"}
{"text": "COPYRIGHT NOTICE .A portion of the disclosure of this patent document contains material which is subject to copyright protection .The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure , as it appears in the Patent and Trademark Office patent file or records , but otherwise reserves all copyright rights whatsoever .", "label": "", "metadata": {}, "score": "85.99665"}
{"text": "For example , a user utterance may be \" What is the forecast for Boston this weekend ? \"Moreover , some utterances may include compound requests , and the one - step access feature may decompose the compound requests into sub - tasks .", "label": "", "metadata": {}, "score": "86.32343"}
{"text": "S3 : What number would you like to call ?U3: 8 1 4 7 7 7 6 6 6 6 ( misunderstood ) .S4 : May I have that number again ?U4 : 8 1 4 7 7 7 6 6 6 6 .", "label": "", "metadata": {}, "score": "87.0346"}
{"text": "11/219,629 filed Sep. 6 , 2005 , now U.S. Pat .No .7,472,060 issued 30 Dec. 2008 , which was a continuation of U.S. patent application Ser .No .09/765,444 filed Jan. 22 , 2001 , now U.S. Pat .", "label": "", "metadata": {}, "score": "87.25873"}
{"text": "Listen for an answer ( from the user ) .In step 110 , the reasoning facility 52 receives an utterance representation 21 based on the answer to the question asked in step 108 .For example , the reasoning facility 52 receives the answer \" Jane Smith .", "label": "", "metadata": {}, "score": "88.13111"}
{"text": "Where this selected flag 39 ; 44 has a status of selected , the status flag 39 ; 44 is updated to have an unselected status .Where the selected flag 39 ; 44 has an unselected status , the status is updated to be a selected status .", "label": "", "metadata": {}, "score": "88.74333"}
{"text": "When one portion of the button is selected this portion is highlighted .If the other portion of the gender button is selected the highlight is moved from the first portion and the second portion is highlighted .Thus in this way by selecting an appropriate part of the gender button 202 a user can indicate the gender of the speaker whose name is entered in the speaker window 201 .", "label": "", "metadata": {}, "score": "88.84344"}
{"text": "Nevertheless human intervention is required at two points : the identification of alternative renderings of a particular identifier ( e.g. , JFK as well as KENNEDY for an airport name ) and the choice of a pronunciation .While it is possible to automatically generate pronunciations as well as variants , human review is always necessary to ensure accuracy .", "label": "", "metadata": {}, "score": "89.38553"}
{"text": "The grammatic specification should not validate a statement such as \" The age of Tom is red \" , for example .Likewise , the grammatic specification disallows sentences that specify attributes of objects that do not possess those attributes .To capture this distinction in BNF format in the grammatic specification would require separate definitions for each type of attribute , and separate sets of attributes for each type of object .", "label": "", "metadata": {}, "score": "90.02247"}
{"text": "ASSIGNOR(S ) HEREBY CONFIRMS THE ASSIGNMENT;ASSIGNOR : AT&T CORP.;REEL / FRAME:036572/0447 .Effective date : 20090821 .Sep 24 , 2015 .AS .Assignment .Owner name : AT&T INTELLECTUAL PROPERTY II , L.P. , GEORGIA .Free format text : CORRECTIVE ASSIGNMENT TO CORRECT THE APPLICATION NUMBER 12/221,332 PREVIOUSLY RECORDED AT REEL : 023372 FRAME : 0044 .", "label": "", "metadata": {}, "score": "90.230606"}
{"text": "A triple X Y Z can be read as \" The X of Y is Z \" ( e.g. , the color of column is green ) .The triples derived from the above frame representation are shown in the example below .", "label": "", "metadata": {}, "score": "90.71926"}
{"text": "For example , a user may initially request information from a voice - enabled media device ( e.g. , a satellite radio player ) about a song currently playing ( e.g. , \" What is this song ? \" )In addition to outputting the requested information about the song ( e.g. , \" This song is Double Barrel by Dave and Ansel Collins . \" ) , a selected advertisement may enable the user to purchase a ringtone for a mobile phone that corresponds to the song .", "label": "", "metadata": {}, "score": "91.53613"}
{"text": "For example , a user may utter \" What 's the weather in Seattle ? \" and context determination process 255 may establish Weather as a context , as well as establishing Seattle as an environmental context .The user may then utter \" and Portland ? \" and context determination process 255 may return a weather report for Portland , Oreg . based on the Weather and an environmental proximity between Portland , Oreg . and Seattle , Wash. The user may then ask \" What time does the game start ? \" \" and a search for sports events with teams from Seattle and/or Portland may occur , with results presented conversationally according to methods described in greater detail below in .", "label": "", "metadata": {}, "score": "91.5983"}
{"text": "If a user selects the number of speakers window 301 , the record duration window 303 or the repetition window 304 any numbers typed in using the keyboard 3 are made to overwrite the number appearing within the selected window 301 ; 303 ; 304 .", "label": "", "metadata": {}, "score": "91.82211"}
{"text": "If the speaker name window 201 is selected using the keyboard or mouse 3 , 5 , any text entered using the keyboard 3 is caused to be displayed within the speaker name window 201 .A user can also use the keyboard 3 or mouse 5 to select the gender button 202 .", "label": "", "metadata": {}, "score": "92.16263"}
{"text": "3 .Correlatively , had user originally uttered \" What 's the weather in Portsmouth , N.H. , \" in the second utterance , context determination process 255 may instead retrieve a weather report for Portland , Me . based on an environmental proximity to New Hampshire .", "label": "", "metadata": {}, "score": "92.389"}
{"text": "Based on a context of the requested information ( e.g. , \" Search , \" \" Sports , \" \" Philadelphia , \" etc . ) , the requested information may be retrieved , while an advertisement for Eagles apparel or memorabilia may be selected .", "label": "", "metadata": {}, "score": "93.14996"}
{"text": "\" The following plan is returned to the Reaction Module : .Communication generation produces the string \" No .You 're pointing at Saturn . \" and sends it the action scheduler along with lip - synch animation commands and animation commands to shake the head in time with the \" No \" .", "label": "", "metadata": {}, "score": "93.61064"}
{"text": "No .11/433,392 filed May 12 , 2006 , now U.S. Pat .No .7,487,088 issued 3 Feb. 2009 , which was a continuation - in - part of U.S. patent application Ser .No . 09/712,194 filed Nov. 15 , 2000 , now U.S. Pat .", "label": "", "metadata": {}, "score": "93.75981"}
{"text": "Ronen Tur , Tirat Carmel IL .Patent application number .Description .Published .METHODS AND SYSTEMS FOR DATA COMMUNICATION IN AN ULTRASOUND SYSTEM - Methods and systems for data communication in an ultrasound system are provided .One method includes acquiring ultrasound data using an ultrasound probe having a plurality of transducer elements , wherein the ultrasound data includes echo information acquired from the plurality of transducer elements and the ultrasound data is acquired using a plurality of transmit events of the ultrasound probe .", "label": "", "metadata": {}, "score": "93.86223"}
{"text": "In step 106 , in an alternate approach , the reasoning facility 52 determines that the ambiguity can be resolved through records or data available to the reasoning facility 52 .Thus , the reasoning facility 52 can proceed from step 106 to step 112 to invoke a command to open the message based on the name \" Jane Smith \" without asking a question of the user ( without proceeding to step 108 ) .", "label": "", "metadata": {}, "score": "94.016"}
{"text": "ASSIGNOR(S ) HEREBY CONFIRMS THE ASSIGNMENT;ASSIGNOR : AT&T PROPERTIES , LLC;REEL / FRAME:036568/0173 .Effective date : 20090811 .Owner name : AT&T PROPERTIES , LLC , NEVADA .Free format text : CORRECTIVE ASSIGNMENT TO CORRECT THE INCORRECT SERIAL NO .", "label": "", "metadata": {}, "score": "96.85563"}
{"text": "Furthermore , user profile information may indicate that the user is visiting Seattle from out - of - town ( e.g. , the profile may indicate that the user 's home is Sacramento ) , and therefore , an advertisement for popular points - of - interest in Seattle may be selected .", "label": "", "metadata": {}, "score": "100.14282"}
{"text": "In conventional Backus Naur Form ( BNF ) , the grammatic specification might take the form : .This would allow the user to create sentences like \" The color of A1 is red \" or \" The age of Tom is 35 \" .", "label": "", "metadata": {}, "score": "102.76949"}
{"text": "For example , in the dialog below the system utterance in S3 counts as a re - prompt because it is a variant of the question in utterance S2 .AT&T How may I help you ?U1 : I need credit please .", "label": "", "metadata": {}, "score": "105.816795"}
{"text": "The architecture of the present invention is provided to KUMO ( a humanoid synthetic character ) , and the following presents a set of sample interactions , and walks through the processing steps and data flow in the architecture .KUMO : \" Is that Jupiter ? \"", "label": "", "metadata": {}, "score": "106.61316"}
{"text": "For example , for an utterance of \" Well , I wanna . . . .Mexi . . .no , steak restaurant please , I 'm hungry , \" existing voice user interfaces make no assumptions regarding models of human speech and would be unable to infer whether the user wanted a Mexican or steak restaurant .", "label": "", "metadata": {}, "score": "106.9305"}
{"text": "Response planner determines that the user is actually pointing at Saturn , and decides that an appropriate response ( based on information in the dynamic KB and discourse model ) is to show the user Jupiter and say \" No , you 're pointing at Saturn .", "label": "", "metadata": {}, "score": "112.68926"}
{"text": "Thus , concept or content information in a request may be used to select an advertisement .For example , a user may request to calculate a route in Seattle , Washington ( e.g. , \" How do I get to the Space Needle ? \" )", "label": "", "metadata": {}, "score": "119.92763"}
