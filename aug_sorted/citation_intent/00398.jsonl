{"text": "Marlow et al .[ 13 ] introduced an Eval monad for explicitly specifying evaluation order .I will start by briefly introducing the monad , so do n't worry if you 're not familiar with it already .I 'll then demonstrate how to define a MonadZip instance for this monad .", "label": "", "metadata": {}, "score": "39.698513"}
{"text": "We can take this applicative style of writing a parser much further .In most cases , the extra compactness that we will gain will not come at any cost in readability , beyond the initial effort of coming to grips with the idea .", "label": "", "metadata": {}, "score": "41.197784"}
{"text": "If you recall , this was defined as follows : .This is interesting for two reasons .First : we have multiple disjunctions handled in the same rule , showing that disjunctive parsers chain just as nicely as do sequential .", "label": "", "metadata": {}, "score": "41.249504"}
{"text": "The parser generator MSTA used as a partial proof method is available at [ 11 ] .Appendix : Ambiguity in DP is undecidable .Dynamic programming is a very general programming technique , and its scope is not precisely circumscribed .", "label": "", "metadata": {}, "score": "41.682068"}
{"text": "The only solution which eliminates these bugs , is to remove the ambiguities and use a Context - free grammar .Parser combinators , like all recursive descent parsers , are not limited to the Context - free grammar and thus do no global search for ambiguities in the LL(k ) parsing First_k and Follow_k sets .", "label": "", "metadata": {}, "score": "41.79118"}
{"text": "While such a mapping may be easy to specify , the proof of its injectivity remains a problem .Recently , Dowell and Eddy have re - addressed this problem [ 1 ] in the framework of stochastic context free grammars ( SCFGs ) .", "label": "", "metadata": {}, "score": "41.89563"}
{"text": "After any part of any rule in the definition of the grammar , you can add a semantic action .This semantic action will be called whenever that particular part of the rule has been successfully matched .This process is a very powerful extension of what is possible in other parsers such as Yacc .", "label": "", "metadata": {}, "score": "42.35354"}
{"text": "This parser must be deterministic , and , in contrast to our CYK parsers , it only exists for non - ambiguous grammars .There are many such generators available ; we will focus on the class of LR ( k ) grammars [ 10 ] and their parser generators .", "label": "", "metadata": {}, "score": "42.55326"}
{"text": "This leads us to the two most interesting parsers , for numbers and strings .We 'll deal with numbers first , since they 're simpler .-- file : ch16/JSONParsec .Our trick here is to take advantage of Haskell 's standard number parsing library functions , which are defined in the Numeric module .", "label": "", "metadata": {}, "score": "43.618927"}
{"text": "Indeed , we might have used quantifiers to specify exact repetition , but then we would n't have had access to captured groups .Now let 's take a look , how the same functionality can be achieved using parser combinators : .", "label": "", "metadata": {}, "score": "43.687443"}
{"text": "The technique described in the following comprises two steps .First , we remove the syntactic ambiguity of the grammar and reduce a possibly existent semantic ambiguity to fl - ambiguity .Then we use a parser generator to check the transformed grammar for fl - ambiguity .", "label": "", "metadata": {}, "score": "43.81772"}
{"text": "Most ' standard ' parsing algorithms for constraint - based grammars [ 55 , 64 , 84 , 25 , 24 ] are not applicable in general for non - concatenative grammars because in these algorithms the assumption that phrases are constructed by concatenation is ' built - in ' .", "label": "", "metadata": {}, "score": "43.99665"}
{"text": "If parsing fails , it returns an error message and the input it was originally given , so another Parser can try and continue where it gave up .So What Are The \" Combinators \" In \" Parser Combinators \" ?", "label": "", "metadata": {}, "score": "44.436127"}
{"text": "This was a motivation for the development of non - monadic parsers , such as the one by Swierstra [ 6 , 7 ] , which are less expressive but more efficient .Applicative functors , developed by McBride and Paterson [ 8 ] , are a weaker abstraction that can be used for writing parsers .", "label": "", "metadata": {}, "score": "44.46108"}
{"text": "The usual applicative parsers allow us to write parsers where the choice of the next parser does n't depend on the value parsed so far .In terms of formal language theory , they can express only context - free languages .", "label": "", "metadata": {}, "score": "44.699615"}
{"text": "In particular , the do notation does n't provide an equivalent syntactic extension for writing parallel comprehensions .In the next three sections , I show how we could implement the mzip operation for several interesting monads , representing parsers , resumable computations , and parallel computations .", "label": "", "metadata": {}, "score": "45.311195"}
{"text": "The standard way to avoid the need for backtracking is to tidy up a parser so that we can decide whether it will succeed or fail using only a single token of input .In this case , the two parsers consume the same initial tokens , so we turn them into a single parser .", "label": "", "metadata": {}, "score": "45.391922"}
{"text": "I 've finished off by using eof to indicate that the parser should fail if there is any left over input .However , this is n't the only way to use parsec , though it 's certainly a convenient way .", "label": "", "metadata": {}, "score": "45.509148"}
{"text": "Once you realize this , the magic behind all of this becomes quite a bit more obvious .However , to really figure it all out , we 're going to need to take a few steps back .Conceptually , a Parser represents a very simple idea : .", "label": "", "metadata": {}, "score": "45.626705"}
{"text": "The recent GHC patch makes them even more useful by generalizing additional features of list comprehensions including parallel binding and support for operations like ordering and grouping .In this article , I focused on the first generalization , although the remaining two are equally interesting .", "label": "", "metadata": {}, "score": "46.07325"}
{"text": "They can either succeed or fail .Parser combinators , on the other hand , combine existing parsers into more complex ones .Therefore , complicated parsers can be built from bottom up , using an appropriate composition of simpler parsers , which are easier to understand , implement and test .", "label": "", "metadata": {}, "score": "46.86033"}
{"text": "1.2 Generalizing to monad comprehensions .The three examples we 've seen in the previous section are straightforward when working with lists .After installing the latest development snapshot of GHC and turning on the MonadComprehensions language extension , we can use the same syntax for working with further notions of computation .", "label": "", "metadata": {}, "score": "46.862534"}
{"text": "As this problem inherits undecidability ( as we show here ) from the namely problem for context free languages , there is no complete algorithmic solution to the problem of ambiguity checking .Results .We explain frequently observed sources of ambiguity , and show how to avoid them .", "label": "", "metadata": {}, "score": "46.890278"}
{"text": "If the first parser succeeds , we yield its value ; otherwise , we try the second parser and return its Result ( whether Success or Failure ) .Thus , our disjunctive combinator should yield a parser which succeeds if and only if one of its component parsers succeeds .", "label": "", "metadata": {}, "score": "46.965515"}
{"text": "This pattern extends to more complicated parsers , too : only infrequently do we need the extra bit of power that monads offer .As we write this book , applicative functors are still quite new to Haskell , and people are only beginning to explore the possible uses for them beyond the realm of parsing .", "label": "", "metadata": {}, "score": "46.980133"}
{"text": "Do you see the beauty here ?Such complicated parsing logic written as a combination of simple , easily understandable tasks .The last necessary step is to write a method which triggers parsing itself : . Conclusion .In this article I 've shown how parser combinators work , how can we use them as a complement to regular expressions and an example where parser combinators are superior to regexps in parsing a language , which is not regular .", "label": "", "metadata": {}, "score": "47.1373"}
{"text": "Fodor et al 1974 ; and as far as I know there are still enough . psycholinguists out there subscribing to this hypothesis but feel free to .correct me if I 'm wrong ) .So is there a parser that does n't just .", "label": "", "metadata": {}, "score": "47.319126"}
{"text": "Parser combinators are indeed an impressive example of functional programming techniques .I used monadic parser combinators a lot , and found the following paper to be a nice introductory text , as well as an illustration of the use of more advanced techniques focused on efficency .", "label": "", "metadata": {}, "score": "47.399963"}
{"text": "Experience from a larger example .The parser generator test works quite well for the small grammars we presented so far .However , there exist cases where , due to the finite lookahead of the generated parser , the parser generator reports conflicts while the grammar is in fact non - ambiguous .", "label": "", "metadata": {}, "score": "47.650772"}
{"text": "Finally , we can build the Parser that parses any string consisting of ' a ' , ' b ' , ' 0 ' and ' 1 ' : .To run the Parser , we can do the following : .", "label": "", "metadata": {}, "score": "47.74362"}
{"text": "I believe that the three laws I proposed in this section partly answer the question of how to relate the two structures combined by parallel monad comprehensions - the MonadPlus type class with the symmetric monoidal functor that defines mzip .Conclusions .", "label": "", "metadata": {}, "score": "48.140846"}
{"text": "The interesting question is , what operation does mzip represent for context - free grammars ?A language we obtain if parses for two other languages both succeed is an intersection of the two languages .An intersection of two context - free languages is not necessarily context - free , which can be demonstrated using the following example : .", "label": "", "metadata": {}, "score": "48.337845"}
{"text": "For example , GLL ( Generalized LL ) is one such technique presented at LDTA 2009 .It 's basically just recursive - descent , except that it can handle multiple simultaneous parse trails .And , as with recursive - descent , it is extremely amenable to representation within a functional , composable framework ( like parser combinators ) .", "label": "", "metadata": {}, "score": "48.667526"}
{"text": "At the end of the day , it returns either Success or Failure .The Sequential Combinator .The first of the two combinators we need to look at is the sequence combinator .Conceptually , this combinator takes two parsers and produces a new parser which matches the first and the second in order .", "label": "", "metadata": {}, "score": "48.929794"}
{"text": "Its successful construction is the proof of non - ambiguity ; for applying our SCFG , we need the original grammar and its CYK parser .MSTA accepts input files in the widely used yacc format .The following shows the input file for grammar G 5 : .", "label": "", "metadata": {}, "score": "48.946453"}
{"text": "The assignment to lazy val(s ) just memoizes that evaluation , turning the parameters into effectively call - by - need ( think : Haskell ) .Personally , I prefer a framework which has lazy disjunctions rather than sequences .We can turn this same trick with the disjunctive combinator , gaining the following advantages : .", "label": "", "metadata": {}, "score": "49.019653"}
{"text": "If so , we return a single quote mark to go on our result string .This try is important .Let 's say we are parsing a quoted cell , and are getting towards the end of it .There will be another cell following .", "label": "", "metadata": {}, "score": "49.053883"}
{"text": "It is not mathematically deep , but rather a tedious exercise , and the likelihood to produce errors or oversights is high .By showing that a one - to - one mapping between parse trees of G and R exists , it is possible to prove the non - ambiguity of G .", "label": "", "metadata": {}, "score": "49.12056"}
{"text": "Those functions are our Combinators .Each Parser we use or build ourselves is a subclass of this abstract Parser defintion .This is why we can call all the predefined combinator functions on it , many of which have the signature we used as an exemplified combinator above .", "label": "", "metadata": {}, "score": "49.16504"}
{"text": "Instead , I used a combination of sequential and disjunctive combinators to produce a Parser which matches the desired pattern .Note that the \" ... \" is not some special syntax , but rather my laziness and wish to avoid a code snippet 310 characters wide .", "label": "", "metadata": {}, "score": "49.30874"}
{"text": "This is quite critical for developing a language : .In the development of Copute 's grammar , I found critical ambiguities that would have not been evident if I had gone with parser combinators ( aka recursive descent algorithms ) .", "label": "", "metadata": {}, "score": "49.337936"}
{"text": "View Article PubMed .Giegerich R : Explaining and Controlling Ambiguity in Dynamic Programming .Proc .Combinatorial Pattern Matching , Springer LNCS 1848 2000 , 46 - 59 .Chomsky N : Three Models for the Description of Language .IRE Transactions on information theory 1956 , 2 : 113 - 124 .", "label": "", "metadata": {}, "score": "49.435013"}
{"text": "The first example runs the entire computation sequentially - aside from some wrapping and unwrapping , there are no evaluation order specifications .The second example runs the two sub - computations in parallel .The evaluation order annotations are added by the mzip function from the desugared parallel comprehension syntax .", "label": "", "metadata": {}, "score": "49.502827"}
{"text": "Quite interestingly , they also generalize syntax for zipping , grouping and ordering of lists .This article shows how to use some of the new expressive power when working with well - known monads .You 'll learn what \" parallel composition \" means for parsers , a poor man 's concurrency monad and an evaluation order monad . 1 Introduction .", "label": "", "metadata": {}, "score": "49.58355"}
{"text": "As we program in a functional style , the result is again a function : .That 's it .That would be the signature of a Combinator combining two Parsers into a new one .Now we have already covered more or less the basics of Parser Combinators .", "label": "", "metadata": {}, "score": "49.671417"}
{"text": "Our parsers wo n't be as short as regular expressions , but they 'll be close enough to negate much of the temptation of regexps .Parsing without variables .A few of our parsers above use do notation and bind the result of an intermediate parse to a variable , for later use .", "label": "", "metadata": {}, "score": "49.743774"}
{"text": "We could of course write a new Parser that does that , but let 's try and solve that by combining four basic Parsers , one for each char .So we need some Parser that first tries one Parser , if that fails , the other .", "label": "", "metadata": {}, "score": "49.747833"}
{"text": "2.5 Applicative and parallel parsers .Before moving to the next example , let 's take a look how mzip relates to applicative functors .As already mentioned , an alternative definition of applicative functors ( [ 8 ] section 7 ) uses an operation with exactly the same type signature as mzip .", "label": "", "metadata": {}, "score": "49.87468"}
{"text": "This may look like a very strong requirement , but it fits quite well with the usual intuition about the zip operation and parallel monad comprehensions .The symmetry law holds for lists , parsers and the evaluation order monad .For the poor man 's concurrency monad , it holds if we treat effects that occur within a single step of the evaluation as unordered ( which may be a reasonable interpretation ) .", "label": "", "metadata": {}, "score": "49.93776"}
{"text": "Of course , this parser is absurd , since it only matches an infinite input consisting of the ' 1 ' character , but it does serve to illustrate that we have a reasonably powerful framework even in its current form .", "label": "", "metadata": {}, "score": "50.04531"}
{"text": "The important difference is that positional information is turned into symbolic information .After this modification , the parser generator runs smoothly through the grammar , which proves its non - ambiguity .Conclusion .In this work , we have presented testing methods and a partial proof procedure to analyze the semantic ambiguity of SCFGs .", "label": "", "metadata": {}, "score": "50.06884"}
{"text": "With this p_series function , parsing an array is simple .-- file : ch16/JSONParsec .The choice combinator allows us to represent this kind of ladder - of - alternatives as a list .It returns the result of the first parser to succeed .", "label": "", "metadata": {}, "score": "50.10327"}
{"text": "It could be implemented just in terms of Applicative and mzip , but we use the nicer monad comprehension syntax : .The example uses both parallel and sequential binding , but the sequential composition does n't involve dependencies on previously parsed results .", "label": "", "metadata": {}, "score": "50.10444"}
{"text": "The operation that generalizes parallel comprehensions is closely related to a merge operation that I designed for F # joinads .In the rest of this article , I demonstrate some of the interesting programs that can be written using this operation and the elegant syntax provided by the re - designed monad comprehensions . 1.1", "label": "", "metadata": {}, "score": "50.182983"}
{"text": "Thereafter , we make some observations with respect to the potential of testing procedures .Three simple cases .Ambiguity does not sneak into our grammars by chance and non - awareness .There are two competing goals in grammar design , and both may foster ambiguity .", "label": "", "metadata": {}, "score": "50.203056"}
{"text": "The mzip operation also defines an instance of applicative functor for parsers , but a different one .The mzip operation can be also viewed as a natural transformation of some monoidal functor , but it may be a different one .", "label": "", "metadata": {}, "score": "50.281673"}
{"text": "This grammar simply says \" match either the ' 1 ' character , or the ' 2 ' character \" .Unfortunately , our framework is incapable of defining a parser according to this rule .We have no facility for saying \" either this or that \" .", "label": "", "metadata": {}, "score": "50.32298"}
{"text": "For this reason alone , many real world compilers and interpreters ( such as javac , ruby , jruby and scalac ) actually use hand - written parsers .These are usually easier to tweak , but they can be very difficult to develop and test .", "label": "", "metadata": {}, "score": "50.3882"}
{"text": "By definition , an LR ( k ) grammar is non - ambiguous , and for a given k it is decidable whether a grammar is LR ( k ) .This decision can be assigned to a parser generator .Given the grammar and the lookahead k , a parser generator tries to construct a parser that uses k symbols of lookahead .", "label": "", "metadata": {}, "score": "50.589687"}
{"text": "For example , the non - ambiguous Wuchty algorithm ( RNAsubopt , [ 2 ] ) requires four tables for storing intermediate results , while the ambiguous Zuker - Stiegler recurrences ( Mfold , [ 7 ] ) require only two .", "label": "", "metadata": {}, "score": "50.697685"}
{"text": "There are some more goodies attached to these classes in the real implementation , but we will skip them for now .I recommend studying the sources in scala / util / parsing / combinator / Parsers . scala .For now it suffices to note the differences to our Result : .", "label": "", "metadata": {}, "score": "50.899773"}
{"text": "Applicative parsing by example .We 'll begin by rewriting our existing form parser from the bottom up , beginning with p_hex , which parses a hexadecimal escape sequence .Here 's the code in normal do -notation style .-- file : ch16/FormApp . fst . head .", "label": "", "metadata": {}, "score": "51.01519"}
{"text": "As you can see , this program even supports different line endings within a single file .Error Handling .At the beginning of this chapter , you saw how Parsec could generate error messages that list the location where the error occurred as well as what was expected .", "label": "", "metadata": {}, "score": "51.08921"}
{"text": "These algorithms are available at the accompanying website [ 8 ] , where readers are welcome to practice their insight on ambiguity matters .In the following , we write G ( \u03c3 , x ) for running the CYK parser based on grammar G with scoring scheme \u03c3 on input x .", "label": "", "metadata": {}, "score": "51.109818"}
{"text": "( Of course you could just use RegexParsers , but for the sake of this example we pretend we do not know about the Regular Expression Parsers ) .So far what we have achieved to parse has not been too impressive , we could have done this with some loops or a RegExp .", "label": "", "metadata": {}, "score": "51.120842"}
{"text": "P. Koopman and M.J. Plasmeijer .Efficient Combinator Parsers , In Proc . of Implementation of Functional Languages ( IFL ' 98 ) , London , UK , K. Hammond , A.J.T. Davie and C. Clack ( Eds . ) , Springer Verlag , LNCS 1595 , pp .", "label": "", "metadata": {}, "score": "51.17176"}
{"text": "Using the first two scoring schemes , we obtain the Viterbi and the Inside algorithm .Using the other two , we obtain an algorithm for counting the number of derivations for the input string , and an algorithm for base pair maximization .", "label": "", "metadata": {}, "score": "51.39953"}
{"text": "The parser is generalized in order to be applicable to any grammar that employs linear and non - erasing operations on strings .The disadvantages Kay noted for his parser do not carry over to this generalized version , as redundant search paths for CF - based grammars turn out to be genuine parts of the search space for this enlarged class of grammars .", "label": "", "metadata": {}, "score": "51.412903"}
{"text": "Instead , they suggest a testing approach to check for the presence of ambiguity , which , of course , can not prove its absence .Formalization of ambiguity .We formalize the problem at hand in two steps , going from context free grammars ( CFGs ) to stochastic context free grammars , and then differentiating between syntactic and semantic ambiguity .", "label": "", "metadata": {}, "score": "51.457306"}
{"text": "Our first approach with the parser generator succeeded , except for one small part of the grammar for which it reports a con - flict .Figure 2 shows two example derivations where this conflict occurs .Two example derivations .Two example derivations of a grammar taken from [ 14 ] .", "label": "", "metadata": {}, "score": "51.611053"}
{"text": "1- .Fodor , J. A. , T.G. Bever and M.F. Garrett .The .Psychology of Language : An Introduction to .Psycholinguistics and Generative Grammar .New York : .McGraw - Hill .[ cf . esp .318ff . ] Goldberg , A. E. 2003 .", "label": "", "metadata": {}, "score": "51.720764"}
{"text": "Larger grammars allow a more sophisticated distinction of cases , hence providing a more fine - tuned model .However , if the underlying \" distinct \" cases lead to the same annotation sequence , then the grammar is ambiguous .This case is witnessed by grammar G 2 , where along with the introduction of base pair specific rules , another source of ambiguity is introduced .", "label": "", "metadata": {}, "score": "51.974037"}
{"text": "When the grammar is not LR ( k ) , the generator will not be able to create a deterministic parser and reports this situations in form of \" shift - reduce \" and \" reduce - reduce\"-conflicts to the user .", "label": "", "metadata": {}, "score": "52.10459"}
{"text": "We will start with parsing Strings in the next section for which Scala provides the necessary String Readers .We will look at how Reader s work bit by bit as we need it .Writing A Simple Parser By Hand .", "label": "", "metadata": {}, "score": "52.1072"}
{"text": "The four grammars G 3 - G 6 passed the Dowell - Eddy test in [ 1 ] , and in the next section we shall prove their non - ambiguity .In this sense , we can state that this test has already worked quite well in practice .", "label": "", "metadata": {}, "score": "52.289726"}
{"text": "I decided that in this case , I would demonstrate another commonly used tool associated with parsing , the conversion of input into a composite tree .Modeling the Input Using a Composite .Many input formats can be parsed successfully by generating a composite tree out of the parser .", "label": "", "metadata": {}, "score": "52.2994"}
{"text": "We can see that this language is not regular anymore , yet context - free .The idea of the proof is very simple - just imagine an n - state finite automaton and an expression starting with n+1 opening parentheses .", "label": "", "metadata": {}, "score": "52.354057"}
{"text": "In most Parser Combinator tutorials I have read , people simply use some of the predefined Parsers and Combinators to solve a relatively complex parsing problem in a couple of lines .This is of course what the whole Parser Combinator API in Scala is for , and most of the time you will only need to use the predifined ones , as they really cover 95 % of all use cases .", "label": "", "metadata": {}, "score": "52.41125"}
{"text": "A recent GHC patch implemented by Nils Schweinsberg [ 2 , 3 ] brings back support for monad comprehensions to Haskell .The change is now a part of the main branch and will be available in GHC starting with the 7.2 release .", "label": "", "metadata": {}, "score": "52.451202"}
{"text": "Degree of ambiguity and consequences for testing .Dowell and Eddy showed that semantic ambiguity produces sometimes mildly , sometimes drastically false results .In one experiment , they showed that the CYK algorithm for the semantically ambiguous grammar G 1 does not give the optimal secondary structure for about 20 % of a sample set of 2455 sequences .", "label": "", "metadata": {}, "score": "52.46701"}
{"text": "Recall that our earlier definition of eol was simply char ' \\n ' .There is a parser called string that we can use to match the multi - character patterns .Let 's start by thinking of how we would add support for \\n\\r .", "label": "", "metadata": {}, "score": "52.644035"}
{"text": "When we use parallel comprehensions , the inputs of the generators are combined using the mzip function .The result is passed to the bind operation , which applies the output function to values of the combined computation .If we also specified filtering , the guard function would be added to the innermost expression , as in the previous example .", "label": "", "metadata": {}, "score": "52.69652"}
{"text": "We want to keep it purely functional , so we are not using exception handling .What we will do is introduce an abstract class that helps us tell a successful parsing from an unsuccessful one : . sealed abstract class Result case class Success(result : Output ) extends Result case class Failure(message : String ) extends Result .", "label": "", "metadata": {}, "score": "52.729717"}
{"text": "Table 1 .Results of mechanical proof procedure .Number of shift - reduce ( SR ) and reduce - reduce ( RR ) conflicts when feeding example grammars G1 to G8 into parser generator MSTA .A 0/0 entry indicates a successful proof of non - ambiguity .", "label": "", "metadata": {}, "score": "52.73832"}
{"text": "Hand - made proof of non - ambiguity .A hand - made de - novo proof of the non - ambiguity of a new grammar G requires an inductive argument on the number of parses corresponding to the same annotation sequence .", "label": "", "metadata": {}, "score": "52.782806"}
{"text": "If I want to do high performance linear algebra , I do n't need to go to Fortran , I can use boost::numeric::ublas .The list goes on ... .5 for this message ( and I 'll give you 5 for the article when I actually take time to carefully read it ) .", "label": "", "metadata": {}, "score": "52.79571"}
{"text": "Still , that does not seem that useful yet , does it ?We still have to do all the work in our one parse method , we need no fancy - schmanzy FP for that , you can do that in Fortran with a big array and a bunch of GOTOs .", "label": "", "metadata": {}, "score": "52.800304"}
{"text": "For simplicity , we chose probabilities independent of certain bases .In SCFG design , often also non - canonical base pairings are allowed with a low probability .For grammar G 1 , the derivations shown in Figure 1 have probabilities of 5.24\u00b710 -14 , 2.1\u00b710 -15 , 4.19\u00b710 -16 and 4.19\u00b710 -16 ( from left to right ) .", "label": "", "metadata": {}, "score": "52.86758"}
{"text": "We added to the error result , but did n't really help clean up the output .Instead of trying another parser in the event of a failure , it presents an error message .Here 's how we 'd use it : .", "label": "", "metadata": {}, "score": "52.926273"}
{"text": "The language B is similar , but it starts with a group of any length followed by two groups of the same length .Both are context - free .In fact , our parser brackets can be used to parse the two character groups with the same length .", "label": "", "metadata": {}, "score": "53.058617"}
{"text": "For example , our earlier brackets parser can be written using the applicative combinators : .The example first creates a parser that always succeeds and returns a function using the pure combinator .Then it applies this function ( contained in a parser ) to three arguments ( produced by the three parsers ) .", "label": "", "metadata": {}, "score": "53.088943"}
{"text": "In this article , I would like to show there is an other , more powerful , way of processing text which is as easy to use as regexps - parser combinators .I first encountered parser combinators during Haskell courses on the university .", "label": "", "metadata": {}, "score": "53.123497"}
{"text": "Performing this test on a large number of inputs x should give a good hint whether ambiguity is present .Of course , enumerating the annotation sequences for all possible derivation trees creates voluminous output , and the automated check for duplicates requires some careful programming .", "label": "", "metadata": {}, "score": "53.166862"}
{"text": "2.1 Introducing parsers .A parser is a function that takes an input string and returns a list of possible results .It may be empty ( if the parser fails ) or contain several items ( if there are multiple ways to parse the input ) .", "label": "", "metadata": {}, "score": "53.18203"}
{"text": "If the grammar is ambiguous , this will be detected with the first application where it occurs .Proving non - ambiguity .Proving the absence of ambiguity in a grammar is of course better than any test procedure .Semantic ambiguity in dynamic programming is unde - cidable .", "label": "", "metadata": {}, "score": "53.31331"}
{"text": "Dowell and Eddy suggest to run the test also for a sample of suboptimal annotation sequences for x .Since the minimizing Viterbi run gives us the least probable derivation tree , we may have a higher chance to find an ambiguous one ( if present ) than in the maximizing run .", "label": "", "metadata": {}, "score": "53.43857"}
{"text": "In this case , the probability of a certain annotation sequence is split up into the probabilities of its multiple derivations .In Figure 1 , this is exemplified by the two derivations on the left that both represent the annotation sequence ( ( ( ( .... ) ) ) ) .", "label": "", "metadata": {}, "score": "53.442513"}
{"text": "We first look at the laws that can be motivated by the category theory behind the operation , and then discuss additional laws inspired by the work on F # joinads .5.1 Basic laws of parallel bindings .As already briefly mentioned , the mzip operation can be viewed as a natural transformation defined by some monoidal functor [ 15 ] .", "label": "", "metadata": {}, "score": "53.48312"}
{"text": "Parsers farther up the line ( like our disjunctive parser ) are still holding a reference to the stream prior to these \" removals \" .This means that we do n't need to make any special effort to implement backtracking , it just falls out as a natural consequence of our use of the Stream data structure .", "label": "", "metadata": {}, "score": "53.539818"}
{"text": "My list of things that I would like to see in the standard probably includes : . 1 ) Some advancements to templates to improve their use in libraries .The export keyword ( virtually unsupported on compilers ) and explicit instantiation are only a partial solution in my view .", "label": "", "metadata": {}, "score": "53.58087"}
{"text": "In order to do that , we have to override the Parser class of the parent Parsers trait we inherit from so we can add the methods we want .If we do that , we get the following : .Now , by redeclaring Parser in our trait , all the previously defined Parsers are instances of our Parser class and therefore have the or method .", "label": "", "metadata": {}, "score": "53.65483"}
{"text": "either ?Furthermore : .What are the predictions towards grammatical complexity and mental work .load in other theories ?Take e.g. the latest grammatical theory : .Construction Grammar ( cf .Fillmore and Kay 1999 ; Goldberg 2003 ) .", "label": "", "metadata": {}, "score": "53.6659"}
{"text": "The point of this example is that we can quite nicely combine several independent rules , which makes the validation code easy to understand and extend .2.4 Parallel composition of context - free parsers .Monadic parser combinators are very expressive .", "label": "", "metadata": {}, "score": "53.67227"}
{"text": "And even if the most likely annotation sequence is returned by the Viterbi algorithm , its computed probability is too small when there are further derivations of this annotation sequence .As Dowell and Eddy have shown , this happens in practice and the effects are severe .", "label": "", "metadata": {}, "score": "53.72125"}
{"text": "Since the generated parser can only read a limited number of input characters ahead ( k ) , the parser generator is not able to construct a deterministic parser for this situation and reports a conflict .However , we can circumvent this problem by extending the alphabet of the annotation sequence by an additional character ( say , ' :') for unpaired bases in left bulges 1 : .", "label": "", "metadata": {}, "score": "53.800674"}
{"text": "It uses two generators to implement a Cartesian product of the two collections .The second example adds a guard to specify that we want only pairs of strings whose second character is the same .The guard serves as an additional filter for the results .", "label": "", "metadata": {}, "score": "53.99198"}
{"text": "For an arbitrary context free grammar G , we can construct a DP problem where L ( G ) serves as the canonical model , and show that the context free grammar G is ambiguous if and only if the DP problem is semantically ambiguous .", "label": "", "metadata": {}, "score": "54.175697"}
{"text": "actually raises a few interesting questions : .If one adopts a computational theory of mind , how can one avoid postulating .mental processes / operations ?I fully agree with that .If , as assumed , e.g. , in the Minimalist Program .", "label": "", "metadata": {}, "score": "54.209602"}
{"text": "Let 's give it an end - of - line character and continue experimenting .Right [ [ \" Hi\",\"\"],[\"\"],[\"\",\"Hello \" ] ] .You can see that parseCSV is doing exactly what we wanted it to do .It 's even handling empty cells and empty lines properly .", "label": "", "metadata": {}, "score": "54.32157"}
{"text": "They both read a single character and they succeed if the character is not ' ( ' and ' ) ' respectively .The resulting parser succeeds only if both of them succeed .Both parsers return the same character , so we return the first one as the result and ignore the second .", "label": "", "metadata": {}, "score": "54.530212"}
{"text": "This means that we do n't actually evaluate our constructor parameters until the parser is applied to a specific stream .This is very important as it allows us to define parsers with recursive rules .Recursion is really what separates context - free grammars from regular expressions .", "label": "", "metadata": {}, "score": "54.57888"}
{"text": "To those of you familiar with the process of building a balanced binary tree , this process is remarkably similar .The diagram below demonstrates the process : .Following this process through , we can see that the first two steps involve adding numeric leaf nodes to the root node .", "label": "", "metadata": {}, "score": "54.583298"}
{"text": "The best optimization techniques I have found ( and read about ) involve eliminating backtracking .Merge common prefixes in productions .This reduces the formal strength of your grammar , but also tends to factor shared code into a single location . combinator to halt backtracking for a specific location in a production .", "label": "", "metadata": {}, "score": "54.586205"}
{"text": "Now that is nice and readable .We can now parse one of our chars , but we wanted to parse a whole string of them !So we need a way to say \" apply this Parser again and again as often as possible \" .", "label": "", "metadata": {}, "score": "54.606224"}
{"text": "The first one is usually called naturality and it specifies the behavior of mzip with respect to the map function of a monad ( the function can be implemented in terms of bind and return and corresponds to liftM from the Haskell base library ) .", "label": "", "metadata": {}, "score": "54.700672"}
{"text": "Not only that the syntax is elegant , but the desugaring also performs a simple sanity check on our code .5 Parallel comprehension laws .I have intentionally postponed the discussion about laws to the end of the article .So far , we have looked at three different implementations of mzip .", "label": "", "metadata": {}, "score": "54.902214"}
{"text": "The first example from the previous section used multiple generators and can be translated purely in terms of Monad : . return $ a + + \" \" + + b ) ) .The operations are nested , and the innermost operation always returns the result of the output function .", "label": "", "metadata": {}, "score": "54.958015"}
{"text": "Proof .We show that for a given CFG G there exists a DP problem and an associated canonical model such that the DP algorithm is semantically am biguous if and only if the grammar is fl - ambiguous .Given an algorithm to decide ambiguity for DP problems , we could hence decide ambiguity for context free grammars , which is impossible .", "label": "", "metadata": {}, "score": "55.015022"}
{"text": "For each matching combination , the parser returns a tuple with the two parsing results .Requiring that the two parsers consume the same number of characters is not an arbitrary decision .It means that the remaining unconsumed strings tail1 and tail2 are the same and so we can return either of them .", "label": "", "metadata": {}, "score": "55.025414"}
{"text": "For instance , we can not use regular expressions to parse source code from most programming languages .Parsec is a useful parser combinator library , with which we combine small parsing functions to build more sophisticated parsers .Parsec provides some simple parsing functions , as well as functions to tie them all together .", "label": "", "metadata": {}, "score": "55.07984"}
{"text": "Try it in ghci : .Loading package parsec-2.1.0.0 ... linking ... done .Right \" \\n \" .It may seem like the parser worked for both endings , but actually looking at it this way , we ca n't tell .", "label": "", "metadata": {}, "score": "55.247223"}
{"text": "If you 're familiar with applicative functors , you may know that there is an alternative definition of Applicative that uses an operation with the same type signature as mzip .We could use mzip to define an Applicative instance , but this would give us a very different parser definition !", "label": "", "metadata": {}, "score": "55.28023"}
{"text": "Now we could provide the same Parser for ' b ' , ' 0 ' and ' 1 ' , but that would of course be pretty daft .Instead , we extend our Parser to parse any char we want : .", "label": "", "metadata": {}, "score": "55.306755"}
{"text": "However I only really understood how Parser Combinators work when I had studied the source and had written some I was missing myself , so let 's build some simple Parsers and Combinators ourselves , from the ground up .We will be solving a really simple parsing task : accept any input that consists of the chars ' a ' , ' b ' , ' 0 ' and ' 1 ' .", "label": "", "metadata": {}, "score": "55.32399"}
{"text": "Without it , the fearTheOnes method would enter an infinite loop and would never return an instance of Parser .However , for all its glitz , our framework is still somewhat impotent compared to \" real \" parser generators .It is almost trivial to derive a grammar which can not be handled by our parser combinators .", "label": "", "metadata": {}, "score": "55.3552"}
{"text": "When evaluating a resumption , we repeatedly run the computation step - by - step .While evaluating , we perform the effects allowed by the monad m until we eventually get a result of type r .If you 're interested in more details about the Resumption type , you can find similar definitions in Harrison 's cheap threads [ 11 ] and Papaspyrou 's resumption transformer [ 12 ] .", "label": "", "metadata": {}, "score": "55.366753"}
{"text": "That however sounds like it is straight out of the Department Of Redundancy Department , so we stick with the former .We have just established that \" Parsers \" are functions that parse input into output together with some error handling and tracking what the current input is .", "label": "", "metadata": {}, "score": "55.425293"}
{"text": "In other cases , ambiguity can cause a DP algorithm to return an \" optimal \" answer which is plainly wrong .Previous work .The phenomenon of ambiguity has been formalized and studied in [ 3 ] in a quite general framework of dynamic programming over sequence data .", "label": "", "metadata": {}, "score": "55.433212"}
{"text": "And finally , we take the five digit number identifying the recording : .All that we need to do now is thread all these parsers together , and we 're done !One option could be to do the following : . , isrcRegCode : : String . , isrcRegYear : : Int . deriving ( Show ) .", "label": "", "metadata": {}, "score": "55.446793"}
{"text": "( If you are parsing Strings , most of the time you will want to extend that trait and not Parsers )To use your own Parser trait you just mix it into the class you want to do the parsing with .", "label": "", "metadata": {}, "score": "55.530167"}
{"text": "List comprehensions are a very powerful mechanism for working with lists in Haskell .I expect that you 're already familiar with them , but let me start with a few examples .I will use the examples later to demonstrate how the generalized monad comprehension syntax works in a few interesting cases .", "label": "", "metadata": {}, "score": "55.55687"}
{"text": "In short , these combinators are only interesting to people who want their parsers to give them a value upon completion ( usually an AST ) .In short , just about any useful application of parser combinators will require these combinators , but since we 're not planning to use our framework for anything useful , there is really no need .", "label": "", "metadata": {}, "score": "55.566963"}
{"text": "There is no way to refer to the \" structure \" of a monadic value directly , but we can create values with a given structure using map .This weaker law holds for both lists and parsers .Additionally , we can describe the case when one of the two computations is mzero and when both of them are created using return : .", "label": "", "metadata": {}, "score": "55.56817"}
{"text": "Specifying parallel evaluation order .The mzip operator for the evaluation order monad encapsulates a common pattern that runs two computations in parallel .We 've seen an example in the previous section - the first computation is started using rpar and the second one is evaluated eagerly in parallel using rseq .", "label": "", "metadata": {}, "score": "55.599888"}
{"text": "If there are no more , the result depends on the //reader .Preferably some special token indicating the end of input //is returned .Now we need to provide input //for all following Parsers . \" rest \" does that for us .", "label": "", "metadata": {}, "score": "55.623222"}
{"text": "Once the input has been parsed , an expression tree will exist in the m_parser object .You can visit this tree to get out the results of the expression , or to print the tree in a formatted way .For example : .", "label": "", "metadata": {}, "score": "55.675095"}
{"text": "As the parser proceeds from head to head it is furthermore possible to use powerful top - down predictions based on the usual head feature percolations .In section 4.5 I show how the head - driven parser can be put to use for another instantiation of constraint - based grammars in which string operations are restricted to be linear and non - erasing : constraint - based and lexical versions of Tree Adjoining Grammars .", "label": "", "metadata": {}, "score": "55.68164"}
{"text": "To support parallel monad comprehensions , we need to implement MonadZip .As a reminder , the type class defines an operation mzip with the following type : .This is a reasonable definition for some monads , such as the Reader monad , but not for all of them .", "label": "", "metadata": {}, "score": "55.702213"}
{"text": "The previous example was of course overly complicated , but it helps understand how Parser Combinators actually work under the hood .Most tutorials try to impress people too much at first with a lot of high - level fancy parsing that is very slick , but does not really teach how it actually works .", "label": "", "metadata": {}, "score": "55.764038"}
{"text": "Here we put both of the two - character endings first , and run both tests under try .We could have put string \" \\n \" within a try , but it would n't have altered any behavior since they look at only one character anyway .", "label": "", "metadata": {}, "score": "55.81434"}
{"text": "Readers who have managed to stay awake to this point may notice that I 'm actually cheating a bit in these definitions .Specifically , I 'm using the ^^ and ^^^ combinators .These are the semantic action combinators which I promised to avoid discussing .", "label": "", "metadata": {}, "score": "55.87182"}
{"text": "It 's helpful to know where Parsec fits compared to the tools used for parsing in other languages .Parsing is sometimes divided into two stages : lexical analysis ( the domain of tools like flex ) and parsing itself ( performed by programs such as bison ) .", "label": "", "metadata": {}, "score": "55.90464"}
{"text": "We introduce , for the special case of stochastic context free grammars and RNA structure modeling , an automated partial procedure for proving non - ambiguity .It is used to demonstrate non - ambiguity for several relevant grammars .Conclusion .", "label": "", "metadata": {}, "score": "55.90773"}
{"text": "Conclusion .Parser combinators are an incredibly clever bit of functional programming .Every time I think about them , I am once again impressed by the ingenuity of their design and the simple elegance of their operation .Despite their simplicity , parser combinators are capable of some very powerful parsing in a very clean and intuitive fashion .", "label": "", "metadata": {}, "score": "55.927094"}
{"text": "This is particularly convenient as it allows for a very nice syntax in pattern matching for semantic actions ( extracting parse results ) .However , since we will not be dealing with the action combinators in this article , it seemed simpler to just use a tuple .", "label": "", "metadata": {}, "score": "55.954746"}
{"text": "It is not quite the same problem , however .In striving for avoidance of ambiguity , we want to get rid of the bad type and retain the good .Ambiguity is not a problem with a dynamic programming ( DP ) algorithm that returns a single , optimal score , together with a solution that achieves this score , and does not make assertions about other solutions in the search space .", "label": "", "metadata": {}, "score": "56.048466"}
{"text": "Because the Parser type is an instance of MonadPlus , we can use the predicate pred ch as a guard .The desugared version of the function is : .The some and many combinators are mutually recursive .The first creates a parser that parses one or more occurrences of p .", "label": "", "metadata": {}, "score": "56.241974"}
{"text": "The task of parsing a file , or data of various types , is a common one for programmers .We already learned about Haskell 's support for regular expressions back in the section called \" Regular expressions in Haskell \" .", "label": "", "metadata": {}, "score": "56.3201"}
{"text": "Let 's get back to the example with parsing brackets .The following snippet uses parallel monad comprehensions to create a version that consumes all brackets : .The parser body takes zero or more of any characters that are not opening or closing brackets .", "label": "", "metadata": {}, "score": "56.36331"}
{"text": "Here is a full CSV parser .You can use this from ghci , or if you compile it to a standalone program , it will parse a CSV file on standard input and convert it to a different format on output .", "label": "", "metadata": {}, "score": "56.44886"}
{"text": "Once again , we can beautify the syntax a little bit by adding an operator to the Parser super - trait : . ... is that all ?Just in case you do n't believe me , consider the grammar for the pure - untyped lambda calculus , expressed using our framework ( alph definition partially elided for brevity ) : .", "label": "", "metadata": {}, "score": "56.53795"}
{"text": "Now we can build a Parser that parses one of our desired chars like this : .Well , this works , but that does not look particularly nice , does it ?We would want a nice infix notation here .", "label": "", "metadata": {}, "score": "56.55297"}
{"text": "For example , if you use a functor which has not yet been defined , you will quite often get a C1001 , Internal Compiler Error .Conclusions .Once you have created a parser in the Spirit Framework , it is pretty easy to plumb in semantic actions .", "label": "", "metadata": {}, "score": "56.68334"}
{"text": "The mzero operation creates a parser that always fails , and mplus represents a nondeterministic choice between two parsers .The two type class instances allow us to use some of the monad comprehension syntax .We can now use the item primitive to write a few simple parsers : .", "label": "", "metadata": {}, "score": "56.72307"}
{"text": "MOVE .Yet , I wonder whether long - distance AGREE isn t more complex for LF . since it involves another PROBE - GOAL search whereas identifying copies of .moved elements might be easier . ]However , another point is that the human parser might use non - grammar . information in addition to grammar , i.e. some kind of heuristic principle .", "label": "", "metadata": {}, "score": "56.804466"}
{"text": "In this section , I demonstrate the idea using a poor man 's concurrency monad inspired by Claessen [ 10 ] .The monad can be used to implement a lightweight cooperative concurrency .When running two computations in parallel , we can allow interleaving of atomic actions from the two threads . 3.1 Modelling resumable computations .", "label": "", "metadata": {}, "score": "56.882256"}
{"text": "When we look at the format of the first FEN element , we can see some repetition there .We can thus create a parser which parses one rank and parsing of the whole board will be a composition of rank parsers .", "label": "", "metadata": {}, "score": "56.908558"}
{"text": "The standard Haskell libraries include a module named Control .Applicative , which we already encountered in the section called \" Infix use of fmap \" .This module defines a typeclass named Applicative , which represents an applicative functor .This is a little bit more structured than a functor , but a little bit less than a monad .", "label": "", "metadata": {}, "score": "56.966194"}
{"text": "That will limit expressiveness over grammars that rely on combinatorial explosion of matching options , etc . , but would help with speed .Ambiguity checking would n't happen until runtime though .In the framework implemented above ( as in Scala 's standard framework ) , circularity problems are avoided by the following declaration : .", "label": "", "metadata": {}, "score": "57.02619"}
{"text": "This grammar in particular is O(n^4 ) for all valid input : .Also , GLR is not fully generalized .There are grammars for which GLR ( as with any shift - reduce parsing technique ) is undefined : .Granted , most GLR parser generators will transform the above grammar into something which is actually usable within the constraints of the algorithm , but it does n't change the fact that GLR is not entirely what it claims to be .", "label": "", "metadata": {}, "score": "57.05867"}
{"text": "The laws for monoidal functors specify that if we combine munit with any other value using mzip , we can recover the original value using map snd .It is important to realize that the computation created using monadic return is n't the same thing as unit of the monoidal functor associated with mzip .", "label": "", "metadata": {}, "score": "57.12534"}
{"text": "For details consult its documentation .School example : Infix to prefix conversion .Let 's go to another example , now something what can not be done using regular expressions .We have a following grammar producing boolean expressions : .", "label": "", "metadata": {}, "score": "57.23195"}
{"text": "-- file : ch16/JSONParsec .The only piece of functionality that applicative functors are missing , compared to monads , is the ability to bind a value to a variable , which we need here in order to be able to validate the value we 're trying to decode .", "label": "", "metadata": {}, "score": "57.281345"}
{"text": "Ambiguity reduction .Paired bases can always also be unpaired - this creates the syntactic ( good ) ambiguity .Used in concert , they create the \" good \" ambiguity that allows us to parse \" CAAAG \" either as \" ( ... ) \" or as \" ..... \" .", "label": "", "metadata": {}, "score": "57.39705"}
{"text": "Then you can run the resulting application with command line arguments + RTS -N2 -RTS , which specifies that the runtime should use two threads .I measured the performance on a dual - core Intel Core 2 Duo CPU ( 2.26GHz ) .", "label": "", "metadata": {}, "score": "57.41687"}
{"text": "We promised you earlier that we could simplify our CSV parser significantly by using a few Parsec helper functions .There are two that will dramatically simplify this code .The first tool is the sepBy function .This function takes two functions as arguments : the first function parses some sort of content , while the second function parses a separator .", "label": "", "metadata": {}, "score": "57.436394"}
{"text": "Once we have the sequence combinator in hand , we can add a bit of syntax sugar to enable its use .With this modification to Parser , we can now create parsers which match arbitrary sequences of tokens .For example , our framework so far is more than sufficient to define the classPrefix parser from our earlier snippet ( with the exception of the regular expression defined in ID , which we currently have no way of handling ) : .", "label": "", "metadata": {}, "score": "57.46858"}
{"text": "I will deal with the details of these functors in a later section in this article .There are many ways in which input can be processed .In the case of a simple command line calculator , it is usually possible to simply process the input as it comes in , with an evaluation stack .", "label": "", "metadata": {}, "score": "57.48919"}
{"text": "But what about increased neuronal activity ?Has anyone so far carried out an fMRI ( functional magnetic resonance . imaging ) study on increased neuronal network activation as an effect of .syntactic complexity ?And if so , do these studies also contrast production .", "label": "", "metadata": {}, "score": "57.53685"}
{"text": "ambiguous .In Table 1 we also report on the number of conflicts found by the parser generator for increasing values of k .While the nature of these conflicts is not relevant for us , the table shows that various behaviors are possible .", "label": "", "metadata": {}, "score": "57.56306"}
{"text": "Since we use try , this is properly recognized as not a character that 's part of the cell , so it terminates the many quotedChar expression as expected .Lookahead has once again proven very useful , and the fact that it is so easy to add makes it a remarkable tool in Parsec .", "label": "", "metadata": {}, "score": "57.646492"}
{"text": "4.1 Introducing the evaluation - order monad .The evaluation - order monad is represented by a type Eval a .These functions take a value of type a , which may be unevaluated , and wrap it inside the monad .", "label": "", "metadata": {}, "score": "57.689262"}
{"text": "The parser parses p followed by many p .Another way to write the some parser would be to use combinators for working with applicative functors .However , using combinators becomes more difficult when we need to specify a guard as in the sat parser .", "label": "", "metadata": {}, "score": "57.71936"}
{"text": "It also adds several constructs that generalize imperative features of F # , including while and for loops as well as exception handling .The joinads extension adds support for pattern - matching on \" monadic values \" .For example , you can define a parallel programming monad and use joinads to wait until two parallel computations both complete or wait until the first of the two completes returning a value matching a particular pattern .", "label": "", "metadata": {}, "score": "57.808098"}
{"text": "Writing parallel algorithms .The + /- 1.4x speedup is less than the maximal 2x speedup , because the example parallelizes two calculations that do not take equally long .To generate a better potential for parallelism , we can implement a recursive pfib function that splits the computation into two parallel branches recursively until it reaches some threshold : .", "label": "", "metadata": {}, "score": "57.82334"}
{"text": "Aho A , Ullman J : The Theory of Parsing , Translation and Compiling Englewood Cliffs , NJ : Prentice - Hall 1973 .[ I and II ] .Giegerich R , Meyer C , Steffen P : A Discipline of Dy namic Programming over Sequence Data .", "label": "", "metadata": {}, "score": "57.86962"}
{"text": "It returns a list of all the content that it was able to parse .The second tool is endBy .It 's similar to sepBy , but expects the very last item to be followed by the separator .That is , it continues parsing until it ca n't parse any more content .", "label": "", "metadata": {}, "score": "57.919884"}
{"text": "Finally , the unit merge law describes how mzip works with respect to the monadic return operation .This is interesting , because we 're relating mzip of one applicative functor with the unit of another applicative functor ( defined by the monad ) .", "label": "", "metadata": {}, "score": "57.99971"}
{"text": "Firstly , you need to place the functors in suitable locations within the grammar .Secondly , you need to ensure that the functors can pass any action onto the application appropriately .If you look back at the two functors defined above , both of them take a reference to a CParser which in the case of this application is the overall managing class .", "label": "", "metadata": {}, "score": "58.00406"}
{"text": "The overall idea is to combine a lot of little , simple Parsers into a powerful complex one .So our Parser probably only parses a small part of the input and leaves something behind for another Parser to continue .That something is again of the same type as the original input and needs to be attached to the result , so we modify our Result class a bit : . sealed abstract class Result case class Success(result : Output , next : Input ) extends Result case class Failure(message : String , next : Input ) extends Result .", "label": "", "metadata": {}, "score": "58.045174"}
{"text": "The discussion about the patch [ 2 ] suggests one more law that relates the mzip operation with the map operation of the monad , called information preservation : .The law specifies that combining a computation with some other computation using mzip and then recovering the original form of the value using map does n't lose information .", "label": "", "metadata": {}, "score": "58.066986"}
{"text": "The problem is that the second argument to mzip attempts to access the value na which is defined later .The value is the result of the first expression , so we can access it only after both of the two parallelized operations complete .", "label": "", "metadata": {}, "score": "58.15271"}
{"text": "To demonstrate the process of placing functors in the grammar , I will show you a section of the grammar : . definition ( Syntax const & self ) .uint_p [ Private::AddNumericChild ( self.m_parser ) ] .; // Parse a bracketed expression , a single integer , or a unary // plus or minus .", "label": "", "metadata": {}, "score": "58.195236"}
{"text": "Ok , maybe that was a little melodramatic , but I can say that parsing with Haskell is an activity that I no longer dread , in fact - I find it fun and exciting ! parsec is a parser combinator library that provides a set of primitives for parsing .", "label": "", "metadata": {}, "score": "58.33259"}
{"text": "We can use sepBy to parse cells , since the last cell will not end with a comma .Take a look at how much simpler our parser is now : . -- file : ch16/csv2 .This program behaves exactly the same as the first one .", "label": "", "metadata": {}, "score": "58.42575"}
{"text": "However , if we create values using return , we can then apply mzip and specify how they should be evaluated later .This means that mzip only works for Eval computations created using return .Once we understand this , implementing mzip is quite simple .", "label": "", "metadata": {}, "score": "58.46748"}
{"text": "I have numerous examples of resolved issues at my Google code tracker for Copute .So that speed up in development effort incurs a cost that is going to paid ( probably more excruciatingly ) down the line .In the general case , recursive descent parsers are not limited to the Context - free grammar and thus do no global search for ambiguities in the LL(k ) parsing First_k and Follow_k sets .", "label": "", "metadata": {}, "score": "58.518314"}
{"text": "The real power of parser combinators is in what happens when you start combining them together ( hence the name ) .A few literal parsers combined in sequence can give us a phrase in our grammar , and a few of these sequences combined in a disjunction can give us the full power of a non - terminal with multiple productions .", "label": "", "metadata": {}, "score": "58.576042"}
{"text": "Although the individual parsers are mostly untouched , the combinators that we 're gluing them together with have changed .Before we continue , here 's a useful aid for remembering what all the angle brackets are for in the combinators from Control .", "label": "", "metadata": {}, "score": "58.59639"}
{"text": "The syntax is available after enabling the ParallelListComp language extension .It allows us to take elements from multiple lists , so that the n th element of the first list is matched with the n th element of the second list .", "label": "", "metadata": {}, "score": "58.661423"}
{"text": "This is all valid and correct Scala .The program method returns an instance of Parser[List[Class _ ] ] , assuming that Class _ is the AST class representing a syntactic class in the language ( and assuming that we had added all of the boiler - plate necessary AST generation ) .", "label": "", "metadata": {}, "score": "58.70266"}
{"text": "As usual , we think that the best way to introduce applicative functors is by putting them to work .In theory , every monad is an applicative functor , but not every applicative functor is a monad .Because applicative functors were added to the standard Haskell libraries long after monads , we often do n't get an Applicative instance for free : frequently , we have to declare the monad we 're using to be Applicative or Alternative .", "label": "", "metadata": {}, "score": "58.836113"}
{"text": "What 's more , we can do this in a very declarative fashion .Thanks to the magic of DSLs , our sources will actually look like a plain - Jane context - free grammar for our language .This means that we get most of the benefits of a hand - written parser without losing the maintainability afforded by parser generators like bison .", "label": "", "metadata": {}, "score": "58.8875"}
{"text": "This is a very academic name for a very simple concept .Let 's think about the framework so far .We have both literal parsers and sequential combinations thereof .Using this framework , we are capable of defining parsers which match arbitrary token strings .", "label": "", "metadata": {}, "score": "59.133896"}
{"text": "A more interesting definition for parsers , which can not be expressed using other monad primitives , is parallel composition : . instance MonadZip Parser where .[( ( a , b ) , n1 , tail1 ) .The parser created by mzip independently parses the input string using both of the parsers .", "label": "", "metadata": {}, "score": "59.15251"}
{"text": "Philip Carr mentions the ill - fated Derivational Theory of Complexity .( DCT ) which assumed that postulated analyses were taken to be analyses of .on - line mental operations .As Fodor et al ( 1974 ) showed , experimental data . seemed to undermine the DCT .", "label": "", "metadata": {}, "score": "59.18899"}
{"text": "The combination of strings is restricted to be linear ( non - copying ) and non - erasing ) .Next , I define , as an example of such a grammar , a simple grammar for Dutch , in which strings are combined by a technique quite similar to Pollard 's head wrapping .", "label": "", "metadata": {}, "score": "59.2259"}
{"text": "Every time we develop a new grammar , the dragon of ambiguity raises its head , but with the weapons presented here , we can be confident to defeat it .Methods .Our way to describe various tests by combining a grammar with varying scoring schemes is derived from the algebraic dynamic programming method , described in detail in [ 6 ] .", "label": "", "metadata": {}, "score": "59.366844"}
{"text": "By different interpretations of the operations H , o and P , different scoring schemes can be plugged in .The recurrences may also be \" conditioned \" by annotating the symbol sequence x with a given annotation sequence s [ 1 ] .", "label": "", "metadata": {}, "score": "59.40666"}
{"text": "Hence , v is injective if and only if G is non - ambiguous .Could we formally decide the semantic ambiguity of an arbitrary DP problem , we could do so for the problem given by G and \u03c3 , and hence , ambiguity of context free languages would be decidable .", "label": "", "metadata": {}, "score": "59.410553"}
{"text": "These are structurally similar , with an opening character , followed by one or more items separated by commas , followed by a closing character .We capture this similarity by writing a small helper function .-- file : ch16/JSONParsec .", "label": "", "metadata": {}, "score": "59.41478"}
{"text": "Now that we have a definition of parsers , we can create our first primitive parser and a function that runs a parser on an input string and returns the results : . item : : Parser Char .The item parser returns the first character of the input string .", "label": "", "metadata": {}, "score": "59.41725"}
{"text": "I have written two visitors for the composite tree .The first is a left to right visitor that will print the expression represented by the tree .The second is a bottom to top visitor that evaluates the expression represented by the tree .", "label": "", "metadata": {}, "score": "59.475918"}
{"text": "If you use the built in number parsers , for example , the uint_p parser will require a functor that takes a single unsigned int .This can be seen below : . struct AddNumericChild .m_parser .private : .Communicating Between the Parser and the Application .", "label": "", "metadata": {}, "score": "59.549965"}
{"text": "[ For the Minimalist junkies out there : this might not .be easy as I first thought .Chomsky ( 2000 )e.g. claims that long - distance .AGREE is simpler than MOVE , which actually is COPY+MERGE+AGREE .If we just .", "label": "", "metadata": {}, "score": "59.615376"}
{"text": "The runEval function unwraps the value and the Monad instance implements composition of computations in the usual way .The power of the monad comes from the evaluation annotations we can add .We transform values of type a into values of type Eval a ; while doing so , we can specify the evaluation strategy .", "label": "", "metadata": {}, "score": "59.6165"}
{"text": "In this article , we 'll just go through the examples from the previous section and examine what the translation looks like .The following declaration shows how to implement the Monad , MondPlus , and MonadZip type classes for lists : . instance Monad [ ] where .", "label": "", "metadata": {}, "score": "59.642357"}
{"text": "Structure counting for sample sequences .An even stronger test is possible when we have a reference grammar R available that generates the same language and is known to be semantically non - ambiguous .Grammar G will produce counts that are larger than those of R if and only if G allows ambiguous derivations for x .", "label": "", "metadata": {}, "score": "59.648582"}
{"text": "Notice what happens if left fails : it invokes the right parser passing the same Stream instance ( s ) .Recall that Stream is immutable , meaning that there is nothing left can do which could possibly change the value of s .", "label": "", "metadata": {}, "score": "59.768707"}
{"text": "The tested equation therefore holds if and only if the annotation sequence s has exactly one derivation tree .If there are more than one , the Inside algorithm will return a higher probability than the Viterbi run , which indicates ambiguity of s ( and hence G ) .", "label": "", "metadata": {}, "score": "59.875046"}
{"text": "For example , it does n't hold for lists if a and b are lists of different length , since the zip function restricts the length of the result to the length of the shorter list .Similarly , it does n't hold for parsers ( from the first section ) that consume a different number of characters .", "label": "", "metadata": {}, "score": "60.105804"}
{"text": "In order to implement whitespace - stripping in my parsers , I would have to do something similar to what RegexParsers does in the Scala combinator framework , which is basically pre - process the stream before every parser , stripping any leading whitespace .", "label": "", "metadata": {}, "score": "60.18237"}
{"text": "The Ackermann function is a well - known function from computability theory .It is interesting because it grows very fast ( as a result , it can not be expressed using primitive recursion ) .For example , the value of ack 4 2 is 2 65536 - 3 .", "label": "", "metadata": {}, "score": "60.183224"}
{"text": "Lookahead .Parsec has a function called try that is used to express lookaheads .try takes one function , a parser .It applies that parser .If the parser does n't succeed , try behaves as if it had n't consumed any input at all .", "label": "", "metadata": {}, "score": "60.209595"}
{"text": "The iterator parameters give you access to the input just parsed , although in this example I did not need the input .When you are designing a functor , it is important to understand the lifetime of these functors .A new functor is not created each time a semantic action is used , instead the same functor exists for the lifetime of the grammar object .", "label": "", "metadata": {}, "score": "60.229042"}
{"text": "Memoization is an interesting optimization and I would imagine a very effective one .The advantage here is it would make most disjunctions constant time as opposed to linear in the number of alternatives .Oh good , I did n't read the markup instructions and my whole comment got eaten .", "label": "", "metadata": {}, "score": "60.285244"}
{"text": "Table 1 summarizes the results for grammars G 1 to G 6 .For G 1 and G 2 , the results only show that both grammars are not LR ( 1 ) , LR ( 2 ) or LR ( 3 ) .", "label": "", "metadata": {}, "score": "60.326843"}
{"text": "Loading package parsec-2.1.0.0 ... linking ... done .Left ( line 1 , column 1 ) : . unexpected end of input .expecting \" \\n\\r \" .We 've stumbled upon the lookahead problem .It turns out that , when writing parsers , it 's often very convenient to be able to \" look ahead \" at the data that 's coming in .", "label": "", "metadata": {}, "score": "60.41877"}
{"text": "We will define Parser[A ] as a function from Stream[Character ] to Result[A ] , where Result[A ] has two implementations : Success[A ] and Failure .The framework looks like the following : . sealed trait Result [ + A ] .", "label": "", "metadata": {}, "score": "60.498074"}
{"text": "You can see the implementation of Monad instance for Resumption m below .The return operation creates a new resumption in the \" done \" state which contains the specified value .When the left parameter is Done , we apply the function to the result and wrap the application inside return ( because the function is pure ) and Step .", "label": "", "metadata": {}, "score": "60.561146"}
{"text": "Also they will never be as faster , because for the k lookahead conflicts , they follow unnecessary paths , because the global optimization ( look ahead tables ) was not done .I do n't see what is the benefit ?", "label": "", "metadata": {}, "score": "60.59509"}
{"text": "The canonical model plays an essential role .It is the mathematical formalization of the real - world domain we want to study , and \" canonical \" means one - to - one correspondence .Any formal proof can only deal with the formalization of the real - world domain , and when the one - to - one correspondence does not hold , all proofs of ( non- ) ambiguity would be meaningless for the real world .", "label": "", "metadata": {}, "score": "60.59589"}
{"text": "For a monoidal functor f , the type of unit is f ( ) .Every applicative functor in Haskell has a unit .For example , the unit value for ZipList is an infinite list of ( ) values .We do not necessarily need to add unit to the definition of MonadZip , because it is not needed by the desugaring .", "label": "", "metadata": {}, "score": "60.62121"}
{"text": ": We have just defined an abstract class and two child classes with working equals , toString , hashCode and getters in three lines .Put that in Java 's pipe and smoke it !But I digress .Now we just refine our parse method a bit : .", "label": "", "metadata": {}, "score": "60.721874"}
{"text": "We 'll get the same result from every one .Yet the program is much shorter and more readable .It wo n't be long before you can translate Parsec code like this into a file format definition in plain English .", "label": "", "metadata": {}, "score": "60.72798"}
{"text": "For me , Boost is an extension of all the things I like about C++ .If I want to do high performance linear algebra , I do n't need to go to Fortran , I can use boost::numeric::ublas .The list goes on ... .", "label": "", "metadata": {}, "score": "60.755795"}
{"text": "Note first of all , that a lot of the sentences considered more complex in .the Standard Theory would receive a much simpler Minimalist analysis .( direct merger of Adj in pre - modifier position , no underlying relative . clause ) .", "label": "", "metadata": {}, "score": "60.786022"}
{"text": "In each step , it performs one step of both of the resumptions given as arguments .When it reaches a state when both of the resumptions complete and produce results , it returns a tuple containing the results using Done .", "label": "", "metadata": {}, "score": "60.794243"}
{"text": "This first example is much longer than it really needs to be .We will introduce more Parsec features in a little bit that will shrink the parser down to only four lines !-- file : ch16/csv1 .Try to parse the first cell , then figure out -- what ends the cell .", "label": "", "metadata": {}, "score": "60.822014"}
{"text": "View Article .Zuker M , Stiegler P : Optimal Computer Folding of Large RNA Sequences using Thermodynamics and Auxiliary Information .Nucleic Acids Research 1981 , 9 : 133 - 148 .View Article PubMed .Chomsky N , Sch\u00fctzenberger MP : The algebraic theory of context - free languages .", "label": "", "metadata": {}, "score": "60.929543"}
{"text": "The parser may compute the overall probability of a given string , summing up probabilities over all its derivations , in which case it is called the Inside algorithm .Or , the parser can return the most likely derivation of the input string , in which case it is known as the Viterbi algorithm .", "label": "", "metadata": {}, "score": "60.9496"}
{"text": "Specifically , we can inherit and add members .Even state .That however can turn nasty , so I do not condone it .To the Scala Buffs : please forgive me if I have oversimplyfied this process , but in essence that should be correct and this understanding helped me a lot in getting a grasp around Scala in general and Parser Combinators in particular .", "label": "", "metadata": {}, "score": "61.15083"}
{"text": "We 've listed the types for the first example here so you can get a better idea of what 's going on .You can always use : t in ghci to inspect types as well .The csvFile uses a do block .", "label": "", "metadata": {}, "score": "61.31584"}
{"text": "The equation has already been identified as a law in the discussion about the patch [ 2 ] .The law is also required by applicative functors [ 8 ] - this is not surprising as applicative functors are also monoidal .", "label": "", "metadata": {}, "score": "61.33641"}
{"text": "Testing procedures .Brute force testing .Checking for duplicates in G ( Dotbracket , x ) .We can simply enumerate the dot - bracket representation of all structures exhaustively for a given input string and check for any repeats .", "label": "", "metadata": {}, "score": "61.394714"}
{"text": "3.3 Parallel composition of resumptions .If we have two resumptions , we can compose them to run in sequence either using the do notation or using a monad comprehension with two generators .To run them in parallel , we need to implement interleaving of the steps as shown in the next snippet : .", "label": "", "metadata": {}, "score": "61.55813"}
{"text": "This is demonstrated by the fact that the four derivation trees of Figure 1 all belong to the same symbol sequence .We now need to refine this notion of ambiguity .In modeling with SCFGs , derivations do not merely produce strings , but they represent objects of interest themselves .", "label": "", "metadata": {}, "score": "61.563564"}
{"text": "When we hit quotedChar , we will fail the noneOf test and proceed to the test that looks for two quotes in a row .We 'll also fail that one because we 'll have a quote , then a comma .", "label": "", "metadata": {}, "score": "61.58448"}
{"text": "In terms of classical logic , this parser corresponds to the AND operation .The code for this parser is almost ridiculously simple : .This is literally just a parser which applies its left operand and then applies its right to whatever is left .", "label": "", "metadata": {}, "score": "61.59847"}
{"text": "To keep the implementation simple , we keep applying step to both of the resumptions and then recursively combine the results .Applying step to a resumption that has already completed is n't a mistake .This operation does n't do anything and just returns the original resumption ( without performing any effects ) .", "label": "", "metadata": {}, "score": "61.61749"}
{"text": "We will need to write three parsers in total .Each one will correspond to a specific rule of the grammar : .Now , when our parsing infrastructure is ready , we only need to write a method which triggers parsing and then converts our internal representation of the expression into the prefix notation : . left ) + \" \" + doConvertToInfix ( x . left ) + \" \" + doConvertToInfix ( x .", "label": "", "metadata": {}, "score": "61.64992"}
{"text": "Computation expressions are quite similar to the do notation in Haskell .After implementing the F # version of joinads , I wanted to see how the ideas would look in Haskell .I was quite surprised to find out that a recent extension for GHC adds some of the expressive power of joinads to Haskell .", "label": "", "metadata": {}, "score": "61.87801"}
{"text": "GetModular ( ) ) ; value ( m_parser . pop ( ) ; .This code sets the base of the modular arithmetic on the CCalculateTreeVisitor , runs the visitor on the expression tree , and gets the result from the top of the visitor stack .", "label": "", "metadata": {}, "score": "61.974937"}
{"text": "It sounded interesting .I 'm glad that you added !I 'm not deeply into Scala , so forgive the ignorance that leads to this question : one of the issues I 've found with trying to create parser combinators in less expressive languages is the circularity problem in the grammar viewed as a graph .", "label": "", "metadata": {}, "score": "62.01111"}
{"text": "Let 's test this with ghci .[ 1 of 1 ] Compiling Main ( csv5.hs , interpreted ) .Ok , modules loaded : Main .Loading package parsec-2.1.0.0 ... linking ... done .Right ( ) .This time , we got the right result !", "label": "", "metadata": {}, "score": "62.113174"}
{"text": "Applications .For our experiments , we used the MSTA parser generator of the COCOM compiler construction toolkit [ 11 ] .MSTA is capable of generating LR ( k ) parsers for arbitrary k. Note that compiler writers prefer other parser generators like yacc [ 12 ] and bison [ 13 ] , which for efficiency reasons only implement LR ( 1 ) parsers .", "label": "", "metadata": {}, "score": "62.212894"}
{"text": "Just - in - time testing .While testing can not guarantee the non - ambiguity of the grammar , we can convert the previous idea to a test that ensures for each application run that the results are not affected by ambiguity .", "label": "", "metadata": {}, "score": "62.223976"}
{"text": "2 Composing parsers in parallel .What does a parallel composition of two parsers mean ?Probably the best thing we can do is to run both parsers on the input string and return a tuple with the two results .That sounds quite simple , but what is this construct good for ?", "label": "", "metadata": {}, "score": "62.249657"}
{"text": "I remember doing something similar few years back as a home assignment in C. If I had known parser combinators that time , the number of lines necessary would have reduced to one fifth or something like that .Our strategy will be following : instead of directly manipulate the input string , we will first convert the expression into our internal representation and then create a new string representing the very same expression , just in the prefix notation .", "label": "", "metadata": {}, "score": "62.27857"}
{"text": "If we were not using parallel monad comprehensions , we could mistakenly think that we can parallelize the function and write the following : . return a .This would compile , but it would n't run in parallel !The value na needs to be evaluated before the second call , so the second call to ack will block until the first one completes .", "label": "", "metadata": {}, "score": "62.30423"}
{"text": "Of course this will swallow all error messages we got , so this is only proof - of - concept .You can easily modify this to return what you like , e.g. Either[String , List[Char ] ] for either an error message or the result .", "label": "", "metadata": {}, "score": "62.307037"}
{"text": "Please note that first - time commenters are moderated , so do n't panic if your comment does n't appear immediately .Daniel Spiewak is a software developer based out of Wisconsin , USA .Over the years , he has worked with Java , Scala , Ruby , C / C++ , ML , Clojure and several experimental languages .", "label": "", "metadata": {}, "score": "62.369934"}
{"text": "While this result rules out an automated proof procedure for arbitrary grammars used in SCFG modeling , there might still be the possibility to design such a procedure for a restricted class of grammars , say all grammars which describe RNA secondary structures .", "label": "", "metadata": {}, "score": "62.462017"}
{"text": "The action function is quite simple .It returns a Step that runs the specified action inside the monad m and then wraps the result using the Done constructor .I implemented the function using monad comprehensions to demonstrate the notation again , but it could be equally written using combinators or the do notation .", "label": "", "metadata": {}, "score": "62.578403"}
{"text": "The algorithm proceeds in a bottom - up , head - driven fashion , which provides for bottom - up and top - down filtering in a simple and straightforward way .In modern linguistic theories very much information is defined in lexical entries , whereas rules are reduced to very general ( and very un - informative ) schemata .", "label": "", "metadata": {}, "score": "62.688175"}
{"text": "This parser uses the sequence combinator for Monad s to run a bunch of parsers , and collect all their results - then I just mconcat the results into a single String .Oh , did I just mention parsers are Monad s ?", "label": "", "metadata": {}, "score": "62.872124"}
{"text": "The best thing about modern C++ is the flexibility : we can easily mix high - level abstractions with low - level C ( or even assembly ) code when necessary .I think there has to be an article out there by someone concerning the future of C++ .", "label": "", "metadata": {}, "score": "62.891518"}
{"text": "In this section , we first review some sources of ambiguity and suggest three ways to deal with it : ambiguity avoidance , testing for ambiguity , and , best of all when successful , a mechanical proof of absence .Sources of ambiguity , and how to avoid them .", "label": "", "metadata": {}, "score": "62.902878"}
{"text": "The order of zipping feels like an implementation detail , but if we do n't require associativity , it may affect the meaning of our code .5.2 Parallel binding as monoidal functor .A monoidal functor in category theory defines a natural transformation ( corresponding to our mzip ) , but also a special value called unit .", "label": "", "metadata": {}, "score": "62.90367"}
{"text": "We could easily adapt our example to be able to handle all these types of line endings in a single file .We would need to make two modifications : adjust eol to recognize the different endings , and adjust the noneOf pattern in cell to ignore \\r .", "label": "", "metadata": {}, "score": "62.91249"}
{"text": "A nice consequence of using parallel comprehensions is that we can see which parts of the computation will run in parallel without any syntactic noise .We just replace a comma with a bar to get a parallel version !The compiler also prevents us from trying to parallelize code that can not run in parallel , because of data dependencies .", "label": "", "metadata": {}, "score": "63.01487"}
{"text": "The three laws that we 've seen so far are motivated by the category theory laws for the ( symmetric ) monoidal functors that define our mzip operation .However , we also need to relate the functors in some way to the monads with which we are combining them .", "label": "", "metadata": {}, "score": "63.117844"}
{"text": "However , we can still try to parallelize the function by replacing the two sequential generators with a parallel comprehension : .If you try compiling this snippet , you get an error message saying Not in scope : na .We can easily see what went wrong if we look at the desugared version : .", "label": "", "metadata": {}, "score": "63.151695"}
{"text": "AddChild ( CParser & parser , createPtr create ) : . m_parser .m_parser .private : .CParser & m_parser ; .Here , we have two operator ( ) s , one taking a single IteratorT , and the other taking a pair of IteratorT s. The single parameter version will be called when you attach an action to a single character parser , for example , the ch_p parser .", "label": "", "metadata": {}, "score": "63.180557"}
{"text": "Testing for ambiguity .Performing a test for semantic ambiguity allows us to obtain more confidence in the grammar , although testing can not prove non - ambiguity , but only ambiguity .Algorithmic arsenal for ambiguity testing .First , we create several variants of the Inside and Viterbi algorithms , which are our algorithmic arsenal for testing .", "label": "", "metadata": {}, "score": "63.19841"}
{"text": "Step by Step : Essays on .Minimalist Syntax in Honor of Howard Lasnik .Cambridge , Massachusetts : MIT Press.89 155 .Kay , Paul & Charles J. Fillmore .Grammatical . constructions and linguistic generalizations : The .What s X doing Y ? construction .", "label": "", "metadata": {}, "score": "63.354057"}
{"text": "The implementation looks as follows : . instance Monad Parser where .[( result , n1 + n2 , tail ) . p1 input + + p2 input ) .The return operation returns a single result containing the specified value that does n't consume any input .", "label": "", "metadata": {}, "score": "63.40351"}
{"text": "The try combinator has to hold onto input in case it needs to restore it , so that an alternative parser can be used .This practice is referred to as backtracking .Because try must save input , it is expensive to use .", "label": "", "metadata": {}, "score": "63.423897"}
{"text": "Unfortunately the implementation is c++ and rather geared towards parsing c++ ( which demonstrates that it can tackle challenging grammars , but does n't so much make it accessible for small languages ) .GLR is interesting , but it has some fairly serious flaws .", "label": "", "metadata": {}, "score": "63.520363"}
{"text": "As above , an extra nonterminal symbol is required to achieve non - ambiguity .Sometimes it is tempting to add a special case by using \u03b5 .The general case of \u03b5 -rules may be more tricky to handle .In general , all context free languages can be described without \u03b5 -rules , except possibly one for the axiom symbol .", "label": "", "metadata": {}, "score": "63.549736"}
{"text": "First Steps with Parsec : Simple CSV Parsing .Let 's jump right in by writing some code for parsing a CSV file .CSV files are often used as a plain text representation of spreadsheets or databases .Each line is a record , and each field in the record is separated from the next by a comma .", "label": "", "metadata": {}, "score": "63.55558"}
{"text": "This is a great article .But it takes no sense to evaluate it if not interested in the \" boost \" things .I could n't agree more .Design patterns are great - but they are only one of the many tools in the programmers toolbox .", "label": "", "metadata": {}, "score": "63.710262"}
{"text": "-- file : ch16/FormParse .The many1 function is similar to many : it applies its parser repeatedly , returning a list of their results .While many will succeed and return an empty list if its parser never succeeds , many1 will fail if its parser never succeeds , and will otherwise return a list of at least one element .", "label": "", "metadata": {}, "score": "63.71511"}
{"text": "The order of monadic bindings usually matters .The monad comprehension syntax makes this fact perhaps slightly less obvious than the do notation .To demonstrate this , let 's look at a parser that parses the body of an expression enclosed in brackets : .", "label": "", "metadata": {}, "score": "63.73898"}
{"text": "All languages somehow support regular expressions , they are relatively easy to use and all over the internet there are predefined ones for many common scenarios ( such as for a correct e - mail , domain name , etc . ) .", "label": "", "metadata": {}, "score": "63.750328"}
{"text": "The type of mzip partially specifies how the operation should behave , but not all well - typed implementations are intuitively right .In my understanding , the laws about mzip are still subject to discussion , although some were already proposed in the discussion about the GHC patch [ 2 ] .", "label": "", "metadata": {}, "score": "63.849667"}
{"text": "Grammar G 3 is LR ( 5 ) and G 4 to G 6 are LR ( 1 ) .Therefore , we have proved mechanically that the four \" good \" grammars studied by Dowell and Eddy are definitely non - ambiguous .", "label": "", "metadata": {}, "score": "63.863255"}
{"text": "Simply speaking , a DP problem is given by a grammar G and a scoring scheme \u03c3 ( not necessarily stochastic ) , as was exemplified in Section Testing for ambiguity .Theorem 1 Semantic ambiguity in dynamic programming is formally undecidable .", "label": "", "metadata": {}, "score": "63.883057"}
{"text": "Let 's take a look at the following code snippet : .[ 0 - 9][0 - 9 ] ? )[ 0 - 9][0 - 9 ] ? )[ 0 - 9][0 - 9 ] ? )[ 0 - 9][0 - 9 ] ? )", "label": "", "metadata": {}, "score": "63.910053"}
{"text": "-- file : ch16/FormParse .We can get rid of the need for explicit variables by using the liftM2 combinator from Control .Monad .-- file : ch16/FormParse .This parser has exactly the same type and behaviour as p_pair , but it 's one line long .", "label": "", "metadata": {}, "score": "63.96881"}
{"text": "If we did n't find a comma , we return the empty list , signifying no remaining cells on the line .Finally , we must define what the end - of - line indicator is .We set it to char ' \\n ' , which will suit our purposes fine for now .", "label": "", "metadata": {}, "score": "64.09418"}
{"text": "The run function applies the underlying function of the parser to a specified input .The next step is to make the parser monadic . 2.2 Implementing the parser monad .Parsers are well known examples of monads and of monoids .", "label": "", "metadata": {}, "score": "64.10567"}
{"text": "In his thesis [ 14 ] , Bj\u00f6rn Voss introduced a new grammar that promises to handle dangling bases of multiloop components in a non - ambiguous way .With 28 nonterminal symbols and 79 rules , the grammar is quite large .", "label": "", "metadata": {}, "score": "64.242424"}
{"text": "I tend to solve this particular problem by growing the tree below a customized root node .As each node in the tree is created , it is added to the root node .Initially , leaf nodes are added , but as composite nodes are added , they detach certain leaf nodes from underneath the root node , and add them to their own children lists .", "label": "", "metadata": {}, "score": "64.24718"}
{"text": "For example : SQL scripts or mathematical expressions .Once you have the composite tree , performing a variety of actions on the tree simply becomes a problem of writing an appropriate composite visitor .A visitor can easily re - output the tree in a new file format , or output the data after it has been edited by the program .", "label": "", "metadata": {}, "score": "64.32062"}
{"text": "Since these functions know nothing about Parsec , we have to work with them specially .Parsec 's getInput function gives us direct access to Parsec 's unconsumed input stream .If readSigned readFloat succeeds , it returns both the parsed number and the rest of the unparsed input .", "label": "", "metadata": {}, "score": "64.34325"}
{"text": "It 's later phases such as the type checker .Seth Tisue Monday , March 29 , 2010 at 12:33 pm .Any chance for a follow up expanding on scala 2.8 angle on parser combinators ?( packrat ? )One major problem with recursive descent algorithms , such as parser combinators , is they do not do a LL(k ) global search for First_k and Follow_k sets ambiguities at parser generation time .", "label": "", "metadata": {}, "score": "64.42402"}
{"text": "3 Parallelizing cooperative computations .As the name parallel monad comprehensions suggests , we can use the syntax for running computations in parallel .Unlike comprehensions with multiple generators , parallel comprehensions can not have any dependencies between the composed bindings .", "label": "", "metadata": {}, "score": "64.43007"}
{"text": "Phew , a lot of work for a single char .But remember , this was just to understand how it works under the hood .When you use Parser Combinators \" properly \" you can use all the goodies already provided by the Scala API !", "label": "", "metadata": {}, "score": "64.446335"}
{"text": "We are thinking in FP terms , so a Parser is obviously a function that turns something into something ( it parses the input and produces an output ) .So in sluggish Pseudo - Scala , it is something like this : .", "label": "", "metadata": {}, "score": "64.47114"}
{"text": "They will consume a certain number of tokens and then return a result along with the truncated stream .Alternatively , they will fail , producing an error message .Every Parser instance complies with this description .To be more concrete , consider the keyword parser ( what I like to call the \" literal \" parser ) which consumes a single well - defined token .", "label": "", "metadata": {}, "score": "64.69016"}
{"text": "Sampling structures from sample sequences .Dowell and Eddy suggested a testing procedure that relies on a comparison of the results from the Viterbi and the Inside algorithms , where the latter is conditioned on the most likely annotation sequence s returned by the Viterbi run .", "label": "", "metadata": {}, "score": "64.78715"}
{"text": "In this case , both occupiedSquaresParser and emptySquaresParser are of type Parser[List[Option[Piece ] ] ] and thus the result of the parser rep would be List[List[Option[Piece ] ] ] ] .Therefore , it is necessary to merge all the nested lists into a single one using flatMap ( ) .", "label": "", "metadata": {}, "score": "64.82611"}
{"text": "I want templates to be able to exist in a separate compilation unit without massive recompilation times . 2 ) Something to do with general abstract base classes .The Java Object class is an example of this .I do n't know exactly what I want here - but an option to make everything derive from an abstract base would be really useful - especially if that abstract base used policies to allow you to do such things as introduce optional garbage collection .", "label": "", "metadata": {}, "score": "64.92639"}
{"text": "A single derivation exists in G for a compatible RNA sequence x , and hence , G is semantically non - ambiguous .Non - ambiguity proof .As stated above , this question is undecidable in general .However , compiler technology provides a partial proof procedure : If a deterministic parser can be generated for a grammar , then it is non - ambiguous [ 5 ] .", "label": "", "metadata": {}, "score": "65.04968"}
{"text": "The possibilities are endless .In this article , I have used code from a previous article that I wrote entitled : Composites and Visitors - a Templatised Approach .This article provides a generic composite base class , as well as provides various schemes for visiting the entire composite tree in a particular order .", "label": "", "metadata": {}, "score": "65.06278"}
{"text": "But this test is much more thorough than our previous one , as the entire structure space of each tested x is analyzed .For example , a sequence of length 30 has an expected number of 175550 feasible structures [ 3 ] .", "label": "", "metadata": {}, "score": "65.21272"}
{"text": "Otherwise , we 're done .So , our first choice in remainingCells is char ' , ' .This parser simply matches the passed character in the input .If we found a comma , we want this function to return the remaining cells on the line .", "label": "", "metadata": {}, "score": "65.28606"}
{"text": "Therefore , the language generated by such grammar can not be described by regular expressions .Let 's say we want to write a method which would check if an expression passed as an argument is correct and convert it into the Scheme - like prefix notation ( incl . converting values true and false to # t and # f , respectively ) .", "label": "", "metadata": {}, "score": "65.36702"}
{"text": "For grammars that are rather distinct , the proof is as messy as the de - novo proof .Mechanical proof of non - ambiguity .We now present a mechanical technique that is a partial proof procedure for the case of modeling RNA structure with SCFGs : If it succeeds , it proofs non - ambiguity , if it fails , we do not know .", "label": "", "metadata": {}, "score": "65.403625"}
{"text": "Reader ) .This article is a re - publication of an article that I wrote some time ago for The Monad .Reader magazine , which is an online magazine about functional programming and Haskell .You can also read the article in the original PDF format as part of the Issue 18 ( together with two other interesting articles ) .", "label": "", "metadata": {}, "score": "65.54939"}
{"text": "So we start off with our skeleton Parser trait : .Now we add a simple Parser to the trait that parses the char ' a ' : .//though it is a function , we actually declare it like an //object , as we need to inherit all the other goodies //from the base Parser .", "label": "", "metadata": {}, "score": "65.554535"}
{"text": "Code examples are written in Scala , which provides very nice DSL for this purpose .However , parser combinator libraries exist for many languages and once you understand the concept , it should n't be difficult to port it across different languages .", "label": "", "metadata": {}, "score": "65.74902"}
{"text": "A tricky aspect of Eval is that it may represent computations with explicitly specified evaluation order ( created , for example , using rpar ) .We can also create computations without specifying evaluation order using return .The two arguments already have to be values of type Eval , but we want to specify the evaluation order using mzip after creating them .", "label": "", "metadata": {}, "score": "65.82007"}
{"text": "You 'd have to manually expand all the options after the \\n like this : .This function first looks for \\n .If it is found , then it will look for \\r , consuming it if possible .Since the return type of char ' \\r ' is a Char , the alternative action is to simply return a Char without attempting to parse anything .", "label": "", "metadata": {}, "score": "65.854515"}
{"text": "Has anyone ever thought about testing whether an increased number of . constructions leads to greater computational work load ?And what about neuronal activity ?As far as I can see a lot of the 1960 .s/1970s studies showed that allegedly higher complexity did n't result in .", "label": "", "metadata": {}, "score": "65.96936"}
{"text": "If the parser fails , optionMaybe does n't fail : it returns Nothing .Otherwise , it wraps the parser 's successful result with Just .This gives us the ability to distinguish between \" no value \" and \" empty value \" , as we mentioned above .", "label": "", "metadata": {}, "score": "66.09627"}
{"text": "So now we are missing only the Input .To understand how Input works we need to have a look at how Parser Combinators are organized in the Scala API .For now it suffices to look at scala / util / parsing / combinator / Parsers . scala where all necessary types and methods are defined .", "label": "", "metadata": {}, "score": "66.11827"}
{"text": "The most important of these is a root node which sits at the root of the tree and has all other nodes underneath .The reason for writing this root node concerns a particular detail of writing parsers that convert input into composite trees .", "label": "", "metadata": {}, "score": "66.260895"}
{"text": "Still , we shall refer to some DP algorithms that are not based on SCFGs , where our treatment also applies .SCFGs for RNA secondary structure analysis .We will further exemplify the above using the grammars G 1 to G 6 studied by Dowell and Eddy : . Dowell and Eddy showed that grammars G 1 and G 2 are semantically ambiguous , while G 3 to G 6 passed a partial test for non - ambiguity .", "label": "", "metadata": {}, "score": "66.272026"}
{"text": "This is because the many item parser can also consume brackets .To correct that , we need to write a parser that accepts any character except opening and closing brace .As we will see shortly , this can be elegantly solved using parallel comprehensions .", "label": "", "metadata": {}, "score": "66.3573"}
{"text": "What is important for us now is how we have to use the Parsers trait .It basically defines a little Microcosmos in which all the Parser Combinator stuff lives .If you want to write your own Parser ( do n't worry , we will get to that shortly ) , you define your own Parsers trait like this : .", "label": "", "metadata": {}, "score": "66.37677"}
{"text": "The lift function takes a computation in the monad m and turns it into a computation in the Resumption monad .This is exactly what our function for wrapping atomic actions does .Equipped with the two type class instances and the run function , we can write some interesting computations .", "label": "", "metadata": {}, "score": "66.43306"}
{"text": "So , saying many ( noneOf \" , \\n \" ) defines a cell the way we want it .Back in remainingCells , we have the first example of a choice in Parsec .This operator behaves like this : it will first try the parser on the left .", "label": "", "metadata": {}, "score": "66.53719"}
{"text": "The latter is a new class which has been added as a generalization of parallel list comprehensions .The name of the function makes it clear that the type class is a generalization of the zip function .The patch also defines a MonadGroup type class that generalizes grouping operations inside list comprehensions , but I will not discuss that feature in this article .", "label": "", "metadata": {}, "score": "66.596"}
{"text": "Some of the examples are inspired by my previous work on joinads that add a similar language extension to F#.The F # version includes an operation very similar to mzip from the newly included MonadZip type class .I also proposed several laws - some of them inspired by category theory and some by my work on F # joinads - hoping that this article may contribute to the discussion about the laws required by MonadZip .", "label": "", "metadata": {}, "score": "66.6047"}
{"text": "Instead , parallel list comprehensions use zipping of lists , which comes from a different applicative functor , namely ZipList .The example with parsers is similar .This would n't be very useful , so I defined mzip as the intersection of parsers .", "label": "", "metadata": {}, "score": "66.699234"}
{"text": "The only difference is that instead of zipping with an arbitrary monadic value b , we 're zipping a with a value constructed using map ( for any total functions f and g ) .This means that the actual value(s ) that the monadic value contains ( or produces ) can be different , but the structure will be the same , because map is required to preserve the structure .", "label": "", "metadata": {}, "score": "66.705795"}
{"text": "z']++['A ' .Z']++['0 ' .9']++\"$-_.toEnum $ d .Some characters can be represented literally .Spaces are treated specially , using a + character .Other characters must be encoded as a % character followed by two hexadecimal digits .", "label": "", "metadata": {}, "score": "66.80484"}
{"text": "This function is just a shortcut that calls Parsec 's parse function , filling in a few parameters . parse returns Either ParseError [ [ String ] ] for the CSV file .If there was an error , the return value will be Left with the error ; otherwise , it will be Right with the result .", "label": "", "metadata": {}, "score": "66.8659"}
{"text": "Parsec provides a way for you to specify custom error messages in the event of parse failures .Let 's look at what happens when our current CSV parser encounters an error : .[ 1 of 1 ] Compiling Main ( csv7.hs , interpreted ) .", "label": "", "metadata": {}, "score": "66.94413"}
{"text": "Applicative functors are more general than monads , which means that every monad is also an applicative functor .Referring to intuition is always tricky , so I 'll express my expectations more formally in terms of laws at the end of the article .", "label": "", "metadata": {}, "score": "66.968346"}
{"text": "The Spirit framework uses either function pointers or functors to callback from the parser into your application .I personally recommend using functors because of the increased object orientation .The functor itself must follow a set format , of which the Spirit framework supports a number .", "label": "", "metadata": {}, "score": "67.02633"}
{"text": "Semantic ambiguity in dynamic programming .Our treatment here extends to all dynamic programming algorithms that fall into the class known as algebraic dynamic programming ( ADP ) [ 6 ] .However , some definitions must be refined , as the ADP approach uses so - called yield grammars rather than ( S)CFGs .", "label": "", "metadata": {}, "score": "67.07498"}
{"text": "Within Parsers you find all the types we have discussed so far .Most importantly we find two type definitions : .We see that the definition of Elem is an abstract type .Why this is so and exactly why they do not make Parsers a generic trait like Parsers[Elem ] would be too much too discuss here .", "label": "", "metadata": {}, "score": "67.1181"}
{"text": "The explanation of the difference in effect lies with the degree of ambiguity .The degree of ambiguity of a given annotation sequence is the number of its derivations , i.e. a degree of 1 means that this annotation sequence is not ambiguous .", "label": "", "metadata": {}, "score": "67.23753"}
{"text": "So , in remainingCells , our task is to come up with all the cells after the first .Recall that cellContent uses noneOf \" , \\n \" .So it will not consume the comma or end - of - line character from the input .", "label": "", "metadata": {}, "score": "67.35391"}
{"text": "Stochastic context free grammars .Stochastic context free grammars associate a ( nonzero ) probability with each production , such that the probabilities for all alternative productions emerging from the same nonterminal symbol add up to 1 .As a string is derived , probabilities of the involved rules multiply .", "label": "", "metadata": {}, "score": "67.44097"}
{"text": "This solution is wrong if several \" different \" solutions represent the same real - world object .Dowell and Eddy experimented with two ambiguous SCFGs , and showed that the quality of results may range from just slightly wrong to totally useless .", "label": "", "metadata": {}, "score": "67.4451"}
{"text": "Semantic ambiguity is not a problem with the Inside algorithm , as a probability sum over all derivations is computed anyway .With the Viterbi algorithm , we can certainly obtain the most likely derivation , but we do not know whether it represents the most likely annotation sequence .", "label": "", "metadata": {}, "score": "67.457954"}
{"text": "The exact signature of the apply method depends on the signature of the function the object represents , so imagine the following function : .If you pass it around , you actually pass around an instance that is more or less equivalent to this Java class : .", "label": "", "metadata": {}, "score": "67.46922"}
{"text": "This will ( hopefully ) show you how useful end easy to use Parser combinators are !24 Days of Hackage : parsec .There comes a time in every programmer 's life when a plain old string just wo n't cut it anymore - you need more structure .", "label": "", "metadata": {}, "score": "67.479836"}
{"text": "Failure is just a \" normal \" error where the Parser could not parse the input .The get method can be called on any instance to retrieve the parsing result , on NoSuccess instances it will cause an Exception .The get method is used to peel the actual result out of the wrapper .", "label": "", "metadata": {}, "score": "67.50797"}
{"text": "For example , a valid Cambridge phone number consists of 10 symbols , contains only digits , and starts with 1223 .The new syntax allows us to directly encode these three rules : .The encoding is quite straightforward .We need some additional combinators , such as replicateM , which repeats a parser a specified number of times , and startsWith , which runs a parser and then consumes any number of characters .", "label": "", "metadata": {}, "score": "67.65752"}
{"text": "Then we look for the end - of - file indicator , called eof .Finally , we return the result .So , a CSV file is made up of many lines , then the end of file .We can often read out Parsec functions in plain English just like this .", "label": "", "metadata": {}, "score": "67.75984"}
{"text": "We start by running many line .many is a function that takes a function as an argument .It tries to repeatedly parse the input using the function passed to it .It gathers up the results from all that repeated parsing and returns a list of them .", "label": "", "metadata": {}, "score": "67.93654"}
{"text": "[ 13 ] .You can find the definition of Eval and its monad instance in the snippet below .We do n't need to know how rpar and rseq work , so we omit them from the listing .The Eval a type is simple .", "label": "", "metadata": {}, "score": "67.98172"}
{"text": "If we implement GameState this way , we will be able to use the following very concise code to convert a string , containing a game in FEN , into our internal representation : .Let 's now take a look what actually do we need to parse .", "label": "", "metadata": {}, "score": "68.10802"}
{"text": "It remains open whether specifically for the class of grammars that describe RNA secondary structure , this problem is decidable .We have proposed several tests , and a partial , mechanical proof procedure .We mechanically proved that the six grammars that passed Dowell and Eddy 's test for non - ambiguity are actually non - ambiguous .", "label": "", "metadata": {}, "score": "68.173874"}
{"text": "The good one is that there are many solutions to choose from .The bad one is that our algorithm may find the same solution several times , or even worse , it may study seemingly different solutions , which in fact represent the same object of interest .", "label": "", "metadata": {}, "score": "68.297035"}
{"text": "Thus , grammar G 1 is syntactically as well as semantically ambiguous .Semantic ambiguity is the \" bad \" , syntactic ambiguity the \" good \" type of ambiguity in SCFG modeling and dynamic programming that was mentioned above .On the pure formal language level , they can not be distinguished - both are manifest as fl - ambiguity .", "label": "", "metadata": {}, "score": "68.339096"}
{"text": "I just stumbled from a google search across your blog .Thanks for the great insight .This helped me a lot to understand the behavior of my experimental parsers written in scala .I also noted the lack of activity in your blog Any chance , you find the time for more elaborations in the future ?", "label": "", "metadata": {}, "score": "68.41669"}
{"text": "The return operation is unit of a monoidal functor defined by the monad , but the unit associated with mzip belongs to a different monoidal functor ! 5.3 Symmetry of parallel binding .Another sensible requirement for mzip ( which exists in F # joinads ) is that reordering of the arguments only changes the order of elements in the resulting tuple .", "label": "", "metadata": {}, "score": "68.46326"}
{"text": "Introduction .In my last Code Project article , An Introduction to the Boost Spirit Parser framework , I introduced some basic concepts of the boost::spirit parser framework .In that article , I created the necessary code to successfully parse the input for a simple modular arithmetic calculator .", "label": "", "metadata": {}, "score": "68.66961"}
{"text": "Here are some of the type classes and functions that are used by the desugaring : . class Monad m where .mzero : : m a .Aside from Monad , the desugaring also uses the MonadPlus and MonadZip type classes .", "label": "", "metadata": {}, "score": "68.74296"}
{"text": "In boolean logic , a disjunction is defined according to the following truth table : .T .T .F .T .F .T .T .F .F .F .In other words , the disjunction is true if one or both of its component predicates are true .", "label": "", "metadata": {}, "score": "68.96798"}
{"text": "Furthermore , in many linguistic theories , a ' head ' of a construction plays an important role .For example , heads of a construction determine what other parts the construction may have .Furthermore , heads carry the features associated with the construction as a whole ( such as case , agreement ) .", "label": "", "metadata": {}, "score": "68.987305"}
{"text": "This concept is slightly simpler than the original poor man 's concurrency monad ( which is based on continuations ) .A resumption is a computation that has either finished and produced some value or has not finished , in which case it can run one atomic step and produce a new resumption : .", "label": "", "metadata": {}, "score": "69.035995"}
{"text": "This allows us to define a thermodynamic matcher , which uses the minimum free energy as a scoring scheme and focuses only on a specific realm of secondary structures .Here , for every new RNA family , a new grammar must be devised .", "label": "", "metadata": {}, "score": "69.081245"}
{"text": "For those of you who are still a little uncomfortable with the more obscure higher - order utility methods in the Scala collections framework : do n't worry about it .While the above may be a bit obfuscated , there is n't really a need to understand what 's going on at any sort of precise level .", "label": "", "metadata": {}, "score": "69.14857"}
{"text": "We want to point out that the non - ambiguity proofs for the grammars studied here do not solve the problem of ambiguity for modeling of RNA secondary structures once and for all .New scientific interests and research questions will always demand new grammars .", "label": "", "metadata": {}, "score": "69.30333"}
{"text": "Let 's create separate parsers for them , too : . fill ( n .Now , when we are able to parse individual characters , let 's create the rank parser : .You can see that the parser combinator rep is used here .", "label": "", "metadata": {}, "score": "69.44266"}
{"text": "The brackets combinator takes characters representing opening and closing brackets and a parser for parsing the body inside the brackets .It uses a monad comprehension with three binding expressions that parse an opening brace , the body or more brackets , and then the closing brace .", "label": "", "metadata": {}, "score": "69.49152"}
{"text": "As the composite is visited from the bottom of the tree to the top , results from visiting each node are placed on a stack .The operator nodes work in a very similar way to a Forth interpreter ; whereby the plus node , for example , pops the top two elements off the stack , calculates the sum of them , and pushes on the results : . void .", "label": "", "metadata": {}, "score": "69.56608"}
{"text": "Monad comprehensions have an interesting history .They were the first syntactic extension for programming with monads .They were implemented in Haskell , but later replaced with plain list comprehensions and monadic do notation .Now , monad comprehensions are back in Haskell , more powerful than ever before !", "label": "", "metadata": {}, "score": "69.63817"}
{"text": "It almost seems that it holds of necessity , because mzero with type m a does n't contain any value of type a , so there is no way we could construct a value of type ( a , b ) .", "label": "", "metadata": {}, "score": "69.69753"}
{"text": "Loading package parsec-2.1.0.0 ... linking ... done .Left \" ( unknown ) \" ( line 1 , column 6 ) : . unexpected end of input .expecting \" , \" , \" \\n\\r \" , \" \\r\\n \" , \" \\n \" or \" \\r \" .", "label": "", "metadata": {}, "score": "69.91016"}
{"text": "This does not mean , however , that the potentialities of .generative models should be left unexplored .Ahmad R. Lotfi .Assistant Professor of linguistics , .Chair of English dept . .Graduate School .Azad University at Khorasgan ( IRAN ) .", "label": "", "metadata": {}, "score": "69.947975"}
{"text": "General News Suggestion Question Bug Answer Joke Praise Rant Admin .Use Ctrl+Left / Right to switch messages , Ctrl+Up / Down to switch threads , Ctrl+Shift+Left / Right to switch pages .This chapter is organized as follows .Firstly I discuss the proposals for more powerful string operations , as presented by [ 67 ] , [ 38 ] , [ 72 ] , [ 106 ] and [ 1 ] .", "label": "", "metadata": {}, "score": "69.988945"}
{"text": "If you 're like me , one of the first things that attracted you to Scala was its parser combinators .Well , maybe that was n't the first thing for me , but it was pretty far up there .Parser combinators make it almost too easy to create a parser for a complex language without ever leaving the comfortable play - pen afforded by Scala .", "label": "", "metadata": {}, "score": "70.136665"}
{"text": "Here , o expects a dot - bracket string as its left argument , a function as its right argument , and applies the latter to the former .( ) \" for the symbol sequence \" agu \" .( ) \" , \" ... \" , \" ... \" , etc . ] , where the duplicate entries result from the ambiguity of G 1 .", "label": "", "metadata": {}, "score": "70.25473"}
{"text": "That 's just two uppercase characters , so lets write that parser : . Simple !This parser requires two uppercase characters , so we 've combined the upper parser with the count combinator to run upper twice .If this parser succeeds , it will return the two uppercase characters that it parsed .", "label": "", "metadata": {}, "score": "70.29001"}
{"text": "That 's a full - featured CSV parser in just 21 lines of code , plus an additional 10 lines for the parseCSV and main utility functions .Let 's look at the changes in this program from the previous versions .", "label": "", "metadata": {}, "score": "70.29839"}
{"text": "When creating a compiler in Scala , it is perfectly acceptable to make use of these conventional Java - generating tools like ANTLR or Beaver , but we do have other options .Parser combinators are a domain - specific language baked into the standard library .", "label": "", "metadata": {}, "score": "70.38599"}
{"text": "I find terrible both to force everything to stay in the \" generics \" or in the classic OOP .And I 'm dreaming a language where templates can be translatable and OOP is not forced \" by definition \" to single inheritance and interfaces .", "label": "", "metadata": {}, "score": "70.45057"}
{"text": "The Spirit framework is a very powerful way of creating highly object oriented parsers .The complex syntax and use of cutting edge language features are not for the fainthearted , but I think that the effort required to learn the framework will be well rewarded .", "label": "", "metadata": {}, "score": "70.45572"}
{"text": "4 Composing computations in parallel .In the previous section , we used the parallel comprehension syntax to create computations that model parallelism using resumptions .Resumptions can be viewed as lightweight cooperative threads .They are useful abstraction , but the simple implementation in the previous section does not give us any speed - up on multi - core CPU .", "label": "", "metadata": {}, "score": "70.49422"}
{"text": "case class Failure ( msg : String ) extends Result [ Nothing ] .Additionally , we must add a concrete parser , keyword , to handle our literals .For the sake of syntactic compatibility with Scala 's parser combinators , this parser will be defined within the RegexpParsers singleton object ( despite the fact that we do n't really support regular expressions ) : . format ( str , trunc .", "label": "", "metadata": {}, "score": "70.72664"}
{"text": "Fillmore and Kay 's ( 1999 ; also in Goldberg 's 2003 ) version of Construction .Grammar a sentence can also be the combination / parallel activation of a . number of constructions .So Goldberg , e.g. , considers ' What did Liza buy the child ' to consist of 6 . types of constructions : 1)the six lexical items , 2 ) the ditransitive . constructions , 3 ) the question construction , 4 ) the Subj - Aux inversion .", "label": "", "metadata": {}, "score": "70.77087"}
{"text": "Here we have 2 simple parser combinators : dot , simply denoting a dot , and ipGroup for numbers 0 - 255 .All parsers have a type .The type of a parser denotes what does it produce when it successfully reads the input .", "label": "", "metadata": {}, "score": "70.95137"}
{"text": "[ 1 of 1 ] Compiling Main ( csv6.hs , interpreted ) .Ok , modules loaded : Main .Loading package parsec-2.1.0.0 ... linking ... done .Right ( ) .All four endings were handled properly .You can also test the full CSV parser with some different endings like this : .", "label": "", "metadata": {}, "score": "70.960144"}
{"text": "The root node therefore contains a function to do this operation : . void . assert ( false ) ; .You can see that this function looks for the last two nodes under the root node , removes them from the root node , adding them to the new node , before finally adding the new node underneath the root .", "label": "", "metadata": {}, "score": "71.13943"}
{"text": "Paul Phillips Tuesday , March 24 , 2009 at 1:11 pm .@Paul .Actually , I 've been doing some research lately involving extensive performance testing of Scala 's parser combinators ( 2.7.3 ) .The results show that parser combinators are about 5x-10x slower than parsers generated by ScalaBison , a directly - encoded recursive ascent / descent parser generator ( generates LALR(1 ) parsers in Scala ) .", "label": "", "metadata": {}, "score": "71.152565"}
{"text": "Each such derivation can uniquely be represented as a derivation tree , and if the same terminal string has two different derivation trees , the grammar is called ambiguous .Our first example is Dowell and Eddy 's grammar G 1 [ 1 ] to describe RNA secondary structures : .", "label": "", "metadata": {}, "score": "71.161606"}
{"text": "In order to convert parser results , there is the parser combinator ^^ , which takes a transformation function as an argument .We can now ask what can actually be a parser .In case of the dot parser , we assign an ordinary string , while ipGroup seems to be a regular expression .", "label": "", "metadata": {}, "score": "71.23181"}
{"text": "Parsing a FEN string and converting it to some internal structure representing a game state is not that difficult .Without the use of some more advanced techniques , however , it would require complicated nested loops and long switches .I will present here , how parsing such string using parser combinators can be elegant , concise and fun .", "label": "", "metadata": {}, "score": "71.36496"}
{"text": "Reader , producing some result if the input is valid , otherwise producing an error .How the Magic Works .The really significant thing to notice here is that program is nothing special ; just another method which returns an instance of class Parser .", "label": "", "metadata": {}, "score": "71.398285"}
{"text": "It relies on using function pointers , or in a more object oriented way , functors , to callback from the parser into the parent application .Defining the Semantic Action Functors .Functors are simply classes that implement a function call operator , operator ( ) .", "label": "", "metadata": {}, "score": "71.48399"}
{"text": "Most imperative languages can not initialize such expressions correctly : one element in the cycle will be null after class initialization , and the graph wo n't have a cycle .The only ways out seem to be some kind of indirection , either encoding one ( or more ) of the productions as a closure ( possibly returning a private field ) , or , if the language has them , location references .", "label": "", "metadata": {}, "score": "71.600876"}
{"text": "Loading package parsec-2.1.0.0 ... linking ... done .[ ( \" foo\",Just \" bar\"),(\"a ! \" , Just \" b c \" ) ] .As appealing and readable as this parser is , we can profit from stepping back and taking another look at some of our building blocks .", "label": "", "metadata": {}, "score": "71.68701"}
{"text": "I 've stumbled across your blog .I just want to say thank you , you have a great writing style and the content is hugely informative .I 'm trying to learn Scala better and because the language is so grand in scope and capability it can be hard getting started .", "label": "", "metadata": {}, "score": "71.935265"}
{"text": "Background .There are numerous ways to parse input from files , the command line , or elsewhere .Despite this , all these techniques have to do two basic functions .The first action to be performed is understanding the structure of the input , ensuring that it meets the specification laid down for that input .", "label": "", "metadata": {}, "score": "71.97786"}
{"text": "toInt ) .Fourth element denotes en passant square .It is written as a square in algebraic notation ( e.g. a1 , c6 , h8 , ... ) .However , in the GameState class , we store all fields as integers , starting with 0 up to 63 , hence our parser will be of type Parser[Option[Int ] ] and not Parser[String ] .", "label": "", "metadata": {}, "score": "72.09163"}
{"text": "It also means that we will return a value of type [ [ String ] ] : a list of a list of strings .The st can be ignored for now .Parsec programmers often omit type declarations , since we write so many small functions .", "label": "", "metadata": {}, "score": "72.20526"}
{"text": "The only solution which eliminates these bugs , is to remove the ambiguities and use a Context - free grammar .Shelby Moore III Saturday , January 15 , 2011 at 3:23 am .Post a Comment .Comments are automatically formatted .", "label": "", "metadata": {}, "score": "72.23901"}
{"text": "A predicate is translated into a call to the guard function in the innermost part of the desugared expression .When the function returns mzero value ( an empty list ) , the result of the binding will also be mzero , so the element for which the predicate does n't hold will be filtered out .", "label": "", "metadata": {}, "score": "72.308075"}
{"text": "It starts calculating fib 36 in parallel with the rest of the computation and then calculates fib 37 sequentially .The do block creates a value of type Eval Integer .We then pass this value to runEval , which returns the wrapped value .", "label": "", "metadata": {}, "score": "72.35179"}
{"text": "In many popular languages , people tend to put regular expressions to work for \" casual \" parsing .They 're notoriously tricky for this purpose : hard to write , difficult to debug , nearly incomprehensible after a few months of neglect , and provide no error messages on failure .", "label": "", "metadata": {}, "score": "72.41832"}
{"text": "-- file : ch16/HttpRequestParser .Because we 're writing in an applicative style , our parser can be both brief and readable .Readable , that is , if you 're becoming used to the applicative parsing notation .-- file : ch16/HttpRequestParser .", "label": "", "metadata": {}, "score": "72.43382"}
{"text": "Write a wrapper in the IO monad that will invoke the parser .Use the System .Timeout module to close the connection if the parser has not completed within 30 seconds .Affiliated with .Abstract .Background .Ambiguity is a problem in biosequence analysis that arises in various analysis tasks solved via dynamic programming , and in particular , in the modeling of families of RNA secondary structures with stochastic context free grammars .", "label": "", "metadata": {}, "score": "72.438034"}
{"text": "The rpar strategy starts evaluating the value in background and rseq evaluates the value eagerly before returning .A typical pattern is to use the do notation to spawn one computation in parallel and then run another computation sequentially .This way we can easily parallelize two function calls : . return $ a + b .", "label": "", "metadata": {}, "score": "72.56929"}
{"text": "However , it is worth noting that the return operation of the monad does n't specify any evaluation order .The function runEval .return is just an identity function that does n't force evaluation of the argument .The evaluation order is specified by additional combinators such as rpar .", "label": "", "metadata": {}, "score": "72.675934"}
{"text": "So let 's look for the end - of - file after our end of line : . -- file : ch16/csv4 .hs -- This function is not correct !This also is n't right .But by the time we are able to see if there is a \\r after the \\n , we 've already consumed the \\n .", "label": "", "metadata": {}, "score": "72.69992"}
{"text": "We construct a scoring scheme \u03c3 for grammar G such that G ( \u03c3 , x ) computes all derivation trees for x .For each production \u03c0 we use a unique tree label T \u03c0 .By construction , G ( \u03c3 , x ) constructs the list of all derivation trees for x .", "label": "", "metadata": {}, "score": "72.80097"}
{"text": "The good news is that we already have this feature almost by accident .Well , obviously not by accident since I put some careful planning into this article , but at no point so far did we actually set out to implement backtracking , and yet it has somehow dropped into our collective lap .", "label": "", "metadata": {}, "score": "72.83268"}
{"text": "Therefore , our parser will be a sequential composition of eleven parsers , six ones parsing individual elements of the FEN string and five ones parsing whitespace between elements .Let 's start with the most simple ones .Last two elements are simple integers .", "label": "", "metadata": {}, "score": "73.09766"}
{"text": "The Spirit framework can pass them around by value quite a lot , so do n't load them down with loads of member variables unless you want to take a hit on the speed of parsing .The functor should really be seen as a point of communication between the parser and the rest of your application .", "label": "", "metadata": {}, "score": "73.10194"}
{"text": "Ok , modules loaded : Main .Loading package parsec-2.1.0.0 ... linking ... done .Left \" ( unknown ) \" ( line 1 , column 6 ) : . unexpected end of input .expecting \" , \" or end of line .", "label": "", "metadata": {}, "score": "73.23164"}
{"text": "The reason that C++ works for me as a language is quite simply that it does everything .If you need to get down and dirty in the memory you have the tools to do it .If you need to write high performance software then you have the tools to do it .", "label": "", "metadata": {}, "score": "73.480354"}
{"text": "The run function takes a resumption that may perform effects specified by the monad m and runs the resumption inside the monad until it reaches Done .The function runs the whole computation sequentially ( and it can not be implemented differently ) .", "label": "", "metadata": {}, "score": "73.89627"}
{"text": "What are semantic actions ?Semantics is the science of extracting meaning from something , so it follows that semantic actions involve carrying out actions based on the meaning of something .In the context of a parser , semantic actions are the code that gets called each time you have successfully figured out part of the input .", "label": "", "metadata": {}, "score": "74.094765"}
{"text": "Not only that , but they are monad transformers , which gives us even more power .If we used a base monad such as IO , it 's entirely possible to write a parser that looks up things in a database while it does the parsing .", "label": "", "metadata": {}, "score": "74.24057"}
{"text": "The latter is the rule rather than the exception .Moreover , if derivations emerging from T are also ambiguous , the degrees of ambiguity multiply .Studying sources of ambiguity helps to better understand the nature of the error .Depending on the grammar , certain types of RNA structures may have their probability split up over a large number of derivations , while others are unaffected .", "label": "", "metadata": {}, "score": "74.29038"}
{"text": "The snippet defines a simple computation cats that prints \" meow \" three times and then returns a string \" cat \" .The computations created by printLoop are not fully opaque .If we have two computations like cats , we can treat them as sequences of steps and interleave them .", "label": "", "metadata": {}, "score": "74.31227"}
{"text": "Other operator nodes are largely similar .Adding Semantic Actions to a Spirit Parser .The preparatory work of defining composites and visitors for the expression tree have prepared us for doing the important work of adding semantic actions to our existing calculator parser .", "label": "", "metadata": {}, "score": "74.318665"}
{"text": "Hey daniel - by coincidence I am just finishing rewriting the scalac parser with combinators .I had to add memoization to the combinator lib but even with no other attempts to improve performance it looks like they might end up fast enough .", "label": "", "metadata": {}, "score": "74.32487"}
{"text": "But we will see how to work with the results later .The definition of the Parser type consists more or less of this : .Here we see a peculiarity of Scala : A Parser is a function as well as a class .", "label": "", "metadata": {}, "score": "74.35716"}
{"text": "Ambiguity can have many sources .Here , we present three common situations that lead us to write ambiguous rules , but can be easily avoided .The price for non - ambiguity is the new nonterminal symbol L , more parameters in the training set , and possibly another DP table in the implementation .", "label": "", "metadata": {}, "score": "74.36328"}
{"text": "PhD thesis University of Bielefeld 2004 .Copyright .\u00a9 Reeder et al .2005 .This article is published under license to BioMed Central Ltd. Parser combinators ( and what if regular expressions are not enough ) .Posted on 11/06/2012 .", "label": "", "metadata": {}, "score": "74.39347"}
{"text": "Ok , modules loaded : Main .Loading package parsec-2.1.0.0 ... linking ... done .Left \" ( unknown ) \" ( line 2 , column 1 ) : . unexpected end of input .expecting \" \\\"\\ \" \" or quote at end of cell .", "label": "", "metadata": {}, "score": "74.52767"}
{"text": "An introduction into how Scala Parser Combinators work under the hood and how to write your own Parsers & Combinators .Takes a low level approach to present the inner workings of Parser Combinators .What Is A Parser ( In A Functional Sense ) ?", "label": "", "metadata": {}, "score": "74.547"}
{"text": "We give the quotedCell option first , because we want to follow that path if the first character in a cell is the quote mark .The quotedCell begins and ends with a quote mark , and contains zero or more characters .", "label": "", "metadata": {}, "score": "74.63072"}
{"text": "Articulatory - Perceptual systems ) , then all postulated syntactic . steps are interpreted as mental processes / operations .Now , I 'm a theoretical linguist and would gladly be corrected by psycho- . and neurolinguists , but the way I see it , we nevertheless have the same . problems as in the 1960s/1970s : .", "label": "", "metadata": {}, "score": "74.63125"}
{"text": "Here 's one generated by a spreadsheet program : . \" Product\",\"Price \" \" O'Reilly Socks\",10 \" Shirt with \" \" Haskell \" \" text\",20 \" Shirt , \" \" O'Reilly \" \" version\",20 \" Haskell Caps\",15 .Now , we can run this under our test program and watch : . [ \" Product\",\"Price \" ] .", "label": "", "metadata": {}, "score": "74.72664"}
{"text": "expecting \" TP \" or \" ML \" .Parsing headers .Following the first line of a HTTP request is a series of zero or more headers .A header begins with a field name , followed by a colon , followed by the content .", "label": "", "metadata": {}, "score": "74.74274"}
{"text": "toInt , b .toInt , c .toInt , d .Unless you are Perl hacker , it took you a couple of seconds to find out what is actually going on in here .It is a method that receives a string on the input and returns either None if the string is not correct IPv4 address or a tuple of 4 integers representing the four parts of the IPv4 address .", "label": "", "metadata": {}, "score": "74.89758"}
{"text": "The result is simply the first cell and the remaining cells assembled into a list .Let 's skip over remainingCells for a minute and look at cellContent .A cell contains any number of characters , but each character must not be a comma or end of line character .", "label": "", "metadata": {}, "score": "75.07004"}
{"text": "Take for example .Proof .Every dot - bracket string describes exactly one possible secondary structure .Then , for an RNA sequence x compatible with z , using the corresponding productions there are different derivations in G which represent the same secondary structure z .", "label": "", "metadata": {}, "score": "75.26796"}
{"text": "transformations sometimes turned out to be easier to process : in the .Standard Theory adjectives in a pre - modifier function such as ' the . small cat ' were sometimes supposed to be derived from underlying relative . clauses , i.e. the cat which is small ( cf .", "label": "", "metadata": {}, "score": "75.328125"}
{"text": "We did n't use many shortcuts here , so remember that this will get shorter and simpler !We 've built it from the top down , so our first function is csvFile .The type of this function is GenParser Char st [ [ String ] ] .", "label": "", "metadata": {}, "score": "75.409256"}
{"text": "So we define a custom quotedChar to process them .When we 're processing characters inside a quoted cell , we first say noneOf \" \\ \" \" .This will match and return any single character as long as it 's not the quote mark .", "label": "", "metadata": {}, "score": "75.426254"}
{"text": "Spirit goes one step further by allowing semantic actions to be attached to any part of the rule .An example used to process a comma separated list of signed integers is : .This section of code states that the integers rule is defined as a single integer followed by zero or more additional integers , separated with commas .", "label": "", "metadata": {}, "score": "75.49356"}
{"text": "Much like our countryCode parser , we 've combined the upperNum parser with the count combinator to run it 3 times .upperNum can be defined by parsing either an upper character ( A - Z ) or a digit ( 0 - 9 ) .", "label": "", "metadata": {}, "score": "75.54938"}
{"text": "Several non - ambiguous reference grammars for RNA are known - the critical part here is to assure that our grammar G to be tested describes the same language as R .Both grammars must impose the same restrictions on loop sizes , lonely base pairs , etc .", "label": "", "metadata": {}, "score": "75.57922"}
{"text": "In The Scala API .A short intermission for Java people : It is at this point important to remember how Scala realizes \" Functions as first class members \" , i.e. how Scala \" tricks \" the VM to pass functions around as values .", "label": "", "metadata": {}, "score": "75.66706"}
{"text": "The url helper does not attempt to validate a URL , because the HTTP specification does not specify what characters an URL contain .The function just consumes input until either the line ends or it reaches a HTTP version identifier .", "label": "", "metadata": {}, "score": "75.87868"}
{"text": "Comments and Discussions . ... and i 'm posting this message simply because i 'm tired to be in the middle of believers .Paradigms ( and patterns ) are not themself \" solutions \" .If respecting a patten makes a solution too tricky to be undertanded ... that 's the time to move to another pattern .", "label": "", "metadata": {}, "score": "76.214134"}
{"text": "I really liked the stream libraries and templates .It took the standards committee until the late 90s to actually standardise these things , and it has taken until now ( and beyond ) for compilers to actually start becoming compliant .", "label": "", "metadata": {}, "score": "76.2801"}
{"text": "The current player 's color is denoted by the second element in FEN .It is either \" w \" or \" b \" .In the object model , the color is denoted by a boolean value passed to the constructor of all pieces .", "label": "", "metadata": {}, "score": "76.34324"}
{"text": "Give me Spring and Hibernate ! \"However , now , when doing real - world , I see how invaluable these theoretical foundations are and how often I can benefit from it in practice .The idea behind parser combinators is quite simple , two fundamental elements are parsers and parser combinators .", "label": "", "metadata": {}, "score": "76.34892"}
{"text": "[ \" Shirt with \\\"Haskell\\ \" text\",\"20 \" ] .[ \" Shirt , \\\"O'Reilly\\ \" version\",\"20 \" ] .[ \" Haskell Caps\",\"15 \" ] .Parsec and MonadPlus .Parsec 's GenParser monad is an instance of the MonadPlus typeclass that we introduced in the section called \" Looking for alternatives \" .", "label": "", "metadata": {}, "score": "76.45068"}
{"text": "head - ' 1 ' ) + ( x .Third element in a FEN string represents available castlings .Since it does not make sense to hold duplicate values , available castlings are represented as a set in our object model .", "label": "", "metadata": {}, "score": "76.70826"}
{"text": "Instead of zipping two arbitrary monadic values , the law for applicative functors zips an arbitrary value with unit .In case of lists , unit is an infinite list , so the law holds .Intuitively , this holds because unit has a maximal structure ( in this case , the structure is the length of the list ) .", "label": "", "metadata": {}, "score": "76.96684"}
{"text": "The result of parsing is a tuple containing a value of type a produced by the parser , the number of characters consumed by the parser , and the remaining unparsed part of the string .The Int value represents the number of characters consumed by the parser .", "label": "", "metadata": {}, "score": "77.04776"}
{"text": "Left \" ( unknown ) \" ( line 1 , column 3 ) : . unexpected end of input .expecting \" , \" or \" \\n \" .Look at that .Recall how we defined that each line must end with the end - of - line character , and we did n't give it .", "label": "", "metadata": {}, "score": "77.22127"}
{"text": "Our case , however , is easy .When RNA secondary structure is our domain of study , base pair sets or the familiar dot - bracket strings can serve as a canonical model , as they uniquely represent secondary structures .", "label": "", "metadata": {}, "score": "77.30662"}
{"text": "and terms it a state ; a single slide taken away from the film in progress .on the screen for scrutiny .What Chomsky does in characterising mental . states ( knowledge of language ) is to make this real - time mental process . stand still momentarily in order to see what 's going on there .", "label": "", "metadata": {}, "score": "77.5879"}
{"text": "The mzero value from MonadPlus type class is an empty list , which means that guard returns [ ( ) ] when the argument is True and the empty list otherwise .Finally , the mzip function for lists is just zip .", "label": "", "metadata": {}, "score": "77.69677"}
{"text": "Let 's look how we can write a sequential and parallel version of a snippet that calculates the 38 th Fibonacci number : .The snippet first declares a helper function fibTask that creates a delayed value using the sequential fib function and wraps it inside the Eval monad without specifying evaluation strategy .", "label": "", "metadata": {}, "score": "78.1261"}
{"text": "The boring method returns a value of type Parser[String ] .That is , a parser which consumes input and somehow produces a String as a result ( along with the truncated stream ) .This parser will either parse the characters b - o - r - e in that order , or it will fail .", "label": "", "metadata": {}, "score": "78.199425"}
{"text": "As they all emerge from the same terminal string acaggaaacuguacggugcaaccg , this grammar is ambiguous .Four derivation trees .Four derivation trees for RNA sequence \" acaggaaacuguacggugcaaccg \" , two ( left ) representing the annotation sequence ( ( ( ( .... ) ) ) ) .", "label": "", "metadata": {}, "score": "78.21607"}
{"text": "Dowell R , Eddy SR : Evaluation of several lightweight stochastic context - free grammars for RNA secondary structure prediction .BMC Bioinformatics 2004 , 5 : 71 .View Article PubMed .Wuchty S , Fontana W , Hofacker I , Schuster P : Complete Suboptimal Folding of RNA and the Stability of Secondary Structures .", "label": "", "metadata": {}, "score": "78.248886"}
{"text": "The expressive power of a grammar type depends on these laws .In 1956 , Noam Chomsky introduced a hierarchy of formal grammars that ranks grammar types by their expressive power , the Chomsky hierarchy [ 4 ] .It consists of four levels : regular grammars , context - free grammars , context - sensitive grammars , and unrestricted grammars .", "label": "", "metadata": {}, "score": "78.41829"}
{"text": "The type parameter T is the type we want as a result of the parsing process .Obviously , we want to define what we want as a result ourselves , so it needs to be a generic type .Typically when working with Parser Combinators you define a Domain Model that represents your possible result types and build instances during parsing .", "label": "", "metadata": {}, "score": "78.43803"}
{"text": "By the term syntactic ambiguity we denote the fact that typically an RNA sequence has many secondary structures , i.e. annotation sequences , hence many derivations .Figure 1 shows two example annotation sequences of the same RNA sequence .Semantic ambiguity exists when there are , for some sequence , several derivations that represent the same annotation sequence , and hence , the same secondary structure .", "label": "", "metadata": {}, "score": "78.482346"}
{"text": "It is also important to know what actually goes on under the hood when your Parser runs , as debugging then becomes a lot easier .But , without further ado , here the \" proper \" way to implement the above Parser in Scala : .", "label": "", "metadata": {}, "score": "78.597275"}
{"text": "Extended Example : Full CSV Parser .Our earlier CSV examples have had an important flaw : they were n't able to handle cells that contain a comma .CSV generating programs typically put quotation marks around such data .But then you have another problem : what to do if a cell contains a quotation mark and a comma .", "label": "", "metadata": {}, "score": "78.605286"}
{"text": "Intro to Parser Combinators .These tools do a very good job of generating sources for efficient and powerful parsers , but they are n't exactly the easiest tools to use .They generally have a very steep learning curve , and due to their unique status as compiler - compilers , an unintuitive architecture .", "label": "", "metadata": {}, "score": "78.674194"}
{"text": "-- file : ch16/HttpRequestParser .Exercises .Our HTTP request parser is too simple to be useful in real deployments .It is missing vital functionality , and is not resistant to even the most basic denial of service attacks .", "label": "", "metadata": {}, "score": "79.01004"}
{"text": "These are suitable to describe the pseudoknot - free secondary structure of RNA .When considering pseudoknots , context - sensitive grammars are needed .Context free grammars .Starting with the axiom symbol , by successive replacement of nonterminal symbols by right - hand sides of corresponding productions , we can derive a set of terminal strings .", "label": "", "metadata": {}, "score": "79.08835"}
{"text": "A single header might contain tens or hundreds of megabytes of garbage text , causing a server to run out of memory .Restructure the header parser so that it will fail if any line is longer than 4096 characters .It must fail immediately when this occurs ; it can not wait until the end of a line eventually shows up .", "label": "", "metadata": {}, "score": "79.27575"}
{"text": "Choices and Errors .Different operating systems use different characters to mark the end - of - line .Unix / Linux systems , plus Windows in text mode , use simply \" \\n \" .DOS and Windows systems use \" \\r\\n \" , and Macs traditionally used \" \\r \" .", "label": "", "metadata": {}, "score": "79.32951"}
{"text": "Background .The ambiguity problem in biosequence analysis .Biosequence analysis problems are typically optimization problems - we seek the best alignment of two protein sequences under a similarity score , or the most stable secondary structure of an RNA molecule under a thermodynamic model .", "label": "", "metadata": {}, "score": "79.513695"}
{"text": "A formal language is a subset of the set of all strings over a finite alphabet .Formal languages are typically described by formal grammars .In general , a formal grammar consists of an alphabet , a set of nonterminal symbols , and a set of production rules .", "label": "", "metadata": {}, "score": "79.707825"}
{"text": "Cognitive Sciences 7,5 : 219 - 224 .Jackendoff , R. 2002 .Foundations of Language : Brain , .Meaning , Grammar , Evolution .Oxford : Oxford University Press ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "79.71867"}
{"text": "hs -- This function is not correct !This is n't quite right .Looking for the single character \\n will match both types of line endings , so it will look to the system that the following line begins with \\r .", "label": "", "metadata": {}, "score": "79.99336"}
{"text": "There exists no program that can determine for an arbitrary grammar G whether or not G is fl - ambiguous .Here , the problem is to decide whether a given SCFG is se - mantically ambiguous .It is not surprising that this problem is not easier : .", "label": "", "metadata": {}, "score": "80.15044"}
{"text": "The code produced for this article relies on both the boost::spirit library and the Loki library .Both of these libraries should be installed and set in your include path for the code to compile .Furthermore , due to the cutting edge language features that both these libraries rely on , the code will only compile on Visual C++ 7.1 or later .", "label": "", "metadata": {}, "score": "80.86147"}
{"text": "My 3 favourite reference books are : Design Patterns , Gamma et al ; The C++ Standard Library , Josuttis ; and Computer Graphics , Foley et al . .Outside computers , I am also the drummer in a band , The Unbelievers and we have just released our first album .", "label": "", "metadata": {}, "score": "81.337204"}
{"text": "As we can see , such expression is very complicated ( 163 characters long ) and thus error - prone ( just imagine you accidentally delete one character - nobody might ever find out ) .Moreover , it is also repetitive .", "label": "", "metadata": {}, "score": "81.466"}
{"text": "what would be best strategy to handle whitespaces and comments ?Walter Chang Monday , April 13 , 2009 at 2:34 am .Whitespace and comments are actually a trickier issue .My personal preference on handling them is to first feed the input source through a proper scanner , which then produces tokens and removes all unnecessary whitespace ( and comments ) .", "label": "", "metadata": {}, "score": "81.6751"}
{"text": "If it fails , it will return an error message along the lines of \" Expected ' bore ' , got ' Boer ' \" , or something to that effect .By itself , such a parser is really not very useful .", "label": "", "metadata": {}, "score": "81.884285"}
{"text": "Although the concepts here should mostly be familiar from our earlier coverage of functors and monads , we 'll walk through this function to explain what 's happening .First , to get a grip on our types , we 'll hoist hexify to the top level and give it a signature .", "label": "", "metadata": {}, "score": "81.90696"}
{"text": "The central nonterminal of the grammar is CL , which splits up into closed structures like hairpin loops , bulges , and multiloops .Due to the necessity to handle dangling bases in a non - ambiguous way , the rules for multiloops are the most complicated of this grammar .", "label": "", "metadata": {}, "score": "82.02121"}
{"text": "Syntactic versus semantic ambiguity .Above , we introduced the formal language - theoretic notion of ambiguity : if the same symbol sequence has two or more different derivation trees , the grammar is called ambiguous .For clarity , we will refer to it as fl - ambiguity .", "label": "", "metadata": {}, "score": "82.07303"}
{"text": "I submitted my PhD thesis at the University of Cambridge , working on making better types for programs that run in rich context ( like F # type providers , distributed prog\u00adramming or data - flow ) .See my academic page for more .", "label": "", "metadata": {}, "score": "82.208954"}
{"text": "Declarations .Acknowledgements .We are grateful to Jens Reeder for discussion and the anonymous referees for very detailed and helpful comments .Work of JR is funded by DFG Graduate College 635 Bioinformatik .Authors ' contributions .RG suggested the topic and contributed the undecid - ability proof .", "label": "", "metadata": {}, "score": "83.07548"}
{"text": "-- file : ch16/ApplicativeParsec .hs module ApplicativeParsec ( module Control .Applicative , module Text .ParserCombinators .Parsec ) where import Control .Applicative import Control .Monad ( MonadPlus ( . , ap ) -- Hide a few names that are provided by Applicative .", "label": "", "metadata": {}, "score": "83.439835"}
{"text": "Thanks to Alan Mycroft for inspiring discussion about some of the monads demonstrated in this article and to Dominic Orchard for many useful comments on a draft of the article as well as discussion about category theory and the mzip laws .", "label": "", "metadata": {}, "score": "83.4966"}
{"text": "Although it may sound too radical ( if not absurd ! ) to some readers , I find .the division of the world into its states and processes rather artificial .( though prhaps still legitimate given man 's limitations in understanding .", "label": "", "metadata": {}, "score": "83.65546"}
{"text": "The construction of these rules guarantees , that every derivation of a multiloop must lead to at least two closed substructures .One of these derivations is shown on the left side of Figure 2 .Therefore , a derivation of a multiloop can by no means conflict with a derivation of a left bulge , which must include a single closed substructure .", "label": "", "metadata": {}, "score": "83.734795"}
{"text": "There is a de - facto standard notation for this purpose , called Forsyth - Edwards Notation ( FEN ) .For details of the structure of games stored in this format , please consult the wiki , its documentation or F.A.Q .", "label": "", "metadata": {}, "score": "83.78551"}
{"text": "As another example of applicative parsing , we will develop a basic parser for HTTP requests .-- file : ch16/HttpRequestParser .hs module HttpRequestParser ( HttpRequest ( . , Method ( . , p_request , p_query ) where import ApplicativeParsec import Numeric ( readHex ) import Control .", "label": "", "metadata": {}, "score": "83.82794"}
{"text": "For the example today , we 'll look at parsing International Standard Recording Codes ( ISRCs ) , a problem that I had to solve for some work on MusicBrainz .The linked Wikipedia does a good job at explaining the format of ISRCs , so lets dive right in and try and build up our own ISRC parser .", "label": "", "metadata": {}, "score": "84.34834"}
{"text": "You might wonder , why the list is reversed in the boardParser .The FEN string describes the board starting from the black 's side ( back rank ) , but in our representation , we start from white 's perspective .", "label": "", "metadata": {}, "score": "84.587715"}
{"text": "We define the line function to do just that .Reading the function , we can see that a line consists of cells followed by the end of line character .So what are cells ?We defined them in the cells function .", "label": "", "metadata": {}, "score": "84.60744"}
{"text": "forced move on the scientist 's part to make sense of the reality , but not .the reality itself .While Chomsky has never claimed his theories to be those of mental .processing / performance but of mental states / competence , the very . terminology he 's always employed since ST through GB and finally in MP . strongly suggests he 's well aware of the potentialities of his competence . model in paving the way to afford a performance model embracing mental .", "label": "", "metadata": {}, "score": "84.676125"}
{"text": "Consider the following annotation sequence : .Here , the string \" ( ( ... ( ( \" appears two times in the annotation sequence .The first appearance denotes a left bulge , the second the beginning of a multiloop .", "label": "", "metadata": {}, "score": "84.713455"}
{"text": "The next snippet demonstrates two ways of composing resumptions .In both examples , we compose a computation that prints \" meow \" two times and then returns \" cat \" with a computation that prints \" woof \" three times and then returns \" dog \" : . [ c + + \" and \" + + d .", "label": "", "metadata": {}, "score": "84.781975"}
{"text": "Shelby Moore III Saturday , January 15 , 2011 at 2:20 am .Also just because the time spent of compilation semantic analysis of the AST is often much greater than the time spent in the parser stage , the speed of the parser stage is very important for JIT compilation / interpreter .", "label": "", "metadata": {}, "score": "84.80394"}
{"text": "Best wishes , .Thomas Hoffmann .References .Chomsky , N. 1995 .The Minimalist Program .Cambridge , . Mass. : MIT Press .Chomsky , Noam .Minimalist inquiries : the . framework .In : David Michaels , Roger Martin and .", "label": "", "metadata": {}, "score": "85.72252"}
{"text": "Not let 's get to the most complicated parser which is responsible for parsing the first element of the FEN string - the position of pieces on the board .In our object model , pieces on the board are represented by a list of exactly 64 elements of type Option[Piece ] .", "label": "", "metadata": {}, "score": "85.763084"}
{"text": "Wonderful post .Exactly what I was looking for ( although , admittedly , it seems like I 'm one year late .Alexander Lehmann Saturday , March 27 , 2010 at 5:11 am .You write : \" hand - written parsers have a tendency toward poor performance ( think : the Scala compiler ) \" .", "label": "", "metadata": {}, "score": "86.2358"}
{"text": "All authors cooperated closely in writing the manuscript .Authors ' Affiliations .InternationaI NRW Graduate School of Bioinformatics and Genome Research , Center of Biotechnology ( CeBiTec ) , Bielefeld University .Practical Computer Science , Faculty of Technology , Bielefeld University .", "label": "", "metadata": {}, "score": "86.60434"}
{"text": "As Clean isa lazy functional programming language , which supports tail recursion , I am not sure these techniques do apply to Scala , but you may find the paper interesting nevertheless .Fabien Todescato Wednesday , April 1 , 2009 at 2:43 am .", "label": "", "metadata": {}, "score": "87.21929"}
{"text": "The only difference between the two examples is that the first one composes the operations using multiple generators ( separated by comma ) and the second one uses parallel comprehensions ( separated by bar ) .When you run the first example , the program prints meow , meow , woof , woof , woof and then returns a string \" cat and dog \" .", "label": "", "metadata": {}, "score": "88.535835"}
{"text": "Amsterdam : North - Holland 1963 , 118 - 161 .View Article .Knuth D : On the Translation of Languages from Left to Right .Information and Control 1965 , 8 ( 6 ) : 607 - 639 .View Article .", "label": "", "metadata": {}, "score": "89.87614"}
{"text": "A more compact representation of a secondary structure is the widely used dot - bracket notation , as shown at the bottom of Figure 1 .In the following , we will use the term annotation sequence for the dot - bracket string representing one secondary structure of the underlying RNA sequence .", "label": "", "metadata": {}, "score": "90.532196"}
{"text": "For RNA secondary structures , there is an obvious choice , our annotation sequences in the widely used dot - bracket notation ( cf .Figure 1 ) .Each secondary structure ( excluding pseudoknots ) is uniquely represented by such a string .", "label": "", "metadata": {}, "score": "91.19331"}
{"text": "else printLoop str ( count - 1 ) result .The function is written using the do notation .It first prints the specified string , using lift to turn the IO ( ) action into a single - step Resumption IO ( ) .", "label": "", "metadata": {}, "score": "91.507385"}
{"text": "[ Private::AddParent ( self.m_parser , & COperatorMultiply::Create ) ] .[ Private::AddParent ( self.m_parser , & COperatorDivide::Create ) ] . ) term .[ Private::AddParent ( self.m_parser , & COperatorPlus::Create ) ] .[ Private::AddParent ( self.m_parser , & COperatorMinus::Create ) ] . )", "label": "", "metadata": {}, "score": "92.008026"}
{"text": "IO ( Handle ) .An HTTP request consists of a method , an identifier , a series of headers , and an optional body .For simplicity , we 'll focus on just two of the six method types specified by the HTTP 1.1 standard .", "label": "", "metadata": {}, "score": "96.57753"}
{"text": "Department of English and American Studies .English Linguistics .PT 3.2.79 .University of Regensburg .Universit\u00e4tsstra\u00dfe 31 .D-93053 Regensburg .Germany .Linguistic Field(s ) : Linguistic Theories Syntax .Dear linguists , Philip Carr . univ - montp3 .", "label": "", "metadata": {}, "score": "97.29795"}
{"text": "License .This article has no explicit license attached to it but may contain usage terms in the article text or the download files themselves .If in doubt please contact the author via the discussion board below .Share .About the Author .", "label": "", "metadata": {}, "score": "98.03248"}
{"text": "A CSV file contains 0 or more lines , each of which is terminated by the end - of - line character .A line contains 1 or more cells , separated by a comma .A cell contains 0 or more characters , which must be neither the comma nor the end - of - line character .", "label": "", "metadata": {}, "score": "98.67578"}
{"text": "Welcome !I 'm an F # open - source developer , book author and computer scientist .I submitted my PhD thesis recently .When offline , I enjoy traveling and taking pictures .You can find me at at @tomaspetricek or email tomas@tomasp.net .", "label": "", "metadata": {}, "score": "99.30373"}
{"text": "Anyways , thanks again .Nathan Matthews Wednesday , July 29 , 2009 at 2:13 pm .unfortunately , most of the regex libraries used are the unintuitive , potentially exponential time ( or worse ) backtracking Perl libraries .It 's a nice idea in theory .", "label": "", "metadata": {}, "score": "101.17883"}
{"text": "Paul Phillips Wednesday , March 25 , 2009 at 6:17 am .Yeah , it 's on my TODO list to come up with a better comment system for my blog ( preferably one with syntax highlighting ) , but WP is just so annoying and my time has been so sparing ...", "label": "", "metadata": {}, "score": "105.71774"}
{"text": "He can be reached by email .If you 're feeling particularly masochistic , you can follow Daniel on Twitter @djspiewak .", "label": "", "metadata": {}, "score": "110.358444"}
{"text": "I went on to study Engineering and Computer Science at Oxford University , getting a first and the University Prize for the best results in Computer Science .Since then I have worked in a variety of roles , involving systems management and development management on a wide variety of platforms .", "label": "", "metadata": {}, "score": "112.61629"}
{"text": "[ \" cat meow \" , \" cat woof \" , \" dog meow \" , \" dog woof \" ] . 1 ] .[ \" dog woof \" ] .[ \" cat meow \" , \" dog woof \" ] .", "label": "", "metadata": {}, "score": "123.33914"}
