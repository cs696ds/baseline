{"text": "As for speaker recognition , there are three types of speaker models ( put in an ascending complexity order ) : speaker dependent , speaker independent , and speaker adaptive .The first recognizes the speech patterns of only one person , the second of a large group of people , while the third starts with a speaker independent model and continues with training by the speaker .", "label": "", "metadata": {}, "score": "38.618736"}
{"text": "The present system uses a multistage word hypothesizer that is applied prior to a frame - by - frame alignment , in order to reduce the search space and to achieve real time performance improvements .The word hypothesizer and fine match procedure share the initial representation of speech as a sequence of multiple phoneme similarity values .", "label": "", "metadata": {}, "score": "40.501213"}
{"text": "With such features , no VTLN is required in the recognition system as the feature is already invariant to such changes .The feature representation described in this chapter takes the output of a simple auditory filterbank as its input ; there are no extra stages of processing in this auditory model .", "label": "", "metadata": {}, "score": "41.391827"}
{"text": "Topographical organization .\" J. Neurophysiol ., 60 , p.1823- .[ 1 ] .Slaney , M. ( 1993 ) .An Efficient Implementation of the Patterson - Holdsworth Auditory Filter Bank Apple technical Report .[ 1 ] [ 2 ] .", "label": "", "metadata": {}, "score": "42.732883"}
{"text": "This belief may drive research effort toward [ ... ]The multistage word recognizer uses a word reference representation based on reliably detected peaks of phoneme similarity values .The word reference representation captures the basic features of the words by targets that describe the location and shape of stable peaks of phoneme similarity values .", "label": "", "metadata": {}, "score": "42.78498"}
{"text": "By combining these quasi - independent sources of information produced at each step , a significant gain in accuracy is obtained .According to one aspect of the invention , a word recognizer for processing an input speech utterance is provided for a speech recognition system .", "label": "", "metadata": {}, "score": "43.34633"}
{"text": "There exist a number of excellent descriptions of various parts of the history of these models , for example Lyon ( 1996 ) and Patterson et al .( 2003 ) .The introduction to this chapter briefly covers the major points of the various models , and introduces a set of increasingly more complex criteria that an auditory model must fulfil in order to accurately model the human auditory system .", "label": "", "metadata": {}, "score": "43.536957"}
{"text": "In this talk , the use of phonetic transition models will be discussed within the context of summit , a segment - based continuous speech recognition system [ Zue et al . , ' ' Acoustic Segmentation and Phonetic Classification in the summit Speech Recognition System , ' ' Proc .", "label": "", "metadata": {}, "score": "43.584473"}
{"text": "First , the n - best list generated by the speech recognizer is expanded with additional candidates , based on confusability information captured via user click statistics .In the second stage , this expanded list is rescored and pruned to produce a more accurate and compact n - best list .", "label": "", "metadata": {}, "score": "43.746704"}
{"text": "In this chapter , taking inspiration from the apparent ability of the human auditory system to summarize speech in features which are automatically normalised for vocal tract length , we developed a scale - shift invariant feature representation for use with a simple syllable recogniser .", "label": "", "metadata": {}, "score": "44.071026"}
{"text": "The first is to demonstrate clearly that traditional speach features ( MFCCs ) are not VTL - invariant ; the second is to provide a baseline system for the assessment of machine hearing systems decribed later in the thesis .Specifically , in chapter 4 , the features developed here are computed on the output of an auditory model that includes strobed temporal integration in order to determine whether stabilization might improve the noise - robustness of recognitions systems .", "label": "", "metadata": {}, "score": "44.916622"}
{"text": "In the speech recognition system described here , the input speech is pre - processed using an algorithm for speech enhancement .A number of different methods for the enhancement of speech , combined with the auditory front - end of Li et al .", "label": "", "metadata": {}, "score": "45.080833"}
{"text": "( See Campbell and King , 2004 ; McAlpine , 2005 ; McAlpine and Grothe , 2003 ; Brand et al . , 2002 ; Zhou et al . , 2005 . )Whether these finer discrepancies between the original Jeffress ' model assumptions and the more recent neurophysiological data constitute a refutation of the core signal processing principles of the model ( binaural temporal cross - correlation operations on temporally - coded inputs ) has been a matter of ongoing discussion and debate .", "label": "", "metadata": {}, "score": "45.773445"}
{"text": "The next step for these features will be to test them on a larger - scale , real - world speech recognition task .Ideally , the features would be assessed by training on one class of speakers , men for example , and then testing on women and children .", "label": "", "metadata": {}, "score": "46.533287"}
{"text": "These are both encouraging findings and both point the way for further research into auditory features .One remaining challenge is to find a feature set which is both constrained enough to retain a set of scale - invariant features , and yet rich enough to allow accurate recognition on more challenging datasets .", "label": "", "metadata": {}, "score": "46.673225"}
{"text": "ICASSP , Vol .I , pp .469 - 472 , 1992 ; \" Speaker Independent Speech Recognition Method Using Phoneme Similarity Vector , \" by M. Hoshimi et al . , Proc .ICSLP , Vol . 3 , pp .", "label": "", "metadata": {}, "score": "46.766136"}
{"text": "Jeffress envisaged that each cochlear place or frequency channel would map to a separate neural cross - correlation circuit , such that the whole architecture consists of an array of these circuits ( Figure 2 ) .The inputs to the binaural time - delay cross - correlator come from the left and right auditory neural pathways .", "label": "", "metadata": {}, "score": "46.894947"}
{"text": "The features are designed so that they do not vary with changes in the VTL of the speaker .The recognition system is assembled using HTK , a standard toolkit used for developing prototype speech recognition systems .The recogniser was trained on a database of syllables with a fixed VTL and glottal pulse rate ( GPR ) .", "label": "", "metadata": {}, "score": "46.913403"}
{"text": "Introduction .In standard speech recognition systems , the acoustic features used to represent the speech change with the vocal tract length of the speaker .By contrast , the human auditory system is exceptionally robust to changes in VTL , even when the test VTL is well outside the range of normal experience ( Ives et al . , 2005 ; Smith et al . , 2005 ) .", "label": "", "metadata": {}, "score": "47.043747"}
{"text": "[ 1 ] .Bridle , J. and Brown , M. ( 1974 ) . \"An experimental automatic word recognition system . \"JSRU Report , 1003 , p .. [ 1 ] .Brown , G.J. and Cooke , M. ( 1994 ) . \"", "label": "", "metadata": {}, "score": "47.29513"}
{"text": "Inspired by the observation that humans appear to be able to perform VTLN automatically on the incoming signal , in chapter 2 , an alternative feature representation for machine hearing which is invariant to changes in the size of the source is developed and tested .", "label": "", "metadata": {}, "score": "47.639362"}
{"text": "Performance with the SAI - based features exceeds that with MFCC - based features , even when the MFCCs are extended to encompass a larger temporal window and higher spectral resolution .The PZFC was used as the cochlear model in this system ; it is an efficient compressive auditory filterbank , and as demonstrated in chapter 5 , can be made to behave similarly to the more computationally demanding dcGC filterbank .", "label": "", "metadata": {}, "score": "47.89446"}
{"text": "After Agarwal and Cheng [ 25 ] , the next best performance across the board is obtained using Ephraim and Malah [ 20 ] , and Westerlund et al .[ 22 ] .This suggests that the choice of speech enhancement algorithm for best speech recognition performance is somewhat independent of the choice of front - end ( though this would have to be validated by further testing with other front ends ) .", "label": "", "metadata": {}, "score": "47.949123"}
{"text": "The proposed model works in two stages .First , the n - best list generated by the speech recognizer is expanded with additiona ... \" .We describe a novel n - best correction model that can leverage implicit user feedback ( in the form of clicks ) to improve performance in a multi - modal speech - search application .", "label": "", "metadata": {}, "score": "47.979248"}
{"text": "Comparison with wide - range training .Performance of the standard MFCC features was low when the recognizer was trained on only the central speakers .This result is expected , since the MFCCs are not scale - invariant .However , in real speech recognition systems , it may be possible to train on a range of speakers .", "label": "", "metadata": {}, "score": "48.36961"}
{"text": "( I ) and Li et al .( II ) , is to allow for a closer comparison with the ETSI basic front - end [ 6 ] and the ETSI advanced front - end [ 7 ] respectively .In all cases training was carried out using clean data , so that the effect of the speech enhancement in removing mismatch could be examined .", "label": "", "metadata": {}, "score": "48.50718"}
{"text": "The syllable recogniser was set up to use either MFCCs , or features generated from a cochlear filterbank .The training data were human syllables from a single talker , and the test data were the same human syllables scaled using STRAIGHT to a range of VTL and GPR combinations .", "label": "", "metadata": {}, "score": "48.51136"}
{"text": "Figure 1 .MFCC feature extraction .Auditory modelling as an alternative front - end .Many computational auditory models have been proposed for use in speech recognition systems , often with excellent results , particularly in the presence of noise .", "label": "", "metadata": {}, "score": "48.690315"}
{"text": "The word recognition processor of claim 1 wherein said region count stage produces a first score corresponding to the degree of fit between the input utterance and each of the first list of word candidates ; . wherein said target congruence stage produces a second score corresponding to the degree of fit between the input utterance and each of the second list of word candidates ; and . wherein said recognizer combines the first and second scores and selects at least the word with the best score as a final word candidate .", "label": "", "metadata": {}, "score": "48.76705"}
{"text": "The feature vectors produced by the auditory model are transmitted over a channel that is subject to packet burst loss and packet loss mitigation to compensate for missing features is investigated .Conclusions are presented in Section 5 .Distributed speech recognition systems .", "label": "", "metadata": {}, "score": "48.861404"}
{"text": "( 2009 ) described a multimodal pervasive framework based specifically at the grammar level and developed a methodology for defining a formal grammar and inductive mechanisms to generate rules for synthesizing grammars .They envisaged four architectural levels : acquisition , analysis , planning , and activation level .", "label": "", "metadata": {}, "score": "48.88217"}
{"text": "This ' undersampling problem ' is described in detail by de Cheveign\u00e9 and Kawahara ( 1999 ) .The SSI .The ' scale - shift covariant ' or ' size - shape ' image ( SSI ) is another two - dimensional frame - based representation of the audio signal .", "label": "", "metadata": {}, "score": "48.910603"}
{"text": "The processing stages of the word hypothesizer are applied in sequence to reduce the search space for a more computationally expensive fine match word recognition system .Speech representation by phoneme similarities has been applied in speaker - independent , template - based word recognition systems for their relative insensitivity to speaker variations .", "label": "", "metadata": {}, "score": "49.19189"}
{"text": "One alternative is to make use of automatic speech recognition ( ASR ) systems that act on speech input from the user .An ASR system has two main elements .The first element is a front - end processor that extracts parameters , or features , that represent the speech signal .", "label": "", "metadata": {}, "score": "49.21363"}
{"text": "The feature models the smoothed output of an auditory filterbank with a constrained Gaussian mixture model .The effectiveness of this approach was demonstrated in a simple syllable recognition task , where scale - shift invariant features were compared with standard MFCC features for recognising a set of 185 syllables generated from 57 different simulated speakers .", "label": "", "metadata": {}, "score": "49.2589"}
{"text": "Two machine hearing systems are developed ; these systems use the auditory features produced by AIM in a speech recognition task and a sound - effects search task .Significantly , the systems are able to scale to large datasets , allowing the use of auditory features in machine learning tasks requiring hundreds of hours of training data .", "label": "", "metadata": {}, "score": "49.26572"}
{"text": "Speech recognition systems which match each input utterance to reference templates composed of phoneme similarity vectors , as in the model speech method of Hoshimi et al . , cited above , have achieved high accuracies for small vocabulary tasks .Their reference speech representation is frame - based and requires a high data rate ( typically 8 to 12 parameters every 10 to 20 milliseconds ) .", "label": "", "metadata": {}, "score": "49.45673"}
{"text": "The first aspect of the auditory system used for inspiration was its apparent ability to generate a stream of information that is invariant to changes in the scale of the source .This observation led to the development of a scale - shift invariant feature , which attempts to encode information about spectral shape in a scale - invariant manner .", "label": "", "metadata": {}, "score": "49.611404"}
{"text": "Abstract .The multistage word recognizer uses a word reference representation based on reliably detected peaks of phoneme similarity values .The word reference representation captures the basic features of the words by targets that describe the location and shape of stable peaks of phoneme similarity values .", "label": "", "metadata": {}, "score": "49.769833"}
{"text": "( 2005 ) extended the stimuli from the study of Smith et al .( 2005 ) to a large database of 180 consonant - vowel and vowel - consonant syllables .They again showed that recognition performance was extremely good across the entire range of GPR and VTL ; indeed , performance was better than for the vowels alone .", "label": "", "metadata": {}, "score": "49.86471"}
{"text": "This work also demonstrates that in the case where the recognizer can be tuned to the new task , environment , or speaker , the post - processor can also contribute to performance improvements .ome training data .We adopt statistical techniques ( some of them from statistical machine translation ) for modeling that channel in order to correct some of the errors introduced there .", "label": "", "metadata": {}, "score": "49.944168"}
{"text": "The audio search system developed at Google demonstrates the effectiveness of auditory features , and includes some very significant technological achievements .The use of sparse features allows the system to scale to extremely large training datasets through the use of PAMIR .", "label": "", "metadata": {}, "score": "50.176697"}
{"text": "So far , this thesis has studied the properties of the human auditory system in gradually increasing levels of detail .At the largest scale , the feature representation developed in chapter 2 aimed to emulate the observed behaviour of the system as a scale - invariant preprocessor , which can provide a representation of pulse - resonance communication sounds independent of the pulse rate and the resonance scale of the sound .", "label": "", "metadata": {}, "score": "50.190853"}
{"text": "The recognisers were then tested on the complete set of scaled speakers without further training .The voices used in training were also added to the test set for completeness , but reported results are for the standard test set only .", "label": "", "metadata": {}, "score": "50.24543"}
{"text": "In this paper we provide the state - of - the - art of existing proprietary and free and open source software ( FOSS ) automatic speech recognition ( ASR ) , speech synthesizers , and Machine Translation ( MT ) tools .", "label": "", "metadata": {}, "score": "50.31362"}
{"text": "Two different feature representation are developed and tested .One on a simple speech recognition task , the second on a more complex sound - effects analysis task .As part of this undertaking , the physiological basis of auditory processing is reviewed , and used to inform improvements to various parts of AIM .", "label": "", "metadata": {}, "score": "50.3953"}
{"text": "\"Auditory toolbox .\"Apple Computer Company : Apple Technical Report , 45 , p .. [ 1 ] .Slaney , M. , Naar , D. and Lyon , R.F. ( 1994 ) .\" Auditory model inversion for sound separation . \"", "label": "", "metadata": {}, "score": "50.40628"}
{"text": "Similar behavior is observed in the phoneme plausibility time series of the VINICS system , as described in \" Plausibility Functions in Continuous Speech Recognition : The VINICS System , \" by Y. Gong and J. P. Haton , Speech Communication , Vol . 13 , Oct. 1993 , pp .", "label": "", "metadata": {}, "score": "50.417145"}
{"text": "Here it should be pointed out that Rosenfeld et al .( 2001 ) also mentioned that constraining language is a plausible method of improving recognition accuracy .SAPI 5.1 was also used by Haage et al .( 2002 ) to develop a speech system to design robot trajectories that would fit with CAD paradigms .", "label": "", "metadata": {}, "score": "50.544292"}
{"text": "The second system is a standard AIM system , based on the sf1992 strobe - detection algorithm ( with various improvements discussed in chapter 3 of this thesis ) and the ti2003 temporal integration system .The next stage of processing ( 3 ) is the sparse coding of the auditory image to produce a high - dimensional feature vector with only a few nonzero elements .", "label": "", "metadata": {}, "score": "50.58174"}
{"text": "DESCRIPTION OF THE PREFERRED EMBODIMENT .The present invention employs a unique compact speech representation based on regions of high phoneme similarity values .As shown in FIG .1 , there is an overall consistency in the shape of the phoneme similarity time series for a given word .", "label": "", "metadata": {}, "score": "50.621563"}
{"text": "These have been proven in a large - scale content - based audio analysis task , but there are also many other possibilities for feature representations from the SAI .As shown in chapter 5 , the temporal profile of the SAI can provide a pitch track , even for stimuli which lack a strong harmonic structure , and the scale shift invariant features developed in chapter 2 show a potential route for the scale - independent analysis of audio .", "label": "", "metadata": {}, "score": "50.625828"}
{"text": "Finally , a complete audio analysis system is constructed which draws together many of the aspects investigated in the previous chapters .In chapter 2 , a simple syllable recognition system is developed which has the important property of scale - shift invariance .", "label": "", "metadata": {}, "score": "50.627647"}
{"text": "Speech recognition system .The classifier used for the recognition experiments in the work presented in this chapter is the HMM - based recogniser architecture specified for use with the Aurora 2 database [ 16 ] , and implemented with the widely - used HTK package [ 19 ] .", "label": "", "metadata": {}, "score": "50.72371"}
{"text": "The experiments presented in this chapter do not , on their own , justify the use of a compressive filterbank in a machine hearing system .However , they provide an insight into the utility of compressive filterbanks in the processing of stimuli in which the temporal fine structure is important .", "label": "", "metadata": {}, "score": "50.767834"}
{"text": "The method used to measure the performance of a speech recognition system is dependent on the type of utterance that is to be recognised , i.e. isolated word or continuous speech .There are three error types associated with the recogniser in a continuous speech recognition system : .", "label": "", "metadata": {}, "score": "50.818546"}
{"text": "These models , which are sometimes very simplistic , are used to generate feature streams which can be passed to automated systems to extract meaning from sounds .Making use of some of the features of the auditory system which are believed to assist in the processing of communication sounds .", "label": "", "metadata": {}, "score": "50.93741"}
{"text": "While tuning of the AGC circuits of the PZFC , and evaluation of compressive filterbanks with a speech recognition task are probably both worthy of further study , an outstanding opportunity to work with auditory features on a much larger scale suddenly arose in the autumn of 2008 .", "label": "", "metadata": {}, "score": "51.015736"}
{"text": "These auditory features were compared to standard MFCC features using a simple syllable recognition task and a database of syllables scaled over a large range of both GPR and VTL values .The scale - invariant features were found to be considerably more robust to changes in speaker VTL than MFCCs , and equally robust to changes in GPR .", "label": "", "metadata": {}, "score": "51.06031"}
{"text": "Earlier Macintosh recognizers were by MacSpeech , a company acquired by Nuance Communications in 2010 .12 In the mid-1990s , Microsoft devoted resources to speech and language processing .Today Microsoft Tellme 9 speech technologies enable speech interaction with PC , phone , car , and TV .", "label": "", "metadata": {}, "score": "51.078335"}
{"text": "( 1998 ) and Glasberg and Moore ( 2000 ) , measured the threshold in humans for detection of a sinusoid in asymmetric notched noise .Both studies covered a large range of frequencies and levels , spanning most of the normal range of hearing .", "label": "", "metadata": {}, "score": "51.26483"}
{"text": "Chapter 2 describes the use of a simple auditory filterbank to produce features for a syllable recognition task .The features generated are designed to be scale - shift invariant , mimicking an important feature of human perception of communication sounds .", "label": "", "metadata": {}, "score": "51.41249"}
{"text": "Valentino Braitenberg proposed a Jeffress - like architecture for his general - purpose cerebellar timing model ( Braitenberg 1961 ; Braitenberg 1967 ; Braitenberg 2000 ) and delay - coincidence models for the cerebral cortex and hippocampus are also conceivable .Although the dominant assumption has been that time patterns are converted to rate - place patterns or rate - based channel - activation , other Jeffress - like cross - correlation networks can readily be envisioned that produce other kinds of output representations .", "label": "", "metadata": {}, "score": "51.492516"}
{"text": "Thus a pattern of temporal disparities is mapped onto a spatial pattern of excitation ( place principle ) .See Colburn ( 1996 ) and Trahiotis et al .( 2006 ) for discussion of the implications of this frequency - interaural time delay ( ITD ) representation for explaining diverse aspects of binaural psychophysics .", "label": "", "metadata": {}, "score": "51.541718"}
{"text": "The SearchManager in the Decoder uses the Features from the FrontEnd and the SearchGraph from the Linguist to perform the actual decoding , generating Results ( Walker et al ., 2004 ) .Hidden Markov Toolkit 14 ( HTK ) : it is a portable toolkit for building and manipulating HMMs .", "label": "", "metadata": {}, "score": "51.60135"}
{"text": "[ 22 ] , for which the overall recognition results are quite close .For Li et al .( I ) , Li et al .( II ) , the ETSI basic front - end and the ETSI advanced front - end , the best overall recognition accuracy is obtained for speech enhancement using the algorithm proposed by Agarwal and Cheng [ 25 ] .", "label": "", "metadata": {}, "score": "51.684723"}
{"text": "There are alternatives to this approach ; Mertins and Rademacher ( 2005 ) , for example , presented an alternative VTL - independent feature based on the cross - correlation between adjacent frames of the spectrum .Their system relies on the fact that the spectral centroid of an utterance will shift as a function of vocal tract length .", "label": "", "metadata": {}, "score": "51.703358"}
{"text": "By combining the quasi - independent sources of information produced at each stage , a significant gain in accuracy is obtained .The system 's architecture features three distinct components that are applied in sequence on the incoming speech to compute the best word candidate .", "label": "", "metadata": {}, "score": "51.737007"}
{"text": "Features that are more robust to changes in the source size will give better performance when trained on data from a speaker of one size , and then tested on a range of speakers of different sizes .The VTL - invariant features developed here also serve as a baseline system for a set of features developed in chapter 4 , where the auditory model is extended to incorporate the noise - robustness exhibited by the stabilised auditory image .", "label": "", "metadata": {}, "score": "51.848312"}
{"text": "It is AIM - C that made it possible to perform the syllable recognition studies presented in chapters 2 and 4 .Invariance properties of the auditory system .The auditory system has two important invariance properties in its processing of sounds .", "label": "", "metadata": {}, "score": "51.916344"}
{"text": "Robustness is achieved by a combination of statistical error post - correction , syntactically- and semantically - driven robust parsing , and extensive use of the dialogue context .We present an evaluation of the system using time - to - completion and the quality of the final solution that suggests that most native speakers of English can use the system successfully with virtually no training . by A. Stolcke , H. Bratt , J. Butzberger , H. Franco , V. R. Rao Gadde , M. Plauch\u00e9 , C. Richey , E. Shriberg , K. S\u00f6nmez , F. Weng , J. Zheng - In Proceedings of the NIST Speech Transcription Workshop , 2000 . \" ...", "label": "", "metadata": {}, "score": "51.921314"}
{"text": "In this paper we presented the state - of - the - art of automatic speech recognition and speech synthesis , dialog systems , and speech - to - speech translation .Gesture examples , recognition software , and meaning of gesture localization were also furnished .", "label": "", "metadata": {}, "score": "52.039474"}
{"text": "Referring to FIG .3 , the interesting regions of high phoneme similarity value are represented as high similarity regions .By representing the speech as features at a lower data rate in the initial stages of recognition , the complexity of the matching procedure is greatly reduced .", "label": "", "metadata": {}, "score": "52.04431"}
{"text": "( 2009 ) deployed sensors into an assistive environment .They state that \" the speech interface is the easiest way for the user to interact with the computer based service system \" .The dialog management system they implemented uses the ASR engine Sphinx combined with the Cepstral and Festival speech synthesis .", "label": "", "metadata": {}, "score": "52.24683"}
{"text": "Finally in chapter 6 , a complete machine hearing system comprising a compressive filterbank , a stabilised auditory image , a sparse feature representation and a machine learning system is used as a sound - effects search tool which is capable of associating text terms with the content of audio files .", "label": "", "metadata": {}, "score": "52.27494"}
{"text": "In a fully embedded ASR system [ 1 ] , the feature extraction and the speech classification are carried out on the mobile device .However , due to the computational complexity of high - performance speech recognition systems , such an embedded architecture can be impractical on mobile hand - held terminals due to limitations in processing and memory resources .", "label": "", "metadata": {}, "score": "52.27809"}
{"text": "In doing this , it was hypothesised that the auditory images generated using strobed temporal integration should be more robust to noise than features generated from more simple , purely spectral models .This hypothesis was investigated in chapter 4 by adapting the auditory features developed in chapter 2 .", "label": "", "metadata": {}, "score": "52.487732"}
{"text": "The Jeffress model is a neurocomputational model that explains how auditory systems can register and analyze small differences in the arrival time of sounds at the two ears in order to estimate the direction of sound sources in the azimuthal plane .", "label": "", "metadata": {}, "score": "52.53382"}
{"text": "In summary , the experiments and results outlined in this chapter show the benefit of combining speech enhancement and packet loss mitigation to combat both noise and packet loss .Furthermore , the performance of the auditory model of Li et al . was generally shown to be superior to that of the standard ETSI advanced front - end .", "label": "", "metadata": {}, "score": "52.543884"}
{"text": "I 'm very excited by the future of machine hearing and I look forward to testing the performance of , and putting to work , ever - improving feature representations based on an understanding of human audition .Aertsen , A. and Johannesma , P. ( 1980 ) . \"", "label": "", "metadata": {}, "score": "52.63739"}
{"text": "Conclusions .We developed a content - based sound ranking system that can learn a match between acoustic features of the sound , and a set of text labels .Two different classes of acoustic features were investigated : MFCCs and features based on the SAI .", "label": "", "metadata": {}, "score": "52.78005"}
{"text": "O'Brien , S. ( 2010 ) .\" Eye tracking in translation process research : methodological challenges and solutions \" in Copenhagen Studies In Language , 38 , pp .251 - 266 .Paulik , M. , F\u00fcgen , C. , St\u00fcker , S. , Schultz , T. , Schaaf , T. , Waibel , A.(2005 ) , \" Document driven machine translation enhanced automatic speech recognition \" in Proceedings of InterSpeech .", "label": "", "metadata": {}, "score": "52.79503"}
{"text": "SAI features also achieve better precision - at - top - k consistently for all values of k , although with lower relative precision improvement .Error reduction from MFCC to SAI features .It is important to note that the parameters found ( and the auditory model architecture in general ) are not guaranteed to be optimal , and it is possible that further refinement could further improve the retrieval precision .", "label": "", "metadata": {}, "score": "52.865753"}
{"text": "The text terms were then stemmed using the Porter stemmer for English ( Porter , 1980 ) , leaving a total of 3,268 unique tags .The sounds had an average of 3.2 tags each .Experimental setup .Cross - validation was used to estimate performance of the learned ranking system .", "label": "", "metadata": {}, "score": "52.90396"}
{"text": "[72 ] or Gold and Morgan [ 57].sCHAPTER 2 .HIDDEN MARKOV MODEL SPEECH RECOGNITION 8 2.2.1 Dynamic Features The set of ... . \" ... roduction - based knowledge into the recognition framework .By using an explicit time - domain articulatory model of the mechanisms of co - articulation , it is hoped to obtain a more accurate model of contextual effects in the acoustic signal , while using fewer parameters than traditional acoustically - dri ... \" .", "label": "", "metadata": {}, "score": "52.91064"}
{"text": "Am . , 108 , p.2318 - 2328 .[ 1 ] [ 2 ] [ 3 ] .Glasberg , B.R. and Moore , B.C.J. ( 2002 ) .\" A model of loudness applicable to time - varying sounds . \"", "label": "", "metadata": {}, "score": "52.981953"}
{"text": "In order to fit the human masking data of Baker et al . and Glasberg and Moore with the PZFC , a number of modifications were made to the fitting technique described by Patterson et al . .K , the measure of detection mechanism efficiency , was removed from the search space as it can be determined from the other parameters .", "label": "", "metadata": {}, "score": "52.985626"}
{"text": "The speed of the PZFC makes it possible to generate auditory features within a large - scale systems .The efficiency of the filter cascade architecture and the AGC network means that it can provide compressive filtering with not much more computation than a linear gammatone filterbank .", "label": "", "metadata": {}, "score": "52.991646"}
{"text": "However , the performance of the features on the task of syllable recognition in noise was markedly different .In the original syllable recognition experiments the MFCC features performed reasonably well , and MFCCs with optimal VTLN performed excellently .The task was then changed so that the syallable recogniser was trained on a range of examples with different signal - to - noise - ratios ( SNRs ) , and then tested at each SNR in turn .", "label": "", "metadata": {}, "score": "53.0303"}
{"text": "\" The Journal of Machine Learning Research , 7 , p.585- .[ 1 ] .Davis , S.B. and Mermelstein , P. ( 1990 ) .\" Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences . \"", "label": "", "metadata": {}, "score": "53.078873"}
{"text": "Soc .Am . , 67 , p.1704 - 1721 .[ 1 ] .Krumbholz , K. , Patterson , R.D. , Nobbe , A. and Fastl , H. ( 2003 ) . \"Microsecond temporal resolution in monaural hearing without spectral cues ?", "label": "", "metadata": {}, "score": "53.10826"}
{"text": "In all these cases , the designers were implicitly adding more prior information about their knowledge of the form of the signal emerging from the auditory filterbank , and attempting to tailor the strobe criterion to that form .Later in this chapter , I attempt to place these implicit constraints on a firmer theoretical basis in order to choose the best parameters of a strobing scheme in a principled way .", "label": "", "metadata": {}, "score": "53.133553"}
{"text": "The method of claim 16 further comprising : . comparing the input speech utterance with each prototype to provide a recognition score .Description .BACKGROUND AND SUMMARY OF THE INVENTION .The present invention relates generally to speech recognition .More particularly , the invention relates to a word recognizer having multistage word candidate hypothesizer .", "label": "", "metadata": {}, "score": "53.162376"}
{"text": "Patterson , R.D. , Walters , T.C. , Monaghan , J. , Feldbauer , C. and Irino , T. ( 2010 ) . \"Auditory speech processing for scale - shift covariance and its evaluation in automatic speech recognition . \"Booktitle : IEEE International Symposium on Circuits and Systems , 2010 .", "label": "", "metadata": {}, "score": "53.16263"}
{"text": "A phoneme similarity module , receptive of the input speech utterance , accesses the phone model database and produces phone similarity data indicative of the correlation between the input speech utterance and the phone model speech data corresponding to successive intervals of time .", "label": "", "metadata": {}, "score": "53.1932"}
{"text": "I have demonstrated some key applications of machine hearing systems , highlighting the potential utility of such systems for scale - independent speech recognition and content - based audio search .I believe that the groundwork has been laid for the development of a ' canonical ' baseline system for machine hearing systems .", "label": "", "metadata": {}, "score": "53.316437"}
{"text": "The various feature variants are compared with each other and with the standard MFCC features used in chapter 2 .The stabilised auditory image .The auditory image model ( AIM ) ( Patterson et al . , 1995 ) provides a framework for creating a stabilized auditory image ( SAI ) from the output of a filterbank .", "label": "", "metadata": {}, "score": "53.420967"}
{"text": "Also , confusion network decoding has been the most successful approach in combining outputs from multiple MTs ( Rosti et al .2008 ) .20 The combination of ASR - SMT systems has two usages : i ) translation dictation and ii ) spoken language translation .", "label": "", "metadata": {}, "score": "53.42473"}
{"text": "This means that the temporal integration that occurs in the auditory system can not be simulated by a running temporal average process , since averaging over time destroys the temporal fine structure within the averaging window ( Patterson et al . , 1995 ) .", "label": "", "metadata": {}, "score": "53.46435"}
{"text": "The FrontEnd comprises one or more parallel chains of replaceable communicating signal processing modules , so that it takes one or more input signals and parameterizes them into a sequence of Features .The Linguist generates the SearchGraph that is used by the decoder during the search ; it translates any type of standard language model , along with pronunciation information from the dictionaryand structural information from one or more sets of acoustic models .", "label": "", "metadata": {}, "score": "53.493275"}
{"text": "There is much scope for further research on the exact form of the features that are present in the auditory image , and what features of the sounds are enhanced by processing through an auditory model .The analysis of audio signals based on their content has typically been founded on signal processing techniques chosen for mathematical and engineering expediency .", "label": "", "metadata": {}, "score": "53.547077"}
{"text": "The word hypothesizer stages , depicted in FIG .4 generally at 14 , comprise the second major component of the system .A peak driven procedure is first applied on the phoneme similarity time series supplied by front end 10 .", "label": "", "metadata": {}, "score": "53.633953"}
{"text": "Of special interest would be to find out which sounds , if any , particularly benefit from the use of a compressive filterbank in the preprocessor .Sparse features for sound effects ranking .In the final chapter of this thesis , I presented a study undertaken at Google research into building a complete , machine hearing based , sound effects search system .", "label": "", "metadata": {}, "score": "53.65387"}
{"text": "Am . , 22 , p.167 - 173 .[ 1 ] .Monaghan , J.J. , Feldbauer , C. , Walters , T.C. and Patterson , R.D. ( 2008 ) .\" Low - dimensional , auditory feature vectors that improve vocal - tract - length normalization in automatic speech recognition .", "label": "", "metadata": {}, "score": "53.671833"}
{"text": "The system relies on the fact that the spectral centroid of an utterance will shift as a function of vocal tract length .Cross - correlating adjacent frames will tend to ' normalise ' the spectrum ( while blurring it ) , shifting the spectrum of a frame towards the overall spectral centroid and thus giving a signal which is more resistant to shifts in VTL .", "label": "", "metadata": {}, "score": "53.738106"}
{"text": "Recognition performance was 99.0 % across the whole test set , with the most errors being made on the speaker with the shortest VTL , where performance fell to 84.9 % .Figure 24 shows the results for these optimally - warped features as a function of VTL and GPR .", "label": "", "metadata": {}, "score": "53.947243"}
{"text": "One approach that can be used to improve the robustness of ASR systems is to enhance the speech signal itself before feature extraction .Speech enhancement can be particularly useful in cases where a significant mismatch exists between training and testing conditions , such as where a recognition system is trained with clean speech and then used in noisy conditions .", "label": "", "metadata": {}, "score": "53.957405"}
{"text": "In effect , the hypothesizer stages select the most probable word candidates and thereby reducing the search space for the fine match procedure .To further improve recognition reliability the probability scores obtained at each stage of the word hypothesizer are combined with the scores of the fine match procedure in order to produce a final word decision .", "label": "", "metadata": {}, "score": "53.964104"}
{"text": "The second stage represents each word by a prototype that consists of a series of phoneme targets and global statistics , namely the average word duration and average match rate .These represent the degree of fit of the word prototype to its training data .", "label": "", "metadata": {}, "score": "54.047142"}
{"text": "In the case of a simple syllable recogniser , each possible syllable is represented by a single HMM .At training time , the transition probabilities and emission probability distribution for each HMM are learned .Experiments .The models were trained on the reference speaker at the centre of the spoke pattern ( Figure 17 ) and the eight speakers closest to the reference speakers to simulate the training of a standard , speaker - specific automatic speech recognition system .", "label": "", "metadata": {}, "score": "54.049744"}
{"text": "Developing such systems requires both efficient and effective algorithms for large - scale machine learning of a range of sound categories , and a representation of the sounds themselves that captures the full range of auditory features that humans use to discriminate and identify different sounds .", "label": "", "metadata": {}, "score": "54.0591"}
{"text": "In DSR , the terminal ( the mobile device ) includes a local front - end processor that extracts , directly from the speech , the features to be sent to the remote server ( back - end ) where recognition is performed .", "label": "", "metadata": {}, "score": "54.07993"}
{"text": "In all the systems discussed above there is an implicit assumption about the form of the sound that the system is dealing with .Event detection in the output of the auditory filterbank is informed by both the characteristics of the filterbank itself , and the characteristics of the class of sounds expected as input to that filterbank .", "label": "", "metadata": {}, "score": "54.105965"}
{"text": "( II ) undergo post - processing in the cepstral domain by means of cepstral mean subtraction ( CMS ) .The recognition results for Li et al .( II ) , for each speech enhancement algorithm , are detailed in Table 3 and the recognition results for the ETSI advanced front - end are detailed in Table 4 .", "label": "", "metadata": {}, "score": "54.128883"}
{"text": "It then learns a linear mapping from the feature space to the query term space .Figure 93 -- Overview of the Machine Hearing system developed at Google Research .In this study , we assessed the difference in performance between MFCC - based features and two forms of SAI - based features .", "label": "", "metadata": {}, "score": "54.200684"}
{"text": "The implementation of noise reduction in the ETSI advanced front - end is summarised in [ 12 ] .Tests and results .This section presents recognition results from tests on the Aurora 2 database [ 16 ] , using the combination of the speech enhancement algorithms described previously and the auditory model proposed by Li et al .", "label": "", "metadata": {}, "score": "54.24277"}
{"text": "The word hypothesizer and fine match stages of the invention share the initial representation of speech as a sequence of multiple phoneme similarity values .The word hypothesizer stages further refine this speech representation , to preserve only the interesting regions of high phoneme similarity , or features .", "label": "", "metadata": {}, "score": "54.287262"}
{"text": "Gaussian features have previously been shown to be effective in single speaker systems ( Zolfaghari et al . , 2006 ; Stuttle and Gales , 2001 ) , and so should provide a succinct , low - dimensional , representation of the spectral profile .", "label": "", "metadata": {}, "score": "54.298325"}
{"text": "First a macroscopic observed property of the auditory system , that it appears to perform automatic scale - normalisation , was used to inform the development of scale - shift invariance of the features .Secondly , a predicted property of the image stabilization process , that it creates auditory images which are more robust to interfering noise , was tested with the scale - shift invariant auditory features .", "label": "", "metadata": {}, "score": "54.345196"}
{"text": "Both of these stimuli lack energy at the fundamental , but both produce a good signal in temporal models of pitch perception , such as those based on the stabilised auditory image .The well - established dynamic compressive gammachirp ( dcGC ) filterbank , developed by Toshio Irino , was compared with the pole - zero filter cascade ( PZFC ) of Dick Lyon , with regard to their ability to explain the strong pitch produced by these stimuli .", "label": "", "metadata": {}, "score": "54.400684"}
{"text": "Top 1 recognition rates under two training speech conditions and 5 test speech conditions are shown in FIG .7 .For more information on the McNemar test see \" Some Statistical Issues in the Comparison of Speech Recognition Algorithms , \" by L. Gillick and S. J. Cox , Proc .", "label": "", "metadata": {}, "score": "54.410957"}
{"text": "Alignment time , memory size and error rate under clean or mild noise conditions are in fact superior to the fine match procedures .The robustness of the word hypothesizer 's top 1 recognition performance under various other adverse conditions is under current investigation .", "label": "", "metadata": {}, "score": "54.42508"}
{"text": "In practice such a system would require the computation of MFCCs with a number of warping factors for each utterance ; the recognition system would then attempt to find the warping of the features which minimises the recognition error .Comparison of computational complexity .", "label": "", "metadata": {}, "score": "54.550545"}
{"text": "The mechanism that sharpens the peak is not immediately clear , but what is clear is that time - varying compression is an important factor in the processing of these stimuli .In the following sections I detail a number of experiments performed to judge the ability of an AIM - based model with a dcGC or PZFC filterbank to detect the dominant periodicity in these stimuli .", "label": "", "metadata": {}, "score": "54.61499"}
{"text": "OriginalCiteRef : huygens:1693 .[ 1 ] .Irino , T. , Patterson , R.D. and Kawahara , H. ( 2006 ) . \"Speech segregation using an auditory vocoder with event - synchronous enhancements . \"IEEE Trans .Audio , Speech , and Language Process . , 14 , p.2212 -", "label": "", "metadata": {}, "score": "54.620407"}
{"text": "Performance both with the scale - shift invariant features and with the MFCC features increased markedly when the system was trained in this way , and overall recognition accuracy was around 99 % with either feature set .When VTLN was performed as well , performance rose to 100 % accuracy .", "label": "", "metadata": {}, "score": "54.74671"}
{"text": "The network was perhaps the first explicit neural information - processing model to successfully account for major aspects of perceptual function ( see note 1 ) .Psychophysics .The model was formulated to account for binaural psychophysical observations .Humans are capable of using interaural time - of - arrival differences ( ITDs ) of as small as 10 - 20 microseconds to distinguish directional differences of sound sources in the horizontal plane as small as 1 - 2 degrees ( azimuth ) .", "label": "", "metadata": {}, "score": "54.76555"}
{"text": "It is difficult to tease apart the aspects of these systems which might lead to small changes in overall performance on an open - ended task such as this .In future work , I intend to assess the use of different strobe systems in a source separation task , in order to fully understand the effect of strobe detection on the generation of stabilised auditory images .", "label": "", "metadata": {}, "score": "54.83825"}
{"text": "It specifically addresses the issue of robust interpretation of speech in the presence of recognition errors .Robustness is achieved by a combination of ... \" .This paper describes a system that leads us to believe in the feasibility of constructing natural spoken dialogue systems in task - oriented domains .", "label": "", "metadata": {}, "score": "54.893528"}
{"text": "In this initial auditory model , the normalized feature representation is generated from the output of a simple , linear auditory filterbank without image stabilization .A linear filterbank provides a reasonable simulation of cochlear processing for wideband sounds that do not vary markedly in level which is the case for the syllable recognition task used to evaluate the normalized auditory features .", "label": "", "metadata": {}, "score": "54.92583"}
{"text": "\" The deterioration of hearing with age : frequency selectivity , the critical ratio , the audiogram , and speech threshold .\" J. Acoust .Soc .Am . , 72 , p.1788 - 1803 .[ 1 ] .Patterson , R.D. , Robinson , K. , Holdsworth , J. , McKeown , D. , Zhang , C. and Allerhand , M. ( 1992 ) .", "label": "", "metadata": {}, "score": "54.998867"}
{"text": "A neural network is used to generate control parameters for a parallel formant speech synthesizer , corresponding to a sequence of allophone tokens .Training is to be accomplished using formant data obtained from both natural and synthetic speech .It is intended that theories of cognitive phonetics , currently being developed in the Department of Language and Linguistics at the University ofEssex , will be used in order to improve the modelling of coarticulation . .", "label": "", "metadata": {}, "score": "55.02942"}
{"text": "Theoretically , it is also more noise - robust than a simple filterbank representation ( Patterson et al . , 1992 ; Patterson , 1994b ) , since the strobed temporal integration process causes the neural patterns associated with successive cycles of a periodic sound to reinforce each other in the SAI .", "label": "", "metadata": {}, "score": "55.04979"}
{"text": "A predictive statistically - based model of co - articulation is described , and found to yield improved articulatory modelling accuracy compared with X - ray articulatory traces .Parameterised acoustic vectors are synthesised by a set of artificial neural networks , and the resulting acoustic representations are used to re - score N - best recognition hypothesis lists produced by an HMM - based recogniser .", "label": "", "metadata": {}, "score": "55.1444"}
{"text": "Content - based search .In the application developed here , the interface is very similar : a user enters a textual search query , and in response is presented with an ordered list of sound documents , ranked by relevance to the query .", "label": "", "metadata": {}, "score": "55.194912"}
{"text": "14 ] , are evaluated for the purpose of robust connected digit recognition .The ETSI basic [ 6 ] and advanced [ 7 ] front - ends proposed for distributed speech recognition are used as a baseline for comparison .Speech enhancement overview .", "label": "", "metadata": {}, "score": "55.279427"}
{"text": "The object - based model makes explicit predictions in line with limited neurophysiological data currently available but can be readily evaluated experimentally .Finally , we draw parallels between the model and anatomical circuits reported to be engaged during active attention .", "label": "", "metadata": {}, "score": "55.33635"}
{"text": "The object - based model makes explicit predictions in line with limited neurophysiological data currently available but can be readily evaluated experimentally .Finally , we draw parallels between the model and anatomical circuits reported to be engaged during active attention .", "label": "", "metadata": {}, "score": "55.33635"}
{"text": "SpeechTrans : AppTek 's system is deployed on computers , wearable machines , and telephony servers 52 ; the input is recorded through a telephone channel or microphone , and recognized using different ASR systems and tuned to either microphone- or telephone - quality speech .", "label": "", "metadata": {}, "score": "55.349297"}
{"text": "I. Characterization of tonal and natural stimuli . \"Biol .Cybern , 38 , p.223 - 234 .[ 1 ] .Baker , R.J. , Rosen , S. and Darling , A.M. ( 1998 ) . \"An efficient characterisation of human auditory filtering across level and frequency that is also physiologically reasonable \" , in Psychophysical and Physiological Advances in Hearing , Palmer , A.R. , Rees , A. , Summerfield , A.Q. and Meddis , R. editors , p.81 - 87 ( Whurr ) .", "label": "", "metadata": {}, "score": "55.3815"}
{"text": "The layout of the chapter is as follows .Section 2 discusses the DSR architecture and standards in more detail .This is followed by an overview of the auditory model used in this chapter as an alternative front - end to those published in the DSR standards .", "label": "", "metadata": {}, "score": "55.64861"}
{"text": "Smith , Walters and Patterson ( 2007 ) investigated the role of the input speaker on the perception of speaker size .In this study , sustained vowels from men , women and male and female children were scaled using STRAIGHT to a range of VTLs and GPRs .", "label": "", "metadata": {}, "score": "55.65275"}
{"text": "A multistage word hypothesizer is used prior to frame - by - frame alignment in order to reduce the search space and thereby improve real time performance .The number of stages in the hypothesizer , as well as the computational complexity of each stage , and the number of word candidates preserved at each stage can be adjusted to achieve desired goals of speed , memory size and recognition accuracy for a particular application .", "label": "", "metadata": {}, "score": "55.67543"}
{"text": "The multimodal input is parsed according to rules included in the Multimodal Grammar Repository .50 Now we present some work on dialog with relation to robotics but not in assistive environments .Motallebipour & Bering ( 2003 ) developed a prototype to study integration of speech dialog into graphical interfaces .", "label": "", "metadata": {}, "score": "55.720036"}
{"text": "By contrast performance only falls to 97.3 % for the AIM features .For completeness , the MFCC features with optimal VTLN were used with the same train / test configuration .In this case , recognition performance was 100 % correct across the entire space .", "label": "", "metadata": {}, "score": "55.738575"}
{"text": "In 1948 , Lloyd Jeffress sought to outline \" a structural mechanism for representing a time difference spatially \" ( Jeffress , 1948 ) .Jeffress 's proposed time - delay neural network model receives two sets of stimulus - locked spike train signals from the left and right auditory pathways and uses a set of delay lines and coincidence detectors to compute a temporal cross - correlation function .", "label": "", "metadata": {}, "score": "55.742813"}
{"text": "In the auditory image model , this deconvolution occurs at the strobe - finding stage .Furthermore , there must be some process that is able to normalise the signal both for changes in pulse rate and changes in resonance scale .", "label": "", "metadata": {}, "score": "55.76628"}
{"text": "Soc .Am . , 96 , p.1419 - 1428 .[ 1 ] [ 2 ] [ 3 ] .Patterson , R.D. , Allerhand , M.H. and Gigu\u00e8re , C. ( 1995 ) .\" Time - domain modeling of peripheral auditory processing : A modular architecture and a software platform .", "label": "", "metadata": {}, "score": "55.81562"}
{"text": "Opin .Neurobiol . , 14 , p.481 - 487 .[ 1 ] .Patterson , R. , Holdsworth , J. , Nimmo - Smith , I. and Rice , P. ( 1988 ) . \"SVOS final report : The auditory filterbank . \" APU report , 2341 , p .. [ 1 ] .", "label": "", "metadata": {}, "score": "55.932392"}
{"text": "Eye tracking particularly in the field of translation has been researched by O'Brien ( 2010 ) .37 Some 3D gesture recognition software and their main functions are presented below : .Android Gesture Recognition Tool ( Ne\u00dfelrath et al .2011 ) : it allows recording hand movement gestures by exploiting the accelerometers of an Android smart phone .", "label": "", "metadata": {}, "score": "55.961178"}
{"text": ", 1966 ) mentioned that ' productivity of human translators might be as much as four times higher when dictating ' ( see ' ASR - MT Combination ' ) . 8 Speech models in ASR are categorized into language and acoustic models .", "label": "", "metadata": {}, "score": "55.98312"}
{"text": "This dynamic smoothing network allows the filterbank to adapt rapidly to changes in input level and spectral content .The various parameters of the PZFC can be chosen to give the best fit to various pieces of physiological and psychophysical data .", "label": "", "metadata": {}, "score": "56.016396"}
{"text": "This tutorial provides a comprehensive overview of the methodolog - ical approach to collecting and analyzing auditory brain stem re - sponses to complex sounds ( cABRs ) .cABRs provide a window into how behaviorally relevant sounds such as speech and music are processed in the brain .", "label": "", "metadata": {}, "score": "56.11794"}
{"text": "This tutorial provides a comprehensive overview of the methodolog - ical approach to collecting and analyzing auditory brain stem re - sponses to complex sounds ( cABRs ) .cABRs provide a window into how behaviorally relevant sounds such as speech and music are processed in the brain .", "label": "", "metadata": {}, "score": "56.11794"}
{"text": "This achieves region - to - region alignment .For each training utterance the number of occurrences ( or probability ) of a particular region is then obtained .At that time , regions with probabilities less than a pre - established Reliability Threshold ( typically 0.25 ) are found unreliable and are eliminated .", "label": "", "metadata": {}, "score": "56.152855"}
{"text": "It is clear that the scale - shift invariant features proposed here require further research before becoming a useful alternative to MFCCs , but the experiments also make it clear that scale - shift invariant features warrant further research .The rationale for using Gaussians to fit the speech spectrum came from Zolfaghari et al .", "label": "", "metadata": {}, "score": "56.157898"}
{"text": "[ 1 ] [ 2 ] .Zweig , G. , Lipes , R. and Pierce , J. ( 1976 ) .\" The cochlear compromise .\" J. Acoust .Soc .Am . , 59 , p.975- .[ 1 ] Survey on Speech , Machine Translation and Gestures in Ambient Assisted Living .", "label": "", "metadata": {}, "score": "56.171677"}
{"text": "Conclusions .This chapter has examined the speech recognition performance of both a speech enhancement algorithm combined with the auditory model front - end proposed by Li et al .[14 ] , and the ETSI advanced front - end [ 7 ] , in the presence of both environmental noise and packet loss .", "label": "", "metadata": {}, "score": "56.180344"}
{"text": "[ 1 ] .Grangier , D. and Bengio , S. ( 2008 ) .\"A discriminative kernel - based model to rank images from text queries . \"IEEE Trans .Pattern Anal .Mach .Intell . , , p.1371 - 1384 .", "label": "", "metadata": {}, "score": "56.32433"}
{"text": "It was tested against dcGC filterbank and the linear and log - compressed gammatone filterbanks in two pitch - strength determination tasks .The PZFC was found to be computationally efficient and to have compression characteristics that enable it to extract pitch from stimuli that have traditionally been challenging to pitch determination algorithms .", "label": "", "metadata": {}, "score": "56.326157"}
{"text": "( II ) when compared with the ETSI advanced front - end [ 7 ] .The other results in Tables 1 to 4 show that enhancement of the speech prior to feature extraction significantly improves the overall recognition performance .This improvement in recognition accuracy is observed for both the ETSI basic [ 6 ] and advanced [ 7 ] front - ends and the front - end proposed by Li et al .", "label": "", "metadata": {}, "score": "56.425583"}
{"text": "( For example , neither model was presented in the two very influential and massive Neurocomputing volumes that were published by MIT Press during the field 's inception in the late 1980s . )It is possible that auditory scientists of the time could have considered the medial superior olivary nucleus as a possible ( correct ) candidate , since Lorente de No had carried out his pioneering neuroanatomical study of the auditory brainstem by the early 1930s .", "label": "", "metadata": {}, "score": "56.452644"}
{"text": "However , the auditory model that we describe above may not always be optimal , and there is potential for improved performance by better characterising the optimal parameters for specific tasks .The processing performed to generate SAIs involves multiple nonlinear components , and this could be one reason why the features generated from SAIs are more discriminative than standard MFCC features .", "label": "", "metadata": {}, "score": "56.474777"}
{"text": "Voices can also be personalized : in EMIME project Kurimo et al .( 2010 ) used the voice of the speaker in the input language to utter the translated sentences in the output language ( see following \" Speech - to - Speech Translation \" ) .", "label": "", "metadata": {}, "score": "56.4824"}
{"text": "The presence of a fundamental harmonic .A structural pattern which repeats from period to period .The second pair of features is derived from the linear model of speech production , which is the production mechanism for pulse - resonance communication sounds described in chapter 1 .", "label": "", "metadata": {}, "score": "56.485233"}
{"text": "This increased variability appears to be due in part to a feature of the strobed temporal integration process chosen to generate the images .In the version of strobed temporal integration used , SAIs are generated taking into account all strobe points which occurred before the snapshot of the auditory image is taken .", "label": "", "metadata": {}, "score": "56.5119"}
{"text": "Cooke , M.P. ( 1993 ) .Modelling auditory processing and organization .( Cambridge University Press ) .[ 1 ] .Crammer , K. , Dekel , O. , Keshet , J. , Shalev - Shwartz , S. and Singer , Y. ( 2006 ) . \"", "label": "", "metadata": {}, "score": "56.529705"}
{"text": "Analysis is carried out in the frequency domain and the signal spectrum is estimated using an FFT .Westerlund et al .[ 22 ] present a speech enhancement technique in which the input signal is first divided into a number of sub - bands .", "label": "", "metadata": {}, "score": "56.634514"}
{"text": "However , in a centralised ASR system the recognition accuracy can be compromised as a result of the speech signal being distorted by low bit - rate encoding at the codec and a poor quality transmission channel [ 2 , 3 ] .", "label": "", "metadata": {}, "score": "56.711906"}
{"text": "A block interleaver of degree d changes the order of transmission of a d x d block of input vectors .Figure 4 .Tests and results .The primary purpose of this section is to investigate the performance of the auditory model proposed by Li et al .", "label": "", "metadata": {}, "score": "56.780136"}
{"text": "The major differences between the strobing schemes are in the form of the threshold that is used .These various criteria are presented in the documentation for AIM1992 and AIM - MAT , and I present the basics of each system below .", "label": "", "metadata": {}, "score": "56.837013"}
{"text": "Text analysis ( tagging and parsing ) by a Natural Language Understanding unit .Semantic analysis by the dialog manager , along with a task manager that has knowledge of the specific task domain .When the input is malformed or inaccurate , the manager has to decide if it is necessary to request a more specific user input or if it is possible to extract the missing accuracy from knowledge resources ( Will , 2010 ) .", "label": "", "metadata": {}, "score": "56.849335"}
{"text": "The hypotheses chosen for translation are based on the ASR system 's acoustic and language model scores , and typically optimized for word error rate , ignoring the intended downstream use : automatic translation .In this paper , we present a coarse - to - fine model that uses features from the ASR and SMT systems to optimize this coupling .", "label": "", "metadata": {}, "score": "56.864784"}
{"text": "The hypotheses chosen for translation are based on the ASR system 's acoustic and language model scores , and typically optimized for word error rate , ignoring the intended downstream use : automatic translation .In this paper , we present a coarse - to - fine model that uses features from the ASR and SMT systems to optimize this coupling .", "label": "", "metadata": {}, "score": "56.864784"}
{"text": "Discrimination of speaker size from syllable phrases .\" J. Acoust .Soc .Am . , 118 , p.3816 - 3822 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] .Ives , D.T. and Patterson , R.D. ( 2008 ) .", "label": "", "metadata": {}, "score": "56.88179"}
{"text": "The three systems assessed are the ' local maximum ' criterion and the new ' constrained threshold ' and ' back - projection ' systems .The results in this section are not directly comparable to the results for single - source stimuli , but these results do allow for basic comparison between algorithms .", "label": "", "metadata": {}, "score": "56.990227"}
{"text": "Pages :2- .[ 1 ] .Bergstra , J. , Casagrande , N. , Erhan , D. , Eck , D. and K\u00e9gl , B. ( 2006 ) .\" Aggregate features and ADABOOST for music classification . \"Machine Learning , 65 , p.473 - 484 .", "label": "", "metadata": {}, "score": "57.09278"}
{"text": "The processing performed in AIM is based on a process known as strobed temporal integration .The key to this process is to locate ' strobe ' points in the signal coming from each frequency band in the output of a cochlear model .", "label": "", "metadata": {}, "score": "57.109142"}
{"text": "4 is a block diagram of the presently preferred word recognizer system ; .FIG .5 is a block diagram illustrating the target congruence word prototype training procedure ; .FIG .6 is a bar graph comparing recognition results for clean test speech for the two hypothesizer stages ( RC , TC ) and the fine match stage ( MSM ) , the word hypothesizer ( RC+TC ) and the recognition system as a whole ( RC+TC+MSM ) .", "label": "", "metadata": {}, "score": "57.129745"}
{"text": "Speech recognition is a computationally demanding task , particularly the stage which uses Viterbi decoding for converting pre - processed speech data into words or sub - word units .We present an FPGA implementations of the decoder based on continuous hidden Markov models ( HMMs ) representing monophones , ... \" .", "label": "", "metadata": {}, "score": "57.199226"}
{"text": "The workflow of the HCI using the specific platform is the following : .User speaks and/or makes a co - speech gesture , and speech and gestures are converted into text ; .Language identification and MT technology to translate the existing grammar in the language of the user ; .", "label": "", "metadata": {}, "score": "57.21413"}
{"text": "4 , an overview of the presently preferred system will be presented .The first component of the present system is a phoneme similarity front end 10 that converts speech signals into phoneme similarity time series .Speech is digitized at 8 kilohertz and processed by 8th order linear predictive coding ( LPC ) analysis to produce 8 cepstral coefficients every 100th of a second .", "label": "", "metadata": {}, "score": "57.24112"}
{"text": "44 Nickel and Stiefelhagen ( 2006 ) recognized with their real - time vision system pointing gestures in human - robot interaction by visual tracking of head , hands , and head orientation .Based on hands ' motion , they decomposed a pointing gesture into three distinct phases and modeled each phase with a dedicated HMM .", "label": "", "metadata": {}, "score": "57.258606"}
{"text": "In order to reduce the number of dimensions , a principal component analysis was performed .A set of diagonal Gaussian models is used to model the transitions .The models were tested by applying them to the N - Best sentence hypotheses from the recognition system .", "label": "", "metadata": {}, "score": "57.312893"}
{"text": "Output rendering using an output renderer , which may include TTS engine .31 As far as the quality of dialog systems is concerned , Will ( 2010 : 60 ) states that the main cause of failure in speech dialogs is the difficulty of recognizing context - sensitive information in full sentence utterances .", "label": "", "metadata": {}, "score": "57.317997"}
{"text": "\" Distance measures for speech recognition , psychological and instrumental . \"Pattern Recognition and Artificial Intelligence , , p.374 - 388 .[ 1 ] .Mertins , A. and Rademacher , J. ( 2005 ) .\" Vocal tract length invariant features for automatic speech recognition . \"", "label": "", "metadata": {}, "score": "57.387962"}
{"text": "The stages involved in feature extraction based on MFCCs are shown in Figure 1 .The speech signal first undergoes pre - emphasis in order to compensate for the unequal sensitivity of human hearing across frequency .Following pre - emphasis , a short - term power spectrum is obtained by applying a fast Fourier transform ( FFT ) to a frame of Hamming windowed speech .", "label": "", "metadata": {}, "score": "57.423775"}
{"text": "14 ] .For the task of connected digit recognition using the Aurora 2 database , the front - end proposed by Li et al .gave the best overall recognition results of all the auditory models examined , and with an overall reduction in recognition error compared to the ETSI basic front - end [ 6 ] which was used as a baseline for comparison .", "label": "", "metadata": {}, "score": "57.60614"}
{"text": "We demonstrate the importance of making the training conditions as close as possible to testing conditions .The best approach yields a 1.3 percent improvement in first pass accuracy , which translates to 0.5 percent improvement after other rescoring passes . by Eric K. Ringger , James F. Allen - In Proceedings of the Fourth International Conference on Spoken Language Processing ( ICSLP-96 , 1996 . \" ...", "label": "", "metadata": {}, "score": "57.63675"}
{"text": "Firstly , the MFCCs were computed using HCopy , which has been progressively optimised over years of use ; AIM - C , by contrast , is relatively fast as auditory models go , but it has not yet been optimised for speech recognition .", "label": "", "metadata": {}, "score": "57.664146"}
{"text": "\" J. Acoust .Soc .Am . , 122 , p.3628 - 3639 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] .Smith , D.R.R. and Patterson , R.D. ( 2005 ) .\" The interaction of glottal - pulse rate and vocal - tract length in judgements of speaker size , sex , and age .", "label": "", "metadata": {}, "score": "57.678963"}
{"text": "These two steps are repeated until the Gaussians provide a good enough fit to the data .In order to ensure a good fit , it was necessary to constrain the standard EM algorithm in a number of ways , based on prior knowledge of the form of a vowel spectrum , and some heuristics .", "label": "", "metadata": {}, "score": "57.735195"}
{"text": "The method of claim 22 wherein said parameters include a representation of the phone similarity peak location , peak height and the left and right frame locations .The method of claim 16 further comprising the step of : . representing an instance of a given spoken word or phrase by the number of high phoneme similarity regions found for each of a plurality of phoneme identifiers .", "label": "", "metadata": {}, "score": "57.76765"}
{"text": "However , the evaluation here is looking primarily at the effect of speech enhancement or noise reduction alone on the connected digit recognition accuracy .Therefore , the waveform processing block in the ETSI advanced front - end was disabled .In addition , the ETSI advanced front - end carries out post - processing in the cepstral domain in the form of blind equalisation as described in [ 13 ] .", "label": "", "metadata": {}, "score": "57.873363"}
{"text": "5 In this chapter we present definitions , the history , and state - of - the - art tools 1 of speech recognition and synthesis , and Machine Translation ( MT ) ; speech - to - speech translation , dialog systems , and gesture recognition and localization will also be discussed .", "label": "", "metadata": {}, "score": "57.875168"}
{"text": "Note the high top 10 % accuracy for the RC stage is graphically depicted in FIG .6 .The region count prototype is constructed as follows .A first utterance of a training word or phrase is represented as time - dependent phoneme similarity data .", "label": "", "metadata": {}, "score": "57.87635"}
{"text": "Many techniques have been incorporated into various components of spoken dialogue systems to try to provide robustness in the presence of speech recognition errors .This paper describes a study that explores how humans go about signaling communication problems caused by speech recognition errors .", "label": "", "metadata": {}, "score": "57.936974"}
{"text": "Experiments on pitch perception indicate that the fine structure retained by phase - locking is required to predict the pitch shift of the residue ( Yost et al ., 1998 ) .Other rectification algorithms like squaring , full - wave rectification and the Hilbert transform only preserve the envelope .", "label": "", "metadata": {}, "score": "57.950726"}
{"text": "Springer , New York .[ Contains many chapters on contemporary theory of spatial hearing . ]Publications .Results for \" paul smolensky \" : .Irvine , Ann ; Dredze , Mark ; Legendre , Geraldine ; Smolensky , Paul ( 2011 ) : Optimality Theory Syntax Learnability : An Empirical Exploration of the Perceptron and GLA .", "label": "", "metadata": {}, "score": "58.04182"}
{"text": "Strobe detection for strobed temporal integration .The scale - shift invariant feature representation used in the experiments in chapter 2 was based on the output of an auditory filterbank .However , no further processing based on functional models of the auditory system was performed on the filterbank output .", "label": "", "metadata": {}, "score": "58.09656"}
{"text": "187 - 196 .Conventional speech recognition systems match each input utterance to reference templates , such as templates composed on phoneme similarity vectors , as in the model speech method ( MSM ) of Hoshimi et al .In these conventional systems the reference speech representation is frame - based and requires a high data rate , typically 8 to 12 parameters every 10 to 20 milliseconds .", "label": "", "metadata": {}, "score": "58.119797"}
{"text": "Sound Source Localization .Springer , New York .Zhou Y , Carney L H , Colburn H S , 2005 \" A model for interaural time difference sensitivity in the medial superior olive : Interaction of excitatory and inhibitory synaptic inputs , channel dynamics , and cellular morphology , \" J. Neurosci .", "label": "", "metadata": {}, "score": "58.13198"}
{"text": "The method of claim 16 further comprising performing a fine match upon said second list of word candidates to select a single recognized word from said second list .The method of claim 16 wherein said region count procedure produces a first score corresponding to the degree of fit between the input utterance and each of the first list of word candidates .", "label": "", "metadata": {}, "score": "58.133698"}
{"text": "Gesture will be defined , gesture recognition software will be furnished , and culture - specific gestures and their localization will be discussed .4 Then we present related work about how speech and gestures are supported in assisted living environments .", "label": "", "metadata": {}, "score": "58.18102"}
{"text": "Sachs , M.B. and Kiang , N.Y.S. ( 1968 ) .\" Two - tone inhibition in auditory nerve fibers .\" J. Acoust .Soc .Am . , 43 , p.1120 - 1128 .[ 1 ] .Schofield , D. ( 1985 ) .", "label": "", "metadata": {}, "score": "58.19585"}
{"text": "[ 1 ] .Irino , T. , Walters , T.C. and Patterson , R.D. ( 2007 ) .\"A computational auditory model with a nonlinear cochlea and acoustic scale normalization \" , in Proceedings of the 19th International Congress on Acoustics , p.07 - 003 .", "label": "", "metadata": {}, "score": "58.242764"}
{"text": "In the remainder of this section , the detection of periodicity in various stimuli is used to compare the temporal dynamics of the dcGC and the PZFC filterbanks .It seems that dynamic , compressive filterbanks produce better features for modelling pitch strength within time - domain models such as AIM .", "label": "", "metadata": {}, "score": "58.268375"}
{"text": "Recently , it has been argued that these characteristics of musical identity ( or timbre ) can be best captured through an analysis that encompasses both time and frequency domains ; with a focus on the modulations or changes in the signal in the spectrotemporal space .", "label": "", "metadata": {}, "score": "58.288944"}
{"text": "Recently , it has been argued that these characteristics of musical identity ( or timbre ) can be best captured through an analysis that encompasses both time and frequency domains ; with a focus on the modulations or changes in the signal in the spectrotemporal space .", "label": "", "metadata": {}, "score": "58.288944"}
{"text": "In this process , low peaks and local peaks of phoneme similarity values are discarded , as illustrated in FIG .3 .In the preferred embodiment regions are characterized by 4 parameters : phoneme symbol , height at the peak location and time locations of the left and right frames .", "label": "", "metadata": {}, "score": "58.337906"}
{"text": "A simple strobe criterion like the temporal shadow method will end up strobing on every peak of the rising envelope , producing a highly symmetrical SAI for a very asymmetrical stimulus .Therefore , various modifications to the strobing system were suggested to deal with this class of stimulus .", "label": "", "metadata": {}, "score": "58.368572"}
{"text": "The next stage of the model is the identification of significant or ' strobe ' points in the NAP .Perceptual research on pitch and timbre indicates that at least some of the fine - grain time - interval information in the NAP survives to later stages of the auditory pathway ( Krumbholz et al . , 2003 ; Patterson , 1994a ; Patterson , 1994b ; Yost et al .", "label": "", "metadata": {}, "score": "58.37277"}
{"text": "The spatial shifter circuits proposed by Pitts and McCulloch in 1947 ( \" How we know universals : the perception of auditory and visual forms \" Bull .Math .Biophys .9 127 - 147 ) for musical transposition and visual magnification invariance have not passed the test of time .", "label": "", "metadata": {}, "score": "58.38084"}
{"text": "The system performs four recognition passes : ( 1 ) bigram recognition with phone - loop - adapted , within - word triphone acoustic models , ( 2 ) lattice generation with transcription - m ... \" .We describe SRI 's large vocabulary conversational speech recognition system as used in the March 2000 NIST Hub-5E evaluation .", "label": "", "metadata": {}, "score": "58.418343"}
{"text": "[ 1 ] [ 2 ] [ 3 ] .Zolfaghari , P. , Kato , H. , Minami , Y. , Nakamura , A. , Katagiri , S. and Patterson , R. ( 2006 ) . \"Dynamic Assignment of Gaussian Components in Modelling Speech Spectra .", "label": "", "metadata": {}, "score": "58.423042"}
{"text": "By using an explicit time - domain articulatory model of the mechanisms of co - articulation , it is hoped to obtain a more accurate model of contextual effects in the acoustic signal , while using fewer parameters than traditional acoustically - driven approaches .", "label": "", "metadata": {}, "score": "58.428326"}
{"text": "The model describes a general strategy for cortical plasticity via an optimization that maximizes discriminability between the foreground and distractors while maintaining a degree of stability in the cortical representation .The first instantiation of the model describes a form of feature - based attention and yields STRF adaptation patterns consistent with a contrast matched filter previously reported in neurophysiological studies .", "label": "", "metadata": {}, "score": "58.450798"}
{"text": "The model describes a general strategy for cortical plasticity via an optimization that maximizes discriminability between the foreground and distractors while maintaining a degree of stability in the cortical representation .The first instantiation of the model describes a form of feature - based attention and yields STRF adaptation patterns consistent with a contrast matched filter previously reported in neurophysiological studies .", "label": "", "metadata": {}, "score": "58.450798"}
{"text": "17 , pp .82 - 90 , Jan. 1999 .2 - D. Pearce , \" Enabling new speech driven services for mobile devices : an overview of the ETSI standards activities for distributed speech recognition front - ends \" , in Proc .", "label": "", "metadata": {}, "score": "58.453278"}
{"text": "Patterson , R.D. and Moore , B.C.J. ( 1986 ) .\"Auditory filters and excitation patterns as representations of frequency resolution \" , in Frequency Selectivity in Hearing , Moore , B.C. editor ( Academic Press , London ) .[ 1 ] .", "label": "", "metadata": {}, "score": "58.46672"}
{"text": "However , the pattern of the reduction in performance is markedly different between the two feature types .Overall recognition performance with the MFCC feature vectors was 70.9 % correct .Performance holds up well along the spokes where VTL does not vary much from that of the reference speaker .", "label": "", "metadata": {}, "score": "58.481804"}
{"text": "Like the evaluation of strobing systems , this analysis of the compressive properties of auditory filterbanks was necessarily confined to a more limited problem than evaluation of a full machine hearing system .Nevertheless , the results suggest that compression is required in auditory filterbanks if they are to explain human pitch perception accurately .", "label": "", "metadata": {}, "score": "58.489193"}
{"text": "( See Casseday and Covey ( 1987 ) for an overview of the neuroanatomy . )Although the rough outlines of major ascending auditory pathways and the existence of phase - locked responses in the auditory nerve were known in 1948 , the circuitry in the auditory brainstem that might support binaural crosscorrelation had not been worked out .", "label": "", "metadata": {}, "score": "58.498566"}
{"text": "The method of claim 27 further comprising the step of computing the recognition score for a given instance of a spoken word or phrase with respect to a given region count prototype .The method of claim 29 wherein said recognition score is a weighted Euclidean distance .", "label": "", "metadata": {}, "score": "58.555607"}
{"text": "The presently preferred word recognizer may be implemented according to the techniques described in \" A Study of English Model Speech Method , \" by Y. Ohno et al . , Proc .Acoustical Society of Japan , Spring 1995 ( in Japanese ) .", "label": "", "metadata": {}, "score": "58.604305"}
{"text": "A reanalysis of the classic formant data of Peterson and Barney ( 1952 ) by Turner , Walters , Monaghan and Patterson ( 2009 ) showed that the relative formant pattern that defines a particular vowel remains approximately unchanged as children grow into adults .", "label": "", "metadata": {}, "score": "58.641712"}
{"text": "Once the word prototype has been obtained in this fashion , the average match rate and average word duration are computed and stored as part of the word prototype data .The number of parameters needed to represent a word depends on the average duration of the word and on the level of phonetic detail that is desired .", "label": "", "metadata": {}, "score": "58.675884"}
{"text": "The steps of this process start with processing the voice signal using the Fast Fourier Transform ( FFT ) , the Hanning window , and a histogram representation to make it suitable for the next part .The identification part is based on a neural network where the identification can be done in one or two classification parts .", "label": "", "metadata": {}, "score": "58.691124"}
{"text": "Given these observations , a Gaussian mixture model ( GMM ) was used to summarise the information in the spectral profile of the auditory image .The spectral profile is modelled as a probability distribution , and fitted with a set of Gaussians of fixed variances .", "label": "", "metadata": {}, "score": "58.70354"}
{"text": "If a process akin to strobed temporal integration is performed on the auditory signals in the brain , then strobe detection must occur with only a small delay of the order of a few milliseconds , as strobe points must be identified and acted upon without any temporal integration .", "label": "", "metadata": {}, "score": "58.773808"}
{"text": "The estimated area A r is computed as the area under the similarity curve for the target 's phoneme label , between the projected locations of the target 's left and right frames .The word congruence score is computed as the weighted sum of congruence scores for all the targets , divided by the sum of their weights .", "label": "", "metadata": {}, "score": "58.799217"}
{"text": "\" The interaction of vocal tract length and glottal pulse rate in the recognition of concurrent syllables .\" J. Acoust .Soc .Am . , 125 , p.1114 - 1124 .[ 1 ] .von B\u00e9k\u00e9sy , G. ( 1960 ) .", "label": "", "metadata": {}, "score": "58.800117"}
{"text": "Soc .Am . , 107 , p.1578 - 1588 .[ 1 ] .Patterson , R.D. and Irino , T. ( 1998 ) .\" Modeling temporal asymmetry in the auditory system .\" J. Acoust .Soc .Am . , 104 , p.2967 - 2979 .", "label": "", "metadata": {}, "score": "58.834633"}
{"text": "It also seems that its properties could be matched to those of the more computationally - costly dcGC filterbank .The efficiency and dynamic level compression used in the PZFC make it a good candidate for use in machine hearing systems , and indeed it is the filterbank used in the complete system presented in chapter 6 .", "label": "", "metadata": {}, "score": "58.836983"}
{"text": "\"Auditory filter shapes at low center frequencies .\" J. Acoust .Soc .Am . , 88 , p.132 - 140 .[ 1 ] .Olshausen , B.A. and Field , D.J. ( 2004 ) .\" Sparse coding of sensory inputs . \"", "label": "", "metadata": {}, "score": "58.850815"}
{"text": "There is a rich literature on the subject of pitch detection in time - domain signals and Hess ( 1983 ) provides an excellent overview of the state of the field at that time .Hess identifies four significant features from which periodicity in a signal can be derived in the time domain .", "label": "", "metadata": {}, "score": "58.904972"}
{"text": "The machine learning system used is called PAMIR -- the ' passive - aggressive model for image retrieval ' ( Grangier and Bengio , 2008 ) .As its name suggests , it was first designed for content - based image search problems , but is equally well suited to the problem of audio search .", "label": "", "metadata": {}, "score": "59.003944"}
{"text": "2011 ) .34 McNeil 's ( 1992 ) categorization of gestures is the following : .Iconics : they bear a close formal relationship to the semantic content of speech .Metaphorics : they are pictorial like iconics but the pictorial content presents an abstract idea rather than a concrete object or event .", "label": "", "metadata": {}, "score": "59.082565"}
{"text": "These gestures usually make the navigational intention of the user more perspicuous .Breslow et al .( 2010 ) distinguish spatial gestures into gestures used for thinking ( cognitive gestures ) and gestures used to help express predetermined ideas ( linguistic gestures ) .", "label": "", "metadata": {}, "score": "59.090477"}
{"text": "That is , when a formant occurs near the edge of the spectrum , the tail of the Gaussian used to fit the formant prevents it from shifting sufficiently to centre the Gaussian on the formant .If this proves to be the reason , it suggests that performance is not limited by the underlying auditory representation but rather by a limitation in the feature extraction process .", "label": "", "metadata": {}, "score": "59.10866"}
{"text": "The performance of Li et al .( II ) was compared with the performance of the ETSI advanced front - end .The ETSI advanced front - end includes a SNR - dependent waveform processing block that is applied after noise reduction and before feature extraction .", "label": "", "metadata": {}, "score": "59.117546"}
{"text": "We provide definitions , history , and a survey on proprietary as well as free / open - source software ( FOSS ) .We cover initiatives and tools both from Academia and Industry .We also refer to speech - to - speech translation systems which combine speech recognition , machine translation , and text - to - speech .", "label": "", "metadata": {}, "score": "59.134193"}
{"text": "Furthermore , the asymmetry functions can be implemented as IIR filters , allowing for an efficient implementation of the filterbank ( Unoki et al . , 2001 ) .The dynamic compressive gammachirp filterbank ( dcGC ) of Irino and Patterson ( 2006 ) is a direct descendant of the cGC filter , which models the compressive nonlinearities in the human auditory system .", "label": "", "metadata": {}, "score": "59.135944"}
{"text": "\" Computer speech and language , 8 , p.297 - 336 .[ 1 ] .Carney , L.H. , McDuffy , M.J. and Shekhter , I. ( 1999 ) . \"Frequency glides in the impulse responses of auditory - nerve fibers .", "label": "", "metadata": {}, "score": "59.15168"}
{"text": "The success of the recognition system with VTL - invariant features appears to depend almost entirely on the features themselves , rather than the recognition system used to compare the two forms of features .Changing the parameters of the HMM recognition system has only a minor effect on performance compared with changing the features themselves .", "label": "", "metadata": {}, "score": "59.21255"}
{"text": "Performance ranking of enhancement algorithms .Discussion .Ignoring speech enhancement , and comparing Tables 1 and 2 , the performance of Li et al .( I ) exceeds the baseline ETSI front - end [ 6 ] by 2.08 % overall .", "label": "", "metadata": {}, "score": "59.21546"}
{"text": "Jeffress was then left with situating his coincidence detectors either in the auditory midbrain ( inferior colliculus ) or thalamus ( medial geniculate body ) see note 2 .It should be noted that Jeffress later ( 1958 ) rejected these more central nuclei in favor of the MSO .", "label": "", "metadata": {}, "score": "59.300644"}
{"text": "D\u00e9silets , A. , Stojanovic , M. , Lapointe , J.F. et al .( 2008 ) \" Evaluating Productivity Gains of Hybrid ASR - MT Sytems for Translation Dictation \" in IWSLT Workshop , Hawaii , pp .158 - 165 .", "label": "", "metadata": {}, "score": "59.31522"}
{"text": "Figure 1 is a block diagram showing the overall structure of the auditory image model when used as a preprocessor for machine hearing applications .This thesis concerns itself with all sections of the model , from the input audio to the machine learning system .", "label": "", "metadata": {}, "score": "59.339485"}
{"text": "The word hypothesizer produced large reductions of computational complexity .On a 100 word task , alignment complexity was reduced by 93 % , with significant error rate reduction for clean and noisy test conditions .The human auditory system is a remarkable signal processing device , which is optimised for the analysis of communication sounds in challenging acoustic environments .", "label": "", "metadata": {}, "score": "59.380287"}
{"text": "Taken together , these two pieces of evidence suggest that speakers may actively vary the position of their tongue in the oral cavity to maintain a fixed formant ratio , regardless of anatomical differences .van Dinther and Patterson ( 2006 ) performed a similar study to those described above , but used musical instrument sounds as the input pulse - resonance signals for size discrimination .", "label": "", "metadata": {}, "score": "59.43601"}
{"text": "Trends Neurosci 26 , 347 - 350 .Pitts W , McCulloch W S , 1947 \" How we know universals : the perception of auditory and visual forms \" Bull .Math .Biophys .Reichardt W , 1961 \" Autocorrelation , a principle for the evaluation of sensory information by the central nervous system \" , in Sensory Communication Ed W A Rosenblith ( New York : New York ) pp 303 - 317 .", "label": "", "metadata": {}, "score": "59.456303"}
{"text": "14 ] in combination with speech enhancement in the presence of noise and packet loss .As a baseline for comparison , results are also presented for the ETSI advanced front - end [ 7 ] .In all cases , training was carried out using clean data .", "label": "", "metadata": {}, "score": "59.488625"}
{"text": "Soc .Am . , 123 , p.3066 .[ 1 ] [ 2 ] .Moore , B.C.J. ( 2003 ) .An Introduction to the Psychology of Hearing .( Academic Press ) .[ 1 ] [ 2 ] [ 3 ] [ 4 ] .", "label": "", "metadata": {}, "score": "59.533012"}
{"text": "Auditory images were generated from IRN stimuli with 0 , 1 , 2 and 4 iterations , as described above .The IRN stimuli ( specifically IRNo , see Yost et al .( 1996 ) ) were generated using the ' gen\\_IRNo ' function in AIM - MAT , and were used to assess the effect of overall pitch saliency on the pitch strength measures extracted from the SAI .", "label": "", "metadata": {}, "score": "59.541656"}
{"text": "In this chapter , a full - scale machine - hearing system was developed and deployed for a real content - based audio analysis task .The goal of the study in this chapter was to demonstrate the potential utility of machine hearing systems for audio analysis , and to present a complete example system .", "label": "", "metadata": {}, "score": "59.594498"}
{"text": "\" Auditory neuroscience : a time for coincidence ? \" Current Biology 14 , R886-R888 .Cariani P , 2001 \" Neural timing nets \" Neural Networks 14 , 737 - 753 .Carr C E , 1993 \" Processing of temporal information in the brain \" Annu . Rev. Neurosci .", "label": "", "metadata": {}, "score": "59.613304"}
{"text": "The baseline recognition results for the two front - ends , without vector quantisation and with no packet loss but with noise , are detailed in Table 7 .The word accuracies in the following tables are calculated as described in Section 2.4 .", "label": "", "metadata": {}, "score": "59.68632"}
{"text": "Reichardt detectors compute temporal crosscorrelations between spikes produced when a visual image is successively presented to two visual receptor elements ( ommatidia ) at two different times ( i.e. a moving image ) ( Reichardt 1961 ) .An array of Reichardt motion detectors arranged to detect many different temporal delays across nearby retinal elements is therefore analogous ( albeit with more dimensions ) to a Jeffress coincidence architecture that detects delays across the two ears .", "label": "", "metadata": {}, "score": "59.73259"}
{"text": "Descriptions of the response of the auditory filter in the frequency domain , based on the results of tone - in - noise masking experiments , came to be known as the ' power - spectrum model of masking ' Moore ( 1995 ) .", "label": "", "metadata": {}, "score": "59.77117"}
{"text": "A procedure to perform VTLN on MFCCs ( Welling et al . , 2002 ) was evaluated using the scaled - syllable database of Ives and Patterson ( 2008 ) .Since the original scaling factors are known it is possible to perform ' optimal ' VTL warping when generating MFCC features for use with the recognizer , and so determine the best performance attainable with a VTLN system .", "label": "", "metadata": {}, "score": "59.79249"}
{"text": "Following initial testing with no packet loss compensation , a number of existing packet loss mitigation techniques were investigated , namely nearest neighbour repetition and interpolation .Results show that the best recognition performance was obtained using nearest neighbour repetition to reconstruct missing features .", "label": "", "metadata": {}, "score": "59.800377"}
{"text": "AIM is an existing computational model of human auditory processing .It simulates the processing which goes on in the early stages of the human auditory pathway , and its design is informed by the physiology of the auditory system .In this thesis , aspects of AIM are developed and refined for use in machine hearing , both by the use of data on human physiology and perception , and by the application of prior knowledge of the structure of communication sounds .", "label": "", "metadata": {}, "score": "59.81848"}
{"text": "The advantage of this is that there is no impact on the computational complexity of the feature extraction or the recognition processes as the enhancement is independent of both , and the speech enhancement can be implemented as an add - on without significantly affecting existing parts of the system .", "label": "", "metadata": {}, "score": "59.84456"}
{"text": "The SAI was introduced in chapter 1 , and the process by which strobe points can be detected was discussed at length in chapter 3 .In this chapter , features generated from SAI - based representations are developed and tested .", "label": "", "metadata": {}, "score": "59.96442"}
{"text": "Speech Commun . , 49 , p.763 - 786 .[ 1 ] .Bergeaud , F. and Mallat , S.G. ( 1995 ) .\" Processing images and sounds with matching pursuits . \"Booktitle : Proceedings of SPIE .Volume : 2569 .", "label": "", "metadata": {}, "score": "59.99034"}
{"text": "[ 1 ] [ 2 ] .Mallat , S.G. and Zhang , Z. ( 1993 ) .\" Matching pursuits with time - frequency dictionaries . \"IEEE Transactions on Signal Processing , 41 , p.3397 - 3415 .[ 1 ] .", "label": "", "metadata": {}, "score": "60.008858"}
{"text": "In the next chapter , the features developed in chapter 2 are computed from the stabilized auditory image , rather than from the cochleogram .We hypothesise that the stabilized features produced with strobed temporal integration will be more noise - robust than those generated from the NAP .", "label": "", "metadata": {}, "score": "60.03205"}
{"text": "\" Comparison of relative and absolute judgments of speaker size based on vowel sounds .\" Proceedings of Meetings on Acoustics , 1 , p.1 - 9 .[ 1 ] [ 2 ] .Welling , L. , Ney , H. and Kanthak , S. ( 2002 ) .", "label": "", "metadata": {}, "score": "60.10126"}
{"text": "Am . , 98 , p.1858 - 1865 .[ 1 ] .Rosen , S. and Baker , R.J. ( 1994 ) .\"Characterising auditory filter nonlinearity . \"Hear .Res ., 73 , p.231 - 243 .", "label": "", "metadata": {}, "score": "60.15535"}
{"text": "Such features would correspond to a subset of the Mellin image ( Irino and Patterson , 2002 ) .These more general features could be assessed by trying them in a range of tasks where MFCCs are normally used .This multi - scale approach to the problem of feature extraction is a crude but effective way of analysing different parts of the SAI in an independent manner , and removes the dependence of the current systems on the expensive fitting of spectral profiles with a constrained GMM .", "label": "", "metadata": {}, "score": "60.18289"}
{"text": "Anastasiou , D. , Sch\u00e4ler , R. ( 2009 ) , \" Translating Vital Information : Localisation , Internationalisation , and Globalisation \" , in Journal Syn - th\u00e8ses .Becker , E. , Le , Z. , Park , K. , Lin , Y. , Makedon , F. ( 2009 ) , \" Event - based experiments in an assistive environment using wireless sensor networks and voice recognition \" in Proceedings of the PETRA ' 09 .", "label": "", "metadata": {}, "score": "60.200356"}
{"text": "The front - end of Li et al . performs marginally better overall than the ETSI advanced front - end for channels A , B and C ; however , for channel D , the overall recognition performance of the ETSI advanced front - end is better than that of Li et al .", "label": "", "metadata": {}, "score": "60.25448"}
{"text": "Patterson et al .( 2003 ) extended the technique to allow fitting to data from multiple probe frequencies simultaneously .The updated procedure makes the assumption that the variation of any of the filter parameters with probe frequency can be represented as a linear function of the frequency in ERBs .", "label": "", "metadata": {}, "score": "60.265"}
{"text": "The overall word accuracies in Table 9 , with vector quantization , compare well with the baseline accuracies , without vector quantization , in Table 7 .Table 8 .Table 9 .Recognition results with VQ codebooks designed using implementation of the GLA .", "label": "", "metadata": {}, "score": "60.292976"}
{"text": "The 800Hz filter condition was designed to exclude the resolved harmonics from the stimulus .The pitch strength measure described above was used to model the data of Patterson et al .( 1996 ) , using the techniques described in that study .", "label": "", "metadata": {}, "score": "60.301933"}
{"text": "In practice , for the fairly simple task of scaled syllable recognition , it was found that four components of this set , the weights of the three Gaussians , and the total energy were enough to provide good recognition results .", "label": "", "metadata": {}, "score": "60.30381"}
{"text": "This simple idea has been proposed and implemented many times ; indeed Hess cites over 20 references to proposals for analogue versions of this scheme dating from 1949 to 1977 .In this section , I review some of the basic properties of the auditory filterbank and human vocalisations to help derive the correct constraints for a strobing scheme that is in some sense optimal for a given filterbank and expected class of signals .", "label": "", "metadata": {}, "score": "60.428825"}
{"text": "It supports a broad spectrum of research into segmental features and detection - based speech recognition , and it is intended to support core academic research in this area .Sensory - Offers speech technologies on both hardware and software platforms for improving user interfaces in consumer electronics .", "label": "", "metadata": {}, "score": "60.478912"}
{"text": "While it is interesting to see that making the AGC of the PZFC react faster has a positive effect in increasing its ability to resolve pitches , it is not immediately clear why this should be the case .Since the effect of fast - acting compression should be to compress glottal - pulses in the input stimulus , one might expect the pitch strength to go down as the speed of the compression was increased .", "label": "", "metadata": {}, "score": "60.56835"}
{"text": "Automatic Speech Understanding ( ASU ) produces some sort of understanding of sentences , rather than just words .Some application areas of ASR , which appeal to those who need or want hands - free approach , are automated commercial phone systems , call - routing , and dictation .", "label": "", "metadata": {}, "score": "60.665398"}
{"text": "In this chapter , existing mechanisms for strobed temporal integration are assessed and compared , and the theoretical basis of this mode of temporal integration is investigated in an effort to identify a simple criterion for optimal strobe generation .The goal was to create a stabilised auditory image for a noise - robust machine hearing system .", "label": "", "metadata": {}, "score": "60.69095"}
{"text": "Thus , Licklider 's model was able to simultaneously produce both temporal and rate - place representations of pitch .In order to account for both monaural and binaural hearing , Licklider 's triplex model ( Licklider 1959 ) combined a Jeffress - like crosscorrelation stage ( sans rate integration ) followed by an autocorrelation stage to form a generalized central correlation analyzer .", "label": "", "metadata": {}, "score": "60.69728"}
{"text": "The ETSI advanced front - end includes a SNR - dependent waveform processing block that is applied after noise reduction and before feature extraction .The waveform processing block in the ETSI advanced front - end is also implemented in the front - end of Li et al .", "label": "", "metadata": {}, "score": "60.771698"}
{"text": "One hypothesised benefit of AIM is that the SAIs which it produces are more robust to interfering noise than simple spectral representations .In chapter 4 , the feature - generation system developed in this chapter is extended for use with the SAI representations developed in chapter 3 .", "label": "", "metadata": {}, "score": "60.786827"}
{"text": "Visualisations of speech based on a model of the peripheral auditory system . \"Unknown , , p .. [ 1 ] .Schreiner , C.E. and Langner , G. ( 1988 ) .\" Periodicity coding in the inferior colliculus of the cat .", "label": "", "metadata": {}, "score": "60.7875"}
{"text": "The process of strobe detection is key to generating the stabilized auditory image ( SAI ) .The SAI is a representation of audio as it might appear in the early stages of the auditory pathway .It is a two - dimensional image which is stable over time when the incoming sound is perceived as being stable .", "label": "", "metadata": {}, "score": "60.837467"}
{"text": "Ephraim and Malah [ 20 ] present a minimum mean - square error short - time spectral amplitude ( MMSE STSA ) estimator .The estimator is based on modelling speech and noise spectral components as statistically independent Gaussian random variables .", "label": "", "metadata": {}, "score": "60.838818"}
{"text": "\"Universal Spech interfaces \" in Interactions 8(6 ) .Rosti , A - V.I. , Zhang , B. , Matsoukas , S. , Schwartz , R. ( 2008 ) , \" Incremental hypothesis alignment for building confusion networks with application to machine translation system combination \" , in Proceedings of the Third Workshop on Statistical Machine Translation .", "label": "", "metadata": {}, "score": "60.842663"}
{"text": "Feature vectors are extracted from the output of this waveform processing block .A detailed description of the waveform processing block can be found in [ 26 ] .The ETSI advanced front - end carries out post - processing in the cepstral domain in the form of blind equalization as described by [ 13 ] .", "label": "", "metadata": {}, "score": "60.863403"}
{"text": "A significant amount of research has been carried out on speech enhancement , and a number of approaches have been well documented in the literature .A survey of a number of approaches to speech enhancement using a single microphone is presented in [ 5 ] .", "label": "", "metadata": {}, "score": "60.87233"}
{"text": "We also obtained an unusually large improvement from modeling crossword pronunciation variants in \" multiword \" vocabulary items .The language model ( LM ) was enhanced with an \" anti - LM \" representing acoustically confusable word sequences .Finally , we applied a generalized ROVER algorithm to combine the N - best hypotheses from several systems based on different acoustic models .", "label": "", "metadata": {}, "score": "60.91473"}
{"text": "It was built on two decades of the scientific research in speech and language processing at Mobile Technologies .Mobile Technologies and Jibbigo maintain a strong research collaboration with InterACT , the International Center for Advanced Communication Technologies at Carnegie Mellon University and Karlsruhe Institute of Technology , Germany .", "label": "", "metadata": {}, "score": "60.947052"}
{"text": "There are three different test sets defined for recognition testing , with the test utterances taken from the testing part of the TIDigits database .Test Set A ( 28028 utterances ) employs the same four noises as used for the multi - condition training .", "label": "", "metadata": {}, "score": "61.006813"}
{"text": "The method of claim 25 further comprising the step of : . building a region count prototype corresponding to a spoken word or phrase that consists of statistics based on the number of high phoneme similarity regions found for each phoneme identifier in each of a plurality of time intervals in the phoneme similarity data .", "label": "", "metadata": {}, "score": "61.02663"}
{"text": "This leads to a temporally smooth spectrogram .The harmonic structure of the spectrogram is then removed using a spline - based smoothing technique , leaving the reconstructed spectral envelope , independent of the pitch .Human perception of size .Humans are remarkably good at understanding the content of vocalisations that come from a wide range of speakers .", "label": "", "metadata": {}, "score": "61.029358"}
{"text": "PAMIR .In order to rank audio documents , we wish to learn a scoring function , S W ( q , a ) , that scores every pair of audio document , a , and query , q .The PAMIR system is based on the passive - aggressive family of learning algorithms ( Crammer et al . , 2006 ) .", "label": "", "metadata": {}, "score": "61.030308"}
{"text": "Patterson , R.D. , Unoki , M. and Irino , T. ( 2003 ) .\"Extending the domain of center frequencies for the compressive gammachirp auditory filter .\" J. Acoust .Soc .Am . , 114 , p.1529 - 1542 .", "label": "", "metadata": {}, "score": "61.042877"}
{"text": "The field of machine hearing is a relatively new one , and this thesis covers a range of interests within the field -- from the low - level operation of the auditory filterbank , to the choice of feature representation for a particular audio analysis task .", "label": "", "metadata": {}, "score": "61.043533"}
{"text": "In chapter 3 , the strobed temporal integration process is reviewed , refined and then in chapter 4 , it is put to use to improve the noise - robustness of the experimental system described in chapter 2 , demonstrating one of the benefits of the stabilised auditory image representation .", "label": "", "metadata": {}, "score": "61.10779"}
{"text": "The front - ends investigated were perceptual linear prediction ( PLP ) proposed by Hermansky [ 17 ] , the PEMO algorithm proposed by Tchorz and Kollmeier [ 18 ] , and the front - end processor proposed by Li et al .", "label": "", "metadata": {}, "score": "61.136497"}
{"text": "The TC stage provides a more selective short list of word candidates , essentially a further refinement of the list produced by the RC stage 18 .The fine match word recognition stage 26 , the final major component of the present system , is preferably a fine match word recognizer that performs frame - by - frame alignment to select the recognized word from the short list supplied by TC stage 20 .", "label": "", "metadata": {}, "score": "61.15311"}
{"text": "The target congruence hypothesizer stage is coupled to the high similarity module for generating a second list of at least one word candidate that is selected from the first list based on similarity regions .A word recognizer stage , having a word template database for storing word template data corresponding to a plurality of predetermined words , receives the second list of word candidates from the target congruence hypothesizer stage .", "label": "", "metadata": {}, "score": "61.162567"}
{"text": "\"A compressive gammachirp auditory filter for both physiological and psychophysical data .\" J. Acoust .Soc .Am . , 109 , p.2008 - 2022 .[ 1 ] .Irino , T. and Patterson , R.D. ( 2002 ) . \"", "label": "", "metadata": {}, "score": "61.231495"}
{"text": "Audio Search SDK - Compure develops software technologies to analyze audio .Products : Speak&Find to search for words or phrases ( audio mining ) ; ACTNow to detect music , jingles , advertisings , speakers ; CoolRec to capture and manage audio data .", "label": "", "metadata": {}, "score": "61.233353"}
{"text": "In the experiments below , Suied 's baseline stimulus is used to experiment with modifications to the PZFC automatic gain control ( AGC ) .For quantitative measurement of the effect of changes on the PZFC parameters , these stimuli are easier to deal with than IRN because IRN is inherently a noisy stimulus , and it would be necessary to average over stimuli to achieve measurements that can be used for comparison .", "label": "", "metadata": {}, "score": "61.238976"}
{"text": "In the previous chapters of this thesis I have developed various parts of an complete system for generating and using features from an auditory model in content - based audio analysis tasks .Having worked on these various individual sections , I was lucky enough to be able to work with a team of researchers at Google , developing an integrated machine hearing system based on auditory images .", "label": "", "metadata": {}, "score": "61.242893"}
{"text": "Strobe - point detection is , in some respects , a similar process to pitch determination of a time - domain signal ( albeit a signal which may have been passed through a nonlinear filter ) .Computational auditory models which can extract the pitch of complex sounds ( see , for example , Brown and Cooke , 1994 ) must , necessarily , integrate over a few cycles of the pitch period to get a result .", "label": "", "metadata": {}, "score": "61.256596"}
{"text": "1991 ; Lazzaro and Mead 1989 , 1990 ) .Subsequent neuroanatomy and neurophysiology has largely confirmed the basic premises of the basic model ( see ( Joris and Yin 2007 ; Joris 2006 ; Joris et al .1998 ) albeit ( arguably ) with better correspondences in birds than in mammals .", "label": "", "metadata": {}, "score": "61.31613"}
{"text": "For the SAI - based features , the PZFC filterbank is used as a first stage as it has good compressive properties and is very computationally efficient ( 1 ) .The two SAI representations ( 2 ) differ in the system used for strobed temporal integration .", "label": "", "metadata": {}, "score": "61.319427"}
{"text": "The second dimension comes from the strobed temporal integration process by which an SAI is generated .Strobed temporal integration works by locating prominent peaks , or ' strobes ' , in the incoming signal and calculating ' lags ' relative to these times .", "label": "", "metadata": {}, "score": "61.344547"}
{"text": "In chapter 6 , a complete sound analysis system is constructed and analysed .The system uses AIM in one of its variants to generate features from audio to pass to a machine learning system .The technology has not previously existed to run AIM - like models on large databases of sounds .", "label": "", "metadata": {}, "score": "61.403645"}
{"text": "Speech enhancement algorithms give a trade - off between noise reduction and signal distortion .A reduction in noise can lead to an improvement in the subjective quality of the speech but a decrease in the measured speech intelligibility [ 5 ] .", "label": "", "metadata": {}, "score": "61.412174"}
{"text": "The problem they faced in their experiments was that the longer and more continuous the speech is , the more recognition errors there are .Thus they concluded that short and distinct phrases help to improve the precision of the speech recognition .", "label": "", "metadata": {}, "score": "61.455738"}
{"text": "Fricke , E. , ( 2009 ) \" Multimodal attribution : How gestures are syntactically integrated into spoken language \" in GESPIN 2009 : Gesture and Speech in Interaction , Pozna\u0144 .Haage , Sch\u00f6tz , S. , and Nugues , P. ( 2002 ) , \" A prototype Robot Speech Interface with Multimodal Feedback \" in Proceedings of the 2002 IEEE Int .", "label": "", "metadata": {}, "score": "61.456734"}
{"text": "The form of the results for the other filterbanks is similar .The curves predicted by this model are a little noisier than those from the model of Patterson et al .( 1996 ) , but the model has the advantage of being normalised making it easier to compare results across filterbanks when their output levels differ .", "label": "", "metadata": {}, "score": "61.481068"}
{"text": "The PZFC , by contrast , has AGC time constants up to the order of hundreds of milliseconds , and so is able to affect the relative level of the output on syllable - length timescales .From this , it seems that there may be a trade - off between fast - acting compression and longer - term gain control .", "label": "", "metadata": {}, "score": "61.481102"}
{"text": "Rule - based MT ( RBMT ) approaches were the first approaches , whereas today the high availability of mono , bi- and multilingual corpora allow for statistical MT ( SMT ) and example - based MT ( Nagao , 1984 ) .", "label": "", "metadata": {}, "score": "61.54564"}
{"text": "All the audio was converted to both MFCCs and scale - shift invariant features .The MFCCs were produced using HTK 's HCopy command and the scale - shift invariant features were produced using AIM - C , employing modules for the gammatone filterbank , the NAP and the Gaussian fitting procedure .", "label": "", "metadata": {}, "score": "61.588623"}
{"text": "Instead of generating features from the NAP , AIM - C was used to generate a SAI , which was then transformed into a size - shape image ( SSI ) .To generate features for use in a recognition system , various spectral profiles of this image are computed and used as the input for the Gaussian fitting scheme described in chapter 2 .", "label": "", "metadata": {}, "score": "61.607773"}
{"text": "\" A mixture of Gaussians front end for speech recognition . \"Booktitle : Seventh European Conference on Speech Communication and Technology .Organization : Citeseer .OriginalCiteRef : stuttle2001mixture .[ 1 ] .Turner , R.E. , Walters , T.C. , Monaghan , J.J. and Patterson , R.D. ( 2009 ) .", "label": "", "metadata": {}, "score": "61.65699"}
{"text": "[14 ] is used .The choice of this auditory front - end is motivated by previous work carried out by the authors [ 15 ] where a number of auditory front - ends were investigated in a comparative study of robust speech recognition with the widely - used Aurora 2 database [ 16 ] .", "label": "", "metadata": {}, "score": "61.698814"}
{"text": "The team was working to extend the model to work with features generated from a version of the auditory image .I was invited to join the team for an internship , working with them on the evaluation of auditory features within the sound effects ranking task .", "label": "", "metadata": {}, "score": "61.703686"}
{"text": "Performance is highest immediately around the training data , and falls slightly further from the training speaker , reaching a low of 97.3 % .The syllable recognition experiments were repeated using these speakers for training , giving a wide variety of different VTL - GPR combinations to train on .", "label": "", "metadata": {}, "score": "61.725117"}
{"text": "Furthermore , Turner , Walters , Monaghan and Patterson ( 2009 ) demonstrated that formant scaling is linear , meaning that changes in VTL correspond to simple shifts of the spectrum on a logarithmic scale .Therefore , if it is possible to find a representation of the spectrum that is , to some degree , invariant to shifts in the spectral dimension , then this representation should perform better than the MFCCs when used as a feature for a size - invariant speech recognition system .", "label": "", "metadata": {}, "score": "61.752262"}
{"text": "In the time domain , the gammatone function had been used for many years to model various forms of auditory response .The function was reintroduced by Johannesma ( 1972 ) , who used it to characterise the response of the cochlear nucleus , and by de Boer ( 1975 ) to describe the cochlear impulse response measured in cats .", "label": "", "metadata": {}, "score": "61.76982"}
{"text": "Results .Tuning HMM parameters .Overall recognition performance was tested over the full range of HMM configurations described above .Recognition performance is reported as the percentage of the test syllables which were correctly identified by the recogniser .Performance of the HMM - based recogniser on the two sets of features was markedly different , leading to overall differences in recognition rate which were in general much larger than those due to the changes in the HMM parameters .", "label": "", "metadata": {}, "score": "61.773476"}
{"text": "If it is possible to do accurate pitch detection in the SAI , then the SSI can be truncated at the pitch - cutoff line as it is generated .Accurate pitch detection is straightforward for single - source problems , however for images that contain multiple independent sources , the problem becomes more challenging .", "label": "", "metadata": {}, "score": "61.783325"}
{"text": "See Wong et al .( 2007 ) ( supplement ) and Russo et al .( 2008 ) for more details .In ... . \" ...In much experimental phonetics the concept of a vowel space is discussed .The density of points within this vowel space can be modelled using a mixture gaussian density function .", "label": "", "metadata": {}, "score": "61.79666"}
{"text": "Speech Commun . , 36 , p.181 - 203 .[ 1 ] [ 2 ] [ 3 ] .Irino , T. and Patterson , R.D. ( 2006 ) . \"A Dynamic Compressive Gammachirp Auditory Filterbank . \"IEEE Transactions on Audio , Speech , and Language Processing , 14 , p.2222 - 2232 .", "label": "", "metadata": {}, "score": "61.838432"}
{"text": "The speech database is derived from utterances of isolated digits and connected digit sequences spoken by US - American adults originally included in the well - known TIDigits database .The speech in the TIDigits database is sampled at 20 kHz and is down - sampled to 8 kHz in the Aurora database .", "label": "", "metadata": {}, "score": "61.854393"}
{"text": "So , to a certain extent , the SAI segregates the two forms of scale information into two dimensions of the auditory image .The SAI is also a reasonable representation from a physiological point of view .A two - dimensional frequency - periodicity mapping , like that seen in the auditory image and the correlogram , has been observed in the inferior colliculus of the mammalian brain ( Schreiner and Langner , 1988 ) .", "label": "", "metadata": {}, "score": "61.87434"}
{"text": "\" J. Acoust .Soc .Am . , 123 , p.2670 - 9 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] .Johannesma , P. ( 1972 ) .\" The pre - response stimulus ensemble of neurons in the cochlear nucleus . \"", "label": "", "metadata": {}, "score": "61.87651"}
{"text": "This stage extracts a short list of word candidates that are then supplied to the next stage of the word hypothesizer 14 , the Target Congruence stage or TC stage 20 .The RC stage 18 has an RC word prototype database 22 that supplies compact word representations based on the novel compact speech representation ( regions of high phoneme similarity values ) of the invention .", "label": "", "metadata": {}, "score": "61.914158"}
{"text": "Joris P X , Carney L H , Smith P H , Yin T C , ( 1994 ) \" Enhancement of neural synchronization in the anteroventral cochlear nucleus .I. Responses to tones at the characteristic frequency , \" J. Neurophysiol .", "label": "", "metadata": {}, "score": "61.935844"}
{"text": "HTK then compiles the speech model .S imon can be used with all languages and dialects and one can even mix languages .The current release can be used to set up command - and - control solutions especially suitable for disabled people .", "label": "", "metadata": {}, "score": "61.950348"}
{"text": "This paper investigates error - corrective language modeling using the perceptron algorithm on word lattices .The resulting model is encoded as a weighted finite - state automaton , and is used by intersecting the model with word lattices , making it simple and inexpensive to apply during decoding .", "label": "", "metadata": {}, "score": "61.959026"}
{"text": "In the previous section , the benefit of speech enhancement prior to feature extraction in a speech recognition system was demonstrated .However , in a DSR system , transmission errors can still have a significant impact on recognition performance .Such transmission errors in the form of bit errors , random packet loss and packet burst loss need to be taken into consideration .", "label": "", "metadata": {}, "score": "61.96229"}
{"text": "Apart from that , the authors carried out an ASR performance study having as training set both male and female speakers of different age and hearing loss .The results showed that the ASR performance was lower for the older persons and for female ( p.25 ) .", "label": "", "metadata": {}, "score": "61.992783"}
{"text": "References .Albeck Y , 1995 \" Sound localization and binaural processing \" , in The Handbook of Brain Theory and Neural Networks Ed M A Arbib ( Cambridge , MA : Cambridge , MA ) pp 891 - 895 .Bekesy von G , 1964a \" Olfactory analogue to directional hearing \" Journal of Applied Physiology 19 , 369 - 373 .", "label": "", "metadata": {}, "score": "61.99848"}
{"text": "Thus , the length of the AIM feature vectors passed to the recogniser was 12 components , whereas it was 39 components for the MFCC feature vectors .Having feature vectors with a lower dimensionality substantially reduces the time taken to run the training and recognition algorithms in full - scale systems .", "label": "", "metadata": {}, "score": "62.057884"}
{"text": "This new technique was tested along with other strobe systems in a strobe detection task , and was found to be approximately as effective as the best of the original techniques .The work in chapter 3 makes explicit the assumptions being made about the process of strobed temporal integration , thus placing it on a firmer theoretical basis .", "label": "", "metadata": {}, "score": "62.058987"}
{"text": "Server - based methods include feature reconstruction , by means of repetition or interpolation , and error correction in the ASR - decoding stage .Reference [ 4 ] provides a survey of robustness issues related to network degradations and presents a number of analyses and experiments with a focus on transmission error robustness .", "label": "", "metadata": {}, "score": "62.100655"}
{"text": "Free input of speech rather than structured dialog is preferred by test subjects .52 Now we present two studies showing how important is multilinguality in AAL .Undoubtedly , translating vital information can often save lives ( see Anastasiou & Sch\u00e4ler , 2010 ) .", "label": "", "metadata": {}, "score": "62.112946"}
{"text": "proposed flexible matching using WordNet ( Fellbaum , 1998)to find all possible synonyms and words with identical stems in a set of hypotheses .21 Speech synthesis or text - to - speech ( TTS ) is the production of speech ( acoustic waveforms ) from text ( Jurafsky & Martin : 2009 : 249 ) .", "label": "", "metadata": {}, "score": "62.197136"}
{"text": "Since the control parameter is updated instantaneously ( on a sample - by - sample basis in the digital implementation ) , the filterbank exhibits extremely fast - acting compression at sub - millisecond timescales .This compression allows the filterbank to compress the individual glottal cycles in human vocalisations , while allowing the resonance that follows them to ring .", "label": "", "metadata": {}, "score": "62.234066"}
{"text": "In addition to auditory localization such systems include mechanoception , electroception , and vision ( Carr 1993 ) .He carried out similar delayed pulse pair experiments using odorants puffed to the two nostrils ( Bekesy von 1964a ) and tastants spritzed to the two sides of the tongue ( Bekesy von 1964b ) .", "label": "", "metadata": {}, "score": "62.242844"}
{"text": "However , DSR systems generally operate in high levels of background noise ( particularly in mobile environments ) .For mobile users in noisy environments ( airports , cars , restaurants etc . ) the speech recognition accuracy can be reduced dramatically as a consequence of additive background noise .", "label": "", "metadata": {}, "score": "62.25585"}
{"text": "A DSR system is designed as a compromise between local and centralised recognition , in order to alleviate the issues associated with these approaches [ 2 , 3 ] .In DSR , the speech recognition task is split between the terminal or client , where the front - end feature extraction is performed , and the network or server , where the back - end recognition is performed .", "label": "", "metadata": {}, "score": "62.270607"}
{"text": "Auditory features parameters .The process of transformation of SAI frames into sparse codes has several parameters that can be varied .We defined a default parameter set and then performed experiments in which one or a few parameters were varied from this default set .", "label": "", "metadata": {}, "score": "62.283848"}
{"text": "SRILM is freely available for noncommercial purposes .Tazti - A multi function speech recognition software for Windows 7 , Windows 8 and Windows 8.1 based PC 's that allows a user to create keybinds , macros and various mashups to user created speech commands .", "label": "", "metadata": {}, "score": "62.28678"}
{"text": "Fletcher , H. ( 1940 ) .\"Auditory patterns .\" Reviews of Modern Physics , 12 , p.47 - 65 .[ 1 ] .Ganchev , T. , Fakotakis , N. and Kokkinakis , G. ( 2005 ) .", "label": "", "metadata": {}, "score": "62.303833"}
{"text": "Speech quality is a subjective measure and is dependent on the individual preferences of listeners .It is a measure of how comfortable a listener is when listening to the speech under evaluation .The intelligibility of the speech can be regarded as an objective measure , and is calculated based on the number or percentage of words that can be correctly recognised by listeners .", "label": "", "metadata": {}, "score": "62.352947"}
{"text": "As demonstrated above , the standard MFCC features normally used for speech recognition have a problem in that they do not vary in an easily predictable way with speaker VTL .Therefore , we would expect that a standard speech recognition system based on MFCCs would perform poorly when trained on a single speaker ( or small group of speakers with similar VTLs ) , and then tested on a speaker with a different VTL .", "label": "", "metadata": {}, "score": "62.391502"}
{"text": "The features were tested using a database of syllables which had been scaled to simulate speakers with a range of vocal tract lengths and glottal pulse rates .In chapter 3 , I focused on the properties of strobed temporal integration , a mechanism whereby the auditory system might generate a stabilized representation of the neural patterns coming from the cochlea .", "label": "", "metadata": {}, "score": "62.427837"}
{"text": "Sound retrieval and ranking using auditory sparse- code representations .\"Journal : Neural Computation .Note : Under review .OriginalCiteRef : lyon:2010a .[ 1 ] .Lyon , R.F. and Mead , C. ( 1988 ) . \"An analog electronic cochlea . \"", "label": "", "metadata": {}, "score": "62.515514"}
{"text": "( 2011 ) stated that the current ASR systems in AAL are either reliable , but complex and very expensive , or inexpensive , but unreliable .As far as speed is concerned , turning the TV on through speech or gesture should not take longer than clicking on a button .", "label": "", "metadata": {}, "score": "62.5456"}
{"text": "( 2010 ) described technologies for acoustic user interaction in AAL scenarios .They designed and evaluated a multi - media reminding and calendar system as a part of a personal activity and household assistant for acoustic sound pick - up , processing , enhancement , and analysis providing functionality for acoustic input and output of assistive systems .", "label": "", "metadata": {}, "score": "62.54859"}
{"text": "Rather , box - cutting followed by sparse coding is intended to make it possible to identify spectro - temporal patterns in different regions of the SAI .In future work , I intend to compute sparse multiscale features for representations derived from the SAI such as the SSI and the Mellin image ( Irino and Patterson , 2002 ) .", "label": "", "metadata": {}, "score": "62.55811"}
{"text": "A set of phonetic models is created that attempt to capture the acoustic - phonetic properties of individual phones , but do not explicitly model the transition between phones .It is readily apparent , however , that these transitions contain important information about the identity of neighboring phones .", "label": "", "metadata": {}, "score": "62.588554"}
{"text": "The word recognition processor of claim 1 wherein said phoneme similarity module includes a phone model database for storing phone model speech data corresponding to a plurality of phonemes that comprise said predetermined phone model speech data .The word recognition processor of claim 1 wherein said region count stage produces a first score corresponding to the degree of fit between the input utterance and each of the first list of word candidates .", "label": "", "metadata": {}, "score": "62.604675"}
{"text": "This increases the chance of the system incorrectly identifying points on a rising edge in the low - frequency channels , but allows the system to strobe accurately on each peak of higher - pitched sounds .The maximum lockout is a configurable parameter .", "label": "", "metadata": {}, "score": "62.64472"}
{"text": "By applying this threshold , the assumption is that the input sound has a pulse - resonance structure with strong onsets and decaying resonances .As we have seen , this is an entirely reasonable assumption to make about the sounds encountered in everyday life ( although it is always possible to construct ' pathological ' stimuli that break this assumption , for example the ramped sounds presented below ) .", "label": "", "metadata": {}, "score": "62.686646"}
{"text": "For the AIM features , performance was 98.4 % and for the MFCC features performance was 97.3 % .In both cases , performance is best closest to the training speakers , and then ' sags ' slightly in the middle of the range , at the largest distance from the training data .", "label": "", "metadata": {}, "score": "62.727688"}
{"text": "This was taken as the pitch strength .Ives and Patterson ( 2008 ) used this to study the relative pitch strength from a model using the dcGC filterbank and the gammatone filter .This pitch strength measure was used to estimate pitch strength from the temporal profiles of auditory images .", "label": "", "metadata": {}, "score": "62.75428"}
{"text": "The auditory image model ( AIM ) ( Patterson et al . , 1992 ; Patterson et al . , 1995 ) is a computational model of auditory processing .It is the basis for most of the work in this thesis .", "label": "", "metadata": {}, "score": "62.887226"}
{"text": "While this approach is reasonable in a computational system , it may bear less resemblance to the processing performed by the auditory system .Noises and damped / ramped sounds .One major concern for a strobing system is that it should be able to ' degrade gracefully ' in the presence of a sound that is not of the type that it is optimised to deal with .", "label": "", "metadata": {}, "score": "62.902565"}
{"text": "Khadivi , S. , Zens , R. , Ney , H. \" Integration of Speech to Computer - Assisted Translation using Finite - State Automata \" , in Proceedings of COLING / ACL 2006 , Sydney , Australia .Koehn , P. ( 2009 ) , \" A Web - Based Interactive Computer Aided Translation Tool \" , Proceedings of the ACL Interactive", "label": "", "metadata": {}, "score": "62.9175"}
{"text": "( 2008 ) .41 After showing some culture - specific gestures , we define gesture localization as follows : .Gesture localization is the adaptation of gestures to a target locale in order to transfer the same meaning as in the original locale .", "label": "", "metadata": {}, "score": "62.934486"}
{"text": "We hope for future research initiatives and projects developing multimodal and multilingual applications in assistive environments .We presented an initial contribution of a distinct speech - to - speech translation system with the goal of a language - independent dialog management tied with localized co - speech gestures initially applied on a wheelchair and later on other devices in ambient assisted living environments .", "label": "", "metadata": {}, "score": "62.953186"}
{"text": "Particularly striking examples of attention - driven plasticity have been reported in primary auditory cortex via dynamic reshaping of spectro - temporal receptive fields ( STRFs ) .By enhancing the neural response to features of the foreground while suppressing those to the background , STRFs can act as adaptive contrast matched filters that directly contribute to an improved cognitive segregation between behaviorally relevant and irrelevant sounds .", "label": "", "metadata": {}, "score": "62.965088"}
{"text": "Particularly striking examples of attention - driven plasticity have been reported in primary auditory cortex via dynamic reshaping of spectro - temporal receptive fields ( STRFs ) .By enhancing the neural response to features of the foreground while suppressing those to the background , STRFs can act as adaptive contrast matched filters that directly contribute to an improved cognitive segregation between behaviorally relevant and irrelevant sounds .", "label": "", "metadata": {}, "score": "62.965088"}
{"text": "The block of analysis frames is then shifted by one frame at a time to produce a vector of phoneme similarity values each centisecond ( each 100th of a second ) .As illustrated in FIG .4 , the phoneme similarity front end works in conjunction with a phone model database 12 that supplies the phoneme reference templates .", "label": "", "metadata": {}, "score": "63.079697"}
{"text": "5 , the HS region computation module 16 is used to convert the similarity time series from the speech database into a list of HS regions .The alignment module 30 operates on this list of HS regions to eliminate unreliable regions by alignment across speakers .", "label": "", "metadata": {}, "score": "63.133125"}
{"text": "STI converts the time dimension of the NAP into a time - interval dimension in the stabilised auditory image ( SAI ) .A series of vertical ridges appear in the auditory image .These are associated with the repetition rate of the source and can be used to identify the start point for any resonance in that channel .", "label": "", "metadata": {}, "score": "63.18"}
{"text": "Conf . on Intelligent Robots and Systems , Lausanne , Switzerland , pp .1338 - 1343 .TR-2004 - 139 .Will , T. ( 2007 ) , Creating a Dynamic Speech Dialogue , VDM Verlag Dr. M\u00fcller .To cite this document / Pour citer ce document .", "label": "", "metadata": {}, "score": "63.23803"}
{"text": "The stabilised auditory image is a model for an early - stage representation of the incoming signal in the brain .As such , we would like to use it to extract auditory features for machine hearing .In chapter 4 , I presented the first of two studies in which features generated from the SAI were used in this way .", "label": "", "metadata": {}, "score": "63.246883"}
{"text": "27 - C. Pel\u00e1ez - Moreno , G. Gallardo - Antol\u00edn and F. D\u00edaz - de - Mar\u00eda , \" Recognizing voice over IP : A robust front - end for speech recognition on the world wide web \" , IEEE Trans .", "label": "", "metadata": {}, "score": "63.300682"}
{"text": "Welling et al .( 2002 ) applied a total of 13 different VTL warpings to each utterance to assess their VTLN system .If this many warpings are required for good performance , then the computational cost of the AIM features becomes more competitive .", "label": "", "metadata": {}, "score": "63.31028"}
{"text": "Our current experiment is based on interoperability between FOSS ASR , MT , and text - to - speech applications , while future experiments will include gesture recognition tools .Our application environment is an ambient assisted living lab at the University of Bremen , suitable for the elderly and/or people with impairments .", "label": "", "metadata": {}, "score": "63.32312"}
{"text": "For example , in a simple fourth - order all - pole gammatone filterbank , each auditory filter is modelled by a cascade of four identical pole - pair filters .A filter cascade has the same architecture , but the stages are non - identical and there is an output at each step .", "label": "", "metadata": {}, "score": "63.379433"}
{"text": "Speech enhancement algorithms .In this section , the various speech enhancement algorithms that were examined are briefly described .The algorithms range from well - established algorithms like that of Ephraim and Malah [ 20 ] , to more recently proposed ones like that of Rangachari and Loizou [ 21 ] .", "label": "", "metadata": {}, "score": "63.413536"}
{"text": "Joris P X , 2006 \" A dogged pursuit of coincidence \" J Neurophysiol 96 , 969 - 72 .Joris P X , Smith P H , Yin T C , 1998 \" Coincidence detection in the auditory system : 50 years after Jeffress \" Neuron 21 , 1235 - 1238 .", "label": "", "metadata": {}, "score": "63.46172"}
{"text": "Next the list of reliable regions , together with the associated probabilities of detecting those regions is passed to the target building module 32 .This module builds targets by unifying the region series to produce a list of phoneme targets associated with each word in the database .", "label": "", "metadata": {}, "score": "63.493843"}
{"text": "Patterson , R.D. , van Dinther , R. and Irino , T. ( 2007 ) .\" The robustness of bio - acoustic communication and the role of normalization \" , in Proceedings of the 19th International Congress on Acoustics , p.07 - 011 .", "label": "", "metadata": {}, "score": "63.49764"}
{"text": "Unknown ref iso:1993 ! !Unknown ref iso:1997 ! ! ) and auditory models have been recommended for the enhancement and segregation of speech sounds in noisy environments ( Slaney et al . , 1994 ; Irino et al . , 2006 ) .", "label": "", "metadata": {}, "score": "63.50851"}
{"text": "In both cases , the filter bandwidths are wider for louder signals , as would be expected , and they both follow the form of the measured ERB function in humans well .However , the PZFC has a smaller range of variation in bandwidth as a function of level .", "label": "", "metadata": {}, "score": "63.53209"}
{"text": "by Teresa Zollo - Proceedings of AAAI Fall Symposium on Psychological Models of Communication in Collaborative Systems , 1999 . \" ...Continuous speech recognition technology has recently matured to the point where it has become feasible to develop spoken dialogue interfaces to computer systems that help people perform tasks in simple domains .", "label": "", "metadata": {}, "score": "63.56951"}
{"text": "Their measure was simple : they computed the temporal profile and found the largest peak in the region of the time - interval associated with the pitch .They then found the two local minima immediately adjacent to this peak , and took the mean of the levels of the two minima .", "label": "", "metadata": {}, "score": "63.620583"}
{"text": "It is tied to natural language processing ( NLP ) , as its input can come from and/or the output can go to NLP applications .Speech recognition , speaker recognition , and speech synthesis are included inter alia under speech processing .", "label": "", "metadata": {}, "score": "63.63524"}
{"text": "The system must model the processing performed in the auditory system with a degree of fidelity that reflects the aspects of auditory processing which make it robust and effective in processing communication sounds .However , it must still be possible to implement the system for use in practical applications which benefit from the improved auditory processing .", "label": "", "metadata": {}, "score": "63.64785"}
{"text": "Given an active lexicon of N words , the region count stage is first applied to produce a short list of word candidates with normalized scores .A weighted Euclidean distance is used to measure the degree of fit of a test word X to a reference word P ( in RC format as supplied by the RC word prototype database ) .", "label": "", "metadata": {}, "score": "63.674725"}
{"text": "The MFCC feature vector clearly contains a distinctive formant pattern : the information that the vowel is an /i/ in all three cases .The MFCC spectrum also contains information about the relative length of the speakers ' vocal tract in the position of the spectrum along the channel dimension .", "label": "", "metadata": {}, "score": "63.68546"}
{"text": "The final score output by the word hypothesizer is a combination of the information obtained at each hypothesizer stage .In the presently preferred embodiment the final score output of the hypothesizer is : .In the presently preferred embodiment the five words having the highest combined scores are selected as word candidates for the final stage fine match process .", "label": "", "metadata": {}, "score": "63.69599"}
{"text": "Albeck Y , 1995 \" Sound localization and binaural processing \" , in The Handbook of Brain Theory and Neural Networks Ed M A Arbib ( Cambridge , MA : Cambridge , MA ) pp 891 - 895 [ Compact synopsis of the Jeffress model from a neurocomputational perspective ] .", "label": "", "metadata": {}, "score": "63.700546"}
{"text": "Standard deviations for the pitch strength measures are given in brackets after each value .The results suggest that the processing performed by the dcGC is fundamentally different to that performed by the PZFC for these stimuli .In order to determine why performance with the PZFC is inferior to that with the dcGC , we now turn to a deterministic signal to perform several experiments on the AGC of the PZFC .", "label": "", "metadata": {}, "score": "63.728973"}
{"text": "3 , pp .209 - 218 , June 2001 .29 - J. Van Sciver , J. Z. Ma , F. Vanpoucke and H. Van Hamme , \" Investigation of speech recognition over IP channels \" , in Proc . of IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) , May 2002 , pp .", "label": "", "metadata": {}, "score": "63.737328"}
{"text": "In the pitch analysis task , the dcGC filterbank was found to produce the greater pitch strength in its default state .However , it proved possible to modify the parameters of the PZFC and ( a ) make the automatic gain control network very fast - acting , and ( b ) skew the processing to propagate compression to lower - frequency channels .", "label": "", "metadata": {}, "score": "63.75307"}
{"text": "The main difference from release five is the introduction of a simple , unlexicalized , phrase - based stack decoder .This phrase - based decoder shares a hypergraph format with the syntax - based systems , permitting a tight coupling with the existing codebase of feature functions and hypergraph tools .", "label": "", "metadata": {}, "score": "63.809914"}
{"text": "( 2010 ) developed ROILA ( Robot Interaction Language ) in order to improve the accuracy of speech recognition and to make it learnable for a user .Initially based on Toki Pona , they conducted a i ) phonological and ii ) morphological overview of natural languages in order to create ROILA which consists of 16 letters , four parts - of - speech and four pronouns .", "label": "", "metadata": {}, "score": "63.937523"}
{"text": "26 - D. Macho and Y. M. Cheng , \" SNR - dependent waveform processing for improving the robustness of ASR front - end \" , in Proc . of IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) , May 2001 , pp .", "label": "", "metadata": {}, "score": "63.96477"}
{"text": "Word prototypes , for the multistyle training condition , used multistyle phoneme models and two training passes over the speech data : once clean and once with 10 dB SNR additive data show noise .Each recognition data point resulted from 3200 trials .", "label": "", "metadata": {}, "score": "63.97049"}
{"text": "The system described above works only with exact terms , and so related terms are counted as a misclassification .However , people may use many different terms to describe similar sounds .This means that the measured performance of the system will be lower than the actual performance , since many sounds which would be judged by a human listener to be similar are not regarded as such by the system . shows some examples of the terms that most frequently caused confusion in the classification system .", "label": "", "metadata": {}, "score": "63.979073"}
{"text": "There is much potential for employing methods that deal with the longer - term temporal structure of sounds .Future work in this area should incorporate more dynamics of the sound over longer times , perhaps representing repeating patterns that contain more temporal context .", "label": "", "metadata": {}, "score": "63.998398"}
{"text": "IEE Int .Conf . on Arti cial Neural Networks , 1991 . \" ...A neural network is used to generate control parameters for a parallel formant speech synthesizer , corresponding to a sequence of allophone tokens .Training is to be accomplished using formant data obtained from both natural and synthetic speech .", "label": "", "metadata": {}, "score": "64.02832"}
{"text": "\" The sound of a sinusoid : Spectral models .\" J. Acoust .Soc .Am . , 96 , p.1409 - 1418 .[ 1 ] [ 2 ] .Patterson , R.D. ( 1994 ) .\" The sound of a sinusoid : Time - interval models .", "label": "", "metadata": {}, "score": "64.04525"}
{"text": "Figure 18 --Scale - shift invariant features for two scaled vowel sounds .When plotted on a logarithmic scale , such as the ERB scale used in the gammatone , dcGC and PZFC filterbanks , the formants of speech have a shape that is roughly Gaussian .", "label": "", "metadata": {}, "score": "64.05142"}
{"text": "OriginalCiteRef : mertins2005vocal .Pages : 308 - 312 .[ 1 ] [ 2 ] [ 3 ] .Miller , G.A. and Licklider , J.C.R. ( 1950 ) .\" The intelligibility of interrupted speech .\" J. Acoust .", "label": "", "metadata": {}, "score": "64.055695"}
{"text": "Schofield ( 1985 ) demonstrated that the magnitude response of the gammatone could be used to explain human masking data , and Patterson et al .( 1988 ) then highlighted the similarities between the gammatone magnitude response and the shape of the roex function .", "label": "", "metadata": {}, "score": "64.11377"}
{"text": "Figure 27 --- Recognition results for MFCC features with optimal vocal - tract length normalisation when trained on the extreme outer speaker on each spoke of the pattern .Performance is perfect across all speakers .This result suggests that the HMM used in these experiments is more than capable of learning the variability of the database , so if there is a reasonable range of training data then there may be little utility in pre - warping the features .", "label": "", "metadata": {}, "score": "64.15299"}
{"text": "The various parameters of the dcGC filterbank have been fitted to human masking data over several studies ( Unoki et al . , 2001 ; Irino and Patterson , 2001 ; Patterson et al . , 2003 ; Irino and Patterson , 2006 ; Unoki et al . , 2006 ) .", "label": "", "metadata": {}, "score": "64.19442"}
{"text": "Lutfi , R.A. and Patterson , R.D. ( 1984 ) .\" On the growth of masking asymmetry with stimulus intensity .\" J. Acoust .Soc .Am . , 76 , p.739 - 745 .[ 1 ] .Lyon , R.F. ( 1996 ) .", "label": "", "metadata": {}, "score": "64.27252"}
{"text": "Upcoming Events .Abstract Deep Learning enabled tremendous breakthroughs in visual understanding and speech recognition .Ostensibly , this is not the case in natural language processing ( NLP ) and higher level reasoning .However , it only appears that way because there [ ... ] .", "label": "", "metadata": {}, "score": "64.315056"}
{"text": "In this chapter , two recent models of the auditory filter that perform dynamic compression are discussed and analysed .The models are the dynamic , compressive gammachirp ( dcGC ) ( Irino and Patterson , 2006 ; Irino , Walters and Patterson , 2007 ) and the pole - zero filter cascade ( PZFC ) ( Lyon et al . , 2010 ) .", "label": "", "metadata": {}, "score": "64.31721"}
{"text": "This has the effect of tying together the responses of all channels and determining a single strobe time across the entire filterbank .The system marks the presence of a pulse in all channels , even if it is masked by other energy in some of those channels .", "label": "", "metadata": {}, "score": "64.3318"}
{"text": "The modified AGC coefficients , and pitch strength estimates , are shown in lines 7 to 11 of .Tested configurations of the PZFC spatial and temporal smoothing filters , and measured pitch strength for a harmonic complex using these parameters .", "label": "", "metadata": {}, "score": "64.35569"}
{"text": "Based on the experimental measurements , a set of packet loss characteristics was defined in [ 33 ] and these are used to analyse recognition performance for different network conditions .The parameters in Table 6 are taken from this defined set of packet loss characteristics .", "label": "", "metadata": {}, "score": "64.3983"}
{"text": "In this thesis , I evaluate and develop some of the many aspects of the auditory image model , with a focus on using AIM to generate features that provide useful and salient information about the content of sound to machine learning systems .", "label": "", "metadata": {}, "score": "64.4246"}
{"text": "The open - source AIM - C software allows for fast processing of large databases of audio .Coupled with HTK , and a set of scripts allowing distributed processing , this experimental framework can easily be extended to test new AIM modules and new feature extraction mechanisms .", "label": "", "metadata": {}, "score": "64.48353"}
{"text": "Enhancement of noisy speech signals is normally used to improve the perception of the speech by human listeners however , it may also have benefits in enhancing robustness in ASR systems .Speech enhancement can be particularly useful in cases where a significant mismatch exists between training and testing conditions , such as where a recognition system is trained with clean speech and then used in noisy conditions , as inclusion of speech enhancement can help to reduce the mismatch .", "label": "", "metadata": {}, "score": "64.48817"}
{"text": "The proposed error corrective language model adaptation approach exploits domain - specific language variations and reco ... \" .We present a new language model adaptation framework integrated with error handling method to improve accuracy of speech recognition and performance of spoken language applications .", "label": "", "metadata": {}, "score": "64.488174"}
{"text": "We demonstrate some experiments of spoken dialogue tasks and empirical results which show an improvement of the accuracy for both speech recognition and spoken language understanding .If we assume that the output word sequences produced by ASR are independent of ...", "label": "", "metadata": {}, "score": "64.49917"}
{"text": "While the magnitude of the basic roex has a simple description in the frequency domain ( a pair of back - to - back exponentials with a rounded top ) , the phase response is not defined .This in turn leaves the impulse response undefined and so the roex , like other simple descriptions of the frequency spectrum of an auditory filter , can not be used to make a time - domain filterbank ( Patterson et al . , 2003 ) .", "label": "", "metadata": {}, "score": "64.51096"}
{"text": "Am . , 55 , p.588 - 596 .[ 1 ] .Robinson , K. and Patterson , R.D. ( 1995 ) .\" The stimulus duration required to identify vowels , their octave and their timbre .\" J. Acoust .", "label": "", "metadata": {}, "score": "64.54718"}
{"text": "( 1996 ) , while others like Paulik et al .( 2005 ) , Khadivi et al .( 2006 ) , Reddy et al .( 2007 ) followed .We particularly look at three more recent approaches : .", "label": "", "metadata": {}, "score": "64.56055"}
{"text": "For the purpose of training the speech recogniser , two modes are defined .The first mode is training on clean data and the second mode is multi - condition training on noisy data .The same 8440 utterances , taken from the training part of the TIDigits , are used for both modes .", "label": "", "metadata": {}, "score": "64.56427"}
{"text": "A region count hypothesizer stage , which includes a first word prototype database for storing similarity region count data for a plurality of words , is coupled to the high similarity module .The region count hypothesizer generates a first list of word candidates selected from the first word prototype database , based on similarity regions .", "label": "", "metadata": {}, "score": "64.62355"}
{"text": "A set of desirable properties of a practical auditory filter are set out by Lyon et al .( 2010 ) .The list is as follows : .Simplicity of description .Either in the time domain , the frequency domain or in the Laplace domain .", "label": "", "metadata": {}, "score": "64.63156"}
{"text": "Figure 25 --- Recognition results for MFCC features when trained on the extreme outer speaker on each spoke of the pattern .Performance is highest immediately around the training data , and falls slightly further from the training speaker , reaching a low of 93.0 % .", "label": "", "metadata": {}, "score": "64.64381"}
{"text": "In each case , a spectral profile was constructed from the SSI and this was used with the Gaussian fitting procedure introduced in chapter 2 .In the first variant , the spectral profile of the complete SSI was taken and used for fitting .", "label": "", "metadata": {}, "score": "64.68938"}
{"text": "The last chapter introduced a feature representation based on the smoothed output from a simulation of the cochlea and a simple hair - cell model .The signal was temporally averaged over a short window by means of a low - pass filter .", "label": "", "metadata": {}, "score": "64.70277"}
{"text": "The results follow the same pattern as the perceptual results reported in Patterson et al .( 1996 ) , but the measure is slightly noisier than the model used in that paper .The predictions made by the normalized pitch strength measure in Figure 88 have the same form as the perceptual results reported in Patterson et al .", "label": "", "metadata": {}, "score": "64.727615"}
{"text": "The response latencies produced by the cross - correlator can then be compared with those of an unprocessed signal .In the binaural case , hypothetically , the longer the detour through the binaural cross - correlator relative to the ipsilateral direct monaural path might indicate a greater degree of lateralization on the ipsilateral side .", "label": "", "metadata": {}, "score": "64.74835"}
{"text": "The algorithm makes use of the parameters from the front - end feature extraction algorithm of the ETSI advanced front - end .The purpose of the algorithm is to reduce the number of bits needed to represent each front - end feature vector and so reduce the bit rate required over the communications channel .", "label": "", "metadata": {}, "score": "64.810776"}
{"text": "Table 14 .Discussion .The results in Table 7 show that the front - end proposed by Li et al .[14 ] , when combined with the speech enhancement algorithm proposed by [ 25 ] , reduces the overall word error rate of the ETSI advanced front - end [ 7 ] by 8 % .", "label": "", "metadata": {}, "score": "64.81232"}
{"text": "The minimum tracking method requires a bias compensation since the minimum power spectral density of the noisy signal is smaller than the average value .In [ 24 ] , Martin further developed the noise estimation algorithm by using a time- and frequency - dependent smoothing parameter when calculating the smoothed power spectral density .", "label": "", "metadata": {}, "score": "64.86224"}
{"text": "( 2008 ) evaluated productivity gains of hybrid ASR - SMT systems for translation dictation .They conducted an experiment with eight professional translators dictating into French using Dragon NaturallySpeaking 8 .Although hypothesis combination ( i ) gave lowest error rates , the use of cross - adaptation was found to be a \" safer combination scheme for translation \" ( p.1280 ) .", "label": "", "metadata": {}, "score": "64.87169"}
{"text": "Phoneme models were trained on the TIMIT database SX sentences , downsampled to 8 kHz sampling rate .For training nominal clean phoneme models , each sentence was used twice : once as clean speech and once with artificially added stationary pink Gaussian noise at 20 dB SNR .", "label": "", "metadata": {}, "score": "64.90732"}
{"text": "Rangachari and Loizou [ 21 ] proposed an algorithm for the estimation of noise in highly non - stationary environments .The noisy speech power spectrum is averaged using time and frequency dependent smoothing factors .This new averaged value is then used to update the noise estimate .", "label": "", "metadata": {}, "score": "64.91877"}
{"text": "The four different packet loss channels investigated are defined in Table 6 .Recognition tests , in the presence of packet loss , were carried out for each of the following conditions : .Tests were first carried out for packet loss with no steps taken to recover the missing features or to minimise the loss burst length .", "label": "", "metadata": {}, "score": "64.94873"}
{"text": "Continuous speech recognition technology has recently matured to the point where it has become feasible to develop spoken dialogue interfaces to computer systems that help people perform tasks in simple domains .Word recognition accuracy for spontaneous dialogue , however , is still a long way from perfect , and any system that uses spoken natural language input hastohave somemechanism for dealing with speech recognition errors .", "label": "", "metadata": {}, "score": "64.989105"}
{"text": "It is not , however , a surprising result ; the scale - shift invariant features were specifically designed to have these properties and the MFCCs were not .Once VTLN is performed , performance recovers and exceeds that obtained with the scale - shift invariant features .", "label": "", "metadata": {}, "score": "64.991035"}
{"text": "Burda ( 2005 ) made an experiment with twenty native speakers of English , ages 62 to 91 , who listened to words and sentences produced by native speakers of English , Taiwanese , and Spanish .Participants transcribed the words and sentences and rated speakers ' comprehensibility and accentedness using separate 7-point Likert - type scales .", "label": "", "metadata": {}, "score": "65.03693"}
{"text": "There is essentially no temporal averaging , in contrast to spectrographic representations where segments of sound 10 to 40 ms in duration are summarised in a spectral vector of magnitude values .There exist several different filterbanks in AIM ; the default , the gammatone ( Patterson and Moore , 1986 ) , is a passive linear filter which does not simulate any of the level - dependent properties of auditory filtering .", "label": "", "metadata": {}, "score": "65.03809"}
{"text": "At the end of that process a target rate constraint ( i.e. desired number of targets per second ) is then applied to obtain a uniform word description level for all the words in the lexicon .The desired number of targets per second can be selected to meet system design constraints such as the ability of a given processor to handle data at a given rate .", "label": "", "metadata": {}, "score": "65.07065"}
{"text": "It is for these last two reasons that the PZFC needs more testing and improving before it can be considered as good as the dcGC for modelling auditory processing .A further problem with the PZFC is that , in the design detailed in this thesis , it is not able to successfully model the data on zero - crossings of the auditory filter response .", "label": "", "metadata": {}, "score": "65.10094"}
{"text": "In this paper the current speech processing in BAALL was described together with its limitations which are lock - in propriety software , monolinguality , grammar minimalism , and activity simplicity .Our contributions to eliminate the limitations are usage of FOSS , a unique speech - to - speech translation system , lexical grammar enrichment , and activity - based ontologies .", "label": "", "metadata": {}, "score": "65.12184"}
{"text": "Spoken language processing : A guide to theory , algorithm , and system development .( Prentice Hall PTR Upper Saddle River , NJ , USA ) .[ 1 ] .Huber , J.E. , Stathopoulos , E.T. , Curione , G.M. , Ash , T.A. and Johnson , K. ( 1999 ) .", "label": "", "metadata": {}, "score": "65.194824"}
{"text": "For training multistyle phoneme models , the additive noise was replaced by data show noise at 10 dB SNR .Word level training and testing was done on one repetition of speech data from 64 talkers .Word prototypes were trained and tested on nonoverlapping gender - balanced sets of 32 talkers each .", "label": "", "metadata": {}, "score": "65.2041"}
{"text": "Kim , D.O. , Molnar , C.E. and Matthews , J.W. ( 1980 ) .\" Cochlear mechanics : nonlinear behaviour in two - tone responses as reflected in cochlear - nerve - fibre responses and in ear - canal sound pressure .", "label": "", "metadata": {}, "score": "65.22389"}
{"text": "They always have the same form regardless of the content .35 As for speech - gesture combination , McNeil ( 1992 ) points out that speech and gesture must cooperate to express a person 's meaning .Although they are closely linked , he refers to some of their distinct differences .", "label": "", "metadata": {}, "score": "65.23135"}
{"text": "Irino and Patterson ( Irino and Patterson , 1997 ) employed these methods in their development of the gammachirp auditory filter .The gammachirp is in fact the minimal uncertainty function for a joint time- scale representation of a signal .When designing new representations of sounds for content - based analysis , it is important to understand the systems which are currently used for these tasks .", "label": "", "metadata": {}, "score": "65.23212"}
{"text": "( See Durlach and Colburn ( 1978 ) and Colburn and Durlach ( 1978 ) for comprehensive reviews of binaural psychophysics and models thereof . ) temporally - coded input signals consisting of spikes that are time - locked to the waveform of the acoustic stimulus , .", "label": "", "metadata": {}, "score": "65.26027"}
{"text": "Theobalt et al .( 2002 ) developed Godot , a mobile robot platform for the interface between a sophisticated low level robot navigation and symbolic high - level spoken dialog system .The dialog component used Discourse Representation Structures .They used the off - the - shelf Nuance 7.0 speech recognizer .", "label": "", "metadata": {}, "score": "65.28125"}
{"text": "These stages are all based on the physical properties of the various structures and systems which perform the processing .The subsequent stages of the model are based less upon observations of the physical processes and more upon observations of human perception of sounds .", "label": "", "metadata": {}, "score": "65.283005"}
{"text": "Recognition performance as a function of speaker GPR and VTL for the MFCC features is plotted in Figure 21 , and recognition performance for the AIM features is plotted in Figure 22 .Figure 22 --- Recognition results for the AIM features for a 2 emitting - state HMM with 4 output distribution components after 15 training iterations .", "label": "", "metadata": {}, "score": "65.30035"}
{"text": "38 - B. P. Milner and A. B. James , \" Robust speech recognition over mobile and IP networks in burst - like packet loss \" , in IEEE Trans .on Audio , Speech and Language Processing vol .14 , ed , Jan. 2006 , pp .", "label": "", "metadata": {}, "score": "65.31204"}
{"text": "Error - robustness techniques are categorised in [ 4 ] under the headings client - based error recovery , and server - based error concealment .Client - based techniques include retransmission , interleaving and forward error correction ( FEC ) .", "label": "", "metadata": {}, "score": "65.394104"}
{"text": "Am . , 108 , p.692 - 695 .[ 1 ] .Hawks , J.W. and Miller , J.D. ( 1995 ) .\"A formant bandwidth estimation procedure for vowel synthesis .\" J. Acoust .Soc .Am . , 97 , p.1343 - 1345 .", "label": "", "metadata": {}, "score": "65.41626"}
{"text": "MFCCs were computed using a Hamming window , with the first and second derivatives as additional features of each frame .Optimal performance was obtained with a codebook of size 5000 , 40ms frames and 40 cepstral coefficients .This configuration corresponds to much higher frequency resolution than the standard MFCC features used for speech .", "label": "", "metadata": {}, "score": "65.493225"}
{"text": "If two animals of the same species make the same call , then the major factor that distinguishes the two calls will be the sizes of the calling individuals .Figure 4 shows a short section of the waveform ( upper panel ) and spectrum ( lower panel ) of a synthetic /a/ vowel , as might be spoken by a child .", "label": "", "metadata": {}, "score": "65.51882"}
{"text": "In the remainder of this chapter , the Gaussian features developed in chapter 2 are used to summarise spectral slices of the SSI , and the robustness of these features to noise is compared with that of the MFCCs and the features derived from the NAP in chapter 2 .", "label": "", "metadata": {}, "score": "65.54198"}
{"text": "d pruned to construct a corrected , more accurate n - best list .The novelty of our approach lies in : ( 1 ) the use of user click data in a deployed multi - modal s .. \" ...We demonstrate that transformation - based learning can be used to correct noisy speech recognition transcripts in the lecture domain with an average word error rate reduction of 12.9 % .", "label": "", "metadata": {}, "score": "65.57182"}
{"text": "Whereas the data rate of the original sound is on the order of 300kbps , the data rate of the auditory image is on the order of 30Mbps .There are clearly substantial redundancies in the SAI and it behoves us to try and find a compact vector of features that summarises the signal and reduces the data - rate burden , if the SAI is to be used as the basis of a recognition system .", "label": "", "metadata": {}, "score": "65.57582"}
{"text": "The method of claim 20 wherein said combining step is performed by averaging said first and second normalized scores .The method of claim 16 further comprising representing said high similarity regions as a parameter representing the high similarity regions of the phone similarity data .", "label": "", "metadata": {}, "score": "65.58267"}
{"text": "Further work and Conclusions .In this section I have introduced Lyon 's pole - zero filter cascade ( PZFC ) filterbank as an efficient compressive auditory filterbank which can model well the masking data from humans , and compared it to another compressive filterbank , the dynamic compressive gammachirp ( dcGC ) .", "label": "", "metadata": {}, "score": "65.59366"}
{"text": "However , as VTL varies further from the training values , performance degrades rapidly , particularly on the spokes with large VTL change , where recognition falls to a minimum of 3.2 % for the extreme VTL values .This provides a practical demonstration of the known lack of robustness to changes in VTL associated with the lack of scale - shift covariance in MFCCs .", "label": "", "metadata": {}, "score": "65.640434"}
{"text": "AAL - Kongress 2011 , Berlin , Germany , January 25 - 26 .Nickel , K. , Stiefelhagen , R. ( 2007 ) , \" Visual recognition of pointing gestures for human - robot interaction \" , in Image and Vision Computing , vol 25 , Issue 12 , pp .", "label": "", "metadata": {}, "score": "65.64999"}
{"text": "The SAI module uses the strobe points to convert the NAP into an auditory image , in which the pulse - resonance pattern of a periodic sound is stabilised using the strobe points generated in the previous stage .The ' ti2003 ' algorithm is the default method for generating SAIs in the software packages AIM - MAT and AIM - C ( which are discussed below ) .", "label": "", "metadata": {}, "score": "65.67102"}
{"text": "Its distinction from a typical SST system is that the intelligent device does not speak in the language the input is translated into , but in the user 's language .MT is used only to translate the existing grammar in the user 's language .", "label": "", "metadata": {}, "score": "65.69"}
{"text": "The level of the stimulus was ramped down linearly ( on a dB scale ) from a maximum to -48dB over the course of one second .Scaling is as in Figure 79 so that dynamic range can be compared .Figure 81 --- ' Cochleagrams ' of the output of the PZFC , dcGC and gammatone filterbanks for a two - formant synthetic vowel .", "label": "", "metadata": {}, "score": "65.7348"}
{"text": "Initially we deal with the simple case of a single speaker with no background noise as the input sound , and then the analysis is extended to cope with the case of a single speaker in noise , and then to multiple speakers in noise .", "label": "", "metadata": {}, "score": "65.74939"}
{"text": "The Lyon - SAI uses the ' Lyon ' strobe mechanism discussed in chapter 3 , and a slightly different strobed temporal integration process .This study was undertaken as part of the ' machine hearing ' research effort at Google .", "label": "", "metadata": {}, "score": "65.789474"}
{"text": "( 2008 ) described an incremental alignment method to build confusion networks based on the translation edit rate ( TER ) algorithm .They used a confusion network as the reference .The algorithm finds the minimum edit distance between the hypothesis and the reference by considering all word arcs between two consecutive nodes in the reference as possible matches for a hypothesis word at that position .", "label": "", "metadata": {}, "score": "65.8479"}
{"text": "Speech - gesture alignment is being researched currently , among others , by the University of Bielefeld ( project SFB 673-B1 55 ) .36 Moving forward from a theoretical view of gestures to gesture - based software , we will refer to some gesture recognition software .", "label": "", "metadata": {}, "score": "65.85231"}
{"text": "The channel characteristics used are G.712 and modified intermediate reference system ( MIRS ) .The down - sampled , filtered speech corresponds to \" clean \" data in the Aurora database .The Aurora database also contains \" noisy \" data .", "label": "", "metadata": {}, "score": "65.877"}
{"text": "This allows detection of pitches up to around 217Hz .This allows for coverage of all pitches in the syllable database used for training and testing .However , more generally , spoken pitches may exceed this value and so the system would need to be modified to include a more robust pitch tracker in order to use the truncated SSI for features .", "label": "", "metadata": {}, "score": "65.87774"}
{"text": "This is clearly a simplistic model of the resonances of the vocal tract , since the vocal filter can not have an instantaneous rise time , but it will suffice for the purposes of defining constraints on the response of the system .", "label": "", "metadata": {}, "score": "65.888306"}
{"text": "The output of the network is a spatial map of running coincidence rates , arranged by frequency channel ( cochleotopic projection ) and interaural delay .The 1948 Jeffress model for binaural localization was closely followed in 1951 by J.C.R. Licklider 's duplex temporal autocorrelation model for pitch ( Licklider 1951 ) in which monaural signals were delayed relative to a copy of themselves .", "label": "", "metadata": {}, "score": "65.88846"}
{"text": "9 - \" Speech Processing , Transmission and Quality Aspects ( STQ ) ; Distributed speech recognition ; Extended advanced front - end feature extraction algorithm ; Compression algorithms ; Back - end speech reconstruction algorithm \" , in ETSI ES 202 212 , Ver .", "label": "", "metadata": {}, "score": "66.03347"}
{"text": "Acoustical Society of Japan , Spring 1995 ( in Japanese ) .Phoneme similarity values are typically computed as the normalized Mahalanobis distance between a segment consisting of consecutive linear predictive coding ( LPC ) analysis frames and a standard phoneme template .", "label": "", "metadata": {}, "score": "66.03769"}
{"text": "Compatible with all major 3D depth - sensing devices , IISU is available now to developers of interactive digital entertainment , serious games , interactive marketing solutions , and consumer electronics applications .Throw and Tilt ( Dachselt & Buchholz , 2009 ) combines sensor - enabled , gesture - based mobile phone interaction with large displays .", "label": "", "metadata": {}, "score": "66.042145"}
{"text": "Prog .Brain Res .Braitenberg V , 2000 \" The neuroanatomy of time \" , in Time and the Brain Ed R Miller ( Australia : Australia ) pp 391 - 396 .Brand A , Behrend O , Marquardt T , McAlpine D , Grothe B , 2002 \" Precise inhibition is essential for microsecond interaural time difference coding , \" Nature 417 , 543-\u00ad547 .", "label": "", "metadata": {}, "score": "66.08182"}
{"text": "Since the repetition rate of the stimuli was already known , the search space for a local maximum in the SAI temporal profile was limited to a region around the fundamental .The search space for a maximum was 1.5ms each side of the repetition rate .", "label": "", "metadata": {}, "score": "66.13835"}
{"text": "( 2008 ) found this more appropriate .69 Multimodality and multilinguality are two different aspects in AAL which can be combined though to make not only human - human but also human - computer interaction efficient .In AAL devices should be reachable , navigation should happen without crashes , and all this at high speed and low cost .", "label": "", "metadata": {}, "score": "66.169495"}
{"text": "Cherry C , 1961 \" Two ears - but one world \" , in Sensory Communication Ed W A Rosenblith ( New York : New York ) pp 99 - 117 .Colburn H S , 1996 \" Computational models of binaural processing \" , in Auditory Computation Eds H Hawkins , T McMullin , A N Popper and R R Fay ( New York : New York ) .", "label": "", "metadata": {}, "score": "66.2834"}
{"text": "The global score of each word in the short list is then defined as : .Evaluation Task .Recognition word accuracy was evaluated in isolated word speaker - independent mode on a speech database of 100 English proper names .Testing was performed in several noise conditions : clean test speech and speech with additive noise at 20 dB or 10 dB signal - to - noise ratio .", "label": "", "metadata": {}, "score": "66.292145"}
{"text": "However , when this system was incorporated into the sound - effects recognition system described in chapter 6 , it was found that performance with a SAI based on this system is actually slightly better than performance with a SAI which uses strobes from a simple thresholding based system .", "label": "", "metadata": {}, "score": "66.29649"}
{"text": "The ETSI advanced front - end [ 7 ] specifies that where missing feature vectors occur due to transmission errors , they should be substituted with the nearest correctly received feature vector in the receiver .The speech vector includes the 12 static cepstral coefficients C 1 - C 12 , the zeroth cepstral coefficient C 0 and the log energy term , and all are replaced together .", "label": "", "metadata": {}, "score": "66.30647"}
{"text": "ISCA ITRW ASR-2000 , Paris , France , Sept. 2000 , pp .181 - 188 .20 - Y. Ephraim and D. Malah , \" Speech enhancement using a minimum mean - square error short - time spectral amplitude estimator \" , IEEE Trans . on Acoustics , Speech and Signal Processing , vol .", "label": "", "metadata": {}, "score": "66.31801"}
{"text": "This set excludes features that are very local in the auditory image .While the codebook sizes remained fixed at 256 , the total number of feature dimensions varied , proportional to the number of boxes used , and performance within each series was found to be monotonic with the total number of feature dimensions .", "label": "", "metadata": {}, "score": "66.39159"}
{"text": "This SAI could be used as the basis of a number of feature representations , either by warping the time - interval axes of the different filterbank channels independently to generate the SSI , or by direct sampling of the SAI itself .", "label": "", "metadata": {}, "score": "66.4632"}
{"text": "Firstly , all the parameters of the system are calculated from the derived envelopes of driven gammatone filters .These parameters provide an upper bound on the expected temporal characteristics of the filter response .Secondly , the ' lockout ' system allows the system to follow a rising edge for a short period , and not issue a strobe point until the top of a rising edge .", "label": "", "metadata": {}, "score": "66.51457"}
{"text": "Figure 72 shows the response of the individual filter stages after adaptation to a human /a/ vowel , and Figure 73 shows the overall filterbank response after adaptation .The original response of the filter stages , before adaptation , is seen in Figure 67 .", "label": "", "metadata": {}, "score": "66.52718"}
{"text": "Bilsen , F.A. ( 2006 ) . \"Repetition pitch glide from the step pyramid at Chichen Itza . \" J. Acoust .Soc .Am . , 120 , p.594- .[ 1 ] .Bleeck , S. , Ives , T. and Patterson , R.D. ( 2004 ) .", "label": "", "metadata": {}, "score": "66.536804"}
{"text": "Cambridge , MA : May 1999 .McNeill , D. ( 1992 ) , Hand and Mind - What Gestures Reveal about Thought , The University of Chicago Press , Chicago , London , 1992 .Motallebipour , H. , Bering , A. ( 2003 ) , \" A Spoken Dialogue System to Control Robots \" Technical report , Dept . of Computer Science , Lund Institute of Technology .", "label": "", "metadata": {}, "score": "66.554306"}
{"text": "The first version of HTK was in 1989 by Steve Young .Julius 15 ; Julius ( Lee & Kawahara , 2009 ) has been developed as a research software for Japanese large vocabulary continuous speech recognition ( LVCSR ) ; currently is developed by Nagoya Institute of Technology .", "label": "", "metadata": {}, "score": "66.581924"}
{"text": "Booktitle : Proceedings of the SPECOM .Volume : 1 .Organization : Citeseer .OriginalCiteRef : ganchev2005comparative .Pages : 191 - 194 .[ 1 ] .Gersho , A. and Gray , R.M. ( 1992 ) . \"Vector quantization and signal compression .", "label": "", "metadata": {}, "score": "66.61573"}
{"text": "auditory model are shown in Figure 2 .Speech is sampled at 8 kHz and blocked into frames of 240 samples .Frame overlap is 66.7 % and a Hamming window is used prior to taking a FFT .An outer / middle ear transfer function that models pressure gain in the outer and middle ears is applied to the spectrum magnitude .", "label": "", "metadata": {}, "score": "66.63173"}
{"text": "Therefore , instead of looking for patterns only in the whole auditory image , local patterns in different parts of the SAI , and at different scales , are identified .To do this , we define a set of overlapping rectangles of different scales that cover the whole SAI frame , and then the content of each of those rectangles is independently encoded using a separate sparse coder .", "label": "", "metadata": {}, "score": "66.65501"}
{"text": "It requires a small ' look ahead ' over 10 - 15ms of the stimulus ( and does not perform any cross - channel integration ) .Additionally , I present a system which strongly enforces cross - channel constraints to infer the original pulse times in the stimulus ( but which is less computationally efficient and which requires a greater ' look - ahead ' time ) .", "label": "", "metadata": {}, "score": "66.67467"}
{"text": "For the two - source cases , the best - performing systems from the single - source tests were tested again .These were the ' local maximum ' system and the two newly - developed systems .Each of the algorithm variants is given a score from 0 to 100 % on its ability to get the timing of the strobe points right , and the mean number of strobes per pulse is reported .", "label": "", "metadata": {}, "score": "66.688"}
{"text": "532 - 535 .Use of the word hypothesizer improved recognition performance ( compared to exhaustive search by the fine match alone ) for every test condition under multistyle training .The error reduction due to the hypothesizer was insignificant ( 2 % ) for 10 dB car noise , but was 25 % or more for each of the 4 other test conditions .", "label": "", "metadata": {}, "score": "66.78868"}
{"text": "In the analysis , two versions of the Li et al .front - end are used .The first , referred to as Li et al .( I ) , generates a feature vector consisting of 13 coefficients made up of the frame log - energy measure and the cepstral coefficients C 1 to C 12 .", "label": "", "metadata": {}, "score": "66.80856"}
{"text": "The final step is the application of a discrete cosine transform ( DCT ) to generate the MFCCs .In the ETSI DSR front - ends , speech , sampled at 8 kHz , is blocked into frames of 200 samples with an overlap of 60 % .", "label": "", "metadata": {}, "score": "66.836136"}
{"text": "HMMs were trained on the nine inner speakers from the spoke pattern , as before .However , in this case each training example was presented with an SNR picked randomly and uniformly from the complete range of SNRs .Testing was performed with all examples from the same SNR .", "label": "", "metadata": {}, "score": "66.851364"}
{"text": "Irino , T. and Unoki , M. ( 1999 ) . \"An analysis / synthesis auditory filterbank based on an IIR implementation of the gammachirp .\" J. Acoust .Soc .Jpn , 20 , p.397 - 406 .[ 1 ] .", "label": "", "metadata": {}, "score": "66.86186"}
{"text": "High SNR values indicate the presence of speech and the sub - band signal is amplified .Low SNR values indicate the presence of noise only and the sub - band signal remains unchanged .Martin [ 23 ] presented an algorithm for the enhancement of noisy speech signals by means of spectral subtraction , in particular through a method for estimation of the noise power on a sub - band basis .", "label": "", "metadata": {}, "score": "66.8798"}
{"text": "Complex Sounds and Auditory Images \" , in Auditory Physiology and Perception , Y Cazals L. Demany and Horner , K. editors ( Pergamon Press , Oxford ) .[ 1 ] [ 2 ] [ 3 ] [ 4 ] .", "label": "", "metadata": {}, "score": "66.905045"}
{"text": "Despite increasing the decay time , the back - projection system fails on the single - source vowel stimulus because the dynamic range is still too small .Further work to improve the performance of the PZFC with the back - projection strobe algorithm should be directed towards defining a ' canonical ' filterbank impulse response from the PZFC , which can be compared with the impulse response in a range of AGC configurations .", "label": "", "metadata": {}, "score": "66.915886"}
{"text": "The advantage of interleaving can be seen by a comparison of Table 14 with Table 13 , where overall recognition results are improved for both front - ends when interleaving is introduced .Looking at Table 14 it is seen that Li et al .", "label": "", "metadata": {}, "score": "66.915985"}
{"text": "This has the effect of adding a repeating temporal structure to the noise .After several iterations of this delay - and - sum process , a weak pitch is observed in the stimulus , which gradually becomes stronger as more iterations are performed .", "label": "", "metadata": {}, "score": "66.946976"}
{"text": "Lee , S. , Potamianos , A. and Narayanan , S. ( 1999 ) .\" Acoustics of children 's speech : developmental changes of temporal and spectral parameters .\" J. Acoust .Soc .Am . , 105 , p.1455 - 68 .", "label": "", "metadata": {}, "score": "66.99544"}
{"text": "The systems in our heads which perform this processing are the result of hundreds of millions of years of evolutionary fine - tuning , and we have only begun to understand how they work .However , just because we do n't fully understand every aspect of auditory processing does n't mean that we should n't try to put what we do know to good use .", "label": "", "metadata": {}, "score": "67.0164"}
{"text": "A strobing system should degrade gracefully when processing any stimulus that is not a periodic , pulse - resonance signal .It should continue to issue strobes at a reasonable rate , but essentially at random .If there is no temporal structure to the input signal , then there will be no temporal structure in the SAI .", "label": "", "metadata": {}, "score": "67.01786"}
{"text": "Holdsworth 's filterbank code was used successfully over many years as the filterbank in AIM ( Patterson et al . , 1995 ) .In its simplest form , however , the gammatone filter is linear , and has a near - symmetrical frequency response around its centre frequency .", "label": "", "metadata": {}, "score": "67.108246"}
{"text": "Figure 74 shows the results of fitting the PZFC to the masking data of Baker et al .( 1998 ) and Glasberg and Moore ( 2000 ) .The four panels show various aspects of the response of the filterbank .", "label": "", "metadata": {}, "score": "67.11376"}
{"text": "The goal of the Speech - to - Speech Translation ( SST ) is to enable real - time , interpersonal communication via natural spoken language for people who do not share a common language .It aims at translating a speech signal in a source language into another speech signal in a target language .", "label": "", "metadata": {}, "score": "67.11577"}
{"text": "The largest pitch strength estimate is achieved when the AGC employs the shortest time constants , and it is larger than that for the dcGC operating on the same stimulus .Modification of the spatial smoothing constants has a smaller effect on the pitch strength estimate , but the case where the coefficients push the activity strongly from higher - frequency channels to lower - frequency channels has the greatest effect .", "label": "", "metadata": {}, "score": "67.184296"}
{"text": "Taking the lowest 13 components has the effect of retaining the envelope of the spectrum while removing most of the harmonic structure , making the MFCCs largely invariant to pitch variability in the incoming signal .The upper lines in Figure 15 show smoothed spectra of three human /i/ vowels from speakers with different VTLs , as represented by the first 13 MFCC coefficients .", "label": "", "metadata": {}, "score": "67.18925"}
{"text": "OriginalCiteRef : gersho - vector .[ 1 ] .Glasberg , B.R. and Moore , B.C.J. ( 2000 ) . \"Frequency selectivity as a function of level and frequency measured with uniformly exciting notched noise .\" J. Acoust .", "label": "", "metadata": {}, "score": "67.204605"}
{"text": "Irino and Patterson ( 2006 ) showed how strobes from one source in a mixture could be located , and that this led to a stabilised auditory image in which the activity of the target souce dominated .This suggests that it might be possible to develop an auditory source separation system by dynamically constraining strobing to a target source .", "label": "", "metadata": {}, "score": "67.217064"}
{"text": "In an HMM speech recognition system , the speech signal is modelled as a sequence of stationary ' frames ' of audio which have been generated by an underlying Markov model .The frames of speech are represented as ' feature vectors ' -- some low - dimensional summary of a short segment of audio .", "label": "", "metadata": {}, "score": "67.23714"}
{"text": "This validates the theory behind this form of VTLN , however , it should be noted that this form of VTLN is computationally expensive , and good performance can only be achieved if the recognition system correctly identifies the precise scaling factor for every speaker .", "label": "", "metadata": {}, "score": "67.24983"}
{"text": "However , in this case , text query terms are associated directly with the content of the audio , and no text annotations or other metadata are used at retrieval time .At training time , a set of labelled sound documents is used , allowing the system to learn to match the acoustic features of a lion 's roar to the text tag ' lion ' , and similarly for a large set of potential sound - related text queries .", "label": "", "metadata": {}, "score": "67.266136"}
{"text": "Figure 60 shows overall recognition performance as a function of SNR for MFCC features , with and without optimal VTLN , and for the features from the AIM NAP .As in the case of clean speech , performance is low on the standard MFCCs due to their lack of scale - shift invariance , and is high for MFCCs with VTLN .", "label": "", "metadata": {}, "score": "67.28162"}
{"text": "CTMaker - Real - time application generator for unified messaging systems ; supports TAPI , SAPI , sharing information between SQL - databases , emails , web - pages , phones , pagers .Allows development of CTI applications .Free Subscription to Speech Technology - Speech Technology Magazine is recognized worldwide as a source of information on speech technology solutions that are changing communications and technology needs of organizations worldwide .", "label": "", "metadata": {}, "score": "67.36267"}
{"text": "A word recognition processor for processing an input speech utterance in a speech recognition system , comprising : . a phoneme similarity module receptive of said input speech utterance for producing phone similarity data indicative of the correlation between said input speech utterance and predetermined phone model speech data ; . a high similarity module coupled to said phoneme similarity module for identifying those regions of the phone similarity data that exceed a predetermined threshold ; . a region count stage having a first word prototype database for storing similarity region count data for a plurality of predetermined words ; . said region count stage coupled to said high similarity module and generating a first list of word candidates selected from said first word prototype database based on similarity regions ; . a target congruence stage having a second word prototype database for storing word prototype data corresponding to a said plurality of predetermined words ; . said target congruence stage being receptive of said first list of word candidates and being coupled to said high similarity module for generating a second list of at least one word candidate , selected from said first list based on similarity regions .", "label": "", "metadata": {}, "score": "67.37831"}
{"text": "13 - 18 .Burda , A. , Hageman , C.F. , ( 2005 ) , \" Perception of accented speech by residents in assisted - living facilities \" in Journal of Medical Speech - Language Pathology .Burkhardt , D. , Nazemi , K. , Stab , C. , Wichert , R. , Breyer , M. , Fellner , D. W. ( 2011 ) , \" Nat\u00fcrliche Gesteninteraktion mit beschleunigungssensorbasierten Eingabeger\u00e4ten in unterst\u00fctzenden Umgebungen \" in AAL Kongress , Berlin , Germany .", "label": "", "metadata": {}, "score": "67.415054"}
{"text": "For example , a sound source directly in front of the listener would maximally excite coincidence detectors in the middle of the array ( with zero relative delay ) , whilst a highly lateralized source at the sides would excite detectors at one edge of the array .", "label": "", "metadata": {}, "score": "67.4785"}
{"text": "Such systems look ahead to see if there is a larger peak within some fixed time after the current candidate .An alternative approach is to have a strobe ' lockout ' that occurs after a strobe is issued , that prevents the system from issuing a strobe for some fixed period of time .", "label": "", "metadata": {}, "score": "67.52381"}
{"text": "2 is a diagram showing the integration of multiple stages of word hypothesization with a fine match procedure ; .FIG .3 is a series of graphs showing the output of the region picking procedure whereby similarity values are converted into high similarity regions ; .", "label": "", "metadata": {}, "score": "67.62267"}
{"text": "This results in higher noise robustness when compared with using a magnitude spectrum estimate as used in the ETSI basic front - end [ 12 ] .The two front - ends both generate a feature vector consisting of 14 coefficients made up of the frame log - energy measure ( determined prior to pre - emphasis ) and cepstral coefficients C 0 to C 12 .", "label": "", "metadata": {}, "score": "67.65169"}
{"text": "A non - linearity in the form of a logarithm followed by a DCT is applied to the filter outputs to generate the cepstral coefficients .The recognition experiments use vectors that include energy and 12 cepstral coefficients ( C 1 to C 12 ) along with velocity and acceleration coefficients .", "label": "", "metadata": {}, "score": "67.71895"}
{"text": "In the case of the basic front - end , pre - emphasis is carried out using a filter coefficient equal to 0.97 while the advanced front - end uses a value of 0.9 .A Hamming window is used in both the ETSI basic and advanced front - ends prior to taking an FFT .", "label": "", "metadata": {}, "score": "67.72473"}
{"text": "247 - 252 .Ivanecky , J. , Mehlhase , S. , Mieskes , M. ( 2011 ) , \" An Intelligent House Control Using Speech Recognition with Integrated Localization \" in AAL Kongress , Berlin , Germany .Jurafsky , D. , Martin J.H. ( 2009 ) , Speech and Language Processing : An Introduction to Natural Language Processing , Speech Recognition , and Computational Linguistics , 2nd edition , Prentice - Hall .", "label": "", "metadata": {}, "score": "67.76649"}
{"text": "Scaling is as in Figure 79 so that dynamic range can be compared .Figure 80 and Figure 81 show the responses of the PZFC , dcGC and gammatone filterbanks to a two - formant synthetic vowel that changes rapidly in level over the course of a second .", "label": "", "metadata": {}, "score": "67.82889"}
{"text": "Chapter 4 describes the generation of noise - robust auditory features by use of the stabilised auditory image ( SAI ) generated by AIM .The process of strobed temporal integration in AIM is found to create features which are more roust to interfering noise than simple spectral features .", "label": "", "metadata": {}, "score": "67.83306"}
{"text": "In the latter case , the participants were asked to provide input commands to the system without a structured dialog .The free input of appointments was preferred by 58 % , the structured by the rest .On the one side , some reasons for preferring free input are i ) input is more familiar , ii ) higher flexibility , iii ) more individual , and iv ) less complicated .", "label": "", "metadata": {}, "score": "67.84747"}
{"text": "Irino , T. and Patterson , R.D. ( 1997 ) .\" A time - domain , level - dependent auditory filter : The gammachirp .\" J. Acoust .Soc .Am . , 101 , p.412 - 419 .[ 1 ] [ 2 ] [ 3 ] .", "label": "", "metadata": {}, "score": "67.87861"}
{"text": "van Dinther , R. and Patterson , R.D. ( 2006 ) .\" Perception of acoustic scale and size in musical instrument sounds .\" J. Acoust .Soc .Am . , 120 , p.2158 - 76 .[ 1 ] [ 2 ] [ 3 ] .", "label": "", "metadata": {}, "score": "67.894714"}
{"text": "14 ] .A comparison of Table 1 with Table 2 shows that Li et al .( I ) outperforms the ETSI basic front - end for all of the speech enhancement techniques evaluated .Furthermore , from Tables 3 and 4 , it is seen that Li et al .", "label": "", "metadata": {}, "score": "67.89554"}
{"text": "Because the approach is computationally costly , it is not well suited to consumer product applications that , for cost reasons , can not use large , powerful processors .The present invention represents a significant departure from current frame - based techniques .", "label": "", "metadata": {}, "score": "67.902534"}
{"text": "\"Acta Acustica , 90 , p.781 - 787 .[ 1 ] .Brandenburg , K. and Stoll , G. ( 1994 ) . \" ISO - MPEG-1 Audio : A generic standard for coding of high - quality digital audio . \"", "label": "", "metadata": {}, "score": "67.9104"}
{"text": "We implemente ... . \" ...This paper investigates error - corrective language modeling using the perceptron algorithm on word lattices .The resulting model is encoded as a weighted finite - state automaton , and is used by intersecting the model with word lattices , making it simple and inexpensive to apply during decoding .", "label": "", "metadata": {}, "score": "67.92551"}
{"text": "Figure 24 --- Recognition results for the syllables database using optimally VTL - warped MFCC features .Performance is consistently good across the whole range of speakers because prior information about the VTL of the speaker is provided when computing the features .", "label": "", "metadata": {}, "score": "67.92763"}
{"text": "Durlach N I , Colburn H S , 1978 \" Binaural phenomena , \" in Handbook of Perception , Eds E C Carterette and M P Friedman ( New York : New York ) pp 365 - 466 .Jeffress L A , 1948 \" A place theory of sound localization , \" J Comp Physiol Psychol 41 , 35 - 39 .", "label": "", "metadata": {}, "score": "67.95733"}
{"text": "In FIG .4 the high similarity region extraction module 16 performs the peak driven procedure .The output of the HS region extraction module is supplied to 2 different word hypothesizer stages that operate using different hypothesizer techniques to provide a short list of word candidates for the fine match final recognizer stage 26 .", "label": "", "metadata": {}, "score": "67.97568"}
{"text": "At 10Hz , the sounds were below the lower limit of pitch , but subjects were still able to detect the vowel type from the individual pulses and resonances .Smith et al .found that combined recognition performance fell to 50 % ( still better than chance ) only at the very far extremes of the GPR and VTL range , despite the fact that these are well outside the range of normal experience .", "label": "", "metadata": {}, "score": "67.98612"}
{"text": "For example , the quasi - logarithmic mel frequency scale employed by mel - frequency cepstral coefficient ( MFCC ) features ( which are ubiquitous in content - based audio analysis ) is based on observations about human pitch perception .However machine hearing is based far more upon the systematic application of knowledge and results from the study of human hearing to audio analysis problems .", "label": "", "metadata": {}, "score": "67.992516"}
{"text": "I worked on the initial design and much of the early infrastructure code with Willem van Engen , a Masters student whom I supervised in 2006 .Both AIM - MAT and AIM - C have a modular architecture .The individual stages of the auditory image model ( PCP , BMM , NAP , Strobes and SAI ) are implemented as separate , interchangeable modules .", "label": "", "metadata": {}, "score": "67.9929"}
{"text": "15 - R. Flynn and E. Jones , \" A comparative study of auditory - based front - ends for robust speech recognition using the Aurora 2 database \" , in Proc .IET Irish Signals and Systems Conference , Dublin , Ireland , 28 - 30 June 2006 , pp . 111 - 116 .", "label": "", "metadata": {}, "score": "68.0455"}
{"text": "These results clearly point the direction for further research into the use of auditory models for content - based audio analysis tasks .The next step will be to explore whether it is possible to improve recognition performance on the SSI to bring it in line with that on the NAP alone .", "label": "", "metadata": {}, "score": "68.08351"}
{"text": "This leads to a representation which is very similar to a correlogram .The next simplest is to issue a strobe on each local maximum in the NAP --- the ' peak ' strobe criterion .In this case as well , much of the asymmetry in the NAP is not preserved in the auditory image generated , leaving a representation that looks similar to a correlogram , once again .", "label": "", "metadata": {}, "score": "68.08533"}
{"text": "Stevens , S. , Volkmann , J. and Newman , E. ( 1937 ) .\"A scale for the measurement of the psychological magnitude pitch .\" J. Acoust .Soc .Am . , 8 , p.185- .[ 1 ] .", "label": "", "metadata": {}, "score": "68.0902"}
{"text": "ASA 127th Meeting M.I.T. 1994 June 6 - 10 .2pSP43 .Phonetic transition modeling for continuous speech recognition .Michael Phillips .James Glass .Spoken Language Systems Group , Lab . for Comput .Sci . , MIT , 545 Technology Sq . , Cambridge , MA 02139 .", "label": "", "metadata": {}, "score": "68.15752"}
{"text": "3820 - 3823 .31 - P. Mayorga , L. Besacier , R. Lamy and J. F. Serignat , \" Audio packet loss over IP and speech recognition \" , in Proc . of IEEE Workshop on Automatic Speech Recognition and Understanding ( ASRU ) , Nov. 2003 , pp .", "label": "", "metadata": {}, "score": "68.17757"}
{"text": "Besides multimodality , multilinguality facilitates not only human - human , but also human - computer interaction .2 Multilinguality is enabled through translation .Translation , in general , facilitates communication between people in different locales .Using intelligent devices of AAL in crosslingual environments means not only that user interfaces are multilingual , but also that speech - to - speech translation systems should be implemented .", "label": "", "metadata": {}, "score": "68.18302"}
{"text": "SSIs were generated from the input sounds using AIM - C , and MFCCs were generated using HTK , as before .The four different types of SSI features ( whole SSI profiles and cycle-1 slices , with and without the pitch cutoff ) were computed for all SNRs .", "label": "", "metadata": {}, "score": "68.18407"}
{"text": "Sound ranking .Using the process in the above stages , a sparse vector is computed for each of the individual boxes tiling the image .These vectors are then concatenated to yield a higher - dimensional sparse feature vector that summarises the entire SAI .", "label": "", "metadata": {}, "score": "68.19274"}
{"text": "\" J. Acoust .Soc .Am . , 123 , p.3339 .[ 1 ] .Fitch , W.T. and Giedd , J. ( 1999 ) . \"Morphology and development of the human vocal tract : A study using magnetic resonance imaging .", "label": "", "metadata": {}, "score": "68.1987"}
{"text": "This is an important and notable step forward in the field .Previously the use of AIM had been limited to the analysis of small datasets .The system described is able to process days of audio data in a matter of a few hours by the combination of efficient code and large computing resources .", "label": "", "metadata": {}, "score": "68.242874"}
{"text": "Single - source stimuli .In the first experiment , a 200ms click train with 8ms between clicks was used as the input stimulus to a set of filterbanks and strobing algorithms .Each system was assessed with a percentage score for the proportion of windowed sections with exactly one strobe in each channel , and an overall number of strobes per pulse in each channel .", "label": "", "metadata": {}, "score": "68.24802"}
{"text": "This effect is visible in some panels of Figure 89 , where the temporal profile is ' clipped ' at the low - lag end .Figure 85 shows how the measure is calculated from the peak and adjacent troughs .Comparison to human pitch perception .", "label": "", "metadata": {}, "score": "68.25833"}
{"text": "The question of how best to transform the SSI from a pitch - invariant , scale - shift covariant representation to a pitch - invariant , scale - shift invariant representation is still an open one .The Mellin image ( Irino and Patterson , 2002 ) has been suggested as a possible scale - shift invariant representation .", "label": "", "metadata": {}, "score": "68.26181"}
{"text": "Since this behaviour is not possible , the amplitudes of the components have to change as the source size changes , and they do so non - monotonically .The problem remains that the individual cepstral coefficients all contain a mixture of both vowel - type and VTL information .", "label": "", "metadata": {}, "score": "68.32156"}
{"text": "front - end .The Li et al .front - end , combined with speech enhancement , still outperforms the ETSI advanced front - end in the presence of vector quantisation although the improvement in overall word error rate is reduced from 8 % ( without vector quantisation ) to 5.3 % .", "label": "", "metadata": {}, "score": "68.33696"}
{"text": "Furthermore , there are also modules in AIM - C for the generation of the box - cutting features and sparse codes .Many of the AIM - C modules have been ported to the Marsyas framework for music analysis by Steven Ness , and indeed the sparse features from box - cutting were used as the basis for an entry to the 2010 MIREX music genre classification challenge .", "label": "", "metadata": {}, "score": "68.360535"}
{"text": "The dynamic range of audio signals is orders of magnitude larger than the dynamic range available to encode those signals in the auditory nerve .This means that the auditory system has to perform some sort of compression on the incoming signal in order to represent it effectively with a neural code .", "label": "", "metadata": {}, "score": "68.36401"}
{"text": "Results .shows the mean results from application of the pitch strength estimation algorithm to 20 randomly generated IRN stimuli using the above parameters .It is clear from these results that the dcGC gives rise to a considerably stronger pitch feature in the temporal profile of an IRN stimulus than do the other filterbanks .", "label": "", "metadata": {}, "score": "68.44417"}
{"text": "This is a representation in which sounds that are perceived as stable by humans give rise to stable auditory images .The SAI is a ' movie ' with 2-dimensional frames along the time dimension ; each frame has two dimensions : cochlear channel and time interval .", "label": "", "metadata": {}, "score": "68.50262"}
{"text": "Notes : submitted .OriginalCiteRef : .[ 1 ] .Patterson , R.D. , Yost , W.A. , Handel , S. and Datta , A.J. ( 2000 ) .\" The perceptual tone / noise ratio of merged iterated rippled noises .", "label": "", "metadata": {}, "score": "68.51376"}
{"text": "\"Size Information in the Production and Perception of Communication Sounds \" , in Auditory Perception of Sound Sources , Yost , W.A. , Popper , A.N. and Fay , R.R. editors ( Springer Science+Business Media , LLC , New York ) .", "label": "", "metadata": {}, "score": "68.53426"}
{"text": "This performance was achieved after 15 iterations of the training algorithm .For the AIM features , the optimum recognition performance was 93.2 % across all syllables using an HMM with 2 emitting states , 6 output distribution components and after 10 training iterations .", "label": "", "metadata": {}, "score": "68.55259"}
{"text": "The final stage of encoding ( 4 ) is to create a histogram of the sparse - code vectors over the period of interest in the audio .This yields a high - dimensional , but still fairly sparse representation of the audio .", "label": "", "metadata": {}, "score": "68.60718"}
{"text": "The word recognition processor of claim 1 wherein said high similarity module produces a parameterized representation of high similarity regions of the phone similarity data .The word recognition processor of claim 8 wherein said parameterized representation includes a representation of the phone similarity peak location and peak height .", "label": "", "metadata": {}, "score": "68.61308"}
{"text": "In the next paragraphs we focus only on multilinguality provided by our platform ; the other two items are outside the scope of this paper .61 Ourplatformcombines ASR , MT , and TTS tools .This unique platform is initially tested in the wheelchair Rolland and later can be implemented in intelligent devices in assisted living environments , such as beds , kitchen drawers , and electronic appliances .", "label": "", "metadata": {}, "score": "68.70742"}
{"text": "In future work , the relative benefits of the two approaches could be compared .A further alternative to the Gaussian mixtures might be to use the Fourier transform , rather than the cosine transform , to generate MFCC - like features in which the phase of the components is allowed to vary , as in the Mellin transform described in chapter 4 .", "label": "", "metadata": {}, "score": "68.779854"}
{"text": "The ASR application they used is Microsoft SAPI 5.1 in command mode .The command node used Context Free Grammar ( CFG ) grammars to recognize single words and short phrases .The CFG format in SAPI 5 defines the structure of grammars and grammar rules using XML .", "label": "", "metadata": {}, "score": "68.78277"}
{"text": "In addition , the AIM - SAI representation was used with otherwise default parameters .The values of all the experimental parameters used are shown in .In one group of experiments we varied the details of the box - cutting step .", "label": "", "metadata": {}, "score": "68.811386"}
{"text": "Acoustic models are not related only with acoustics and phonetics , but also with gender and dialect difference among speakers .10 As far as the history of speech recognition is concerned , in the early 1960s IBM developed and demonstrated Shoebox , a forerunner of today 's voice recognition systems .", "label": "", "metadata": {}, "score": "68.81256"}
{"text": "Therefore , an implementation of the Generalized Lloyd Algorithm ( GLA ) , described by [ 39 ] , was used to design the VQ codebooks for both the ETSI advanced front - end and the front - end of Li et al .", "label": "", "metadata": {}, "score": "68.81377"}
{"text": "In the case of the real stimuli , it is possible to generate stimuli with known pulse times by first analysing the signal with STRAIGHT , and then re - synthesising with a known pitch track .Examples of the various synthetic stimuli and associated pulse times are shown in Figure 46 and Figure 47 .", "label": "", "metadata": {}, "score": "68.82287"}
{"text": "Methods .Using the synthetic stimuli detailed above , it is possible to test the various strobing systems on some basic criteria .We are interested in how many strobes there are in each channel for each pulse of the input sound , and what proportion of the pulses are correctly strobed upon .", "label": "", "metadata": {}, "score": "68.87352"}
{"text": "Rather the features demonstrate a macroscopic property of the auditory system .In the following chapter , I look in detail at a proposed model of the processing performed in the early stages of the auditory pathway .The auditory image model ( AIM ) describes a process of strobed temporal integration in which signals from the cochlea are ' stabilised ' with respect to the pulses in the input sound in order to generate a stabilised auditory image ( SAI ) , which changes over time .", "label": "", "metadata": {}, "score": "68.886154"}
{"text": "In the system described here , the information in the cochleogram is summarised by its spectral profile and fitted with a mixture of Gaussians , and several constraints are applied to ensure that they fit only large and well - spaced spectral peaks .", "label": "", "metadata": {}, "score": "68.88661"}
{"text": "History and Future of Auditory Filter Models . \"OriginalCiteRef : .Booktitle : IEEE International Symposium on Circuits and Systems , 2010 .ISCAS 2007 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] .", "label": "", "metadata": {}, "score": "68.92775"}
{"text": "The data are replotted from chapter 2 in Figure 57 for comparison .So , in clean speech , overall performance with NAP - based features is somewhat better than for SSI - based features derived from the whole SSI .Figure 57 --- Scaled syllable recognition performance on the original NAP - based features .", "label": "", "metadata": {}, "score": "68.95043"}
{"text": "Additionally , interleaving , a technique used to reduce feature vector loss burst lengths ( with a penalty of additional delay ) , is also briefly discussed .Interleaving is carried out on the client side of a DSR system , with de - interleaving on the server side .", "label": "", "metadata": {}, "score": "68.969864"}
{"text": "The word recognition processor of claim 1 wherein said region count stage represents an instance of a given spoken word or phrase by the number of high similarity regions found corresponding to each of a plurality of phoneme identifiers .The word recognition processor of claim 11 further comprising means for breaking said phone similarity data into a plurality of time intervals and wherein said instance of a given spoken word or phrase is represented by the number of high similarity regions in each of said time intervals .", "label": "", "metadata": {}, "score": "68.987"}
{"text": "Strobe points are identified in each channel of the filterbank output , and these points act as triggers for a temporal integration process in which shifted copies of the signal are overlaid on one another .Since strobe points tend to occur at or near the pulses in a pulse - resonance sound , representing a signal containing a pulse - resonance sound as an SAI will tend to accentuate the periodic , pulse - resonance components of a signal relative to any background noise .", "label": "", "metadata": {}, "score": "68.98888"}
{"text": "This version added the ' bunt ' and ' parabola ' mechanisms in addition to the strobe criteria from AIM92 .Figure 30 , Figure 31 , Figure 32 , Figure 33 and Figure 34 show the form of threshold in each of the various strobe algorithms employed in AIM1992 and AIM - MAT .", "label": "", "metadata": {}, "score": "68.98911"}
{"text": "Ruggero , M.A. , Robles , L. and Rich , N.C. ( 1992 ) .\" Two - tone suppression in the basilar membrane of the cochlea : Mechanical basis of auditory - nerve rate suppression .\" J. Neurophysiol ., 68 , p.1087 - 1099 .", "label": "", "metadata": {}, "score": "69.005646"}
{"text": "The upper formants of the vowel sounds are now more clearly visible .Although this effect of increased compression has a positive effect on pitch strength , it may in fact degrade the output signal , giving low - level features too much weight relative to high - level ones .", "label": "", "metadata": {}, "score": "69.03888"}
{"text": "6 - \" Speech Processing , Transmission and Quality Aspects ( STQ ) ; Distributed speech recognition ; Front - end feature extraction algorithm ; Compression algorithms \" , in ETSI ES 201 108 , Ver .1.1.3 , Sept. 2003 .", "label": "", "metadata": {}, "score": "69.06628"}
{"text": "Moreover , the cultural background of gestures should be taken into account when developing or adapting recognition software .We plan to conduct a survey regarding how people in different locales make gestures for various purposes ( spatial or device controlling ) .", "label": "", "metadata": {}, "score": "69.102394"}
{"text": "It is also important to note that , with the scale - shift invariant features , only one feature vector is required per utterance .A system with optimal VTLN requires a feature vector to be computed for all candidate warpings of the frequency axis , and the optimal warping has to be identified in a separate recognition step .", "label": "", "metadata": {}, "score": "69.14459"}
{"text": "Santo Pietro , M.J. , Ostuni , E. ( 1997 ) , Successful communication with Alzheimer 's Disease Patients - An In - service Manual .Boston : MA , Butterworth - Heinemann .Theobalt , C. Bos , J. Chapman , T. Espinosa - Romero , A. Fraser , M. Hayes , G. Klein , E. Oka , T. Reeve .", "label": "", "metadata": {}, "score": "69.15454"}
{"text": "The algorithm learns from one observation at a time , and it is capable of learning from a noisy corpus of observed natural language .The perceptron algorithm learns a set of numeric , weighted constraints ( a Harmonic Grammar ) .", "label": "", "metadata": {}, "score": "69.19926"}
{"text": "The algorithm learns from one observation at a time , and it is capable of learning from a noisy corpus of observed natural language .The perceptron algorithm learns a set of numeric , weighted constraints ( a Harmonic Grammar ) .", "label": "", "metadata": {}, "score": "69.19926"}
{"text": "The system uses sparse features computed from the SAI , and learns a mapping from these audio feature vectors to a sparse feature vector representing words associated with the sound .In the experiments , two versions of the SAI are used : the ' Lyon - SAI ' and the ' AIM - SAI ' .", "label": "", "metadata": {}, "score": "69.23763"}
{"text": "Temporal averaging is performed in a ' smart ' way - such that there is no ' beating ' between the windowing function and the pulse rate of the incoming signal ( Kawahara and Irino , 2004 ) .By contrast , noises which have no temporal regularity will not be reinforced in this way , and will appear at a lower level relative to the pulse - resonance sounds since they will not , in general , interfere constructively .", "label": "", "metadata": {}, "score": "69.34551"}
{"text": "The output is then translated by a hybrid MT ( RBMT and SMT ) .Trippo VoiceMagix 53 : it uses speech technology by Nuance Communications ; Speech input is US English and supports 27 languages .29 Dialog systems are widely used to decrease human workload in telephony applications , for example in call centres .", "label": "", "metadata": {}, "score": "69.372574"}
{"text": "However , how a system performs in noise is also an important consideration for practical speech recognition .As discussed above , the SSI is expected to provide a representation of the input signal which is more robust to interfering noise than a purely spectral representation like the smoothed NAP profile or the mel - frequency spectrum .", "label": "", "metadata": {}, "score": "69.41838"}
{"text": "This figure was redrawn from a figure by Ralph van Dinther .Used with permission .The SSI is calculated from the SAI by taking the signal in each channel , and truncating it to leave the portion between zero - lag and the first peak associated with the next excitation pulse , that is the peak that completes the pitch period .", "label": "", "metadata": {}, "score": "69.47127"}
{"text": "We demonstrate that transformation - based learning can be used to correct noisy speech recognition transcripts in the lecture domain with an average word error rate reduction of 12.9 % .Our method is distinguished from earlier related work by its robustness to small amounts of training data , and its resulting efficiency , in spite of its use of true word error rate computations as a rule scoring function . \" ...", "label": "", "metadata": {}, "score": "69.62298"}
{"text": "A candidate system : Event - time back - projection .Given knowledge of the rise time and decay characteristics of the filter , it is possible to make an estimate of when an event occurred based on the amplitudes and timings of consecutive peaks of the NAP .", "label": "", "metadata": {}, "score": "69.62553"}
{"text": "While this system is extremely effective at ' back - projecting ' to find the original strobe time , it is inefficient and so can not be used in a large - scale machine hearing system at this point in time .", "label": "", "metadata": {}, "score": "69.640305"}
{"text": "6 for the different stages and combinations in the system .The output of the hypothesizer ( list of top 5 word candidates ) shows no critical deterioration ( 99.6 % accuracy ) even when compared to original fine match alone ( 99.3 % accuracy for top 5 candidates ) .", "label": "", "metadata": {}, "score": "69.64747"}
{"text": "Each subfigure of Figure 8 shows the waveform from a different speaker uttering the vowel sound .In the lower subfigures , the waveforms have a resonance rate of 89 % of that of the original speaker .This corresponds to a person with a VTL of approximately 17.5 cm or of height of 194 cm .", "label": "", "metadata": {}, "score": "69.66024"}
{"text": "Figure 56 --- Scaled syllable recognition performance on the full SSI profile with the pitch cutoff .Figure 55 shows the performance of the whole - SSI features with no pitch cutoff on the syllable database .Performance is 84.8 % overall , falling to a low of 31.6 % at the shortest VTL .", "label": "", "metadata": {}, "score": "69.728096"}
{"text": "( II ) , generates a feature vector that contains the cepstral coefficients C 1 to C 12 along with a weighted combination of cepstral coefficient C 0 and the frame log - energy measure .The reason for investigating two versions of the Li et al .", "label": "", "metadata": {}, "score": "69.732956"}
{"text": "Gestures are also synthetic because one gesture can combine many meanings , while in language the relationship of words to meaning is analytic , that means that distinct meanings are attached to distinct words .One interesting observation about the syntactic relationship between speech and co - speech gestures in multimodal grammar is explored by Fricke ( 2009 ) .", "label": "", "metadata": {}, "score": "69.77846"}
{"text": "To create the noisy data set , the syllables in the database were mixed with pink ( 1 / f ) noise using the ' sox ' sound processing tool .The normalised RMS level of the voiced portion of the syllable was used as the reference level to establish SNR .", "label": "", "metadata": {}, "score": "69.79933"}
{"text": "In the baseline case , 256 means were used for the k - means clustering .Once the codebooks are trained , encoding a dense feature vector is simply a matter of assigning it to the closest cluster in the codebook .", "label": "", "metadata": {}, "score": "69.82771"}
{"text": "Section 3 addresses the problem of robustness of speech recognition systems in the presence of additive noise , in particular , by examining in detail the use of speech enhancement techniques to reduce the effects of noise on the speech signal .", "label": "", "metadata": {}, "score": "69.84169"}
{"text": "To extend the gammatone , Irino and Patterson ( 1997 ) derived the gammachirp filter as the minimum - uncertainty operator for a joint time - scale representation of signals ( Cohen , 1993 ) .The derivation is analogous to that of the Gabor function as the minimum - uncertainty operator for a joint time - frequency representation .", "label": "", "metadata": {}, "score": "69.85208"}
{"text": "Users feel more secure and friendlier towards intelligent machines .60 In order to mitigate the limitation ii .we mentioned above , we develop a platform where ASR , MT , and TTS systems are combined .It is a distinct SST system , as the difference between our designed SST system and other traditional SST systems is that the output is in the source language ( usually mother tongue of the user ) and not in the target language .", "label": "", "metadata": {}, "score": "69.926025"}
{"text": "Previous work demonstrated that a simple word - for - word channel model was sufficient to yield substantial increases in word accuracy .This paper demonstrates that some improvements in word accuracy result from augmenting the channel model with an account of word fertility in the channel .", "label": "", "metadata": {}, "score": "70.00863"}
{"text": "Pulse - resonance communication sounds are used as a primary means of communication , in one form or another , by most animals .They are the calls of a Jamaica weakfish ( Cynoscion jamaicensis ) , a North American bullfrog ( Rana catesbeiana ) , a macaque ( Macaca mulatta ) and a human adult saying the syllable /ma/. All the sounds in the figure may be heard on the CNBH acoustic scale wiki .", "label": "", "metadata": {}, "score": "70.193726"}
{"text": "For each of the variants , the spectral profiles of successive image frames were fitted using the Gaussian fitting procedure described in chapter 2 .This generates a 4-dimensional feature vector , containing the three relative weights of the Gaussians and a total energy term , as before .", "label": "", "metadata": {}, "score": "70.1944"}
{"text": "Since the SAI profiles were truncated at 0.5ms ( the standard parameter for the ti2003 AIM - MAT module ) , this led in many cases to the peak due to the repetition rate being the highest point in the temporal profile .", "label": "", "metadata": {}, "score": "70.2002"}
{"text": "Fine match word recognition is performed in stage 26 .Unlike the word hypothesizer 14 , the word recognizer stage 26 uses the phoneme similarity time series directly in a frame - by - frame , dynamic programming match on the list of 5 word candidates given by the hypothesizer .", "label": "", "metadata": {}, "score": "70.208"}
{"text": "A potential way of countering this effect would be to make a ' softer ' pitch decision ; this could take the form of a simple roll - off function that is applied to the edge of the SSI ( for example a tanh window ) .", "label": "", "metadata": {}, "score": "70.28908"}
{"text": "A standard approach in such systems is to make two passes over the input waveform .In the first pass , the un - normalised version of the signal is used , and then in the second pass , the system attempts to find the optimal warping to improve recognition .", "label": "", "metadata": {}, "score": "70.330154"}
{"text": "In practice , this system modifies the thresholding functions from previous systems to include two filter - dependent parameters : the decay rate ( and trajectory ) , and the ' look - ahead ' time , which is determined by the rise time of the filter .", "label": "", "metadata": {}, "score": "70.35549"}
{"text": "Unoki , M. , Irino , T. , Glasberg , B. , Moore , B.C. and Patterson , R.D. ( 2006 ) .\" Comparison of the roex and gammachirp filters as representations of the auditory filter .\" J. Acoust .", "label": "", "metadata": {}, "score": "70.36205"}
{"text": "To compute the AIM features for the entire scaled syllables database of around 10,000 600ms sounds ( 100 minutes of audio ) takes approximately 160 minutes of CPU time on a modern , single - core computer .By comparison , it takes just 5 minutes to compute the MFCC features using the same system , so the AIM features are approximately 32 times more costly to compute .", "label": "", "metadata": {}, "score": "70.37215"}
{"text": "Journal : unpublished .OriginalCiteRef : Ldraft96 .[ 1 ] .Lyon , R.F. ( 1997 ) .\" All - pole models of auditory filtering \" , in Diversity in Auditory Mechanics , E. R. Lewis , S.C. and Lyon , R.F. editors , p.205 - 211 ( World Scientific Publishing , Singapore ) .", "label": "", "metadata": {}, "score": "70.37602"}
{"text": "To find the response of a driven filter , the envelope derived above can simply be processed in the same way as the output signal is .Using the constraints described above , it is fairly simple to modify the parameters of some of the existing strobing systems to fulfil these constraints .", "label": "", "metadata": {}, "score": "70.40535"}
{"text": "MT with Babelfish is also possible as a potential next step .25 It should be pointed out that various companies sell different voices for different locales .Some examples are A&T Natural Voices , Nuance Real Speak and so on .", "label": "", "metadata": {}, "score": "70.417595"}
{"text": "In this analysis , I have placed assumptions implicit in previous strobe detection systems on a firmer theoretical basis , and confirmed that the choice of constants made for these systems was reasonable .While the improvement gained by the ' constrained threshold ' system described here over previous systems is small , the understanding of filterbank dynamics should prove useful for the development of future strobe detection systems .", "label": "", "metadata": {}, "score": "70.43215"}
{"text": "This is an important feature of the SAI , as temporal asymmetry is a key feature of pulse - resonance sounds ( Patterson and Irino , 1998 ) .Figure 14 shows correlograms for the four vowel sounds .The zero - lag line is at the left of the image .", "label": "", "metadata": {}, "score": "70.44006"}
{"text": "The second property is that , over a wide range of values , it is scale invariant with respect to the message : the same message can be perceived over a range of time - scalings of the input signal .Time - shift invariance may seem obvious , but it is an important property of the system and leads to certain mathematical constraints .", "label": "", "metadata": {}, "score": "70.513916"}
{"text": "1.1.5 , Jan. 2007 . 8 - \" Speech Processing , Transmission and Quality Aspects ( STQ ) ; Distributed speech recognition ; Extended front - end feature extraction algorithm ; Compression algorithms ; Back - end speech reconstruction algorithm \" , in ETSI ES 202 211 , Ver .", "label": "", "metadata": {}, "score": "70.51965"}
{"text": "The challenge for ASR systems here would be the prosody of the elderly .ASR software works usually with clear voice and short and distinct sentences which is often not the case with elderly 's speech .Thus in our future prospects belongs to train acoustic models with voices of older people ; we will use VoxForge project for this purpose .", "label": "", "metadata": {}, "score": "70.5526"}
{"text": "( 2006 ) .Panel ( a ) shows the absolute frequency response of the filters as a function of stimulus level .Panel ( b ) shows the responses of the component filters of the cGC .The solid lines show the response of the passive gammachirp filter , and the dotted lines show the response of the active filter .", "label": "", "metadata": {}, "score": "70.55374"}
{"text": "Conclusions .Performance with the new strobe finding mechanisms based either on ' constrained thresholding ' or ' event time back - projection ' shows some slight improvements over previous systems .However , the change is not that great , and the ' local maximum ' variant of the ' temporal shadow ' strobe criterion performs almost as well as the new mechanisms in many cases .", "label": "", "metadata": {}, "score": "70.55934"}
{"text": "Scale - shift invariant representations .Benzeghiba et al .( 2007 ) cite a number of alternative approaches to VTLN .Most of these approaches involve some form of warping of the frequency axis or the normalisation of the frequency spectrum to some ' canonical ' speaker .", "label": "", "metadata": {}, "score": "70.57197"}
{"text": "32 - J. Vicente - Pe\u00f1a , G. Gallardo - Antol\u00edn , C. Pel\u00e1ez - Moreno and F. D\u00edaz - de - Mar\u00eda , \" Band - pass filtering of the time sequences of spectral parameters for robust wireless speech recognition \" , Speech Communication , vol .", "label": "", "metadata": {}, "score": "70.604774"}
{"text": "The system was implemented in AIM - MAT as described , but is not intended for use in a large - scale system .It is compared against the alternative systems below .In preliminary testing of this system , the default parameters of the ' local maximum ' strobe threshold ( 5ms lockout , 20ms decay time ) were found to work well for all filterbanks apart from the PZFC .", "label": "", "metadata": {}, "score": "70.64271"}
{"text": "The method of claim 16 wherein said region count procedure produces a first score corresponding to the degree of fit between the input utterance and each of the first list of word candidates ; . wherein said target congruence procedure produces a second score corresponding to the degree of fit between the input utterance and each of the second list of word candidates ; and .", "label": "", "metadata": {}, "score": "70.65352"}
{"text": "The congruence score of a matched target CG match , that is , the alignment found between target t of the prototype and region r of the test word , is defined as . where A t and A r respectively represent the target 's area and the aligned region 's area in the time similarity plane .", "label": "", "metadata": {}, "score": "70.68175"}
{"text": "1996 ) .The approach to planning , which is interesting for its emphasis on plan modification and i .. by James F. Allen , Bradford W. Miller , Eric K. Ringger , Teresa Sikorski - In 34th Meeting of the Association for Computational Linguistics , 1995 . \" ...", "label": "", "metadata": {}, "score": "70.691605"}
{"text": "We describe and compare the two learning algorithms in detail and use a held out set of empirical data to quantitatively evaluate each .We show that by allowing for so - called ganging - up - effects , the more expressive Harmonic Grammar models Czech Word Order more accurately than the GLA OT grammar .", "label": "", "metadata": {}, "score": "70.707466"}
{"text": "We describe and compare the two learning algorithms in detail and use a held out set of empirical data to quantitatively evaluate each .We show that by allowing for so - called ganging - up - effects , the more expressive Harmonic Grammar models Czech Word Order more accurately than the GLA OT grammar .", "label": "", "metadata": {}, "score": "70.707466"}
{"text": "The word recognition processor of claim 13 wherein said region count prototype consists of statistics based on the number of high phoneme similarity regions found for each phoneme identifier in each of a plurality of time intervals .The word recognition processor of claim 14 wherein said statistics comprise the mean and inverse variance of the number of said high phoneme similarity regions found for each phoneme identifier in each of said plurality of time intervals .", "label": "", "metadata": {}, "score": "70.70936"}
{"text": "In the absence of any succeeding strobes , the process continues for 35ms and then terminates .If more strobes appear within 35 ms , as they usually do in music and speech , then each strobe initiates a new temporal integration process .", "label": "", "metadata": {}, "score": "70.75263"}
{"text": "\" J. Acoust .Soc .Am . , 117 , p.305 - 318 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] .Smith , D.R.R. , Walters , T.C. and Patterson , R.D. ( 2007 ) . \"", "label": "", "metadata": {}, "score": "70.76991"}
{"text": "The model can generalise , producing a smooth r ... \" .In much experimental phonetics the concept of a vowel space is discussed .The density of points within this vowel space can be modelled using a mixture gaussian density function .", "label": "", "metadata": {}, "score": "70.80424"}
{"text": "Dimensionality reduction .The transforms that convert a sound into an auditory image are intended to project the incoming signal into a space where pulse - resonance sounds are enhanced relative to background noise , and changes in acoustic scale leave the pattern of information largely unchanged , save for a spatial shift .", "label": "", "metadata": {}, "score": "70.83447"}
{"text": "This suggests that the normalisation mechanisms at work may be the same for human voices and for other pulse - resonance sounds .The problem of automatic vocal tract length normalisation ( VTLN ) is an area of active research in speech recognition .", "label": "", "metadata": {}, "score": "70.892426"}
{"text": "Through the years MT systems have been faster and with higher accuracy .Lately many FOSS MT tools have made their appearance .17 There is a plethora of MT systems nowadays , both proprietary and open - source .A good distinction between these two can be found in Forcada ( 2006 : 2 ) .", "label": "", "metadata": {}, "score": "70.90467"}
{"text": "[ 1 ] .Handel , S. and Patterson , R.D. ( 2000 ) .\" The perceptual tone / noise ratio of merged , iterated rippled noises with octave , harmonic , and nonharmonic delay ratios .\" J. Acoust .", "label": "", "metadata": {}, "score": "70.913826"}
{"text": "For a more complete understanding of the invention , its objects and advantages , reference may be had to the following specification and to the accompanying drawings .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a phoneme similarity time series for the word \" hill \" spoken by two speakers ; .", "label": "", "metadata": {}, "score": "70.93982"}
{"text": "Speech enhancement , Hermite interpolation .When interleaving is introduced , the receive side perceives that the average loss burst length is reduced [ 37 ] .Table 14 shows the recognition results obtained when interleaving , with an interleaving depth of 4 , is used in conjunction with Hermite interpolation .", "label": "", "metadata": {}, "score": "70.964554"}
{"text": "Currently , the dcGC is better tuned to these data than the PZFC .However , the experiments above demonstrate that it is possible to manipulate parameters of the PZFC AGC to give better performance on certain real - world tasks .", "label": "", "metadata": {}, "score": "70.9812"}
{"text": "389 - -392 , Glasgow , Scotland ( 1989)].The transition models use a feature vector based on Mel - frequency spectral coefficients ( MFSC 's ) .The vector is created by concatenating multiple spectral averages on both sides of a transition .", "label": "", "metadata": {}, "score": "71.012184"}
{"text": "853 - 856 .35 - A. B. James and B. P. Milner , \" Towards improving the robustness of distributed speech recognition in packet loss \" , in Proc .Second COST278 and ISCA Tutorial and Research Workshop ( ITRW ) on Robustness Issues in Conversational Interaction , University of East Anglia , U.K. , Aug. 2004 , p. paper", "label": "", "metadata": {}, "score": "71.078384"}
{"text": "Baseline recognition results .In order to implement split vector quantization it is necessary to design VQ codebooks for each of the seven coefficient pairs .ETSI has made available script files for the ETSI advanced front - end and included with these are the VQ codebooks for the coefficient pairs .", "label": "", "metadata": {}, "score": "71.21698"}
{"text": "15Last but not least , another research field of ASR regards the development of silent , subvocal speech recognition .As application areas they suggest spacesuits , noisy places like airport towers , or even traditional voice - recognition programs to increase accuracy .", "label": "", "metadata": {}, "score": "71.26484"}
{"text": "The a i j are the transition probabilities and the b i ( o t ) are the emission probabilities .The hidden Markov model toolkit ( HTK ) ( Young et al . , 2005 ) was used as the machine learning system for these experiments .", "label": "", "metadata": {}, "score": "71.27635"}
{"text": "This level estimate is calculated from a linear combination of the original passive filter output , and the output of an asymmetric compensation filter with fixed parameters acting on that output .Figure 78 shows the architecture of the dcGC .The active part is shown for only one channel of the filterbank .", "label": "", "metadata": {}, "score": "71.291565"}
{"text": "This computational efficiency is one of the major practical benefits of strobed temporal integration above autocorrelation .The next , more complex , systems add the decaying threshold to the NAP to decide whether a strobe should be issued or not .", "label": "", "metadata": {}, "score": "71.400055"}
{"text": "The sparse code used to represent an auditory image is based on identifying patterns that typically appear in a SAI , and then representing the image as a histogram of those patterns that could appear .Patterns that are due to certain sound sources are likely to appear at specific positions in the auditory image .", "label": "", "metadata": {}, "score": "71.410034"}
{"text": "The base harmonic complex stimulus ( 0 degrees phase shift , no spectral envelope shift ) was used to further assess the effect of changing the PZFC parameters on the pitch strength measures produced with that filterbank .Temporal smoothing in the PZFC AGC is implemented with a smoothing filter that is convolved with the AGC activity once per sample .", "label": "", "metadata": {}, "score": "71.507675"}
{"text": "DSR avoids both the speech encoding and decoding stages associated with centralised recognition and so eliminates the degradations that originate from the speech compression algorithms .The bandwidth required to transmit the extracted features to the server is much less than what is required to send the encoded speech signal .", "label": "", "metadata": {}, "score": "71.59184"}
{"text": "1109 - 1121 , Dec. 1984 .25 - A. Agarwal and Y.M. Cheng , \" Two - stage mel - warped wiener filter for robust speech recognition \" , in Proceedings of Automatic Speech Recognition and Understanding Workshop , Keystone , Colorado , USA , 1999 , pp .", "label": "", "metadata": {}, "score": "71.64616"}
{"text": "It shows that the designers of the local maximum system were sensible in their choice of constraints , and used values which were already near optimal .The performance of the local maximum and constrained threshold are comparable for single sources .", "label": "", "metadata": {}, "score": "71.647896"}
{"text": "In the auditory image model , stabilised auditory images are produced by strobed temporal integration .An image is built up by repeatedly adding sections of a NAP signal to a buffer .Each time a ' significant ' event or ' strobe ' occurs in the signal , the process restarts , adding the signal following the strobe to the buffer , starting at zero .", "label": "", "metadata": {}, "score": "71.68071"}
{"text": "This expansion is according to a power - law with an exponent of 0.6 .This parameter was again chosen in initial testing with vowel sounds only .Finally , an initialisation stage was introduced distribute the Gaussians across the whole frequency range at the start of the EM process and preclude their converging on specral peaks associated with resolved harmonics of the GPR .", "label": "", "metadata": {}, "score": "71.68446"}
{"text": "However , by learning what makes our own abilities so special , and then applying some of the tricks that we learn to the automated analysis of audio we hope to improve the performance of machine systems which attempt to understand some features of sound .", "label": "", "metadata": {}, "score": "71.6921"}
{"text": "It shows the feature space formed by the 7th , 8th , and 9th cepstral coefficients for the vowel /i/ as VTL varies over the range of human lengths .Whereas the mel - frequency spectrum shifts in an approximately linear way as VTL increases with height , the magnitudes of the individual components change in a nonlinear way .", "label": "", "metadata": {}, "score": "71.69285"}
{"text": "How well does this STRF representation capture timbral identity of musical instruments in continuous solo recordings remains unclear .The current work investigates the applicability of the STRF feature space for instrument recognition in solo musical phrases and explores best approaches to leveraging knowledge from isolated musical notes for instrument recognition in solo recordings .", "label": "", "metadata": {}, "score": "71.70155"}
{"text": "How well does this STRF representation capture timbral identity of musical instruments in continuous solo recordings remains unclear .The current work investigates the applicability of the STRF feature space for instrument recognition in solo musical phrases and explores best approaches to leveraging knowledge from isolated musical notes for instrument recognition in solo recordings .", "label": "", "metadata": {}, "score": "71.70155"}
{"text": "In the comparison of Li et al .( I ) and the ETSI basic front - end , there was no post - processing of the feature vectors carried out .The recognition results using the Aurora 2 database for Li et al .", "label": "", "metadata": {}, "score": "71.71077"}
{"text": "These harmonics are logarithmically spaced on the ERB axis of the auditory filterbank .This leads to the logarithmic spacing of points in the frequency dimension .In the time - interval dimension , the main points of interest are the peaks of the cycles of the impulse response in each channel .", "label": "", "metadata": {}, "score": "71.71173"}
{"text": "By contrast for VTLN , MFCC features would have to be computed with a range of around 10 different VTL warpings and then be passed to a more complex recognition system in order to be useful .The scale - shift \" invariant \" features derived with AIM exhibit some residual sensitivity to change in VTL .", "label": "", "metadata": {}, "score": "71.767914"}
{"text": "A further two non - filter parameters are fitted with parabolic functions , rather than linear functions .These non - filter parameters , K and P 0 , define the efficiency of the detection mechanism following the cochlear filter , and the lower limit on the threshold respectively .", "label": "", "metadata": {}, "score": "71.77106"}
{"text": "If there is a one strobe per section in each channel , then the system is deemed to be working perfectly .For multi - source sounds , this evaluation becomes slightly more complex , as the windows of interest are different for the different sources .", "label": "", "metadata": {}, "score": "71.79511"}
{"text": "Licklider J C R , 1959 \" Three auditory theories \" , in Psychology : A Study of a Science .Study I. Conceptual and Systematic Ed S Koch ( New York : New York ) pp 41 - 144 .McAlpine D , 2005 \" Creating a sense of auditory space \" J Physiol 566 , 21 - 28 .", "label": "", "metadata": {}, "score": "71.82421"}
{"text": "Sprague , M.W. ( 2000 ) .\" The single sonic muscle twitch model for the sound - production mechanism in the weakfish , Cynoscion regalis .\" J. Acoust .Soc .Am . , 108 , p.2430 -2437 .", "label": "", "metadata": {}, "score": "71.83801"}
{"text": "In the case of the pitch - truncated SSI , for higher pitches , the lower - frequency regions of both these profiles may be zeroed - out .This can lead to a discontinuity in the spectral profile at that point .", "label": "", "metadata": {}, "score": "71.84538"}
{"text": "There is currently no known physiological analogue for a mechanism by which gain control information propagates symmetrically out from a point on the basilar membrane to points both higher and lower in frequency .Fitting the PZFC to human masking data .", "label": "", "metadata": {}, "score": "71.85557"}
{"text": "The initial version of AIM , AIM92 , was written by John Holdsworth and Mike Allerhand , with contributions from Christian Giguere and Michael Akeroyd .This version included the ' peak ' , ' temporal shadow ' and ' local maximum ' strobe criteria .", "label": "", "metadata": {}, "score": "71.85762"}
{"text": "The auditory filter is able to compress the peaks of the waveform within a single cycle , and leave the zero - crossings effectively unchanged .Models of auditory filtering attempt to describe mathematically the processing performed by the cochlea on an incoming sound , which ultimately leads to a neural response .", "label": "", "metadata": {}, "score": "71.858536"}
{"text": "Control Methods Used in a Study of the Vowels .\" J. Acoust .Soc .Am . , 24 , p.175 - 184 .[ 1 ] [ 2 ] .Porter , M. ( 1980 ) . \"An algorithm for suffix stripping . \"", "label": "", "metadata": {}, "score": "71.89948"}
{"text": "In the case of an SSI without the pitch cutoff , the second and subsequent pitch periods are ' squashed ' together in the lower right corner of the image .To generate the pitch cutoff for the experimental features described below , the temporal profile of the SAI was taken and the largest peak after the zero - lag peak is taken as the most prominent pitch period in the signal .", "label": "", "metadata": {}, "score": "71.90341"}
{"text": "Rehn , M. , Lyon , R.F. , Bengio , S. , Walters , T.C. and Chechik , G. ( 2009 ) .[ 1 ] .Rhode , W.S. and Cooper , N.P. ( 1993 ) .\" Two - tone suppression and distortion production on the basilar membrane in the hook region of the cat and guinea pig cochleae . \"", "label": "", "metadata": {}, "score": "71.92465"}
{"text": "The amplitudes and positions of the peaks are plotted in each case .The click in this case occurs at 2ms on the time axis .The frequency and phase of the filtered noise signal are not necessarily the same as those of the impulse response .", "label": "", "metadata": {}, "score": "71.969284"}
{"text": "In practice , it is not necessary for the strobe finding to be perfectly accurate in order that a good SAI be built up from a pulse - resonance sound .The exact choice of which peak of the filter 's impulse response to strobe on does not make a significant difference to the auditory image that is produced , and there does not have to be exactly one strobe for each glottal cycle .", "label": "", "metadata": {}, "score": "72.01881"}
{"text": "[ 1 ] .Turner , R.E. and Patterson , R.D. ( 2003 ) . \"An analysis of the size information in classical formant data : Peterson and Barney ( 1952 ) revisited . \"Journal of the Acoustical Society of Japan , 33 , p.585 - 589 .", "label": "", "metadata": {}, "score": "72.032646"}
{"text": "This defines a normalized score S RC for each word .Normalized scores range from 0 to 1 and are dimensionless , making it possible to combine scores resulting from different scoring methods .The target congruence stage is then applied on each word candidate selected by the RC stage .", "label": "", "metadata": {}, "score": "72.03409"}
{"text": "The loss of phase - locking at higher frequencies is then simulated with a low - pass filter , and since the signal has already been half - wave rectified at this point , this reduces to a simple leaky integrator .", "label": "", "metadata": {}, "score": "72.05423"}
{"text": "Soc .Am . , 105 , p.2384 - 2391 .[ 1 ] .Cohen , L. ( 1993 ) .\"The scale representation . \"IEEE Trans .Sig .Proc . , 41 , p.3275 - 3292 .", "label": "", "metadata": {}, "score": "72.09151"}
{"text": "Training and testing were repeated for all three splits of the data , in order to obtain an estimate of the performance on all the documents .Queries that had fewer than 5 documents in either the training set or the test set were removed from both sets , and the corresponding documents were removed if these contained no other tag .", "label": "", "metadata": {}, "score": "72.11349"}
{"text": "First , HS regions are extracted from the phoneme similarity time series for a number of training speakers .The training data may be generated based on speech from a plurality of different speakers or it may be based on multiple utterances of the same training words by a single speaker .", "label": "", "metadata": {}, "score": "72.13933"}
{"text": "Applying a noisy - channelmodel , SPEECHPP uses a Viterbi beam - search that employs language and channel models .Previous work demonstrated that a simple word - for - word channel m ... \" .We have implemented a post - processor called SPEECHPP to correct word - level errors committed by an arbitrary speech recognizer .", "label": "", "metadata": {}, "score": "72.170494"}
{"text": "This paper describes the technique in detail , reports some tentative results and finally discusses the use of the model as a normalisation technique and as a method for measuring care of articulation .1 Introduction Formants are areas of high energy in the frequency spectrum of voiced speech .", "label": "", "metadata": {}, "score": "72.20704"}
{"text": "( McGraw - Hill ) .[ 1 ] .von Helmholtz , H.L.F. ( 1875 ) .On the Sensations of Tone as a Physiological Basis for the Theory of Music .( Longmans , Green and Co. ) .[ 1 ] .", "label": "", "metadata": {}, "score": "72.21035"}
{"text": "For the AIM features , 92.6 % accuracy was achieved with the 2 emitting state , 4 component HMM model after 15 training iterations .Since this performance is almost at the ceiling for the AIM features , and the same HMM parameters lead to optimal performance for the MFCC features , all further comparisons are made using recognition results for an HMM with these parameters .", "label": "", "metadata": {}, "score": "72.21042"}
{"text": "Desktop application users can keybind application controls to speech commands .Robots can be controlled via voice .Other features include voice mouse clicker .Vangard Voice Systems - Provides software tools to voice enable mobile and business applications .Voice recognition software tools for public safety , inventory management and logistics , medical IT , government , and customer records management .", "label": "", "metadata": {}, "score": "72.24342"}
{"text": "The low - pass liftering of the cepstrum removes much of the harmonic structure present in the original spectrum , meaning that the MFCCs capture the overall spectral shape of a sound well , but they are not very sensitive to pitch .", "label": "", "metadata": {}, "score": "72.24615"}
{"text": "However , auditory image construction is robust , in the sense that strobing does not have to occur exactly once per cycle to be effective .Strobe detection in AIM is performed using a dynamic thresholding technique .Figure 11 shows the ' parabola ' dynamic thresholding algorithm applied to a NAP .", "label": "", "metadata": {}, "score": "72.26868"}
{"text": "NAP peaks should be identified as strobes within a few milliseconds of entering the processing system .Choosing the correct threshold .The initial problem is that of identifying the points in time at which glottal pulses occurred in a human vocalisation , given the output of an auditory filterbank excited by that vocalisation .", "label": "", "metadata": {}, "score": "72.28126"}
{"text": "The ' tape speed transform ' simultaneously simulates a change in glottal pulse rate , a corresponding change in vocal tract length and a change in the rate of speaking .For the purposes of investigating the properties of the early stages of the auditory system , it is only the first two of these properties that are of interest to us since longer - term temporal variations are dealt with at a later stage of processing .", "label": "", "metadata": {}, "score": "72.30219"}
{"text": "Software .The two major software tools used in this thesis are AIM - MAT ( Bleeck et al ., 2004 ) and AIM - C , the MATLAB and C++ implementations of AIM .The implementations are in many ways complementary .", "label": "", "metadata": {}, "score": "72.38792"}
{"text": "The model can generalise , producing a smooth representation of sometimes noisy data .The model can be used to normalise vowel spaces produced by different speakers .It can be used to categorise different vowels .It can be used to categorise and compare different types of speech , such as citation speech against running speech .", "label": "", "metadata": {}, "score": "72.39025"}
{"text": "The resonances that follow the pulses in the input sound put energy into the filters at some frequencies , causing them to ring for longer and decay more slowly .These resonances are the formants of speech .For the short VTL ( upper panels ) , the entire pattern of formants is shifted up in frequency and decays faster in time .", "label": "", "metadata": {}, "score": "72.4146"}
{"text": "We discuss what constitutes an integrated system in AI , and why AI researchers should be interested in building and studying them .We describe one particular integrated sys - tem we have developed that supports spoken - language dia - logue to collaboratively solve planning problems .", "label": "", "metadata": {}, "score": "72.45701"}
{"text": "The crosses are individual query terms , with some marked .The plot is slightly skewed to higher precision for the SAI ( there are more queries above the line than below it ) .This plot was generated to test the hypothesis that the MFCC features and SAI features might perform better for one class of queries or another .", "label": "", "metadata": {}, "score": "72.47858"}
{"text": "Content areas : AI systems , natural language understanding , planning and control , problem solving , user interfaces . ... ources or agents ) can be easily added to the suite of resources at TRIPS ' disposal .Space obviously precludes discussing all these components here .", "label": "", "metadata": {}, "score": "72.47956"}
{"text": "These experiments point the way for future work on optimising the PZFC .The PZFC is an efficient and accurate implementation of an auditory filterbank , and it has the benefit of being based firmly in the fluid dynamics of the cochlea .", "label": "", "metadata": {}, "score": "72.487015"}
{"text": "Given that the majority of energy in speech is carried in the vowels ( Greenberg and Ainsworth , 2006 ) , this approach seems reasonable as a first approximation .The second modification introduces a ' repulsion ' term between the Gaussians , which adds a penalty for too much overlap between the individual components .", "label": "", "metadata": {}, "score": "72.51372"}
{"text": "The purpose is to compensate for the frequency - dependent transmission characteristics of the outer ear ( pinna and ear canal ) , the tympanic membrane , and the middle ear ( ossicular bones ) .At absolute threshold , the transducers in the cochlea are assumed to be equally sensitive to audible sounds , so the pre - processing filters apply a transfer function similar to the shape of hearing threshold .", "label": "", "metadata": {}, "score": "72.52219"}
{"text": "In both Test Sets A and B , the frequency characteristic used in the filtering of the speech and noise is the same as that used in the training sets , namely G.712 .The frequency characteristic of the filter used in Test Set C ( 14014 utterances ) is the MIRS , and is different from that used in the training sets .", "label": "", "metadata": {}, "score": "72.60385"}
{"text": "Hess , W. ( 1983 ) .Pitch determination of speech signals : algorithms and devices .( Springer - Verlag ) .[ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] .", "label": "", "metadata": {}, "score": "72.64055"}
{"text": "[ 1 ] .de Boer , E. ( 1975 ) . \"Synthetic whole - nerve action potentials for the cat .\" J. Acoust .Soc .Am . , 58 , p.1030- .[ 1 ] .de Cheveign\u00e9 , A. and Kawahara , H. ( 1999 ) .", "label": "", "metadata": {}, "score": "72.66036"}
{"text": "Gestures is a mode of communication in multimodal systems and they emphasize or express more accurately the content of the spoken language .Gestures are used , among others , when verbal communication is not possible or limited , i.e. in road works ( very noisy ) or airfield .", "label": "", "metadata": {}, "score": "72.71649"}
{"text": "MFCCs are calculated by taking the Fourier spectrum of a short , windowed portion of a signal ( typically around 25ms ) .The frequency spectrum is then mapped onto the mel scale ( Stevens et al . , 1937 ) by means of a bank of triangular filters , and the logarithm of the power at each of the mel frequencies is taken .", "label": "", "metadata": {}, "score": "72.71714"}
{"text": "( 1996 ) did not show much difference between the 50Hz and 800Hz condition , and a similar result was seen when using the pitch strength measure described here , so only the more challenging 800Hz condition is compared .Figure 88 --- Predictions ( dashed lines ) of the perceptual data of Patterson et al .", "label": "", "metadata": {}, "score": "72.71768"}
{"text": "OZGF ' is the one - zero gammatone filterbank and ' PrlGC ' and ' CasGC ' are parallel and cascade gammachirp filterbanks respectively .In the ' -fb ' variants , feedback from the output in a filter channel controls the gain of the filterbank in that channel ( a potentially unstable configuration ) .", "label": "", "metadata": {}, "score": "72.82623"}
{"text": "Am . , 120 , p.1474 - 1492 .[ 1 ] [ 2 ] .Unoki , M. , Irino , T. and Patterson , R.D. ( 2001 ) . \"Improvement of an IIR asymmetric compensation gammachirp filter .\" Acoustical Science and Technology , 22 , p.426 - 430 .", "label": "", "metadata": {}, "score": "72.85939"}
{"text": "an array of binaural spike coincidence detectors , whose outputs are then inputs into . coincidence counters that provide the number of coincidences as a function of relative delay .The delay lines are arranged in antiparallel fashion to implement a range of available relative delays between the two sets of monaural lines .", "label": "", "metadata": {}, "score": "72.912384"}
{"text": "The instructions were used within a restricted domain and that had as benefits that the speech vocabulary and the number of natural sentences are limited and the prototype can be integrated into existing ( computer - aided design ) CAD software .", "label": "", "metadata": {}, "score": "72.91783"}
{"text": "Since the gammatone had a well - defined impulse response , producing systems to model auditory filters was now possible .Martin Cooke produced an early gammatone filterbank while working with Schofield at the National Physical Laboratory ( Cooke , 1993 ) , and John Holdsworth produced the Cambridge gammatone filterbank code while working with Roy Patterson .", "label": "", "metadata": {}, "score": "72.92468"}
{"text": "The benefit of speech enhancement in the presence of packet loss , without any missing feature reconstruction , can be seen by comparing Table 10 and Table 11 .With speech enhancement and no packet loss compensation , Table 11 shows that Li et al .", "label": "", "metadata": {}, "score": "72.92889"}
{"text": "This summary signal is passed to the simple ' local maximum ' decaying threshold strobe algorithm described earlier .The strobe points are then placed , based upon the known peaks in the impulse response of the filterbank for different channels .", "label": "", "metadata": {}, "score": "72.9296"}
{"text": "Once the complete sound has been processed , the system iterates over the remaining strobe points , and finds those intervals where there are unclaimed strobes .These intervals are marked as containing errors .This tests that the total number of strobes is roughly the same as the total number of pulses , and that the strobes occur at a reasonable rate .", "label": "", "metadata": {}, "score": "72.93513"}
{"text": "Formant synthesis does not use human speech samples at runtime , but uses additive synthesis and an acoustic model to create artificial speech .In the next paragraphs we refer exclusively to some speech TTS software ; for those tools who include both speech recognition and synthesis , look at previous chapter \" Automatic Speech Recognition - Current tools \" .", "label": "", "metadata": {}, "score": "73.0038"}
{"text": "Signal presence is determined by computing the ratio of the noisy speech power spectrum to its local minimum , which is updated continuously by averaging past values of the noisy speech power spectra with a look - ahead factor .The results in [ 21 ] indicate that the local minimum estimation algorithm adapts very quickly to highly non - stationary noise environments .", "label": "", "metadata": {}, "score": "73.037224"}
{"text": "32 As seen in the stages i. and iv . above , dialog systems have also employed other modes for communication for input and output , such as gestures , and we will examine that in the next chapter ' Gesture Recognition and Localization ' .", "label": "", "metadata": {}, "score": "73.09082"}
{"text": "Delays of the order of 10ms at this stage of the system are entirely reasonable from the point of view of auditory perception .As an additional example , I present a strobe detection system that processes whole sections of the NAP across multiple channels .", "label": "", "metadata": {}, "score": "73.142105"}
{"text": "IRN has been a challenging stimulus for spectral models of pitch perception ( Yost and Hill , 1979 ) .Pitch extraction in AIM is based on the temporal fine structure of a sound , and pitch strength corresponds to the peak height in the temporal profile of the SAI .", "label": "", "metadata": {}, "score": "73.16911"}
{"text": "This means that a wide range of the sounds which are encountered by humans in their everyday life take this form .When a pulse excites resonances in the body of a calling animal , the form of the resonances provides information about the resonating body .", "label": "", "metadata": {}, "score": "73.19024"}
{"text": "The back - projection system takes around 100 seconds to run on the same stimulus , so there is roughly an order of magnitude performance decrease associated with using back projection .The back - projection system does not work well with the PZFC filterbank in all cases .", "label": "", "metadata": {}, "score": "73.196365"}
{"text": "In order to combat this , a timeout can be added which prevents the system from issuing a strobe in a short window after a previous strobe point .This means that the first peak in the rising edge of a new pulse is the strobe point , and as long as the rise time of the filter 's impulse response is short enough , no more strobes will be issued on this peak .", "label": "", "metadata": {}, "score": "73.2018"}
{"text": "We present following recent advances which prove this expectation true : .They made an experiment installing the entire system into real houses and asking the users to talk as they wish ( out of grammar ) .The results showed action accuracy 91.23 % , taken into account also that almost 30 % of utterances were spoken by a non - native speaker .", "label": "", "metadata": {}, "score": "73.2269"}
{"text": ", 1966 ) stated that \" there is no immediate or predictable prospect of useful MT \" .Although the report 's impact was that the USA government reduced its funding for MT , the research projects in the USA were extended .", "label": "", "metadata": {}, "score": "73.268234"}
{"text": "The output of each filter channel is first half - wave rectified and weakly compressed using a cubic nonlinearity .This monopolar signal is then passed through a set of low - pass filters , which have the effect of smoothing the signal .", "label": "", "metadata": {}, "score": "73.32659"}
{"text": "This is another manifestation of the undersampling problem .Figure 52 shows an SSI for a real human /a/ vowel .The pitch cutoff line is clearly visible as a strong diagonal in the image .Beyond this line , subsequent cycles of the waveform are squashed into a smaller and smaller space .", "label": "", "metadata": {}, "score": "73.34622"}
{"text": "One difference between SAI and MFCC representations is that SAIs retain fine timing information , while MFCCs preserve fine spectral structure ( when the number of coefficients is large enough ) .However , further study will be required to ascertain exactly what the key properties of the systems involved in going from a sound to a sparse feature vector are , and how these affect performance .", "label": "", "metadata": {}, "score": "73.41319"}
{"text": "When designing the system , it as important to keep in mind the problem of scalability : the systems used are both effective and efficient , as it is desirable to be able to scale up the system to Internet - sized datasets .", "label": "", "metadata": {}, "score": "73.49065"}
{"text": "Figure 14 --- Correlograms ( positive side only ) for the four vowel sounds .Note that the correlogram representation is more symmetrical than the stabilised auditory image .The correlograms were generated by processing the AIM NAP output using Slaney 's auditory toolbox ( Slaney , 1993e ) .", "label": "", "metadata": {}, "score": "73.514336"}
{"text": "Booktitle : IPO Symposium on Hearing Theory .IPO , Eindhoven , The Netherlands .OriginalCiteRef : johannesma1972pre .[ 1 ] .Kawahara , H. , Masuda - Katsuse , I. and de Cheveign\u00e9 , A. ( 1999 ) .\"", "label": "", "metadata": {}, "score": "73.53189"}
{"text": "n errors remains as a long - standing goal in speech recognition research .Moreover , our survey of related studies reveals that the system - initiated , data - driven paradigm is widely adopted .Confidence Measures Confidence measures are referred to as a method for detecting ... . \" ...", "label": "", "metadata": {}, "score": "73.541534"}
{"text": "Comparison with features from the NAP .Recognition performance with these new SSI - based features was compared with that of the NAP - based features of chapter 2 , using the syllable recognition task of chapter 2 .The NAP features were compared with each of the four feature variants derived from the SSI .", "label": "", "metadata": {}, "score": "73.57149"}
{"text": "Figure 9 shows the output of the AIM BMM module for the four input sounds from above .The output of the BMM stage is a multi - channel representation of the incoming sound ; the output channels correspond to the motion over time of points spaced equally along the length of the basilar membrane .", "label": "", "metadata": {}, "score": "73.66667"}
{"text": "A Speech Recognition Friendly Artificial Language \" in Proceedings of the 7th IceTAL ( Reykjavik , Iceland ) 6233/2010 , pp .250 - 256 .Nagao , M. ( 1984 ) , \" A Framework of a Mechanical Translation between Japanese and English by Analogy Principle \" in Elithorn , A. ; Banerji , R. ( Eds . ) , Artificial and Human Intelligence , Amsterdam , North - Holland , 173 - 180 .", "label": "", "metadata": {}, "score": "73.69766"}
{"text": "An even more advanced way is to seamlessly transfer the whole UI between various devices .38 A full list of gesture recognition software can be found at various webpages 60 .39 We turn our attention now to gesture localization and how it is related to gesture recognition .", "label": "", "metadata": {}, "score": "73.811745"}
{"text": "Smith et al .found that while the sex of the input speaker did not make a significant difference to the judgement , the age of the speaker did .This prompted them to suggest that the differences in the ratio of the sizes of the oral cavity and pharynx between children and adults may account for the difference .", "label": "", "metadata": {}, "score": "73.873695"}
{"text": "Series B ( Methodological ) , 39 , p.1 - 38 .[ 1 ] .Dudley , H. ( 1939 ) .\" Remaking speech .\" J. Acoust .Soc .Am . , 11 , p.169 - 177 .", "label": "", "metadata": {}, "score": "73.90109"}
{"text": "Notably , subcortical auditory function is neither passive nor hardwired but dynamically interacts with higher - level cognitive processes to refine how sounds are transcribed into neural code .This experience - dependent plasticity , which can occur on a number of time scales ( e.g. , life - long experience with speech or music , short - term auditory training , on - line auditory processing ) , helps shape sensory perception .", "label": "", "metadata": {}, "score": "74.05061"}
{"text": "If a VTLN system performs optimally , then it should be possible to infer the ideal warp factor for every speaker at test time .In the case of the syllables database the optimal frequency warping factor is already known , since the input syllables are themselves scaled .", "label": "", "metadata": {}, "score": "74.05458"}
{"text": "The time constant for the decay is set such that the threshold will decay more slowly than the resonance following a pulse , and so the next supra - threshold peak in the signal is likely to have been caused by a new incoming pulse .", "label": "", "metadata": {}, "score": "74.151184"}
{"text": "The standard approach to VTLN involves applying a piecewise linear warping to the frequency axis of the mel filterbank before the MFCC coefficients are computed .With the correct per - speaker choice of warp factor , it is possible to map the format patterns for different VTLs to the same pattern .", "label": "", "metadata": {}, "score": "74.16491"}
{"text": "Its Speech Application Programming Interface ( SAPI ) allows the use of speech recognition and synthesis within Windows applications ; the latest version 5.4 ships in Windows 7 . 13 A supplier exclusively of speech technologies for the automotive and mobile industries is SVOX 10 .", "label": "", "metadata": {}, "score": "74.20262"}
{"text": "The system uses a linear gammatone filterbank , which is a good first approximation to the cochlear filterbank , but which lacks the fast - acting compression which is known to exist in the cochlea .This system also makes no attempt to use the strobed temporal integration from AIM .", "label": "", "metadata": {}, "score": "74.22807"}
{"text": "Finally , Joshua includes a number of simplifications and improvements focused on usability for both researchers and end - users , including the release of language packs --- precompiled models that can be run as black boxes .Findings of the 2015 Workshop on Statistical Machine Translation ( Inproceeding ) .", "label": "", "metadata": {}, "score": "74.23065"}
{"text": "The first filtering stage coarsely reduces the noise and whitens any residual noise while the second stage attempts to remove the residual noise .Filtering is based on the Wiener filter concept and filter optimisation is carried out in the mel - frequency domain .", "label": "", "metadata": {}, "score": "74.23238"}
{"text": "\" J. Acoust .Soc .Am . , 105 , p.3497 - 3508 .[ 1 ] .Dempster , A.P. , Laird , N.M. , Rubin , D.B. and Others ( 1977 ) .\" Maximum likelihood from incomplete data via the EM algorithm . \"", "label": "", "metadata": {}, "score": "74.26941"}
{"text": "As the number of features becomes very large , performance begins to saturate .The top performance is for the system with 73 % at the top - ranked sound file , achieved with 4,000 codewords per codebook and a total of 49 codebooks .", "label": "", "metadata": {}, "score": "74.2957"}
{"text": "8 .The times reported here were for nonoptimized software .For a 100 word lexicon the whole system requires only 7.3 % of the alignment time used by the fine match alone .For larger lexicons the alignment time reduction is yet larger , as shown in the right side of FIG .", "label": "", "metadata": {}, "score": "74.32387"}
{"text": "Gray , H. ( 1918 ) .Anatomy of the human body .( Lea \\ & Febiger ) .[ 1 ] .Greenberg , S. and Ainsworth , W.A. ( 2006 ) .Listening to speech : an auditory perspective .", "label": "", "metadata": {}, "score": "74.381546"}
{"text": "The parameters of the lower - frequency channels will determine the maximum values for the look - ahead time .If some maximum look - ahead is desired , then the look - ahead can be truncated in the low - frequency channels , at the expense of accuracy .", "label": "", "metadata": {}, "score": "74.40813"}
{"text": "One possible way to do this would be to summarise the spectral profile of the NAP and SSI by a more MFCC - like representation that does not have the scale - shift invariance properties of the Gaussian fitting procedure used in the above experiments .", "label": "", "metadata": {}, "score": "74.43119"}
{"text": "IEEE Transactions on Speech and Audio Processing , 10 , p.415 - 426 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] .Yost , W.A. ( 1996 ) .\" Pitch of iterated rippled noise .\" J. Acoust .", "label": "", "metadata": {}, "score": "74.457634"}
{"text": "An idealised pulse train will have a frequency spectrum that also looks like a pulse train , with all harmonics of the pulse rate present in the spectrum .The pulse - resonance generation model has a stream of pulses exciting resonances of the vocal tract or other body .", "label": "", "metadata": {}, "score": "74.476006"}
{"text": "The dynamic compressive gammachirp ( dcGC ) filterbank is a parallel - architecture filterbank with a cascaded control channel ( Irino and Patterson , 2006 ) .It was demonstrated by Irino and Unoki ( 1999 ) and Unoki et al .", "label": "", "metadata": {}, "score": "74.54997"}
{"text": "FIG .7 is a bar graph that compares the recognition rates under five test speech conditions : clean , data show 20 dB , car 20 dB , data show 10 dB , and car 10 dB SNR .Word prototypes were trained on clean speech ( left ) or on both clean and noisy ( data show noise at 10 dB SNR ) speech ( right ) ; and .", "label": "", "metadata": {}, "score": "74.55113"}
{"text": "Speech Comm . , 27 , p.187 - 207 .[ 1 ] [ 2 ] .Kawahara , H. and Irino , T. ( 2004 ) .\" Underlying principles of a high - quality speech manipulation system STRAIGHT and its application to speech segregation \" , in Speech separation by humans and machines , Divenyi , P.L. editor , p.167 - 180 ( Kluwer Academic ) .", "label": "", "metadata": {}, "score": "74.58328"}
{"text": "Intermediate sizes and shapes capture a variety of localised features , so even when multiple sounds are present , some of the features corresponding to regions of the SAI dominated by one sound or the other will often still show a recognisable pattern .", "label": "", "metadata": {}, "score": "74.62212"}
{"text": "In chapter 3 , the properties of an ' ideal ' strobe detection system are defined , and a number of strobe detection systems are presented and analysed based on this definition .Figure 13 shows the results of the STI process for the four vowels .", "label": "", "metadata": {}, "score": "74.65172"}
{"text": "In the ideal case , the mechanism will wait as the amplitude of successive peaks gradually rises , and then fire a strobe at the top of the highest peak in the NAP .This requires the system to look ahead a certain amount of time to determine if it is indeed dealing with a rising set of peaks due to a pulse .", "label": "", "metadata": {}, "score": "74.67425"}
{"text": "Although Jeffress ( 1948 ) talked explicitly about \" densities of coincidence cells \" that varied with the delay ( suggesting more delays near zero ) , the actual distribution of available delays and the dependence of that distribution on characteristic frequency is still an active topic .", "label": "", "metadata": {}, "score": "74.69797"}
{"text": "The ETSI basic front - end [ 6 ] was developed for implementation over circuit - switched channels and this implementation is also considered in the other three standards .The advanced front - end [ 7 ] produces superior performance to the basic front - end , and was designed to increase robustness in background noise .", "label": "", "metadata": {}, "score": "74.716675"}
{"text": "Am . , 100 , p.511 - 518 .[ 1 ] .Yost , W.A. , Patterson , R. and Sheft , S. ( 1996 ) .\" A time domain description for the pitch strength of iterated rippled noise .", "label": "", "metadata": {}, "score": "74.73947"}
{"text": "Here , the output of the dcGC filterbank is half - wave rectified and low - pass filtered ( but no further compression is applied ) .The basilar membrane motion is converted into a simulation of the neural activity pattern ( NAP ) observed in the auditory nerve using a model of the neural transduction that occurs in the hair cells of the cochlea .", "label": "", "metadata": {}, "score": "74.7454"}
{"text": "The PZFC filterbank was used as the cochlear model for all the auditory processing in this study .In both cases , the filterbank had 95 channels , spanning a frequency range from 40Hz to 9.3kHz .The NAP was calculated by simple half - wave rectification of the filterbank output .", "label": "", "metadata": {}, "score": "74.74688"}
{"text": "When using standard MFCCs , performance was high around the training speakers , but degraded rapidly as the simulated vocal tract length of the speakers became either smaller or larger than that of the speakers in the training set .However , when simulated , optimal , vocal tract length normalisation ( VTLN ) was performed on the spectrum before computing the MFCCs , performance was better than that with the auditory features .", "label": "", "metadata": {}, "score": "74.797775"}
{"text": "In order to compare the PZFC results against the other filterbanks , the baseline measurements of pitch strength for the default configurations of the other filterbanks are shown in .Measured pitch strength for a harmonic complex using the dcGC and gammatone filterbanks .", "label": "", "metadata": {}, "score": "74.81012"}
{"text": "Preliminary experiments to this end , which directly swapped the gammatone filterbank for the PZFC filterbank , led to recognition results which were significantly worse than the results gained with the gammatone filterbank .However the exact parameters of the Gaussian fitting procedure were tuned to the output of a simple gammatone filterbank and these parameters were not modified in the initial experiments .", "label": "", "metadata": {}, "score": "74.824036"}
{"text": "Fant , G. ( 1960 ) .Acoustic Theory of Speech Production .( Mouton De Gruyter , The Hague ) .[ 1 ] .Feldbauer , C. , Monaghan , J.J. and Patterson , R.D. ( 2008 ) . \"", "label": "", "metadata": {}, "score": "74.83255"}
{"text": "In the active part , the output of each channel is passed through a dynamically controlled asymmetric compensation filter that modifies the bandwidth and peak frequency of the overall composite filter .The parameters of this active asymmetric compensation filter are controlled by the processed output of a higher - frequency channel in the filterbank .", "label": "", "metadata": {}, "score": "74.85134"}
{"text": "( 2003 ) .The dcGC filterbank includes a system for dynamic modification of the cGC filterbank compression parameters in response to the input audio .Simple representations of the gammatone family in the Laplace domain .Lyon ( 1997 ) noted that the representation of the gammatone filter could be simplified by discarding the zeros from the S - plane transfer function to yield an ' all - pole ' gammatone filter ( APGF ) .", "label": "", "metadata": {}, "score": "74.89195"}
{"text": "Comparing Table 9 with Table 11 , a significant reduction in recognition performance is observed in the presence of packet loss , in particular for channels C and D where the probability of packet loss is 50 % .When nearest neighbour repetition is used to reconstruct missing features , Table 12 shows that there is a significant increase in recognition performance across all channels when compared to the results presented in Table 11 .", "label": "", "metadata": {}, "score": "74.899765"}
{"text": "The male speakers are coloured red , the female speakers green and the children blue .Mel - frequency cepstral coefficients ( MFCCs ) are the representation typically used for speech recognition and other audio classification and data - mining .MFCCs are generated by taking a short - term Fourier transform of a windowed section of the signal ( normally around 20ms ) ; the Fourier spectrum is then mapped to a mel - frequency scale using a triangular filterbank , and the logarithm of each output band is taken .", "label": "", "metadata": {}, "score": "74.99189"}
{"text": "Based on an observation by Nick Clarke , that an auditory model with a compressive PZFC filterbank was able to explain the results of a pitch strength detection experiment better than a gammatone filterbank , I assessed the relative performance of various auditory filterbanks on pitch - strength detection tasks .", "label": "", "metadata": {}, "score": "75.00453"}
{"text": "The word accuracies for each of the Aurora test sets presented throughout this chapter are calculated according to [ 16 ] , which defines the performance measure for a test set as the word accuracy averaged over all noises and over all SNRs between 0 dB and 20dB.", "label": "", "metadata": {}, "score": "75.0083"}
{"text": "Soc .Am . , 118 , p.3177 - 3186 .[ 1 ] [ 2 ] [ 3 ] .Smith , J.O. and Abel , J.S. ( 1999 ) .\"Bark and ERB bilinear transforms . \"IEEE Transactions on Speech and Audio Processing , 7 , p.697 - 708 .", "label": "", "metadata": {}, "score": "75.01857"}
{"text": "Speech enhancement .Additive noise from interfering noise sources , and convolutional noise arising from transmission channel characteristics both contribute to a degradation of performance in automatic speech recognition systems .This section addresses the problem of robustness of speech recognition systems in the first of these conditions , namely additive noise .", "label": "", "metadata": {}, "score": "75.028336"}
{"text": ".. is how to provide robustness in the presence of speech recognition errors .Current spoken dialogue systems inform the user when they can ... . by Lina Zhou , Yongmei Shi , Dongsong Zhang , Andrew Sears - Journal of Management Information Systems , 2006 . \" ... interests include natural language processing , speech recognition , information retrieval , and machine learning .", "label": "", "metadata": {}, "score": "75.054665"}
{"text": "Feature vectors were extracted directly from the enhanced speech with no intermediate processing .The recognition experiments used vectors that include 13 static coefficients along with velocity and acceleration coefficients .This results in vectors with an overall dimension equal to 39 .", "label": "", "metadata": {}, "score": "75.0765"}
{"text": "The majority of algorithms for strobe finding employed in AIM rely on the third of Hess 's features to perform their classification of strobe points .When a pulse excites resonances which decay with a finite time constant , an exponential threshold which decays more slowly than the resonance can be applied to the signal to ' follow ' the decaying resonances .", "label": "", "metadata": {}, "score": "75.09895"}
{"text": "The threshold then decays again until it meets the signal and the process repeats .This has the effect of causing strobes to be issued only on certain peaks in the NAP .Figure 12 shows the results of applying the same algorithm to the NAP output for the four vowels .", "label": "", "metadata": {}, "score": "75.10187"}
{"text": "Soc .Am . , 106 , p.1511 - 1522 .[ 1 ] .Flanagan , J.L. and Guttman , N. ( 1960 ) .\" On the pitch of peridic pulses .\" J. Acoust .Soc .Am . , 32 , p.1308 - 1319 .", "label": "", "metadata": {}, "score": "75.103226"}
{"text": "Once an accurate pitch track has been extracted , the sound is re - analysed using a pitch - synchronous window .Typically when a periodic sound is analysed using a short - window Fourier transform , the periodicity of the waveform and the window size interfere to create a periodic temporal structure in the extracted spectrogram .", "label": "", "metadata": {}, "score": "75.10626"}
{"text": "In his original 1948 paper Jeffress definitely considered the superior olive as a candidate locus because of its anatomical connections .He rejected this possibility based on evidence for phase - locking to the two ears and their \" equal representation \" at the level of the lateral lemniscus , which is above the superior olive .", "label": "", "metadata": {}, "score": "75.18344"}
{"text": "In this experiment , listeners were asked to judge the height of a speaker with a given combination of GPR and VTL on a seven - point scale from ' very tall ' to ' very short ' .Listeners were also asked to judge the sex and the age of the presented speakers from four choices : ' man ' , ' woman ' , ' boy ' and ' girl ' .", "label": "", "metadata": {}, "score": "75.199036"}
{"text": "Volume : 2 .Organization : Citeseer .OriginalCiteRef : slaney1994auditory .Pages : 77 - 80 .[ 1 ] .Smith , D.R.R. , Patterson , R.D. , Turner , R.E. , Kawahara , H. and Irino , T. ( 2005 ) .", "label": "", "metadata": {}, "score": "75.20268"}
{"text": "Lazzaro J , Mead C , 1989 \" Silicon models of binaural localization \" Neural Computation 1 , 41 - 70 .Lazzaro J , Mead C , 1990 \" Silicon models of auditory localization \" , in An Introduction to Neural and Electronic Networks Ed D Zornetzer , Lau ( New York : New York ) pp 158 - 174 .", "label": "", "metadata": {}, "score": "75.2486"}
{"text": "The configurations of the parameters , along with the pitch strength estimates , are shown in as parameter sets 1 to 6 .In the case of parameter sets 5 and 6 , the activity does not diffuse along the spatial dimension but is actively ' transported ' , since one of the off - centre coefficients is larger than the central coefficient .", "label": "", "metadata": {}, "score": "75.24868"}
{"text": "11 - \" RTP Payload Formats for European Telecommunications Standards Institute ( ETSI ) European Standard ES 202 050 , ES 202 211 , and 202 212 Distributed Speech Recognition Encoding \" , in RFC 4060 , May 2005 .14 - Q. Li , F. K. Soong and O. Siohan , \" A high - performance auditory feature for robust speech recognition \" , in Proc . of 6th International Conference on Spoken Language Processing ( ICSLP ) , Beijing , China , Oct. 2000 , pp .", "label": "", "metadata": {}, "score": "75.25165"}
{"text": "An inductive or iterative process is then performed for each of the successive utterances of the training word or phrase .Specifically , each successive utterance is represented as a vector like that of the first utterance .The two vectors are then combined to generate the vector sum and the vector sum of the squares .", "label": "", "metadata": {}, "score": "75.27503"}
{"text": "Joris P , Yin T C , 2007 \" A matter of time : internal delays in binaural processing \" Trends Neurosci 30 70 - 8 .[Covers more recent controversies over time delays vs. inhibition .] Popper , Arthur N. and Richard R. Fay , eds .", "label": "", "metadata": {}, "score": "75.27707"}
{"text": "Figure 102 shows the average precision of the top - ranked result against the length of the sparse feature vector .In each set of experiments , the series of markers show the effect of changing the variable in question .In each experimental case , all other parameters were left at their ' baseline ' values .", "label": "", "metadata": {}, "score": "75.34253"}
{"text": "This is simple to implement , but does not follow well the form of the actual filter decay .In initial testing of the new algorithm , it was found that strobing accuracy could be improved slightly by using a threshold that matches more closely the form of the driven filter envelope .", "label": "", "metadata": {}, "score": "75.34752"}
{"text": "The result is to generate a new vector sequence Y i that is related to X i by .In order for the interleaver to carry out the reordering of the feature vectors , it is necessary to buffer the vectors , which introduces a delay .", "label": "", "metadata": {}, "score": "75.37985"}
{"text": "Figure 2 shows a cross - section of the human vocal tract ; in human speech the configuration of the excited vocal tract , and thus the resonance pattern which it produces , carries information about the vowel which was spoken .", "label": "", "metadata": {}, "score": "75.38965"}
{"text": "AIM - C includes modules for the gammatone , dcGC and PZFC filterbanks and for various strobed temporal integration algorithms .The filterbank implementations in AIM - C run considerably faster than the equivalent versions in AIM - MAT .In general , there is at least an order of magnitude improvement in speed available in using AIM - C over AIM - MAT .", "label": "", "metadata": {}, "score": "75.43195"}
{"text": "These same four channels are used here to determine the effect of packet loss on speech recognition performance .The parameter values for the four channels are detailed in Table 6 .These parameters result from work in [ 33 ] on IP and wireless networks .", "label": "", "metadata": {}, "score": "75.43483"}
{"text": "\" J. Acoust .Soc .Am . , 125 , p.2374 -2386 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] .Turner , R.E. , Walters , T.C. and Patterson , R.D. ( 2004 ) .", "label": "", "metadata": {}, "score": "75.49364"}
{"text": "Furthermore , it provides a simpler way to model the level - dependent gain , bandwidth , asymmetry and centre - frequency shift exhibited by human auditory filters .Filter cascade models .When considering the analogy between the cochlea and auditory filterbanks , it is important to remember that the cochlea is in fact a complex hydrodynamic system , in which a wave travels along a continuous medium from base to apex .", "label": "", "metadata": {}, "score": "75.497375"}
{"text": "The pulse times are arranged in the order in which they occur ( regardless of which source they came from ) .The system then iterates through the sequentially - ordered pulse - times , looking forward from the pulse time in each channel , and assigns the first strobe that it finds within the interval to that pulse .", "label": "", "metadata": {}, "score": "75.55555"}
{"text": "Then , the initial locations for the four Gaussians in the main fitting stage are chosen relative to the final locations of the two components in the initial fitting stage .Calculating spectral profiles .Spectral profiles from AIM were produced by low - pass filtering the NAP to blur short - term fluctuations in its level , and then summing short sections to obtain the desired frame length .", "label": "", "metadata": {}, "score": "75.58401"}
{"text": "The ASR system used is proprietary .Grammar is in German and English only ; that means that users can speak only in these two languages .Grammar is minimal ; thus the instructions limited .Rolland is not intelligent enough to remember his original position so that he returns back or follow a sequence of events ( e.g. after Mario finishes his pizza he wants to wash his hands , so Rolland brings him to the bathroom ) .", "label": "", "metadata": {}, "score": "75.606"}
{"text": "Extra sharpness can be given to the individual filter stages by adding either extra poles or extra zeros to the transfer function .Lyon also presented a three - pole system , and a pair of two - pole , two - zero filters .", "label": "", "metadata": {}, "score": "75.64626"}
{"text": "An application was designed to reveal the spread of adaptation in frequency and time , in preparation for experiments designed to examine the physiological plausibility of the smoothing network , which is unlikely to be symmetric in the cochlea .Figure 70 shows the impulse response of the smoothing network .", "label": "", "metadata": {}, "score": "75.666046"}
{"text": "Multiple pulses .The system needs to be able to identify a series of pulses followed by resonances .If the pulse rate is high enough , new pulses will interfere with the tails of previous resonances .The interaction of a given resonance decay with the onset of the next pulse makes it somewhat more difficult both to identify pulses and to track the rise and fall of vocal tract resonances .", "label": "", "metadata": {}, "score": "75.76283"}
{"text": "By contrast , the dcGC , while still efficient , uses a fourth - order filter cascaded with a set of four second - order asymmetry functions for the signal path in each stage , and another four second - order asymmetry functions for the level estimation path .", "label": "", "metadata": {}, "score": "75.77536"}
{"text": "To simulate the output of the cochlea to the auditory nerve , the output of the basilar membrane is half - wave rectified .In many models , there is also a low - pass filter applied to the signal which simulates the loss of phase - locking in the hair cells at high frequencies .", "label": "", "metadata": {}, "score": "75.821915"}
{"text": "Recent comparative studies have shown the superior performance of DSR to codec - based ASR [ 4 ] .However , in a DSR system , transmission errors in the form of random packet loss and packet burst loss still need to be taken into consideration .", "label": "", "metadata": {}, "score": "75.86015"}
{"text": "We varied the base size of the rectangle , starting from the sizes 8 \u00d7 16 and 32 \u00d7 64 .We also restricted the number of sizes , by limiting the doublings of each dimension .This restriction serves to exclude the global features that are taken across a large part of the auditory image frame .", "label": "", "metadata": {}, "score": "75.890884"}
{"text": "However , there were many other differences between the two systems tested in chapter 6 , and so the effect of the strobe systems is difficult to discern amongst all the variables .Nevertheless , the theoretical work in chapter 3 shows why current strobe detection systems work well , and it places the choice of parameters on a firm theoretical footing .", "label": "", "metadata": {}, "score": "75.89435"}
{"text": "Target Congruence Modeling .In the presently preferred embodiment targets are generalized HS regions described by 5 parameters : . phoneme symbol ; . target weight ( percentage occurrence in training data ) ; . average peak height ( phoneme similarity value ) ; . average left frame location ; . average right frame location .", "label": "", "metadata": {}, "score": "75.92474"}
{"text": "In its simplest form , scale invariance can be seen as an invariance to changing the ' tape speed ' of a signal .Imagine a tape or vinyl recording of speech which is played back at the wrong speed .For a wide range of playback speeds , it is still easily possible to discern what the speaker is saying , even if other characteristics of the voice ( such as the perceived size or age of the speaker ) may change wildly .", "label": "", "metadata": {}, "score": "75.95485"}
{"text": "The pitch strength estimates are stronger than for the log - compressed gammatone , but the linear gammatone is not a physiologically reasonable auditory filter model as it has no compression , and it is included in these experiments only for comparison with the other compressive filterbanks .", "label": "", "metadata": {}, "score": "75.95942"}
{"text": "We present an FPGA implementations of the decoder based on continuous hidden Markov models ( HMMs ) representing monophones , and demonstrate that it can process speech 75 times real time , using 45 % of the slices of a Xilinx Virtex XCV1000 . ... inuous HMMs compute their observation probabilities based on feature vectors extracted from the speech waveform .", "label": "", "metadata": {}, "score": "76.05272"}
{"text": "The lines show the developmental path as children grow into adults , and the individual red and blue data points show the VTL - GPR combinations for males and females at different ages .This figure is adapted from figure 13 in Turner et al .", "label": "", "metadata": {}, "score": "76.1252"}
{"text": "Soc .Am . , 98 , p.1890 - 1894 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] .Patterson , R.D. , Handel , S. , Yost , W.A. and Datta , A.J. ( 1996 ) .", "label": "", "metadata": {}, "score": "76.12544"}
{"text": "Each auditory fiber innervates one cochlear inner hair cell and projects in a cochleotopic manner to a small number of spherical bushy cells in the anteroventral cochlear nucleus .Their large , highly secure synapses , called endbulbs of Held , drive the target spherical cells to produce trains of action potentials that preserve or even strengthen the precise spike timing of the auditory nerve ( cf . , Joris et al . , 1994 ) .", "label": "", "metadata": {}, "score": "76.17624"}
{"text": "The height of the signal at these strobe points determines the weight with which that time interval is represented in the output .The process is less computationally intensive than autocorrelation , as one of the signals is sparse , being composed mostly of zeros .", "label": "", "metadata": {}, "score": "76.22328"}
{"text": "f L was set at 10Hz and f H was set at 10500Hz , to encompass almost the full range of frequencies when a 22kHz sampling rate is used for the input .The scaled MFCC features were then used to train a standard 2 emitting - state , 4 mixture - component HMM .", "label": "", "metadata": {}, "score": "76.27429"}
{"text": "Sparse coding .In the next stage of processing , the low - dimensional dense feature vectors from individual boxes are converted to sparse codes by use of vector quantisation ( VQ ) ( Gersho and Gray , 1992 ) .In the training stage , a ' codebook ' is learned over a range of sounds using k - means clustering .", "label": "", "metadata": {}, "score": "76.29529"}
{"text": "While it is useful , in practical terms , to ascribe AGC timescales on the order of hundreds of milliseconds to processes in the cochlea , it is not physiologically realistic .Adaptation that occurs on this timescale is likely to originate more centrally .", "label": "", "metadata": {}, "score": "76.31305"}
{"text": "The compression is intended to simulate the cochlear compression which is essential to cope with the large dynamic range of natural sounds .This compression is already present in the dcGC and PZFC filters , but is absent in the gammatone filters .", "label": "", "metadata": {}, "score": "76.32259"}
{"text": "This result shows the potential benefit for SSI - based features in noise .Compressive auditory filtering .The cochlea performs dynamic level compression based on stimulus level .This dynamic response was not included in the simple gammatone filterbank used in the experiments of chapters 2 and 4 .", "label": "", "metadata": {}, "score": "76.37463"}
{"text": "Experiments using the Aurora connected - digit recognition framework [ 16 ] found that the best performance was obtained using the method of Agarwal and Chang [ 25 ] .The test results also suggest that the choice of speech enhancement algorithm for best speech recognition performance is independent of the choice of front - end .", "label": "", "metadata": {}, "score": "76.395515"}
{"text": "I compared performance of the features from the SSI with the features from the neural activity pattern ( NAP ) , derived from the cochlear output used in chapter 2 .Performance on the features was once again compared with that on MFCCs , with and without VTLN .", "label": "", "metadata": {}, "score": "76.39791"}
{"text": "For the MFCCs , the performance after 2 more training iterations for all HMM parameters shown in the plot is between 64 % and 72.3 % .For the same set of parameters with the AIM features , performance is between 78 % and 93.2 % .", "label": "", "metadata": {}, "score": "76.41319"}
{"text": "It seems an obvious idea , then , to look across multiple frequency channels when trying to detect strobe points .A set of criteria for good strobe detection .Having discussed the various desirable features of a strobe system , we can draw up a set of criteria for a good strobing system that is both computationally efficient and physiologically plausible : .", "label": "", "metadata": {}, "score": "76.48903"}
{"text": "A wheelchair called \" Rolland \" serves mobility assistance in the BAALL .Rolland is equipped with two laser range - sensors , wheel encoders , and an onboard computer .In BAALL natural interaction with the users is taken in serious consideration , and thus it is enabled through special devices for compensating special limitations .", "label": "", "metadata": {}, "score": "76.53641"}
{"text": "In each case , the horizontal axis is the tone to noise ratio , and the vertical axis is the predicted proportion of the time that the standard noise - masked tonal stimulus was picked as having a higher pitch strength than the IRN stimulus .", "label": "", "metadata": {}, "score": "76.55379"}
{"text": "The SAI for a noise will consist of sustained activity , proportional to the energy present in each channel .The effect of low - pass filtering and compression .After the filterbank stage in AIM , the NAP stage simulates the response of the inner hair cells to the motion of the basilar membrane .", "label": "", "metadata": {}, "score": "76.59024"}
{"text": "Soc .Am . , 108 , p.1170 - 1180 .[ 1 ] .Ladefoged , P. and Broadbent , D.E. ( 1957 ) .\" Information Conveyed by Vowels .\" J. Acoust .Soc .Am . , 29 , p.98 - 104 .", "label": "", "metadata": {}, "score": "76.76614"}
{"text": "An ad - hoc set of rules is used to modify these targets depending on the combination of allophones ...Annosoft Lipsync Toolkit - Offers speech tools SDK for building automatic realtime animation lipsync , closed captioning and annotation applications .Clever downloadable demo animation lipsyncs to your microphone speech or .", "label": "", "metadata": {}, "score": "76.80481"}
{"text": "In these systems , the timeout is more explicitly encoded in the threshold .In the ' parabola ' case , the threshold is ' thrown ' up from a strobe peak in a parabolic shape .The parabola is then truncated after some period of time and the threshold then decays linearly .", "label": "", "metadata": {}, "score": "76.85317"}
{"text": "STRAIGHT works by first extracting a pitch , or fundamental frequency ( f 0 ) track for a sound .This is done by a combination of spectral and temporal analysis .In the frequency domain , instantaneous f 0 extraction is performed using an analysis wavelet that encodes prior information about the expected shape of the distribution of harmonics in a voiced speech sound .", "label": "", "metadata": {}, "score": "76.8664"}
{"text": "Given this choice of boxes , dense features are computed from each one in turn .The image inside each box is downsampled to the size of the smallest box .This rescaling causes the larger rectangles to be viewed at a coarser resolution .", "label": "", "metadata": {}, "score": "76.88184"}
{"text": "Examples of sex - dependent gestures are \" thank you \" and \" goodbye \" in Zimbabwe .The International Society for Gesture Studies ( ISGS ) investigates , among others , the roles and organization of gesture in face - to - face conversation , universal and cultural aspects of gesture , and gesture 's relationship to thought and language .", "label": "", "metadata": {}, "score": "76.898026"}
{"text": "45 Burkhardt et al .( 2011 ) described some intuitive and easy gestures for the elderly .They made an experiment where test subjects were asked to make gestures with the WiiMote controller to scroll ( right , left , up , down ) , zoom , renew , and navigate in a relational database .", "label": "", "metadata": {}, "score": "76.93776"}
{"text": "We describe the version six release of Joshua , an open - source statistical machine translation toolkit .The main difference from release five is the introduction of a simple , unlexicalized , phrase - based stack decoder .This phrase - based decoder shares a hypergraph format with the syntax - based systems , permitting a tight coupling with the existing codebase of feature functions and hypergraph tools .", "label": "", "metadata": {}, "score": "76.93855"}
{"text": "Once a strobe has occurred and the filter response starts to fall , the system can simply ' follow ' the decaying envelope of the filter down .Any peaks at or below the envelope of the decaying filter 's response at a certain time after the strobe can be ignored .", "label": "", "metadata": {}, "score": "76.97371"}
{"text": "Given the effectiveness of the DCT in lowering the dimensionality of the spectrum in MFCCs , a potential feature of interest might be created by taking the first DCT coefficient from each column of the SSI - generating a per - cycle MFCC - like representation .", "label": "", "metadata": {}, "score": "77.00767"}
{"text": "An increase in vocal tract length causes the resonance following each pulse to ring longer and decay more slowly .In the frequency domain , this corresponds to a shift of the spectral envelope on a log - frequency scale .A decrease in glottal pulse rate causes the time between pulses to increase ; in the frequency domain this leads to the harmonic peaks becoming more closely spaced .", "label": "", "metadata": {}, "score": "77.19847"}
{"text": "Soc .Am . , 66 , p.400- .[ 1 ] .Young , S. , Evermann , G. , Gales , M. , Hain , T. , Kershaw , D. , Moore , G. , Odell , J. , Ollason , D. , Povey , D. , Valtchev , V. and Woodland , P. ( 2005 ) .", "label": "", "metadata": {}, "score": "77.204056"}
{"text": "A comparison of Table 10 with Table 11 illustrates the benefit of using speech enhancement in improving recognition performance .Comparing Table 11 with Table 9 ( no packet loss ) it is seen that packet loss has a significant impact on the recognition results , in particular for channels C and D where the probability of packet loss is 50 % .", "label": "", "metadata": {}, "score": "77.223076"}
{"text": "This dissertation is the result of my own work and includes nothing which is the outcome of work done in collaboration .It has not been submitted in whole or in part for a degree at any other university .Some of the work has been published previously in conference proceedings . ... ly used speech parameterisation , its optimality has been questioned [ 63 , 65 , 67].", "label": "", "metadata": {}, "score": "77.23784"}
{"text": "The following four parameters define the model , and from these parameters the transition probabilities of the 3-state model can be determined : .The authors in [ 33 ] suggest that an alternative to performing speech recognition tests using simulated channels is to define a set of packet loss characteristics , thus enabling recognition performance to be analysed across a range of different packet loss conditions .", "label": "", "metadata": {}, "score": "77.270355"}
{"text": "The maxima of a given cosine fit a set of formant peaks for a vowel with a given VTL , but they can not shift to follow the formant peak pattern as it shifts with VTL .For example , the lower section of Figure 15 shows that the magnitude of the 8th coefficient changes markedly with changes in VTL .", "label": "", "metadata": {}, "score": "77.29509"}
{"text": "The back - projection system works well ( except in the case of the PZFC ) and is much better than the others in the multi - source case .However , it remains a computationally expensive alternative .For the purposes of large - scale processing of datasets , computational load is a critical concern .", "label": "", "metadata": {}, "score": "77.29674"}
{"text": "Figure 64 shows the impulse responses of the gammatone and gammachirp filters .They found that it was possible to achieve a similar fit to the masking data with a 4-parameter cGC model as could be achieved with a 6-parameter roex model .", "label": "", "metadata": {}, "score": "77.34161"}
{"text": "The cochlea is known to have a degree of nonlinearity .Another effect that a cochlear model should be able to account for is two - tone suppression ( Moore , 2003 ; Sachs and Kiang , 1968 ) , where an off - frequency stimulus can cause suppression of the on - frequency response of an auditory neuron .", "label": "", "metadata": {}, "score": "77.34903"}
{"text": "Each stage has a different time constant , which determines how much the state in a channel should be affected by the current filter output .Spatial smoothing is achieved by coupling the states to their neighbours at adjacent channels --- a simple filter convolves the AGC state for each stage with a three - channel wide triangular window , once per sample .", "label": "", "metadata": {}, "score": "77.38451"}
{"text": "However , because the AGC causes the poles of the filter to move in circular trajectories in the S - plane , the zero - crossings of the PZFC impulse response do shift with level .Recently , Lyon ( personal communication ) has shown that the positions of the zero crossings can be fixed by making the poles move parallel to the real axis , but details of this change are not currently available .", "label": "", "metadata": {}, "score": "77.536415"}
{"text": "In some cases , such as ' clock - tick ' and ' cuckoo ' , the terms are not immediately related , but it is easy to imagine how these sounds would occur together .This effect demonstrates the power of content - based models to identify examples that sound similar , even if their textual labels are incomplete or simply wrong .", "label": "", "metadata": {}, "score": "77.5719"}
{"text": "The target rate constraint ( the desired number of targets per second ) may be set to a level that achieves the desired target rate .After adjusting the target rate a statistical analyzer module 36 estimates the global statistics ( the average match rate and the average word duration ) and these statistics along with the list of targets at the selected rate are then stored as the TC word prototype database 24 .", "label": "", "metadata": {}, "score": "77.58275"}
{"text": "The dcGC and PZFC filterbanks compress the output into a smaller dynamic range than the simple gammatone filterbank .The dcGC is particularly effective in bringing up the level of the formants relative to the glottal pulses for the voiced sections .", "label": "", "metadata": {}, "score": "77.5834"}
{"text": "The linear gammatone filterbank was used as the cochlear model , the NAP was generated by half - wave rectification and was then low - pass filtered with a second - order filter with a cutoff frequency of 100Hz .Feature vectors were generated by first applying power - law compression with an exponent of 0.8 to the profile magnitude and normalising them to sum to unity .", "label": "", "metadata": {}, "score": "77.6095"}
{"text": "This section examines the performance of a DSR system in the presence of both background noise and packet loss .Channel models and loss compensation .A DSR client and server may be interconnected over either a circuit - switched channel or a packet - switched channel .", "label": "", "metadata": {}, "score": "77.62204"}
{"text": "This rotation was chosen as it causes one spoke to lie parallel to the line connecting the average woman and the average man in the GPR - VTL plane .This same configuration of scaled stimuli was used by Vestergaard et al .", "label": "", "metadata": {}, "score": "77.65135"}
{"text": "Undersampling .Having said that the SAI segregates the pulse rate information and the resonances , it is still the case that changes in the pulse rate must have an effect on the structure of the resonances in the signal .This effect is easy to see by considering a pulse - resonance signal in the frequency domain .", "label": "", "metadata": {}, "score": "77.68164"}
{"text": "In order to make these decisions , it is necessary to have a good understanding of the properties of all aspects of the system that might help them improve audio analysis tasks .In this thesis , I model a number of properties of the auditory system , from macroscopic , behavioural observations , right down to the analysis of fine timing in the cochlea , and assess systems based on these models on audio analysis tasks .", "label": "", "metadata": {}, "score": "77.71462"}
{"text": "In autocorrelation , a signal is cross - correlated with itself to yield a measure of how well - correlated the signal is with itself when delayed by a range of different ' lags ' .Zero - lag is at the centre of the output , and the function is symmetrical about this point .", "label": "", "metadata": {}, "score": "77.800415"}
{"text": "It is further suggested in [ 38 ] that , for a DSR application , it is more beneficial to trade delay for accuracy rather than trading bit - rate for accuracy as in forward error correction schemes .Reference [ 35 ] combines block interleaving to reduce burst lengths on the client side with packet loss compensation at the server side .", "label": "", "metadata": {}, "score": "77.80989"}
{"text": "The axonal conduction lines make excitatory synapses onto the coincidence detector elements .When incoming pulses arrive at roughly the same time at a given detector , within a given temporal coincidence window , the detector emits an output pulse .Trains of output pulses are then transmitted to coincidence counters , which sum spikes over a given temporal integration window to compute the running firing rates of their respective coincidence detectors .", "label": "", "metadata": {}, "score": "77.88107"}
{"text": "The ellipses show the position of , from left to right , men , women and children in the GPR - VTL plane .They are plotted at two standard deviations , so they enclose around 80 % of the speakers in that particular class .", "label": "", "metadata": {}, "score": "77.89043"}
{"text": "Users with physical impairments can speak instead of clicking on buttons ; .Users feel friendlier when speaking to Rolland ; .Rolland can intelligently make second steps ( connecting pizza with kitchen ) saving time and sparing tiresome single instructions .", "label": "", "metadata": {}, "score": "77.892654"}
{"text": "In particular , with feature reconstruction channel C shows improvements in recognition accuracy greater than 55 % for both front - ends .Channel D also shows good improvement .Nearest neighbour repetition gives a slightly higher performance compared to Hermite interpolation .", "label": "", "metadata": {}, "score": "77.94213"}
{"text": "Dynamic .In addition to being parameterised by level , the filter should be dynamically variable with a fast time constant , such that the filter can compress the glottal pulses in a pulse - resonance sound .Roex filters for frequency - domain fits .", "label": "", "metadata": {}, "score": "77.98024"}
{"text": "They used the speech synthesizer Festival .51 We draw some conclusions from some of the above related work : .Speech vocabulary and training set of words / sentences ( corpus ) are limited , but give less error rates ; .", "label": "", "metadata": {}, "score": "77.98514"}
{"text": "HandVu 58 : vision - based Hand Gesture Recognition and User Interface ( UI ) ; it detects the hand in a standard posture , then tracks it and recognizes key postures - all in real - time and without the need for camera or user calibration .", "label": "", "metadata": {}, "score": "77.99684"}
{"text": "The other filterbanks used in AIM , the PZFC and dcGC , do not have exactly the same impulse response as the gammatone , but to a first approximation the response is similar enough to allow for improved strobing .The compression applied by these filterbanks is less aggressive than the logarithmic compression used in the gammatone , so this stage can be left out when calculating the parameters of the envelope for these filterbanks .", "label": "", "metadata": {}, "score": "77.99848"}
{"text": "Two iterations shown .Figure redrawn from Yost et al .( 1996 ) .The phenomenon of a repeated noise giving rise to a pitch was first reported by Huygens ( 1693 ) , who observed that a pitch was present in the sound of a fountain opposite a flight of stone steps .", "label": "", "metadata": {}, "score": "78.018875"}
{"text": "The strobe - point - finding ( or ' strobing ' ) process identifies certain peaks in the NAP and the timings of these strobe points are used to initiate a temporal integration process in the following stage .The strobe pulses enable the segregation of the pulse and resonance information and they control pulse - rate normalisation .", "label": "", "metadata": {}, "score": "78.05582"}
{"text": "The left subfigures are for a GPR of 110 Hz and the right subfigures for a GPR of 256 Hz .Outer and middle ear .The first structures of the auditory system which are encountered by an incoming sound wave are the outer and middle ear .", "label": "", "metadata": {}, "score": "78.10343"}
{"text": "This cross - correlation is accomplished efficiently by simply sliding a piece of the waveform for each channel to move the strobe point to the centre , and adding up the five copies for the five strobe points in the frame .", "label": "", "metadata": {}, "score": "78.15156"}
{"text": "To run ASR with Julius one should prepare a language and an acoustic model .It offers , though free Japanese and English language and acoustic models .Simon 16 : it has been developed since 2007 by ' simon listens ' , a non - profit organization for research and apprenticeship .", "label": "", "metadata": {}, "score": "78.18133"}
{"text": "As with the MFCCs , performance remains high along the spokes associated with major changes in GPR .However , performance along all of the spokes also remains near ceiling , and only drops off significantly at the extremes of VTL .", "label": "", "metadata": {}, "score": "78.29903"}
{"text": "PC Command and Control - e - Speaking offers desktop command and control speech recognition software compatible with and complementary to Windows XP and Windows 2000 .A fully functional version can be downloaded for free containing over 100 built - in commands .", "label": "", "metadata": {}, "score": "78.30835"}
{"text": "The lower two vowels ( c ) and ( d ) are for the same two GPRs with a longer VTL .This figure was prepared by Ralph van Dinther in connection with Patterson et al .( 2007 ) .Used with permission .", "label": "", "metadata": {}, "score": "78.36806"}
{"text": "Transmission - line , and more recently , filter cascade models of the cochlea attempt to capture this continuous structure , and describe it as a cascaded sequence of filters .When k is independent of x , the solution is exact , and as long as k varies only slowly with x , the approximation remains valid .", "label": "", "metadata": {}, "score": "78.38417"}
{"text": "Listeners compared sequences of vowels scaled in GPR and VTL to represent speakers with slightly different sizes .The experiment was of a two - alternative forced - choice design , in which subjects were required to choose the interval with the smaller speaker .", "label": "", "metadata": {}, "score": "78.38829"}
{"text": "When the system is in an ' emitting ' state , i , it will emit a given feature vector o t with probability b i ( o t ) .HTK uses a Gaussian mixture model ( GMM ) as a continuous density multivariate output distribution to model the continuous variables from the feature vectors .", "label": "", "metadata": {}, "score": "78.42305"}
{"text": "The various previously existing strobe finding algorithms described above require either simple identification of NAP peaks or a short delay of a few milliseconds before positively identifying a NAP peak as a strobe , apart from the Lyon parabola system , which may look up to 40ms ahead .", "label": "", "metadata": {}, "score": "78.427895"}
{"text": "The pulse - resonance structure of the vowel sounds is clearly visible ; the pulses excite filters at all frequencies , leading to a periodic curved ridge in the plots .For the high glottal pulse rate ( right panels ) , the pulses occur more frequently .", "label": "", "metadata": {}, "score": "78.49269"}
{"text": "A single SAI is a snapshot of the audio in a short window around a point in time .The SAI changes continuously with time , and successive snapshots can be concatenated to make a movie of these two - dimensional frames .", "label": "", "metadata": {}, "score": "78.49677"}
{"text": "Controlling devices , like turning the TV on , for example , is another application where the SST system can be used .Making the grammar lexically rich ( with morphological and syntactic extensions ) will lead to a wider spectrum of tasks Rolland can undertake .", "label": "", "metadata": {}, "score": "78.50684"}
{"text": "The plot was generated using Lyon 's updated filter fitting routines , and it shows that the PZFC can fit the human masking data more accurately with fewer parameters than the parallel and cascade versions of the compressive gammachirp filterbank .Figure 76 --- Results from fitting the compressive gammachirp filterbank to human masking data .", "label": "", "metadata": {}, "score": "78.53955"}
{"text": "Feature vectors .In addition to these seven degrees of freedom , the energy of the profile before normalisation is also available as a further piece of information .The weights of the Gaussians are scale - independent as they are , but the means of the Gaussians are not .", "label": "", "metadata": {}, "score": "78.548706"}
{"text": "Interestingly , this transformation also has the effect of normalising out the faster decay rate of higher - frequency resonances in pulse - resonance sounds .With a logarithmic horizontal ' cycles ' axis as well , the truncation of the signal at the pitch period of the incoming waveform has the effect of placing a diagonal ' cutoff line ' in the SSI at the point where the next pitch period begins .", "label": "", "metadata": {}, "score": "78.555786"}
{"text": "The ' cold ' AGC in the PZFC will be in a different state to that when it has adapted to the incoming stimulus .Testing strobe detection .Test stimuli .In order to test a strobe detection system , a set of stimuli with known pulse times is required .", "label": "", "metadata": {}, "score": "78.604416"}
{"text": "Shoebox was operated by speaking into a microphone , which converted voice sounds into electrical impulses .Today IBM offers various products 4 to connect mobile and speech middleware .To give two examples , IBM Embedded ViaVoice 5 technology can be used for small mobile devices and automobile components .", "label": "", "metadata": {}, "score": "78.6624"}
{"text": "Dachselt , R. , Buchholz , R. , ( 2009 ) , \" Natural Throw and Tilt Interaction between Mobile Phones and Distant Displays \" in CHI 2009 , The Human - Computer Interaction Archive , April 4 - 9 , 2009 , Boston , Massachusetts , USA , pp .", "label": "", "metadata": {}, "score": "78.69343"}
{"text": "The coefficients .a . a . a . 2 and .a .3 in ( 6 ) are determined from the two correctly received feature vectors either side of the loss burst , .x .b and .x .", "label": "", "metadata": {}, "score": "78.74957"}
{"text": "Results .The following configurations of source stimulus were tested with various strobe algorithms and filterbanks : .Single - rate pulse train .Frequency - swept pulse train .Synthetic vowel .Two pulse trains with different rates .Two synthetic vowels with different rates .", "label": "", "metadata": {}, "score": "78.77817"}
{"text": "Lyon , R.F. ( 1998 ) .\" Filter cascades as analogs of the cochlea . \"Hum .Mov .Sci . , , p.3 - 18 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] .", "label": "", "metadata": {}, "score": "78.81026"}
{"text": "Figure 83 --- NAPs and SAIs generated from a 16-iteration IRN stimulus using the PZFC and gammatone filterbanks .The PZFC output is half - wave rectified and lowpass filtered ( hl ) , the gammatone filterbank output is logarithmically compressed as well as being half - wave rectified and low - pass filtered ( hcl ) .", "label": "", "metadata": {}, "score": "78.82584"}
{"text": "Gesture localization should be always taken into consideration when gesture recognition software is developed , so that the software can be used by other locales at least to the same extent as in the original locale .The curled finger gesture , for instance , to tell a robot to navigate to the user , would have not found any acceptance by users in Singapore .", "label": "", "metadata": {}, "score": "78.8374"}
{"text": "( In addition to the HMM configurations shown in this graph , odd - numbered values of the HMM parameters were also tried but , for simplicity of presentation , they are not plotted here .These results cluster in the same way . )", "label": "", "metadata": {}, "score": "78.845474"}
{"text": "Given the massive increase in data rate that happens at the BMM and SAI stages of the model , this means that only short sounds ( on the order of a few seconds ) can be processed before the host computer runs out of RAM .", "label": "", "metadata": {}, "score": "78.84686"}
{"text": "30 A speech dialog system consists of three components : speech input , internal processing , and speech output .The input has two functions : ASR and language understanding .The internal processing includes dialog management , while the speech output includes rendering and response .", "label": "", "metadata": {}, "score": "78.8806"}
{"text": "In a similar fashion the weighting factor ( reciprocal of the variance ) is converted into a scaler number by adding all of the vector elements .The final score is then computed by dividing the scaler distance by the scaler weight .", "label": "", "metadata": {}, "score": "78.94419"}
{"text": "Experiments .Dataset .The dataset used for the training and testing of the system consisted of 8,638 sound effects , from various sources .3,855 of these were from commercial sound effects libraries , and the rest from a range of websites FindSounds , Partners in Rhyme , Acoustica , I Love WAVs , SimplyTheBest Sounds , wav - sounds .", "label": "", "metadata": {}, "score": "78.960655"}
{"text": "STRAIGHT was used to generate 57 versions of the syllable database ( referred to as ' speakers ' ) in which the syllables were all transformed to have a specific combination of VTL and GPR .The seven speakers along each spoke are spaced logarithmically in log(GPR)-log(VTL ) space .", "label": "", "metadata": {}, "score": "78.96492"}
{"text": "Pulse - resonance excitation .The case of pulse - resonance excitation is an extension of the filtered pulse case .In this version , the pulse is filtered first by a resonance , and then by the auditory filter .The form of the vocal tract filter is taken to be the same as that of a gammatone filter , but with different coefficients .", "label": "", "metadata": {}, "score": "78.977646"}
{"text": "undergo post - processing in the cepstral domain by means of cepstral mean subtraction ( CMS ) .As defined by the ETSI advanced front - end [ 7 ] , each packet transmitted over the communication channel carries two feature vectors .", "label": "", "metadata": {}, "score": "79.007256"}
{"text": "Soc .Am . , 99 , p.1066 - 1078 .[ 1 ] [ 2 ] .Yost , W.A. , Patterson , R. and Sheft , S. ( 1998 ) .\" The role of the envelope in processing iterated rippled noise .", "label": "", "metadata": {}, "score": "79.04067"}
{"text": "8 is a series of graphs illustrating alignment time by stage ( left ) and alignment time ratio versus lexicon size ( right ) .Alignment time is given for one test word aligned to 100 reference words .Corresponding alignment time for the fine match is 3.4 seconds .", "label": "", "metadata": {}, "score": "79.05629"}
{"text": "[ 1 ] .Gomersall , P.A. , Walters , T.C. and Patterson , R.D. ( 2005 ) .\" Size and temperature information in bullfrog calls .\"Howpublished :Poster , British Society of Audiology short papers meeting , Cardiff , UK .", "label": "", "metadata": {}, "score": "79.1265"}
{"text": "Object Description General Discussion Map Reading Photographic Interpretation Cartoon Description Table 4.1 : Message classes in classification experiments of Rose et al .Now , an estimate of I(C i ; w k ) can be calculated by a four -- way partition of the set of test messages , depending on ( a ) whether ... \" .", "label": "", "metadata": {}, "score": "79.13054"}
{"text": "Kurimo , M. et al .( 2010 ) , \" Personalising speech - to - speech translation in the EMIME project \" , in Proceedings of the ACL 2010 System Demonstrations , Uppsala , Sweden .Lee , A. , Kawahara , T. ( 2009 ) , \" Recent Development of Open - Source Speech Recognition Engine Julius \" in Asia - Pacific Signal and Information Processing Association Annual Summit and Conference ( APSIPA ASC ) .", "label": "", "metadata": {}, "score": "79.16596"}
{"text": "The leftmost column shows the SAI temporal profile for a zero - iteration IRN , which is a noise .The remaining columns show the response for 1 , 2 , and 4 iteration IRN stimuli .For the 1 , 2 and 4 iteration IRN , a peak is expected in the temporal profile at 8ms time interval .", "label": "", "metadata": {}, "score": "79.1701"}
{"text": "Benzeghiba , M. , De Mori , R. , Deroo , O. , Dupont , S. , Erbes , T. , Jouvet , D. , Fissore , L. , Laface , P. , Mertins , A. , Ris , C. and Others ( 2007 ) . \"", "label": "", "metadata": {}, "score": "79.228775"}
{"text": "Namely , the product W a is viewed as a ' bag of words ' description of the audio document , and the dot product of this bag of words with the query words q gives the score .The learning goal is then to learn this matrix W , so that the scoring function gives relevant documents a higher score than irrelevant ones .", "label": "", "metadata": {}, "score": "79.29253"}
{"text": "Human - computer interaction ( HCI ) is indispensable part in ICT and speech recognition and synthesis are intuitive realizations of HCI .There have been many research initiatives and advances in AAL environment the last years , for example , AALIANCE project 65 , AAL Joint Programme 66 and so on .", "label": "", "metadata": {}, "score": "79.37225"}
{"text": "However , in understanding sounds , the human auditory system takes a very different approach , and one which has the benefit of several hundred million years of the force of evolution behind it .In this thesis I have investigated the hypothesis that , in order to build automated systems that understand sounds , we would do well to make use of the many tricks that the auditory system has developed over this time .", "label": "", "metadata": {}, "score": "79.38214"}
{"text": "The use of the Internet for accessing information has expanded dramatically over the past few years , while the availability and use of mobile hand - held devices for communication and Internet access has greatly increased in parallel .Industry has reacted to this trend for information access by developing services and applications that can be accessed by users on the move .", "label": "", "metadata": {}, "score": "79.413956"}
{"text": "Tools . by George Ferguson , James F. Allen - In Proceedings of the Fifteenth National Conference on Artificial Intelligence ( AAAI-98 , 1998 . \" ...We discuss what constitutes an integrated system in AI , and why AI researchers should be interested in building and studying them .", "label": "", "metadata": {}, "score": "79.43335"}
{"text": "Some research projects which developed SST systems are TC - STAR ( 2004 - 2007 ) , LC - STAR ( 2002 - 2005 ) , NESPOLE ! ( 2000 - 2002 ) , TONGUES ( 2000 - 2002 ) , and Verbmobil ( 1996 - 2000 ) .", "label": "", "metadata": {}, "score": "79.604126"}
{"text": "Computers in Translation and Linguistics , Report by the Automatic Language Processing Advisory Committee ( ALPAC ) , Division of Behavioral Sciences , National Academy of Sciences , National Research Council .Reddy , A. Rose , R. Desilets , A. ( 2007 ) , \" Integration of ASR and Machine Translation Models in a Document Translation Task \" , in InterSpeech 2007 , Antwerp , Belgium .", "label": "", "metadata": {}, "score": "79.648994"}
{"text": "However , the process then continues to encode the ' residual ' , the difference between the codeword and the original input .The residual is calculated and is again matched to the closest codeword .This process continues until either the residual is smaller than some limiting value , or the maximum number of codewords is reached .", "label": "", "metadata": {}, "score": "79.6763"}
{"text": "In practical terms , the cGC can be implemented as a gammachirp filter with an arbitrary value of the chirp parameter , c , cascaded with an ' asymmetry function ' , which is either high - pass or low - pass , depending on c ( Patterson et al . , 2003 ) .", "label": "", "metadata": {}, "score": "79.69032"}
{"text": "When processing a pulse - resonance communication sound in AIM , it is desirable that the strobe points should fall at points in the NAP signal which were caused by a pulse in the original sound .When this occurs , the resonances following each pulse are added exactly in phase in the auditory image , such that the resonances following each vertical ridge in the image resemble as closely as possible the original resonances in the sound .", "label": "", "metadata": {}, "score": "79.69603"}
{"text": "Performance in this case is somewhat improved , rising to 86.7 % overall , and 37.8 % at the shortest VTL .The improvement in performance is mainly due to the stability of the results across the pitch dimension when there is a pitch cutoff on the SSI .", "label": "", "metadata": {}, "score": "79.842735"}
{"text": "The FFT magnitude coefficients are grouped into the appropriate critical bands and then weighted by the triangular filters .The energies in each band are summed , creating a filter bank vector of spectral energies on the mel scale .The size of this vector of spectral energies is equal to the number of triangular filters used .", "label": "", "metadata": {}, "score": "79.90322"}
{"text": "TTS is used , for example , by blind people through screen readers , software applications that interpret what is being displayed on the screen .In addition , TTS can be used in education to help foreign language learning .22 TTS technology can be categorized into concatenative and formant .", "label": "", "metadata": {}, "score": "80.02942"}
{"text": "In order to combat this effect , the decay time was extended to 50ms when using the PZFC with the back - projection strobe system .The likely explanation for this behaviour is that the calculated impulse response of the PZFC filterbank does not match up well with the real impulse responses seen in the filterbank .", "label": "", "metadata": {}, "score": "80.03256"}
{"text": "High amplitudes at the start of a period and low amplitudes at the end , since the vocal tract can be assumed to be a linear passive system whose impulse response consists of exponentially decaying sinusoids ( Fant , 1960 ) .", "label": "", "metadata": {}, "score": "80.06433"}
{"text": "Google develops software for translator phone 49 by analyzing chunks of speech , and translating them in their entirety .Jibbigo 50 : it is an SST application for mobile devices .Its available language pairs are Chinese - English , French - English , German - English , Iraqi Arabic - English , Japanese - English , Korean - English , Spanish - English , and Tagalog - English .", "label": "", "metadata": {}, "score": "80.080284"}
{"text": "Soc .Am . , 113 , p.2790 - 2800 .[ 1 ] .Krumbholz , K. , Patterson , R.D. and Pressnitzer , D. ( 2000 ) .\" The lower limit of pitch as determined by rate discrimination .", "label": "", "metadata": {}, "score": "80.091446"}
{"text": "Given these parameters , the ' temporal shadow ' strobe criterion can be updated to take into account the known properties of the filter in each channel .To determine the time constants in each channel , the filter response derived above is processed to mimic the effect of the NAP stage on the filter output .", "label": "", "metadata": {}, "score": "80.11575"}
{"text": "The definition of Machine Translation ( MT ) is the automatic translation of text or speech from one natural language ( source language ) into another ( target language ) by means of computer software .In 1955 the first MT experiment between Georgetown University and IBM took place ; it translated 60 sentences from Russian into English .", "label": "", "metadata": {}, "score": "80.21112"}
{"text": "This allows AIM - C to process arbitrarily long pieces of audio , limited only by the available hard drive space of the host machine .AIM - C is also significantly faster at processing sounds , since it is written in C++ rather than MATLAB .", "label": "", "metadata": {}, "score": "80.21746"}
{"text": "Res . , 66 , p.31 - 45 .[ 1 ] .Rhode , W.S. and Robles , L. ( 1974 ) .\" Evidence from M\u00f6ssbauer experiments for non - linear vibration in the cochlea .\" J. Acoust .", "label": "", "metadata": {}, "score": "80.2675"}
{"text": "The Johns Hopkins University MultiModal Action ( JHUMMA ) dataset contains a set of twenty - one actions recorded with four sensor systems in three different modalities .The data was collected with a data acquisition system that includes three independent active sonar devices at three different frequencies and a Microsoft Kinect sensor that provides both RGB and Depth data .", "label": "", "metadata": {}, "score": "80.28687"}
{"text": "Given the results presented above , the features generated from the SSI would be expected to be more noise - robust that those generated from the NAP .In this chapter I have tested one possible feature representation generated from the SAI in a constrained task .", "label": "", "metadata": {}, "score": "80.30814"}
{"text": "Finally , the form of the threshold in each channel is pre - calculated to follow the form of the decaying envelope of a driven filter in that channel .This threshold follows the real envelope of the NAP more closely than a linear threshold .", "label": "", "metadata": {}, "score": "80.36267"}
{"text": "Dragon NaturallySpeeking 7 ASR system works today with most Windows applications , has Nuance Text - to - Speech ( TTS ) technology , and reaches up to 99 % ASR accuracy 8 .The latest features , as of version 11 , show more intuitive user interface ( elimination of distractions ) , improved accuracy ( 15 % greater than previous version ) , and faster performance .", "label": "", "metadata": {}, "score": "80.424736"}
{"text": "The system is described by the following transfer function : .The natural frequencies of the pole and the zero are constants , decreasing from one stage to the next , along a cochlear frequency - place map , or ERB - rate scale .", "label": "", "metadata": {}, "score": "80.43956"}
{"text": "In a world where authentication and privacy are taking a lot of our daily efforts , it is becoming more important for us to prove our identity to different systems every day so that we can access required and useful services .", "label": "", "metadata": {}, "score": "80.44148"}
{"text": "In a world where authentication and privacy are taking a lot of our daily efforts , it is becoming more important for us to prove our identity to different systems every day so that we can access required and useful services .", "label": "", "metadata": {}, "score": "80.44148"}
{"text": "With Hermite interpolation , Table 13 shows that the front - end of Li et al .outperforms the ETSI advanced front - end for the packet loss conditions of channels A and B , however , for channel C the reverse is the case .", "label": "", "metadata": {}, "score": "80.45888"}
{"text": "AIM - C by contrast provides capabilities for the fast processing of long audio files through a pre - prepared set of modules .Both AIM - MAT and AIM - C were written in the CNBH lab in Cambridge .AIM - MAT was written by Stefan Bleeck and was released in 2004 .", "label": "", "metadata": {}, "score": "80.45967"}
{"text": "In order to make a good digital filter , the model either needs to be described in terms of poles and zeros , be convertible to such a description , or be approximated by such a description .Connection to the underlying assumptions about the travelling - wave hydrodynamics of the cochlea .", "label": "", "metadata": {}, "score": "80.488235"}
{"text": "The bullfrog and macaque calls were kindly provided by Mark Bee and Asif Ghazanfar respectively .Figure 3 ( as published in Patterson et al . , 2008 ) shows the communication ' syllables ' of four different animals .Each ' syllable ' is an example of a pulse - resonance sound .", "label": "", "metadata": {}, "score": "80.551056"}
{"text": "Tutorials and the demo version of the library are available online .VDK is offered by NetResults S.r.l .a spin off company from the University Of Pisa in Italy .Voxi - Swedish company which develops and licenses a general - purpose speech recognition software platform , Intelligent Speech Interfaces ( TM ) , natural language understanding , and high - quality audio feedback .", "label": "", "metadata": {}, "score": "80.581955"}
{"text": "This corresponds to a multiplication of the resonance envelope by a comb of peaks in the frequency domain : the resonance is ' sampled ' at the harmonics of the driving function .Thus although the pulse - resonance production mechanism allows a signal to be generated over longer time scales than the length of a single damped resonance , in doing so it causes information about the structure of the resonance to be lost .", "label": "", "metadata": {}, "score": "80.60115"}
{"text": "In this section , the 3-state model proposed in [ 33 ] is used to simulate packet loss and loss bursts .To compensate for missing packets , two error - concealment methods are examined , namely nearest neighbour repetition and interpolation .", "label": "", "metadata": {}, "score": "80.66058"}
{"text": "Packet loss parameters .Packet loss mitigation .Two error concealment methods are examined , namely nearest neighbour repetition and interpolation .These methods attempt to reconstruct the feature vector stream when packet loss is detected .Missing feature vectors are estimated solely from correctly received feature vectors .", "label": "", "metadata": {}, "score": "80.67273"}
{"text": "The major difference between the MFCC and SAI representations is that SAIs retain better the fine timing information in the signal , whereas MFCCs better preserve the fine spectral structure ( especially when the number of MFCC coefficients is large ) .", "label": "", "metadata": {}, "score": "80.67584"}
{"text": "Also , the Speechlator ( part of BABYLON project , 2003)was a two - way system working with Arabic as TL on a consumer PDA .28 More recently , some tools which offer SST systems are the following : .Google 's Conversation Mode 48 : in 2010 it was announced thatin Android operating systems there will be a conversation mode , where users speak , Google Translate translates their speech , and reads the translation out loud ( currently that is available for English - Spanish ) .", "label": "", "metadata": {}, "score": "80.6861"}
{"text": "Various more complicated versions of the filter emerged , with up to six free parameters .In this way , the roex family could be used to fit human masking data very accurately , but at the expense of adding many additional free parameters .", "label": "", "metadata": {}, "score": "80.73703"}
{"text": "The profiles for the zero - iteration IRN ( just noise ) show little temporal structure , as we would expect .It is clear from inspection that the gammatone filterbank with logarithmic compression produces profiles in which the peak in the profile which corresponds to the perceived pitch is much less strong than for the other filterbanks .", "label": "", "metadata": {}, "score": "80.74277"}
{"text": "Soc .Am . , 104 , p.2349 - 2361 .[ 1 ] [ 2 ] [ 3 ] .Yost , W.A. and Hill , R. ( 1979 ) .\" Models of the pitch and pitch strength of ripple noise .", "label": "", "metadata": {}, "score": "80.75575"}
{"text": "and It 's fun to wreck a nice beach ? , sound the same .A statistical language model assigns a probability to a sequence of words by means of a probability distribution .It should be pointed out that language modeling is not related only to speech recognition , but also MT , PoS - tagging and Information Retrieval ( IR ) .", "label": "", "metadata": {}, "score": "80.78639"}
{"text": "The human auditory system .The human auditory system is an immensely powerful signal processing system .The anatomy of the peripheral auditory system is illustrated in Figure 7 .One of the central premises of this thesis is that a great deal may be learned from the auditory system about the best strategies for the extraction of salient information from sounds .", "label": "", "metadata": {}, "score": "80.860634"}
{"text": "The expectation maximisation ( EM ) algorithm ( Dempster et al . , 1977 ) was used to fit Gaussian components to the AIM spectral profile .The EM algorithm is an iterative process which seeks to find the set of parameters for the Gaussian components which allows them to fit the spectral profile as closely as possible .", "label": "", "metadata": {}, "score": "80.89479"}
{"text": "The vectors across the GPR - VTL plane were integrated to estimate the size surface .The results indicated that the size surface would be essentially planar if determined by size discrimination alone .This suggests that relative size judgements are different from absolute size judgements .", "label": "", "metadata": {}, "score": "80.923454"}
{"text": "A report by Santo Pietro and Ostuni ( 1997 ) denoted that at least 30 - 40 % of direct care staff in health care settings are from backgrounds other than native English - speaking Euro - American , while 90 % of the residents are native English - speaking Euro - American .", "label": "", "metadata": {}, "score": "81.16057"}
{"text": "Company product and support information is available .Speech Filing System - Tools for Speech Research - SFS provides a computing environment for conducting research into the nature of speech .It comprises free software tools ; special file and data formats ; subroutine libraries for I / O , signal processing and graphics ; use and documentation standards ; and special programming languages .", "label": "", "metadata": {}, "score": "81.265366"}
{"text": "Figure 91 shows cochleagrams for the baseline PZFC parameter set ( top ) and the parameter sets 8 and 9 ( middle and bottom ) for the word ' washwater ' once again .Parameter set 9 produced a considerably higher pitch strength estimate than parameter set 8 for the harmonic complex stimulus .", "label": "", "metadata": {}, "score": "81.348465"}
{"text": "Obviously it is trivial to encode such a vector as a single integer : the index of the nonzero element .Matching pursuit .In addition to the simple VQ scheme described above , we also used a matching pursuit ( MP ) based encoding scheme to allow a less sparse , but potentially richer representation to be used ( Bergeaud and Mallat , 1995 ; Mallat and Zhang , 1993 ) .", "label": "", "metadata": {}, "score": "81.36456"}
{"text": "The process proceeds inductively or iteratively in this fashion , each new utterance being combined with the previous ones such that the sum and sum of squares vectors ultimately represent the accumulated data from all of the utterances .Once all training utterances have been processed in this fashion the vector mean and vector variance are calculated .", "label": "", "metadata": {}, "score": "81.43021"}
{"text": "This maximum rise time can be calculated in each channel in the same way .Adding a carrier .This analysis has so far been carried out only for the envelopes of the functions involved .If the carrier is included in the calculation as well , the ensuing expression becomes even more complicated .", "label": "", "metadata": {}, "score": "81.47598"}
{"text": "1379 - 1398 , Oct. 2006 .33 - B.P. Milner and A.B. James , \" An analysis of packet loss models for distributed speech recognition \" , in Proc . of 8th International Conference on Spoken Language Processing ( ICSLP ) , Jeju Island , Korea , Oct. 2004 , pp . 1549 - 1552 .", "label": "", "metadata": {}, "score": "81.49394"}
{"text": "See Lyon and Mead ( 1988 ) for a complete treatment of the mathematics .This led the way for a set of cochlear models known as ' cascade filterbanks ' ( Lyon , 1998 ) in which the continuous BM is modelled as a chain of discrete filters with output ' taps ' between successive stages ( Lyon , 1998 ) .", "label": "", "metadata": {}, "score": "81.49765"}
{"text": "However , for practical purposes , the Lyon SAI technique is an effective and efficient method for generating an SAI .The AIM - SAI as used in this study uses a variant of the local maximum algorithm ( see chapter 3 ) for strobe - detection , and the ti2003 system ( as employed in both AIM - MAT and AIM - C ) for SAI generation .", "label": "", "metadata": {}, "score": "81.5127"}
{"text": "The first of these [ 10 ] specifies the real - time transport protocol ( RTP ) payload format for the basic front - end while the second [ 11 ] specifies the RTP payload format for the advanced front - end .", "label": "", "metadata": {}, "score": "81.625656"}
{"text": "For this analysis , it is assumed that the auditory filter is a simple gammatone or gammachirp filter , without any compression built in .This means that the filter has a known envelope of the form where the subscript a refers to the fact that this is the auditory filter .", "label": "", "metadata": {}, "score": "81.714386"}
{"text": "Deletions ( D ) - A word in the original sentence is missed .Insertions ( I ) - A new word is inserted between two words of the original sentence .The performance measure used throughout the work presented here , and also used in [ 16 ] , is the word accuracy as defined by ( 1 ): .", "label": "", "metadata": {}, "score": "81.73314"}
{"text": "All points which are not local maxima are ignored .When the signal exceeds threshold , the threshold is set to the level of the signal at that time , and that point is labelled as a strobe candidate .The threshold decays according to the longest possible decay of the filter in that channel when struck with a damped formant .", "label": "", "metadata": {}, "score": "81.83692"}
{"text": "Clara Suied generated an interesting set of bandpass - filtered harmonic complexes for an experiment on the perception of pitch height .These stimuli were 125Hz harmonic tones , in which the 9th harmonic was the lowest component .The envelope of the amplitude spectrum was flat in a pass band which was six ERBs wide .", "label": "", "metadata": {}, "score": "81.86948"}
{"text": "Having this as motivation , we want to move from a monolingual setting to a multilingual one .BAALL is the environment and Rolland the implementation device of our designed platform .54 The user can interact through speech with Rolland in BAALL to navigate through the living areas .", "label": "", "metadata": {}, "score": "81.87177"}
{"text": "HTK3 is available for free download as C source .Used at hundreds of research sites world wide .Institute for Language and Speech Processing - Founded in Athens ( Greece ) in 1991 under the auspices of the General Secretariat of Research and Technology of the Ministry of Development .", "label": "", "metadata": {}, "score": "81.9132"}
{"text": "Bekesy von G , 1967 Sensory Inhibition ( Princeton : Princeton University Press ) .Boring E G , 1933 The Physical Dimensions of Consciousness ( New York : Dover ) .Braitenberg V , 1961 \" Functional interpretation of cerebellar histology \" Nature 190 , 539 - 540 .", "label": "", "metadata": {}, "score": "81.92512"}
{"text": "This is the parameter set used in the experiments described in section 2 of chapter 4 .The PZFC was developed by Dick Lyon , based on his previous work on cascade filterbanks .I developed versions of the PZFC filterbank for AIM - MAT and AIM - C , based on Lyon 's original implementation .", "label": "", "metadata": {}, "score": "81.92815"}
{"text": "Synthetic vowel - 200ms length , 8ms repetition rate .Line 1 : percentage of pulses correctly identified .Line 2 : mean number of strobes per pulse . lyon .Multi - source stimuli .The test system described above is less robust for the multi - source stimuli than it is for the single - source stimuli .", "label": "", "metadata": {}, "score": "82.112175"}
{"text": "This is an incremental step towards understanding exactly which aspects of human auditory processing are necessary for effective machine hearing .A short history of models of auditory filtering .The presence of a set of simple damped resonances , or filters , in the cochlea was conjectured by von Helmholtz ( 1875 ) , but the idea of resonances in the human auditory system had been discussed as early as 1605 ( Wever , 1949 ) .", "label": "", "metadata": {}, "score": "82.20356"}
{"text": "The longest decay times will be associated with the smallest formant bandwidths , so for a 50Hz formant bandwidth , \u03b1 v will be around .This gives an upper bound on the expected envelope of the filter response when it is driven by a formant of speech .", "label": "", "metadata": {}, "score": "82.21669"}
{"text": "Figure 2 .Aurora 2 database .The recognition problem examined in this work is connected digit recognition using the Aurora 2 database [ 16 ] .The motivation behind the creation of the Aurora database was to provide a framework that allowed for the evaluation and comparison of speech recognition algorithms in noisy conditions , thus providing a good basis for comparison between researchers .", "label": "", "metadata": {}, "score": "82.230934"}
{"text": "The PZFC automatic gain control ( AGC ) is achieved by a temporal and spatial smoothing network .This network takes the output of all the channels , applies smoothing in both the time and frequency dimensions , and uses both global and the local averages of the filterbank response to affect the pole damping , \u03be p at each stage .", "label": "", "metadata": {}, "score": "82.336464"}
{"text": "These marginals are known as the ' temporal profile ' and ' spectral profile ' of the image .The SAI spectral profile is essentially a smoothed and temporally averaged version of the filterbank output .The temporal profile summarises information concerning the time intervals between prominent NAP pulses , and the time intervals in the fine structure following prominent pulses .", "label": "", "metadata": {}, "score": "82.39216"}
{"text": "In the spectral domain , the delay - and - sum process adds a small ' ripple ' to the spectrum of the sound , which gives it a weak harmonic structure .Repeated iterations of the delay - and - sum process enhance the depth of the ripple .", "label": "", "metadata": {}, "score": "82.40921"}
{"text": "According to McNeil ( 1992 ) , gestures are the movements of the hands and arms that we see when people talk .The meanings of ' gesture ' as an action performed to convey a feeling or intention , oran action performed for show in the knowledge that it will have no effect are not considered here .", "label": "", "metadata": {}, "score": "82.409775"}
{"text": "Robust Distributed Speech Recognition Using Auditory Modelling .[ 1 ] School of Engineering , Athlone Institute of Technology , Athlone , , Ireland .[ 2 ] College of Engineering and Informatics , National University of Ireland , Galway , , Ireland .", "label": "", "metadata": {}, "score": "82.41997"}
{"text": "Figure 54 shows the regions of the SSI used to calculate the four feature variants used in the experiments , and the spectral profile for each region .Figure 54 --- The four SSI variants used in the experiments .Each SSI is for the same /i/ vowel , spoken by a male .", "label": "", "metadata": {}, "score": "82.52857"}
{"text": "A database of 185 human utterances , consisting of 180 syllables and five vowels , was used as the basis for the experiments .The database consists of five strong vowels ( /a/ , /e/ , /i/ , /o/ , /u/ ) crossed with 6 sonorant consonants , 6 fricative consonants and 6 stop consonants to produce 90 consonant - vowel and 90 vowel - consonant pairs .", "label": "", "metadata": {}, "score": "82.57893"}
{"text": "This means that changes in VTL correspond to simple shifts of the image .Patterson et al .( 2007 ) provide an overview of the mathematics of the SSI and the process of generating images .Figure 50 --- Four synthetic two - formant vowels , that differ in pitch and VTL .", "label": "", "metadata": {}, "score": "82.588196"}
{"text": "Indeed , the chirp parameter of any gammachirp filter can be modified by cascading it with an asymmetric compensation function of the correct form .Such a cascade architecture is used in the dcGC filterbank to dynamically modify the chirp parameter of each filterbank stage independently as a function of the input signal .", "label": "", "metadata": {}, "score": "82.589134"}
{"text": "Many of the tools developed in this thesis may prove useful for the future study of machine hearing .The source code for AIM - C is available online under the Apache 2.0 licence which allows for free copying and development for both commercial and noncommercial applications .", "label": "", "metadata": {}, "score": "82.59572"}
{"text": "To allow for close comparison between the ETSI advanced front end and the front - end proposed by Li et al . , the VQ codebooks for Li et al . should be determined in the same manner as the VQ codebooks for the ETSI advanced front - end .", "label": "", "metadata": {}, "score": "82.6134"}
{"text": "An alternative simple strobe detection system was developed by Dick Lyon for use in the sound effects ranking experiments described in chapter 6 .In this system , the signal in each channel is multiplied pointwise by a windowing function .The maximum point in the windowed signal is the strobe point .", "label": "", "metadata": {}, "score": "82.61355"}
{"text": "The ' baseline ' rectangle size was chosen to be 16 samples in the lag dimension , by 32 filterbank channels .From this size , both dimensions were multiplied up by powers of 2 up to the largest size box that fits in the SAI frame .", "label": "", "metadata": {}, "score": "82.66417"}
{"text": "This mechanism was , found to be suboptimal for the specific task of accurate , on pulse , strobe detection .Thus , it was somewhat surprising to discover that the AIM - SAI system , which made use of a better strobe finding mechanism , was found to support almost identical performance to the Lyon - SAI with baseline parameters .", "label": "", "metadata": {}, "score": "82.66711"}
{"text": "Akin to filtering in the frequency domain , ' liftering ' can be applied in the cepstral domain .Typically the mel - frequency cepstrum is low - pass liftered by discarding all but the lowest DCT coefficients ( in many standard implementations , the first 13 coefficients are retained ) .", "label": "", "metadata": {}, "score": "82.69757"}
{"text": "The thesis describes novel techniques and algorithms for the practical parsing of realistic Natural Language ( NL ) texts with a wide - coverage unification - based grammar of English .The thesis starts by presenting a new unification algorithm , justifies why it is well - suited to practical NL parsing , and describes a bottom - up active chart parser which employs this unification algorithm together with several other novel processing and optimisation techniques .", "label": "", "metadata": {}, "score": "82.70591"}
{"text": "shows the results from this experiment .Swept pulse train - 1000ms length , 10ms - 5ms repetition rate .Line 1 : percentage of pulses correctly identified .Line 2 : mean number of strobes per pulse . lyon .In the third experiment , a synthetic three - formant /a/ vowel was used .", "label": "", "metadata": {}, "score": "82.75589"}
{"text": "The cosines associated with the 8th coefficient of the three feature vectors are shown in the lower part of Figure 15 .Since the DCT basis functions are cosines , they can not change phase and are all constrained to have a maximum at zero .", "label": "", "metadata": {}, "score": "82.82828"}
{"text": "In order to optimise these variables , and to provide a suitable comparison between systems , an exhaustive search was performed over all these variables for each of the two datasets .HMM topologies from 1 to 6 emitting states , and from 1 to 7 Gaussians in the output distribution were tested .", "label": "", "metadata": {}, "score": "82.91846"}
{"text": "In that study , Smith et al .presented scaled versions of five human vowels ( /a/ , /e/ , /i/ , /o/ and /u/ ) to human subjects in a 5-alternative forced - choice experiment .The vowels were scaled in GPR and VTL using the vocoder STRAIGHT ( Kawahara et al . , 1999 ) .", "label": "", "metadata": {}, "score": "82.9308"}
{"text": "The SRI Language Modeling Toolkit 3 is a toolkit for building and applying statistical language models .9 On the other side , acoustic models ' compile ' audio speech recordings and their transcriptions into statistical representations of the sounds that make up each word .", "label": "", "metadata": {}, "score": "82.96596"}
{"text": "The pulse rate determines the pitch of the sound , and the form of the resonance contains information about the shape and the size of the resonating structures in the body of the animal .The pulse production mechanisms used by the fish , the frog and the mammals in this example are very different .", "label": "", "metadata": {}, "score": "82.98557"}
{"text": "Figure 71 shows the response of a single filter stage as the pole position is modified by the AGC system .The pole dampings in each channel are scaled ( increased from their values in quiet ) by a factor proportional to the mean of the four AGC stages in that channel .", "label": "", "metadata": {}, "score": "83.057846"}
{"text": "The voiced parts of human speech take the form of pulse - resonance signals .The production mechanism for these sounds is simple : the vocal folds interrupt the stream of air from the lungs periodically , producing a stream of pulses which excite resonances of the vocal tract above the larynx .", "label": "", "metadata": {}, "score": "83.07869"}
{"text": "Figure 77 --- Response of the passive gammachirp filter ( pGC ) , the high - pass asymmetry function ( HP - AF ) , and the compressive gammachirp ( cGC ) filter for probe levels of 30 , 40 , 50 , 60 , and 70 dB. Figure taken from Irino and Patterson ( 2006 ) used with permission of the authors .", "label": "", "metadata": {}, "score": "83.09416"}
{"text": "( 2000 ) .Above the flat pass band , the envelope of the amplitude spectrum was smoothly attenuated to zero with a quarter - cycle cosine envelope function .Below the passband , the envelope was simiarly raised from zero with a quarter - cycle sine envelope .", "label": "", "metadata": {}, "score": "83.14179"}
{"text": "The formants appear as ' flags ' running horizontally from the vertical pitch ridge .The formats shift up in frequency and get narrower in the time - interval dimension from the long VTL waveforms to the short VTL .The horizontal axis is now time interval rather than time .", "label": "", "metadata": {}, "score": "83.28954"}
{"text": "The second stimulus is two synthetic vowels , an /a/ vowel with an 8ms pulse rate and an /i/ vowel with a 5ms pulse rate .The two vowels had the same amplitude .shows the results .Two synthetic vowels - 200ms length , 8ms repetition rate /a/ vowel and 5ms repetition rate /i/ vowel .", "label": "", "metadata": {}, "score": "83.32361"}
{"text": "YAKiToMe !47 : this is a web service where one can copy and paste text into a box , select a topic , and the text will be converted to audio .Then the Podcast Library page displays how long users have to wait before their audio file is ready for listening .", "label": "", "metadata": {}, "score": "83.35594"}
{"text": "Figure 62 --- Recognition results for the SSI - slice profile AIM features , where the model was trained and tested in noise .Figure 63 shows the results for the AIM SSI features ( without pitch cutoff ) and the AIM NAP features for comparison .", "label": "", "metadata": {}, "score": "83.43924"}
{"text": "In the left panels , the glottal pulse rate ( GPR ) is 110Hz and in the right panels the GPR is 256Hz .In the next few sections , the workings of AIM will be discussed .In order to illustrate each stage , four STRAIGHT - scaled vowel sounds will be processed using the model , and plotted side - by - side for comparison .", "label": "", "metadata": {}, "score": "83.58629"}
{"text": "The pitch feature in the SAI of the PZFC is better defined than that in the SAI of the simple gammatone filterbank .Measures of pitch strength .In order to further investigate the pitch strengths produced by the three filterbanks it is necessary to have some absolute measure of pitch strength in the SAI temporal profile .", "label": "", "metadata": {}, "score": "83.61749"}
{"text": "The Gilbert model was found in [ 3 ] to be inadequate for simulating a GSM channel and instead a two - fold stochastic model is used in which there are two processes , namely shadowing and Rayleigh fading .This same model was used by [ 32 ] , again to model a GSM network .", "label": "", "metadata": {}, "score": "83.68677"}
{"text": "Speech enhancement , no error mitigation .Two methods , nearest neighbour repetition and Hermite interpolation , are used to reconstruct the feature vector stream as a result of missing features due to packet loss .Table 12 details the recognition results obtained when using nearest neighbour repetition while Table 13 details the results obtained when Hermite interpolation is implemented ( speech enhancement is used in both cases ) .", "label": "", "metadata": {}, "score": "83.68972"}
{"text": "Figure 42 shows the rise times for the channels of the standard gammatone filterbank when driven by an on - frequency formant .There is a problem with such a simple lockout system .If the pulse - rate is faster than the lockout time , the system will not produce strobes on every pulse .", "label": "", "metadata": {}, "score": "83.79387"}
{"text": "The different symbols highlight the experiment sets varying different parameters .Parameters for some experiments are shown on the plot .The crosses are individual query terms , with some marked .The plot is slightly skewed to higher precision for the SAI , but there is no consistent bias to be seen in the types of query terms that are better represented by MFCC or SAI features .", "label": "", "metadata": {}, "score": "83.80101"}
{"text": "Filter bandwidth varies as a function of cochlear place , and of sound level .Realistic and controllable relationship between peak shape and skirts .After bandwidth , the shape of the filter near the edges of its band is the next most important feature , and this should vary with level .", "label": "", "metadata": {}, "score": "83.80124"}
{"text": "The grey boxes denote the region which is included in the spectral profile calculation .Spectral profiles for the region in the grey box are plotted to the right of each SSI .The large boxes cover the whole image , the small boxes just cover the first cycle of the filter impulse response in each channel .", "label": "", "metadata": {}, "score": "83.803024"}
{"text": "In this panel , the dotted line shows a linear response , and the red lines correspond to the different filter centre frequencies .In the case of the gammachirp filter , the procedure fits a total of five filter parameters with constants or linear functions .", "label": "", "metadata": {}, "score": "83.86457"}
{"text": "WebSphere Voice Server 6 includes ASR , text - to - speech ( TTS ) software and speaker verification , and can be integrated with other software and hardware telephony products .11 In 1984 Apricot Portable Computer was the first PC with built - in speech recognition , licensed from Dragon Systems , Inc.", "label": "", "metadata": {}, "score": "83.95676"}
{"text": "These effects are likely to be due to the different time constants employed in the gain control circuits of the two filterbanks .The dcGC has very fast - acting compression , but no time constants that are longer than a few milliseconds .", "label": "", "metadata": {}, "score": "83.99375"}
{"text": "log(gammatone ) .linear gammatone .Modification of both the spatial AGC parameters and the temporal AGC parameters can lead to higher pitch strength estimates than those produced with the baseline configuration .Interestingly , the largest improvement occurs when the time constants are much larger than the default values ( leading to far shorter half - lives for the AGC ) and when the range of the half - lives is reduced .", "label": "", "metadata": {}, "score": "84.01921"}
{"text": "The time to the maximum is the filter rise time .All the parameters for the strobing system can be pre - calculated once for a given set of filterbank parameters , and then reused .The parameters to be saved are the rise time , the filter centre frequency , and the form of the decaying threshold ( this is used rather than a decay rate , since the absolute amplitude of the filter response will change on the basis of the input ) .", "label": "", "metadata": {}, "score": "84.02684"}
{"text": "Each of these truncated signals is then plotted as a function of cycles of the impulse response for the filter in that particular channel .In practice , this means that the time axis of each channel in the SAI is independently dilated by an amount proportional to the centre frequency of the filter in that channel .", "label": "", "metadata": {}, "score": "84.07388"}
{"text": "There are several major concentrations of energy , the formants , in vowels .The largest three of these are fitted by three of the Gaussians .The remaining distribution is of low energy and acts as a ' spacer ' , encoding the presence of a spectral gap .", "label": "", "metadata": {}, "score": "84.091324"}
{"text": "This means that there is a maximum of 6ms delay between a NAP peak being identified , and being marked as a strobe point .It does , however , mean that the maximum rise time can be larger than the lockout for around two - thirds of the channels .", "label": "", "metadata": {}, "score": "84.113464"}
{"text": "The multiple reflections of the fountain noise from the vertical surfaces of the staircase had the effect of summing multiple copies of the noise waveform , giving rise to what we would now call IRN .A similar effect has been observed in Mexican step pyramids , where a handclap elicits a chirping noise reflected from the vertical surfaces ( Bilsen , 2006 ) .", "label": "", "metadata": {}, "score": "84.15576"}
{"text": "Ramped sounds are perceived differently by the listener to the equivalent damped sounds , and the SAI produced by these sounds should retain the asymmetry seen in the NAP for each sound ( Patterson , 1994a ; Patterson , 1994b ) .", "label": "", "metadata": {}, "score": "84.25151"}
{"text": "The pole Q , or equivalently the pole damping \u03be , is varied dynamically to modify the filterbank properties .The filterbank consists of a cascade of these two - pole , two - zero stages and a dynamic smoothing network , as shown in Figure 65 .", "label": "", "metadata": {}, "score": "84.273285"}
{"text": "The channel density for the filterbank is set by a step factor , which determines the channel density as number of channels per ERB .The channel density is set at 3 channels per ERB in the baseline case .Figure 67 shows the individual filter stages of the PZFC before any adaptation due to the smoothing network , and Figure 68 shows the overall frequency response of the PZFC filterbank at each output .", "label": "", "metadata": {}, "score": "84.309654"}
{"text": "5 illustrates the word prototype training procedure by which the TC word prototype database 24 is constructed .The RC word prototype database 22 is constructed by similar , but far simpler process , in that only the presence or absence of an HS region occurring with each of the 3 equal time intervals must be detected .", "label": "", "metadata": {}, "score": "84.41584"}
{"text": "The vector variance is the mean of the squares minus the square of the means .The mean and variance vectors are then stored as the region count prototype for the given word or phrase .The same procedure is followed to similarly produce a mean and variance vector for each of the remaining words or phrases in the lexicon .", "label": "", "metadata": {}, "score": "84.47992"}
{"text": "Figure 39 --- An auditory filter with a centre frequency of 1000Hz excited by a decaying resonance with a carriers of 800 , 900 , 1000 , 1100 and 1200Hz .The envelope of the impulse response is the dotted blue line and the theoretical maximum envelope is the solid blue line .", "label": "", "metadata": {}, "score": "84.58024"}
{"text": "The bottom - right panel shows the input - output curve for the filterbank as a function of level .In this panel , the dotted line shows a linear response , and the red lines correspond to the different filter centre frequencies .", "label": "", "metadata": {}, "score": "84.58912"}
{"text": "In a standard simulation , a single time - domain waveform might be split into 50 time - domain channels , each with the same data - rate as the original waveform .SAIs can then be generated from these data at an arbitrarily high rate .", "label": "", "metadata": {}, "score": "84.734024"}
{"text": "SpokenText 38 : it offers a trial for 7 days and the supported download format is MP3 only , while in the paid versions it is Audio Book and Multiple MP3 as well .Talking Clipboard 39 : it uses natural sounding synthetic voices ( SAPI 5 compliant ) and can convert them to MP3 or WAV audio files ; it has 30-day free trial .", "label": "", "metadata": {}, "score": "84.75752"}
{"text": "As discussed above , formant bandwidth increases with frequency , such that when plotted on a logarithmic scale the width remains relatively constant .For this reason , it is possible to constrain the Gaussians to have a fixed standard deviation .", "label": "", "metadata": {}, "score": "84.769264"}
{"text": "The frog pushes air between its lungs and an air sac , causing a resonance in its tympanic membrane ( Purgue , 1997 ) , and fish employ mechanisms such as swift contraction of a ring of muscle around the swimbladder ( Sprague , 2000 ) .", "label": "", "metadata": {}, "score": "84.76966"}
{"text": "Figure 23 --- Warping the frequency axis for VTLN .The warping factor \u03b1 controls the gradient of the centre part of the line .f L and f H control the lower and upper ' break ' points of the line respectively , such that the full range of input frequencies are mapped to the full range of output frequencies .", "label": "", "metadata": {}, "score": "84.77169"}
{"text": "The RC stage 18 of word hypothesizer 14 represents each reference word with statistical information on the number of HS regions over a predefined number of time intervals .These parameters are easily estimated from training data .Each word requires exactly 330 parameters , which corresponds to 2 statistics , each over 3 intervals each comprising 55 phoneme units ( 2 statistics\u00d73 intervals\u00d755 phoneme units ) .", "label": "", "metadata": {}, "score": "84.82982"}
{"text": "The timeout , however , has the effect of suppressing strobe points on the local maximum of the envelope .The system will issue a strobe point on the first NAP peak in a rising edge , and the timeout will prevent subsequent strobes .", "label": "", "metadata": {}, "score": "84.87013"}
{"text": "The importance of reducing the average burst length of lost feature vectors rather than reducing the overall packet loss rate is central to the work in these papers .By minimising the average burst length , the estimation of lost feature vectors is more effective .", "label": "", "metadata": {}, "score": "84.88802"}
{"text": "The models are a 2-state Markov chain , the Gilbert - Elliot model and a 3-state Markov chain .The 2-state Markov chain in [ 33 ] uses State 1 to model a correctly received packet and State 2 to model a lost packet .", "label": "", "metadata": {}, "score": "84.93185"}
{"text": "Figure 23 shows the warping scheme used by HTK 's HCopy tool when computing MFCCs .A frequency warping factor , \u03b1 , controls the gradient of the central part of the line , and two parameters control the upper and lower frequencies bounding this line .", "label": "", "metadata": {}, "score": "84.931915"}
{"text": "Von Kempelen built between 1760 and 1790 the first full sentence speech synthesizer ( not the chess - playing hoax Mechanical Turk ) .Since the early 1980s many computer operating systems have included speech synthesizers .TTS applications are mainly used in hands and/or eyes - busy situations , such as automobile navigation .", "label": "", "metadata": {}, "score": "84.96033"}
{"text": "Both of these models include level - dependent asymmetry , and fast acting compression .The BMM plots in Figure 9 were generated using the dcGC filterbank .In the plots , time runs along the horizontal axis , and cochlear channel is along the vertical axis .", "label": "", "metadata": {}, "score": "85.055435"}
{"text": "The standard low - pass filter in AIM is a two - stage filter with a cutoff frequency of 1200Hz , meaning that the filter skirt is 24dB down by 4800Hz .For non - compressive filterbanks , such as the gammatone filter , compression is also added at this stage .", "label": "", "metadata": {}, "score": "85.1255"}
{"text": "Panel ( d ) shows the input - output curve for the filterbank as a function of level for a range of different centre frequencies , P g c p is the output level of the passive gammachirp filter .Figure 76 shows the characteristics of the compressive gammachirp ( cGC ) filterbank in the same format as presented in Figure 74 for the PZFC .", "label": "", "metadata": {}, "score": "85.31556"}
{"text": "Figure 40 shows the effect of exciting one channel of a filterbank with Gaussian noise .Note that the output of the filter , when driven by a noise , is not necessarily at the same frequency as the filter 's impulse response , and that the output frequency varies with time .", "label": "", "metadata": {}, "score": "85.31746"}
{"text": "The total duration was 200ms . shows the results from this experiment .Two click trains - 200ms length , 8ms repetition rate and 5ms repetition rate Line 1 : percentage of pulses correctly identified .Line 2 : mean number of strobes per pulse .", "label": "", "metadata": {}, "score": "85.34434"}
{"text": "Initially these weights are inversely proportional to the index of the strobe in the series so , for example , if there are three active strobes , the oldest strobe is added with weight 1/3 relative to the most recent strobe which is added with weight 1 .", "label": "", "metadata": {}, "score": "85.539215"}
{"text": "Figure 51 shows idealised SSIs for the four vowels in Figure 50 .The SSIs are ' idealised ' in the sense that they are generated from a single cycle of the source vowel .The blue diagonal line in each case shows the cutoff line where the next pitch period would begin .", "label": "", "metadata": {}, "score": "85.54929"}
{"text": "The cGC is the filterbank upon which the dynamic compressive gammachirp ( dcGC ) is based .While the results for the PZFC and the cGC are similar , there are some differences between the responses of the two filterbanks .In panel ( a ) , the cGC is seen to have a steeper high side to the filter .", "label": "", "metadata": {}, "score": "85.55206"}
{"text": "So far , all the strobing systems discussed have not made any use of the obvious constraints between channels .If a pulse - resonance sound hits a filterbank , then the pulse , which is by its very nature broadband , will excite channels at a whole range of frequencies .", "label": "", "metadata": {}, "score": "85.569626"}
{"text": "The results suggest that for packet loss compensation , the decoder - based strategy is best .This is especially true in the presence of large bursts of losses as the accuracy of reconstruction methods falls off rapidly as burst length increases .", "label": "", "metadata": {}, "score": "85.655396"}
{"text": "Interleaving .Research has shown that by minimising the average burst length of lost vectors the estimation of lost feature vectors is more effective [ 34 ] .The aim of interleaving is to break a long loss burst into smaller loss bursts by distributing them over time and so making it appear that the errors are more randomly distributed .", "label": "", "metadata": {}, "score": "85.69457"}
{"text": "The \" sil \" model has 3 states and each state has 6 mixtures .The \" sp \" model has a single state .The Baum - Welch re - estimation algorithm is applied in the training of the word models .", "label": "", "metadata": {}, "score": "85.78279"}
{"text": "The Fourier magnitude spectrum in the lower panel is shown as a set of vertical lines , and the spectral envelope is shown as a dashed line connecting the peaks of the magnitude spectrum .The shape of this envelope corresponds to the form of the damped resonance following each pulse , and the spacing of the harmonic peaks is determined by the pulse rate .", "label": "", "metadata": {}, "score": "85.78462"}
{"text": "68 Future prospects concerning our platform include testing various FOSS STT , MT , and TTS systems to select the best one which fits our needs .After that , we plan to follow the system combination of ASR systems to see whether they perform with higher accuracy than when used individually .", "label": "", "metadata": {}, "score": "85.87154"}
{"text": "In this case , a decaying threshold is placed on the signal .This threshold is reset to the level of the NAP at the time when a strobe is issued , and then decays linearly such that it is zero after a predetermined time period .", "label": "", "metadata": {}, "score": "85.980125"}
{"text": "The impulse response of the filterbank is calculated for each channel .Then a summary statistic , the probability that the last section of the NAP was caused by a glottal pulse , is calculated .This summary probability is summed across channels to produce a single probability signal for the whole input , which represents the probability that the incoming signal was produced by a glottal pulse at that point .", "label": "", "metadata": {}, "score": "86.02507"}
{"text": "The rise time t rise is calculated in each channel .The system then waits for t rise after each strobe candidate to see if any larger strobes occur in that time .If a larger NAP peak does occur , then the new peak is marked as a candidate .", "label": "", "metadata": {}, "score": "86.10527"}
{"text": "In AIM - MAT it is possible to easily visualise the output of the different modules by use of the graphical user interface .The main motivation for the development of AIM - C was to improve the speed of processing available .", "label": "", "metadata": {}, "score": "86.11583"}
{"text": "From this default experiment , variations were made by systematic modification of the smallest rectangle size used for sparse segmentation and by limiting the maximum number of rectangles used for the sparse segmentation ( with variations favouring smaller rectangles and larger rectangles ) .", "label": "", "metadata": {}, "score": "86.17294"}
{"text": "Where there was no text description provided , the sounds were listened to and tagged manually with a few key words .Higher - level tags were also added to each file automatically , so for example a file labelled ' cat ' would have the tags ' mammal ' and ' feliformia ' added .", "label": "", "metadata": {}, "score": "86.18034"}
{"text": "1 phoneme similarity time series for the word \" hill \" spoken by two speakers are compared .Although the precise wave shapes differ between the two speakers , the phoneme similarity data nevertheless exhibit regions of similarity between the speakers .", "label": "", "metadata": {}, "score": "86.18432"}
{"text": "In each case , the results vary very little depending on whether the pitch cutoff is used or not .In each case , there is a very slight benefit to using the pitch cutoff at high SNRs , but the cutoff is detrimental at low SNRs .", "label": "", "metadata": {}, "score": "86.21827"}
{"text": "This envelope , with a sinusoidal carrier -- a gammatone filter -- can be seen in Figure 37 .The envelope of the resonance of the vocal tract is taken to be a simple damped exponential : , with the v referring to the vocal tract filter .", "label": "", "metadata": {}, "score": "86.2696"}
{"text": "When multiple strobes are active ( that is , when more than one strobe has occurred within a 32ms window ) , the signal following each strobe is weighted by an amount inversely proportional to the number of strobes currently active , before being added to the buffer .", "label": "", "metadata": {}, "score": "86.35756"}
{"text": "If there is not enough signal available in a given channel to fill the complete width of the SSI , then the signal will be added up to the point where the signal stops , which can lead to small discontinuities in the generated image .", "label": "", "metadata": {}, "score": "86.38801"}
{"text": "Presently each utterance is divided into 3 time intervals , with each time interval being represented by data corresponding to the 55 phonemes .Thus the presently preferred implementation represents each utterance as a 3\u00d755 vector .In representing the utterance as a 3\u00d755 vector , each vector element in a given interval stores the number of similarity regions that are detected for each given phoneme .", "label": "", "metadata": {}, "score": "86.40451"}
{"text": "Iterated rippled noise .Iterated rippled noise ( IRN ) is a stimulus that is frequently used as a test of auditory models .It has a power spectrum that resembles that of a noise , but gives rise to a pitch percept in the auditory system .", "label": "", "metadata": {}, "score": "86.51671"}
{"text": "After the peak , the threshold decays in some way with time , and any NAP peaks which are under the threshold are ignored .A strobe can be issued on every NAP peak which is above the threshold , or only on a subset of those peaks , based on some other criteria .", "label": "", "metadata": {}, "score": "86.52626"}
{"text": "Subjects compared IRN with different numbers of iterations to a tonal stimulus ( 256-iteration IRN with a 16ms delay time ) masked with noise .Subjects were asked to select the stimulus with the stronger pitch strength as the SNR of the noise - masked tonal stimulus was changed .", "label": "", "metadata": {}, "score": "86.58417"}
{"text": "The NAP maxima are marked by red dots .Single - pulse excitation .In the case of a single pulse exciting the filterbank , the response in a single channel is simply the impulse response shown above .This is the most simple form of excitation , and provides a good basis for developing an algorithm which will ultimately extract the timings and amplitudes of filtered pulses .", "label": "", "metadata": {}, "score": "86.62909"}
{"text": "For a first treatment of the problem , the low - pass filtering will be put aside , and signals which have simply been half - wave rectified will be considered .This class of signal is known as the Neural Activity Pattern , or NAP .", "label": "", "metadata": {}, "score": "86.68762"}
{"text": "The three models in [ 33 ] are all validated for GSM and wireless local area network ( WLAN ) channels .Results indicate that the 3-state Markov model gives the best results overall and this model is used in the work described here ; the model is described in more detail later in this chapter .", "label": "", "metadata": {}, "score": "86.69899"}
{"text": "LumenVox 12 is another provider of ASR software that allows users to control their telephony or computer application using their voice .Some FOSS ASR tools follow : .CMU Sphinx 13 : this tool is developed by the Carnegie Mellon University ( CMU ) .", "label": "", "metadata": {}, "score": "86.75243"}
{"text": "The first makes use of physical layer models that simulate transmission phenomena that occur on the physical channel .The second category involves the use of statistical models that model unconditional packet loss probability and conditional packet loss burst lengths .This is the approach used in this chapter .", "label": "", "metadata": {}, "score": "87.05103"}
{"text": "[ 1 ] .Purgue , A. ( 1997 ) . \" Tympanic sound radiation in the bullfrog Rana catesbeiana . \"Journal of Comparative Physiology A : Neuroethology , Sensory , Neural , and Behavioral Physiology , 181 , p.438 - 445 .", "label": "", "metadata": {}, "score": "87.05777"}
{"text": "Such periods of low speech energy occur between words or syllables in an utterance and during speech pauses .The energy of the signal during these periods reflects the noise power level .Martin 's minimum statistics noise estimation method tracks the short - term power spectral density estimate of the noisy speech signal in each frequency bin separately .", "label": "", "metadata": {}, "score": "87.117615"}
{"text": "Initial experiments have resulted in 10%--20 % reductions in word error rates .Tools . \" ...The thesis describes novel techniques and algorithms for the practical parsing of realistic Natural Language ( NL ) texts with a wide - coverage unification - based grammar of English .", "label": "", "metadata": {}, "score": "87.15477"}
{"text": "Full text / Texte int\u00e9gral . 1 Today we are experiencing the aging population phenomenon .In 2002 United Nations stated that the number of older persons has tripled over the last 50 years and will more than triple again over the next 50 years .", "label": "", "metadata": {}, "score": "87.19209"}
{"text": "The short - time Fourier transform ( STFT ) is a joint time - frequency representation of a signal : it transforms a 1-dimensional signal into a 2-dimensional time - frequency representation .In the case of the joint time - frequency representation , the minimum uncertainty function is the Gabor function .", "label": "", "metadata": {}, "score": "87.23152"}
{"text": "This simplicity makes the design an excellent choice for implementation in analogue electronics , and indeed Lyon and Mead ( 1988 ) designed an analogue VLSI chip in which each stage was an order-1 ( 2-pole ) APGF .Lyon ( 1998 ) discussed a set of four different transfer functions as possible stages for a filter cascade model of the cochlea .", "label": "", "metadata": {}, "score": "87.25623"}
{"text": "The PZFC also has a less well - organised structure to the compression functions than the cGC .Overall , the PZFC fits the masking data well using fewer parameters than the dcGC , but the compression functions are not as orderly , and the upper side of the PZFC is probably not quite as sharp as it should be .", "label": "", "metadata": {}, "score": "87.26626"}
{"text": "The dcGC is a parallel filterbank , in which dynamic gain control is obtained by sampling the signal level in a higher - frequency ' level estimation ' filter , and dynamically adjusting the gain based on that .By contrast , the PZFC is a cascade of filters , in which the output of a high - frequency band - pass filter is fed through a cascade of filters with successively lower peak frequencies .", "label": "", "metadata": {}, "score": "87.3117"}
{"text": "n . 1 , and their first derivatives , .x .b and .x .b .n .Equation ( 6 ) can be rewritten as .x .^ .b .n .x .b .", "label": "", "metadata": {}, "score": "87.35575"}
{"text": "In general performance was good as long as C was not too high , and lower C values required longer training .In preliminary experiments , we found that the system was not very sensitive to the value of these parameters .", "label": "", "metadata": {}, "score": "87.39933"}
{"text": "When these coefficients are convolved with the smoothing network activity in each channel , the activity spreads out equally to higher and lower frequencies .This default configuration is tested as parameter set 0 in the experiments below .To force the activity to spread asymmetrically , the experiments above were repeated with several different configurations of the AGC parameters .", "label": "", "metadata": {}, "score": "87.40575"}
{"text": "Festvox 42 : this project is part of the work at CMU 's speech group ; it is firmly grounded within Festival and Flite ( see below ) .Flite 43 : Flite ( festival - lite ) is a small , run - time synthesis engine developed at CMU and primarily designed for small embedded machines and/or large servers .", "label": "", "metadata": {}, "score": "87.43448"}
{"text": "This is : . which has a similar form to the gamma envelope , but with exponents of both \u03b1 a and \u03b1 v and a polynomial in t rather than a single power of t .This , then , is the form of the envelope of a gammatone auditory filter struck with a decaying exponential resonance .", "label": "", "metadata": {}, "score": "87.476105"}
{"text": "Moreover , Rose proposed , but did no ... . \" ...This dissertation is the result of my own work and includes nothing which is the outcome of work done in collaboration .It has not been submitted in whole or in part for a degree at any other university .", "label": "", "metadata": {}, "score": "87.52392"}
{"text": "This transformed representation is known as the ' cepstrum ' ( a play on the word ' spectrum ' ) .Taking the logarithm of the power spectrum means that a convolution in the time domain corresponds to summation in this log - frequency domain .", "label": "", "metadata": {}, "score": "87.62184"}
{"text": "Look - ahead .The major distinction between different models of strobing is whether or not a model needs to look at the signal beyond a point in time in order to classify that point as a strobe or not .In a causal system with no delay , a NAP peak may only be classified as a strobe on the basis of the information in the NAP up to and including that point ; that is , strobe points may not be identified retrospectively .", "label": "", "metadata": {}, "score": "87.6229"}
{"text": "In practice , the gammachirp extends the gammatone by adding a parameter , c , which controls the addition of a log - time term to the carrier ( cos(\u03c9 r t + \u03c8 + c log ( t ) ) ) .", "label": "", "metadata": {}, "score": "87.72246"}
{"text": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing ( Volume 2 : Short Papers ) , pp .588 - 593 , Association for Computational Linguistics , Beijing , China , 2015 .", "label": "", "metadata": {}, "score": "87.76641"}
{"text": "It is desirable that there should be roughly one strobe per pulse , that the choice of strobe points should be reasonably consistent across channels and across pulses and that strobe timing should not be affected too greatly by the exact form of the resonance following each pulse .", "label": "", "metadata": {}, "score": "87.90553"}
{"text": "The studies presented in this chapter provide some evidence that dynamic , within - cycle , compression is a feature of auditory processing which is important for correctly modelling human perception of certain stimuli .The stimuli used in this chapter are iterated rippled noise ( IRN ) and high - pass filtered harmonic complexes in which the fundamental and lower harmonics of the stimulus are not present .", "label": "", "metadata": {}, "score": "87.94066"}
{"text": "Figure 60 --- Recognition results for the AIM NAP profile and MFCC features , where the model was trained and tested in noise .Figure 61 and Figure 62 show the results for the whole - SSI profile and SSI cycle-1 slice features respectively .", "label": "", "metadata": {}, "score": "88.02158"}
{"text": "This rise time of the filter runs from a maximum of about 15.6ms for a gammatone filter at 50Hz , to 0.83ms for a gammatone filter at 5kHz .Thus , looking forward as far as the rise time of the lowest gammatone filter requires a maximum look - ahead of about 16ms .", "label": "", "metadata": {}, "score": "88.152245"}
{"text": "For pulse - resonance sounds , strobes should be issued at a peak of the NAP that corresponds to a pulse in the input sound .In sounds with a repeating pulse - resonance structure , only one strobe should be issued for each cycle , in each channel .", "label": "", "metadata": {}, "score": "88.39553"}
{"text": "The noise signals added are chosen to reflect environments in which telecommunication terminals are used .In total there are eight different noise types : subway , babble , car , exhibition hall , restaurant , street , airport and train station .", "label": "", "metadata": {}, "score": "88.42048"}
{"text": "The formant has a frequency of 800 , 900 , 1000 , 1100 and 1200 Hz in the five panels .The maximum temporal extent of the filter envelope is when it is driven exactly on frequency ; the decaying resonance has the same carrier frequency as that of the channel of the filterbank which is being observed .", "label": "", "metadata": {}, "score": "88.51923"}
{"text": "This happens because , in a noise , strobes will occur randomly , and the activity in each channel will tend to have a random phase .This means that the characteristic peaks and troughs in each SAI channel will become smeared out relative to the pattern for a pulse - resonance sound , and the overall level of activity in the SAI will be lower and the dynamic rage smaller than for a pulse - resonance sound .", "label": "", "metadata": {}, "score": "88.52783"}
{"text": "Overall performance with no pitch cutoff is 79.0 % , and 81.3 % with the pitch cutoff .In the no pitch cutoff case , performance is again lowest for the speaker with the shortest vocal tract , falling to 27.0 % .", "label": "", "metadata": {}, "score": "88.62427"}
{"text": "65The elderly and people with physical or cognitive impairments is a group which needs special care and specific , easy - to - use technology should be developed to meet their needs .The elderly suffer often from hearing loss , speak with pauses or unclearly , and typically have impaired vision .", "label": "", "metadata": {}, "score": "88.665924"}
{"text": "The architecture of the dcGC is fundamentally different from that of the PZFC .Whereas the dcGC is essentially a parallel filterbank wherein all filters get the same input signal , the PZFC is a cascade filterbank with each filter fed by the one before it in the cascade .", "label": "", "metadata": {}, "score": "88.73715"}
{"text": "At a sample rate of 44kHz , these constants correspond to activity half - lives of roughly 2ms , 10ms , 40ms and 160ms .These constants can be modified to change the integration time of the AGC .Several alternative sets of constants were tried to test the temporal dynamics of the filterbank .", "label": "", "metadata": {}, "score": "88.75517"}
{"text": "The cascade architecture of the PZFC mimics transmission - line architecture of the cochlea , in which the incoming wave travels along a medium with slowly - changing properties .This makes the filterbank a more physiologically plausible model of the processing actually occurring in the cochlea .", "label": "", "metadata": {}, "score": "88.79045"}
{"text": "Size information is also seen in the calls of animals , for example there is a strong correlation between the body size of the North American bullfrog ( Rana catesbiana ) and the fundamental frequency of its call ( Gomersall , Walters and Patterson , 2005 ) .", "label": "", "metadata": {}, "score": "88.9371"}
{"text": "However , interestingly , performance degrades far less rapidly as the noise level increases for the SSI - based features , such that by 24dB SNR , the SSI - based features are outperforming the NAP - based features .Performance with the SSI - based features remains consistently higher right down the 0dB SNR .", "label": "", "metadata": {}, "score": "88.943146"}
{"text": "One interesting approach to this problem would be to modify the AGC of the PZFC so that its architecture was more like that of the dcGC .The AGC activity could be shifted so that the state of an AGC stage which takes input from one frequency is used to affect the PZFC filter stage at a lower frequency .", "label": "", "metadata": {}, "score": "89.005554"}
{"text": "Such an expectation is not unreasonable ; ' If we can do these tasks so easily , ' runs the train of thought , ' then it must be trivial for these complicated computing machines . 'Of course , nothing could be further from the truth .", "label": "", "metadata": {}, "score": "89.02214"}
{"text": "There are eleven whole word HMMs each with 16 states ; each state has 3 Gaussian mixtures .The topology of the models is left - to - right without any skips over states .This topology is suitable for modelling the sequential nature of speech and the consecutive states represent the consecutive speech states in a particular utterance .", "label": "", "metadata": {}, "score": "89.083954"}
{"text": "Figure 90 --- Pitch strength measures from SAI profiles generated from a harmonic complex .The PZFC filterbank was used in all cases , and the automatic gain control coefficients of the PZFC were varied .Figure 91 --- Cochleagrams for the word ' washwater ' using the baseline PZFC ( top ) and PZFC parameter sets 8 and 9 ( faster AGC time constants ) ( middle and bottom ) .", "label": "", "metadata": {}, "score": "89.09117"}
{"text": "Effectiveness can be assessed in terms of strobe rate or the precision of the predicted stimulus pulse times .Pulse trains and synthetic vowels were used to assess the effectiveness of the strobing systems .Figure 47 --- A synthetic , three - formant , /a/ vowel with a pulse rate of 125Hz ( 8ms pulse interval ) ( blue ) and the associated pulse times ( red ) .", "label": "", "metadata": {}, "score": "89.11596"}
{"text": "They can not read the text written under buttons in TV remote controllers , for instance .Although , there are remote controllers designed today for the elderly with bigger buttons and text in bigger font , speech recognition software would facilitate their interaction .", "label": "", "metadata": {}, "score": "89.11735"}
{"text": "The PZFC frequency response consists of a peak due to the pole , which can be varied by changing the pole quality factor , Q , and a dip caused by the zero .The zero is placed close to the pole on the high - frequency side to give a steep drop in the response above peak frequency .", "label": "", "metadata": {}, "score": "89.17327"}
{"text": "Sex and age judgements for vowels with GPR and VTL values in the range of normally - encountered speakers were influenced about equally by both variables , but for vowels with low GPR and short VTL , VTL played a greater role in the decision .", "label": "", "metadata": {}, "score": "89.27585"}
{"text": "The PZFC and dcGC filternbanks are described in detail in chapter 5 ; the methods and main results presented here are based on the use of the gammatone filterbank , but the experimental results also include values for the compressive dcGC and PZFC filterbanks for comparison purposes .", "label": "", "metadata": {}, "score": "89.35162"}
{"text": "In the PZFC , activity from a filter spreads out in both directions symmetrically to influence the response of both lower and higher frequency filters .In the dcGC , the activity in each channel affects only one other channel in the filterbank , as the control signal always flows from a higher - frequency channel to a lower - frequency channel .", "label": "", "metadata": {}, "score": "89.374985"}
{"text": "( 2010 ) mention characteristically : \" older persons targeted by AAL technologies especially need more easy - to - use methods to interact with inherently complex supporting technology \" .48 One motivation for AAL initiatives is the demographic change due to the aging population phenomenon .", "label": "", "metadata": {}, "score": "89.40405"}
{"text": "Panel ( a ) shows the absolute frequency response of the filters as a function of stimulus level .Panel ( b ) shows the responses at a single stimulus level with the filter tail tied at 0dB gain .Panel ( c ) shows the equivalent rectangular bandwidth of the filter ( ERB ) as a function of centre frequency , for three different probe levels .", "label": "", "metadata": {}, "score": "89.54224"}
{"text": "Allowing one zero back into the APGF transfer function yields the one - zero gammatone filter ( OZGF ) ; the zero is constrained to lie along the real axis .The special case where the OZGF has its zero at the origin in the S - plane is known as the differentiated all - pole gammatone filter ( DAPGF ) .", "label": "", "metadata": {}, "score": "89.68471"}
{"text": "Choosing the relative levels of the three coefficients changes the way in which energy is distributed in the smoothing process .The default configuration of the smoothing filter has the coefficients 0.3 , 0.4 and 0.3 ( left , centre and right ) .", "label": "", "metadata": {}, "score": "89.87169"}
{"text": "71 Navigation of people on a wheelchair through speech interaction , sensor - based frameworks , speaking calendars , showing a website in a large display by throwing gestures and so on are today reality and not research goals any longer .", "label": "", "metadata": {}, "score": "89.928085"}
{"text": "CamSpace 56 : this platform can detect human gestures and turns everyday products ( like can , bottles , boxes , etc ) or objects into computer controllers that can operate new or existing games and applications .Use for educational games or advertizing lets advertisers and advertising agencies create motion games and experiences based around advertisers ' products and user hand gestures .", "label": "", "metadata": {}, "score": "90.01131"}
{"text": "Hence translation plays , apart from a communicative and socioeconomic , also a life - saving role in AAL .53 In Bremen Ambient Assisted Living Lab ( BAALL ) natural interaction with the users is enabled through spoken dialog with special devices .", "label": "", "metadata": {}, "score": "90.034836"}
{"text": "The sum of these two delays is known as the latency of the interleaving / de - interleaving process .The spread S of an interleaver is a metric that indicates how good an interleaver is at breaking up error bursts .", "label": "", "metadata": {}, "score": "90.06706"}
{"text": "In the baseline case , P damp is set at 0.12 and Z damp is set at 0.2 .Figure 69 shows the effect of changing the two damping parameters on the peak of the stage frequency response .When P damp is varied , Z damp is held at 0.2 , and when Z damp is varied , P damp is held at 0.12 .", "label": "", "metadata": {}, "score": "90.195206"}
{"text": "Figure 44 shows the effect of running the system on a pulse train input with an 8ms interval between pulses .Figure 43 --- The constrained threshold system at work in a single channel .Notable features are the suppression of strobe points on the rising edge of the filter response and the non - linear decaying threshold .", "label": "", "metadata": {}, "score": "90.240005"}
{"text": "To promote the propagation of strobes across multiple channels , an additional rule may be added : .If a strobe is known to have occurred in a higher frequency channel , then the threshold in the current channel is lowered by a set proportion for each higher channel in which a strobe occurred .", "label": "", "metadata": {}, "score": "90.30258"}
{"text": "Performance is still better than with the MFCCs without VTLN , however , where overall performance was 75.5 % .Performance with the SSI features does not approach that of MFCCs with optimal VTLN at 99.2 % .Testing in noise .", "label": "", "metadata": {}, "score": "90.33165"}
{"text": "Two techniques for generating SAIs were used in this study .The first , known as ' Lyon - SAI ' performs strobe detection using multiple overlapping parabolic windows on the NAP signal .The signal in each channel is multiplied pointwise by the windowing function , a parabola of 40ms width .", "label": "", "metadata": {}, "score": "90.354256"}
{"text": "In [ 27 - 29 ] , a voice over IP ( VoIP ) channel is simulated using such a model .References [ 30 , 31 ] simulate IP channels and use a 2-state Gilbert model to simulate burst type packet loss on the channel .", "label": "", "metadata": {}, "score": "90.3577"}
{"text": "Also , the curled finger gesture 62 means telling someone to come to you in America and England , but is considered rude in Japan and death in Singapore .Prolonged eye contacted is considered rude in Japan , Korea , and Thailand , while it is preferred in North America and Europe 63 .", "label": "", "metadata": {}, "score": "90.42586"}
{"text": "Also , almost double amount of people will be retired .The ever more increasing amount of older people who need care makes the need for a safer , healthier , and more independent lifestyle essential .The aging phenomenon is reality and technology should help increase the autonomy of the elderly and their active participation in society .", "label": "", "metadata": {}, "score": "90.46605"}
{"text": "Gain variation .Gain , as well as bandwidth , varies as a function of level .Stable low - frequency tail .In order to provide a good match to physiological data , the gain of the low - frequency tail of the filter should not vary much as a function of input level .", "label": "", "metadata": {}, "score": "90.61488"}
{"text": "To test for the number of strobes per cycle in a single - source sound , a simple sliding window approach can be taken .The NAP and strobes are windowed into sections that are the width of the inter - pulse interval .", "label": "", "metadata": {}, "score": "90.64825"}
{"text": "Figure 59 --- Scaled syllable recognition performance on the SSI cycle-1 profile with the pitch cutoff .In general , then , when there is no background noise , performance with the SSI - based features is lower than for the NAP - based features , and the SSI - based features are more susceptible to changes both in pitch and in VTL .", "label": "", "metadata": {}, "score": "90.69848"}
{"text": "Packet loss can arise in wireless and packet switched ( IP ) networks , both networks over which a DSR system would normally be expected to operate .Packet loss , in particular packet burst loss , can have a serious impact on recognition performance and needs to be considered in the design of a DSR system .", "label": "", "metadata": {}, "score": "90.77678"}
{"text": "The pole - zero filter cascade .The pole - zero filter cascade ( PZFC ) ( Lyon et al . , 2010 ) is a cascade filterbank in which each stage is described in the Laplace domain by a complex - conjugate pole pair and a similar conjugate zero pair .", "label": "", "metadata": {}, "score": "90.82588"}
{"text": "Interpolation .The disadvantage of stationary periods that arise with nearest neighbour repetition can be alleviated somewhat by polynomial interpolation between the correctly received feature vectors either side of a loss burst .Reference [ 34 ] found that non - linear interpolation using cubic Hermite polynomials gives the best estimates for missing feature vectors .", "label": "", "metadata": {}, "score": "90.86862"}
{"text": "Figure 79 shows ' cochleagrams ' for the word ' washwater ' after processing through the PZFC , dcGC and gammatone filterbanks .A ' cochleagram ' has the same dimensions as the spectrogram , but the output is continuous in each filter channel , unlike the spectrogram where the output is quantised into ' frames ' by the window time - step .", "label": "", "metadata": {}, "score": "91.00075"}
{"text": "These parameters determine the decay rate of activity in each of the four AGC channels .In channels with a large constant , activity in a channel at a certain time dies away quickly .Conversely , a small decay constant leads to activity affecting the AGC state for a longer period of time .", "label": "", "metadata": {}, "score": "91.058975"}
{"text": "The horizontal axis in each panel is time , as before .The vertical axis is cochlear channel , from low frequency at the bottom to high frequency at the top .A 50-channel dynamic compressive gammachirp ( dcGC ) filterbank , with filter centre frequencies ranging from 100Hz to 6kHz on an ERB scale was used to generate the figures .", "label": "", "metadata": {}, "score": "91.12749"}
{"text": "\" J. Acoust .Soc .Am . , 100 , p.3286 - 3294 .[ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] [ 7 ] [ 8 ] [ 9 ] .", "label": "", "metadata": {}, "score": "91.226654"}
{"text": "Time - reversed pulse - resonance sounds present an interesting problem for a system that is optimised for normal pulse - resonance communication sounds .These ' ramped ' stimuli are characterised by an exponentially increasing envelope that is suddenly truncated and falls to zero .", "label": "", "metadata": {}, "score": "91.300385"}
{"text": "In the variant of the strobe algorithm used here , the strobe threshold starts at zero .When the signal exceeds threshold , a strobe point occurs and the threshold is raised to the level of the signal at the time of the strobe .", "label": "", "metadata": {}, "score": "91.38699"}
{"text": "The width of each rectangle is doubled ( with the left edge still pinned to the zero - lag line ) .When the box width is wider than the remaining space in the image , the box is shifted so the right edge is at the right edge of the SAI .", "label": "", "metadata": {}, "score": "91.454575"}
{"text": "Replacing the current PZFC with a version where the zero - crossings do not shift with level may help aleviate the strobing problem .The Lyon strobe detection system with a parabolic window performs very badly with respect to the criteria for a good strobe mechanism .", "label": "", "metadata": {}, "score": "91.72844"}
{"text": "The left - hand image shows the full - resolution rectangle from the SAI .The right - hand image shows the region downsampled to 16 \u00d7 32 pixels .The mean values of each of the rows and columns of this image are then calculated .", "label": "", "metadata": {}, "score": "91.84421"}
{"text": "For example , there were 7 sound files that were labelled ' evil laugh ' but were not ranked within the top k documents for the query ' evil laugh ' .At the same time , these documents were ranked highly for the query ' laugh ' .", "label": "", "metadata": {}, "score": "92.090485"}
{"text": "\" J. Acoust .Soc .Am . , 106 , p.1532 - 1542 .[ 1 ] [ 2 ] .Huygens , C. ( 1693 ) .\" En envoiant le probleme d'Alhazen en France .\" Date - added : 2009 - 11 - 27 16:56:45 +0000 .", "label": "", "metadata": {}, "score": "92.22194"}
{"text": "The 14 coefficients ( C 1 to C 12 , C 0 & lnE ) are grouped into pairs , and each pair is quantized using its own vector quantisation ( VQ ) codebook .The resulting set of index values is then used to represent the feature vector .", "label": "", "metadata": {}, "score": "92.27413"}
{"text": "Line 2 : mean number of strobes per pulse .back - projection .Discussion .The new constrained threshold and back - projection algorithms work well , both for single sources and combined sources .For single sources , the local maximum strobe criterion and the constrained threshold system exhibit very similar performance .", "label": "", "metadata": {}, "score": "92.55645"}
{"text": "The bottom - left panel shows the responses with the filter tail tied at 0dB gain .The filter gain increases in the low ERB range , and levels off in the higher ERB range .The top - right panel shows the equivalent rectangular bandwidth of the filter ( ERB ) as a function of centre frequency , for three different probe levels .", "label": "", "metadata": {}, "score": "92.644455"}
{"text": "The rise time is the time taken for the filter envelope to reach its maximum value .The decay time is the time required for the filter envelope to fall to some small proportion of its maximum height .Two possible thresholds are shown .", "label": "", "metadata": {}, "score": "92.69444"}
{"text": "The nonlinear threshold is the driven filter envelope , shifted to take account of the cases in which the highest NAP peak occurs before the maximum of the filter envelope .Figure 42 --- Rise time of a gammatone filter driven by an on - frequency damped formant as a function of filter centre - frequency .", "label": "", "metadata": {}, "score": "92.881836"}
{"text": "In this section , I use the gammatone as an example filterbank .I use the characteristics of the gammatone itself , and a simple model of pulse - resonance sounds , to derive some constraints on the signal in each channel of the NAP .", "label": "", "metadata": {}, "score": "92.882126"}
{"text": "This , in turn , means bigger effort in implementation or training .46 In this chapter we focus on ambient assisted living ( AAL ) environments and related work regarding dialog and gesture - based systems in AAL .Then we refer specifically to the Bremen Ambient Assisted Living Lab ( BAALL 64 ) and its human - robot speech interaction .", "label": "", "metadata": {}, "score": "93.043884"}
{"text": "Figure 97 , Figure 98 , Figure 99 and Figure 100 show the process of tiling the SAI space with boxes .Different box shapes and sizes capture different forms of information .Short , wide boxes restrict the temporal pattern features to a localised frequency region and capture local spectral shape .", "label": "", "metadata": {}, "score": "93.05076"}
{"text": "Packet loss framework .Packet loss model .The packet loss model used in this work is the 3-state Markov chain proposed by [ 33 ] .This 3-state model was found to be more effective at simulating different packet loss conditions in comparison with a 2-state Markov chain and the Gilbert - Elliot model .", "label": "", "metadata": {}, "score": "93.15352"}
{"text": "The vertical axis shows overall recognition performance .The horizontal axis shows the number of HMM training iterations .Solid lines denote HMMs with 2 emitting states , dashed lines 4 emitting states and dotted lines 6 emitting states .Stars show performance with 2 Gaussian components in the output distribution , circles are for 4 components and plus symbols show performance with 6 components ) .", "label": "", "metadata": {}, "score": "93.26305"}
{"text": "In this case , the strobe points are placed on the NAP peak closest to the detected strobe time .Figure 45 --- Results of applying the back - projection algorithm to a pulse train stimulus .Figure 45 shows the strobes generated by this back - projection algorithm for a small segment of a pulse train stimulus .", "label": "", "metadata": {}, "score": "93.33546"}
{"text": "The level in each plot is scaled such that the darkest greyscale value corresponds to the highest output level for each filterbank , and the greyscale level decays from there to zero for pure white .This allows for comparison of the relative dynamic range of each of the filterbanks .", "label": "", "metadata": {}, "score": "93.53016"}
{"text": "When a strobe occurs in a channel , a short segment of the signal following the peak in that channel is added to a buffer , starting at zero lag .The signals following multiple strobe points add constructively in the buffer .", "label": "", "metadata": {}, "score": "94.09169"}
{"text": "In addition , users would prefer some gesture recognition software against some other for the reason that they want to do only gestures which are ' semantically allowed ' in their culture and hence are not offending in another locale .40 Some examples of different gestures in different locales follow : the ' thumbs up ' 61 gesture means that everything is good in America and many European countries , whereas it is rude in Asian and Islamic countries .", "label": "", "metadata": {}, "score": "94.38547"}
{"text": "Mary 46 : it was originally developed as a collaborative project of Language Technology lab from the German Research Center for Artificial Intelligence ( DFKI ) and the Institute of Phonetics at Saarland University .Version 4.3 supports German , British and American English , Telugu , Turkish , and Russian .", "label": "", "metadata": {}, "score": "94.64537"}
{"text": "The SAI generation is the standard system from ti2003 : when a strobe occurs , the signal following the strobe starts to be added into the AIM - SAI buffer , starting from zero time - interval .This process continues for 32ms after the strobe has occurred ( leading to an AIM - SAI width of 32ms , which is slightly wider than the Lyon - SAI system described above ) .", "label": "", "metadata": {}, "score": "94.79164"}
{"text": "VAX VoIP Software Development Kit - Enable applications and Web pages to have voice conversation over the internet protocol ( VoIP ) .It includes VoIP activeX ( OCX ) , VoIP COM DLL , VoIP LIB and VoIP CAB , to provide wide implementation choice .", "label": "", "metadata": {}, "score": "95.094345"}
{"text": "The strobe position in each channel is set to be the NAP peak which is closest to the ideal strobe point in the ' pulse NAP ' .This approach is considerably more computationally expensive than a simple thresholding approach , since a section of the NAP must be compared against an entire saved impulse response for every time step .", "label": "", "metadata": {}, "score": "95.23781"}
{"text": "The window used is an inverted parabola of 40ms width .Thus , there is guaranteed to be an average of one strobe point every 4ms , but it is possible for multiple strobes to occur at one point in the signal , since the windows overlap .", "label": "", "metadata": {}, "score": "96.06792"}
{"text": "The Euclidean distance between the test utterance and the prototype is computed by subtracting the test utterance RC data vector from the prototype mean vector and this difference is then squared .The Euclidean distance is then multiplied by a weighting factor , preferably the reciprocal of the prototype variance .", "label": "", "metadata": {}, "score": "96.076805"}
{"text": "In either case , the results returned are based not on the content of the audio itself , but rather on metadata associated with the audio .Figure 92 shows the results of typing the query ' lion roar ' into Google ( in June 2008 ) .", "label": "", "metadata": {}, "score": "96.19682"}
{"text": "Making a gesture like showing with the hand to the right , Rolland will turn right ; also a ' tick in the air ' could turn the TV on .In controlling devices particularly , the limitation is that users have to learn specific gestures and software has to be trained to recognize them .", "label": "", "metadata": {}, "score": "96.71688"}
{"text": "The window is then shifted by 4ms and the process is repeated .Thus , there is guaranteed to be an average of one strobe point every 4ms , or five per 20ms frame , but it is possible for multiple strobes to occur at one point in the signal , since the windows overlap .", "label": "", "metadata": {}, "score": "96.733025"}
{"text": "eSpeak 40 : it uses a \" formant synthesis \" method ; this allows many languages to be provided in a small size .Festival 41 : it is developed by the University of Edinburgh and offers a general framework for building speech synthesis systems as well as including examples of various modules .", "label": "", "metadata": {}, "score": "97.11534"}
{"text": "( 2010 ) discussed in the following case scenario : Mario is sitting in his wheelchair at the desk of his home office .He says to Rolland ' I 'd like to eat a pizza ' .The wheelchair reaches the kitchen and replies to the user ' OK , I m going to take you to the kitchen ' .", "label": "", "metadata": {}, "score": "97.18484"}
{"text": "Long periods of fading in a wireless network can result in bursts of packet loss .The authors in [ 33 ] measured the characteristics of an IP network and a WLAN , and the results showed the packet loss rate ( \u03b1 ) and the burst length ( \u03b2 ) to be highly variable .", "label": "", "metadata": {}, "score": "97.42479"}
{"text": "The system is deemed to be working correctly if there is exactly one strobe in each channel for each windowed section .Figure 48 --- Windowing system for assessing the accuracy of strobe detection systems .There should be one strobe point in each channel within each of the four coloured windows if the system is working perfectly .", "label": "", "metadata": {}, "score": "97.97174"}
{"text": "FreeTTS 45 : it is based upon Flite .Some possible uses of FreeTTS are Java Speech API JSAPI 1.0 synthesizer , remote TTS Server that can work with a speech / telephony system , desktop TTS engine , or downloadable web application .", "label": "", "metadata": {}, "score": "98.52388"}
{"text": "Pulse train - 200ms length , 8ms repetition rate .Line 1 : percentage of pulses correctly identified .Line 2 : mean number of strobes per pulse . lyon .In the second experiment , the pulse train was swept in pulse interval from 10ms between pulses to 5ms between pulses .", "label": "", "metadata": {}, "score": "98.85238"}
{"text": "Figure 34 --- ' Bunt ' criterion -- after each strobe , the threshold jumps up by a random amount .The basic mode of operation of strobing systems is to place a decaying threshold on the incoming NAP signal .The threshold starts off at zero activity , and it is updated constantly .", "label": "", "metadata": {}, "score": "100.369705"}
{"text": "Channel centre frequency is along the vertical dimension and time interval along the horizontal dimension .The units in the vertical dimension are harmonics of the fundamental .The units in the horizontal dimension are cycles of the impulse response .In the frequency dimension , the points of interest are dictated by the pulse rate of the waveform .", "label": "", "metadata": {}, "score": "100.87639"}
{"text": "The output was band pass filtered with a pass band between 500Hz and 2kHz .The pass band was ramped up over 200Hz and down over 1.6kHz using a raised cosine window ; therefore the region of the spectrum containing energy went from 300Hz to 3.6kHz .", "label": "", "metadata": {}, "score": "101.06741"}
{"text": "For the standard small box size of 16 \u00d7 32 this is a 48 dimensional vector .The use of the marginals of each box reduces the dimensionality into the following sparse - code extraction step , while preserving much of the important information about spectral and temporal structure .", "label": "", "metadata": {}, "score": "101.94478"}
{"text": "Ambient assisted living ( AAL ) ' s initiative is to make the lifestyle of the elderly or people in need more autonomous in a domestic environment by means of advanced technology .Technology used by people in need should be easy - to - use , user - friendly , accessible , flexible , and interaction efficient .", "label": "", "metadata": {}, "score": "102.26161"}
{"text": "Machine speaks back into the user 's language .63 The advantage of multilingual support in BAALL is that users can speak in their own mother language ; that means that Rolland can be used in a crosslingual setting , not only by German or English native speakers or speakers who can speak German / English .", "label": "", "metadata": {}, "score": "103.142715"}
{"text": "Figure 43 shows the effect of applying the new constrained threshold in one channel of the filterbank .The threshold can be seen to rise a small amount before it falls .This occurs because the threshold is taken from being one NAP cycle ( 1/centre frequency ) before the peak of the envelope , allowing for the case where the NAP peaks are out of phase with the envelope peak .", "label": "", "metadata": {}, "score": "103.64134"}
{"text": "Occupancy of states 1 and 3 indicate no packet loss while occupancy of state 2 indicates packet loss .In Figure 3 , Q , q and Q ' are the self - loop probabilities of states 1 , 2 and 3 respectively .", "label": "", "metadata": {}, "score": "103.75669"}
{"text": "Looking at undriven filter rise times , we see that a 6ms rise time lockout only affects channels below about 450Hz .Furthermore , in the low - frequency channels there are few NAP peaks per pulse , and so the exact choice of NAP peak for strobing on is less important .", "label": "", "metadata": {}, "score": "103.76224"}
{"text": "This convolution can be achieved in the Laplace domain .The Laplace transform of the function is .It is possible to calculate the inverse Laplace transform explicitly for certain numerical values of the constant n a ( the general solution is also possible , but it is not particularly useful in this case ) .", "label": "", "metadata": {}, "score": "103.91507"}
{"text": "The pole and zero positions are specified in terms of their natural frequencies ( \u03c9 p and \u03c9 z , for the pole and zero , respectively ) and their damping constants ( \u03be p and \u03be z ) .As the damping is increased from zero , the pole and zero move on a circle in the S - plane .", "label": "", "metadata": {}, "score": "104.69697"}
{"text": "TABLE I _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Alignment Memory System Error Rate Time Ratio Size Clean 20 dB 10 dB______________________________________Fine Match 100 % 600 5.8 7.2 11.2Hypothesizer 2.3 % 457 5.1 5.7 12.2Whole System 7.3 % 1057 4.0 4.4 7.9 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "105.83863"}
{"text": "t .x .b .t .t .x .b .t .t .t .x .b .t .t .n . where .t .n .It was found in [ 34 ] that performance was better when the derivative components in ( 7 ) are set to zero .", "label": "", "metadata": {}, "score": "107.355515"}
{"text": "Figure 29 shows a set of strobe points on that NAP .There is exactly one strobe point per cycle in each channel , and the strobe points occur consistently at the peak of the envelope in each channel , so in some sense the algorithm applied here has found the optimal set of strobe points for this signal .", "label": "", "metadata": {}, "score": "108.35765"}
{"text": "In an IP network , packet loss arises primarily due to congestion at the routers within the network , due to high levels of IP traffic .The nature of IP traffic is that it can be described as being ' bursty ' in nature with the result that packet loss occurs in bursts .", "label": "", "metadata": {}, "score": "108.42601"}
{"text": "I am taking you to the fridge ' .A snippet of the grammar that enables ( part of ) the above scenario follows : .56 At the moment the grammar is available in German and English and Rolland can speak back in German , English , and ( some ) Italian .", "label": "", "metadata": {}, "score": "110.98244"}
