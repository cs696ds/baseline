{"text": "Church and Hanks made use of mutual information ( MI ) to evaluate the correlation between a pair of words .They take a window size of five words for co - occurrence and conduct experiments based on a corpus .They were able to extract interesting pairs of related words such as doctors and nurses doctors and treating .", "label": "", "metadata": {}, "score": "33.60253"}
{"text": "As we have mentioned , about 70 lexical functions were distinguished in ( Mel'\u010duk , 1996 ) .The only other existing typology based on semantic and syntactic features includes only 15 different types of collocations ( Benson et al . , 1997 ) .", "label": "", "metadata": {}, "score": "39.043625"}
{"text": "First of all , it falls under category of obvious collocations .If a student knows a basic meaning for each of the two words , they 're likely to be able to put them together without a teaching bringing their attention to it .", "label": "", "metadata": {}, "score": "40.35643"}
{"text": "It has students recording , working with and studying these collocations .In the TESL - L discussion , I argued that this view was both unworkable and unprofitable , mainly because of the low frequency of collocations .While language learners can build knowledge of collocations through extensive reading and listening , this is not something that we can do effectively by design in the classroom .", "label": "", "metadata": {}, "score": "42.614815"}
{"text": "I think where teachers could benefit most from this would be to stop treating vocabulary as one word , and start recognizing the collocations as part of vocabulary as well .We do this sometimes , but generally when you look at lists of new vocabulary , you usually see one individual word instead of two or three .", "label": "", "metadata": {}, "score": "44.09901"}
{"text": "Since the linguistic point we have dealt with speaks of collocations , we will first give a definition of collocation .Many definitions have been proposed by linguists , the first one was given in ( Firth , 1957 ) where the author sees collocations of a given word as statements of the habitual or customary places of that word .", "label": "", "metadata": {}, "score": "44.132217"}
{"text": "Examples of such techniques are extraction of linguistic units or linguistic features from textual chains , analysis of lexical semantic patterns , analysis of collocations and coherent groups , analysis of co - occurrences and conceptual chains , analysis of affect , and others .", "label": "", "metadata": {}, "score": "45.65236"}
{"text": "It was demonstrated in Section 2.5 .that rule - based methods outperformed statistical methods in detecting lexical functions .It means that collocations are analyzed better by rules than by frequency counts ; that rules tell us more of what collocations are than frequency counts do ; that collocations can be recognized better semantically than statistically .", "label": "", "metadata": {}, "score": "45.672752"}
{"text": "b ) removal of stop - words [ list re - ordered ] .c ) analysis of lexical semantic patterns .d ) analysis of collocations and coherent groups .e ) analysis of co - occurrences and conceptual chains .", "label": "", "metadata": {}, "score": "46.41326"}
{"text": "Another preferred combination is wherein the linguistic analysis is the analysis of co - occurrences and collocations and the statistical analysis in hypothesis testing .The system according to the present invention is in particular suitable for textual data which are captured from one or more of : . a ) interviews .", "label": "", "metadata": {}, "score": "46.983475"}
{"text": "That 's seven .So , if we 're looking at the top 2,000 words in English , and we estimate that there are an average of 3 collocates each that are as strong as strong wind , that 's 6,000 collocates ( minus whatever mutual collocates there are ) .", "label": "", "metadata": {}, "score": "47.035065"}
{"text": "Comparison of extracted collocations on synthetic redundant corpora and non - redundant corpora ( WSJ - X words / Y distinct words ) .Collocations were extracted using using True Mutual Information and Pointwise Mutual Information ( with cutoffs of 0.001 and 0.01 respectively ) .", "label": "", "metadata": {}, "score": "47.291077"}
{"text": "The statement affirms that collocations are not a stock , or a ' bag ' of word combinations , where each combination exists as a separate unit with no connection to others , but they are related via collocational isomorphism represented as lexical functions .", "label": "", "metadata": {}, "score": "47.782314"}
{"text": "Halliday , M. A. K. ( 1961 ) .Categories of the Theory of Grammar .Word , 17 , 241 - 292 .Herbst , T. & Mittmann , B. ( 2008 ) .Collocation in English dictionaries at the beginning of the twenty - first century .", "label": "", "metadata": {}, "score": "47.806107"}
{"text": "The system is computationally tractable on large corpora and large lists of terms .Illustrative examples of term variations from a large medical corpus are given .An experimental evaluation of the method shows that only a small proportion of co - occurring words are lexically related and motivates the call for natural language parsing techniques in text windowing .", "label": "", "metadata": {}, "score": "48.034866"}
{"text": "In this sense , collocations of words ( phrases ) have to be considered .However , like individual words , phrases sometimes show polysemy as well depending on the context .More noticeably , a composition of two ( or more ) words is a phrase in some context , but not in other contexts .", "label": "", "metadata": {}, "score": "48.310524"}
{"text": "We introduce a formalization for this class of models , which allows linguistic knowledge to guide the construction process .We evaluate our framework on a range of tasks relevant for cognitive science and natural language processing : semantic priming , synonymy detection , and word sense disambiguation .", "label": "", "metadata": {}, "score": "48.41444"}
{"text": "Journal of Experimental Psychology , 58 ( 2 ) , 159 - 165 .Handl , S. ( 2008 ) .Essential collocations for learners of English : The role of collocational direction and weight .In F. Meunier & S. Granger ( Eds . ) , Phraseology in foreign language learning and teaching ( pp .", "label": "", "metadata": {}, "score": "48.89058"}
{"text": "Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , ... \" .This paper is a comparative study of feature selection methods in statistical learning of text categorization .", "label": "", "metadata": {}, "score": "49.111652"}
{"text": "A mutual information score for two collocates of about 3.0 or above shows a \" semantic bonding \" between the two words .The score for work / job is only 0.97 in the Corpus of Contemporary American English .In fact , there are 168 collocations for job which occur over 100 times and have MI scores higher than work / job .", "label": "", "metadata": {}, "score": "49.568035"}
{"text": "We presented a sufficient number of collocations annotated with lexical functions to the computer that learned characteristic features of each function .It was demonstrated that the computer was able to assign lexical functions to unseen collocations with a significant average accuracy of 0.759 .", "label": "", "metadata": {}, "score": "49.674667"}
{"text": "See Table 2 .The second type of error , loss of signal can also be observed .Another method for selecting the significant collocations is using a top - N cutoff instead of a PMI cutoff .Comparing the top 1,000 collocations with TMI for All Informative Notes and Last Informative Notes , we find a marked difference of 196 collocations .", "label": "", "metadata": {}, "score": "49.71277"}
{"text": "Before formulating the linguistic point we are going to test via computer experiments , we will first localize it within the vast realm of linguistics .Our statement is concerned with the concept of collocation , one of contemporary controversial issues in theoretical and applied linguistics .", "label": "", "metadata": {}, "score": "49.949383"}
{"text": "Of the many suggested methods of development of learner 's linguistic competence , several , given the context , stood out as being either practical or practicable .All of these factors played a part in the next stage of the project , the vocabulary companions .", "label": "", "metadata": {}, "score": "49.97921"}
{"text": "For collocations detection , in Reduced Redundancy Informative Notes , 6,034 collocations were extracted , on average each collocation is supported by 37 distinct patients and collocations supported by 3 patients or less make 6 % of the extracted collocation .We see a significant reduction in the number of collocations based on very few patients from 36 % to 6 % ( Table 3 ) .", "label": "", "metadata": {}, "score": "49.997223"}
{"text": "We can compare our result with computer performance on another task of natural language processing : word sense disambiguation , i.e. , identifying the intended meanings of words in context .Today , automated disambiguating systems reach the accuracy of about 0.700 and this is considered a substantial achievement .", "label": "", "metadata": {}, "score": "49.99965"}
{"text": "Previous works have suggested that the quality of access to information relies heavily on the characteristics of the windows .This study provides a linguistic approach to text windowing through an extraction of term variants with the help of a partial parser .", "label": "", "metadata": {}, "score": "50.01227"}
{"text": "I beg to differ , but I believe you have misunderstood the power of collocational awareness - raising and other more interesting features of the Lexical Approach .In no sense should collocations be the ONLY FOCUS of classroom practice , it sure is more profitable than teaching loose word definitions , though .", "label": "", "metadata": {}, "score": "50.27699"}
{"text": "The m ... \" .This paper describes preliminary experiments documenting significant variations in word usage patterns within topical sublanguages .As some phrases have very different collocational patterns than their constituent words , we look beyond occurrences of individual words , to consider word phrases .", "label": "", "metadata": {}, "score": "50.434326"}
{"text": "Secondly , important academic vocabulary items might have appeared only once or twice in a particular unit .This would n't have provided the level of frequency necessary to include the word on the syllabus .However , by analysing frequency on a whole - book basis , such items appeared many times over the course of five or six units .", "label": "", "metadata": {}, "score": "50.618103"}
{"text": "The detailed distribution supports the distinction into 2 groups of notes : those with heavy repetition ( about 37 % of the pairs - with similarity between 40 % and 100 % ) and those with no repetition ( about 63 % of the notes ) .", "label": "", "metadata": {}, "score": "50.738274"}
{"text": "At any rate , last summer , there was quite a bit of debate on the TESL - L mailing list about collocations and frequency .According to Wikipedia , \" collocation is defined as a sequence of words or terms which co - occur more often than would be expected by chance .", "label": "", "metadata": {}, "score": "50.96844"}
{"text": "With regard to developing linguistic competence , it was decided that the companions would be developed with a number of considerations in mind .Firstly , the companions had to reflect the word lists , i.e. contain the same vocabulary items , therefore becoming a natural progression from the word list , where words are presented in isolation , to a document that would foster a deeper level of understanding .", "label": "", "metadata": {}, "score": "51.013622"}
{"text": "Collocations are not a stock or a ' bag ' of word combinations , where each combination exists as a separate unit with no connection to the others , but they are related via collocational isomorphism represented as lexical functions .Collocational isomorphism .", "label": "", "metadata": {}, "score": "51.06653"}
{"text": "With these goals in mind , one might want to identify concepts that are associated by looking for frequently co - occurring pairs of concepts or phrases in patient notes , or cluster concepts across patients to identify latent variables corresponding to clinical models .", "label": "", "metadata": {}, "score": "51.223625"}
{"text": "In addition to the POC tags assigned to the characters , the merging component incorporates a number of linguistic and statistical heuristics to detect words with regular internal structures , recognize long words , and filter non - words .Experiments show that , without resorting to a separate unknown word identification mechanism , the model achieves an F - score of 95.0 % for word segmentation and a competitive recall of 74.8 % for unknown word recognition . .", "label": "", "metadata": {}, "score": "51.37654"}
{"text": "CA , Los Angeles : University of California Press .Wehrli , E. , Seretan , V. , Nerima , L. & Russo , L. ( 2009 ) .Collocations in a rule - based MT system : A case study evaluation of their translation adequacy .", "label": "", "metadata": {}, "score": "51.593376"}
{"text": "Definition of a concept must contain necessary and sufficient criteria for distinguishing this concept from other concepts .The debate over the most relevant criterion for defining collocations has already lasted over a long period .Should this criterion be statistical or semantic ?", "label": "", "metadata": {}, "score": "51.62018"}
{"text": "Chatfield C. ( 1996 ) .While such statistical methods may provide information from numerical data , they are not directly applicable to textual data .New profiling and segmentations of the consumer population are being sought , which are no longer based on demographics but on new drivers like life style , educational attainment , attitudes to the environment , health issues , social preferences , etc . .", "label": "", "metadata": {}, "score": "51.64907"}
{"text": "Now we are going to see if computer experiments can supply evidence to the existence of collocational isomorphism as defined by lexical functions .The idea is to submit a list of collocations to the computer and see if it is able to distinguish collocations belonging to different lexical functions .", "label": "", "metadata": {}, "score": "51.930843"}
{"text": "Their similarity is represented by the formalism of lexical functions ( Mel'\u010duk , 1996 ) .We experimented with 20 statistical and 21 rulebased machine learning techniques on the training set of Spanish verb - noun collocations annotated with eight lexical functions .", "label": "", "metadata": {}, "score": "51.988163"}
{"text": "Clearly , with the existence of the companion documents , the students were receiving a greater level of support than a learner meeting the word in an everyday uncontrolled situation , especially as the examples used in the companions were lifted directly from the reading texts and listening scripts .", "label": "", "metadata": {}, "score": "51.998955"}
{"text": "The original intent of our research was to test one linguistic model experimentally .The obtained results produced evidence for verifying this model , but they also made it possible to get more insight into the nature of collocation which has been a controversial issue in linguistics for many years .", "label": "", "metadata": {}, "score": "52.1927"}
{"text": "Many studies have indeed shown that cross - domain learned corpora yield poor language models [ 35 ] .The field of domain adaptation attempts to compensate for the poor quality of cross - domain data , by adding carefully picked text from other domains [ 36 , 37 ] or other statistical mitigation techniques .", "label": "", "metadata": {}, "score": "52.220375"}
{"text": "Among 900 most frequent verb - noun collocations , there were 261 free word combinations and 639 collocations belonging to 36 lexical functions .As it was said in Section 1.4 , the overall number of lexical functions that have been identified is 70 .", "label": "", "metadata": {}, "score": "52.32872"}
{"text": "In this scenario , we control for vocabulary : only word types that appear in the smaller corpus ( Last Informative Note ) are considered for collocations .To measure the impact of redundancy on the extracted collocations , for each collocation , we count the number of patients whose notes contain this collocation .", "label": "", "metadata": {}, "score": "52.34871"}
{"text": "Besides , If we are to think of frequency , should n't we then focus on frequent collocations which might have more evident communicational power such as the ones listed above ?I certainly agree that spending classtime(which is supposedly a means to learning faster ) with 6000 collocations is counter - productive , but in no way would I advocate against their teaching .", "label": "", "metadata": {}, "score": "53.10882"}
{"text": "In all cases , 80 to 90 % of the texts were made up of the most common 2000 words .Believe me , this is an important starting block if you 're seriously intending your students to understand reading texts or audio tape scripts .", "label": "", "metadata": {}, "score": "53.18354"}
{"text": "k ) books .l ) magazines .m ) electronically published media .n ) naturally occurring conversations .o ) mixtures of the above .Although the origin of the text may be anything as set out above ( and even other ) , the physical format of such textual data to be analysed is one or more of : . a ) transcripts of speech .", "label": "", "metadata": {}, "score": "53.188454"}
{"text": "By following this formula , it became clear that the companion would be a valuable reference document and go some way to fulfilling the suggestions laid out in the CEF .However , this was not all .The companion had to be something that could act as a springboard to greater development of vocabulary acquisition .", "label": "", "metadata": {}, "score": "53.188904"}
{"text": "One may ask , however , whether the fact that the sentences are repeated in EHR corpora reflects on their semantic importance from a clinical standpoint , and therefore , whether the collocations extracted from the full EHR corpus contain more clinically relevant collocations .", "label": "", "metadata": {}, "score": "53.223923"}
{"text": "By searching using the lexical item as the keyword , a list of headlines were shown , from which collocations could be observed .As the above example shows , these collocations were then used by students to prepare materials to share with their friends .", "label": "", "metadata": {}, "score": "53.285103"}
{"text": "In this work , we study how statistical methods perform on the task of assigning lexical functions to collocations .The second approach in machine learning is based on rules .The computer examines the data and looks for rules which can be inferred from it .", "label": "", "metadata": {}, "score": "53.357906"}
{"text": "Specifically , we investigate on - line ephemeral clustering , whereby the input document set is generated dynamically , typically by search results , and the output clustering hierarchy has a short life span , and is used for interactive browsing purposes .", "label": "", "metadata": {}, "score": "53.40592"}
{"text": "In such a case we deal with the probability of a positive and negative response .These probabilities will be results of a classifier that assigns the class ' yes ' to collocations at random .Since we will compare the probabilities of the random choice with the results obtained in our experiments , we present the former as numbers within the range from 0 to 1 in Table 5 as well as in Table 6 .", "label": "", "metadata": {}, "score": "53.42855"}
{"text": "If that pattern of distance is relatively predictable then we have evidence for a collocation of variable phrases like cement ... relations .Hypothesis Testing .Hypothesis testing is used to check whether two words co - occur more often than a chance .", "label": "", "metadata": {}, "score": "53.77991"}
{"text": "Each data set contains the same 900 verb - noun collocations represented as sets of hyperonyms .The only difference between these data sets is the value of the class variable , which is ' yes ' if a collocation belongs to a given lexical function , and ' no ' if it does not .", "label": "", "metadata": {}, "score": "53.97462"}
{"text": "Collocation or lexical collocation means two or more words co - occur in a sentence more frequently than by chance .A collocation is an expression that forms a specific meaning .It may be noun phrase like large house , verbal phrase like pick up , idioms , cliches or technical terms .", "label": "", "metadata": {}, "score": "54.048195"}
{"text": "Now that the vocabulary items had been decided on , it was necessary to find a way of organizing the content over the course of the academic year : how would 2,500 - 3,000 headwords be presented , taught / learned and assessed ?", "label": "", "metadata": {}, "score": "54.361805"}
{"text": "Experiments show that our techniques significantly increase coverage and effectiveness in the setting of sponsored search . ...Therefore we work with ... . \" ...Algorithms for the alignment of words in translated texts are well established .However , only recently new approaches have been proposed to identify word translations from non - parallel or even unrelated texts .", "label": "", "metadata": {}, "score": "54.379204"}
{"text": "Ghiglione , R. , Landr\u00e9 , A. , Bromberg , M. , Molette , P. ( 1998 ) .L'analyse automatique des contenus .Paris : Dunod .Lebart L. , Salem A. , Berry L. ( 1998 ) .Exploring textual data .", "label": "", "metadata": {}, "score": "54.506294"}
{"text": "These clusters identify countries experiencing similar snow conditions reflected in the use of similar language in their snow reports .An idea of the conditions represented by each of these clusters can be obtained by observing the words used in the descriptions of the conditions of the countries in the cluster which are used infrequently elsewhere .", "label": "", "metadata": {}, "score": "54.614437"}
{"text": "Note that here verbs precede propositions .Calzolari and Bindi uses mutual information for extracting lexical information from an Italian corpus .They used a measure , dispersion , to show how the second word is distributed within the window under consideration .", "label": "", "metadata": {}, "score": "54.7063"}
{"text": "Redundancy across two documents may be measured in different manners : shared words , shared concepts or overlapping word sequences .The most stringent method examines word sequences , and allows for some variation in the sequences ( missing or changed words ) .", "label": "", "metadata": {}, "score": "54.720642"}
{"text": "Unlike other approaches , which involve a dictionary of legal words and are therefore language - specific , i ... \" .This paper describes a general scheme for segmenting text by inferring the position of word boundaries , thus supplying a necessary preprocessing step for applications like those mentioned above .", "label": "", "metadata": {}, "score": "54.86322"}
{"text": "We observe that the lists of extracted collocations on these two corpora differ markedly ( collocations were extracted with a threshold of 0.001 and 0.01 for TMI and PMI respectively ) .The PMI algorithm identified 15,814 collocations in the All Informative Notes corpus , and 2,527 in the Last Informative Notes corpus .", "label": "", "metadata": {}, "score": "54.883858"}
{"text": "Figure 1 further details the full histogram of redundancy for pairs of same - patient informative notes .The redundancy ( percentage of aligned tokens ) was computed for the notes of a random sample of 100 patients .For instance , it indicates that 7.6 % of the same patient note pairs in the corpus have between 20 % and 30 % identity .", "label": "", "metadata": {}, "score": "54.9387"}
{"text": "Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , a \u00d8 2 -test ( CHI ) , and term strength ( TS ) .", "label": "", "metadata": {}, "score": "54.973495"}
{"text": "In other words , we want to determine the presence or absence of what hyperonyms is characteristic for what lexical function and necessary for distinguishing one lexical function from another .Experimental results .As it was explained in Section 2.2 , we chose eight lexical functions for our experiments .", "label": "", "metadata": {}, "score": "55.466118"}
{"text": "We combine them into a single probability that enables hs to identify the referent .Our first experiment shows the relative contribution of each source Of information and demonstrates a success rate of 82.9 % for all sources combined .The second experiment investigates a method for unsuper- vised learning of gender / number / animaticity information .", "label": "", "metadata": {}, "score": "55.508198"}
{"text": "Algorithms for the alignment of words in translated texts are well established .However , only recently new approaches have been proposed to identify word translations from non - parallel or even unrelated texts .This task is . \" ...This article presents methods for biasing statistical translation models to reflect these properties .", "label": "", "metadata": {}, "score": "55.75164"}
{"text": "To infer word boundaries , a general adaptive text compression technique is used that predicts upcoming characters on the basis of their preceding context .Spaces are inserted into positions where their presence enables the text to be compressed more effectively .", "label": "", "metadata": {}, "score": "55.766205"}
{"text": "We present new concepts , techniques and algorithms that tailor clustering to ... . by Amy M. Steier , Richard K. Belew - Second Symposium on Document Analysis and Information Retrieval , 1993 . \" ...This paper describes preliminary experiments documenting significant variations in word usage patterns within topical sublanguages .", "label": "", "metadata": {}, "score": "55.854538"}
{"text": "In that case , such linguistic post - processing comprises preferably one or more of .the grouping of concepts , .the averaging out of semantic values , .the building of word nets from results .The output , either with or without linguistic post processing , may be generated in any suitable form .", "label": "", "metadata": {}, "score": "56.042404"}
{"text": "In the above example , the student is required to choose which of the given definitions is true .Several similar activities were developed , with the aim of giving the learner an entry point to the journey of understanding a word .", "label": "", "metadata": {}, "score": "56.04917"}
{"text": "And that 's over two successive 16-week courses .If they do n't recur , students are very unlikely to pick them up .So what if you deal with them out of context ?The problem is that there are simply too many .", "label": "", "metadata": {}, "score": "56.153152"}
{"text": "Our experiments allowed us to verify this linguistic statement .Moreover , they suggested that semantic considerations are more important in the definition of the notion of collocation than statistical ones .Resumen : La Ling\u00fc\u00edstica , siendo el estudio cient\u00edfico del lenguaje humano , intenta describirlo y explicarlo .", "label": "", "metadata": {}, "score": "56.241364"}
{"text": "More recently , Perotte et al .leveraged topic models in a supervised framework for the task of assigning ICD-9 codes to discharge summaries [ 29 ] .There , the input consisted of the words in the discharge summaries and the hierarchy of ICD-9 codes .", "label": "", "metadata": {}, "score": "56.3225"}
{"text": "Correlation .These statistical techniques are known as such .It has been found that it may be preferred to analyse texts by a combination of techniques according to the invention in which the linguistic analysis is the extraction of linguistic units or linguistic features and the statistical analysis is dimension reduction .", "label": "", "metadata": {}, "score": "56.32563"}
{"text": "The results of high redundancy in patient notes are consistent with Wrenn et al .[14 ] observations on a similar EHR dataset .The contrast between same - patient and across - patient redundancy , however , is surprising given that the whole corpus is sampled from a population with at least one shared chronic condition .", "label": "", "metadata": {}, "score": "56.427757"}
{"text": "Collocational isomorphism is not a complete equality of the meaning of two or more collocations , but rather a semantic and structural similarity between collocations .What do we mean by semantic and structural similarity between collocations ?For convenience of explanation , we will comment on the structural similarity of collocations first .", "label": "", "metadata": {}, "score": "56.614613"}
{"text": "There are many approaches to find collocations in a text corpus .The important ones are : .Frequency 2 .Mean and Variance 3 .Hypothesis Testing 4 .Mutual Information .Frequency .Frequency is the simplest method for finding collocations in a text corpus .", "label": "", "metadata": {}, "score": "56.680695"}
{"text": "In the clinical domain , Arnold et al .[28 ] used LDA for comparing patient notes based on topics .A topic model was learned for different cohorts , with the number of topics derived experimentally based on log - likelihood fit of the created model to a test set .", "label": "", "metadata": {}, "score": "56.819412"}
{"text": "As such , the LDA topics group words that tend to co - occur .From the viewpoint of disease modeling , LDA topics are an attractive data modeling and corpus exploration tool .As illustrative examples , we show the top-20 tokens corresponding to three topics acquired from a corpus of patient notes in Table 1 .", "label": "", "metadata": {}, "score": "56.91501"}
{"text": "To understand this discrepancy , we examine the topics obtained on the redundant corpora qualitatively .Topics are generated by LDA as ranked lists of words .Once a topic model is applied on a document , we can compute the topic assignment for each word in the document .", "label": "", "metadata": {}, "score": "56.9281"}
{"text": "A subset of this matrix ( as an example , whole matrix is too big to display ) is shown in Table 2 .The dimension reduction technique , correspondence analysis ( as described in Greenacre ( 1984 )Theory and Applications Of Correspondence Analysis , London : Academic Press ) was then applied to this frequency matrix and the scores for the first two dimensions extracted for both the countries and words .", "label": "", "metadata": {}, "score": "56.95882"}
{"text": "Haug P , Koehler S , Lau L , Wang P , Rocha R , Huff S : A natural language understanding system combining syntactic and semantic techniques .Proc Annu Symp Comput Appl Med Care 1994 , 247 - 251 .", "label": "", "metadata": {}, "score": "56.99265"}
{"text": "In order to do this , the second stage of the analysis was undertaken : a frequency analyser was employed .Frequency analysers are really cool , because they make it possible to see how many times particular words appeared in particular units .", "label": "", "metadata": {}, "score": "57.02207"}
{"text": "[Links ] .Bolshakov , I.A. & Miranda - Jim\u00e9nez S. ( 2004 ) .A small system storing Spanish collocations .In A. Gelbukh ( Ed . ) , Lecture notes in computer science : Computational linguistics and intelligent text processing ( pp .", "label": "", "metadata": {}, "score": "57.035637"}
{"text": "Successive bigrams form longer phrases .We present experiments showing meaningful phrases and more interpretable topics from the NIPS data and improved information retrieval performance on a TREC collection . ... hort - distance dependency .Most research on phrases in information retrieval has employed an independent collocation discovery module .", "label": "", "metadata": {}, "score": "57.067863"}
{"text": "Conventional wisdom is that larger corpora yield better results in text mining .In fact , it is well established empirically that larger datasets yield more accurate models of text processing ( see for example , [ 31 - 34 ] ) .", "label": "", "metadata": {}, "score": "57.102364"}
{"text": "In this paper , we ask three research questions : ( i ) How can redundancy be quantified in large - scale text corpora ?( ii )Conventional wisdom is that larger corpora yield better results in text mining .But how does the observed EHR redundancy affect text mining ?", "label": "", "metadata": {}, "score": "57.113968"}
{"text": "Stage Three activities created needs for the students to use the vocabulary productively .One of the fears of using a relatively small corpus , in the region of 250,000 words , was that the amount of data available to develop ' linguistic competence ' would be insufficient .", "label": "", "metadata": {}, "score": "57.19326"}
{"text": "The average amount of redundancy in removed note pairs is sampled as well .Redundancy is computed in the same way as in Section 2.1.1 .We randomly sampled 2,000 same - patient pairs of notes and aligned them using Smith - Waterman alignment .", "label": "", "metadata": {}, "score": "57.66239"}
{"text": "We observe that the log - likelihood graphs for them have the same shape , with the larger corpora achieving higher log - likelihood , and the best fits obtained with topic numbers between 100 and 200 ( Figure 4 a ) .", "label": "", "metadata": {}, "score": "57.82599"}
{"text": "We define a scale for evaluating query substitution , and show that our method performs well at generating new queries related to the original queries .We build a model for selecting between candidates , by using a number of features relating the query - candidate pair , and by fitting the model to human judgments of relevance of query suggestions .", "label": "", "metadata": {}, "score": "57.87291"}
{"text": "This phenomenon also hampers the use of machine learning methods by preventing a good division of the data to non - overlapping test and train sets .Results and discussion .Quantifying redundancy in a large - scale EHR corpus .Word sequence redundancy at the patient level .", "label": "", "metadata": {}, "score": "57.950195"}
{"text": "I found that , in Interactions 1 Reading and Interactions 2 Reading combined , 60 % of these word families appeared less than four time , with singletons being the largest group .Only 24 % of word families were repeated more than 7 times .", "label": "", "metadata": {}, "score": "58.07551"}
{"text": "TS compares favorably with the other methods with up to 50 % vocabulary redu ... . ... to thes2 distribution ) if any cell in the contingency table is lightly populated , which is the case for low frequency terms . 2.5 Term strength ( TS ) Term strength is originally proposed and evaluated by Wilbur and Sirotkin [ 22 ] for vocabulary reduction in text retrieval , and later applied by Yang and Wilbur to text categor ... . \" ...", "label": "", "metadata": {}, "score": "58.107483"}
{"text": "The output of this extraction and classification system can be viewed as a single - document summary in its own right ; alternatively , it can be used to generate task - oriented and user - tailored summaries designed to give users an overview of a scientific field . by Niyu Ge , John Hale , Eugene Charniak - In Proceedings of the Sixth Workshop on Very Large Corpora , 1998 . \" ...", "label": "", "metadata": {}, "score": "58.26153"}
{"text": "However , in order to analyse and interpret the long - term target vocabulary for the university 's lexical syllabus , the texts were analysed on a whole - book basis .Why ?Well , there were two main reasons for adopting such an approach .", "label": "", "metadata": {}, "score": "58.3316"}
{"text": "The entire contents of every book were put through the frequency analysis and vocabulary profile tools .Firstly , each unit of each book was analysed separately to choose the unit specific vocabulary .Profiling the vocabulary for each unit and then choosing words that were not from the most common 2000 or the AWL / UWL made this possible .", "label": "", "metadata": {}, "score": "58.625565"}
{"text": "We provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics with human judgements of rhetorical status and relevance .We present several experiments measuring our judges ' agreement on these annotations .", "label": "", "metadata": {}, "score": "58.629734"}
{"text": "Collocation discovery can help identify lexical variants of medical concepts that are specific to the genre of clinical notes and are not covered by existing terminologies .Topic modeling , another text - mining technique , can help cluster terms often mentioned in the same documents across many patients .", "label": "", "metadata": {}, "score": "58.75912"}
{"text": "The number of topics is a free parameter of LDA - given two LDA models with the same log - likelihood on withheld data , the one with the lower number of topics has better explanatory power ( fewer latent variables or topics are needed to explain the data ) .", "label": "", "metadata": {}, "score": "58.781944"}
{"text": "The fact that redundancy never occurs across patients , but within same - patient notes only , seems to create unintended biases in the extracted collocations .The results on the WSJ and its synthetic variants confirm our results on the EHR corpora : collocations extracted on a redundant corpus differ significantly from those extracted on a corpus of similar size without redundancy .", "label": "", "metadata": {}, "score": "58.800594"}
{"text": "Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?( iii )How can one mitigate the impact of redundancy on text mining ?Results .We analyze a large - scale EHR corpus and quantify redundancy both in terms of word and semantic concept repetition .", "label": "", "metadata": {}, "score": "58.88115"}
{"text": "Semantic Collocations : They are lexically restricted word pairs , for which only a subset of the synonym of the collocator can be used in the same lexical context .Collocations are also categorized into compounds and flexible word pairs .Compounds : Compounds include word pairs that occur consecutively in language and typically are immutable in function .", "label": "", "metadata": {}, "score": "58.970013"}
{"text": "Mutual information and topic modeling .Collocation identification was carried out on the different corpora using the Ngram Statistics Package [ 53 ] , which provides an implementation for collocation detection using True Mutual Information ( TMI ) and Pointwise Mutual Information ( PMI ) .", "label": "", "metadata": {}, "score": "59.00657"}
{"text": "Even the simplest kinds of languagespecific knowledge , such as the distinction between content words and function words , are shown to reliably boost translation model performance on some tasks .Statistical models that reflect knowledge about the model domain combine the best of both the rationalist and empiricist paradigms . \" ...", "label": "", "metadata": {}, "score": "59.145622"}
{"text": "1 shows a plot of the scores of the words and countries on the first two dimensions .Countries who are experiencing similar conditions and who have similar language used to describe their conditions will have similar scores from the correspondence analysis and so will be plotted close together in this map .", "label": "", "metadata": {}, "score": "59.378803"}
{"text": "With these four stages in place , it was time to ask whether or not these materials were adequate , were they doing the job ?Getting feedback .How would I find out how this was going if I did n't ask the major stake holders ?", "label": "", "metadata": {}, "score": "59.566376"}
{"text": "In M. Everaert , E.-J. van der Linden , A. Schenk & R. Schreuder ( Eds . ) , Idioms : Structural and Psychological perspectives ( pp .167 - 232 ) .Hillsdale , NJ : Lawrence Erlbaum .Mel'\u010duk , I. ( 1996 ) .", "label": "", "metadata": {}, "score": "59.590645"}
{"text": "We extracted collocations which are most frequently met in the Spanish Web Corpus ; therefore , these are most common collocations in contemporary Spanish Internet communication .The list of 900 verb - noun collocations was manually annotated with lexical functions 4 .", "label": "", "metadata": {}, "score": "59.63917"}
{"text": "Less stringent metrics include : amount of shared words , amount of shared concepts or amount of overlapping bi - grams [ 16 ] .While these methods have been shown to identify semantic similarity of texts , they do not specifically capture instances of copy - paste operations , which reproduce whole paragraphs .", "label": "", "metadata": {}, "score": "59.67733"}
{"text": "For the sake of preserving the complete notation , we use the name of the function and the subscripts , but since we are interested in the semantic aspect of collocations , here we leave the subscripts unexplained .However , a detailed description of subscripts and their meanings can be obtained from ( Mel'\u010duk , 1996 ) .", "label": "", "metadata": {}, "score": "59.706024"}
{"text": "What form would such documents take ?How would such activities be described in a syllabus ?In order to do this ( and to set descriptors for the project in the syllabus ) , activities were developed under three headings ; Stage One - First Encounters ; Stage Two - Getting to know the word ; and Stage Three - Using the word .", "label": "", "metadata": {}, "score": "59.847256"}
{"text": "We revisit document clustering in the context of the Web .Specifically , we investigate on - line ephemeral clustering , whereby the input document set is generated dynamically , typically by search results , and the output clustering hierarchy has a short life span , and is used for interactive browsing ... \" .", "label": "", "metadata": {}, "score": "60.165302"}
{"text": "As set out herein before , the invention provides a system for analysing textual data .Likewise , it may be preferred to compare the revealed information obtained using a system according to the invention with existing numerical or textual data .", "label": "", "metadata": {}, "score": "60.250397"}
{"text": "Thus lexical functions as a linguistic concept get evidence received in computational experiments which can be repeated on the same data as well as on new data .It means that the formalism of lexical functions is a legitimate model of collocational isomorphism described in Section 1.3.1 .", "label": "", "metadata": {}, "score": "60.316315"}
{"text": "Operating on our linguistic data , methods based on frequency counts , or statistical methods , calculate the probability of collocations in the input data to belong to a given lexical function under study using Bayes ' theorem .Many statistical machine learning methods use Bayes ' formula together with optimizations and improvements , but all are based on probabilistic knowledge .", "label": "", "metadata": {}, "score": "60.331627"}
{"text": "The Stage Two activities addressed such issues , and necessitated that students develop a deeper level of understanding of the lexical item .The examples below show two of the activities used to develop greater level of cognition .In these examples , the students are required to do such tasks as recognise the grammar associated with the lexical item ( does it require the use of the infinitive or gerund ? ) and develop their knowledge of some of the strong collocations and lexical chunks associated with each item .", "label": "", "metadata": {}, "score": "60.409225"}
{"text": "Gathering such information can be done in many different ways , e.g. by interviewing individuals or groups of consumers , feedback after purchase , spontaneous email ( e.g. from consumers to care - lines of product websites ) , questionnaires call for free - text answers , et cetera .", "label": "", "metadata": {}, "score": "60.486763"}
{"text": "Compounds form a bridge between collocations and idioms as they are quite invariable but need not be semantically opaque .Flexible Word Pairs : Flexible word pairs include collocations between subject and verb , or verb and object .Any number of intervening words may occur between the words of the collocation .", "label": "", "metadata": {}, "score": "60.49579"}
{"text": "So collocations have structural similarity when they share a common syntactic structure .We say that two or more collocations are similar semantically if they possess a common semantic content .In Table 1 , we present collocations with the same syntactic structure , namely , ' verb + noun ' .", "label": "", "metadata": {}, "score": "60.503944"}
{"text": "Publishers , Mahwah , N.J. .Sinclair , J.M. ( 1991 ) .Corpus , concordance , collocation .Oxford : Oxford University Press .Whissell , C. , Fournier , M. , Pelland , R. , Weir , D. & Makarec , K. ( 1986 ) .", "label": "", "metadata": {}, "score": "60.584076"}
{"text": "His theory postulates that collocations are produced by a mechanism called lexical function .Lexical function is a mapping from the base to the collocate ; it is a semantically marked correspondence that governs the choice of the collocate for a particular base .", "label": "", "metadata": {}, "score": "60.605938"}
{"text": "Therefore , our result is weighty enough to be a trustworthy evidence for the linguistic statement under discussion .In the Introduction we stated , that if we develop a computer program on the premise of a certain linguistic model and this program accomplishes its task successfully , then the linguistic model being the basis of the program is thus verified .", "label": "", "metadata": {}, "score": "60.613712"}
{"text": "In other words , certain fairly natural word combinations do not appear with sufficient frequency in print ( or in pixels ) to register on collocational radar if their appearances in fiction are discounted .The reason this strikes us as being odd is this : is n't a great deal of fiction supposed to be a reflection of what really goes down ?", "label": "", "metadata": {}, "score": "60.63206"}
{"text": ".. matical systems .As we are most interested in simple word compounds ( such as \" social security \" ) , we use sequential word pairs , or bigrams to identify potentially interesting word co - occurrences .Church and Hanks ... . \" ...", "label": "", "metadata": {}, "score": "60.681454"}
{"text": "About 70 lexical functions have been identified in ( Mel'\u010duk , 1996 ) ; each is associated with a particular meaning according to which it receives its name .The name of a lexical function is an abbreviated Latin word whose semantic content is closest to the meanings of this lexical function .", "label": "", "metadata": {}, "score": "60.721363"}
{"text": "The more frequently they appear , the more likely they are to be used again by lazy writers , and soon you have an overwhelming preponderance of these phrases in fiction as opposed to anywhere else .Tools . by W. J. Teahan , Yingying Wen , Rodger Mcnab , Ian H. Witten - Computational Linguistics . \" ...", "label": "", "metadata": {}, "score": "60.751762"}
{"text": "Semantically , the base is used in its typical meaning while the collocate accepts another meaning , not typical for it but determined by the base .Now we are going to present our linguistic statement .The terms ' collocational isomorphism ' and ' lexical function ' are explained in the sections that follow .", "label": "", "metadata": {}, "score": "60.85962"}
{"text": "In the highly - redundant All Informative Notes corpus , the peak is the most pronounced , with more concepts occurring four to eight times in the corpus than once .Concept - distribution .Distribution of UMLS concept occurrences in corpora with different levels of redundancy .", "label": "", "metadata": {}, "score": "60.875694"}
{"text": "We incorporate multiple anaphora resolution factors into a statistical framework -- specifically the distance between the pronoun and the proposed antecedent , gender / number / animaticity ... \" .This paper presents an algorithm for identifying pronominal anaphora and two experiments based upon this algorithm .", "label": "", "metadata": {}, "score": "60.88977"}
{"text": "San Francisco : Morgan Kaufmann .[Links ] .Zhong , Z. & Tou Ng , H. ( 2010 ) .It makes sense : A wide - coverage word sense disambiguation system for free text .Proceedings of System Demonstrations , 48th Annual Meeting of the Association for Computational Linguistics .", "label": "", "metadata": {}, "score": "60.960495"}
{"text": "Similarity matrix of language usage between snow reports of different countries .The Stuff of Fiction .Some months ago in the Lounge ( last August , to be exact ) we talked about the results of a project on collocations that yielded up some interesting features of English .", "label": "", "metadata": {}, "score": "61.012802"}
{"text": "While the semantics of a free word combination is the sum of the meanings of its elements , collocational meaning is formed by adding more abstract semantic features expressed by the collocate to the full meaning of the base .Our experiments showed that collocations are recognized better using rules , or conceptual knowledge .", "label": "", "metadata": {}, "score": "61.03286"}
{"text": "Berlin : Springer - Verlag .Boonyasaquan , S. ( 2006 ) .An analysis of collocational violations in translation .Journal of Humanities , 27 , 79 - 91 .Firth , J. R. ( 1957 ) .Modes of meaning .", "label": "", "metadata": {}, "score": "61.062122"}
{"text": "2.4 Evaluation Performance of Chinese word segmenters is generally reported in terms of precision and recall .However , a comparison across systems cou ... . \" ...This paper describes a hybrid model that combines machine learning with linguistic heuristics for integrating unknown word identification with Chinese word segmentation .", "label": "", "metadata": {}, "score": "61.218613"}
{"text": "In this paper , we ask three research questions : ( i ) how can redundancy be quantified in large - scale text corpora ?( ii )Conventional wisdom is that larger corpora yield better results in text mining .But how does the observed text redundancy in EHR affect text mining ?", "label": "", "metadata": {}, "score": "61.239014"}
{"text": "They both rely on patterns of co - occurrence of words .Collocations are word sequences that co - occur more often than expected by chance .Collocations , such as \" heart attack \" and \" mineral water , \" carry more information than the individual words comprising them .", "label": "", "metadata": {}, "score": "61.338036"}
{"text": "Methodology .In other words , the computer must find what features distinguish Oper 1 from other lexical functions .This knowledge will be used later , when the computer is given a list of collocations whose lexical functions are unknown to it .", "label": "", "metadata": {}, "score": "61.388798"}
{"text": "Fingerprinting algorithm .Detecting redundancy within the notes of a single patient is feasible using standard alignment methods borrowed from bioinformatics such as : Smith - Waterman [ 52 ] , FastA [ 41 ] or Blast2seq [ 40 ] .However , some available EHR corpora are de - identified to protect patient privacy [ 57 ] and notes are not grouped by patients .", "label": "", "metadata": {}, "score": "61.46467"}
{"text": "Collocational isomorphism represented as lexical functions .Several attempts to conceptualize and formalize semantic similarity of collocations have been made .The common semantic content in these pairs is ' typical action of an object ' .Research of Firth ( 1957 ) drew linguists ' attention to the issue of collocation and since then collocational relation has been studied systematically .", "label": "", "metadata": {}, "score": "61.700737"}
{"text": "Unlike many attempts to combine natural ... \" .This paper describes the results of some experiments using a new approach to information access that combines techniques from natural language processing and knowledge representation with a penaltybased technique for relevance estimation and passage retrieval .", "label": "", "metadata": {}, "score": "61.770245"}
{"text": "In Proceedings of the 1st international workshop on Text mining in bioinformatics : 2006 .ACM ; 2006:7 - 14 .McInnes BT , Pedersen T , Pakhomov SV : Determining the syntactic structure of medical terms in clinical notes .In Proceedings of the Workshop on BioNLP 2007 : Biological , Translational , and Clinical Language Processing : 2007 .", "label": "", "metadata": {}, "score": "61.905308"}
{"text": "The output is eight data sets , one for each of the selected lexical functions .The data sets include all hyperonyms 1 of each verb and all hyperonyms of each noun in the collocations .The hyperonyms are retrieved from the Spanish WordNet , an electronic dictionary .", "label": "", "metadata": {}, "score": "61.94226"}
{"text": "I have a hunch that many collocations appear in fiction more than anywhere else because they have become cliches that automatically come to mind when writers are trying to think of a way to describe something , but do n't want to work too hard .", "label": "", "metadata": {}, "score": "61.948174"}
{"text": "An automated system for measuring semantic orientation would have application in text classification , text filtering , tracking opinions in online discussions , analysis of survey responses , and automated chat systems ( chatbots ) .This article introduces a method for inferring the semantic orientation of a word from its statistical association with a set of positive and negative paradigm words .", "label": "", "metadata": {}, "score": "61.99457"}
{"text": "The next step in developing a formalism representing semantic relations between the base and the collocate as well as semantic and structural similarity between collocations was done by Mel'\u010duk .Up to now , his endeavor has remained the most fundamental and theoretically well - grounded attempt to systematize collocational knowledge .", "label": "", "metadata": {}, "score": "61.99936"}
{"text": "Our method can produce corpora with different redundancy amounts quickly , without alignment of documents and without any prior knowledge of the documents .We confirmed that the parameter of our Selective Fingerprinting method is a good predictor of document alignment and can be used as the sole method for removing redundancy .", "label": "", "metadata": {}, "score": "62.038002"}
{"text": "g ) analysis of affect .h ) tagging units in the textual chain yields : Part - Of - Speech tags , semantic descriptors , other indexing tags , syntactic tagging , functional tagging .i ) analysis of syntactic complexity .", "label": "", "metadata": {}, "score": "62.12757"}
{"text": "The method is experimentally tested with 3,596 words ( including adjectives , adverbs , nouns , and verbs ) that have been manually labeled positive ( 1,614 words ) and negative ( 1,982 words ) .The method attains an accuracy of 82.8 % on the full test set , but the accuracy rises above 95 % when the algorithm is allowed to abstain from classifying mild words . \" ...", "label": "", "metadata": {}, "score": "62.18761"}
{"text": "This document does not indicate the advantages of first applying a linguistic analysis and subsequently applying a statistical analysis on the results thereof .DETAILED DESCRIPTION OF THE INVENTION .It has now been found that statistical analyses may be performed on data that is obtained from a preceding linguistic analysis of textual data , and that such a combination of techniques yields information from unstructured , subjective or personal texts not available so far .", "label": "", "metadata": {}, "score": "62.550766"}
{"text": "TREC collections .Most research on phrases in information retrieval has employed an independent collocation discovery module , e.g. , using the methods descr ... .by William A. Woods , Lawrence A. Bookman , Ann Houston , Robert J. Kuhns , Paul Martin , Stephen Green - In Sixth Annual Applied Natural Language Processing Conference , 1999 . \" ...", "label": "", "metadata": {}, "score": "62.65661"}
{"text": "The differences we observe in this experiment are caused by the fact that some sentences only are copied , in a variable number of times ( some sentences occur once , some twice , and others 5 times ) .Thus , PMI ( which does not simply reflect word frequencies in a corpus , but takes into account global patterns of co - occurrences , since it relies on the probability of seeing terms jointly and terms independently ) does not behave similarly when fed with our different corpora .", "label": "", "metadata": {}, "score": "62.671127"}
{"text": "This suggested that the texts in all of the books were extremely well suited to academic English study .The project was starting with good foundations .To give these statistics some context , they can be compared to those of a typical academic text .", "label": "", "metadata": {}, "score": "62.781967"}
{"text": "We empirically measure the damage caused by redundancy on the tasks of collocation extraction and topic modeling through a series of controlled experiments .Preliminary qualitative inspection of the results suggests that idiosyncrasies of each patient ( where the redundancy occurs ) explain the observed bias .", "label": "", "metadata": {}, "score": "62.877026"}
{"text": "In this paper , we focused on intrinsic , quantitative evaluations to assess the impact of redundancy on two text - mining techniques .Qualitative analysis as well as task - based evaluations are needed to get a full understanding of the role of redundancy in clinical notes on text - mining methods .", "label": "", "metadata": {}, "score": "62.95787"}
{"text": "Whether the information appears directly expressed or implicit in the text , it may be desired to perform some analysis or information extraction and/or interpretation to obtain this information .Existing examples of information extraction from factual documents ( e.g. reports , scientific prose , news feeds , legal texts , etc . ) are based on the recognition of entities and events .", "label": "", "metadata": {}, "score": "62.95816"}
{"text": "Reliability , validity , and applications .Perceptual and Motor Skills .While such information extraction or linguistic analysis techniques may provide valuable information , there is more information which is hidden in textual data which is not revealed by these methods .", "label": "", "metadata": {}, "score": "62.995556"}
{"text": "Experiments o ... \" .We propose a self - supervised word segmentation technique for text segmentation in Chinese information retrieval .This method combines the advantages of traditional dictionary based , character based and mutual information based approaches , while overcoming many of their shortcomings .", "label": "", "metadata": {}, "score": "63.138615"}
{"text": "Towards automatic fine - grained semantic classification of verb - noun collocations .Natural Language Engineering , 10 ( 2 ) , 95 - 143 .Weinreich , U. ( 1969 ) .Problems in the analysis of idioms .In J. Puhvel ( Ed . ) , Substance and structure of language ( pp .", "label": "", "metadata": {}, "score": "63.14613"}
{"text": "Add the set of hyperonyms to the data set .Return the data set .Figure 1 .Algorithm of compiling the data sets .For each of eight lexical functions , a data set is compiled according to the algorithm presented in Figure 1 .", "label": "", "metadata": {}, "score": "63.166542"}
{"text": "It is with these two constraints in mind that the need for an explicit vocabulary syllabus was realised .My task : analysis .Nunan ( 1999:73 ) notes : ' Key tasks for a syllabus designer are the selection of the items [ to be taught ] and their sequence and integration . '", "label": "", "metadata": {}, "score": "63.24155"}
{"text": "CONCLUSIONS .It has been demonstrated that computer experiments we made on Spanish verb - noun collocations verify the linguistic hypothesis that collocations are not a random stock of word combinations , but they are semantically and syntactically related to one another .", "label": "", "metadata": {}, "score": "63.275055"}
{"text": "Intelligent Systems , IEEE 2009 , 24 ( 2 ) : 8 - 12 .View Article .Dredze M , Blitzer J , Talukdar PP , Ganchev K , Graca J , Pereira F : Frustratingly hard domain adaptation for dependency parsing .", "label": "", "metadata": {}, "score": "63.371403"}
{"text": "We demonstrate this e ect by presenting an empirical investigation of information retrieval on Chinese TREC data , using a wide variety of word segmentation algorithms with word segmentation accuracies ranging from 44 % to 95 % .It appears that the main reason for the drop in retrieval performance is that correct compounds and collocations are preserved by accurate segmenters , while they are broken up by less accurate ( but reasonable ) segmenters , to a surprising advantage .", "label": "", "metadata": {}, "score": "63.372818"}
{"text": "They confirm that in outpatient notes , like for inpatient notes , there is a large amount of redundancy .Different metrics for quantifying redundancy exist for text .Sequence alignment methods such as the one proposed by Zhang et al .", "label": "", "metadata": {}, "score": "63.48861"}
{"text": "Assessing redundancy through alignment is a more appropriate and more stringent method than counting simple token overlap as in a bag - of - word model .High percentage of alignment between two notes indicates not only that tokens are similar across the two notes , but that the sequences of tokens in the notes are also similar .", "label": "", "metadata": {}, "score": "63.491226"}
{"text": "Even more striking , when examining the behavior of WSJs5 ( with 3,300 documents sampled from 1,300 distinct documents ) up to 100 topics , we observe it reaches the same fit as WSJ-600 .We have seen that for the naturally occurring WSJ corpus training on more data produces better fit to held out data ( see Figure 4 a ) .", "label": "", "metadata": {}, "score": "63.506165"}
{"text": "We measure the impact of redundancy on two standard text - mining applications : collocation identification and topic modeling .We compare the results of these methods on synthetic data with controlled levels of redundancy and observe significant performance variation .Finally , we compare two mitigation strategies to avoid redundancy - induced bias : ( i ) a baseline strategy , keeping only the last note for each patient in the corpus ; ( ii ) removing redundant notes with an efficient fingerprinting - based algorithm .", "label": "", "metadata": {}, "score": "63.63836"}
{"text": "Even if you did focus entirely on collocation , the payback would be minimal .If we can take the British National Corpus ( BNC ) as being representative of English as a whole , then the strong wind collocation occurs a mere 3.06 times per million words ( strong within 4 words either side of wind(s ) ) .", "label": "", "metadata": {}, "score": "63.726517"}
{"text": "Therefore , the four - stage approach would serve to define how the level of control was to be defined .So , how ?Concentrate , because this is where it gets interesting ( for me , at least ) , because I 'm not sure if anyone else has done it quite like this .", "label": "", "metadata": {}, "score": "63.95809"}
{"text": "So , is it more worthwhile to enrich students ' understanding of wind by looking at collocates , or to have students study a basic meaning for compromise ?Would n't \" big wind \" or \" heavy wind \" get them by just fine ?", "label": "", "metadata": {}, "score": "63.9953"}
{"text": "A6 sentences .A7 paragraphs .A8 discourse structures , rhetorical structures .A9 functions ( e.g. subject , object , complement , adverbial ) .A10 semantic patterns ( e.g. Key Words In Context 's ) , collocations , co - occurrences , semantic fields , semantic networks , semantic components ) .", "label": "", "metadata": {}, "score": "64.21608"}
{"text": "Pieces of data examined by machine learning techniques are called instances , or examples .In our case , an example is a set of all hyperonyms for a particular collocation as represented in Figure 2 .Examples can be annotated with respective lexical functions called classes in machine learning , or can be left without such annotation .", "label": "", "metadata": {}, "score": "64.27397"}
{"text": "Barcelona : Spain .[Links ] .Williams , G. ( 2002 ) .In search of representativity in specialised corpora : Categorisation through collocation .International Journal of Corpus Linguistics , 7 , 43 - 64 .Witten , I. H. & Frank , E. ( 2005 ) .", "label": "", "metadata": {}, "score": "64.39293"}
{"text": "In this paper we show that , for Chinese , the relationship between segmentation and retrieval performance is in fact nonmonotonic ; that is , at around 70 % word se ... \" .It is commonly believed that word segmentation accuracy is monotonically related to retrieval performance in Chinese information retrieval .", "label": "", "metadata": {}, "score": "64.3933"}
{"text": "..e search effectiveness in this system . \" ...Windowing techniques play a key role in information retrieval .Previous works have suggested that the quality of access to information relies heavily on the characteristics of the windows .This study provides a linguistic approach to text windowing through an extraction of term variants with the hel ... \" .", "label": "", "metadata": {}, "score": "64.401596"}
{"text": "We show that this algorithm does not require the slower alignment stage of BLAST and that it accurately identifies instances of copy - paste operations .Text mining techniques .We review two established text - mining techniques : collocation identification and topic modeling .", "label": "", "metadata": {}, "score": "64.48077"}
{"text": "All of them , except for Plus and Minus , were introduced earlier in this section .Plus ( more ) and Minus ( less ) are self - explanatory .Table 3 .Semantic patterns represented as lexical functions .Semantic pattern and examples .", "label": "", "metadata": {}, "score": "64.48347"}
{"text": "Other examples that students picked up on were the learner training activity mentioned previously , and other activities that promoted autonomy and creativity .Another important issue raised was that of spending time on vocabulary work in class .Students strongly indicated that they felt time spent working with the materials in class to be more valuable than having to work through the materials themselves .", "label": "", "metadata": {}, "score": "64.60459"}
{"text": "Our method is completely language independent and unsupervised , which provides a promising avenue for constructing accurate multi - lingual or cross - lingual information retrieval systems that are exible and adaptive .We nd that although the segmentation accuracy of self - supervised segmentation is not as high as some other segmentation methods , it is enough to give comparable ( in some cases even better ) retrieval performance .", "label": "", "metadata": {}, "score": "64.60781"}
{"text": "On this synthetic corpus , we obtain a different list of collocations when using the PMI algorithm : 17,015(\u00b1950 ) instead of 2,737 .The growth in number of extracted collocations is expected since WSJs5 is 2.5 times larger than WSJ-1300 , but this growth is less than expected when comparing the trend ( WSJ-400 , WSJ-600 , WSJ-1300 ) with a growth of ( 565 , 1,000 and 2,737 ) extracted collocations .", "label": "", "metadata": {}, "score": "64.73125"}
{"text": "But just selecting the most frequently occurring bigrams ( sequence of two adjacent words ) does not always yield the better results .Following are a few bigrams resulted from an experiment . of the in the to the as a has been New York is a for a .", "label": "", "metadata": {}, "score": "64.77356"}
{"text": "For the experiments , eight lexical functions were chosen .This choice was made on the basis of data available to us .This is further explained in Section 2.2 .Algorithm : constructing data sets Input : a list of 900 Spanish verb - noun collocations annotated with 8 lexical functions Output : 8 data sets - one for each lexical function For each lexical function Create an empty data set and assign it the name of the lexical function .", "label": "", "metadata": {}, "score": "64.79317"}
{"text": "In this article we present a novel framework for constructing semantic spaces that takes syntactic relations into account .We introduce a formalization for this class of m ... \" .Traditionally , vector - based semantic space models use word co - occurrence counts from large corpora to represent lexical meaning .", "label": "", "metadata": {}, "score": "64.92017"}
{"text": "Marchand , P. ( 1998 ) .L'analyse du discours assist\u00e9e par ordinateur .Concepts , m\u00e9thodes , outils .Paris : Armand Colin ( U ) .Roberts , C.W. ( 1997 ) .Text analysis for the social sciences : methods for drawing statistical interferences from texts and transcripts .", "label": "", "metadata": {}, "score": "64.923584"}
{"text": "One way in which this issue was addressed was in the development of ' Stage Zero ' activities , for learner training .A typical activity was to assign particular lexical items to groups of students and have them research that word on the Internet .", "label": "", "metadata": {}, "score": "65.00248"}
{"text": "The purpose of the experiments is to test a linguistic statement concerning collocational semantics .It should be added here that testing a linguistic hypothesis on computer models not only demonstrates validity or rejection of the hypothesis , but also motivates the researcher to search for more profound explanations or to explore new approaches in order to improve computational operation .", "label": "", "metadata": {}, "score": "65.256165"}
{"text": "It differentiates from most of the previous approaches mainly in three respects .First of all , while theoretical linguists have defined Chinese words with various linguistic criteria , Chinese words in this study are defined pragmatically as segmentation units whose definition depends on how they are used and processed in realistic computer applications .", "label": "", "metadata": {}, "score": "65.33542"}
{"text": "T\u00fcbingen : Niemeyer .Jin , P. , Sun , X. , Wu , Y. & Yu , S. ( 2007 ) .Word clustering for collocation - based word sense disambiguation .In P. Jin , X. Sun , Y.Wu & S.Yu ( Eds . ) , Lecture notes in computer science : Computational linguistics and intelligent text processing ( pp .", "label": "", "metadata": {}, "score": "65.36602"}
{"text": "Some systems now use the syntactic structures themselves as descriptors .In such systems , the syntax structure of a query will have to match the syntax structure of some expressions in a candidate ...Tools . \" ...This paper is a comparative study of feature selection methods in statistical learning of text categorization .", "label": "", "metadata": {}, "score": "65.39664"}
{"text": "Most existing Chinese word segmentation approaches are either statistics - based or dictionary - based .The pure statistical method has lower precision , while the pure dictionary - based method can not deal with new words beyond the dictionary .In this paper , we propose a hybrid method that is able to avoid the limitations of both types of approaches .", "label": "", "metadata": {}, "score": "65.45729"}
{"text": "Perotte A , Bartlett N , Elhadad N , Wood F : Hierarchically Supervised Latent Dirichlet Allocation .[ NIPS :2011 ] .Bisgin H , Liu Z , Fang H , Xu X , Tong W : Mining FDA drug labels using an unsupervised learning technique - topic modeling .", "label": "", "metadata": {}, "score": "65.46863"}
{"text": "The parameter n is the granularity of the method , and its choice determines how stringent the comparison is .In order to compare two notes A and B , we compute the number of fingerprints shared by A and B. The level of similarity of B to A is defined as the ratio ( number of shared fingerprints ) / ( number of fingerprints in A ) .", "label": "", "metadata": {}, "score": "65.51869"}
{"text": "The shapes of the distributions of concepts differ depending on the presence of redundancy in the corpus .The difference in shapes of distributions confirms in a qualitative fashion our hypothesis about the three corpora and their varying levels of redundancy .", "label": "", "metadata": {}, "score": "65.55245"}
{"text": "In this way the new query is strongly related to the original query , containing terms closely related to all of the original terms .This contrasts with query expansion through pseudo - relevance feedback , which is costly and can lead to query drift .", "label": "", "metadata": {}, "score": "65.60159"}
{"text": "However , for Chinese , we nd that the relationship between segmentation and retrieval performance is in fact nonmonotonic ; that is , at around 70 % word segmentation accuracy an over - segmentation phenomenon begins to occur which leads to a reduction in information retrieval performance .", "label": "", "metadata": {}, "score": "65.67389"}
{"text": "c ) printed or handwritten media .d ) transliterations .The system according to the invention may have any suitable physical form .The information may be stored using electronic storage means , e.g. in the form of databases , computer readable data carriers or other .", "label": "", "metadata": {}, "score": "65.706856"}
{"text": "In this work , we study only Spanish verb - noun collocations , and we were interested in lexical functions encountered in most frequent of them .We have found out that the list of 900 verb - noun collocations described above contains 36 lexical functions .", "label": "", "metadata": {}, "score": "65.72702"}
{"text": "This model is used in a parsing system by finding the parse for the sentence with the highest probability .This system outperforms previou ... \" .We describe a parsing system based upon a language model for English that is , in turn , based upon assigning probabilities to possible parses for a sentence .", "label": "", "metadata": {}, "score": "65.829704"}
{"text": "Table 6 presents the results of these techniques together with the results demonstrated by the statistical method called Na\u00efve Bayes ( Witten & Frank , 2005 ) .Na\u00efve Bayes is widely used in natural language processing and has proved itself to be one of the most effective methods for accomplishing linguistic tasks .", "label": "", "metadata": {}, "score": "65.84715"}
{"text": "We see that the significantly smaller Last Informative Note performs as well as All Informative Notes ( 8,557 notes vs. 1,247 ) while Reduced Redundancy Informative Notes ( 3,970 notes ) outperforms both .As we showed in Figure 4 a , we would expect a larger corpus to yield a better fit on the model : All Informative Notes is more than 7 times larger than Last Informative , still it yields the same fit on held out data .", "label": "", "metadata": {}, "score": "66.414185"}
{"text": "This is similar to the approach used by Arnold et al .( 2010 ) [ 28 ] and is accepted as a method for comparing LDA performance [ 54 ] .The topic models were learned using the Collapsed Gibbs Sampler provided in Mallet [ 55 ] with the recommended parameters and with hyper - parameter optimization as described in Wallach et al .", "label": "", "metadata": {}, "score": "66.472305"}
{"text": "My conclusion is that LMI is not needed for effective retrieval , but has other important roles within information - selection systems .Retrieval itself has various modes , including filtering or routing as well as one - off searching ; . by M. R. Girardi , B. Ibrahim - The Journal of Systems and Software , 1995 . \" ...", "label": "", "metadata": {}, "score": "66.5217"}
{"text": "It requires an efficient algorithm , since clustering is performed on - line .It also requires high precision , because users who are not domain experts are less tolerant to errors , and because the resulting hierarchy is fully automatically generated , as opposed to off - line clustering in which the hierarchy is often manually modified .", "label": "", "metadata": {}, "score": "66.57707"}
{"text": "These tasks are usually conducted separately in other systems .Finally , we do not assume the existence of a universal word segmentation standard which is application independent .Instead , we argue for the necessity of multiple segmentation standards due to the pragmatic fact that different NLP applications might require different granularities of Chinese words .", "label": "", "metadata": {}, "score": "66.63244"}
{"text": "The course books had been analysed and the lexical items chosen , so what was the next stage ?What did we want to do with the information ?The first step was to form lists of vocabulary for each unit .", "label": "", "metadata": {}, "score": "66.65699"}
{"text": "All Informative , input corpus , the corpus obtained by the redundancy reduction baseline ( Last Informative Note ) , and the corpora produced by the fingerprinting redundancy reduction strategy at different level .Computation time for constructing a redundancy - reduced corpus at a given similarity threshold using the selective fingerprinting is 6 minutes ( with an Intel Xeon CPU X5570 2.93 GHz ) .", "label": "", "metadata": {}, "score": "66.868866"}
{"text": "An alternative embodiment is illustrated below using the same data set as in Example 1 ( table 1 ) .The data is subjected to the same linguistic analysis as in the previous embodiment .Distances between countries were then calculated using Jaccard coefficients , i.e. for each pair of countries the fraction of the words used in the description of conditions for either country which were used in the description of the conditions in both companies were calculated .", "label": "", "metadata": {}, "score": "67.065765"}
{"text": "Holm L , Sander C : Removing near - neighbour redundancy from large protein sequence collections .Bioinformatics 1998 , 14 ( 5 ) : 423 .PubMed View Article .Bateman A , Birney E , Durbin R , Eddy SR , Howe KL , Sonnhammer ELL : The Pfam protein families database .", "label": "", "metadata": {}, "score": "67.13493"}
{"text": "Downey D , Etzioni O , Soderland S : Analysis of a probabilistic model of redundancy in unsupervised information extraction .Artif Intell 2010 , 174 ( 11 ) : 726 - 748 .View Article .Altschul SF , Madden TL , Sch\u00e4ffer AA , Zhang J , Zhang Z , Miller W , Lipman DJ : Gapped BLAST and PSI - BLAST : a new generation of protein database search programs .", "label": "", "metadata": {}, "score": "67.14689"}
{"text": "The information in notes can be found in the form of narrative and semi - structured format through lists or templates with free - text fields .As such , much research has been devoted to parsing and information extraction of clinical notes [ 1 - 3 ] with the goal of improving both health care and clinical research .", "label": "", "metadata": {}, "score": "67.22457"}
{"text": "The other consideration was the Common European Framework of Reference for Languages .The Framework , or CEF ( or CEFR , or CEFRL , depending on how the mood takes you on any given day ) , has a long and not particularly interesting story behind it .", "label": "", "metadata": {}, "score": "67.27396"}
{"text": "56 ] .The log - likelihood graphs were computed on withheld datasets .A non - redundant withheld dataset of 233 Informative notes was created for EHR corpus ( all the notes from the same patients were removed from the redundant corpora to prevent contamination between corpora and the withheld dataset ) .", "label": "", "metadata": {}, "score": "67.2893"}
{"text": "The CEF guidelines also suggest syllabus writers may wish to consider , ' what size ... range ... control of vocabulary the learner will need / be equipped / be required to control ' ( Council for Cultural Co - operation , Education Committee , Modern Languages Division ( 2001 : 150 ) ) .", "label": "", "metadata": {}, "score": "67.32295"}
{"text": "Hence , there was a need for a tool or system that can be used to analyse unstructured , subjective or personal text .It has now been found that the above may be achieved ( at least in part ) by a system for revealing information by subjecting textual data to : . a ) a module for entering textual data .", "label": "", "metadata": {}, "score": "67.36786"}
{"text": "We propose a strategy which concentrates on the rhetorical status of statements in the article : Material for summaries is selected in such a way that summaries can highlight the ... \" .this paper we argue that scientific articles require a different summarization strategy than , for instance , news articles .", "label": "", "metadata": {}, "score": "67.38791"}
{"text": "This paper describes a hybrid model that combines machine learning with linguistic heuristics for integrating unknown word identification with Chinese word segmentation .The model consists of two components : a position - of - character ( POC ) tagging component that annotates each character in a sentence with a POC tag that indicates its position in a word , and a merging component that transforms a POCtagged character sequence into a word - segmented sentence .", "label": "", "metadata": {}, "score": "67.39143"}
{"text": "Words in a piece of fiction writing are layered ; they are heavy in meaning .Differently than the spoken daily words that are superficial .It is so difficult for me to imagine that one day \" computers might someday read , comprehend , summarize , and even translate language as efficiently and accurately as the good old human brain does .", "label": "", "metadata": {}, "score": "67.404015"}
{"text": "However , word order and phrases are often critical to capturing the meaning of text in many text mining tasks .This paper presents topical n - grams , a topic model that discovers topics as well as topical phra ... \" .", "label": "", "metadata": {}, "score": "67.41434"}
{"text": "Atkins , B.T.S. & Zampolli , A. ( eds ) ( 1994 ) .Computational approaches to the lexicon .Oxford : Oxford University Press .Firth , J.R. ( 1951 ) .Modes of meaning ( Essays and Studies ) .", "label": "", "metadata": {}, "score": "67.43064"}
{"text": "For plagiarism detection , HaCohen - Kerner et al .[42 ] compare two fingerprinting methods : ( i ) Full fingerprinting - all substrings of length n of a string are used as fingerprints .This means that for a string of length m , m - n+1 fingerprints will be used ; and ( ii ) Selective Fingerprinting - non - overlapping substrings are chosen .", "label": "", "metadata": {}, "score": "67.56403"}
{"text": "Blei DM , Ng AY , Jordan MI : Latent dirichlet allocation .J Mach Learn Res 2003 , 3 : 993 - 1022 .Arnold CW , El - Saden SM , Bui AAT , Taira R : Clinical Case - based Retrieval Using Latent Topic Analysis .", "label": "", "metadata": {}, "score": "67.62669"}
{"text": "This paper presents a pragmatic approach to Chinese word segmentation .It differentiates from most of the previous approaches mainly in three respects .First of all , while theoretical linguists have defined Chinese words with various linguistic criteria , Chinese words in this study are defined pragm ... \" .", "label": "", "metadata": {}, "score": "67.70733"}
{"text": "c ) syndicate groups .d ) questionnaires ( free text ) .e ) computer mediated communication ( e.g. chat room conversations , email , computer conferencing ) .f ) telephone conversations .g ) video conferences .h ) audio and audiovisual broadcasts .", "label": "", "metadata": {}, "score": "67.71968"}
{"text": "There is a wide variation in the number of notes per patient , either because of their health status , or because some patients go to different health providers while others have all their visits in the same institution .Furthermore , clinicians typically copy and paste information from previous notes when documenting a current patient encounter .", "label": "", "metadata": {}, "score": "67.746925"}
{"text": "On the contrary , the results of rule - based methods are significantly higher than the baseline .Discussion : Testing the linguistic statement .The purpose of this work is to provide evidence for the linguistic statement made in Section 1.2 .", "label": "", "metadata": {}, "score": "67.75522"}
{"text": "The results from the correspondence analysis may alternatively be related to other measures such as temperature or altitude .If a series of reports were collected over time , time series modelling techniques may be used .Alternatively , given other relevant information , model building approaches to develop predictive models may be used , for example to be able to model visitor satisfaction or resort income with the resort as a function of the language used in the snow condition reports .", "label": "", "metadata": {}, "score": "67.79711"}
{"text": "The chosen lexical functions are shown in Table 4 , and the number of collocations for each lexical function is presented in Table 5 . keep silence maintain one 's balance .Func 0 .the noun occurs .el tiempo pasa la raz\u00f3n existe .", "label": "", "metadata": {}, "score": "67.89337"}
{"text": "Most natural language based document retrieval systems use the syntax structures of constituent phrases of documents as index terms .Many of these systems also attempt to reduce the syntactic variability of natural language by some normalisation procedure applied to these syntax structures .", "label": "", "metadata": {}, "score": "67.91019"}
{"text": "Most natural language based document retrieval systems use the syntax structures of constituent phrases of documents as index terms .Many of these systems also attempt to reduce the syntactic variability of natural language by some normalisation procedure applied to these syntax structures .", "label": "", "metadata": {}, "score": "67.91019"}
{"text": "What knowledge is necessary and sufficient for the computer to analyze and generate texts in natural language ?And what type of knowledge should it be ?Up to now , the two foremost approaches in natural language processing have been the statistical and the symbolic .", "label": "", "metadata": {}, "score": "67.98022"}
{"text": "Consequently , the themes are recycled ; the notion being that learning is further reinforced through repeated exposure .Furthermore , the series is academically oriented ; it supports the teaching of academic skills and language through the use of academic texts .", "label": "", "metadata": {}, "score": "68.18428"}
{"text": "First , while theoretical linguists have defined Chinese words using various linguistic criteria , Chinese words in this study are defined pragmatically as segmentation units whose definition depends on how they are used and processed in realistic computer applications .Second , we propose a pragmatic mathematical framework in which segmenting known words and detecting unknown words of different types ( i.e. , morphologically derived words , factoids , named entities , and other unlisted words ) can be performed simultaneously in a unified way .", "label": "", "metadata": {}, "score": "68.207565"}
{"text": "In L. Wanner ( Ed . ) , Lexical functions in lexicography and natural language processing ( pp .37 - 102 ) .Amsterdam , Philadelphia : Johm Benjamins .Porzig , W. ( 1934 ) .Wesenhafte Bedeutungsbeziehungen .Betr\u00e4ge zur Geschichte der deutsche Sprache und Literatur , 58 , 70 - 97 .", "label": "", "metadata": {}, "score": "68.22498"}
{"text": "Methods for identifying redundancy in large string - based databases exist in both bioinformatics and plagiarism detection [ 40 - 42 ] .A similar problem has been addressed in the creation of sequence databases for bioinformatics : Holm and Sander [ 43 ] advocated the creation of non - redundant protein sequence databases and suggested that databases limit the level of redundancy .", "label": "", "metadata": {}, "score": "68.38077"}
{"text": "A similar pattern is observed at the bi - gram level ( a Zipfian distribution for the non - redundant corpus and a non - Zipfian distribution for the redundant corpus ) .Impact of redundancy on text mining .We have observed that redundant corpora exhibit different statistical profiles than non - redundant ones , according to their word occurrence distributions .", "label": "", "metadata": {}, "score": "68.574875"}
{"text": "Automatic indexing is required to turn software retrieval systems cost - effective .Reuse ... . ... efore is simpler than what is usually required in NLP applications .One problem of indexing by noun phrases is that there are many different syntactic forms to express the same concept ( e.g. ' software retrieval ' and ' retrieval of software ' ) .", "label": "", "metadata": {}, "score": "68.57913"}
{"text": "Conclusions .Before applying text - mining techniques , one must pay careful attention to the structure of the analyzed corpora .While the importance of data cleaning has been known for low - level text characteristics ( e.g. , encoding and spelling ) , high - level and difficult - to - quantify corpus characteristics , such as naturally occurring redundancy , can also hurt text mining .", "label": "", "metadata": {}, "score": "68.63748"}
{"text": "It 's rather early days in our study of collocations ( the rest of the alphabet still lies waiting ) , and we expect that by the end of it we 'll have a more definite view of the rather skewed patterns of English that are represented in fiction .", "label": "", "metadata": {}, "score": "68.70379"}
{"text": "Along with the advent of EHR comes the ability to copy and paste from one note to another .While this functionality has definite benefits for clinicians , among them more efficient documentation , it has been noted that it might impact the quality of documentation as well as introduce errors in the documentation process [ 9 - 13 ] .", "label": "", "metadata": {}, "score": "68.74403"}
{"text": "View Article .Banko M , Brill E : Mitigating the paucity - of - data problem : Exploring the effect of training corpus size on classifier performance for natural language processing .Association for Computational Linguistics ; 2001:1 - 5 .", "label": "", "metadata": {}, "score": "68.74585"}
{"text": "Lexical semantics .( In Russian ) .Moscow : Vostochnaya Literatura RAN .[Links ] .Benson , M. , Benson , E. & Ilson , R. ( 1997 ) .The BBI Combinatory Dictionary of English : A Guide toWord Combinations .", "label": "", "metadata": {}, "score": "68.77697"}
{"text": "Two implications of noise are possible .The first is false positive identification , i.e. , extracting collocations which are the result of mere chance .The second implication is loss of significant collocations due to noise ( or because important collocations are out - ranked by less important ones ) .", "label": "", "metadata": {}, "score": "68.78451"}
{"text": "Advances in informatics 2005 , LNCS 3746 : 382 - 392 .View Article .Smith TF , Waterman MS , Fitch WM : Comparative biosequence metrics .J Mol Evol 1981 , 18 ( 1 ) : 38 - 46 .", "label": "", "metadata": {}, "score": "68.80937"}
{"text": "Finally , we do not assume the existence of a universal word segmentation standard that is application - independent .Instead , we argue for the necessity of multiple segmentation standards due to the pragmatic fact that different natural language processing applications might require different granularities of Chinese words .", "label": "", "metadata": {}, "score": "68.974525"}
{"text": "Detecting Drug Interactions From Adverse - Event Reports : Interaction Between Paroxetine and Pravastatin Increases Blood Glucose Levels .Clin Pharmacol Ther 2011 , 90 ( 1 ) : 133 - 142 .PubMed View Article .Wang X , Hripcsak G , Markatou M , Friedman C : Active Computerized Pharmacovigilance Using Natural Language Processing , Statistics , and Electronic Health Records : A Feasibility Study .", "label": "", "metadata": {}, "score": "69.04382"}
{"text": "2.4 Evaluation Performance of Chinese word segmenters is generally reported in terms of precision and recall .However , a comparison across systems cou ... . by Radu Florian , Grace Ngai - Conference on Natural Language Learning , 2001 . \" ...", "label": "", "metadata": {}, "score": "69.320175"}
{"text": "There are also examples of linguistic analysis tools that have some basic statistical analysis incorporated therein , and some statistical tools which have a minimum of linguistic analysis embedded in them .For the purpose of this invention , these will still be called linguistic tools , and statistical tools , respectively , i.e. independent of the presence of a bit of the other technique in them .", "label": "", "metadata": {}, "score": "69.39499"}
{"text": "It shows that collocations play a key role in understanding sentences .Collocations are recursive so collocational phrase may contain more than two words .Types of Collocations .Grammatical Collocations : Contain prepositions , including paired syntactic categories , such as verb+preposition ( e.g come to , put on ) , adjective+preposition ( e.g. afraid that , fond of ) , and noun+preposition ( e.g by accident , witness to ) .", "label": "", "metadata": {}, "score": "69.57648"}
{"text": "We artificially introduce redundancy by randomly sampling documents and repeating them until a controlled level of redundancy is achieved .Collocation identification .We expect that in a redundant corpus , the word sequences ( n - grams ) which are copied often will be over - represented .", "label": "", "metadata": {}, "score": "69.655464"}
{"text": "..y this involves segmenting the text into individual words . by Xiangji Huang , Fuchun Peng , Dale Schuurmans , Nick Cercone , Stephen Robertson , 2002 . \" ...We propose a self - supervised word segmentation technique for text segmentation in Chinese information retrieval .", "label": "", "metadata": {}, "score": "69.79154"}
{"text": "CausFunc 0 .CausFunc 1 .The next step in data preparation was to find out in what sense words were used in collocations .So every noun and every verb in the list was disambiguated manually with word senses of the Spanish WordNet ( Vossen , 1998 ) .", "label": "", "metadata": {}, "score": "69.8752"}
{"text": "The extraction of linguistic units or linguistic features is preferably done in such as way that it yields one or more of : .A1 letters .A2 morphemes .A3 words ( e.g. simple , compound ) , lemmas & word classes ( POS ) .", "label": "", "metadata": {}, "score": "70.05522"}
{"text": "This is expected based on the definition of PMI , and we confirm this prediction on WSJx2 and WSJx3 which produce exactly the same list of collocations as WSJ-1300 ( WSJx2 is a corpus constructed by doubling every document in WSJ-1300 ) .", "label": "", "metadata": {}, "score": "70.21384"}
{"text": "Complex lexical function description .create an entity or process escribir un libro dar vida . intensify a property or attribute aumentar el riesgo elevar el nivel . reduce a property or attribute disminuir la probabilidad reducir el consumo .begin to realize an action or begin to manifest an attribute iniciar la sesi\u00f3n adoptar una actitud .", "label": "", "metadata": {}, "score": "70.24814"}
{"text": "[ 39 ] suggested a model for unsupervised information extraction which takes redundancy into account when extracting information from the web .They showed that the popular information extraction method , Pointwise Mutual Information ( PMI ) , is less accurate by an order of magnitude compared to a method with redundancy handling .", "label": "", "metadata": {}, "score": "70.34622"}
{"text": "Firstly , semi - formal teacher feedback , in the form of feedback sheets , was obtained .Students were also asked for their feedback on the resources produced .Feedback was initially taken in the form of group interviews and samples were taken from students at all levels of proficiency .", "label": "", "metadata": {}, "score": "70.38202"}
{"text": "View Article .Zhou G , Zhao J , Liu K , Cai L : Exploiting web - derived selectional preference to improve statistical dependency parsing .Proceedings of ACL : 2011 , 2011 : 1556 - 1565 .Chen HB , Huang HH , Tan CT , Tjiu J , Chen HH : A statistical medical summary translation system .", "label": "", "metadata": {}, "score": "70.38501"}
{"text": "The redundant corpus , though 6.9 times larger , produces the same fit as the non - redundant corpus ( Last Informative Note ) .When applied to the synthetic WSJ corpora , we get a finer picture of the behavior of LDA under various corpora sizes and redundancy levels ( Figure 4 ) .", "label": "", "metadata": {}, "score": "70.49986"}
{"text": "Such statistical methods can be anything from simple counting to more advanced statistical techniques , e.g. dimension reduction , clustering , hypothesis testing , model fitting , correlation and others .Various such statistical techniques are described in : .Dimension reduction : Krzanowski W.J. & Marriot F.H.C. ( 1994 ) Multivariate Analysis - Edward Arnold .", "label": "", "metadata": {}, "score": "70.52157"}
{"text": "EHR corpora , however , exhibit specific characteristics when compared with corpora in the biomedical literature domain or the general English domain .This paper is concerned with the inherent characteristics of corpora composed of longitudinal records in particular and their impact on text - mining techniques .", "label": "", "metadata": {}, "score": "70.57586"}
{"text": "It seems simple and straightforward , but missing out any of these steps could leave you with a rubbish syllabus .Therefore , the question really was of how a vocabulary syllabus would fit into an already existing system .Furthermore , the considerations had been made for the course book series as a whole and not with regard to vocabulary specifically .", "label": "", "metadata": {}, "score": "70.58104"}
{"text": "My first task : Putting all of this into practice .When determining what lexical items the students would need , the approach taken was , admittedly , a conventional one .Bearing in mind the constraints mentioned above , a practicable target had to be envisioned .", "label": "", "metadata": {}, "score": "70.60009"}
{"text": "The All EHR corpus , which contains all notes of all types , fits between these two extremes , since we expect less redundancy across note types , even for a single patient .One standard way of characterizing large corpora is to plot the histogram of terms and their raw frequencies in the corpus .", "label": "", "metadata": {}, "score": "70.75573"}
{"text": "Brush as a transitive verb can accommodate a wide range of objects .The top five in terms of salience ( that is , roughly speaking , in terms of statistical significance ) are : teeth , hair , strand , lock , and lip .", "label": "", "metadata": {}, "score": "70.93331"}
{"text": "Endnotes .Declarations .Acknowledgements .This work was supported by a National Library of Medicine grant R01 LM010027 ( NE ) .Any opinions , findings , or conclusions are those of the authors , and do not necessarily reflect the views of the funding organization .", "label": "", "metadata": {}, "score": "70.959"}
{"text": "Metric for assessing redundancy at the patient level .Given two notes , we computed redundancy for the pair by aligning the two notes .We applied the Smith - Waterman text alignment algorithm , a commonly used string alignment algorithm in bioinformatics [ 52 ] .", "label": "", "metadata": {}, "score": "71.053024"}
{"text": "Documents are added one by one to the new corpus , a document sharing a proportion of fingerprints larger than the cutoff value with a document already in the corpus is not added .See Figure 6 for pseudo code of this algorithm .", "label": "", "metadata": {}, "score": "71.078026"}
{"text": "We expect that the lower the similarity threshold , the lower the actual redundancy level of the resulting corpus ( in other words , we verify that our fingerprinting redundancy reduction algorithm effectively reduces redundancy ) .Descriptive statistics of reduced corpora .", "label": "", "metadata": {}, "score": "71.11216"}
{"text": "Admission notes showed a redundancy of 30 % compared to the progress , discharge and sign - out notes of the same patient .More recently , Zhang et al .[ 15 ] experimented with different metrics to assess redundancy in outpatient notes .", "label": "", "metadata": {}, "score": "71.226234"}
{"text": "The level of overall redundancy is significant and spread over many documents ( over a third ) .Concept redundancy at the corpus level .Since free - text notes exhibit high level of variability in their language , the redundancy measures may be different when we examine terms normalized against a standard terminology .", "label": "", "metadata": {}, "score": "71.28995"}
{"text": "This article ... \" .This article presents methods for biasing statistical translation models to reflect these properties .Evaluation with respect to independent human judgments has confirmed that translation models biased in this fashion are significantly more accurate than a baseline knowledge - free model .", "label": "", "metadata": {}, "score": "71.35443"}
{"text": "France : Universit\u00e9 de Bretagne Sud .Mel'\u010duk , I. ( 1974 ) .Opyt teorii lingvisti\u010deskix modelej \" Smysl ?Tekst \" . 'A Theory of the Meaning - Text Type Linguistic Models ' .Moskva : Nauka .Mel'\u010duk , I. ( 1995 ) .", "label": "", "metadata": {}, "score": "71.43793"}
{"text": "Topic modeling .The algorithm for topic modeling that we analyze , LDA , is a complex inference process which captures patterns of word co - occurrences within documents .To investigate the behavior of LDA on corpora with varying levels of redundancy , we rely on two standard evaluation criteria : log - likelihood fit on withheld data and the number of topics required in order to obtain the best fit on the withheld data .", "label": "", "metadata": {}, "score": "71.44594"}
{"text": "As it was said earlier in this section , machine learning methods take advantage of various mathematical or statistical models .Basically , they are built on two types of models , in other words , two strategies or approaches .A lot of methods have been elaborated and implemented in WEKA .", "label": "", "metadata": {}, "score": "71.451904"}
{"text": "Table 1 .Verb - noun collocations and their meaning .Spanish collocation .English literal translation .Translation into natural English .Meaning of collocation .English translation .hacer uso dar un abrazo prestar atenci\u00f3n tener inter\u00e9s tomar la medida .", "label": "", "metadata": {}, "score": "71.526825"}
{"text": "The NSP package we use in our experiments is widely used for collocation and n - gram extraction in the clinical domain [ 19 - 22 ] .Collocations in a corpus of clinical notes are prime candidates to be mapped to meaningful phenotypes [ 19 - 21 ] .", "label": "", "metadata": {}, "score": "71.533936"}
{"text": "In Fig .2 we list all hyperonyms of hacer _ 15 and broma _ 1 .The words of the collocation , i.e. hacer _ 15 and broma _ 1 , are considered hyperonyms of themselves , or zerolevel hyperonyms , and are included in the hyperonym set .", "label": "", "metadata": {}, "score": "71.58328"}
{"text": "Translation into natural English .Meaning of collocation . create an entity or process .escribir un libro elaborar un plan construir la sociedad dar vida .write a book elaborate a plan construct a society give life .write a book develop a plan build a society give life . intensify a property or attribute .", "label": "", "metadata": {}, "score": "71.60605"}
{"text": "It can be noted that the collocational semantics in Table 2 are complex lexical functions .Table 3 presents the meanings from Table 2 through the instrumentality of the lexical function formalism .The meanings are accompanied by sample collocations taken from Table 2 as well .", "label": "", "metadata": {}, "score": "71.61859"}
{"text": "But the other main collocates of brush - hair , strand , lock , and lip - appear overwhelmingly in fiction - up to 150 times more frequently than in any other genre .The frequency of these collocations in fiction is so great that it completely skews the statistics for brush generally .", "label": "", "metadata": {}, "score": "71.62724"}
{"text": "Examples of subjective or unstructured text are literature , free - text questionnaire answers , interviews and loosely - directed monologues , focus - groups interactions , spontaneous communications , etc .The information which is to be revealed are not events or entities , but rather qualifiers , concepts , opinions , etc . as well as the characteristics of a specific linguistic expression .", "label": "", "metadata": {}, "score": "71.73093"}
{"text": "We can improve these results by using heuristic : pass through the candidate phrases through a part - of - speech filter which only allows those patterns that are likely to be phrases .Juteson and Katz have introduced a part - of - speech filter that uses the patterns adjective - noun , noun - noun , etc to decide which pattern should be allowed to let through .", "label": "", "metadata": {}, "score": "71.79097"}
{"text": "Evaluation on five test sets with different standards shows that the adaptive system achieves state - of - the - art performance on all the test sets . rules ( or transformations ) are acquired automatically from application data via the TBL method ( Gao et al .", "label": "", "metadata": {}, "score": "71.8012"}
{"text": "Evaluation on five test sets with different standards shows that the adaptive system achieves state - of - the - art performance on all the test sets . rules ( or transformations ) are acquired automatically from application data via the TBL method ( Gao et al .", "label": "", "metadata": {}, "score": "71.8012"}
{"text": "PubMed View Article .Pearson WR : [ 5 ] Rapid and sensitive sequence comparison with FASTP and FASTA .Academic Press ; 1990:63 - 98 .[Methods in Enzymology .vol .Volume 183 ] .HaCohen - Kerner Y , Tayeb A , Ben - Dror N : Detection of simple plagiarism in computer science papers .", "label": "", "metadata": {}, "score": "71.86868"}
{"text": "190 - 215 ) .Oxford : Oxford University Press .Bachman , L. F. ( 1990 ) .Fundamental considerations in language testing .Oxford : Oxford University Press .[Links ] .Flavell , J. H. & Flavell , E. R. ( 1959 ) .", "label": "", "metadata": {}, "score": "71.87634"}
{"text": "It can also identify new words through MI - based token merging and dictionary updating .In addition , with the proposed Improved Bigram method IASeg can process N - grams .To evaluate the Tools . byXuerui Wang , Andrew Mccallum , Xing Wei - In Proceedings of the 7th IEEE International Conference on Data Mining , 2007 . \" ...", "label": "", "metadata": {}, "score": "71.90785"}
{"text": "A limitation of statistical methods is the assumption that all features in data ( hyperonyms in our case ) are equally important in contributing to the decision of assigning a particular class to an example and also independent of one another .", "label": "", "metadata": {}, "score": "72.14769"}
{"text": "This system outperforms previous schemes .Introduction We present a statistical parser that induces its grammar and probabilities from a hand - parsed corpus ( a tree - bank ) .Parsers induced from corpora are of interest both as simply exercises in machine learning and also because they are often the best parsers obtainable by any method .", "label": "", "metadata": {}, "score": "72.278114"}
{"text": "Baldridge J , Morton T , Bierner G : The opennlp maximum entropy package .[ Technical report , SourceForge ] .Teufel S , Elhadad N : Collection and Linguistic Processing of a Large - scale Corpus of Medical Articles .", "label": "", "metadata": {}, "score": "72.413605"}
{"text": "A token is not a word , but every concrete usage of a word , number , or other symbol in text .For example , in the sentence ' I saw him but he did not see me ' there are nine tokens but eight words ( ' saw ' and ' see ' is the same word used in different tense forms ) .", "label": "", "metadata": {}, "score": "72.60523"}
{"text": "The motivation for constructing such a system stems from the ... \" .This paper presents a novel method that allows a machine learning algorithm following the transformation - based learning paradigm ( Brill , 1995 ) to be applied to multiple classication tasks by training jointly and simultaneously on all elds . by Fuchun Peng , Xiangji Huang , Dale Schuurmans , Nick Cercone - Retrieval Performance in Chinese IR , Coling2002 , 2002 . \" ...", "label": "", "metadata": {}, "score": "72.67029"}
{"text": "PubMed .Manning CD , Schutze H : Foundations of statistical natural language processing .MIT Press , Cambridge MA ; 1999:151 - 190 .Joshi M , Pakhomov S , Pedersen T , Chute CG : A comparative study of supervised learning as applied to acronym expansion in clinical reports .", "label": "", "metadata": {}, "score": "72.71704"}
{"text": "Approximation techniques to make this problem tractable were developed in bioinformatics to search sequence databases and for plagiarism detection .In both fields , fingerprinting schemes are applied .In BLAST , short substrings are used as fingerprints , whose length is defined by biological significance .", "label": "", "metadata": {}, "score": "72.7568"}
{"text": "Computational linguistics 2003 , 29 ( 3 ) : 333 - 347 .View Article .Atterer M , Sch tze H : The effect of corpus size in combining supervised and unsupervised training for disambiguation .Association for Computational Linguistics ; 2006:25 - 32 .", "label": "", "metadata": {}, "score": "72.76047"}
{"text": "This paper addresses the value of linguistically - motivated indexing ( LMI ) for document and text retrieval .After reviewing the basic concepts involved and the assumptions on which LMI is based , namely that complex index descriptions and terms are necessary , I consider past and recent research on LMI , and specifically on automated LMI via NLP .", "label": "", "metadata": {}, "score": "73.0815"}
{"text": "So , how on Earth was all of this done ?Graves ( 1996:13 ) and Brown ( 1995:20 ) offer comparable checklists of components to consider when designing a syllabus : .OK , so you skipped past the table because you though it was unimportant .", "label": "", "metadata": {}, "score": "73.121056"}
{"text": "Computer experiments .Outline of the experimental procedure .This section gives an overview of the experiments , and how the data analysis was accomplished .Basically , the experiments consist in asking the computer if a given collocation belongs to a particular lexical function or not For example , the computer has to decide if iniciar la sesi\u00f3n from Table 3 is IncepOper1 or not .", "label": "", "metadata": {}, "score": "73.15326"}
{"text": "Given a corpus , a histogram of term frequencies is computed to examine whether the corpus follows Zipf 's law .According to Zipf 's law , terms frequencies have a long tail in their distribution : that is , very few terms occur frequently ( typically function words and prominent domain words ) while most terms occur only once or twice in the corpus overall .", "label": "", "metadata": {}, "score": "73.25923"}
{"text": "Now we turn to considering the two approaches .Two approaches in machine learning : Word frequency count and rules .The first approach to finding patterns in data is to count how many times each feature , also called attribute , occur in examples of each class .", "label": "", "metadata": {}, "score": "73.29823"}
{"text": "Note that the WSJs5 corpus has roughly 2.5 times the size of WSJ-1300 .The process was repeated 10 times to eliminate bias from the choice of documents repeated .Synthetic corpora with various levels of redundancy , for WSJs5 we report averages and standard deviation based on 10 replications .", "label": "", "metadata": {}, "score": "73.39081"}
{"text": "many collocations are too specialised to bother teaching to moststudents ( e.g. , insolvency act ) .most collocations are too infrequent to bother teaching ( e.g. , rancid butter ; a glimmer of hope ) .individual words are often far more frequent than even a strong collocation , so keep things in perspective .", "label": "", "metadata": {}, "score": "73.43177"}
{"text": "Some systems therefore use a meaning representation language to index and retrieve documents .In this paper , a system is presented that uses Horn Clause Logic as meaning representation language , employs advanced techniques from Natural Language Processing to achieve incremental extensibility , and uses methods from Logic Programming to achieve robustness in the face of insufficient data . .", "label": "", "metadata": {}, "score": "73.56141"}
{"text": "The evaluation is done in terms of F - measure .The methodology is further explained in Section 2.3 , and the experimental results are given in Section 2.5 .Data .In this section , more explanation and details are given as to what data was used and how data sets for machine learning experiments were compiled .", "label": "", "metadata": {}, "score": "73.67484"}
{"text": "[ 30 ] applied LDA topic modeling to FDA drug side effects labels , their results demonstrated that the acquired topics properly clustered drugs by safety concerns and therapeutic uses .As observed for the field of collocation extraction , redundancy mitigation is not mentioned as standard practice in the case of topic modeling .", "label": "", "metadata": {}, "score": "73.72078"}
{"text": "We find that specialized topic areas give rise to phrases with very descriptive constituents which are then & quot;exported & quot ; into general vocabulary .These phrases are also much more informative as word pairs outside the topic area than within it .", "label": "", "metadata": {}, "score": "73.758865"}
{"text": "Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus ?( iii )How can one mitigate the impact of redundancy on text mining ?Before presenting results of our experiments and methods , we first review previous work in assessing redundancy in the EHR , two standard text - mining techniques of interest for data - driven disease modeling , and current work in how to mitigate presence of information redundancy .", "label": "", "metadata": {}, "score": "73.87398"}
{"text": "EHR corpora , however , exhibit specific statistical and linguistic characteristics when compared with corpora in the biomedical literature domain .We focus on copy - and - paste redundancy : clinicians typically copy and paste information from previous notes when documenting a current patient encounter .", "label": "", "metadata": {}, "score": "73.88072"}
{"text": "Figure 2 .Hyperonym set for hacer una broma .All 900 collocations are represented likewise and become input data for machine learning techniques .We believe that hyperonym sets have the power of distinguishing collocations belonging to different lexical functions .", "label": "", "metadata": {}, "score": "74.24742"}
{"text": "Table 6 specifies the names of rule - based methods in WEKA implementation ; presents their results as well as the number of examples for each lexical function in the training set .To compare our results with the baseline explained above in the previous paragraphs , the probability values of a random selection of the class ' yes ' are demonstrated in the same table .", "label": "", "metadata": {}, "score": "74.267654"}
{"text": "We focus on the All Informative Notes corpus .The metadata - based baseline produces the Last Informative Note corpus .The content - based mitigation strategy , which relies on fingerprinting , can produce corpora with varying levels of redundancy .", "label": "", "metadata": {}, "score": "74.31929"}
{"text": "However , word order and phrases are often critical to capturing the meaning of text in many text mining tasks .This paper presents topical n - grams , a topic model that discovers topics as well as topical phrases .The probabilistic model generates words in their textual order by , for each word , first sampling a topic , then sampling its status as a unigram or bigram , and then sampling the word from a topic - specific unigram or bigram distribution .", "label": "", "metadata": {}, "score": "74.513504"}
{"text": "This paper identifies a characteristic of EHR text corpora : their inherent high level of redundancy , caused by the process of cut and paste involved in the creation and editing of patient notes by health providers .We empirically measure this level of redundancy on a large patient note corpus , and verify that such redundancy introduces unwanted bias when applying standard text mining algorithms .", "label": "", "metadata": {}, "score": "74.56494"}
{"text": "[ Proceedings of the 2nd ACM SIGHIT symposium on International health informatics : 2012 ] .Zeng QT , Crowell J : Semantic classification of consumer health content .MEDNET Retrieved May 2008 , 2006 : 19 .Jiang Y : A computational semantics system for detecting drug reactions and patient outcomes in personal health messages .", "label": "", "metadata": {}, "score": "74.626785"}
{"text": "N N .Chief .Executive .A N .next . year .A N . real . estate .A N .Where A stands for adjective , N for noun and P for propositon .Note that the bigrams , last week and last year can not be regarded as non - compositional phrases .", "label": "", "metadata": {}, "score": "74.68039"}
{"text": "We investigate whether a redundant corpus exhibits a different distribution of concepts than a less redundant one .We expect that different subsets of the EHR corpus exhibit different levels of redundancy .The All Informative Notes corpus , which contains several notes per patient , but only the ones of types : \" primary - provider \" , \" clinical - note \" and \" follow - up - note \" , is assumed to be highly redundant , since it is homogeneous in style and clinical content .", "label": "", "metadata": {}, "score": "74.98518"}
{"text": "Joshi M , Pedersen T , Maclin R : A comparative study of support vector machines applied to the supervised word sense disambiguation problem in the medical domain .[ Proceedings of the 2nd Indian International Conference on Artificial Intelligence ( IICAI'05 ) : 2005 ] .", "label": "", "metadata": {}, "score": "75.04317"}
{"text": "Cormode G , Hadjieleftheriou M : Finding frequent items in data streams .Proceedings of the VLDB Endowment 2008 , 1 ( 2 ) : 1530 - 1541 .Copyright .\u00a9 Cohen et al . ; licensee BioMed Central Ltd. 2013 .", "label": "", "metadata": {}, "score": "75.084404"}
{"text": "There are two words in between in the third sentence .Moreover the words between cement and relations may vary and the distance between the two words also can vary .But there is a regularity in the patterns so that we can determine that cement is the right verb to use for this situation .", "label": "", "metadata": {}, "score": "75.33664"}
{"text": "For this reason , we use a sophisticated SVM - based initial tagger .A second initial tagger based on the hidden Markov model ( HMM ) is used for comparison .The second component is the space of transfo ... . by", "label": "", "metadata": {}, "score": "75.426254"}
{"text": "Unlike statistical methods based on probabilistic knowledge , rule - based methods acquire and use conceptual knowledge which is more human - readable and easy to understand .A concept in fact is a number of features that describe an abstract idea .", "label": "", "metadata": {}, "score": "75.47689"}
{"text": "This is the end of part one .In the second part I 'll be focusing on how the students themselves feel about all of this .Archives .", "label": "", "metadata": {}, "score": "75.55081"}
{"text": "Bodenreider O : The unified medical language system ( UMLS ) : integrating biomedical terminology .Nucleic Acids Res 2004 , 32 : D267 .PubMed View Article .Gildea D : Corpus variation and parser performance .Citeseer ; 2001:167 - 202 .", "label": "", "metadata": {}, "score": "75.58424"}
{"text": "Statistical machine learning methods use models built on probabilistic knowledge while rule - based methods take advantage of conceptual knowledge .Concepts are semantic units and rules are a means of identifying concepts .Therefore , a better performance of rule - based methods over statistical methods demonstrates that the semantic approach to collocation is more helpful in exploring the nature of such a linguistic phenomenon as collocations .", "label": "", "metadata": {}, "score": "75.58966"}
{"text": "Using IG thresholding with a knearest neighbor classifier on the Reuters corpus , removal of up to 98 % removal of unique terms actually yielded an improved classification accuracy ( measured by average precision ) .DF thresholding performed similarly .Indeed we found strong correlations between the DF , IG and CHI values of a term .", "label": "", "metadata": {}, "score": "75.62825"}
{"text": "Pfam [ 44 ] is a non - redundant protein sequence database manually built using representatives from each protein family .This database is used for construction of Hidden - Markov - Model classifiers widely used in Bioinformatics .When constructing a corpus of patient notes for statistical purposes , we encounter patients with many records .", "label": "", "metadata": {}, "score": "75.72113"}
{"text": "Our EHR corpus can be organized by patient identifier .We can , therefore , quantify the amount of redundancy within a patient record .On average , our corpus contains 14 notes per patient , with standard deviation of 16 , minimum of 1 and 167 maximum notes per patient .", "label": "", "metadata": {}, "score": "75.75487"}
{"text": "Basically , the CEF is a guideline which is being ever more frequently used to describe the achievements of learners of foreign languages across Europe .Its main aim is to provide a method of assessing and teaching that applies to all languages in Europe .", "label": "", "metadata": {}, "score": "75.819534"}
{"text": "And when he sees someone waving frantically he 'll think waving frantically instead of waving hard or something else that we would never say .Abstract .Background .The increasing availability of Electronic Health Record ( EHR ) data and specifically free - text patient notes presents opportunities for phenotype extraction .", "label": "", "metadata": {}, "score": "75.83801"}
{"text": "This lack of consistency explains the confusion and consequently low performance achieved by LDA on redundant corpora .Mitigation strategies for handling redundancy .Given a corpus with inherent redundancy , like the EHR corpus , the basic goal of redundancy mitigation is to choose the largest possible subset of the corpus with an upper bound on the amount of redundancy in that subset .", "label": "", "metadata": {}, "score": "75.85083"}
{"text": "900 verb - noun collocations were extracted from the Spanish Web Corpus automatically using the Sketch Engine , software for automatic text processing ( Kilgarriff , Rychly , Smrz & Tugwell , 2004 ) .The Spanish Web Corpus 2 contains 116 900 060 tokens 3 and is compiled of texts found in the Internet .", "label": "", "metadata": {}, "score": "75.86612"}
{"text": "[14 ] examined 1,670 patient notes of four types ( resident sign - out note , progress note , admission note and discharge note ) and assessed the amount of redundancy in these notes through time .Redundancy was defined through alignment of information in notes at the line level , using the Levenshtein edit distance .", "label": "", "metadata": {}, "score": "75.93089"}
{"text": "Berlin : Springer - Verlag .Kilgarriff , A. , Rychly , P. , Smrz , P. & Tugwell , D. ( 2004 ) .The Sketch Engine .In G. Williams & S. Vassier ( Eds . ) , Proceedings of EURALEX ( pp .", "label": "", "metadata": {}, "score": "75.95035"}
{"text": "However , text is indeed a sequence of discrete word tokens , and without considering the order of words ( in another word , the nearby context where a word is located ) , the accurate meani ... \" .Most of the popular topic models ( such as Latent Dirichlet Allocation ) have an underlying assumption : bag of words .", "label": "", "metadata": {}, "score": "75.999306"}
{"text": "In this first part I 'll be look at the process of defining aims and objectives , as well as the nitty gritty of the corpus analysis that was undertaken in order to create the syllabus .I 'd planned this to be my first post of 2011 , but have managed to put it off until now .", "label": "", "metadata": {}, "score": "76.01289"}
{"text": "Some words will collocate with both work and job ( e.g. you can find work or find a job ) but others do n't ( e.g. you can lose your job but you ca n't lose work ) .Travel and trip are even better - looking at the verbs which can take each one as an object , and the adjectives which go with each one , gives a clear picture of the differences .", "label": "", "metadata": {}, "score": "76.13066"}
{"text": "Figure 2 shows the distribution of UMLS concepts ( CUI ) frequencies in the three corpora with expected decreasing levels of redundancy : the All Informative Notes corpus , the All Notes corpus , and the Last Informative Note Corpus .We observe that the profile in the non - redundant Last Informative Note corpus differs markedly from the ones of the redundant corpora ( All Notes and All Informative Notes ) .", "label": "", "metadata": {}, "score": "76.13464"}
{"text": "A synset may be accompanied by a brief definition , or ' gloss ' .Below we give all senses for the word broma , joke , found in the Spanish WordNet ; each sense has its number , synset and gloss , words in synsets are written in the form ' word _ number of the sense ' : .", "label": "", "metadata": {}, "score": "76.4061"}
{"text": "Training and improvement of NLP tools for Medical - Informatics tasks on public available data will continue growing as more EHRs are incorporated into health care givers worldwide .The nature of epidemiological research demands looking at cohorts of patients , such as our kidney patient notes .", "label": "", "metadata": {}, "score": "76.783806"}
{"text": "To build a segmenter for a new language , the only resource required is a corpus of segmented text to train the compression model ... . byJianfeng Gao , Andi Wu , Grapecity Inc , Mu Li , Chang - ning Huang - Computational Linguistics , 2005 . \" ...", "label": "", "metadata": {}, "score": "76.80429"}
{"text": "Retrieve all hyperonyms of the noun .Retrieve all hyperonyms of the verb .Make a set of hyperonyms : .If a given collocation belongs to this lexical function . assign ' 1 ' to the set of hyperonyms , .", "label": "", "metadata": {}, "score": "76.870995"}
{"text": "These results can also be related to other sources of data .For example , the snow reports also contains measures of the depth of snow .If we take an average of these values for each country as a measure of the average depth of snow present in resorts in that country then we can relate this data to the output from the textual analysis .", "label": "", "metadata": {}, "score": "77.08072"}
{"text": "One of these was that the materials had to be ' motivating ' .This was a point picked up on by many of the interviewees .The example below shows one way in which this issue was addressed .Using pictures of famous Turkish celebrities meant that the vocabulary being presented became more meaningful , and the task more enjoyable .", "label": "", "metadata": {}, "score": "77.378296"}
{"text": "View Article .Kohane IS : Using electronic health records to drive discovery in disease genomics .Nat Rev Genet 2011 , 12 ( 6 ) : 417 - 428 .PubMed View Article .Tatonetti N , Denny J , Murphy S , Fernald G , Krishnan G , Castro V , Yue P , Tsau P , Kohane I , Roden D , et al .", "label": "", "metadata": {}, "score": "77.56942"}
{"text": "The topical n - gram model ... . by Karen Sparck Jones - In T. Strzalkowski , Natural language information retrieval , 1999 . \" ...This paper addresses the value of linguistically - motivated indexing ( LMI ) for document and text retrieval .", "label": "", "metadata": {}, "score": "77.83951"}
{"text": "How I developed an academic vocabulary syllabus ( part one ) .This is the first of two posts describing the initial and continuing development of an academic vocabulary syllabus .This post has been some five or six years in the making , give or take a few months here or there .", "label": "", "metadata": {}, "score": "77.91565"}
{"text": "Graphically , hyperonyms form a hierarchic structure called a tree where every hyperonym has its ancestor ( except for the hyperonym at the root of the tree ) and daughter(s ) ( except for hyperonyms at the leaves of the tree ) .", "label": "", "metadata": {}, "score": "78.09396"}
{"text": "State of the art articles ( as cited above ) and libraries ( such as the NSP package ) do not include any form of redundancy control or noise reduction .Redundancy mitigation is currently not a standard practice within the field of collocation extraction .", "label": "", "metadata": {}, "score": "78.12924"}
{"text": "Alonso Ramos , M. ( 2003 ) .Hacia un Diccionario de colocaciones del espa\u00f1ol y su codificaci\u00f3n .In M. A. Mart\u00ed ( Eds . ) , Lexicograf\u00eda computacional y sem\u00e1ntica ( pp .11 - 34 ) .Barcelona : Edicions de l'Universitat de Barcelona .", "label": "", "metadata": {}, "score": "78.14638"}
{"text": "In particular , we compared the results of the best rule - based methods for detecting lexical functions with the results Na\u00efve Bayes , one of the most efficient methods in natural language processing , on the same task .The average F - measure reached by Na\u00efve Bayes is 0.145 while the average F - measure of rule - based methods is 0.759 .", "label": "", "metadata": {}, "score": "78.176926"}
{"text": "We expect redundancy to be high across notes of the same patient and low across notes of distinct patients .Furthermore , within a single patient record , we expect heavy redundancy across notes from the same note types .We report redundancy on same patient / similar note type ( we focus on the most informative note types : primary provider , follow up and clinical notes ; in this analysis we ignore the template - based note types which are redundant by construction ) .", "label": "", "metadata": {}, "score": "78.268105"}
{"text": "For instance , the phrase \" hip rplc \" is a common phrase used to refer to the hip replacement procedure , which does not match any concept on its own in the UMLS .When gathering counts or co - occurrence patterns for association studies with the goal of high - level applications , like detection of adverse drug events or disease modeling , augmenting existing terminologies with such collocations can be beneficial .", "label": "", "metadata": {}, "score": "78.38817"}
{"text": "Table 8 provides descriptive statistics of the different WSJ - based corpora with which we experiment : .The WSJ-1300 corpus contains a random sample of 1,300 documents from the Wall Street Journal corpus , .The WSJ-400 corpus is a subset of WSJ-1300 of 400 documents , .", "label": "", "metadata": {}, "score": "78.614365"}
{"text": "EHR corpora .We collected a corpus of patient notes from the clinical data warehouse of the New York - Presbyterian Hospital .The study was approved by the Institutional Review Board ( IRB - AAAD9071 ) and follows HIPAA ( Health Insurance Portability and Accountability Act ) privacy guidelines .", "label": "", "metadata": {}, "score": "78.65384"}
{"text": "Model fit as function of number of topics on the WSJ corpora .In ( a ) we compare the effect of size on LDA , bigger corpora yield better fit .In ( b ) we examine the effect of redundancy : the doubled / trebled corpora reduce fit slightly while the noisier WSJs5 performs almost as badly as training on the smaller WSJ-600 corpus .", "label": "", "metadata": {}, "score": "78.756935"}
{"text": "WSJx2 , WSJx3 , and WSJs5 are all larger in size than WSJ-1300 .We therefore would expect them to reach higher log - likelihood , but this does not occur .Instead , their log - likelihood graphs keep increasing as the number of topics increases , all the while remaining consistently inferior to the WSJ-1300 corpus , from which they are derived .", "label": "", "metadata": {}, "score": "78.80804"}
{"text": "A pesar de estos problemas , las t\u00e9cnicas y los modelos computacionales pueden proporcionar la evidencia para que las teor\u00edas ling\u00fc\u00edsticas sean comprobadas o refutadas .Nuestros experimentos nos permiten verificar esa declaraci\u00f3n ling\u00fc\u00edstica .Asimismo , los experimentos sugieren que las consideraciones sem\u00e1nticas son m\u00e1s importantes en la definici\u00f3n de colocaciones que las estad\u00edsticas .", "label": "", "metadata": {}, "score": "78.85217"}
{"text": "An alternative route to text mining in the presence of high levels of redundancy consists of keeping all the existing redundant data , but designing redundancy immune statistical learning algorithms .This is a promising route of future research .Methods .", "label": "", "metadata": {}, "score": "79.00192"}
{"text": "We compare the performance of standard algorithms for collocation identification and topic modeling inference on a variety of corpora with different redundancy levels .We introduce synthetic corpora where we can control the level of redundancy .These synthetic corpora are derived from the Wall Street Journal ( WSJ ) standard corpus .", "label": "", "metadata": {}, "score": "79.06639"}
{"text": "A computational technique used for tasks similar to the one we have just described , is called machine learning .In fact , machine learning is a class of methods developed in the area of artificial intelligence .These methods are based on various mathematical or statistical models and applied to extract knowledge from data : find data patterns , build structural description of data items , classify these items .", "label": "", "metadata": {}, "score": "79.32967"}
{"text": "Links ] .Provost , J. ( 1999 ) Naive - Bayes vs. Rule - Learning in classification of email .Technical report AI - TR-99 - 284 .Austin , Texas : University of Texas at Austin .[Links ] .", "label": "", "metadata": {}, "score": "79.44145"}
{"text": "The WSJx2 corpus is constructed from WSJ-1300 to simulate redundancy , where each document of WSJ-1300 appears twice in the corpus .The WSJx3 corpus is similar to the WSJx2 corpus , except it contains three copies of each document in the WSJ-1300 corpus .", "label": "", "metadata": {}, "score": "79.56535"}
{"text": "The success of methods was evaluated with F - measure .For more details , see ( The University of Waikato , 2010a ) .Values of F - measure lie within the range from 0 to 1 . 'The training set submitted to WEKA techniques , or classifiers , is built according to the algorithm in Figure 1 .", "label": "", "metadata": {}, "score": "79.592575"}
{"text": "Banerjee S , Pedersen T : The design , implementation , and use of the ngram statistics package .[Computational Linguistics and Intelligent Text Processing ] .Wallach HM , Murray I , Salakhutdinov R , Mimno D : Evaluation methods for topic models .", "label": "", "metadata": {}, "score": "79.611145"}
{"text": "The input , Full EHR corpus , is the largest .As expected , the Last Informative Note corpus obtained through our metadata - based baseline is the smallest corpus .While redundancy is reduced , its size is also drastically decreased from the original corpus .", "label": "", "metadata": {}, "score": "79.61601"}
{"text": "PubMed View Article .Hirschtick R : A piece of my mind .Copy - and - paste .JAMA 2006 , 295 ( 20 ) : 2335 - 2336 .PubMed View Article .Yackel TR , Embi PJ : Copy - and - paste - and - paste .", "label": "", "metadata": {}, "score": "79.85303"}
{"text": "At the second stage , called testing , the computer tests the model constructed at the learning stage by using it for assigning classes to non - annotated examples ( called unseen examples ) in a data set called a test set .", "label": "", "metadata": {}, "score": "79.89168"}
{"text": "PubMed View Article .O'Donnell HC , Kaushal R , Barr\u00f3n Y , Callahan MA , Adelman RD , Siegler EL : Physicians ' Attitudes Towards Copy and Pasting in Electronic Note Writing .J Gen Intern Med 2009 , 24 ( 1 ) : 63 - 68 .", "label": "", "metadata": {}, "score": "79.89732"}
{"text": "PubMed View Article .Li W : Random texts exhibit Zipf's - law - like word frequency distribution .Information Theory , IEEE Transactions on 1992 , 38 ( 6 ) : 1842 - 1845 .View Article .Yoshimasa Tsuruoka YT , Jin - Dong K , Tomoko O , Sophia A , Jun'ichi T : Developing a Robust Part - of - Speech Tagger for Biomedical Text .", "label": "", "metadata": {}, "score": "80.01741"}
{"text": "Background .The Electronic Health Record ( EHR ) contains valuable information entered by clinicians .Besides its immediate clinical use at the point of care , the EHR , when treated as a repository of medical information across many patients , provides rich data waiting to be analyzed and mined for clinical discovery .", "label": "", "metadata": {}, "score": "80.09942"}
{"text": "c ) a module ( B ) for statistical analysis of the results of module ( A ) .Preferably the system of the invention is an electronic system for example a computer system .In this , the statistical analysis is understood not to relate just to simple counting and calculating averages and percentages .", "label": "", "metadata": {}, "score": "80.22627"}
{"text": "What do we mean by more abstract sense ?An abstract sense is not independent , it is not complete , but rather can be called a ' semantic particle ' whose function is not to express the full semantics , but to add semantic features to the base of collocation .", "label": "", "metadata": {}, "score": "80.24846"}
{"text": "The Last Informative Note corpus is a subset of All Informative Notes , and contains only the most recent note for each patient .Synthetic WSJ redundant corpora .We construct synthetic corpora with a controllable level of redundancy to compare the behavior of the text mining methods on various levels of redundancy .", "label": "", "metadata": {}, "score": "80.58945"}
{"text": "Berlin : Springer - Verlag .[Links ] .Hall , M. , Frank , E. , Holmes , G. , Pfahringer , B. , Reutemann , P. & Witten I. H. ( 2009 ) .The WEKA Data Mining Software : An Update .", "label": "", "metadata": {}, "score": "80.66263"}
{"text": "For the hair - related collocations , the evidence points to a different , irrefutable conclusion : fictional characters can not stop playing with their hair .Fictional heroines constantly brush theirs , often as a backdrop to pondering weighty questions or holding t\u00eate - \u00e0 - t\u00eates with their confidantes .", "label": "", "metadata": {}, "score": "80.69605"}
{"text": "Of course , such a system will contain some form of module to enter the textual data to be analysed .A system according to the invention may also comprise a module to present the output , but it may also be possible that the module that provides the statistical analysis provides the output itself .", "label": "", "metadata": {}, "score": "80.718376"}
{"text": "It differs from most previous approaches mainly in three respects .First , while theoretical linguists have defined Chinese words using various linguistic criteria , Chinese words in this study are defined pragmatically as segmen ... \" .This article presents a pragmatic approach to Chinese word segmentation .", "label": "", "metadata": {}, "score": "80.73764"}
{"text": "Generally speaking , the aim of my university 's ' preparatory program , and indeed such programs in general , is to equip students with the concepts and background knowledge they need to support their studies in faculties , in addition to developing their language and academic skills .", "label": "", "metadata": {}, "score": "80.776794"}
{"text": "Abstract As the amount of online Chinese contents grows , there is a critical need for effective Chinese word segmentation approaches to facilitate Web computing applications in a range of domains including terrorism informatics .Most existing Chinese word segmentation approaches are either statistic ... \" .", "label": "", "metadata": {}, "score": "80.94377"}
{"text": "Some are template based , such as radiology or lab reports , and others are less structured and contain mostly free text .We identified that note types : \" primary - provider \" , \" clinical - note \" and \" follow - up - note \" contain more information than other note types .", "label": "", "metadata": {}, "score": "81.01979"}
{"text": "Background : Who needs a vocabulary syllabus ?Before explaining how the vocabulary syllabus began , I guess I should give some background information on the series .The course books I use are content based and the units have a thematic approach ; each unit within the series is based on content areas and related themes in the areas of , for example , Psychology , History , Science , and Art .", "label": "", "metadata": {}, "score": "81.02849"}
{"text": "mantener el equilibrio guardar silencio seguir el modelo llevar una vida . maintain the balance keep silence follow a model carry a life .keep the balance keep quiet follow an example lead a life .Since these collocations share common semantics and structure , we may say that they are isomorphic , or that they are tied to one another by the relation we termed above as ' collocational isomorphism ' .", "label": "", "metadata": {}, "score": "81.18545"}
{"text": "All of the data we work with in the Lounge is proprietary but if we can engage the sympathies of its owners we will likely publish something .As for understanding the \" research process \" : it 's pretty straightforward and actually mind - numbing at times -- just looking at screens and screens of data and drawing conclusions about it .", "label": "", "metadata": {}, "score": "81.322395"}
{"text": "The next stage of the experimental procedure is to submit the data sets to machine learning techniques which construct models for making decisions .How the data is analyzed and how the model is build is specific to every machine learning method .", "label": "", "metadata": {}, "score": "81.33182"}
{"text": "Computer experiments play a very important role in science today .Simulations on computers have not only increased the demand for accuracy of scientific models , but have helped the researcher to study regions which can not be accessed in experiments or would demand very costly experiments .", "label": "", "metadata": {}, "score": "81.33397"}
{"text": "Authors ' Affiliations .Department of Computer Science , Ben - Gurion University in the Negev .Department of Biomedical Informatics , Columbia University .References .Friedman : A general natural - language text processor for clinical radiology .Jamia - Journal of the American Medical Informatics Association 1994 , 1 ( 2 ) : 161 .", "label": "", "metadata": {}, "score": "81.39608"}
{"text": "17 ] , the most popular sequence similarity algorithm in bioinformatics , is based on hashing of short sub - strings within the genetic sequence and then using the slower optimized dynamic programming alignment for sequences found to share enough sub - sequences .", "label": "", "metadata": {}, "score": "81.44382"}
{"text": "In a collocation , one word dominates over the other and determines its choice ( Hausmann , 1984 ) .The dominant word is called the ' base ' , and the other word whose choice is not free but depends on the base is called the ' collocate ' .", "label": "", "metadata": {}, "score": "81.50794"}
{"text": "Mach Learn 2010 , 79 ( 1 ) : 123 - 149 .View Article .Blitzer J , Dredze M , Pereira F : Biographies , bollywood , boom - boxes and blenders : Domain adaptation for sentiment classification .Moore RC , Lewis W : Intelligent selection of language model training data .", "label": "", "metadata": {}, "score": "81.89138"}
{"text": "PubMed View Article .Wrenn JO , Stein DM , Bakken S , Stetson PD : Quantifying clinical narrative redundancy in an electronic health record .J Am Med Inform Assoc 2010 , 17 ( 1 ) : 49 .PubMed View Article .", "label": "", "metadata": {}, "score": "82.044174"}
{"text": "Abstract : Linguistics as a scientific study of human language intends to describe and explain it .However , validity of a linguistic theory is difficult to prove due to volatile nature of language as a human convention and impossibility to cover all real - life linguistic data .", "label": "", "metadata": {}, "score": "82.640434"}
{"text": "Mutual Information .By the chain rule for entropy , .Therefore , . where H represents entropy and X and Y are random variables .This difference is called the mutual information between X and Y. It is the amount of information one random variable contains about another .", "label": "", "metadata": {}, "score": "82.78883"}
{"text": "We present a method for extracting parts of objects from wholes ( e.g. \" speedometer \" from \" car \" ) .Given a very large corpus our method finds part words with 55 % accuracy for the top 50 words as ranked by the system .", "label": "", "metadata": {}, "score": "82.96039"}
{"text": "We present a method for extracting parts of objects from wholes ( e.g. \" speedometer \" from \" car \" ) .Given a very large corpus our method finds part words with 55 % accuracy for the top 50 words as ranked by the system .", "label": "", "metadata": {}, "score": "82.96039"}
{"text": "Notes contain the following metadata : unique patient identifier , date , and note type ( e.g. , Primary - Provider ) .HealthTermFinder identifies named - entities mentions and maps them against semantic concepts in UMLS [49 ] .As such , it is possible to map lexical variants ( e.g. , \" myocardial infarction , \" \" myocardial infarct , \" \" MI , \" and \" heart attack \" ) of the same semantic concept to a UMLS CUI ( concept unique identifier ) .", "label": "", "metadata": {}, "score": "82.96854"}
{"text": "1 Introduction The assumption is often made in information retrieval ( IR ) and corpus - based linguistics that the documents of interest are part of a single , homogeneous and unstructured collection .If the text corpus is of small or moderate size , topically well - focused and generated by one author or a small group of authors sharing a common vocabulary , this can be a reasonable and useful simplification .", "label": "", "metadata": {}, "score": "82.98958"}
{"text": "Substantively , a Lexical Function is , roughly speaking , a special meaning ( or semanticosyntactic role ) such that its expression is not independent ( in contrast to all \" normal \" meanings ) , but depends on the lexical unit to which this meaning applies .", "label": "", "metadata": {}, "score": "83.072296"}
{"text": "This present invention relates to a lamp drive apparatus and a drive method for an LCD equipped portable electronics to maintain a user - selected level of brightness in accordance with surrounding temperature of the lamp .Accordingly , the battery power can be used more efficiently or effectively .", "label": "", "metadata": {}, "score": "83.30176"}
{"text": "Words are ranked by their significance in the topic ( i.e. , in the first topic the most important word is \" renal \" ) .The first topic includes words pertaining to renal disease , the second to hypertension and the third to symptoms and treatments related to the pulmonary system .", "label": "", "metadata": {}, "score": "83.42921"}
{"text": "PubMed View Article .Kho A , Pacheco J , Peissig P , Rasmussen L , Newton K , Weston N , Crane P , Pathak J , Chute C , Bielinski S : Electronic Medical Records for Genetic Research : Results of the eMERGE Consortium .", "label": "", "metadata": {}, "score": "83.565056"}
{"text": "Our technique uses modifications based on typical substitutions web searchers make to their queries .In this way the new query is strongly related to the original query , containi ... \" .We introduce the notion of query substitution , that is , generating a new query to replace a user 's original search query .", "label": "", "metadata": {}, "score": "83.66494"}
{"text": "Int J Med Inform 2002 , 67 ( 1/3 ) : 63 - 74 .PubMed View Article .Kullo IJ , Fan J , Pathak J , Savova GK , Ali Z , Chute CG : Leveraging informatics for genetic studies : use of the electronic medical record to enable a genome - wide association study of peripheral arterial disease .", "label": "", "metadata": {}, "score": "83.88967"}
{"text": "We have taken the liberty of arranging them in an impromptu narrative .The frequent ( in fiction ) collocations are in italics : .A powerfully built man knocked and entered the basement .It was Jayde 's new bodyguard !", "label": "", "metadata": {}, "score": "84.147934"}
{"text": "Mean and Variance .Collocations are not always of fixed phrases .Consider the following sentences .Obama cemented relations with the East .Jill cemented his relations with Jack .John cemented Mark Taylor 's relations with Tom .While cement and relations occur together frequently cement does not follow relations immediately always .", "label": "", "metadata": {}, "score": "84.28723"}
{"text": "For the purpose of evaluation , various methods and metrics are applied .In our experiments , we used the method called 10-fold cross - validation and the metrics called F - measure .We will not explain this method and metrics here since it is not our purpose to go into mathematical and computational details , but a more technical - oriented reader may wish to consult ( The University of Waikato , 2010a ) on these topics .", "label": "", "metadata": {}, "score": "84.371185"}
{"text": "Retrieval similarity measures provide good retrieval effectiveness by supporting semantic matching and processing of lexical relationships between terms .Some results from an experiment evaluating retrieval effectiveness are discussed .1 Introduction This paper describes ROSA ( Reuse Of Software Artifacts ) a software reuse system based on the processing of the natural language descriptions of software artifacts [ 9][10][11][12].", "label": "", "metadata": {}, "score": "84.41284"}
{"text": "It 's also used to refer to finishes in jewelry .Does art imitate life , or does n't it ?Art is for sure related to life , and it mirrors all different thoughts , ideas and actions of human existence .", "label": "", "metadata": {}, "score": "84.46004"}
{"text": "At the first stage , called learning , computer finds what features are associated with each class of examples in the data set where all examples are tagged with respective classes .Such a set is called a training set .The result of this step is a model built by the computer on the training data .", "label": "", "metadata": {}, "score": "84.61603"}
{"text": "We call notes of these 3 types \" Informative Notes \" .In our experiments , we rely on different variants of the EHR corpus ( see Table 7 ): .The All Notes corpus is our full EHR corpus , .", "label": "", "metadata": {}, "score": "84.68265"}
{"text": "claim 1 , wherein the first mode and the second mode for operating the lamp occur regardless of a time since initialization .The method of .claim 9 , wherein the first and second modes are performed more than two minutes from when an inverter for driving the lamp is enabled .", "label": "", "metadata": {}, "score": "84.918625"}
{"text": "Lexical , syntactic and semantic analysis of software descriptions is performed to automatically extract both verbal and nominal phrases from descriptions and use thi ... \" .This paper describes ROSA , a software reuse system based on the processing of the natural language descriptions of software artifacts .", "label": "", "metadata": {}, "score": "85.0005"}
{"text": "Why am i not a lexicographer ?Where do you order a book that lightly storytells about words ? yummy !Thomas S : \" brush with death \" is actually most common in journalism , but fiction holds the second - place spot .", "label": "", "metadata": {}, "score": "85.9901"}
{"text": "This healthy behavior strongly indicates that Reduced Redundancy Informative Notes indeed behaved as a non - redundant corpus with respect to the LDA algorithm .Model fit as function of number of topics .Patient notes corpora , including the \" Reduced Informative \" corpus .", "label": "", "metadata": {}, "score": "86.093765"}
{"text": "High redundancy and copy - and - paste operations in the notes create a biased sample of the \" patient note \" genre .From a practical perspective , redundant data in a corpus lead to waste of CPU time in corpus analysis and waste of I / O and storage space especially in long pipelines , where each stage of data processing yields an enriched set of the data .", "label": "", "metadata": {}, "score": "86.45984"}
{"text": "The Reduced Redundancy Informative Notes corpus contains 3,970 patient notes , 3.18 as many notes as the Last Informative Notes corpus while having same - patient redundancy of only 9.8 % compared to 29 % in the All Informative Notes Corpus .", "label": "", "metadata": {}, "score": "86.55654"}
{"text": "Therefore , this particular lexical item was extremely important for this one text , if not for the students ' overall vocabulary development .One example of how the data was analysed is detailed below .The headword in this example is access ( this sample contains the word forms to access ( verb ) , access ( noun ) and accessible ( adjective ) ) .", "label": "", "metadata": {}, "score": "86.68959"}
{"text": "Mitigation strategies for handling redundancy .Metadata - based baseline .The metadata - based mitigation strategy leverages the note creation date , the note type and the patient identifier information and selects the last available note per patient in the corpus .", "label": "", "metadata": {}, "score": "86.77502"}
{"text": "For example , consider the semantics of ' begin to realize an action or begin to manifest an attribute ' from Table 2 , which consists of two elements:'begin ' and ' realize / manifest ' .To represent such compound meanings , complex lexical functions are used , those being combinations of elementary lexical functions , termed ' simple lexical functions ' .", "label": "", "metadata": {}, "score": "86.9655"}
{"text": "Latent Dirichlet Allocation ( LDA ) , introduced by Blei et al .[ 27 ] , is an unsupervised generative probabilistic graphical model for topic modeling .Documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over words .", "label": "", "metadata": {}, "score": "87.00384"}
{"text": "Siegler EL , Adelman R : Copy and Paste : A Remediable Hazard of Electronic Health Records .Am J Med 2009 , 122 ( 6 ) : 495 - 496 .PubMed View Article .Markel A : Copy and Paste of Electronic Health Records : A Modern Medical Illness .", "label": "", "metadata": {}, "score": "87.1143"}
{"text": "In our experiments , the majority class is always ' no ' since the number of negative examples for each lexical function is much bigger than the number of its positive examples .The number of positive examples for the rest seven lexical functions is even less than for Oper1 as it is seen from Table 5 , so ZeroR has no sense as the baseline .", "label": "", "metadata": {}, "score": "87.18564"}
{"text": "Amsterdam : John Benjamins .Hausmann , F. J. ( 1984 ) .Wortschatzlernen ist Kollokationslernen .Zum Lehren und Lernen franz\u00f6sischer Wortverbindungen .Praxis des neusprachlichen Unterrichts , 31 , 395 - 406 .Hausser , R. ( 2001 ) .", "label": "", "metadata": {}, "score": "87.53374"}
{"text": "make use give a hug pay attention take interest take action .usar abrazar fijarse interesarse actuar .use hug pay attention be interested act .Table 2 .Verb - noun collocations grouped according to their common semantic pattern .Spanish collocation .", "label": "", "metadata": {}, "score": "88.655045"}
{"text": "FIELD OF THE INVENTION .The present invention relates to a system for analysing textual data .In particular , the analysis results in revealing information hidden in textual data .Such a system can be used in a method for developing consumer products , or for better targeting the marketing consumer products , when the textual data that is to be analysed is obtained from consumers .", "label": "", "metadata": {}, "score": "89.021866"}
{"text": "Hyperonyms were taken from the same dictionary , i.e. , the Spanish WordNet .The purpose was to represent the meaning of each verb- noun collocation by all hyperonyms of the verb and all hyperonyms of the noun .As an example , let us take hacer una broma , make a joke .", "label": "", "metadata": {}, "score": "89.17514"}
{"text": "Collocational windows are used to capture bigrams at a specific distance .Let us use a three word collocational window for the following sentence .Plane crashed as climate worsened .We get the following bigrams .Plane crashed plane as plane climate . crashed as crashed climate crashed worsened as climate as worsened . climate worsened .", "label": "", "metadata": {}, "score": "89.721985"}
{"text": "For machine learning experiments , we used WEKA version 3 - 6 - 2 , open - source machine learning software ( Hall , Frank , Holmes , Pfahringer , Reutemann & Witten , 2009 ; The University of Waikato , 2010b ) .", "label": "", "metadata": {}, "score": "89.82741"}
{"text": "claim 1 , wherein the first and third temperature ranges are equal , and wherein the second and fourth temperature ranges are equal .The method of .claim 1 , wherein the first mode is a brightness maintaining mode .The method of .", "label": "", "metadata": {}, "score": "90.11245"}
{"text": "McCallum AK : Mallet : A machine learning for language toolkit .Wallach H , Mimno D , McCallum A : Rethinking LDA : Why priors matter .Advances in Neural Information Processing Systems 2009 , 22 : 1973 - 1981 .", "label": "", "metadata": {}, "score": "90.14177"}
{"text": "The evaluative character of a word is called its semantic orientation .Positive semantic orientation indicates praise ( e.g. , \" honest \" , \" intrepid \" ) and negative semantic orientation indicates criticism ( e.g. , \" disturbing \" , \" superfluous \" ) .", "label": "", "metadata": {}, "score": "90.37149"}
{"text": "The evaluative character of a word is called its semantic orientation .Positive semantic orientation indicates praise ( e.g. , \" honest \" , \" intrepid \" ) and negative semantic orientation indicates criticism ( e.g. , \" disturbing \" , \" superfluous \" ) .", "label": "", "metadata": {}, "score": "90.37149"}
{"text": "Lips is the standalone and probably the easiest one to decipher : the frequency of \" brush lips \" in fiction may simply be a reflection of two things : . sex sells , and a modern novel without someone 's lips brushing up against someone else 's ( or up against someone else 's cheek , ear , shoulder , etc . ) is a dry novel indeed .", "label": "", "metadata": {}, "score": "90.8078"}
{"text": "[Links ] This present invention relates to a lamp drive apparatus and a drive method for an LCD equipped portable electronics to maintain a user - selected level of brightness in accordance with surrounding temperature of the lamp .Lamp drive apparatus and drive method of a notebook computer US 7042434 B2 .", "label": "", "metadata": {}, "score": "91.0621"}
{"text": "lower chances reduce consumption bring down the price restrict rights .begin to realize an action or begin to manifest an attribute . iniciar la sesi\u00f3n tomar la palabra asumir el papel adoptar una actitud . initiate a session take the word assume a role adopt the attitude . start a session take the floor assume a role take the attitude .", "label": "", "metadata": {}, "score": "91.12876"}
{"text": "Proc AMIA : 2011 , 2011 : 1612 - 1620 .Lin CY : Rouge :A package for automatic evaluation of summaries .[Text Summarization Branches Out : Proceedings of the ACL-04 Workshop : 2004 ] .Altschul SF , Gish W , Miller W , Myers EW , Lipman DJ : Basic local alignment search tool .", "label": "", "metadata": {}, "score": "91.51085"}
{"text": "Hypothesis testing : Altman D.G. ( 1991 ) Practical Statistics for Medical Research - Chapman & Hall .Model fitting : e.g. Draper N.R. & Smith H. Applied Regression Analysis - Wiley ( 1998 ) .Correlation : The Cambridge Dictionary of Statistics ( 1998 ) , Everitt B.S.-Cambridge University Press .", "label": "", "metadata": {}, "score": "91.60875"}
{"text": "claim 1 , wherein said one of the first and second modes is determined by a user action at the portable computer .The method of . claim 2 , wherein the first mode is a power saving mode , and wherein in the second temperature range the brightness changes .", "label": "", "metadata": {}, "score": "91.82212"}
{"text": "CausFunc 0 .the agent of the noun cause the noun to occur .establecer un sistema producir un efecto . establish a system produce an effect .CausFunc 1 . a participant different from the agent of the noun cause the noun to occur .", "label": "", "metadata": {}, "score": "92.12013"}
{"text": "A12 syntactic patterns , syntactic complexity .In the system according to the invention the statistical analysis is preferably achieved by subjecting the results of module ( A ) to one or more of : .Dimension reduction .Clustering .Hypothesis testing .", "label": "", "metadata": {}, "score": "92.96033"}
{"text": "M. H. Abrams wrote the seminal book , \" The Mirror and the Lamp , \" on these distinctions back in 1971 .I think Art can camouflage what 's real in life and it can also show the truth that life wants to hide .", "label": "", "metadata": {}, "score": "93.973"}
{"text": "The method of .claim 11 , wherein the first and second modes for operating the lamp occur during normal operations .The method of .claim 11 , wherein the first and second modes for operating the lamp occur after initialization .", "label": "", "metadata": {}, "score": "94.08177"}
{"text": "increase the risk lift the level develop a capacity improve a condition . increase the risk raise the level develop a capacity improve a condition . reduce a property or attribute . disminuir la probabilidad reducir el consumo bajar el precio limitar los derechosa .", "label": "", "metadata": {}, "score": "94.799774"}
{"text": "I blamed myself .I bit my lip .I drew a breath .Would he think that I was growing bold ? \" Just thought we might grab a bite , \" he blurted out .How about brushed nickel ?", "label": "", "metadata": {}, "score": "94.93156"}
{"text": "For example , .He is known for his fair and square dealings and everybody trusts his work .Here fair and square means honest but if we take the individual words though the word fair gives somewhat closer meaning as it means just the word square confuses us .", "label": "", "metadata": {}, "score": "95.21225"}
{"text": "I see what you mean about me misunderstanding F\u00e1bio 's point .But even in this sense , I do n't think teaching the collocations of job and work is a good use of time .Here are the main collocations of these two words ( as nouns ) : . work : social , hard , done , force , ethic , volunteer , dirty , detective job : done , doing , satisfaction , training , quit , full - time , creation , lose .", "label": "", "metadata": {}, "score": "95.79896"}
{"text": "The method of .claim 1 , wherein the first mode and the second mode for operating the lamp occur after initialization .The method of .claim 1 , wherein the first mode and the second mode for operating the lamp operate after lamp ignition .", "label": "", "metadata": {}, "score": "96.12472"}
{"text": "We 'll illustrate a few examples from the letter B , the spot in the alphabet where we were recently parked for a couple weeks .The verb brush , as its wordmap illustrates , is an extremely busy one in English .", "label": "", "metadata": {}, "score": "96.4655"}
{"text": "I think Fabio 's point is important and you 've slightly misunderstood it .Students often use \" work \" and \" job \" in the wrong situations and it is quite tricky to explain to them what the difference is .", "label": "", "metadata": {}, "score": "97.11386"}
{"text": "I really do n't know where my interest in language wants to take me .I 'm a sort of psychologist who works for an IT Company , and I find it quite a stimulating mix !Disclaimer for bad english : I 'm Italian !", "label": "", "metadata": {}, "score": "97.86172"}
{"text": "Had n't I bolted the door ? \"Just checking up on you , \" he said , blowing a cloud of smoke in my direction .I noticed a bruise on his bronzed skin .\" What 's the fruit basket for ?", "label": "", "metadata": {}, "score": "99.01825"}
{"text": "The last collocation , lips , is the sense that means \" touch gently \" : \" Armand lightly brushed her lips with his .\" Now , here 's the curious thing : were it not for their appearances in fiction , the only one of these collocations of brush that hits the billboards for English generally is teeth .", "label": "", "metadata": {}, "score": "99.18146"}
{"text": "For specific purposes , it may also be preferred to feed back the obtained output using the system according to the invention to the individuals who produced the original textual data .EXAMPLES .Example 1 .The description for Scotland was excluded from the analysis as both the presentation and information contained within the report were judged to be very different to those used for the other countries .", "label": "", "metadata": {}, "score": "99.71558"}
{"text": "The chosen profiler was that found at the University of Hong Kong 's webpage , due to its relative ease of use .There are now many more resources freely available on the Internet than there were back in 2004 , and I would probably use a more sophisticated tool ( the free and marvelous AntConc , for example ) were I undertaking such a project today .", "label": "", "metadata": {}, "score": "100.70139"}
{"text": "Of course it is not surprising that particular collocations should appear mainly in genre fiction - warp speed and cryogenically frozen , for example , immediately conjure science fiction , and collocations like lace bodice and fiery passion more or less define the romance genre .", "label": "", "metadata": {}, "score": "100.992004"}
{"text": "The verb be in its function as an auxiliary verb does not express any meaning except abstract grammatical categories of time , aspect , and person .Likewise , fall does not express an event , or a state , but to the word denoting an event or state ' adds ' the semantic feature ' begin to occur ' .", "label": "", "metadata": {}, "score": "101.71781"}
{"text": "A method of driving a lamp for an LCD of a portable computer , comprising : . setting a default brightness in the LCD that corresponds to a prescribed value stored in the portable computer ; . checking a surrounding temperature of the LCD ; . selecting one of a first mode and a second mode for operating the lamp , wherein operating the lamp is the first mode comprises , . receiving a user selected one of plurality of brightness control levels to set a first brightness and determining a corresponding first drive current as a drive current for the lamp , . maintaining the first brightness within a first temperature range while the drive current varies to reduce lamp power consumption , . determining a corresponding drive current at a minimum temperature of the first temperature range as a second drive current for a second temperature range that is below the first temperature range , and . maintaining the second drive current while the temperature of the lamp is within the second temperature range to reduce the lamp power consumption , and wherein the operating the lamp in the second mode comprises , . determining a third drive current that corresponds to the default brightness , . maintaining the third drive current within a third temperature range while the brightness changes , . determining a corresponding brightness level at a minimum temperature of the third temperature range to set a fourth brightness for a fourth temperature range that is below the third temperature range , and . maintaining the fourth brightness while the temperature of the lamp is within the fourth temperature range while the drive current changes .", "label": "", "metadata": {}, "score": "102.14638"}
{"text": "It 's possible that people are , in fact , always playing with their hair , and that it only ever gets written about in fiction .This conclusion is consistent with the \" art imitates life \" thesis , and is certainly supported by the fact that grooming of self and others is a basic mammalian behavior : have hair , will groom .", "label": "", "metadata": {}, "score": "103.63817"}
{"text": "There are cases in which a given lexical function represents one elementary meaning , as Oper , Func , Real , for which we have explained their meanings and listed examples .More functions representing elementary meanings have been discovered : Labor ( Lat . laborare , to work , toil ) , Incep ( Lat . incipere , to begin ) , Cont ( Lat . continuare , to continue ) , Fin ( Lat . finire , to cease ) , Caus ( Lat . causare , to cause ) , Perm ( Lat . permittere , to permit ) , Liqu ( Lat . liquidare , to liquidate ) , etc .", "label": "", "metadata": {}, "score": "103.7449"}
{"text": "The authors declare that they have no competing interests .Authors ' contributions .RC participated in the study design , carried out the statistical analyses and wrote the paper .ME participated in study design and wrote the paper .NE participated in study design and wrote the paper .", "label": "", "metadata": {}, "score": "103.91237"}
{"text": "For example France and Andorra are plotted close to each other on the correspondence analysis map suggesting that the conditions in both of these countries are similar .Similarly Germany and Canada are grouped together .The conditions in France and Andorra are characterised by words such as \" wet \" and \" slushy \" , whilist the conditions in America are characterised by words such as \" powder \" , \" excellent \" and \" great \" .", "label": "", "metadata": {}, "score": "104.32263"}
{"text": "This meaning of ' fall ' is more abstract as compared with its typical meaning given in ( WordNet , 2005 ) ' descend in free fall under the influence of gravity ' , e.g. , ' The branch fell from the tree ' .", "label": "", "metadata": {}, "score": "106.26143"}
{"text": "In its turn , hyperonym of ' flower is plant ' , and the hyperonym of ' plant ' is ' living thing ' , and hyperonym of ' living thing ' is ' entity ' .3 A notion of token is used mainly in computational linguistics .", "label": "", "metadata": {}, "score": "108.17389"}
{"text": "Sense 2 : broma _ 2 vacilada _ 1 burla _ 4 a ludicrous .or grotesque act done for fun and amusement .Sense 3 : broma _ 3 jocosidad _ 3 activity characterized by good humor .Sense 4 : broma _ 4 teredo _ 1 typical shipworm .", "label": "", "metadata": {}, "score": "108.266136"}
{"text": "Unless human essence becomes tangible and \" transplanted \" into computers .I have to say that I lovveeee visual thesaurus .It is a wonderful tool to explore the \" world of the words .\"The comment \" does n't art imitate life \" is as old as criticism ( Aristotle ? )", "label": "", "metadata": {}, "score": "109.00886"}
{"text": "Another example of a lexical function is Func0 , from Lat . functionare , function .realis , real , means ' to fulfill the requirement of the keyword ' , ' to do with the keyword what you are supposed to with it ' , or ' the keyword fulfils its requirement ' .", "label": "", "metadata": {}, "score": "110.97814"}
{"text": "Bristle with hatred \" turns out to be not all that frequent : top honors go to \" bristle with indignation / energy / confidence \" .Mary Lee M : \" brushed nickel \" is just frequent enough to make the charts and turns up mainly in \" lifestyle \" journalism .", "label": "", "metadata": {}, "score": "113.57747"}
{"text": "My email address is TEACHERFABIO@GMAIL.COM if you feel like keeping on with the discussion .i 'd love to .Differ away F\u00e1bio , but I do n't think I 've misunderstood this .In fact , the examples you give simply support my argument .", "label": "", "metadata": {}, "score": "113.952156"}
{"text": "However , we will exemplify collocational structures with Spanish data , listing some typical collocates of the noun alegr\u00eda , joy : . verb + noun : sentir alegr\u00eda , to feel joy adjective + noun : gran alegr\u00eda , great joy preposition + noun : con alegr\u00eda , with joy noun + preposition : la alegr\u00eda de ( esa muchacha ) , the joy of ( this girl ) .", "label": "", "metadata": {}, "score": "122.91498"}
