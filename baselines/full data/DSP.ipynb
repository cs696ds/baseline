{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfcGxa6AJKUH"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import shutil\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIWO9pEUMlwC"
      },
      "source": [
        "import warnings\n",
        "import logging\n",
        "warnings.filterwarnings('ignore')\n",
        "def setup():\n",
        "  # Authenticate and create the PyDrive client.\n",
        "  print(\"Step 1. Authenticating Google account user\")\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  #Authenticate access to Google drive\n",
        "  print(\"Step 2. Authenticating access to Google drive\")\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  os.chdir(\"/content/drive/My Drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOyC_TLcOaUa",
        "outputId": "223deb6e-1614-48ed-a36e-750fc3fefe72"
      },
      "source": [
        "print(\"Setting up\")\n",
        "setup()\n",
        "print(\"Setup done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting up\n",
            "Step 1. Authenticating Google account user\n",
            "Step 2. Authenticating access to Google drive\n",
            "Mounted at /content/drive\n",
            "Setup done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtyIwUqCObwI",
        "outputId": "91eef57d-d82d-44f6-b6e3-762e9b6c246d"
      },
      "source": [
        "!git clone \"https://github.com/allenai/dont-stop-pretraining.git\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dont-stop-pretraining'...\n",
            "remote: Enumerating objects: 439, done.\u001b[K\n",
            "remote: Total 439 (delta 0), reused 0 (delta 0), pack-reused 439\u001b[K\n",
            "Receiving objects: 100% (439/439), 566.01 KiB | 4.07 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to0IjUskOxWU",
        "outputId": "f48cedd0-e6cf-40a1-ea89-9737e232525c"
      },
      "source": [
        "cd dont-stop-pretraining/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dont-stop-pretraining\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0259oLCcShs5",
        "outputId": "69e7b223-e9d0-40d4-dc26-49eba6fe81be"
      },
      "source": [
        "!pip install git+https://github.com/kernelmachine/allennlp.git@4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/kernelmachine/allennlp.git@4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7\n",
            "  Cloning https://github.com/kernelmachine/allennlp.git (to revision 4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7) to /tmp/pip-req-build-xkvp0yhb\n",
            "  Running command git clone -q https://github.com/kernelmachine/allennlp.git /tmp/pip-req-build-xkvp0yhb\n",
            "  Running command git checkout -q 4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/1a/f2db026d4d682303793559f1c2bb425ba3ec0d6fd7ac63397790443f2461/jsonpickle-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (0.5.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (2.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (3.2.2)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Collecting conllu==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/06/e5c80e2e0f979628d47345efba51f7ba386fe95963b11c594209085f5a9b/ftfy-5.9.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[?25hCollecting spacy<2.2,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/f3/554271be8ff46471586d164bfbb6999364ba30ca5a0045e2a86da5f3b2c5/spacy-2.1.9-cp37-cp37m-manylinux1_x86_64.whl (30.8MB)\n",
            "\u001b[K     |████████████████████████████████| 30.8MB 170kB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (3.6.4)\n",
            "Collecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/43/0e/2f50064e327f41a1eb811df089f813036e19a64b95e33f8e9e0b96c2447e/flaky-3.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (4.41.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (2018.9)\n",
            "Collecting numpydoc>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1d/9e398c53d6ae27d5ab312ddc16a9ffe1bee0dfdf1d6ec88c40b0ca97582e/numpydoc-1.1.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/4f/62a3badb45bd88f6fbedcbb27273e379f11ecae86e69cd920e7c5ab51f84/boto3-1.17.36-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 71.2MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 64.5MB/s \n",
            "\u001b[?25hCollecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/b1/a1/162c90162e0f4539534b6ce6d723c4c07be8ad38c1cb975d7c63128502e0/responses-0.13.1-py2.py3-none-any.whl\n",
            "Collecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 54.5MB/s \n",
            "\u001b[?25hCollecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (1.1.2)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (1.8.0+cu101)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (2.23.0)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 59.2MB/s \n",
            "\u001b[?25hCollecting flask-cors>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 66.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (1.4.1)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (0.4.1)\n",
            "Collecting gevent>=1.3.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 61.6MB/s \n",
            "\u001b[?25hCollecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp===0.9.1-unreleased) (3.2.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonpickle->allennlp===0.9.1-unreleased) (3.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp===0.9.1-unreleased) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (0.10.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp===0.9.1-unreleased) (0.2.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (0.8.2)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/5f/47b7b29ad202b2210020e2f33bfb06d1db2abe0e709c2a84736e8a9d1bd5/blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 59.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (2.0.5)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/42/d7ea7539af3852fd8c1f0b3adf4a100fb3d72b40b69cef1a764ff979a743/thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 55.6MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (1.0.5)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/2b/3ecd5d90d2d6fd39fbc520de7d80db5d74defdc2d7c2e15531d9cc3498c7/preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (1.0.5)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp===0.9.1-unreleased) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp===0.9.1-unreleased) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp===0.9.1-unreleased) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp===0.9.1-unreleased) (8.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp===0.9.1-unreleased) (54.1.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp===0.9.1-unreleased) (20.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp===0.9.1-unreleased) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.11.3)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.8.5)\n",
            "Collecting botocore<1.21.0,>=1.20.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/19/72416dd9df0161e8494ed5dfc3f96ef1efcc1b91fc0b2dad43c555231e3c/botocore-1.20.36-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 44.0MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert>=0.6.0->allennlp===0.9.1-unreleased) (2019.12.20)\n",
            "Collecting urllib3>=1.25.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c6/d3e3abe5b4f4f16cf0dfc9240ab7ce10c2baa0e268989a4e3ec19e90c84e/urllib3-1.26.4-py2.py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 75.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 65.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->allennlp===0.9.1-unreleased) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (2020.12.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp===0.9.1-unreleased) (3.12.4)\n",
            "Collecting greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/25/f52f0dde4135833c2f85eae30a749d260231065b46942534df8366d7e1ec/greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl (160kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 63.5MB/s \n",
            "\u001b[?25hCollecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/57/8a68360d697cf9159cba5ee35f2d25bdcda33883e8b5a997714a191a0b11/zope.interface-5.3.0-cp37-cp37m-manylinux2010_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 59.4MB/s \n",
            "\u001b[?25hCollecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle->allennlp===0.9.1-unreleased) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.1.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.1.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.2.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.9.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (0.16)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (0.7.12)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (20.9)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.2.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.1.4)\n",
            "Building wheels for collected packages: allennlp\n",
            "  Building wheel for allennlp (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for allennlp: filename=allennlp-0.9.1_unreleased-cp37-none-any.whl size=7535391 sha256=50108a0b1ae7827bda2b4e46aff55488e37eb275c89c4a7ead1094809decf0c3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dgzl_j59/wheels/16/b3/9b/fceece1cbc3a6ac0c759db090cb239c3f4cba5bb369bb933c3\n",
            "Successfully built allennlp\n",
            "Building wheels for collected packages: word2number, ftfy, jsonnet, overrides, parsimonious\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp37-none-any.whl size=5589 sha256=42d8f13ca7bb889ed93277accd32f229408aaa1bef434642f090080eb7c894ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.9-cp37-none-any.whl size=46451 sha256=d41802a5586d7dfcb55abeff877537ddc4f296e1ade1b921934026ee8b79e507\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/2e/f0/b07196e8c929114998f0316894a61c752b63bfa3fdd50d2fc3\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388709 sha256=314cb39ca711763a0f9ba34bd48e8afaa004bc74e8b7df55edfe88eb6fce98c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=04878cc16c56455b6108791ea41a141dd5169750803786491df19f40af45ae09\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp37-none-any.whl size=42711 sha256=4b058a2b2b9690b41ea96eee48f265f557d4c2471f0302ee7feb404bf63ae1b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "Successfully built word2number ftfy jsonnet overrides parsimonious\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jsonpickle, word2number, conllu, ftfy, blis, preshed, plac, thinc, spacy, jsonnet, flaky, numpydoc, urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, responses, sentencepiece, pytorch-transformers, overrides, unidecode, flask-cors, tensorboardX, greenlet, zope.interface, zope.event, gevent, parsimonious, allennlp\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: preshed 3.0.5\n",
            "    Uninstalling preshed-3.0.5:\n",
            "      Successfully uninstalled preshed-3.0.5\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed allennlp-0.9.1-unreleased blis-0.2.4 boto3-1.17.36 botocore-1.20.36 conllu-1.3.1 flaky-3.7.0 flask-cors-3.0.10 ftfy-5.9 gevent-21.1.2 greenlet-1.0.0 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-2.0.0 numpydoc-1.1.0 overrides-3.1.0 parsimonious-0.8.1 plac-0.9.6 preshed-2.0.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.13.1 s3transfer-0.3.6 sentencepiece-0.1.95 spacy-2.1.9 tensorboardX-2.1 thinc-7.0.8 unidecode-1.2.0 urllib3-1.26.4 word2number-1.1 zope.event-4.5.0 zope.interface-5.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "htdavMMYTHVV",
        "outputId": "dd32b71a-6bce-41c8-c58d-7dfdb8093802"
      },
      "source": [
        "!pip install pytorch-transformers==1.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0) (1.8.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0) (0.1.95)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0) (1.17.36)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers==1.2.0) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.2.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.2.0) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 16.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: botocore<1.21.0,>=1.20.36 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers==1.2.0) (1.20.36)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers==1.2.0) (0.3.6)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers==1.2.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.36->boto3->pytorch-transformers==1.2.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=bcd4cd37730690b2cb5f407b0289d3bc26994004f5d44c33453c2a5fdea05666\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: allennlp 0.9.1-unreleased has requirement pytorch-transformers==1.1.0, but you'll have pytorch-transformers 1.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, pytorch-transformers, urllib3\n",
            "  Found existing installation: pytorch-transformers 1.1.0\n",
            "    Uninstalling pytorch-transformers-1.1.0:\n",
            "      Successfully uninstalled pytorch-transformers-1.1.0\n",
            "  Found existing installation: urllib3 1.26.4\n",
            "    Uninstalling urllib3-1.26.4:\n",
            "      Successfully uninstalled urllib3-1.26.4\n",
            "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.43 urllib3-1.25.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j98UAhQbWMs_",
        "outputId": "8b6c6010-1e91-4c5f-d98b-8526943e4dbb"
      },
      "source": [
        "!pip install transformers==2.4.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 6.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/cb/3e8902d528538972873d0e9e4e47a31d1849a98e057009e9d383637c96fb/tokenizers-0.0.11-cp37-cp37m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.4.1) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.4.1) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.4.1) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.4.1) (0.1.95)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.4.1) (1.17.36)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.4.1) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.4.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.4.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.4.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.4.1) (1.25.11)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.4.1) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.4.1) (0.3.6)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.36 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.4.1) (1.20.36)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.36->boto3->transformers==2.4.1) (2.8.1)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG5-QN7PWPUe",
        "outputId": "5668fff2-965b-4585-8344-5e0d5933bd06"
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.10.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "allennlp===0.9.1-unreleased\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "asgiref==3.3.1\n",
            "astor==0.8.1\n",
            "astropy==4.2\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.4.0\n",
            "attrs==20.3.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.2.4\n",
            "bokeh==2.1.1\n",
            "boto3==1.17.36\n",
            "botocore==1.20.36\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cachetools==4.2.1\n",
            "catalogue==1.0.0\n",
            "certifi==2020.12.5\n",
            "cffi==1.14.5\n",
            "chainer==7.4.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "conllu==1.3.1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.1\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda101==7.4.0\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.22\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.3\n",
            "distributed==1.25.3\n",
            "Django==3.1.7\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.5\n",
            "docopt==0.6.2\n",
            "docutils==0.16\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.255\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.5\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "flaky==3.7.0\n",
            "Flask==1.1.2\n",
            "Flask-Cors==3.0.10\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "ftfy==5.9\n",
            "future==0.16.0\n",
            "gast==0.3.3\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gevent==21.1.2\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.1\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.27.1\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.3\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.0.0\n",
            "grpcio==1.32.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==2.10.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.1\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.13.5\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "image==1.5.33\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==3.7.2\n",
            "importlib-resources==5.1.2\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "intel-openmp==2021.1.2\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.10\n",
            "jaxlib==0.1.62+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "jmespath==0.10.0\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonnet==0.17.0\n",
            "jsonpickle==2.0.0\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.10\n",
            "kapre==0.1.3.1\n",
            "Keras==2.4.3\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "knnimpute==0.1.0\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.0\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "lucid==0.3.8\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.7.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.11.1\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.2\n",
            "nest-asyncio==1.5.1\n",
            "networkx==2.5\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "np-utils==0.5.12.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "numpydoc==1.1.0\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "overrides==3.1.0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.9.7\n",
            "param==1.10.1\n",
            "parsimonious==0.8.1\n",
            "parso==0.8.1\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.0.0\n",
            "pip-tools==4.5.1\n",
            "plac==0.9.6\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.3.0\n",
            "portpicker==1.3.1\n",
            "prefetch-generator==1.0.1\n",
            "preshed==2.0.1\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.9.0\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.1.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==1.7.2\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "PyMeeus==0.5.9\n",
            "pymongo==3.11.3\n",
            "pymystem3==0.2.0\n",
            "pynndescent==0.5.2\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==4.0.1\n",
            "python-utils==2.5.6\n",
            "pytorch-pretrained-bert==0.6.2\n",
            "pytorch-transformers==1.2.0\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.0.1\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.0.3\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.0.3\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "responses==0.13.1\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.2\n",
            "rsa==4.7.2\n",
            "s3transfer==0.3.6\n",
            "sacremoses==0.0.43\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.2\n",
            "seaborn==0.11.1\n",
            "Send2Trash==1.5.0\n",
            "sentencepiece==0.1.95\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==4.2.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.3.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.1.9\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.4\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.3.23\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.4.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorboardX==2.1\n",
            "tensorflow==2.4.1\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.4.0\n",
            "tensorflow-gcs-config==2.4.0\n",
            "tensorflow-hub==0.11.0\n",
            "tensorflow-metadata==0.28.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.9.2\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "Theano==1.0.5\n",
            "thinc==7.0.8\n",
            "tifffile==2021.3.17\n",
            "tokenizers==0.0.11\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.0+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.0\n",
            "torchvision==0.9.0+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "transformers==2.4.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "umap-learn==0.5.1\n",
            "Unidecode==1.2.0\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.25.11\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "word2number==1.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.15.1\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n",
            "zope.event==4.5.0\n",
            "zope.interface==5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pj_B3eUzWX_1",
        "outputId": "f5430833-4c48-4df2-e209-5a7c0fcf4533"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/dont-stop-pretraining'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLkRNmeqTPae",
        "outputId": "0af2a8e0-ae8f-4042-a7d8-a863b3645da4"
      },
      "source": [
        "!python -m scripts.train \\\n",
        "        --config training_config/classifier.jsonnet \\\n",
        "        --serialization_dir model_logs/citation_intent_base \\\n",
        "        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n",
        "        --dataset citation_intent \\\n",
        "        --model roberta-base \\\n",
        "        --device 0 \\\n",
        "        --perf +f1 \\\n",
        "        --evaluate_on_test"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-25 14:36:14,293 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2021-03-25 14:36:14,749 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2021-03-25 14:36:14,752 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2021-03-25 14:36:15,150 - INFO - allennlp.common.params - random_seed = 842972\n",
            "2021-03-25 14:36:15,151 - INFO - allennlp.common.params - numpy_seed = 842972\n",
            "2021-03-25 14:36:15,151 - INFO - allennlp.common.params - pytorch_seed = 842972\n",
            "2021-03-25 14:36:15,177 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu101\n",
            "2021-03-25 14:36:15,181 - INFO - allennlp.common.params - evaluate_on_test = True\n",
            "2021-03-25 14:36:15,182 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n",
            "2021-03-25 14:36:15,182 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n",
            "2021-03-25 14:36:15,183 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n",
            "2021-03-25 14:36:15,183 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n",
            "2021-03-25 14:36:15,183 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n",
            "2021-03-25 14:36:15,183 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer'> from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n",
            "2021-03-25 14:36:15,184 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n",
            "2021-03-25 14:36:15,184 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n",
            "2021-03-25 14:36:15,184 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n",
            "2021-03-25 14:36:15,184 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n",
            "2021-03-25 14:36:15,510 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "2021-03-25 14:36:15,511 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "2021-03-25 14:36:15,670 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n",
            "2021-03-25 14:36:15,670 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n",
            "2021-03-25 14:36:15,671 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n",
            "2021-03-25 14:36:15,671 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n",
            "2021-03-25 14:36:15,671 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n",
            "2021-03-25 14:36:15,671 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n",
            "2021-03-25 14:36:15,671 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n",
            "2021-03-25 14:36:15,671 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n",
            "2021-03-25 14:36:15,971 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "2021-03-25 14:36:15,971 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "2021-03-25 14:36:16,050 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n",
            "2021-03-25 14:36:16,050 - INFO - allennlp.common.params - dataset_reader.sample = None\n",
            "2021-03-25 14:36:16,050 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n",
            "2021-03-25 14:36:16,051 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-03-25 14:36:16,051 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n",
            "2021-03-25 14:36:16,051 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n",
            "2021-03-25 14:36:16,051 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n",
            "2021-03-25 14:36:16,051 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n",
            "2021-03-25 14:36:16,052 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n",
            "2021-03-25 14:36:16,052 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n",
            "2021-03-25 14:36:16,052 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer'> from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n",
            "2021-03-25 14:36:16,052 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n",
            "2021-03-25 14:36:16,052 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n",
            "2021-03-25 14:36:16,052 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n",
            "2021-03-25 14:36:16,052 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n",
            "2021-03-25 14:36:16,342 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "2021-03-25 14:36:16,342 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "2021-03-25 14:36:16,416 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n",
            "2021-03-25 14:36:16,416 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n",
            "2021-03-25 14:36:16,416 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n",
            "2021-03-25 14:36:16,417 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n",
            "2021-03-25 14:36:16,417 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n",
            "2021-03-25 14:36:16,417 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n",
            "2021-03-25 14:36:16,417 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n",
            "2021-03-25 14:36:16,417 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n",
            "2021-03-25 14:36:16,788 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "2021-03-25 14:36:16,789 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "2021-03-25 14:36:16,861 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n",
            "2021-03-25 14:36:16,861 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n",
            "2021-03-25 14:36:16,861 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n",
            "2021-03-25 14:36:16,861 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n",
            "2021-03-25 14:36:16,862 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/train.jsonl\n",
            "2021-03-25 14:36:16,862 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/train.jsonl\n",
            "0it [00:00, ?it/s]2021-03-25 14:36:17,138 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/train.jsonl not found in cache, downloading to /tmp/tmpioml3udz\n",
            "\n",
            "  0%|          | 0/465895 [00:00<?, ?B/s]\u001b[A\n",
            " 11%|#1        | 52224/465895 [00:00<00:00, 443563.79B/s]\u001b[A\n",
            "100%|##########| 465895/465895 [00:00<00:00, 1934675.32B/s]\n",
            "2021-03-25 14:36:17,754 - INFO - allennlp.common.file_utils - copying /tmp/tmpioml3udz to cache at /root/.allennlp/cache/e63c8ea977152f5441f122048babaae85c0cfec5b476939d47c48007b693a46d.7ea13b1f554882ff49054868a00c2f567c01d9e088e553eae187bf27f5c033cf\n",
            "2021-03-25 14:36:17,755 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/e63c8ea977152f5441f122048babaae85c0cfec5b476939d47c48007b693a46d.7ea13b1f554882ff49054868a00c2f567c01d9e088e553eae187bf27f5c033cf\n",
            "2021-03-25 14:36:17,755 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpioml3udz\n",
            "1688it [00:01, 962.68it/s]\n",
            "2021-03-25 14:36:18,617 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/dev.jsonl\n",
            "2021-03-25 14:36:18,617 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/dev.jsonl\n",
            "0it [00:00, ?it/s]2021-03-25 14:36:18,882 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/dev.jsonl not found in cache, downloading to /tmp/tmpn0ccctvr\n",
            "\n",
            "100%|##########| 30138/30138 [00:00<00:00, 507059.62B/s]\n",
            "2021-03-25 14:36:19,223 - INFO - allennlp.common.file_utils - copying /tmp/tmpn0ccctvr to cache at /root/.allennlp/cache/569819492be704f7055bba5bd57667102ae010298fa7017f6f1f5827eddd1951.eb12b0ed0574347d6dd1adcfa52d200c30780569bea1ae08ccdda0711abd3bf6\n",
            "2021-03-25 14:36:19,224 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/569819492be704f7055bba5bd57667102ae010298fa7017f6f1f5827eddd1951.eb12b0ed0574347d6dd1adcfa52d200c30780569bea1ae08ccdda0711abd3bf6\n",
            "2021-03-25 14:36:19,224 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpn0ccctvr\n",
            "114it [00:00, 162.97it/s]\n",
            "2021-03-25 14:36:19,317 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/test.jsonl\n",
            "2021-03-25 14:36:19,318 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/test.jsonl\n",
            "0it [00:00, ?it/s]2021-03-25 14:36:19,585 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/test.jsonl not found in cache, downloading to /tmp/tmppq7ozocq\n",
            "\n",
            "100%|##########| 38637/38637 [00:00<00:00, 640104.77B/s]\n",
            "2021-03-25 14:36:19,938 - INFO - allennlp.common.file_utils - copying /tmp/tmppq7ozocq to cache at /root/.allennlp/cache/e40b8ad548dc5d5fc1f7e5173ea148954ca4b64794f7c0d7716b6dc541ccc63e.7a59da5c45951a1f2465d419a131bdb5578f02ae00fa3593cad3168caccf2390\n",
            "2021-03-25 14:36:19,938 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/e40b8ad548dc5d5fc1f7e5173ea148954ca4b64794f7c0d7716b6dc541ccc63e.7a59da5c45951a1f2465d419a131bdb5578f02ae00fa3593cad3168caccf2390\n",
            "2021-03-25 14:36:19,939 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmppq7ozocq\n",
            "139it [00:00, 196.97it/s]\n",
            "2021-03-25 14:36:20,038 - INFO - allennlp.training.trainer_pieces - From dataset instances, validation, train, test will be considered for vocabulary creation.\n",
            "2021-03-25 14:36:20,038 - INFO - allennlp.common.params - vocabulary.type = None\n",
            "2021-03-25 14:36:20,039 - INFO - allennlp.common.params - vocabulary.extend = False\n",
            "2021-03-25 14:36:20,039 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
            "2021-03-25 14:36:20,039 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
            "2021-03-25 14:36:20,039 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
            "2021-03-25 14:36:20,039 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
            "2021-03-25 14:36:20,039 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n",
            "2021-03-25 14:36:20,040 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n",
            "2021-03-25 14:36:20,040 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
            "2021-03-25 14:36:20,040 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
            "2021-03-25 14:36:20,040 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "1941it [00:00, 124389.13it/s]\n",
            "2021-03-25 14:36:20,057 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n",
            "2021-03-25 14:36:20,057 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n",
            "2021-03-25 14:36:20,057 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n",
            "2021-03-25 14:36:20,058 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n",
            "2021-03-25 14:36:20,058 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2021-03-25 14:36:20,058 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n",
            "2021-03-25 14:36:20,058 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n",
            "2021-03-25 14:36:20,059 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n",
            "2021-03-25 14:36:20,059 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n",
            "2021-03-25 14:36:20,059 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n",
            "2021-03-25 14:36:20,059 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n",
            "2021-03-25 14:36:20,059 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n",
            "2021-03-25 14:36:20,225 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "2021-03-25 14:36:20,226 - INFO - pytorch_transformers.modeling_utils - Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "2021-03-25 14:36:20,377 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "2021-03-25 14:36:24,382 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n",
            "2021-03-25 14:36:24,383 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n",
            "2021-03-25 14:36:24,383 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n",
            "2021-03-25 14:36:24,383 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n",
            "2021-03-25 14:36:24,384 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n",
            "2021-03-25 14:36:24,384 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n",
            "2021-03-25 14:36:24,384 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n",
            "2021-03-25 14:36:24,385 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n",
            "2021-03-25 14:36:24,385 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n",
            "2021-03-25 14:36:24,385 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n",
            "2021-03-25 14:36:24,390 - INFO - allennlp.common.params - model.dropout = 0.1\n",
            "2021-03-25 14:36:24,390 - INFO - allennlp.common.params - model.num_labels = None\n",
            "2021-03-25 14:36:24,390 - INFO - allennlp.common.params - model.label_namespace = labels\n",
            "2021-03-25 14:36:24,391 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-03-25 14:36:24,392 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-03-25 14:36:24,392 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n",
            "2021-03-25 14:36:24,392 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n",
            "2021-03-25 14:36:24,392 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n",
            "2021-03-25 14:36:24,393 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n",
            "2021-03-25 14:36:24,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n",
            "2021-03-25 14:36:24,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n",
            "2021-03-25 14:36:24,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n",
            "2021-03-25 14:36:24,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2021-03-25 14:36:24,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n",
            "2021-03-25 14:36:24,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2021-03-25 14:36:24,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2021-03-25 14:36:24,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2021-03-25 14:36:24,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2021-03-25 14:36:24,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2021-03-25 14:36:24,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2021-03-25 14:36:24,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2021-03-25 14:36:24,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2021-03-25 14:36:24,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2021-03-25 14:36:24,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2021-03-25 14:36:24,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2021-03-25 14:36:24,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2021-03-25 14:36:24,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2021-03-25 14:36:24,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2021-03-25 14:36:24,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2021-03-25 14:36:24,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2021-03-25 14:36:24,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2021-03-25 14:36:24,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2021-03-25 14:36:24,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2021-03-25 14:36:24,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2021-03-25 14:36:24,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2021-03-25 14:36:24,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2021-03-25 14:36:24,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2021-03-25 14:36:24,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2021-03-25 14:36:24,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2021-03-25 14:36:24,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2021-03-25 14:36:24,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2021-03-25 14:36:24,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2021-03-25 14:36:24,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2021-03-25 14:36:24,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2021-03-25 14:36:24,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2021-03-25 14:36:24,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2021-03-25 14:36:24,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2021-03-25 14:36:24,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2021-03-25 14:36:24,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2021-03-25 14:36:24,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2021-03-25 14:36:24,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2021-03-25 14:36:24,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2021-03-25 14:36:24,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2021-03-25 14:36:24,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2021-03-25 14:36:24,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2021-03-25 14:36:24,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2021-03-25 14:36:24,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2021-03-25 14:36:24,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2021-03-25 14:36:24,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2021-03-25 14:36:24,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2021-03-25 14:36:24,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2021-03-25 14:36:24,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2021-03-25 14:36:24,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2021-03-25 14:36:24,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2021-03-25 14:36:24,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2021-03-25 14:36:24,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2021-03-25 14:36:24,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2021-03-25 14:36:24,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2021-03-25 14:36:24,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2021-03-25 14:36:24,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2021-03-25 14:36:24,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2021-03-25 14:36:24,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2021-03-25 14:36:24,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2021-03-25 14:36:24,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2021-03-25 14:36:24,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2021-03-25 14:36:24,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2021-03-25 14:36:24,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2021-03-25 14:36:24,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2021-03-25 14:36:24,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2021-03-25 14:36:24,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2021-03-25 14:36:24,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2021-03-25 14:36:24,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2021-03-25 14:36:24,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2021-03-25 14:36:24,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2021-03-25 14:36:24,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2021-03-25 14:36:24,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n",
            "2021-03-25 14:36:24,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n",
            "2021-03-25 14:36:24,432 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n",
            "2021-03-25 14:36:24,432 - INFO - allennlp.common.params - iterator.type = bucket\n",
            "2021-03-25 14:36:24,432 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n",
            "2021-03-25 14:36:24,433 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n",
            "2021-03-25 14:36:24,433 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n",
            "2021-03-25 14:36:24,433 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n",
            "2021-03-25 14:36:24,433 - INFO - allennlp.common.params - iterator.batch_size = 8\n",
            "2021-03-25 14:36:24,433 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
            "2021-03-25 14:36:24,434 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
            "2021-03-25 14:36:24,434 - INFO - allennlp.common.params - iterator.cache_instances = False\n",
            "2021-03-25 14:36:24,434 - INFO - allennlp.common.params - iterator.track_epoch = False\n",
            "2021-03-25 14:36:24,434 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n",
            "2021-03-25 14:36:24,434 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n",
            "2021-03-25 14:36:24,435 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n",
            "2021-03-25 14:36:24,435 - INFO - allennlp.common.params - validation_iterator.type = bucket\n",
            "2021-03-25 14:36:24,435 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n",
            "2021-03-25 14:36:24,435 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n",
            "2021-03-25 14:36:24,435 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n",
            "2021-03-25 14:36:24,436 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n",
            "2021-03-25 14:36:24,436 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n",
            "2021-03-25 14:36:24,436 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n",
            "2021-03-25 14:36:24,436 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n",
            "2021-03-25 14:36:24,436 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n",
            "2021-03-25 14:36:24,437 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n",
            "2021-03-25 14:36:24,437 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n",
            "2021-03-25 14:36:24,437 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n",
            "2021-03-25 14:36:24,437 - INFO - allennlp.common.params - trainer.no_grad = ()\n",
            "2021-03-25 14:36:24,439 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n",
            "2021-03-25 14:36:24,439 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n",
            "2021-03-25 14:36:24,439 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n",
            "2021-03-25 14:36:24,439 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n",
            "2021-03-25 14:36:24,439 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2021-03-25 14:36:24,439 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n",
            "2021-03-25 14:36:24,439 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n",
            "2021-03-25 14:36:24,440 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2021-03-25 14:36:24,440 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2021-03-25 14:36:24,440 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2021-03-25 14:36:24,440 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2021-03-25 14:36:24,440 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2021-03-25 14:36:24,440 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2021-03-25 14:36:24,440 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,441 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,441 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,441 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,441 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,441 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,441 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2021-03-25 14:36:24,442 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2021-03-25 14:36:24,442 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,442 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,442 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2021-03-25 14:36:24,442 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2021-03-25 14:36:24,442 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2021-03-25 14:36:24,442 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2021-03-25 14:36:24,443 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2021-03-25 14:36:24,443 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2021-03-25 14:36:24,520 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,520 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,520 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,520 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,521 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,521 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,521 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2021-03-25 14:36:24,521 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2021-03-25 14:36:24,522 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,522 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,522 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2021-03-25 14:36:24,522 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2021-03-25 14:36:24,522 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2021-03-25 14:36:24,522 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2021-03-25 14:36:24,522 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2021-03-25 14:36:24,523 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2021-03-25 14:36:24,523 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,523 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,523 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,523 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,523 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,523 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,524 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2021-03-25 14:36:24,524 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2021-03-25 14:36:24,524 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,524 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,524 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2021-03-25 14:36:24,524 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2021-03-25 14:36:24,524 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2021-03-25 14:36:24,525 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2021-03-25 14:36:24,525 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2021-03-25 14:36:24,525 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2021-03-25 14:36:24,525 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,525 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,525 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,526 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,526 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,526 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,526 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2021-03-25 14:36:24,526 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2021-03-25 14:36:24,526 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,527 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,527 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2021-03-25 14:36:24,527 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2021-03-25 14:36:24,527 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2021-03-25 14:36:24,527 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2021-03-25 14:36:24,527 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2021-03-25 14:36:24,528 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2021-03-25 14:36:24,528 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,528 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,528 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,528 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,528 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,528 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,529 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2021-03-25 14:36:24,529 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2021-03-25 14:36:24,529 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,529 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,529 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2021-03-25 14:36:24,529 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2021-03-25 14:36:24,529 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2021-03-25 14:36:24,530 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2021-03-25 14:36:24,530 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2021-03-25 14:36:24,530 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2021-03-25 14:36:24,530 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,530 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,530 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,531 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,531 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,531 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,531 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2021-03-25 14:36:24,531 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2021-03-25 14:36:24,532 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,532 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,532 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2021-03-25 14:36:24,532 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2021-03-25 14:36:24,532 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2021-03-25 14:36:24,532 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2021-03-25 14:36:24,532 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2021-03-25 14:36:24,533 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2021-03-25 14:36:24,533 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,533 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,533 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,533 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,533 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,533 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,534 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2021-03-25 14:36:24,534 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2021-03-25 14:36:24,534 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,534 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,534 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2021-03-25 14:36:24,535 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2021-03-25 14:36:24,535 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2021-03-25 14:36:24,535 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2021-03-25 14:36:24,535 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2021-03-25 14:36:24,535 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2021-03-25 14:36:24,536 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,536 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,536 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,536 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,536 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,536 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,536 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2021-03-25 14:36:24,537 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2021-03-25 14:36:24,537 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,537 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,537 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2021-03-25 14:36:24,537 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2021-03-25 14:36:24,537 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2021-03-25 14:36:24,537 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2021-03-25 14:36:24,537 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2021-03-25 14:36:24,538 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2021-03-25 14:36:24,538 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,538 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,538 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,538 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,538 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,538 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2021-03-25 14:36:24,539 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2021-03-25 14:36:24,540 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,541 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,541 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2021-03-25 14:36:24,541 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2021-03-25 14:36:24,541 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2021-03-25 14:36:24,541 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2021-03-25 14:36:24,541 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2021-03-25 14:36:24,541 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2021-03-25 14:36:24,541 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,542 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,542 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,542 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,630 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,631 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,631 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2021-03-25 14:36:24,631 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2021-03-25 14:36:24,632 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,632 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,632 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2021-03-25 14:36:24,632 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2021-03-25 14:36:24,632 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2021-03-25 14:36:24,632 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2021-03-25 14:36:24,632 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2021-03-25 14:36:24,633 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2021-03-25 14:36:24,633 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2021-03-25 14:36:24,633 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2021-03-25 14:36:24,633 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,633 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,634 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2021-03-25 14:36:24,634 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2021-03-25 14:36:24,634 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2021-03-25 14:36:24,634 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2021-03-25 14:36:24,634 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2021-03-25 14:36:24,634 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2021-03-25 14:36:24,635 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n",
            "2021-03-25 14:36:24,635 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n",
            "2021-03-25 14:36:24,635 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n",
            "2021-03-25 14:36:24,635 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n",
            "2021-03-25 14:36:24,635 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n",
            "2021-03-25 14:36:24,635 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n",
            "2021-03-25 14:36:24,636 - INFO - allennlp.common.params - trainer.patience = 3\n",
            "2021-03-25 14:36:24,636 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n",
            "2021-03-25 14:36:24,636 - INFO - allennlp.common.params - trainer.shuffle = True\n",
            "2021-03-25 14:36:24,636 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
            "2021-03-25 14:36:24,636 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2021-03-25 14:36:24,636 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
            "2021-03-25 14:36:24,637 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2021-03-25 14:36:24,637 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
            "2021-03-25 14:36:24,637 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2021-03-25 14:36:24,637 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n",
            "2021-03-25 14:36:27,205 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n",
            "2021-03-25 14:36:27,205 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2021-03-25 14:36:27,205 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2021-03-25 14:36:27,206 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n",
            "2021-03-25 14:36:27,207 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
            "2021-03-25 14:36:27,207 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight'], {'weight_decay': 0}\n",
            "2021-03-25 14:36:27,241 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight'], {}\n",
            "2021-03-25 14:36:27,242 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n",
            "2021-03-25 14:36:27,243 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125240838\n",
            "2021-03-25 14:36:27,243 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n",
            "2021-03-25 14:36:27,243 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2021-03-25 14:36:27,244 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2021-03-25 14:36:27,244 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n",
            "2021-03-25 14:36:27,244 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n",
            "2021-03-25 14:36:27,244 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n",
            "2021-03-25 14:36:27,244 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n",
            "2021-03-25 14:36:27,244 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n",
            "2021-03-25 14:36:27,245 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n",
            "2021-03-25 14:36:27,245 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n",
            "2021-03-25 14:36:27,245 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n",
            "2021-03-25 14:36:27,245 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n",
            "2021-03-25 14:36:27,245 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n",
            "2021-03-25 14:36:27,246 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n",
            "2021-03-25 14:36:27,246 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n",
            "2021-03-25 14:36:27,246 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
            "2021-03-25 14:36:27,246 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
            "2021-03-25 14:36:27,247 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
            "2021-03-25 14:36:27,247 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n",
            "2021-03-25 14:36:27,247 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n",
            "2021-03-25 14:36:27,247 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n",
            "2021-03-25 14:36:27,259 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2021-03-25 14:36:27,259 - INFO - allennlp.training.trainer - Epoch 0/9\n",
            "2021-03-25 14:36:27,259 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3571.816\n",
            "2021-03-25 14:36:27,343 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1425\n",
            "2021-03-25 14:36:27,346 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/211 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "f1: 0.2014, accuracy: 0.5693, loss: 1.2705 ||: 100%|##########| 211/211 [00:31<00:00,  6.65it/s]\n",
            "2021-03-25 14:36:59,089 - INFO - allennlp.training.trainer - Validating\n",
            "f1: 0.2565, accuracy: 0.6404, loss: 0.9900 ||: 100%|##########| 2/2 [00:00<00:00,  5.34it/s]\n",
            "2021-03-25 14:36:59,466 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n",
            "2021-03-25 14:36:59,467 - INFO - allennlp.training.tensorboard_writer - f1              |     0.201  |     0.256\n",
            "2021-03-25 14:36:59,468 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  3571.816  |       N/A\n",
            "2021-03-25 14:36:59,469 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.569  |     0.640\n",
            "2021-03-25 14:36:59,469 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1425.000  |       N/A\n",
            "2021-03-25 14:36:59,470 - INFO - allennlp.training.tensorboard_writer - loss            |     1.270  |     0.990\n",
            "2021-03-25 14:37:05,227 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_base/best.th'.\n",
            "2021-03-25 14:37:07,215 - INFO - allennlp.training.trainer - Epoch duration: 0:00:39.955872\n",
            "2021-03-25 14:37:07,216 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:59\n",
            "2021-03-25 14:37:07,216 - INFO - allennlp.training.trainer - Epoch 1/9\n",
            "2021-03-25 14:37:07,216 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3590.036\n",
            "2021-03-25 14:37:07,299 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6843\n",
            "2021-03-25 14:37:07,302 - INFO - allennlp.training.trainer - Training\n",
            "f1: 0.3155, accuracy: 0.6777, loss: 1.0051 ||: 100%|##########| 211/211 [00:34<00:00,  6.09it/s]\n",
            "2021-03-25 14:37:41,942 - INFO - allennlp.training.trainer - Validating\n",
            "f1: 0.3254, accuracy: 0.6667, loss: 0.9390 ||: 100%|##########| 2/2 [00:00<00:00,  5.45it/s]\n",
            "2021-03-25 14:37:42,311 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n",
            "2021-03-25 14:37:42,312 - INFO - allennlp.training.tensorboard_writer - f1              |     0.316  |     0.325\n",
            "2021-03-25 14:37:42,313 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  3590.036  |       N/A\n",
            "2021-03-25 14:37:42,313 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.678  |     0.667\n",
            "2021-03-25 14:37:42,314 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  6843.000  |       N/A\n",
            "2021-03-25 14:37:42,314 - INFO - allennlp.training.tensorboard_writer - loss            |     1.005  |     0.939\n",
            "2021-03-25 14:37:48,126 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_base/best.th'.\n",
            "2021-03-25 14:37:54,767 - INFO - allennlp.training.trainer - Epoch duration: 0:00:47.550902\n",
            "2021-03-25 14:37:54,767 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:50\n",
            "2021-03-25 14:37:54,768 - INFO - allennlp.training.trainer - Epoch 2/9\n",
            "2021-03-25 14:37:54,768 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3590.096\n",
            "2021-03-25 14:37:54,849 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6843\n",
            "2021-03-25 14:37:54,851 - INFO - allennlp.training.trainer - Training\n",
            "f1: 0.5206, accuracy: 0.7559, loss: 0.7724 ||: 100%|##########| 211/211 [00:34<00:00,  6.15it/s]\n",
            "2021-03-25 14:38:29,170 - INFO - allennlp.training.trainer - Validating\n",
            "f1: 0.5524, accuracy: 0.7544, loss: 0.7303 ||: 100%|##########| 2/2 [00:00<00:00,  5.43it/s]\n",
            "2021-03-25 14:38:29,541 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n",
            "2021-03-25 14:38:29,542 - INFO - allennlp.training.tensorboard_writer - f1              |     0.521  |     0.552\n",
            "2021-03-25 14:38:29,543 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  3590.096  |       N/A\n",
            "2021-03-25 14:38:29,543 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.756  |     0.754\n",
            "2021-03-25 14:38:29,544 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  6843.000  |       N/A\n",
            "2021-03-25 14:38:29,545 - INFO - allennlp.training.tensorboard_writer - loss            |     0.772  |     0.730\n",
            "2021-03-25 14:38:35,220 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_base/best.th'.\n",
            "2021-03-25 14:38:37,368 - INFO - allennlp.training.trainer - Epoch duration: 0:00:42.600447\n",
            "2021-03-25 14:38:37,369 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:03\n",
            "2021-03-25 14:38:37,369 - INFO - allennlp.training.trainer - Epoch 3/9\n",
            "2021-03-25 14:38:37,369 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3590.1\n",
            "2021-03-25 14:38:37,452 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6843\n",
            "2021-03-25 14:38:37,454 - INFO - allennlp.training.trainer - Training\n",
            "f1: 0.6820, accuracy: 0.8389, loss: 0.5545 ||: 100%|##########| 211/211 [00:34<00:00,  6.14it/s]\n",
            "2021-03-25 14:39:11,848 - INFO - allennlp.training.trainer - Validating\n",
            "f1: 0.6394, accuracy: 0.7368, loss: 0.8040 ||: 100%|##########| 2/2 [00:00<00:00,  5.41it/s]\n",
            "2021-03-25 14:39:12,220 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n",
            "2021-03-25 14:39:12,220 - INFO - allennlp.training.tensorboard_writer - f1              |     0.682  |     0.639\n",
            "2021-03-25 14:39:12,221 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  3590.100  |       N/A\n",
            "2021-03-25 14:39:12,222 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.839  |     0.737\n",
            "2021-03-25 14:39:12,222 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  6843.000  |       N/A\n",
            "2021-03-25 14:39:12,223 - INFO - allennlp.training.tensorboard_writer - loss            |     0.555  |     0.804\n",
            "2021-03-25 14:39:18,418 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_base/best.th'.\n",
            "2021-03-25 14:39:22,863 - INFO - allennlp.training.trainer - Epoch duration: 0:00:45.494065\n",
            "2021-03-25 14:39:22,863 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:23\n",
            "2021-03-25 14:39:22,863 - INFO - allennlp.training.trainer - Epoch 4/9\n",
            "2021-03-25 14:39:22,864 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3590.104\n",
            "2021-03-25 14:39:22,943 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6843\n",
            "2021-03-25 14:39:22,946 - INFO - allennlp.training.trainer - Training\n",
            "f1: 0.7838, accuracy: 0.8880, loss: 0.3750 ||: 100%|##########| 211/211 [00:33<00:00,  6.23it/s]\n",
            "2021-03-25 14:39:56,819 - INFO - allennlp.training.trainer - Validating\n",
            "f1: 0.7516, accuracy: 0.7982, loss: 0.8171 ||: 100%|##########| 2/2 [00:00<00:00,  5.39it/s]\n",
            "2021-03-25 14:39:57,193 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n",
            "2021-03-25 14:39:57,193 - INFO - allennlp.training.tensorboard_writer - f1              |     0.784  |     0.752\n",
            "2021-03-25 14:39:57,194 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  3590.104  |       N/A\n",
            "2021-03-25 14:39:57,194 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.888  |     0.798\n",
            "2021-03-25 14:39:57,195 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  6843.000  |       N/A\n",
            "2021-03-25 14:39:57,196 - INFO - allennlp.training.tensorboard_writer - loss            |     0.375  |     0.817\n",
            "2021-03-25 14:40:02,959 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_base/best.th'.\n",
            "2021-03-25 14:40:06,525 - INFO - allennlp.training.trainer - Epoch duration: 0:00:43.661657\n",
            "2021-03-25 14:40:06,525 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:39\n",
            "2021-03-25 14:40:06,526 - INFO - allennlp.training.trainer - Epoch 5/9\n",
            "2021-03-25 14:40:06,526 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3590.108\n",
            "2021-03-25 14:40:06,633 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6843\n",
            "2021-03-25 14:40:06,636 - INFO - allennlp.training.trainer - Training\n",
            "f1: 0.8492, accuracy: 0.9248, loss: 0.2758 ||: 100%|##########| 211/211 [00:34<00:00,  6.13it/s]\n",
            "2021-03-25 14:40:41,034 - INFO - allennlp.training.trainer - Validating\n",
            "f1: 0.6750, accuracy: 0.7281, loss: 1.0419 ||: 100%|##########| 2/2 [00:00<00:00,  5.50it/s]\n",
            "2021-03-25 14:40:41,400 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n",
            "2021-03-25 14:40:41,401 - INFO - allennlp.training.tensorboard_writer - f1              |     0.849  |     0.675\n",
            "2021-03-25 14:40:41,402 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  3590.108  |       N/A\n",
            "2021-03-25 14:40:41,402 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.925  |     0.728\n",
            "2021-03-25 14:40:41,403 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  6843.000  |       N/A\n",
            "2021-03-25 14:40:41,404 - INFO - allennlp.training.tensorboard_writer - loss            |     0.276  |     1.042\n",
            "2021-03-25 14:40:47,363 - INFO - allennlp.training.trainer - Epoch duration: 0:00:40.837108\n",
            "2021-03-25 14:40:47,363 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:53\n",
            "2021-03-25 14:40:47,364 - INFO - allennlp.training.trainer - Epoch 6/9\n",
            "2021-03-25 14:40:47,364 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3590.12\n",
            "2021-03-25 14:40:48,017 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6843\n",
            "2021-03-25 14:40:48,019 - INFO - allennlp.training.trainer - Training\n",
            "f1: 0.8983, accuracy: 0.9425, loss: 0.2037 ||: 100%|##########| 211/211 [00:32<00:00,  6.51it/s]\n",
            "2021-03-25 14:41:20,441 - INFO - allennlp.training.trainer - Validating\n",
            "f1: 0.6635, accuracy: 0.7456, loss: 1.0462 ||: 100%|##########| 2/2 [00:00<00:00,  5.31it/s]\n",
            "2021-03-25 14:41:20,820 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n",
            "2021-03-25 14:41:20,821 - INFO - allennlp.training.tensorboard_writer - f1              |     0.898  |     0.663\n",
            "2021-03-25 14:41:20,822 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  3590.120  |       N/A\n",
            "2021-03-25 14:41:20,823 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.943  |     0.746\n",
            "2021-03-25 14:41:20,824 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  6843.000  |       N/A\n",
            "2021-03-25 14:41:20,824 - INFO - allennlp.training.tensorboard_writer - loss            |     0.204  |     1.046\n",
            "2021-03-25 14:41:26,879 - INFO - allennlp.training.trainer - Epoch duration: 0:00:39.515161\n",
            "2021-03-25 14:41:26,879 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:08\n",
            "2021-03-25 14:41:26,879 - INFO - allennlp.training.trainer - Epoch 7/9\n",
            "2021-03-25 14:41:26,880 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3590.12\n",
            "2021-03-25 14:41:26,978 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6843\n",
            "2021-03-25 14:41:26,981 - INFO - allennlp.training.trainer - Training\n",
            "f1: 0.9283, accuracy: 0.9556, loss: 0.1731 ||: 100%|##########| 211/211 [00:32<00:00,  6.54it/s]\n",
            "2021-03-25 14:41:59,266 - INFO - allennlp.training.trainer - Validating\n",
            "f1: 0.7067, accuracy: 0.7895, loss: 0.9290 ||: 100%|##########| 2/2 [00:00<00:00,  5.45it/s]\n",
            "2021-03-25 14:41:59,635 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n",
            "2021-03-25 14:41:59,639 - INFO - allennlp.training.checkpointer - loading best weights\n",
            "2021-03-25 14:42:00,347 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n",
            "2021-03-25 14:42:00,349 - INFO - allennlp.training.util - Iterating over dataset\n",
            "f1: 0.63, accuracy: 0.76, loss: 0.64 ||: 100%|##########| 3/3 [00:00<00:00,  7.85it/s]\n",
            "2021-03-25 14:42:00,736 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/citation_intent_base/model.tar.gz\n",
            "2021-03-25 14:42:30,507 - INFO - allennlp.common.util - Metrics: {\n",
            "  \"best_epoch\": 4,\n",
            "  \"peak_cpu_memory_MB\": 3590.12,\n",
            "  \"peak_gpu_0_memory_MB\": 6843,\n",
            "  \"training_duration\": \"0:04:53.565752\",\n",
            "  \"training_start_epoch\": 0,\n",
            "  \"training_epochs\": 6,\n",
            "  \"epoch\": 6,\n",
            "  \"training_f1\": 0.8982517123222351,\n",
            "  \"training_accuracy\": 0.9425355450236966,\n",
            "  \"training_loss\": 0.20368668444507637,\n",
            "  \"training_cpu_memory_MB\": 3590.12,\n",
            "  \"training_gpu_0_memory_MB\": 6843,\n",
            "  \"validation_f1\": 0.6634638160467148,\n",
            "  \"validation_accuracy\": 0.7456140350877193,\n",
            "  \"validation_loss\": 1.0462083965539932,\n",
            "  \"best_validation_f1\": 0.7516409258047739,\n",
            "  \"best_validation_accuracy\": 0.7982456140350878,\n",
            "  \"best_validation_loss\": 0.8170840442180634,\n",
            "  \"test_f1\": 0.6252323041359583,\n",
            "  \"test_accuracy\": 0.762589928057554,\n",
            "  \"test_loss\": 0.6405182331800461\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8RsBe2T3dK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}