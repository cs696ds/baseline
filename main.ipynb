{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/heeh/Projects/da'"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filtering I (BM25 Retrieval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688\n",
      "Number of retrieved documents: 10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import requests\n",
    "################################################################################\n",
    "# Filtering\n",
    "################################################################################\n",
    "pretty = lambda x : json.dumps(x, indent=2, sort_keys=True)\n",
    "solr_select = 'http://localhost:8983/solr/depcc/select?q='\n",
    "train_path  = 'data/02-acl-arc/train.jsonl'\n",
    "with open(train_path, 'r') as train_file:\n",
    "    json_lines = []\n",
    "    lines = train_file.readlines()\n",
    "    for line in lines:\n",
    "        j = json.loads(line)\n",
    "        json_lines.append(j)\n",
    "N = len(json_lines)\n",
    "print(N)\n",
    "j = json_lines[0]\n",
    "query = j['text'].replace(' ', '+')\n",
    "rp_retrieval = requests.get(solr_select + query).json()\n",
    "cc_docs = (rp_retrieval['response']['docs'])\n",
    "print('Number of retrieved documents: %d' % len(cc_docs))\n",
    "cc_doc0 = json.loads(cc_docs[0]['_src_'])\n",
    "#print(cc_doc0)\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Segmentation (Documents -> Passages)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://technokoopa.deviantart.com/art/Dragoon-class-Destroyer-448332152\n",
      "s3://aws-publicdatasets/common-crawl/crawl-data/CC-MAIN-2016-07/segments/1454701156520.89/warc/CC-MAIN-20160205193916-00243-ip-10-236-182-209.ec2.internal.warc.gz\n",
      "Number of passages in document 0: 54 \n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Segmentation\n",
    "################################################################################\n",
    "val_url = cc_doc0['url']\n",
    "print(val_url)\n",
    "val_s3 = cc_doc0['s3']\n",
    "print(val_s3)\n",
    "cc_words = cc_doc0['text'].split()\n",
    "cc_psgs = []\n",
    "num_psgs = len(cc_words) // 100\n",
    "print('Number of passages in document 0: %d ' % num_psgs)\n",
    "for i in range(num_psgs):\n",
    "    start = i * 100\n",
    "    end   = -1 if (i == num_psgs-1) else (i+1) * 100\n",
    "    psg = ' '.join(cc_words[start:end])\n",
    "    dict = {'doc_id' : val_url, 'doc_text'  : psg,  'title': ''  }\n",
    "    cc_psgs.append(dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "127"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# Encoding\n",
    "################################################################################\n",
    "\n",
    "import csv\n",
    "import subprocess\n",
    "\n",
    "# Encode CC\n",
    "# f_out = 'emb/cc_sample.tsv'\n",
    "# with open(f_out, 'w') as output_file:\n",
    "#     dw = csv.DictWriter(output_file, cc_psgs[0].keys(), delimiter='\\t')\n",
    "#     for psg in cc_psgs:\n",
    "#         dw.writerow(psg)\n",
    "# subprocess.call(['sh', 'emb/generate_embedding.sh ' + 'cc_sample'])\n",
    "\n",
    "# Encode train set\n",
    "num_train = len(json_lines)\n",
    "train_psgs = []\n",
    "for i in range(num_train):\n",
    "    train_dict = {'doc_id': str(i), 'doc_text': json_lines[i]['text'], 'title': ''}\n",
    "    train_psgs.append(train_dict)\n",
    "#print(train_psgs[0])\n",
    "\n",
    "f_train_out = 'emb/train_sample.tsv'\n",
    "with open(f_train_out, 'w') as output_file:\n",
    "    dw = csv.DictWriter(output_file, train_psgs[0].keys(), delimiter='\\t')\n",
    "    for tp in train_psgs:\n",
    "        dw.writerow(tp)\n",
    "subprocess.call(['sh', 'emb/generate_embedding.sh ' + 'train_sample'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nearest Neighbors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "54 768\n",
      "Number of CC passages: 54\n",
      "(768,)\n",
      "10 768\n",
      "Number of train passages: 10\n",
      "[[-8.7804133e-01  5.2036103e-02 -6.7804471e-02 ... -5.1974082e-01\n",
      "  -2.2222115e-01 -2.3715140e-02]\n",
      " [-7.5261265e-01 -1.5401670e-01  3.3758375e-01 ... -7.0269495e-01\n",
      "  -6.7983367e-02  2.2842372e-03]\n",
      " [-4.3047079e-01  7.1437828e-02 -3.3563085e-02 ... -5.2040094e-01\n",
      "  -7.8418620e-02  1.7523374e-01]\n",
      " ...\n",
      " [-1.9698891e-01  2.3213519e-01  3.3778602e-01 ... -4.7779170e-01\n",
      "  -1.2492716e-04 -3.6839178e-01]\n",
      " [-3.2815686e-01  2.1539052e-01  2.5606854e-02 ... -3.9178729e-01\n",
      "  -1.1939787e-01  2.3145039e-01]\n",
      " [-3.6438248e-01  4.4869799e-03  4.0559188e-01 ... -4.8237056e-01\n",
      "  -5.3450578e-01 -1.0792198e-01]]\n",
      "trained? True\n",
      "Total number of indexed CC passages:  54\n",
      "\n",
      "Using an indentical CC set\n",
      "4 nearest neighbors\n",
      "[[ 0 13  4 24]\n",
      " [ 1  2 13 40]\n",
      " [ 2  1 40 18]\n",
      " [ 3 40 31 18]\n",
      " [ 4  0 40 13]]\n",
      "\n",
      "distances(sanity check)\n",
      "[[ 0.       36.441696 37.077488 41.76454 ]\n",
      " [ 0.       36.791702 39.25956  39.92917 ]\n",
      " [ 0.       36.791702 39.89359  39.978657]\n",
      " [ 0.       28.037733 43.363792 44.88707 ]\n",
      " [ 0.       37.077488 43.40751  49.89235 ]]\n",
      "\n",
      "Using the query(train set)\n",
      "4 nearest neighbors\n",
      "[[50 51 45 42]\n",
      " [18 52 34 53]\n",
      " [45 28 53 32]\n",
      " [ 9 30 28 21]\n",
      " [ 7 51 30 34]]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Nearest Neighbor (FAISS)\n",
    "################################################################################\n",
    "#print(emb[0])\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Read CC embeddings (DATABASE)\n",
    "cc_embeddings = np.load('emb/cc_sample_0.pkl', allow_pickle=True)\n",
    "print(cc_embeddings[0][1].shape)  # Dimension of the embedding\n",
    "nb = len(cc_embeddings) # database size\n",
    "d = cc_embeddings[0][1].size\n",
    "print(nb,d)\n",
    "xb = np.zeros((nb,d), dtype='float32')\n",
    "for i in range(nb):\n",
    "    xb[i] = cc_embeddings[i][1]\n",
    "print('Number of CC passages: %d' % nb)\n",
    "\n",
    "# Read train embeddings (QUERY)\n",
    "train_embeddings = np.load('emb/train_sample_0.pkl', allow_pickle=True)\n",
    "print(train_embeddings[0][1].shape)  # Dimension of the embedding\n",
    "nq = len(train_embeddings[:10]) # database size\n",
    "d = train_embeddings[0][1].size\n",
    "print(nq,d)\n",
    "xq = np.zeros((nq,d), dtype='float32')\n",
    "for i in range(nq):\n",
    "    xq[i] = train_embeddings[i][1]\n",
    "\n",
    "print('Number of train passages: %d' % nq)\n",
    "print(xq)\n",
    "\n",
    "\n",
    "index = faiss.IndexFlatL2(d)   # build the index\n",
    "\n",
    "print('trained? %r' % index.is_trained)\n",
    "index.add(xb)                  # add vectors to the index\n",
    "print('Total number of indexed CC passages: ', index.ntotal)\n",
    "print()\n",
    "print('Using an indentical CC set')\n",
    "k = 4                          # we want to see 4 nearest neighbors\n",
    "D, I = index.search(xb[:5], k) # sanity check\n",
    "print('4 nearest neighbors')\n",
    "print(I)\n",
    "print()\n",
    "\n",
    "print('distances(sanity check)')\n",
    "print(D)\n",
    "print()\n",
    "print('Using the query(train set)')\n",
    "D, I = index.search(xq, k)     # actual search\n",
    "print('4 nearest neighbors')\n",
    "print(I[:5])                   # neighbors of the 5 first queries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}