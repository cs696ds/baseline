{"text": "A chart parser is disclosed which incorporates rule and observation probabilities with stochastic unification grammars .The parser operates frame synchronously to provide top - down hypotheses and to incorporate observation probabilities as they become available .A chart parser is disclosed which incorporates rule and observation probabilities with stochastic unification grammars .The parser operates frame synchronously to provide top - down hypotheses and to incorporate observation probabilities as they become available .Because the language model produces multiple explanations of the speech data between frames , the prediction and combination of rules may create cycles in a graph representing the best scores .", "label": "", "metadata": {}}
{"text": "The algorithm creates no more states than a nonprobilistic chart parser , and remains linear for regular grammars and cubic in the worst case for CFGs .The parser allows a direct integration of statistical speech information and linguistic constraints within the same language model , while the language model permits a generalization of HMM - type models .The efficiency of the parser makes it applicable to multiple levels of a spoken language system ( e.g. , sentence , word , phoneme , and phone levels ) .( n ) parsing terminal symbols from the current grammar level as start symbols for the next lower grammar level unless at the lowest grammar level ; .", "label": "", "metadata": {}}
{"text": "( p ) scanning observations from said next lower grammar level into waiting states of said current grammar level ; .( q ) repeating steps ( j ) through ( p ) until no new states can be completed ; .( r ) reporting complete states corresponding to start symbols of said current level to the next higher grammar level ; .( s ) parsing said start symbols according to the spoken input and grammars to produce observations of said symbols ; and .( t ) explaining the input based on the results of said step of parsing .", "label": "", "metadata": {}}
{"text": "( u ) between steps ( d ) and ( e ) reading an ending frame indicator ; and .The method of claim 3 , wherein said probability score for said completed state is the probability for completing states in the state set using already complete states in the state sets .The method of claim 3 , wherein said score is calculated by summing the ending probability of the active state with the difference between the ending and initial probabilities of the complete state , wherein the active state is the state requiring the symbol which the complete state defines .", "label": "", "metadata": {}}
{"text": "The method for recognizing spoken sentences of claim 1 , wherein said state sets are 1 rows corresponding to the number of grammar levels and N columns correspondong to the number of input frames of speech .The method for recognizing spoken sentences of claim 1 , wherein said grammar is a stochastic unification grammar .The method for recognizing spoken sentences of claim 1 , wherein said grammar is a context - free or regular grammar .A system for recognizing a spoken sentence representing a plurality of words , comprising : . a processing means ; . a grammar coupled to said processing means for defining sentences in terms of elements of a language model ; . a lexicon for defining elements of the grammar in terms of symbols ; . a parser coupled to said grammar for combining words into partial sentences , for generating sets of states and for determining completed states ; . a predictor coupled to said grammar and said processing means for predicting the symbols of valid next elements generated by said parser ; . a completer for explaining the results from the parser ; and .", "label": "", "metadata": {}}
{"text": "The system for recognizing a spoken sentence of claim 11 , further comprising a means for generating a chart , wherein the chart is accessed by said parser , said predictor , and said completer for storing intermediate results .The system for recognizing a spoken sentence of claim 12 , wherein the chart comprises states and state sets , said states to be manipulated by said parser and said predictor .The system for recognizing a spoken sentence of claim 11 , further comprising a scanner coupled to said parser and said completer , for reading symbols from the parser to the completer .", "label": "", "metadata": {}}
{"text": "The system for recognizing a spoken sentence of claim 11 , wherein said language model incorporates stochastic unification grammars .The system for recognizing a spoken sentence of claim 11 , wherein said language model incorporates context - free or regular grammars .The system for recognizing a spoken sentence of claim 11 , wherein said processing means includes an input means for recording spoken words and an acoustic device for tranforming spoken words into a medium readable by said processing means .The system for recognizing a spoken sentence of claim 11 , wherein said processing means is coupled to a translating means adapted to receive spoken input and transform said input into a medium readable by said processing means .", "label": "", "metadata": {}}
{"text": "The system for parsing of claim 20 , wherein the chart comprises states and state sets , said states to be manipulated by said parser and said predictor .The system for parsing of claim 20 , further comprising a knowledge base coupled to said predictor for supplying symbols and appropriate operating data .The system for parsing of claim 20 , wherein said language model incorporates stochastic unification grammars .The system for parsing of claim 20 , wherein said language model incorporates context - free grammars .A method for parsing a spoken sentence having a plurality of words , comprising the steps of : .", "label": "", "metadata": {}}
{"text": "( b ) inputting at least one grammar having terminal and nonterminal symbols for defining allowable sentence structures ; .( c ) inputting a lexicon having entries for defining terminal symbols of said at least one grammar in terms of linguistic , syntactic or semantic features ; .( d ) generating a matrix of state sets ; .( e ) initializing said state sets ; .( f ) reading said desired spoken input ; .( g ) predicting initial and final probabilities for a current frame for each start symbol of grammar ; .( h ) predicting a valid next nonterminal symbol to thereby create at least one state from its corresponding at least one rule according to said at least one grammar ; .", "label": "", "metadata": {}}
{"text": "( j ) generating a probability score for each said completed state ; .( k ) repeating steps ( h ) to ( j ) until no new states can be created ; .( l ) parsing terminal symbols from the current grammar level as start symbols for the next lower grammar level unless at the lowest grammar level ; .( m ) if at lowest grammar level , comparing features of the spoken input with features of the predicted next lexical entries ; .( n ) scanning observations from said next lower grammar level into waiting states of said current grammar level ; .", "label": "", "metadata": {}}
{"text": "( p ) reporting complete states corresponding to start symbols of said current level to the next higher grammar level ; .( q ) parsing said start symbols according to the spoken input and grammars to produce observations of said symbols ; and .( r ) explaining the input based on the results of said step of parsing .The method for parsing of claim 25 , wherein a complete state is a state which fully explains a segment of the spoken input .The method for parsing of claim 25 , further comprising the steps of : .", "label": "", "metadata": {}}
{"text": "( t ) after step ( n ) , incrementing a frame counter .The method for parsing of claim 25 , further comprising the steps of : .( s ) between steps ( d ) and ( e ) , reading an ending frame indicator ; and .( t ) after step ( k ) , incrementing a frame counter .The method for parsing of claim 25 , wherein said state sets are 1 rows corresponding to the number of grammar levels and N columns corresponding to the number of input frames of speech .The method for parsing of claim 25 , wherein said grammar incorporates context - free or regular grammars .", "label": "", "metadata": {}}
{"text": "The method of parsing of claim 25 , wherein said probability score for said completed state is the probability for completing states in the state set using already complete states in the state sets .Description .BACKGROUND OF THE INVENTION .Field of the Invention .This invention relates to spoken language interfaces , and more particularly to a spoken language processor containing a chart parser that incorporates rule and observation 10 probabilities with stochastic unification grammars .Description of the Related Art .It has been the goal of recent research to make machine understanding of spoken language possible through a tight coupling between speech and natural language systems .", "label": "", "metadata": {}}
{"text": "Furthermore , speech systems have come to rely heavily on grammar constraints to accurately recognize connected speech .Language modeling has become an essential element in high performance , speaker - independent , continuous speech systems .Until recently , speech recognition systems have primarily used Finite State Automatons ( FSAs ) as the language model .These models offer efficient processing , easily accommodate observation probabilities , and permit simple training techniques to produce transition probabilities .Attempts to model spoken language with FSAs have resulted in stochastic language models such as bigrams and trigrams .These models provide good recognition results when perplexity can be minimized , but preclude any direct support for spoken language systems by eliminating the semantic level .", "label": "", "metadata": {}}
{"text": "These formalisms , generally known as unification grammars , offer great flexibility with respect to processing for both parsing and generation .Unification grammars have allowed the close integration of syntax , semantics , and pragmatics .These grammars are especially significant for spoken language systems because syntactic , semantic , and pragmatic constraints must be applied simultaneously during processing .Discourse and domain contraints can then limit the number of hypotheses to consider at lower levels , thereby greatly improving performance .Several efforts have been made to combine Context - Free Grammars ( CFGs ) and unification grammars ( UGs ) with statistical acoustic information .", "label": "", "metadata": {}}
{"text": "Top - down constraints from CFG 's have been integrated with speech using the Cocke - Younger - Kasami ( CYK ) algorithm , but this algorithm has bad average time complexity ( cubic ) .This complexity becomes especially detrimental with frame synchronous parsing where the number of input hypotheses under consideration is typically large .For example , a person 's average speech input is 4 - 5 seconds long , which corresponds to 400 - 500 frames .When cubed , those 400 - 500 frames yield 64,000,000 - 125,000,000 processing steps to recognize an input .", "label": "", "metadata": {}}
{"text": "With natural language systems , N is traditionally words ; however with speech systems , N is equal to frames , which are the fundamental time units used in speech recognition .The algorithm was significant in that it provided a time synchronous algorithm for speech recognition which improved accuracy because the processor did not have to be concerned about how the words fit together .The CYK algorithm is very simple in that it resembles matrix multiplication .Unfortunately it always takes N 3 time , rather than linear time , even when processing a regular grammar .Additionally , the CYK algorithm is exhaustive ; it systematically expands everything whether it will be needed or not .", "label": "", "metadata": {}}
{"text": "Earley 's algorithm ( J. Earley , ' An Efficient Context - Free Parsing Algorithm',Comm . of the ACM , Vol . 13 , No . 2 , Feb. 1970 , pp .94 - 102 ) is one of the most efficient parsing algorithms for written sentence input and can operate in linear time for regular grammars .It was one of the first parsing methods that used a central data structure , known as a chart , for storing all intermediate results during the parsing process of a sentence .Subsequently chart parsers were widely used in natural language systems for written input .", "label": "", "metadata": {}}
{"text": "An example of such a modified algorithm is shown in A. Paeseler , ' Modification of Earley 's Algorithm for Speech Recognition ' , Proc . of NATO ASI , Bad Windsheim , 1987 .Paeseler 's algorithm combines probabilities in context - free grammars based on Earley 's algorithm but it does not do so optimally due to certain defects in the algorithm .One such defect involves the calculation of probabilities .For context - free grammars , a nonterminal symbol may rewrite to another nonterminal symbol without having to go through a terminal symbol .Probabilities can therefore occur from many directions in the grammar .", "label": "", "metadata": {}}
{"text": "But in order to expand those subsequent symbols , according to Paeseler 's algorithm , the best probability must be known , otherwise if a better probability appears , the parsing must be redone .This means potentially an exponential amount of work , which is highly undesirable .SUMMARY OF THE INVENTION .Another goal of the present invention is to provide a chart parser that correctly computes hypothesis probabilities in an efficient manner for CFGs and stochastic unification grammars , by interleaving the search for explanations of symbols from both the top down and from the bottom up .", "label": "", "metadata": {}}
{"text": "It saves time and memory space by expanding symbols only once .The present invention extends Earley 's basic CFG parsing algorithm to combine rule and observation probabilities with the use of unification grammars .This retains the Earley algorithm complexity while extending the results to spoken input recognition : linear for regular grammars , quadratic for unambiguous CFGs , and cubic for general CFGs .The complexity results also hold for unification grammars that do not include arbitrary nesting of features .Because of this efficiency , the algorithm applies to multiple grammar levels of a spoken language system .", "label": "", "metadata": {}}
{"text": "The present invention loads the grammars and the reference data from a disk or appropriate memory space into internal data structures for access by the parser .The present invention then enables the chart processor to predict all start symbols and parse for all input frames .The parse function requires that the processor alternately repeat a predict function and a complete function until no new states can be added .If the processor is on the bottom grammar level , then it will score any terminal symbols with respect to the input frame .If the processor is not on the bottom level , then it will predict the terminal symbols at the next lower level and proceed to parse .", "label": "", "metadata": {}}
{"text": "It will complete active states as new complete states become available and return to the next higher grammar level the complete states from symbols of the current grammar level .The present invention assigns probabilities to the hypotheses that it next wants to explore .It also employs a beam pruning technique , well - known in the art , and a delayed commitment in the score caluclation to determine the most probable correct response ( speech recognition ) .These and other features and advantages of the invention will be apparent to those skilled in the art from the following detailed description of a preferred embodiment , taken together with the accompanying drawings , in which : .", "label": "", "metadata": {}}
{"text": "FIG .1 is a block diagram showing a speech recognition processor which employs the present invention ; .FIG .2 is a stack diagram demonstrating a possible grammar level structure and positioning as used by the present invention ; .FIGS .3A - C show an example demonstrating frame synchronous parsing using probabilities employed by the present invention ; .FIGS .4A - D show an example showing a typical left recursive rule showing rule probabilities correctly computed by the present invention ; and .FIG .5 is a graph showing the effect of chart parsing on pruning as employed by the present invention .", "label": "", "metadata": {}}
{"text": "The present invention discloses a method which makes use of an algorithm ( discussed below ) which includes a parsing subalgorithm to affect the central data structure of a spoken language processor .As seen in FIG .1 , an input device 10 receives input from a user and transmits the input along connecting element 12 to processor 14 .Processor 14 contains a central data structure , known as a chart 24 , not shown , where the algorithm is implemented .The algorithm instructs processor 14 to load a grammar , a lexicon , probabilities , and other appropriate operating data from processor memory 16 .", "label": "", "metadata": {}}
{"text": "After processor 14 has completed the algorithm and has identified the input from input device 10 , processor 14 transmits an output to output device 22 via connecting element 20 .The grammar contains rules which define the appropriate grammar used and is well known in computational linguistics arts .The lexicon contains definitions of the terminal symbols of the grammar .These terminal grammar symbols are preferably word classification descriptors , such as verb , noun , and article , with syntactic and semantic information .The terms of the lexicon are assigned features , such as tense , plurality , or definiteness .", "label": "", "metadata": {}}
{"text": "The actual words , also called atoms , are defined elsewhere , such as in a knowledge base .The grammar and lexicon , taken together , can be compiled without reference to a particular domain .The result is to define a spoken language reference which can be a fairly complex subset of a language .Since the rules for the grammar and lexicon refer only to word types , the number of rules is relatively small , even at execution time , so they run quickly .The \" output device \" may be a screen , another processor , an audio speaker , a robotic arm , etc .", "label": "", "metadata": {}}
{"text": "However , this should not in any way limit the present invention .Before considering the algorithm of the present invention , two definitions are needed .First , one defines a stochastic unification grammar which is based on the definition of stochastic context - free grammar and is described by the generalization that the symbols are not restricted to atomic symbols but can be feature - value pairs or feature sets .A feature set may be indexed with a variable using the notation X+FS , where X is a variable and FS is a feature set .The variable may be used elsewhere to denote the occurence of the same feature set .", "label": "", "metadata": {}}
{"text": "INPUT : .A vector of grammars , G , G o , . . ., G l .An ending frame n. .OUTPUT : .A matrix of state sets E , 1 rows and n columns . , the best score for S of G o .METHOD : .Make E l , o empty for all l. .For each s\u03b5S , predict [ i , -- , s , -- , -- , -- , -- , \u03c3 o , \u03c3 o ] .METHOD : .Repeat the following two steps until no new states can be added : .", "label": "", "metadata": {}}
{"text": "( b ) Complete .Hypothesize .Scan .Repeat the following two steps until no new states can be added : .( a ) Predict .( b ) Complete .In implementing the above algorithm , the processor reads a vector of grammars representing any number of grammar levels .Looking for the moment at FIG .2 , an example of grammar levels is shown .The highest level is sentence grammar level 0 .Below that is word grammar level 1 , and below that is phoneme grammar level 2 .The next lower level shown is phone grammar level 3 .", "label": "", "metadata": {}}
{"text": "A reference frame is the fundamental time unit set by the speech developer .For example , the fundamental time unit may be 20 milliseconds .This means that every 20 milliseconds the processor will characterize speech data with a vector of length 18 or so , floating point features of various characteristics of the speech signal and will match those characteristics to the expected data or symbols which correspond to words .Returning to the algorithm , before the processor has completed the input , it generates an output of a matrix of state sets E which is 1 rows corresponding to the number of levels and N columns corresponding to the number of input frames of speech .", "label": "", "metadata": {}}
{"text": "2 ) , which is the sentence level grammar .After reading the vector of grammars , in the preferred embodiment , the processor will then input an ending frame indicator n. Although this is not required , it makes the algorithm more complete .Furthermore , there are other means by which the end point can be indicated to the processor .At this point , the processor initializes all of the state sets to empty at all levels of the first frame and sets the initial probability to 0.0 which is a logarithmic probability .The processor sets the level to 0 ( starts at the sentence grammar level ) , and sets the frame to 0 .", "label": "", "metadata": {}}
{"text": "For each start symbol of grammar , the processor predicts the current frame 's initial and final probability as 0.0 .The processor then parses , given the start frame , the state set , and the level .In the parse algorithm , the processor inputs the matrix of state sets , a level 1 , a frame index i , and outputs an extra state for the next input frame request i+1 .This cycle is repeated until no new predicted and completed states are added .The cycle produces some terminal symbols that are hypothesized at the next lower grammar level .", "label": "", "metadata": {}}
{"text": "It returns a set of observations which are scanned into the waiting states .In the preferred embodiment , the frame counter is then incremented because any state that completes will do so at the next frame .It should be noted , however , that the frame counter may be incremented at other times during the execution of the algorithm depending on how one wants to keep track of the frames .At this point , either the states are complete or are reported as observations to the next higher grammar level .They may also still be active ( not completed ) and be placed in a pending list for processing during the next cycle .", "label": "", "metadata": {}}
{"text": "2 , the processor looks at the inputted grammar and sees that there is a symbol , say S , that corresponds to a sentence .The processor proceeds to the parse function , does the prediction and completion , and finds out that it needs some words which are terminal symbols in the sentence grammar level .The processor then calls the hypothesizer with that set of words , which also are start symbols at the next lower level -- level 1 in this case .Then the processor predicts and completes grammar rules for the words which are composed of phonemes and when it finds a set of phonemes which are terminal symbols , it then calls itself at grammar level 2 which has phoneme symbols as start symbols .", "label": "", "metadata": {}}
{"text": "HMM grammars have reference vectors symbols corresponding to reference vectors as their terminal symbols .The processor then scores these reference vectors and gets probabilities for the frame and returns those as observations to the next higher level .Those observations are scanned into that next higher level .Through the next iteration , the processor predicts and completes those states that were advanced .This continues until all of the input has advanced up to sentence grammar level 0 and advanced S over several time frames to cover all of the input data .At this point , the processor has completed its parse and outputs its hypothesis of the spoken input .", "label": "", "metadata": {}}
{"text": "Explanations of each of those different functions are given below .Further assume all symbols are at level 1 unless otherwise indicated .If B 1 and B 2 are atomic symbols for context - free grammars , then they are unified by default .Next the set of symbols is added to the set of states under consideration .This is what the processor needs to see to indicate it has seen B 3 . \u03b5 is a string of 0 or more terminals and nonterminals In this case the ending frame is also the current frame because the processor has not processed anything .", "label": "", "metadata": {}}
{"text": "This is especially important for left recursive rules .Subtracting the beginning probability from the ending probability , yields \u03b7 . sigma .-\u03c3.sub.\u03bf ) ] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .To complete the symbol , there is a state that begins at some time k and ends at some time i , containing the symbol V for which the final probability is \u03c3 and the initial probability is \u03c3 o .", "label": "", "metadata": {}}
{"text": "For all terminals \" b \" at a given level 1 , the processor computes a new probability based on the ending probability \u03c1 of the state , \u03c1 ' .This is part of the delayed commitment algorithm .Since the processor is at a terminal symbol , it can then perform this algorithm because all states have been predicted and completed and there is no more information available to enable it to predict or complete any more states .The processor will predict at level 1 + 1 , which is the next lower level .That is indicated by symbol b at the current frame with initial and ending probabilities \u03c1 ' .", "label": "", "metadata": {}}
{"text": "This shows a mutually recursive relationship between hypothesize and parse .rh o.+(\u03c3.sub.\u03bf -\u03c3 ) ] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .Scan is essentially the same as complete .The only difference is that \" complete \" deals with nonterminal symbols and \" scan \" deals with terminal symbols .First the processor makes the state set at level 1 , frame i+1 , empty .", "label": "", "metadata": {}}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ add______________________________________given [ f , p , A 1 , \u03b1 1 , j , \u03b2 1 , i , \u03c3.sub.\u03bf , \u03c3]if there exists [ f , p , A 2 , \u03b1 2 , j , \u03b2 2 , i , \u03c1.sub . omic ron . , \u03c1]and subsumes(A 1 , A 2 ) -replace \u03c1 with max(\u03c1 , \u03c3),symbolicallyotherwise append the given state to E l , i _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}}
{"text": "It does not evaluate \u03c1 or \u03c3 , but instead marks the ending in the existing state set , thereby noting it has been added until the processor can later look up the probability and find the maximum .Otherwise the processor will just append the given state to the state set at level 1 of frame i , because there is no other existing subsumming state .Efficient implementation of the algorithm depends on use of some details set out in Earley 's work .Furthermore , inherent throughout the program is a compute function .When finding probabilities for terminal symbols , it is up to the compute step to note cycles and efficiently find the probability of a given state .", "label": "", "metadata": {}}
{"text": "3 , an example of frame synchronous parsing using probabilities is demonstrated .In the portion labeled A , a simple grammar is given which consists of one rule , namely sentence rewrites to a noun and a verb .One noun \" boys \" and two verbs \" sleep \" and \" leap \" are given .The portion of FIG .3 labeled B discloses a word lattice , which is the input to the system ( in this example ) showing the beginning and ending frames of each of the word hypotheses .The lattice contains a plurality of lines which show the logarithmic probability of seeing a particular word over a particular span of data and gives such probability as a negative number .", "label": "", "metadata": {}}
{"text": "The dot above that refers to the place in the rule or how far one has progressed through the rule which , at this point , is none .The numbers at the end of the rule represent the logarithmic probabilities of the initial and final probabilities , respectively .The first state came about because of predicting the start symbol S. The starting probability represents the probability of wanting to start this hypothesis and the ending probability represents having seen as much of the hypothesis as has been seen .When the parser has predicted and completed as much as it can , it has a set of terminal symbols that it needs to see before it can go on and the set consists of one element which is \" boys \" .", "label": "", "metadata": {}}
{"text": "Once it has a complete noun from frame 0 to frame 2 , it checks if there are any symbols that ended at zero that needed a noun that it can complete and finds there was one starting with S in the very first state .It then creates a new state that indicates it has seen a noun by having the dot after the n and indicates that the noun extends to frame 2 with the same probability , -0.04 , as its ending probability .When it has done all the predicting and completing it can do , it sees that it needs a verb indicated by v. There are two verb rules , so it predicts them .", "label": "", "metadata": {}}
{"text": "There it sees \" boys \" again with the probability of -0.03 .The two noun hypotheses ( \" boys \" from frame 0 to frame 2 and \" boys \" from frame 0 to frame 3 ) are non - intersecting hypotheses since they have different stop times , and therefore remain separate .Now the parser sees that at frame 3 it needs a verb from state 8 so it predicts that verb and creates states 9 and 10 that both begin at frame 3 and end at frame 3 .One of the newly created states needs the terminal \" sleep \" and one needs terminal \" leap \" , both of which have the same beginning and end probabilities of -0.03 .", "label": "", "metadata": {}}
{"text": "The ending probabilities are calculated by adding the intial probability plus the probability of seeing the particular word from its starting frame to its ending frame .The parser now has two complete verb symbols and it extends , or looks , for states that need a verb that starts at either frame 2 or frame 3 and finds an S that corresponds to both back in state 8 and state 4 .Now the parser has a complete state corresponding to the start symbol S in state 13 and one corresponding to the start symbol S in state 14 , although the middle states for each are different .", "label": "", "metadata": {}}
{"text": "This phrase will then be outputted as the speech recognition processor 's best explanation for the spoken input given .The desired probability is that which is most positive , or as seen in this example , the least negative .FIG .4 is an example of a typical left recursive rule showing rule probabilities , using a treatment of conjunctions and disjunctions such as \" a or b or d \" .As seen in portion A of FIG .4 , the example shown has the four terminal symbols : a , b , d and \" or \" .", "label": "", "metadata": {}}
{"text": "The tree in portion B reflects the desired outcome of this parse .The tree shows that to recognize this input the parser has to use a left recursive rule two times and the non - left recursive S choice , which is S goes to C , once at the bottom .The tree also shows the rule probabilities .The probability of parsing this input is the product of all the rule probabilitiesthat are given in portion C of FIG .4 .The trace seen in Portion D of FIG .4 shows the behaviour of the algorithm with these rule probabilities with respect to the input .", "label": "", "metadata": {}}
{"text": "Because the chart parser parses symbols only once , it can specifically treat left recursive rules .To add the probabilities correctly , it is very important that the predict function add the rule probabilitiy onto the final probability of the state , not to add it onto the initial probability of the state .Thus each time the state is used the rule probability will then be added into subsequent states using the previous state .At the bottom of the trace , it is seen that the one - third arises the correct number of times ( 3 ) , the 0.4 arises twice , and the 0.6 arises once , which accurately reflect the number of times the left and nonleft recursive rule were applied .", "label": "", "metadata": {}}
{"text": "5 is a graph showing the effect of chart parsing by the present invention on pruning .The graph considers time versus logarithmic probability of hypotheses .Each of the dots represent the same hypothesis symbol at times t i and t k .The top line represents the best probability of any symbol on any explanation .The bottom line represents the best plus some predetermined log probability amount , or threshold .With other algorithms , if the probability of a symbol drops below that threshold at any point , it is discarded .Furthermore , when the best probability symbol completes , the parser will then associate the lower probability symbols with their starting states .", "label": "", "metadata": {}}
{"text": "Accordingly , it is intended that the invention be limited only in terms of the appended claims .Trehan , R. et al . , A paralle chart parser for the committed choice non deterministic logic languages , IEEE Proceedings of the Fifth International Conference and Symposium : Logic Programming , Seattle , WA , Aug. 1988 , 212 232 , vol .An ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}}
{"text": "The ontology - based parser contains functional components for receiving documents in a plurality of formats , tokenizing them into instances of concepts from an ontology , and assembling the resulting concepts into predicates .The ontological parser has two major functional elements , a sentence lexer and a parser .The sentence lexer takes a sentence and converts it into a sequence of ontological entities that are tagged with part - of - speech information .The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .", "label": "", "metadata": {}}
{"text": "a parser for converting the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the natural language sentence and binds arguments into predicates .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said sentence lexer comprises : . a document iterator that receives text input and outputs individual sentences ; . a lexer that receives said individual sentences from said document iterator and outputs individual words ; and . an ontology that receives said individual words from said lexer and returns ontological entities or words tagged with default assumptions about an ontological status of said individual words to said lexer .", "label": "", "metadata": {}}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a non - negative number indicates agreement .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a negative number indicates feature incompatibility .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 6 , wherein a first digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 6 , wherein said predicates and arguments are represented by encodings comprising at least one digit separated into multiple groups to provide multiple ontological levels and a branching factor at each node .", "label": "", "metadata": {}}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 10 , wherein said lexer filters comprise at least one of : a noun filter , an adjective filter , an adverb filter , a modal verb filter , a stop word filter , a pseudo - predicate filter , and a pseudo - concept filter .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said stop word filter removes stop words from said individual sentences .", "label": "", "metadata": {}}
{"text": "claim 11 , wherein said adjective filter removes lexemes representing adjectives from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said noun filter groups proper nouns into single lexical nouns .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said modal verb filter removes modal verbs from objects of said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said pseudo - predicate filter removes verbs from queries .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said pseudo - concept filter removes concepts from queries .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said parser comprises : . a sentence receiver that receives sentences including ontological entities from said sentence lexer ; . a parser component that parses said sentences , received by said sentence receiver , into parse trees representing concepts in a respective sentence received by said sentence receiver ; and .", "label": "", "metadata": {}}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 19 , wherein said parser component further comprises : . parser filters operating on said predicates to remove erroneous predicates .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 19 , wherein said parser component looks ahead at least one word , scans input from left - to - right , and constructs said parse tree .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 22 , wherein said parser filters include a selectional restriction filter and a parse probability filter .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 23 , wherein said selectional restriction filter vetoes parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said system is modular to permit the use of any part - of - speech - tagged ontology .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 6 , wherein said parse trees is represented by modified hexadecimal digits that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format comprising the steps of : . converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and . converting said sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the natural language sentence and binds arguments into predicates .", "label": "", "metadata": {}}
{"text": "claim 28 , further comprising the step of modifying said natural language sentence based on word meanings .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the steps of : . receiving sentences including ontological entities ; . parsing said sentences including ontological entities into parse trees representing concepts in the corresponding sentence including ontological entities ; and . converting said parse trees into predicates .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of removing parse trees that violate one of statistical and ontological criteria for well - formedness .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 34 , further comprising the step of subtracting said numbers to determine if features are in agreement , wherein a negative number indicates feature incompatibility .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 34 , further comprising the step of subtracting said numbers to determine if features are in agreement , wherein a non - negative number indicates agreement .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 39 , wherein a most significant digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of representing said predicates and arguments by encodings comprising at least one digit separated into groups to provide multiple ontological levels and a branching factor at each node .Description .Applicants hereby incorporate by reference co - pending application Ser .No .09/627,295 filed in the U.S. Patent and Trademark Office on Jul. 27 , 2000 , entitled \" Concept - Based Search and Retrieval System . \" BACKGROUND OF THE INVENTION .", "label": "", "metadata": {}}
{"text": "The present invention relates to an ontological parser for natural language processing .More particularly , the present invention relates to a system and method for ontological parsing of natural language that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .The system utilizes unstructured text as input and produces a set of data structures representing the conceptual content of the document as output .The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}}
{"text": "The ontology - based parser is designed around the idea that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .The system and method of ontology - based parsing of the present invention is directed towards techniques for deriving predicate structures with minimal computational effort .", "label": "", "metadata": {}}
{"text": "The output predicate structures contain numeric tags that represent the location of each concept within the ontology .The tags are defined in terms of an absolute coordinate system that allows calculation of conceptual similarity according to the distance within a tree structure .All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .Background of the Invention .Numerous techniques have been developed to process natural language input .These techniques tend to be complicated and cumbersome .", "label": "", "metadata": {}}
{"text": "Often the previous techniques do not have very robust feature checking capabilities .In particular , the techniques do not check for both syntactic and semantic compatibility .Often these techniques expend significant time trying to parse words that can be pruned or filtered according to their information .The previous techniques of natural language processing are often limited to the performance of a particular purpose and can not be used for other purposes .Conventional parsing techniques may be designed to function as part of a grammar checking system , but can not function as part of a search engine , summarization application , or categorization application .", "label": "", "metadata": {}}
{"text": "This limits the versatility of the techniques .U.S. Pat .No .4,864,502 to Kucera et al . discloses a device that tags and parses natural - language sentences , and provides interactive facilities for grammar correction by an end user .The system taught by Kucera et al .has a complicated analysis , and can not afford semantic status to each word relative to all the other words within the dictionary .The Kucera et al . system uses three parsing stages , each of which needs more than one pass through the sentence to complete its analysis .", "label": "", "metadata": {}}
{"text": "No .4,887,212 to Zamora et al . discloses a parser for syntactic analysis of text using a fast and compact technique .After part - of - speech tagging and disambiguation , syntactic analysis occurs in four steps .The grammar of Zamora et al . operates by making multiple passes to guess at noun phrases and verb phrases and then attempts to reconcile the results .Furthermore , the grammar violation checking technique of the Zamora et al .system checks only for syntactic correctness .U.S. Pat .No .4,914,590 to Loatman et al . discloses a natural language understanding system .", "label": "", "metadata": {}}
{"text": "Case frames used in Loatman et al . require substantial hard - coded information to be programmed about each word , and a large number of case frames must be provided to obtain reasonable coverage .Tokuume et al . , U.S. Pat .No .5,101,349 , discloses a natural language processing system that makes provisions for validating grammar from the standpoint of syntactic well - formedness , but does not provide facilities for validating the semantic well - formedness of feature structures .U.S. Pat .No .5,146,496 to Jensen discloses a technique for identifying predicate - argument relationships in natural language text .", "label": "", "metadata": {}}
{"text": "Post - parsing analysis is needed and the parsing time is impacted by the maintenance of these variables .Additionally , semantic feature compatibility checking is not possible with Jensen 's system .U.S. Pat .No .5,721,938 to Stuckey discloses a parsing technique , which organizes natural language into symbolic complexes , which treat all words as either nouns or verbs .The Stuckey system is oriented towards grammar - checker - style applications , and does not produce output suitable for a wide range of natural - language processing applications .The parser of the Stuckey system is only suitable for grammar - checking applications .", "label": "", "metadata": {}}
{"text": "No .5,960,384 to Brash discloses a parsing method and apparatus for symbolic expressions of thought such as English - language sentences .The parser of the Brash system assumes a strict compositional semantics , where a sentence 's interpretation is the sum of the lexical meanings of nearby constituents .The Brash system can not accommodate predicates with different numbers of arguments , and makes an arbitrary assumption that all relationships are transitive .The Brash system makes no provisions for the possibility that immediate relationships are not in fact the correct expression of sentence - level concepts , because it assumes that syntactic constituency is always defined by immediate relationships .", "label": "", "metadata": {}}
{"text": "Furthermore , the Brash system requires target languages to have a natural word order that already largely corresponds to the style of its syntactic analysis .Languages such as Japanese or Russian , which permit free ordering of words , but mark intended usage by morphological changes , would be difficult to parse using the Brash system .The patent to Hemphill et al .( U.S. Pat .No . 4,984,178 ) discloses a chart parser designed to implement a probabilistic version of a unification - based grammar .The decision - making process occurs at intermediate parsing stages , and parse probabilities are considered before all parse paths have been pursued .", "label": "", "metadata": {}}
{"text": "U.S. Pat .No .5,386,406 to Hedin et al . discloses a system for converting natural - language expressions into a language - independent conceptual schema .The output of the Hedin et al . system is not suitable for use in a wide variety of applications ( e.g. machine translation , document summarization , categorization ) .The Hedin et al . system depends on the application in which it is used .SUMMARY OF THE INVENTION .The foregoing and other deficiencies are addressed by the present invention , which is directed to an ontology - based parser for natural language processing .", "label": "", "metadata": {}}
{"text": "The system utilizes unstructured text as input and produces a set of data structures representing the conceptual content of the document as output .The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .The resulting ontological entities are predicate - argument structures designed in accordance with the best practices of artificial intelligences and knowledge - base research .The design of the ontology - based parser is based on the premise that predicate structures represent a convenient approach to searching through text .", "label": "", "metadata": {}}
{"text": "Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .The ontology - based parser of the present invention is directed towards techniques for deriving predicate structures with minimal computational effort .In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .", "label": "", "metadata": {}}
{"text": "The tags are defined in terms of an absolute coordinate system that allows calculation of conceptual similarity according to the distance within a tree structure .All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .The present system imposes a logical structure on text , and a semantic representation is the form used for storage .The present system further provides logical representations for all content in documents .The advantages of the present system are the provision of a semantic representation of comparable utility with significantly reduced processing requirements , and no need to train the system to produce semantic representations of text content .", "label": "", "metadata": {}}
{"text": "The preferred implementation of the present system and method affords semantic status to each word relative to all the other words within the dictionary , and uses a single - pass context - free grammar to provide complete predicate structures containing subject and object relationships .The system and method of the present invention also provides a robust feature - checking system that accounts for semantic compatibility as well as syntactic compatibility .The ontology of the present invention converts all inflected words to their canonical forms .Additionally , the system and method can filter lexical items according to their information content .", "label": "", "metadata": {}}
{"text": "In the embodiment discussed above , the grammar violation checking of the system and method of the present invention filters both by the probability of a syntactically successful parse and the compatibility of the lexical semantics of words in the ontology .The compatibility referred to here is the self - consistent compatibility of words within the ontology ; no particular requirement is imposed to force the ontology to be consistent with anything outside the present system .In the predicate representation scheme of the present invention , there are only a few distinct frames for predicate structures , as many as needed to cover the different numbers of arguments taken by different verbs .", "label": "", "metadata": {}}
{"text": "The manner in which the present invention constructs parse trees , from which predicate structures and their arguments can be read directly , uses context - free grammars , which result in faster execution .The system of the present invention maintains arguments as variables during the parsing process , and automatically fills in long - distance dependencies as part of the parsing process .No post - parsing analysis is needed to obtain this benefit , and the parsing time is not impacted by the maintenance of these variables , thus resulting in faster parsing execution .Additionally , the ontologies used permit semantic feature compatibility checking .", "label": "", "metadata": {}}
{"text": "The predicate - argument relationships can be used in search , grammar - checking , summarization , and categorization applications , among others .The system and method of the present invention can accommodate predicates with different numbers of arguments , and does not make arbitrary assumptions about predicate transitivity or intransitivity .Instead the system and method of the present invention incorporates a sophisticated syntactic analysis component , which allows facts about parts - of - speech to determine the correct syntactic analysis .Additionally , by incorporating ontologies as the basis for the lexical resource , the present invention permits the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}}
{"text": "As long as grammatical roles can be identified , the present system and method can be easily adapted to any language .For example , certain case - marked languages , such as Japanese or German , can be parsed through a grammar which simply records the grammatical relationships encoded by particular markers , and the resulting output is still compatible with the parsing results achieved for other languages .From the foregoing , it is an object of the present invention to provide a system and method for parsing natural language input that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}}
{"text": "Yet another object of the present invention is to provide a system and method for parsing natural language input that provides ontological entities as output that are predicate - argument structures .Another object of the present invention is to provide a system and method for parsing natural language input that derives predicate structures with minimal computational effort .Another object of the present invention is to provide a system and method for parsing natural language input that realizes enormous speed benefits from the parameterized ontology that the parser utilizes .BRIEF DESCRIPTION OF THE DRAWINGS .These and other attributes of the present invention will be described with respect to the following drawings in which : .", "label": "", "metadata": {}}
{"text": "1 is a block diagram of the sentence lexer according to the present invention ; .FIG .2 is a block diagram of the parser according to the present invention ; .FIG .3 is a diagram showing two complete parse trees produced according to the present invention ; .FIG .4 is an example parse tree according to the present invention ; .FIG .5 is another example parse tree according to the present invention ; .FIG .6 is another example parse tree according to the present invention ; and .FIG .", "label": "", "metadata": {}}
{"text": "DETAILED DESCRIPTION OF THE INVENTION .In the following detailed discussion of the present invention , numerous terms , specific to the subject matter of a system and method for concept - based searching , are used .In order to provide complete understanding of the present invention , the meaning of these terms is set forth below as follows : .The term concept as used herein means an abstract formal representation of meaning , which corresponds to multiple generic or specific words in multiple languages .Concepts may represent the meanings of individual words or phrases , or the meanings of entire sentences .", "label": "", "metadata": {}}
{"text": "A predicate structure is a data type that includes a predicate and multiple additional concepts ; as a grouping of concepts , it is itself a concept .An ontology is a hierarchically organized complex data structure that provides a context for the lexical meaning of concepts .An ontology may contain both individual concepts and predicates .The ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}}
{"text": "The ontological parser is designed to be modular , so that improvements and language - specific changes can be made to individual components without reengineering the other components .The components are discussed in detail below .The ontological parser has two major functional elements , a sentence lexer and a parser .The sentence lexer takes a sentence and converts it into a sequence of ontological entities that are tagged with part - of - speech information .The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .", "label": "", "metadata": {}}
{"text": "An ontological parser is a tool that transforms natural - language sentences into predicate structures .Predicate structures are representations of logical relationships between the words in a sentence .Every predicate structure contains a predicate , which is either a verb or a preposition , and a set of arguments , which may be any part of speech .Predicates are words which not only have intrinsic meaning of their own , but which also provide logical relations between other concepts in a sentence .Those other concepts are the arguments of the predicate , and are generally nouns , because predicate relationships are usually between entities .", "label": "", "metadata": {}}
{"text": "The sentence lexer 100 is a tool for transforming text strings into ontological entities .The parser is a tool for analyzing syntactic relationships between entities .Referring to .FIG .1 , the sentence lexer 100 is shown .Document iterator 120 receives documents or text input 110 , and outputs individual sentences to the lexer 130 .As the lexer 130 receives each sentence , it passes each individual word to the ontology 140 .If the word exists within the ontology 140 , it is returned as an ontological entity ; if not , it is returned as a word tagged with default assumptions about its ontological status .", "label": "", "metadata": {}}
{"text": "After the lexer 130 has checked the last word in a sentence against the contents of the ontology 140 , the unparsed sentence is passed to a series of lexer filters 150 .Lexer filters 150 are modular plug - ins , which modify sentences based on knowledge about word meanings .The preferred embodiment contains several filters 150 , although more may be developed , and existing filters may be removed from future versions , without altering the scope of the invention .For example , in an information retrieval application , an ontological parser may employ the following filters : proper noun filter , adjective filter , adverb filter , modal verb filter , and stop word filter .", "label": "", "metadata": {}}
{"text": "The stop word filter removes stop words from sentences .Stop words are words that serve only as placeholders in English - language sentences .The stop word filter will contain a set of words accepted as stop words ; any lexeme whose text is in that set is considered to be a stop word .An adjective filter serves to remove lexemes representing adjective concepts from sentences .Adjective filter checks each adjective for a noun following the adjective .The noun must follow either immediately after the adjective , or have only adjective and conjunction words appearing between the noun and the adjective .", "label": "", "metadata": {}}
{"text": "The noun must also meet the selectional restrictions required by the adjective ; if not , the adjective filter will veto the sentence .If a noun is found and it satisfies the restrictions of the adjective , the adjective filter will apply the selectional features of the adjective to the noun by adding all of the adjective 's selectional features to the noun 's set of selectional features .The proper noun filter groups proper nouns in a sentence into single lexical nouns , rather than allowing them to pass as multiple - word sequences , which may be unparsable .", "label": "", "metadata": {}}
{"text": "Although a number of proper nouns are already present in the lexicon , they are already properly treated as regular lexical items .Since proper nouns behave syntactically as regular nouns , there is no need to distinguish proper nouns and nouns already in the lexicon .The purpose of the proper noun filter is to ensure that sequences not already in the lexicon are treated as single words where appropriate .The modal verb filter removes modal verbs from sentence objects .Modal verbs are verbs such as \" should \" , \" could \" , and \" would \" .", "label": "", "metadata": {}}
{"text": "Since truth conditions do not need to be addressed by the ontological parser 120 or 140 , such words can be eliminated to reduce parsing complexity .The modal verb filter will contain a set of modal verbs similar to the stop word list contained in stop word filter .Any Lexeme whose text is in that set and whose concept is a verb is identified as a modal verb , and will be removed .The adverb filter removes Lexemes containing adverb concepts from sentences .Adverbs detail the meaning of the verbs they accompany , but do not change them .", "label": "", "metadata": {}}
{"text": "The pseudo - predicate filter operates in one embodiment , as a query ontological parser .It removes verbs from queries which are not likely to be the actual predicate of the query .Pseudo - predicate verbs include \" give \" , \" show \" , and \" find \" .Not all instances of these verbs are pseudo - predicates ; however , the first instance of them in a query often is .In one embodiment , the deterministic rule to be used in implementing the pseudo - predicate filter is that it should remove any instance of these verbs not preceded by a content - bearing noun ( i.e. , one not appearing in the list of pseudo - concepts or stop words ) .", "label": "", "metadata": {}}
{"text": "It removes concepts from queries , which are not likely to be the actual concept the user intends .Pseudo - concepts are largely nouns , and can be captured by a stop word list .Pseudo - concepts include \" I \" , \" me \" , \" you \" , and in certain syntactic usages , \" information \" , \" news \" , and related words .Two rules are included in this example of a pseudo - concept filter implementation .The first rule is that any word relating to the user , or his current situation , such as \" I \" or \" me \" is always deleted .", "label": "", "metadata": {}}
{"text": "The configuration of the parser 200 is shown in FIG .2 .First , the sentence receiver 220 obtains sentences 210 consisting of ontological entities produced by the sentence lexer 100 .These sentences are parsed by the parser 230 , which is designed to use a context - free grammar , although other grammatical models may be used without departing from the scope and spirit of the invention .Sentences are parsed into structures called parse trees , which represent the relationships between concepts in a sentence .Parse tree converter 240 receives the output of the parser 230 , and converts the parse trees into predicates .", "label": "", "metadata": {}}
{"text": "The sentence receiver 220 is an architectural feature designed to provide an interface between the sentence lexer 100 and the ontological parser 200 .The sentence receiver is a software abstraction that may be realized through any number of techniques .The parser 230 takes a sequence of instances from an ontology , in the form of a sentence , and converts them into a collection of parse trees .Preferably , the parser 230 will use a modified version of an LALR parser , which looks ahead ( by one word ) , scans the input from left - to - right , and constructs a parse tree from the bottom up .", "label": "", "metadata": {}}
{"text": "While the description is a preferred embodiment , it will be understood that any implementation of a context - free grammar within a similar architecture , including such variants as an LALR-2 parser ( which looks ahead by two words ) , are within the scope of the present invention .LALR parsers and parser generators are incapable of handling ambiguous grammars , as well as some grammars that are not ambiguous but do not follow the prescribed LALR format .Consequently , a parser that handles both of these conditions is needed .The parser 230 must pursue all possible parse trees , in effect branching and pursuing more than one path at every ambiguity .", "label": "", "metadata": {}}
{"text": "The finite state machine makes use of a two - dimensional table , called an action table , that specifies what action the finite state machine is to perform when the state machine is in a given current state and the next symbol in the input stream is a given symbol .At every cycle , a new character is read from the input stream and the character and current state are used to look up , in the action table , which action to perform .The actions are in one of the following forms : .Shift actions cause the parser to enter a new state and indicate that some progress has been made in assembling the production currently in progress ; .", "label": "", "metadata": {}}
{"text": "Accepts cause the parser to finish assembling a complete parse tree and halt ; .Errors cause the parser to give up because no grammar rule is available to reconcile what has already been parsed with what remains in the input stream .LALR parsers can be generated by a standard algorithm that builds the parser finite state machine 's action table from a set of grammar rules .These grammar rules , called productions , specify language that the target parser is supposed to recognize .Each production indicates that a specific combination of input symbols , called terminals , and assembled groups of terminals , called non - terminals , can be assembled into a new non - terminal .", "label": "", "metadata": {}}
{"text": "The standard LALR parser generator algorithm fails when the grammar does not provide the parser generator enough information to decide whether the correction to perform given a certain current state and input symbol is to shift or to reduce .The generator algorithm also fails when the grammar does not provide the parser generator enough information to decide which of two or more rules should be reduced .For instance , consider the following grammar : .Given this grammar , an LALR parser generator would fail to produce a parser because of a shift / reduce conflict .The modified LALR parser generator algorithm that the ontological parser of the present invention uses must be aware of the possibility of more than one possible course of action , and should recursively try both actions .", "label": "", "metadata": {}}
{"text": "FIG .3 , for the input string ' ab . 'An example of a context - free grammar that would be used in implementing the parser is as follows : .The modified LALR parser generator , grammar , and modified LALR parsing engine discussed previously should generate a non - deterministic recursive parser .Since a natural language is the input to the grammar , some sentences will fail to meet the foregoing conditions .In other cases , syntactic ambiguity will result in multiple possible parses .The parser should not generate any output trees for a sentence that does not reduce according to the rules ; rather it should generate a tree for every possible parse of an ambiguous sentence .", "label": "", "metadata": {}}
{"text": "Since the parser is both probabilistic and operating on multiple streams of possible ontological entities , it is necessary to prune out spurious parse trees generated by the parser 230 .Parser filters 250 are designed to prune out spurious parse trees generated by the parser 230 , by removing trees that violate either statistical or ontological criteria for well - formed - ness .While several types of parser filter are set forth above , other filters may be included , such as a selectional restriction filter and a parse probability filter .Similar to the lexer filters 150 , the parser filters 250 may be chained together to form a list of filters to be applied to each candidate parse tree .", "label": "", "metadata": {}}
{"text": "Since each parse filter 250 may alter or veto each candidate parse tree , each parse filter 250 must expect this possible behavior from the previous filter in a chain .A selectional restriction filter vetoes any parse tree where there are conflicts between the selectional features of the concepts serving as arguments to another concept and the restrictions of that concept .Selectional restrictions are imposed on the argument positions of predicate structures .The filter checks the selectional features of the concepts , which could fill the argument slots , to see if they are compatible .This operation may be accomplished in several ways : .", "label": "", "metadata": {}}
{"text": "They must share the same hierarchy of features up to the point of the restriction .Consider a sample path through an ontology : .In this example , if the argument position of a predicate must be an example of transportation , then any of the three more - specific words will be an acceptable argument for the predicate .However , it will take multiple iterations through the hierarchy to discover this fact .Similarly , the filter would need to check twice to determine that \" car \" is in agreement with \" transportation , \" and once for \" vehicle . \"", "label": "", "metadata": {}}
{"text": "Suppose we assign to the same sequence of concepts the set of numbers : .We can then subtract numbers to see if the features are in agreement , and a non - negative result suffices to prove this .Since 1 is nonnegative , we know that the features are in agreement .If concepts are identical , they will subtract to zero , which is equivalent to passing the filter by having two identical strings .This result is negative , so the parse would be rejected because of feature incompatibility .The parse probability filter vetoes parse trees that fall below a minimum probability for valid semantic interpretation .", "label": "", "metadata": {}}
{"text": "Certain rules are more probable than others .However , appropriate probabilities for each rule can only be determined by experimentation .In the initial version , probabilities will be assigned by linguistic intuition ; as iterations of the design progress , probabilities will be determined through experimentation .Since sentence probabilities are generally very small numbers , the parse probability filter should pass any parse tree with a probability of at least 30 % of the highest probability parse .Parse trees may be useful in some applications , and thus an interface is provided to output parse trees directly .", "label": "", "metadata": {}}
{"text": "The predicate structures may be used by any application , which incorporates the present invention .The modular design of the ontological parser permits the use of any part - of - speech - tagged ontology , with only minimal rewriting of the lexer and parser to accommodate format - specific issues .However , maximum benefits are recognized through the use of a parameterized ontology , an innovation heretofore unavailable in any parser or information retrieval system .Ontologies are hierarchies of related concepts , traditionally represented by tree structures .These trees are implemented via a variety of techniques , which are generally equivalent to doubly - linked lists .", "label": "", "metadata": {}}
{"text": "That is , the pointer to the node previous to the head contains the address of the head , and the pointer to the node after the tail contains the address of the tail .This structure guarantees that an arbitrary number of nodes may be inserted into the list without losing track of the locations of existing nodes , as well as enabling the list to be searched from either the top or bottom .However , the great flexibility of tree data structures , which may encompass trees of arbitrary depth , also imposes a significant cost in computability .", "label": "", "metadata": {}}
{"text": "Knowledge bases contain instances of real data , which represent a location somewhere within the ontology .Validating the equivalence of an instance with a concept in an ontology entails comparing the features of an instance with the features of a concept .Since algorithms to compare these features must be general enough to cover the potentially arbitrary number of levels from the root of the ontology to the feature in question , they can not be optimized to compare such trees in a single operation .Instead , they must traverse the list of links and compare structures on a node - by - node basis to guarantee identity .", "label": "", "metadata": {}}
{"text": "This entails even more general - purpose algorithms for logic programming , as several branches of a tree need to be followed .The result is that the time complexity of structure - comparison algorithms attains the polynomial order of the number of features ( or nodes ) being compared .This fact makes the use of ontologies inefficient for high - performance computing applications , such as searching terabyte - sized databases with wide - ranging conceptual content .A crucial assumption may be used to define the problem so that algorithms can be designed much more efficiently to compare structures .", "label": "", "metadata": {}}
{"text": "When the ontology is applied to natural - language processing applications , such as indexing web pages for a search engine , it will only be able to assign feature structures to those words , which are instances of concepts already in the ontology .Crucially , a limitation of this assumption is that substantially more effort must be applied in crafting the ontology , since re - indexing large volumes of text becomes extraordinarily expensive as the text grows .The designers of a parameterized ontology must be certain that their coverage is adequate before making a decision to freeze the structure .", "label": "", "metadata": {}}
{"text": "A key to intelligent design is leaving room for expansion .As long as the maximum depth of trees is not reached , adding additional levels is transparent .The trade - off in a parameterized ontology is selecting the size of a data structure so that it is no larger than it needs to be , but with adequate room for correcting mistakes or expanding coverage later on .It is possible to mitigate the risk entailed in reengineering a parameterized ontology by mapping the old structure to a new one , and simply writing a translation routine to recode existing data into the new form .", "label": "", "metadata": {}}
{"text": "The following is a suggested implementation .The proposed data structure includes an integer value , where each digit of the integer corresponds to a specific branch taken at the corresponding level in the tree .For example , if an array with 10 elements , all of which were base-10 integers , was defined to be the representation of an ontology , a maximum of 10 10 ( 10 billion ) distinct concepts could be defined .The above data structure naturally lends itself to one particular algorithm for comparing the identity or subsumption of ontological features .The algorithm relies on the implementation of the tree by associating with each node in the tree an integer value that represents the position of that node within the hierarchical structure .", "label": "", "metadata": {}}
{"text": "4 .Each arrowhead in .FIG .4 represents a concept node .The deeper into the tree ( i.e. , the higher the numbered level of the concept node ) , the more specific the concept is .Consider one path through FIG .4 .The path starts at the root node ( Level 1 ) and takes the 2nd branch to level 2 , then takes the 3rd branch from that node to get to level 3 .The final \" 0 \" is a terminator , indicating that this particular node of the tree is not at the lowest possible level of the tree ; it does not necessarily indicate that no nodes branch from this level .", "label": "", "metadata": {}}
{"text": "Such a representation scheme gives each node in the tree a unique identifier that completely determines the relative place of that node in the tree structure .It also provides a simple way to compare relative positions of two discovered node instances .This is as simple as subtracting the value of one node identifier from the other .For example , in a search engine application , it may be useful to check whether or not a particular noun can serve as an argument of a predicate .The features of the noun should be more specific than the features of the argument position it is attached to .", "label": "", "metadata": {}}
{"text": "Similar features will have similar paths through the tree .Referring to .FIG .5 , an example is illustrated .Node A is represented with the decimal number \" 1212 . \"Node B is represented with the decimal number \" 1220 .\" The difference between Node A and Node B , taken digit - by - digit from left to right is \" 001- .\" It is worth noting that once the first digit difference is detected , there is no further need to compute remaining digits .They diverge at level 3 , the third digit in the representation , and thereafter lie along completely different sub - trees that do not intersect .", "label": "", "metadata": {}}
{"text": "If the ontological tree structure is carefully crafted , proximity within the tree should , in some measure , correspond to ontological proximity .Therefore , detecting the first digit difference , as above , gives a reasonable measure of the degree of ontological proximity of the two concepts .The closer the concepts are , the smaller the numerical value of the divergence .Thus , for example , the node to Node A 's immediate left , is represented by \" 1211 .\" When the difference comparison is made , it works out to be \" 0001 , \" which implies a correspondingly close ontological relationship between the two concepts .", "label": "", "metadata": {}}
{"text": "For example , consider a tree shown in FIG .7 .It is clear that in some cases , it is useful to know the distance between words , but that it is not equally useful in all cases .However , since neither of these terms shares any properties beyond \" organic \" with \" amino acid , \" it is not helpful to know the distance between \" bread \" and \" amino acid , \" even though they are only one level apart .This makes the utility of the numerical encoding scheme as a parsing tool clearer .", "label": "", "metadata": {}}
{"text": "The argument position for each predicate structure may be tagged with codes from any level of the ontology .The parser will only output predicate structures where the noun inherits at least those features specified by the code .For example , the object of the verb \" eat \" is usually a type of food .A predicate structure built from \" eat \" might thus require that the object of the predicate have a code beginning with \" 112 .\" As can be seen from the tree shown , it is clear that all the foods listed inherit the \" 112 \" prefix .", "label": "", "metadata": {}}
{"text": "The difference is simply a digit - by - digit comparison that starts with the most significant bit and continues until the first decimal digit difference is located .Importantly , though , the differences due to inheritance along incompatible sub - trees do not correspond to elements of natural - language meaning .Thus , to use the example above , even though \" amino acid \" and \" food \" differ by the same order of magnitude from \" organic , \" they are not synonymous , and applications making use of this coding must be aware of this fact .", "label": "", "metadata": {}}
{"text": "Larger values from the subtraction operation mean further distance apart in the tree , so even when two concepts are in the same branch , the representation provides a convenient metric of conceptual distance .The results from the feature - comparison operation could be used in a ranking algorithm so that smaller differences receive higher relevance rankings .However , it is clear from the tree above that not all differences are equally meaningful .In order for the magnitude of the difference to be relevant , it must first be the case that one of the concepts inherits all the properties of the others .", "label": "", "metadata": {}}
{"text": "A 10-digit decimal number allows 10 10 , or 10 billion possible concepts to be stored in the tree .That is a sufficient number of total concepts , but the branching factor is too small .There can be a maximum of ten possible branches out of each node to the next level .As an example of the problem inherent in this limit , consider the concept \" move . \" As a more specialized example , consider a warfare ontology .Consequently , ten is too small to constrain the branching factor for each level .", "label": "", "metadata": {}}
{"text": "Thus , using a 16-digit ( i.e. , a 64-bit ) hexadecimal number gives 16 branches at each node for 16 levels : 16 16 possible concepts .In addition to eliminating the need to do binary - to - decimal conversions , such a hexadecimal representation stores more concepts than any reasonable ontology will ever need .Despite such an improvement over a decimal representation , the branching factor of only 16 is still unacceptably small .A solution to this is to use a modified hexadecimal representation .Since it is unlikely that a reasonable , specialized ontology will need more than eight levels of general concept representation , a 16-digit hexadecimal number can be interpreted slightly differently , as an octet of hexadecimal pairs : .", "label": "", "metadata": {}}
{"text": "This representation also provides optimized execution of the difference comparison , since using hexadecimals instead of decimals optimizes the logical digit - by - digit comparison to a computer - efficient byte - by - byte comparison .It should also be noted that the above examples of decimal , hexadecimal , or multi - digit hexadecimal are typical parameter choices for the node encoding included in the present invention .The specific parameters chosen do not alter the conception of the invention , which is the numerically encoded ontology tree .For example , another possible encoding of the ontology tree might involve a 40-digit decimal number .", "label": "", "metadata": {}}
{"text": "One other factor that should be considered is whether these node representation values should be computed on the fly as the tree is traversed or whether they should be stored at each node .It would certainly be possible to compute these dynamically , since any tree - search algorithm must keep track of which branches it traverses in trying to locate a particular node .However , as the search backtracks and corrects its path a fair number of adjustments and recalculations of the current node value would likely result .The trade - off is to store at each node the relative position of the node in the tree via the 16-digit hexadecimal number .", "label": "", "metadata": {}}
{"text": "For a 10,000-concept tree , this is only 80 KB .For a 100,000-concept tree , it is 800 KB .And for a 1,000,000-concept tree , it is 8 MB .Regardless of whether the values are maintained statically or dynamically , it is clear that both implementation details fall within the spirit and scope of the invention .It should be readily apparent that the ordering of elements of the code can be arbitrary , but must be used consistently in order to compare features .There are two ways to construct a parameterized ontology .", "label": "", "metadata": {}}
{"text": "This method allows rapid bootstrapping of existing ontologies to higher levels of performance , although it will preserve any redundancies and inefficiencies in the original construction .The second method is to perform research from the ground up in defining an ontology , assigning elements on an as - needed basis .Since minimal representation size is a main goal of parameterizing the ontology , one would want to eliminate many of the redundancies found in general - purpose ontologies such as WordNet .For example , WordNet provides a concept for \" run \" which is derived from \" move , \" and another concept for \" run \" which is derived from \" leave / go away , \" where the two parent concepts are in no way linked .", "label": "", "metadata": {}}
{"text": "A compromise approach is to attempt to make judgments about redundancy , and write software to merge branches as specified by the judgments of a knowledge engineer .This requires the creation of a table of equivalent branches and tree depths , and requires substantial knowledge engineering time , but not as much as attempting to create an ontology from the ground up .The following is an example of a sentence and demonstrates both how it is parsed as a sentence within a document , and how a question to an information retrieval system would produce matching predicates to retrieve the document containing this sentence .", "label": "", "metadata": {}}
{"text": "The example sentence is : .The octopus has a heart .First , the sentence lexer 100 would process this sentence .The first component of the sentence lexer 100 , the document iterator 110 , would extract this sentence from the document it was contained in .At this stage , it would exist as the text string shown above .Following that , it would be passed to the lexer 120 , which would access the ontology 140 , and return the sequence : .The - det octopus - noun have - verb a - det heart - noun .", "label": "", "metadata": {}}
{"text": "The other tags , noun and verb , indicate parts of speech with ontological content .Thus , when the sentence passes through the lexer filters 150 as discussed in the previous example embodiment , the stop word filter removes \" a \" and \" the , \" leaving : . octopus - noun have - verb heart - noun .The sentence is then taken up by the sentence receiver 210 , which passes it to the parser 220 .In the parser 220 , the tree shown in .FIG .6 is produced .The parse tree converter 230 then converts this tree into a predicate , where octopus is the subject of have , and heart is the object .", "label": "", "metadata": {}}
{"text": "In this sample embodiment , this predicate is then passed through the parser filters , where it successfully passes the parse probability and selectional feature compatibility tests .In the foregoing example , \" have \" is a verb unlikely to have any selectional restrictions on arguments .Following filtering , the predicate can be used within any application which benefits from the ability to manipulate natural language .Suppose that a user of a search engine which makes use of this parser asks the question : .Do octopuses have hearts ?The sentence lexer 100 will read the question , and a sentence made of ontological entities is produced .", "label": "", "metadata": {}}
{"text": "Do - verb octopus - noun have - verb heart - noun .In the preferred embodiment 's lexer filters , the pseudo predicate filter removes the first verb \" do , \" because it is not the main verb of the sentence . \"Do \" only serves to fill a grammatical role within this type of question , and is thus removed , leaving : . octopus - noun have - verb heart - noun .This is identical to the sentence produced above , and results in the same parse tree , and the same predicate structure .", "label": "", "metadata": {}}
{"text": "In this way , the parser enables information retrieval using natural language .Having described several embodiments of the concept - based indexing and search system in accordance with the present invention , it is believed that other modifications , variations and changes will be suggested to those skilled in the art in view of the description set forth above .It is therefore to be understood that all such variations , modifications and changes are believed to fall within the scope of the invention as defined in the appended claims .Dunja Mladinic , Turning Yahoo into an Automatic Web Page Classifier , ECAI 98:13th European Conference on Artificial Intelligence , Brighton , UK , Aug. 23 to Aug. 28 , 1998 , pp .", "label": "", "metadata": {}}
{"text": "Apparatus and method for managing and inferencing contextural relationships accessed by the context engine to answer queries received from the application program interface , wherein ontology manager is operationally coupled with a working memory Pedestrian Tracking Solution Combining an Impulse Radio Handset Transmitter with an Ankle - Mounted Inertial Measurement Unit .CEA - Leti Minatec Campus , 17 rue des Martyrs , 38054 Grenoble Cedex 09 , France .Received 16 December 2011 ; Accepted 17 May 2012 .Copyright \u00a9 2012 Joe Youssef et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}}
{"text": "We address the indoor tracking problem by combining an Impulse Radio - Ultra - Wideband handset with an ankle - mounted Inertial Measurement Unit embedding an accelerometer and a gyroscope .The latter unit makes possible the detection of the stance phases to overcome velocity drifts .Regarding radiolocation , a time - of - arrival estimator adapted to energy - based receivers is applied to mitigate the effects of dense multipath profiles .A novel quality factor associated with this estimator is also provided as a function of the received signal - to - noise ratio , enabling us to identify outliers corresponding to obstructed radio links and to scale the covariance matrix of radiolocation measurements .", "label": "", "metadata": {}}
{"text": "In the proposed fusion strategy , processed inertial data control the filter state prediction whereas Combined Time Differences Of Arrival are formed as input observations .These combinations offer low computational complexity as well as a unique filter structure over time , even after removing outliers .Experimental results obtained in a representatively harsh indoor environment emphasize the complementarity of the two technologies and the relevance of the chosen fusion method while operating with low - cost , noncollocated , asynchronous , and heterogeneous sensors .Introduction .For the last past years , new location and tracking ( LT ) needs have been gradually introduced into a wide variety of applications , such as security , health care , rescue , logistics ; or house automation .", "label": "", "metadata": {}}
{"text": "In this context , alternative technologies are currently under investigation , based on for example , location - enabled wireless networks [ 1 , 2 ] .On their own , most of modern wireless networks can indeed retrieve the positions of mobile radio devices relative to the known position of reference anchors or base stations ( BS ) .The radiolocation functionality simply relies on the measurement of radio metrics , which depend on the distance traveled in the air by transmitted signals .For instance , when a mobile radio device is synchronized with a BS ( e.g. , using n -way ranging protocol transactions [ 3 ] ) , range information can be derived from the time of arrival ( TOA ) of the received signal .", "label": "", "metadata": {}}
{"text": ", spherical ) location estimation problem in 2D ( resp . , 3D ) .Alternatively , if the surrounding BSs are strictly synchronized ( i.e. , independently of the clock of a mobile transmitter ) , the time difference of arrival ( TDOA ) can be considered , leading to a hyperbolic problem formulation .However , despite the claimed fine properties of IR - UWB signals , obstructed radio links notoriously introduce additional biases and high dispersion onto measurements , for example , when direct paths are blocked , or when transmitted paths are severely attenuated and shifted in time [ 3 ] .", "label": "", "metadata": {}}
{"text": "One more point would be to evaluate the instantaneous quality of TOA estimates , or even to efficiently remove measurement outliers due to NLOS to assist and enhance the fed LT algorithms .But it is also well known that radiolocation solutions operating in harsh radio environments could benefit from external means , like assisting inertial navigation systems ( INSs ) based on inertial measurement units ( IMUs ) .In a navigation scenario , one INS can deliver relevant information out of raw inertial measurements for example , the pedestrian displacement amplitude , velocity , or heading [ 10 - 12 ] .", "label": "", "metadata": {}}
{"text": "Finally , coupling low - power and low - cost technologies particularly makes sense for the perennial and massive deployment of such systems .This implies the use of adequate radio technologies with energy - efficient transceiver design , reasonably simple inertial units ( i.e. , with a limited number of embedded sensors ) , and low - computational complexity for further postprocessing ( including data fusion tasks ) .In this context , we address herein the pedestrian navigation problem in indoor environments that present dense multipath profiles and magnetic perturbations , by loosely coupling an IR - UWB handset transmitter with a shoe - mounted IMU endowed with a 3-axis accelerometer and a 3-axis gyroscope .", "label": "", "metadata": {}}
{"text": "Adapting and extending previous results from [ 19 ] , this formulation also combines UWB measurements ( obtained through the method proposed in [ 20 ] ) into new observations defined as combined TDOA ( CTDOA ) .While reducing filter complexity ( as a function of the number of available measurements ) , the proposed solution allows us to remove outlier measurements , without reconfiguring the whole filter structure and without omitting relevant measurement information .The selection of nonoutlier measurements is performed by monitoring the instantaneous quality of TOA estimates , based on a new practical SNR - dependent indicator .", "label": "", "metadata": {}}
{"text": "The obtained pedestrian heading and average body velocity subsequently feed the fusion filter to control the state prediction phase .Indoor experiments were carried out to validate the proposed fusion approach , as well as to draw intermediary statistical UWB channel parameters useful to TOA estimation .The paper is structured as follows .In Section 2 , we present a selection of techniques and concerns from the recent state of the art in the fields of IR - UWB TOA - based ranging , inertial navigation systems , and the fusion of both modalities .We also try to position the main contributions of this paper in comparison with existing solutions .", "label": "", "metadata": {}}
{"text": "Then a robust TOA estimator adapted to energy detection receivers is recalled .We also show how to practically evaluate the quality of this estimator and to remove outlier measurements , from a filter - oriented perspective .In Section 4 , we present our INS , which basically consists of an ankle / foot - mounted magnetometer - free IMU .In particular , we show how to use detected stance phases to remove the drift on INS velocity and infer the average body velocity .In Section 5 we detail and justify further our loosely - coupled fusion strategy , along with the corresponding filter structure .", "label": "", "metadata": {}}
{"text": "Finally , Section 7 concludes the paper .Related State - of - the - Art and Paper Contributions .Impulse Radio - Ultra - Wideband Time - of - Arrival Estimation .Many solutions have been described in the literature to cope with IR - UWB TOA estimation , including sophisticated algorithms inspired by former high - resolution channel estimation solutions [ 6 ] requiring high sampling rates .More recently , various other techniques adapted to the low - complexity LDR context have been proposed and compared ( e.g. , [ 7 ] ) .A specific focus is usually made on noncoherent receivers like energy detectors ( ED ) , for which one simple approach consists in comparing the energy collected in consecutive time bins with an appropriate detection threshold .", "label": "", "metadata": {}}
{"text": "Unfortunately , within realistic indoor channels , threshold - based ED suffers from overlapping multipath components ( MPC ) and poor signal - to - noise ratio ( SNR ) conditions , introducing significant estimation errors and biases .One weakness of these methods is that they do not take benefit from the whole MPC profile ( though conveying constructive information ) , but they only depend on marginal and independent energy terms .Therefore , new TOA estimators have been proposed very recently in [ 20 ] , assuming realistic path amplitude statistics in compliance with IEEE 802.15.4a recommendations [ 22 ] , and considering the whole observed energy profile before making a decision on the estimated TOA .", "label": "", "metadata": {}}
{"text": "But one more challenge is to allow the real - time prediction of TOA estimation uncertainty or dispersion .A relationship could then be established a priori between the error affecting the measured TOA and the SNR through simulations , experimental campaigns , or even theoretical analysis ( e.g. , [ 23 ] ) .However , this kind of method can hardly benefit from the specificities of the received signal at each instant ( e.g. , of the current multipath energy profile ) under mobility .As an example , under given SNR conditions , the received signal could have either sparse or dense multipath profile , which directly impacts the reliability of the estimated TOA .", "label": "", "metadata": {}}
{"text": "Hence a new practical method is still required to associate the instantaneous TOA estimation quality with practical estimators ( e.g. , [ 20 ] ) .Inertial Navigation Systems .INSs based on integrated IMUs are more and more used for navigation purposes due to their low cost , low weight , and low consumption .Moreover , as stand - alone autonomous solutions , they can be used indifferently in indoor or outdoor situations , in the lack of surrounding means or infrastructure .They can also be considered for dead reckoning navigation ( DRN ) ( i.e. , estimation of the current position from a known starting point ) when any absolute positioning system or GNSS is not available , ensuring the navigation service continuity .", "label": "", "metadata": {}}
{"text": "Such units , available as commercial devices now [ 24 ] , are intended for numerous applications such as motion capture , unmanned vehicular control , antenna stabilization , video gaming , and pedestrian navigation .Those IMUs provide metrics related to acceleration , orientation , magnetic field , and angular rate .The raw measurements must be processed and analyzed further in order to get relevant navigation information , such as the direction , displacement , speed , and so forth .In the specific pedestrian navigation context , DRN systems rely on step detection and , for each detected step , on length and heading estimation [ 25 ] .", "label": "", "metadata": {}}
{"text": "For step length estimation , two kinds of approaches can be considered .One approach is based on an empirical model linking the step length with some parameters extracted from the sensors measurement during the step [ 28 , 29 ] .The advantage of this approach is that the models can be adapted to any placement of the IMU .The disadvantage is that a calibration is needed for each pedestrian .A second approach uses the integration of the gyroscope and the accelerometer raw data .Nevertheless , even small errors on the measurements would lead , after integration , to a large error cumulated over time .", "label": "", "metadata": {}}
{"text": "Other methods enable to limit the drift of foot - mounted INSs [ 30 ] .As no calibration is needed and drifts are limited , this kind of method leads to better performances than empirical methods .However , the IMU has to be placed on the foot in order to benefit from zero velocity .For heading estimation , magnetometers can be used .But they can be subject to local magnetic disturbances induced by pieces of furniture , buried or on - body metallic materials .Those perturbation are particularly present near walls and floors , making hazardous the use of foot - mounted magnetometers in typical indoor environments .", "label": "", "metadata": {}}
{"text": "Three different fusion strategies can be applied to merge heterogeneous data in a tracking context .The first one is the so - called decoupled strategy , for example [ 13 ] : the mobile node position is estimated separately and independently by each subsystem and then the set of estimated positions ( delivered by independent systems ) is fused into one final solution .This strategy is preferably applied when both location systems are not subject to drift , or when raw data are not available .The second strategy is tightly coupled , for example [ 15 ] : some raw data are available at each subsystem , which are processed at once to track the location .", "label": "", "metadata": {}}
{"text": "The tightly coupled fusion seems to be the best method at first sight since it enables to jointly optimize the output estimate given all the available data .However , these solutions require that the involved subsystems are physically collocated or rigidly connected , what is neither necessarily relevant nor practical for inertial - based pedestrian navigation .Finally , the synchronization issue between subsystems , which is inherent to any fusion strategy , is all the more critical within these tightly coupled solutions .The last fusion strategy is loosely coupled , for example [ 16 , 17 ] : the inputs to the location estimator can be raw and/or preprocessed data issued from sub - systems .", "label": "", "metadata": {}}
{"text": "It tolerates that the radio part includes a controlling module to remove outlier measurements and/or to adjust the assumed quality of radio measurements .Finally , this loosely - coupled strategy enables different placements of the involved subsystems .But another feature of navigation fusion filters concerns the way the IMU data are exploited .In a first approach , the inertial data are used in the prediction phase of the filter [ 17 ] .In the second one , they are integrated as observations in the correction phase [ 16 ] .In the following , we will provide detailed justifications for retaining a loosely - coupled scheme based on EKF and using inertial data in the prediction phase of the filter , given our system architecture constraints .", "label": "", "metadata": {}}
{"text": "The slots are numbered starting from slot .To verify these model assumptions and characterize key channel parameters , a channel measurement campaign was carried out in the indoor environment described in Section 6.1 for our tracking experiments .Averaging over all the measured channel profiles , an exponential model was fitted to the empirical average power decay , and an empirical function was drawn for the path presence probability , depending on the channel excess delay ( or time index , equivalently ) .To get a better fit of the power decay to our measurements , we preliminarily conditioned received energy upon the presence of a path in each slot so that the slots with no detected path energy were not taken into account in the average .", "label": "", "metadata": {}}
{"text": "According to [ 22 ] , each received profile realization is affected by a distinct shadowing effect .Thus , the measured channel profiles were normalized in power before averaging .Figure 2 represents the exponential power decay model .the theoretical cumulative density function ( CDF ) of the normalized path energy satisfactorily fits to the empirical one computed out of our experiments .In the following , the exponential power decay and Nakagami- .parameters , as well as the probability of path presence as a function of the excess time index , are used as prior information to feed our TOA estimator .", "label": "", "metadata": {}}
{"text": "TOA Covariance Estimation .We now intend to provide an indicator reflecting the quality of energy - based TOA estimation .For this purpose , we rely here on the instantaneous SNR of the received signal .First , the noise power spectral density . can be rather straightforwardly estimated in the absence of transmitted signal .Thus we assume that it is available on the receiver side .One ideal solution would consist in jointly estimating the SNR and the TOA .However , for the sake of practicability and simplicity , it is chosen to estimate the SNR first out of all the collected normalized energy samples .", "label": "", "metadata": {}}
{"text": "Figure 4 shows the RMSE of the estimated TOA as a function of .Measurement Outliers Detection and Discarding . , assuming unbiased estimated TOAs .Unfortunately , most of NLOS situations result in biased estimates .From a tracking filter perspective , a first approach to mitigate harmful NLOS effects consists in increasing the diagonal elements of the measurement covariance matrix .Different solutions can also be used to detect NLOS outliers , for instance based on innovation tests [ 15 , 16 ] .In this case , the innovation is related to the difference between the current observation and the predicted one , computed under an unbiased hypothesis .", "label": "", "metadata": {}}
{"text": "Moreover , in some scenarios , severely obstructed NLOS situations might also coincide with situations where the location information is adversely conditioned , for instance due to a poor geometrical dilution of precision ( GDOP ) .In this case , the values in the predicted state covariance matrix are so large ( and so are the values in the covariance matrix of predicted measurements ) that outliers can hardly be detected through simple innovation tests .Another method is to preliminarily identify the channel state LOS / NLOS based for example , on collected channel energy [ 37 , 38 ] .", "label": "", "metadata": {}}
{"text": "Whatever the detection method , outliers can be discarded before the location estimation step [ 15 ] independently of the latest state estimate .In our context , as ED receivers naturally provide access to the channel energy profile , the last approach is considered .One indicator of the channel status ( and hence indirectly of potential TOA estimation biases ) is conditioned on the received signal energy as follows : .Inertial Navigation System .As already pointed out in Section 2.2 , it is better to place the INS on the foot in order to benefit from ZUPT resetting methods [ 10 ] or other update methods [ 30 ] .", "label": "", "metadata": {}}
{"text": "Then we assume a foot / ankle - mounted IMU with a triaxis gyrometer and a triaxis accelerometer only .First , two main frames are defined : ( i ) the body frame ( BF ) is the frame in which raw data are measured .BF data are referred to their definition frame with .Since no magnetometer is used , it is not possible to estimate the orientation of the sensor with respect to the North .Hence the navigation frame includes a rotation around the vertical axis with respect to the North frame defined by the East , North , and Up orientations .", "label": "", "metadata": {}}
{"text": "Vertical axis ( orthogonal to the horizontal plane ) is given during the stance phase by the measurement of the accelerometer .Let . , denoting the orientation of the NF in the BF using the relation given in the appendix .Initial orientation with respect to the vertical axis is given , at the beginning of the walk and during the stance phase , by the accelerometer measurement .Considering our definition of the NF , with respect to horizontal axis , initial orientation is set to zero .Then , as the gyroscope measures the angular rate , . can be estimated by integrating its raw data .", "label": "", "metadata": {}}
{"text": "Then the raw data issued at the accelerometer can be written as .corresponds to the derivative of the velocity and to the second derivative of the position .The velocity can hence be estimated by integrating this proper acceleration .In order to limit the drift due to noise or bias integration , it is necessary to detect correctly the stance phase and suppose the velocity is null during this phase , as proposed within the ZUPT method [ 10 ] .Stance Phase Detection .Many step detection methods are proposed in the literature .For instance , in [ 39 ] the step detection method is based on the Fourier transform through counting zero - crossing points over a threshold of the accelerometer output .", "label": "", "metadata": {}}
{"text": "Then , the beginning and the end of the step can be defined according to this detected pattern .In [ 27 ] several other methods are also compared .In the scenario considered here , the pedestrian is assumed to be walking in a building , moving from one room to another one with some stops and a direction that may change after a few steps .The pedestrian can not walk very quickly , thus the stance phase of his foot is large enough to be easily detectable .A simple method used to detect the stance phase consists in comparing the acceleration variance to a threshold .", "label": "", "metadata": {}}
{"text": "To overcome this problem , as .IMU Proper Acceleration . )Then the acceleration has to be integrated only during this time interval , whereas during the remaining time , the velocity is set to zero .Thus , the velocity of the pedestrian ankle is computed step by step , whereas the orientation of the NF in the BF at time index . in ( 17 ) compensates at the same time the gravity and the velocity bias .Inertial Support to Pedestrian Navigation .Our aim is to continuously compute the ankle velocity of the pedestrian together with his heading .", "label": "", "metadata": {}}
{"text": "Since during the stance phase the velocity is set to zero , then the velocity is computed separately for each step with .Unlike in [ 10 ] , the velocity here is continuous between different gait phases after centering the acceleration in ( 17 ) during the swing phase of each step .Thus , the computed IMU velocity in ( 18 ) starts at zero and ends up at zero .We consider that the pedestrian walks on a flat floor .The pieces of horizontal information of the ankle velocity and heading are then given as follows : .", "label": "", "metadata": {}}
{"text": "Hence , the pedestrian waist experiences almost a constant velocity , whereas the ankles experience high velocity variations alternating between maximum and null speed values .As the horizontal waist velocity of the pedestrian does not vary as much as the ankle velocity , then we compute the waist velocity . are the two processed inertial data simultaneously incorporated into the tracking filter , contrarily to the loosely - coupled fusion strategies in [ 16 , 17 ] , where the IMU is used only for heading and step detection .Furthermore , in our proposal , there is no need to have the same pedestrian heading and displacement orientation .", "label": "", "metadata": {}}
{"text": "Moreover , there is no need to estimate the step length as in [ 16 , 17 ] or to calibrate the leg length as in [ 40 ] .Tracking Problem Statement and Fusion Filter Formulation .In the considered scenario , we remind that inertial sensors are attached on the ankle , whereas the pedestrian holds in his hands an IR - UWB transmitter , and .refer to the Cartesian coordinates .For this purpose , we consider using an Extended Kalman Filter ( EKF ) , which is widely used in mobile tracking applications .After recalling the general EKF formulation in Section 5.1 , we will then justify our overall fusion strategy in Section 5.2 .", "label": "", "metadata": {}}
{"text": "Generic Extended Kalman Filter Formulation .We start formulating the tracking problem with the following generic state equation .with the EKF is typically split in two steps , namely the state prediction and the state update , which rely , respectively , on the dynamic state equation in ( 20 ) and the observation equation in ( 21 ) .( a ) Prediction : .Overall Fusion Strategy and Filter Structure .In Section 2.3 , we presented \" decoupled , \" \" tightly coupled , \" and \" loosely coupled \" options as three different fusion strategies to merge radio and inertial subsystems into a single navigation solution .", "label": "", "metadata": {}}
{"text": "For instance , the pedestrian can hold the UWB transmitter in his hand , avoiding many near - floor obstacles , and increasing visibility with respect to anchor nodes , whereas a foot - mounted IMU can take advantage of ZUPT to overcome the INS velocity drift .Moreover , with the \" loosely coupled \" strategy , each drift - free observation issued from the UWB subsystem can be used to limit the INS drifts .For instance , in our application , the UWB rate is applied to the correction phase , whereas the inertial rate is applied to the prediction phase .", "label": "", "metadata": {}}
{"text": "The raw inertial data are preprocessed as described in Section 4 to get pedestrian velocity and heading as inputs to the filter prediction phase .In parallel , IR - UWB TOA measurements are delivered at each receiver with their estimated variance , as computed in Section 3.3 .In the update part of the filter , specific combinations of such measurements are performed , as introduced in [ 19 ] , enabling us to remove outliers using the indicator presented in Section 3.4 without changing the filter structure ( e.g. , the size of involved matrices ) .receivers are synchronized , but independently of the mobile transmitter , so that all the pseudo - TOA measurements are biased by a common unknown delay .", "label": "", "metadata": {}}
{"text": "It is hence worth noting that the most significant part of EKF complexity results from filter gain computations , which directly depend on the size of the observation vector .Hence we consider using the combination - based observations proposed in [ 19 ] to reduce the number of observation functions from the number ., while maintaining a constant filter architecture as a function of time .Within a more classical filter formulation , this would lead to change the size of the filter gain matrix , whereas this size is constant in our proposal and only dependent on .", "label": "", "metadata": {}}
{"text": "Experimental Setup .m - long round - trip path in two rooms and a corridor , referring to visual markers on the floor .The pedestrian was holding an IR - UWB transmitter in his hand and an IMU was attached to one of his ankles , in compliance with the fusion scenario and system architecture considered so far .We used inertial data from a 3A3 G IMU at the sampling rate . ns ( i.e. , for the duration of the ED observation window ) .Then the ED - based TOA estimation method described in Section 3.2 was applied to the acquired signals .", "label": "", "metadata": {}}
{"text": "The four DSO Rx channels were triggered synchronously but affected by the same unknown delay , which could vary from one acquisition to the next , hence requiring CTDOA as observations in the tracking filter , as previously mentioned .Finally , the UWB acquisition rate was not constant , and reached .Evaluation Procedure and Algorithms Benchmark .Five different estimator settings , depicted as so - called \" scenarios \" in the following , were tested and compared : ( i ) scenario .: EKF tracking fusing IR - UWB and INS data as in Section 5 , that is , idem as scenario 3 , with INS outputs controlling the filter state prediction ( with predictions of the IMU frequency and updates whenever UWB measurements are available ) .", "label": "", "metadata": {}}
{"text": "As for the second performance indicator , we consider the difference between the real and estimated traveled distance ( over the entire back and forth trajectory ) , normalized by the real traveled distance .This second relative performance indicator gives an idea about the uncertainty on the overall trajectory length , what could be interesting in several applications besides navigation ( e.g. , sports analysis , activity monitoring in physical rehab or as dietetics support , etc . ) .Figure 8(b ) shows the estimated trajectory obtained within scenario 5 , where the location drift is now significantly reduced .", "label": "", "metadata": {}}
{"text": "Noting that . are in NLOS configurations in this first portion , thus the mobile could not properly correct the position drift until it gets sufficiently good pseudorange estimates .Consequently , the mobile gets closer to the real trajectory in the middle of the scene , and it even sticks to the real trajectory for the remaining part of the walk ( see e.g. , the trip back in straight lines ) .over the entire trajectory and in each room separately .The error is particularly large in Room B for a single IR - UWB radiolocation system ( i.e. , scenarios 1 to 3 ) .", "label": "", "metadata": {}}
{"text": "Comparing .( scenario 2 ) and removing further outlier measurements ( scenario 3 ) clearly help to reduce the error .As expected , fusing the two subsystems ( scenario . ) reduces systematically the overall error , even if the enhancement is far more spectacular in Room B in comparison with both scenarios 3 and 4 .These results open the floor to parsimonious fusion schemes , where one could switch from a stand - alone subsystem into the complete fusion - oriented system on demand , depending on the operating conditions , hence saving energy and complexity at the price of slight performance degradations . per actually traveled meter .", "label": "", "metadata": {}}
{"text": "Due to NLOS situations , a tracking system only based on IR - UWB would tend to overestimate the traveled distance mostly because of occasional but strongly biased TOA - based measurements , which lead to nonstraight and more erratic estimated paths .Omitting measurement outliers , the estimated traveled distance is significantly reduced , but still rather large .The use of INS then enables us to reduce significantly this error .Table 1 : Average estimated traveled distance per actually traveled meter , for different tracking scenarios .The previous results illustrate the complementarity of the two subsystems and the potential of the proposed fusion scheme , under the architectural constraints of noncollocated and asynchronous sensors .", "label": "", "metadata": {}}
{"text": "Conclusion .In this paper , we have addressed the problem of pedestrian tracking by coupling an IR - UWB transmitter handset with an ankle - mounted INS device .One motivation to couple these subsystems was to overcome their respective limitations in harmful operating indoor environments , while benefiting from their complementary capabilities .The raw measurements of each subsystem have been carefully studied , and new preprocessing techniques have been proposed before applying hybrid data fusion techniques .Regarding IR - UWB first , TOAs are estimated at low complexity energy - based receiver following a Bayesian approach .", "label": "", "metadata": {}}
{"text": "Real channel measurements have been carried out and exploited to validate a few statistical multipath parameters .As for INS , in order to limit the drift due to noise integration and avoid magnetic disturbances , we have considered one ankle - mounted IMU with a 3-axis gyroscope and a 3-axis accelerometer , whose measurements are processed to determine the pedestrian average velocity and biased heading .This ankle - mounted INS ( when considered with a UWB Tx handset ) obviously imposes further challenging constraints in terms of system architecture , while operating with noncollocated and asynchronous heterogeneous devices , hence impacting in turn the fusion strategy .", "label": "", "metadata": {}}
{"text": "Combined time difference of arrival [ 19 ] of nonoutlier TOA measurements are used as observation inputs to the filter , the observation covariance matrix being dynamically scaled thanks to the new practical TOA estimation quality indicator .The use of CTDOA enables to remove outliers without changing the low complexity structure of the tracking filter .The velocity and heading estimates issued at the IMU are taken into account into the filter during the prediction phase .This option enables us to take benefit from zero velocity information during the stance phase , as well as to operate under different sampling / refreshment rates for the IMU and IR - UWB subsystems .", "label": "", "metadata": {}}
{"text": "Overall , coupling both systems enables reliable and robust tracking with uniform quality of service over the scene .Finally , the possibility to apply parsimonious fusion schemes , hence saving energy and complexity at the price of slight performance degradations , has been pointed out and briefly discussed .Accordingly , one could switch from a stand - alone subsystem into the complete fusion - oriented system on demand , depending on the operating conditions ( i.e. , while experiencing generalized NLOS or generalized LOS , poor or favorable GDOP , etc . ) .Appendix .Acknowledgments .", "label": "", "metadata": {}}
{"text": "The authors also thank the reviewers for their valuable comments and suggestions .References . A. H. Sayed , A. Tarighat , and N. Khajehnouri , \" Network - based wireless location : challenges faced in developing techniques for accurate wireless location information , \" IEEE Signal Processing Magazine , vol .22 , no .4 , pp .24 - 40 , 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .K. Yu , I. Sharp , and Y. J. Guo , Ground - Based Wireless Positioning , IEEE Series on Digital & Mobile Communication , John Wiley & Sons , 2009 , 2012 DRAFT .", "label": "", "metadata": {}}
{"text": "54 , no .4 , part 2 , pp .1896 - 1910 , 2006 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . \" PART 15.4 : Wireless Medium Access Control ( MAC ) and Physical Layer ( PHY ) Specifications for Low - Rate Wireless Personal Area Networks ( LR - WPANs ) , \" IEEE Std802.15.4a-2007 , Amendment 1 , Add Alternate PHYs , 2007 .I. Guvenc , S. Gezici , and Z. Sahinoglu , \" Ultra - wideband range estimation : theoretical limits and practical algorithms , \" in Proceedings of the IEEE International Conference on Ultra - Wideband ( ICUWB ' 08 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .S. Gezici , Z. Tian , G. B. Giannakis et al . , \" Localization via ultra - wideband radios : a look at positioning aspects of future sensor networks , \" IEEE Signal Processing Magazine , vol .22 , no .4 , pp .70 - 84 , 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .I. Guvenc , S. Gezici , and Z. Sahinoglu , \" Ultra - wideband range estimation : theoretical limits and practical algorithms , \" in Proceedings of the IEEE International Conference on Ultra - Wideband ( ICUWB ' 08 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Fang , P. J. Antsaklis , L. A. Montestruque et al . , \" Design of a wireless assisted pedestrian dead reckoning system - the NavMote experience , \" IEEE Transactions on Instrumentation and Measurement , vol .54 , no .6 , pp .2342 - 2358 , 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . D. B. Jourdan , J. J. Deyst , M. Z. Win , and N. Roy , \" Monte Carlo localization in dense multipath environments using UWB ranging , \" in Proceedings of the IEEE International Conference on Ultra - Wideband ( ICU ' 05 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Scopus .J. D. Hol , F. Dijkstra , H. Luinge , and T. B. Sch\u00f6ny , \" Tightly coupled UWB / IMU pose estimation , \" in Proceedings of the IEEE International Conference on Ultra - Wideband ( ICUWB ' 09 ) , pp .688 - 692 , September 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .V. Renaudin , B. Merminod , and M. Kasser , \" Optimal data fusion for pedestrian navigation based on UWB and MEMS , \" in Proceedings of the IEEE / ION Position , Location and Navigation Symposium ( PLANS ' 08 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .J. Youssef , B. Denis , C. Godin , and S. Lesecq , \" New TOA estimators within energy - based receivers under realistic UWB channel statistics , \" in Proceedings of the IEEE 71stVehicular Technology Conference ( VTC ' 10 ) , pp . 1 - 5 , May 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . A. F. Molisch , D. Cassioli , C. Chong , et al . , \" A comprehensive standardized model for ultrawideband propagation channels , \" IEEE Transactions on Antennas and Propagation , vol .", "label": "", "metadata": {}}
{"text": "11 , part 1 , pp .3151 - 3166 , 2006 .View at Google Scholar . D. Dardari , C.-C. Chong , and M. Z. Win , \" Improved lower bounds on time - of - arrival estimation error in realistic UWB channels , \" in Proceedings of the IEEE International Conference on Ultra - Wideband ( ICUWB ' 06 ) , pp .531 - 538 , September 2006 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . A. Croci , M. De Agostino , and A. M. Manzino , \" A GNSS / INS - based architecture for rescue team monitoring , \" in Proceedings of the International Conference on Indoor Positioning and Indoor Navigation ( IPIN ' 10 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .I. Skog , J.-O. Nilsson , and P. Handel , \" Evaluation of zero - velocity detectors for foot - mounted inertial navigation systems , \" in Proceedings of the International Conference on Indoor Positioning and Indoor Navigation ( IPIN ' 10 ) , pp .959 - 969 , Zurich , Switzerland , September 2010 .View at Publisher \u00b7 View at Google Scholar .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . S. Miyazaki , \" Long - term unrestrained measurement of stride length and walking velocity utilizing a piezoelectric gyroscope , \" IEEE Transactions on Biomedical Engineering , vol .", "label": "", "metadata": {}}
{"text": "753 - 759 , 1997 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .N. Castaneda and S. Lamy - Perbal , \" An improved shoe - mounted inertial navigation system , \" in Proceedings of the International Conference on Indoor Positioning and Indoor Navigation(IPIN ' 10 ) , pp .934 - 944 , Zurich , Switzerland , September 2010 .View at Publisher \u00b7 View at Google Scholar .I. Guvenc and Z. Sahinoglu , \" Threshold - based TOA estimation for impulse radio UWB systems , \" in Proceedings of the IEEE International Conference on Ultra - Wideband ( ICU ' 05 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Scopus . D. Cassioli , M. Z. Win , and A. F. Molisch , \" The ultra - wide bandwidth indoor channel : from statistical model to simulations , \" IEEE Journal on Selected Areas in Communications , vol .20 , no .6 , pp .1247 - 1257 , 2002 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . Y. Bar - Shalom and T. E. Fortmann , Tracking and Data Association , Academic Press Professional , 1987 .K. M.-L. Saxena and K. Alam , \" Estimation of the non - centrality parameter of a chi squared distribution , \" The Annals of Statistics , vol .", "label": "", "metadata": {}}
{"text": "1012 - 1016 , 1982 .View at Google Scholar .S. Gezici , H. Kobayashi , and H. V. Poor , \" Non - parametric non - line - of - sight identification , \" in Proceedings of the IEEE 58th Vehicular Technology Conference ( VTC - Fall ' 03 ) , pp .2544 - 2548 , Orlando , Fla , USA , October 2003 .View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .Q. Ladetto and B. Merminod , \" In step with INS : navigation for the blind , tracking emergency crews , \" GPS World , vol .", "label": "", "metadata": {}}
{"text": "10 , pp .30 - 38 , 2002 .View at Google Scholar \u00b7 View at Scopus .V. Renaudin , O. Yalak , P. Tom , and B. Merminod , \" Indoor navigation of emergency agents , \" European Journal of Navigation , vol .5 , no . 3 , pp .36 - 45 , 2007 .View at Google Scholar Is anyone using a HAML implementation for PHP like phpHaml or pHAML ?Is it feasible / wise to use HAML for a large PHP application , or is it too immature ?Does anybody have experience with Chaml for CakePHP ?", "label": "", "metadata": {}}
{"text": "I really want to use HAML or something minimalistic like it , but I do n't want it to add another layer of debugging problems .Recommendations are welcome .3 Answers 3 .My expertise is not with HAML but with CakePHP so I can only answer part of your question .CakePHP is a tightly coupled framework so you either work with it or against it .If you wanted to use a different template engine such as HAML you 'd be better with a loosely coupled framework such as Code Igniter or Zend . deceze is intimately familiar with cakephp from the history of answers he has provided and his reputation score . -", "label": "", "metadata": {}}
{"text": "I just noticed that I did overlook the existence of Chaml in the original question , however my answer still remains in that it is more feasible to replace the view system in a loosely coupled framework .-Mathew Attlee Dec 4 ' 09 at 17:59 . :) - deceze Dec 5 ' 09 at 1:24 .Oh well , so in the meantime , I did start writing a small site using Chaml , which uses the phpHaml parser .First of all : HAML is so much fun !X- D .Second : phpHaml is still a little buggy .", "label": "", "metadata": {}}
{"text": "Inserting something on the following line removed the duplicate .This means you 're always required to double check you 're actually producing the markup you think you are .The Chaml plugin is working quite well , I have n't had any particular problems with it .The included SASS parser is not really worth talking about though , it 's experimental at best .Overall , HAML on PHP at this stage does add a slight debugging overhead , so I would n't recommend using it to just anybody .It may be worth it if you 'd have to type loads and loads of markup otherwise .", "label": "", "metadata": {}}
{"text": "It depends on how much of the HAML features you want to use .Most of them get simple HAML right .A novel indoor positioning solution is proposed in this work .An inertial navigation system ( INS ) is integrated with optical angle of arrival ( OAOA ) measurements to yield a smoother , more accurate , and robust positioning solution for indoor environments .An extended Kalman filter ( EKF ) is used to integrate the INS and OAOA measurements .Four different algorithms are proposed for the novel indoor positioning solution by INS / OAOA integration .", "label": "", "metadata": {}}
{"text": "In previous work , magnetometer error estimation was not included in the EKF state vector .In this work , magnetometer error estimation is added to the EKF state vector , and this reduced the average position error by 3.7 % to 7 % .Quaternion algebra is used instead of Euler angles due to the possibility of mathematical singularities for certain Euler angles .Quaternion vector estimation is performed by adding the quaternion vector to the state vector of the EKF .Both loosely coupled and tightly coupled integration strategies are explored for INS / OAOA integration .The tightly coupled strategy reduces the average positioning error by 60 % compared to an OAOA - only system while the loosely coupled strategy reduces the average error by 44 % .", "label": "", "metadata": {}}
{"text": "The loosely and tightly coupled algorithms are modified by augmenting the observation vector with a prior accelerometer bias estimate and a quaternion vector estimate .This results in loosely and tightly coupled algorithms with augmented observations .The algorithms with augmented observations perform significantly better , especially in a case of the low update rate for the OAOA sensor .An average position error of 4.89 cm is reduced to 3.11 cm by using the loosely coupled algorithm with augmented observations instead of the loosely coupled algorithm without observation augmentation .This is an improvement of approximately 36 % .", "label": "", "metadata": {}}
{"text": "However , where the update rate from the OAOA sensor is fast enough , no significant performance improvement is observed by using algorithms with augmented observations .Indoor Positioning through Integration of Optical Angles of Arrival with an Inertial Measurement Unit by Md.Shariful Islam 2012 Abstract A novel indoor positioning solution is proposed in this work .An inertial navigation system ( INS ) is integrated with optical angle of arrival ( OAOA ) measurements to yield a smoother , more accurate , and robust positioning solution for indoor environments .An extended Kalman filter ( EKF ) is used to integrate the INS and OAOA measurements .", "label": "", "metadata": {}}
{"text": "An error state Kalman filter is used for implementing all four algorithms .In previous work , magnetometer error estimation was not included in the EKF state vector .In this work , magne- tometer error estimation is added to the EKF state vector , and this reduced the average position error by 3.7 % to 7 % .Quaternion algebra is used in- stead of Euler angles due to the possibility of mathematical singularities for certain Euler angles .Quaternion vector estimation is performed by adding the quaternion vector to the state vector of the EKF .Both loosely coupled and tightly coupled integration strategies are ex- plored for INS / OAOA integration .", "label": "", "metadata": {}}
{"text": "However , the performance improvement of the tightly coupled system comes with an in- ii Abstract creased computational cost due to nonlinearities in the measurement model .The loosely and tightly coupled algorithms are modified by augmenting the observation vector with a prior accelerometer bias estimate and a quater- nion vector estimate .This results in loosely and tightly coupled algorithms with augmented observations .The algorithms with augmented observations perform significantly better , especially in a case of the low update rate for the OAOA sensor .An average position error of 4.89 cm is reduced to 3.11 cm by using the loosely coupled algorithm with augmented observations instead of the loosely coupled algorithm without observation augmentation .", "label": "", "metadata": {}}
{"text": "For the tightly coupled system , this improvement is approximately 32 % .However , where the update rate from the OAOA sensor is fast enough , no significant performance improvement is observed by using algorithms with augmented observations .iii Table of Contents Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .ii Table of Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "label": "", "metadata": {}}
{"text": "vii List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .ix List of Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xi Abbreviations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xvi Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . .", "label": "", "metadata": {}}
{"text": "11 2.1.2 Location Technologies , Techniques and Algorithms .11 2.1.3 Network - Based vs. Non - Network - Based System . . .132.1.4 Criteria of Evaluating Indoor Positioning System .Richard is such a nice person and mentor to work with that graduate life might not feel like a conventional graduate life at all .I am really lucky to have such a pleasant start of my graduate life with a supervisor like him .I would like to thank my committee members , Dr. Jonathan Holzman and Dr. Thomas Jhonson , for kindly being a part of my supervisory com- mittee .", "label": "", "metadata": {}}
{"text": "I got an opportunity to find a research topic by finding some problems in the new positioning solution .As a forget- ful person , I have to thank him again , as he lives in the same building with me .That is why , I can , sometimes , forget my laptop charger or backpack in the office and request him to bring those home , so that I can collect those at night .He is really a wonderful guy .I would like to thank my apartment - mates Nijam , Azam and Russell for keeping our apartment unit lively , which did n't let me realize the huge xvii Acknowledgements distance between me and my family .", "label": "", "metadata": {}}
{"text": "Lastly , my family ; I will not thank my family , my mom , my dad , my sisters and my brother .It 's them , who make it really difficult for me to stay cool even in Canada ; because they are the reason , I am still warm .However , I will not thank them , because we do n't thank our family to be with us , we call them family because they are always with us . xviiiDedication To the truth I seek xix Chapter 1 Introduction 1.1 Context What is meant by the term ' positioning ' ?", "label": "", "metadata": {}}
{"text": "Indoor and outdoor environ- ments , being totally different , manifest different kinds of challenges for a positioning system , and thus make indoor positioning and outdoor position- ing different fields of research .GNSS ( global navigation satellite system ) is used almost universally for outdoor positioning , where line of sight ( LOS ) views between the GNSS receiver and at least four satellites are available .The most well known GNSS system is the Navigation by Satellite Ranging and Timing ( NAVS- TAR )Global Positioning System ( GPS ) , owned and operated by the US government and commonly known as GPS .", "label": "", "metadata": {}}
{"text": "Context is also operational .These GNSS techniques are almost universally used for outdoor navigation and positioning without any significant competitor in the market .Due to signal blockage , GNSS does not work well , or at all , in indoor en- vironments .Moreover , indoor environments are different in many attributes compared to outdoor environments .Indoor environments are more complex .Various obstacles , such as , walls , equipment , and human beings , influence the propagation of electromagnetic waves , which leads to multi - path effects .The indoor environment changes more dynamically making indoor position- ing and navigation a challenging research field needing special attention .", "label": "", "metadata": {}}
{"text": "Dempsey [ 2 ] defines an IPS as a system that continuously and in real - time can determine the position of something or someone in a physical space such as in a hospital , a gymnasium , a school , etc .An IPS can provide different kinds of location information for location - based applications used by the user .Usually the absolute position information with respect to the map of a coverage area is offered by indoor positioning tracking systems and indoor navigation systems , because tracking and guidance services need the exact positions of the targets .", "label": "", "metadata": {}}
{"text": "Motivation 1.2 Motivation Accurate , reliable and real - time indoor positioning and position - based protocols and services are required in future generation communication net- works to significantly improve the performance of wireless networks through network planning , network adaptation , and load balancing .Position - based tracking systems can also be used in hospitals for patient tracking , and in warehouses for tracking valuable goods .Considering the importance of positioning information and its applica- tion in different fields , many positioning systems have been developed over the years .Infrared - based , ultrasound - based , radio frequency based , and vision - based positioning systems are among the most well - known position- ing solutions with potential .", "label": "", "metadata": {}}
{"text": "The industry and research com- munities are still looking for a robust , accurate , cheap and reliable indoor positioning solution .In 2011 , a novel indoor positioning solution , based on angle of arrival ( AOA ) of light measured by a newly devised differential photosensor , was proposed in [ 4 , 5 ] by Arafa , Jin , and Klukas .The positioning solution is based on a newly devised photosensor [ 6 ] , which can determine the AOA of a light beam transmitted by a source and incident on the photosensor .Positioning information can be determined from the AOAs and the known frame of reference using simple trigonometry .", "label": "", "metadata": {}}
{"text": "As 3 1.2 .Motivation reported in [ 4 ] , above a certain threshold , the AOA values does not depend on the intensity of the incident light .This makes the system independent of incident power and thus overcomes the problems associated with proximity methods .Moreover , the sensor itself is very inexpensive , and it is antici- pated that it will be possible to use existing indoor lighting systems as the necessary light sources for the positioning system .This will decrease the extra infrastructure required further lowering the cost of the system .However , an unobstructed LOS view between the optical source and pho- tosensor is required given that the system is based on visible light .", "label": "", "metadata": {}}
{"text": "In addition , the optical angle of arrival ( OAOA ) positioning solution at each epoch of time is independent of the solution at the previous and following epochs , and the noise associated with each epoch is uncorrelated .This results in a trajectory which is not smooth .Now the question is , can we find any positioning solution , that supports the OAOA based positioning system for a robust and more reliable positioning solution , even in the absence of LOS view ?An inertial navigation system ( INS ) is a dead reckoning technique that uses a navigation processor and inertial sensors such as accelerometers and gyroscopes to continuously calculate the position , orientation , and velocity of a moving object without the need for external references .", "label": "", "metadata": {}}
{"text": "The most important parts of an inertial navigation system are the inertial measurement unit ( IMU ) and 4 1.2 .Motivation a navigation processor , which integrates the IMU outputs to produce a po- sition , velocity and attitude solution .In basic terms , the velocity is updated by integrating the acceleration from the accelerometers , and the position is updated by integrating velocity .An inertial navigation system suffers from three basic problems .Firstly , being a dead reckoning system , the navigation solution must be initialized with some initial value .Secondly , being an it- erative integration process , error from the previous stages accumulates and becomes very large after a few stages .", "label": "", "metadata": {}}
{"text": "However , short - term performance of an INS - based positioning system is very good and provides a smooth trajectory , unlike an OAOA - based positioning system .The most important point to be noted is that the inertial navigation system does not need any external reference .Now the question is , can we use an inertial navigation system to back up an OAOA - based positioning solution to enhance the performance of the overall positioning system ?The above two questions motivate this research .INS and OAOA - based positioning systems are largely complementary , so by integrating them , the advantages of both technologies are combined to give a continuous , com- plete positioning solution with good long and short - term accuracy .", "label": "", "metadata": {}}
{"text": "Different integra- tion algorithms and their effect on overall system performance is the main focus .In an integrated INS / OAOA indoor positioning system , the OAOA- based system should prevent the inertial solution from drifting , while the 5 1.3 .Problem Statement and Objective INS should smooth the OAOA positioning solution and bridge any LOS view outages .1.3 Problem Statement and Objective The following statements summarize the problem at hand .Firstly , because visible light is the communication link between the receiver and transmitter , the positioning system re- quires a continuous LOS view between the transmitter and receiver .", "label": "", "metadata": {}}
{"text": "Secondly , the maxi- mum output rate of the novel photosensor is yet to be determined .To date , the sensor has only been used for determining static positions .In the dynamic case , the sensors 's update rate may limit the smooth- ness of the trajectory .Thirdly , the positioning information provided by the sensor for a particular position does not depend on the previ- ous position , and due to measurement noise and system imperfections , the OAOA - based positioning system is not likely to provide a smooth trajectory .Moreover , since inertial navigation is an iterative integration process , errors accumulate as they pass through the various stages .", "label": "", "metadata": {}}
{"text": "Problem Statement and Objective just a few stages .Therefore , an independent positioning system is necessary to update the position information at every stage or at least after every few stages so the errors are not allowed to accumulate .However , the advantage of inertial sensors is that they have a fairly high output rate , which is typically 100 Hz .Moreover , being a dead reckoning system , position information at a particular point of time depends on the position information of the previous point of time , which results in a smooth trajectory .Given the above problem statements , the following objectives are defined for this particular research work .", "label": "", "metadata": {}}
{"text": "The problem statements , objectives and contri- butions are clearly stated in this chapter .Chapter 2 summarizes all of the relevant current research and the state - of- the - art - techniques for indoor positioning .An overview on the existing positioning solutions and their performance , cost , and limitations is given .Chapter 3 gives the necessary theoretical background for OAOA / INS in- tegration performed .This chapter starts with a detailed overview of the OAOA - based indoor positioning solution , which is followed by the basics of inertial navigation .The proposed algorithms for integration are then described .", "label": "", "metadata": {}}
{"text": "Chapter 5 presents the conclusion and make recommendations on the fu- ture work . 1.5Contribution The contribution of this work can be summarized as follows .Contribution to provide an accurate , reliable and inexpensive indoor positioning solution .These algorithms are described in Chapter 3 .Based on these technologies different companies , researchers , and universities have developed different indoor positioning solutions [ 3].Each solution has its own advantages and disadvantages .The designer of the in- door positioning system must compromise between performance and system complexity .In [ 7 ] it is reported that combining some positioning technolo- gies can improve the quality of positioning services .", "label": "", "metadata": {}}
{"text": "2.1 Indoor Positioning Systems : An Overview In this section the attributes of various indoor positioning solutions are described .Various evaluation criteria are discussed to compare the solution for the services demanded by users .Indoor Positioning Systems : An Overview 2.1.1 What is an Indoor Positioning System ?An indoor positioning system is a system that can provide the position of something or someone continuously and in real - time in a physical space such as in a building , a hospital , a gymnasium [ 2].An indoor positioning system can provide different kinds of location information depending on the user requirement .", "label": "", "metadata": {}}
{"text": "Relative position estimation and proximity detection are other types of output which also provided by some indoor positioning systems .2.1.2 Location Technologies , Techniques and Algorithms The need for an indoor positioning solution has led researchers to in- troduce different locationing technologies such as IR , ultra - sound , RFID , WLAN , Bluetooth , UWB , magnetic technology , etc .Equipped with these lo- cationing technologies an indoor positioning solution uses several techniques to locate objects and provide location information .The basic techniques of indoor positioning are known as trilateration , triangulation , fingerprinting and vision analysis [ 8 , 9].", "label": "", "metadata": {}}
{"text": "However , the cost of high grade inertial sensors is too high for most civilian applications .An aviation grade IMU costs approximately $ 100,000 and still drifts approximately 1.5 km in the first hour of operation [ 10].Trilateration is the process of determining location by the measurement of distance , and then using the geometry of circles or spheres .In the case 11 2.1 .Knowing the distance between the point and each reference point , circles with radius equal to the distances and centered at the reference points can be drawn .The common intersection point of all circles is the position solution .", "label": "", "metadata": {}}
{"text": "However , it is complex to implement because it requires complex circuitry for precise clock synchronization .Although RSS measurements are generally easy to make , they may not be accurate due to change in the propagation environ- ment .Note that , RSS and TOA require at least three reference points .In contrast to the trilateration , triangulation is the process of estimating the location of a point by measuring angles to it reference points of known position .The measurements made are known as angle of arrival .In contrast to RSS and TOA , AOA requires only two reference points to determine position [ 3].", "label": "", "metadata": {}}
{"text": "Fingerprint - based positioning refers to algorithms that first collect the features of a scene and then estimate location by matching the collected features with a - priori information .The problem with fingerprint based po- sitioning is the need for a very large database for storing the a - priori infor- mation .Fingerprinting for location estimation is also complex and costly if 12 2.1 .Indoor Positioning Systems : An Overview the number of users of the positioning system increases significantly [ 3].Vision analysis for location determination uses a camera or camera array to collect images and then analyzes the images to determine the position of a point or object with respect to other objects of known position in the image .", "label": "", "metadata": {}}
{"text": "However , any change in the indoor environment , even a change in the light level , can affect the positioning performance .2.1.3 Network - Based vs. Non - Network - Based System Any indoor positioning solution can be categorized depending on var- ious criteria .A positioning solution can be categorized as network - based approach and non - network - based approach depending on whether the IPS uses any existing wireless network infrastructure to determine the position information .A non - network - based approach uses its own infrastructure ac- cording the designer and depending on the need of accuracy .", "label": "", "metadata": {}}
{"text": "2.1.4 Criteria of Evaluating Indoor Positioning System In this subsection some criteria given in [ 3 ] are discussed for evaluating an indoor positioning system .Security and Privacy : Any indoor positioning system uses some kind of personal network ( PN ) for communicating the position information .Therefore , network security and privacy is an important issue for an 13 2.1 .Indoor Positioning Systems : An Overview indoor positioning system .Cost : The cost of a positioning solution for an indoor environment depends on the cost of the infrastructure components , the cost of the position- ing device for each user and the cost of the system installation and maintenance .", "label": "", "metadata": {}}
{"text": "The initial cost of the positioning device carried by an individual user and its maintenance cost and lifetime should also be considered .The ' delay ' of a measurement and the number of objects that an IPS can locate within a ceratin infrastructure , are also important performance evaluation issues .Usually , a trade - off exists between the performance and the price of an indoor positioning solution .User Preference : User preference is also an important issue when design- ing an indoor positioning solution .For the comfort of the users , the device should be wireless , small and light weight , have low power con- sumption , and be computationally powerful to offer accurate and real- time positioning information .", "label": "", "metadata": {}}
{"text": "In this section some exist- ing positioning solutions are introduced and their advantages and limitations are discussed .2.2.1 Infrared ( IR ) Positioning Systems The IR - based positioning system is a non - network based positioning sys- tem which uses proximity technique to determine the positioning solution .The IR - based indoor positioning system is very accurate ( several millime- ters ) in position estimation .An IR - based positioning system needs line of sight communication between transmitter and receiver .Thus the coverage range per infrastructure is limited within a room [ 3].", "label": "", "metadata": {}}
{"text": "Optical filtering and noise canceling signal processing algo- rithms are necessary to filter out the interference effect from florescent light and sunlight [ 14 ] , which raises the cost of the system .The requirement of expensive system hardware such as a receiver camera array and connected via wires makes the positioning system very expensive [ 3].2.2.2Ultra - sound Positioning Systems Position estimation using ultra - sound is described in [ 15 - 20].Ultra- sound signals are used by bats to navigate and this inspires people to design a similar navigation systems [ 3].", "label": "", "metadata": {}}
{"text": "Existing Indoor Positioning Solutions based positioning solutions ( several millimeters ) .Moreover , ultra - sound based solutions suffer from reflected ultrasound signals from different ob- stacles [ 3].2.2.3 Radio Frequency ( RF )Positioning Systems Radio waves can travel through walls and human bodies , which can be an advantage for indoor positioning .RF - based positioning systems can reuse existing RF technology systems such as WLAN [ 3].In [ 3 ] some basic RF - based positioning solutions are described .RFID : Radio frequency identification ( RFID ) [ 21 ] is commonly used in complex indoor environments .", "label": "", "metadata": {}}
{"text": "An RFID system can uniquely identify equip- ment and persons tracked in the system .However , this positioning technology needs numerous infrastructure components to be installed and maintained in the working area of the system [ 3].Moreover , typi- cal RFID positioning solutions offer an error of 2 m to 3 m [ 22 ] , which may not be suitable for some applications .WLAN : WLAN based indoor positioning technology is based on the fin-gerprinting technique .WLAN based IPS uses existing WLAN infras- tructure which makes it a cost effective solution [ 23 - 26].", "label": "", "metadata": {}}
{"text": "Existing Indoor Positioning Solutions points ( AP ) , and nearby mobile devices , walls , doors , etc .WLAN technology is widely used and integrated in various wireless devices such as laptops , mobile phones , etc .Thus , WLAN - based posi- tioning systems can also reuse these wireless devices as tracked targets to locate persons .However , because of complex indoor environments [ 23 - 26 ] , the performance of these positioning systems is not very good given accuracy of several meters .Moreover , using the stored informa- tion and fingerprinting technique for location estimation is complex and costly if the number of users of the positioning system increases significantly .", "label": "", "metadata": {}}
{"text": "Various Bluetooth clusters can be formed for Bluetooth - based indoor positioning [ 27- 30].The main advantage of using Bluetooth for indoor positioning is the option of using devices that already have Bluetooth in them .Moreover , being cheap , Bluetooth - based indoor positioning offers a cost effective positioning solution for indoor environments .However , Bluetooth - based systems offer accuracies of only 2 m to 3 m and , more importantly , with a minimum delay of 20 s. Sensor Networks : Sensor - based positioning systems consist of a large num- ber of sensors fixed in predefined locations [ 31].", "label": "", "metadata": {}}
{"text": "A person or device can be located from the measurements taken by 17 2.2 .Existing Indoor Positioning Solutions the sensors .Sensor - network - based positioning has great potential for indoor positioning due to emerging sensor network technology .How- ever , cheap and small sensors have limited processing capability and battery power compared to other mobile device which results in poorer accuracy [ 3].Ultra - wideband : UWB - based positioning system uses both TOA and AOA techniques for position determination .The most exciting feature of an ultra - wideband signal is its extremely large bandwidth or extremely short pulse - width .", "label": "", "metadata": {}}
{"text": "The duration of an ultra - wideband pulse is less than 1 ns , which makes it possible to filter reflected signals from the original signal , and thus offer high accu- racy [ 3].Compared with other RF - based positioning systems , UWB systems offer higher accuracies of about 15 cm in 3-D [ 3 ] and have coverage areas up to 400 m2 .Therefore , UWB technology offers sev- eral advantages over other indoor positioning technologies , such as no line - of - sight ( LOS ) requirement , little multi - path distortion , less in- terference , high penetration ability , etc .", "label": "", "metadata": {}}
{"text": "A high precision UWB indoor positioning research package reported in [ 3 ] costs about $ 16,875 .Existing Indoor Positioning Solutions 2.2.4 Magnetic Positioning Systems A magnetic positioning system is a very high accuracy positioning system that does not suffer from the line - of - sight problem .This is an old and classic way of tracking and position measurement [ 32].The magnetic sensors are small in size , robust and cheap .Moreover , it offers higher accuracy and enables multi - positioning tracking at the same time .However , the coverage was reported to be only 3 m in [ 32 ] , which is not scalable for large indoor public application services .", "label": "", "metadata": {}}
{"text": "The positive side is that , in a vision - based positioning system , the tracked person or object does not need to carry any tracking device .Moreover , a low price camera can cover a large area .However , this system is not good considering the privacy of people .Moreover , in a dynamically changing environment , this system is not very reliable , since the position estimation is based on the saved vision information in a database .Interference sources such as weather changes and light conditions can also degrade the performance of a vision based positioning system .", "label": "", "metadata": {}}
{"text": "Existing Indoor Positioning Solutions 2.2.6 Audible Sound Positioning Systems Currently , every wireless mobile device has the ability to emit audible sounds .The possibility of using audible sounds for indoor positioning was introduced in [ 35].A 3-D indoor positioning solution named ' Beep ' was de- signed using audible sound technology .It uses trilateration technique based on time of arrival ( TOA ) measured by a sensor in the ' Beep ' system .An accuracy of around 0.4 m was found in an experimental environment of a 20 m \u00d7 9 m room in 90 % of all the cases .", "label": "", "metadata": {}}
{"text": "However , such systems suffer interference from sound noises in many public indoor situa- tions .Moreover , transmitting audible sound for positioning is a continuous disturbance to the people in the indoor environment [ 3].2.2.7 Differential Photosensor - based Positioning System Recently a differential photosensor was introduced for simultaneous op- tical retroreflection , detection , and control in bidirectional sensor links [ 6].This is an architecture with three mutually orthogonal photodiodes in a corner - cube arrangement ( used to retroreflect incident light and sample the incident optical signal ) .Recent work [ 4 , 5 ] proposes an indoor positioning technique based on the AOA of incident light measured with the differential photosensors .", "label": "", "metadata": {}}
{"text": "pending on the AOA of the incident light .From the AOA measurements for two or more light sources with known positions , the position of the corner- 20 2.2 .Existing Indoor Positioning Solutions cube sensor can be determined .An accuracy on the range of 2 - 3 cm in a 2-D plane was reported in [ 4].The proposed system has several advantages over some of the existing positioning technologies .As reported in [ 4 ] , above a certain threshold , the AOA value does not depend on the intensity of the incident light .", "label": "", "metadata": {}}
{"text": "Moreover , the sensor it- self is very inexpensive , and it is anticipated that it may be possible to use indoor lighting as the necessary light sources for the positioning system .However , it should be noted that if room lights are used , the lighting system must be based on LED lights , since other types of room lighting ( i.e fluores- cent ) can not be modulated as required by the system .Use of existing room lighting will decrease the extra infrastructure required and further lower the cost of the system .Table 2.1 summarizes the performance , cost and coverage of the above mentioned indoor positioning technologies .", "label": "", "metadata": {}}
{"text": "Inertial navigation system technology used as an alternative to GPS , because GPS does not work well in all environments [ 36].MEMS ( microelectromechanical systems ) inertial technology is seen as both a possible complement and a potential alternative to GPS [ 36].An inertial measurement unit ( IMU ) usually combines three accelerom- eters and gyros to produce a 3-D measurement of specific forces and angular rates .An accelerometer measures specific forces and a gyroscope measures angular rates , both without an external reference [ 10].An IMU is the sensor package for an inertial navigation system which can produce an independent 3-D navigation solution .", "label": "", "metadata": {}}
{"text": "MEMS sensors are small , light , and exhibit much greater shock tolerance than conventional mechanical designs , though with relatively poor performance .Although there is no universally accepted definition of a high- , medium- , and low - grade IMU , they can be broadly grouped into five perfor- mance categories : marine , aviation , intermediate , tactical , and automotive [ 10].According to [ 10 ] marine and aviation grade IMU sensors are not suitable for civilian use because of their high price , which is approximately $ 1 million and $ 100,0000 respectively .", "label": "", "metadata": {}}
{"text": "Proposed Indoor Positioning Solution small aircrafts and helicopters , might cost up to $ 50,000 .A tactical grade IMU can be used to provide stand - alone positioning solution for a few minutes [ 10].A long term positioning solution can be obtained by integrating it with a positioning system , such as GPS .These systems typically cost between $ 5,000 to $ 20,000 [ 10 ] , and are typically used in guided weapons and unmanned air vehicles .The lowest grade IMU , which is known as automotive grade IMU are actually very cheap , and can be bought as a single accelerometer and gy- roscope unit .", "label": "", "metadata": {}}
{"text": "According to [ 36 ] , a single gyroscope can currently cost as low as $ 5 .They are expected to become less expensive according to current market predictions [ 36].However , INS based on automotive grade IMUs , can not be used as a standalone navigation system due to the large drift in the accelerometer and gyroscope .Therefore , INS based on automotive grade MEMS systems must be integrated with some other positioning system to yield a complete navigation solution [ 10].2.3.2 GPS and INS Integration Strategy Inertial navigation systems have a number of advantages .", "label": "", "metadata": {}}
{"text": "However , the accuracy of an inertial navigation solution degrades with time as the errors are integrated through the navigation equations and are propagated through stages .Proposed Indoor Positioning Solution On the other hand GNSS or GPS can provide high long - term position accuracy with limited error .However , compared to INS , the update rate is low .Moreover , GNSS signals are also subject to obstruction and inter- ference , such that GNSS can not be relied upon to provide a continuous navigation system [ 10].For outdoor applications where real - time kinematic ( RTK ) positioning capability in degraded environments requires centimeter level accuracy , INS is integrated with GNSS .", "label": "", "metadata": {}}
{"text": "INS / GNSS integration architecture depends on three factors : how corrections are applied to the inertial navigation solution , what type of GNSS measurements are used , and how the GNSS user equipment is aided by the INS and integration algorithm [ 10].In the literature , terms such as loosely coupled , tightly coupled , ultratightly coupled , closely coupled , cascaded , and deep are used to define integration architecture [ 38 , 39].In the loosely coupled architecture , INS and GNSS receivers operate as independent navigation systems and position information is blended using an Extended Kalman filter ( EKF ) .", "label": "", "metadata": {}}
{"text": "In general , the classical tightly coupled architecture provides a more accurate solution than the loosely coupled architecture .In this architecture , the INS and GNSS measurements are combined to generate a single blended navigation solution [ 40].Proposed Indoor Positioning Solution 2.3.3 Proposed Solution For the integration of INS with OAOA , loosely coupled and tightly cou- pled integration strategies similar to those used for GPS / INS integration will be used .From the above discussion it becomes apparent that , although there are a number of indoor positioning solutions , none of them has proven to be a complete solution in terms of accuracy , coverage , cost and robust- ness .", "label": "", "metadata": {}}
{"text": "The recently proposed indoor positioning solution based on OAOA is a potential indoor positioning solution that needs more detailed investigation .The loosely coupled and tightly coupled archi- tectures used for GNSS / INS integration will be investigated with necessary modifications for INS / OAOA integration .26 Chapter 3 INS and OAOA Integration In this chapter the basic theoretical background for OAOA - based indoor positioning system is investigated .The basics of the inertial navigation system is then introduced .The algorithms for loosely coupled and tightly coupled integration strategies of INS and OAOA - based indoor positioning and a modification of the algorithms using a error compensation block , is proposed at the end of the chapter . 3.1 OAOA for Indoor Positioning The recently proposed indoor positioning solution based on angles of ar- rival of light , uses a photosensor , consisting of three photodiodes arranged in a corner - cube .", "label": "", "metadata": {}}
{"text": "The position of the photosensor can be determined from the AOA and knowledge of the position of the optical sensor in a frame of reference .The proposed system has several advantages over some of the existing positioning technologies .As reported in [ 4 ] , above a certain thresh- old , the AOA values does not depend on the intensity of the incident light .This makes the system independent of incident power and thus overcomes the problems associated with proximity methods .OAOA for Indoor Positioning PD 2 PD 1 PD 3 Figure 3.1 : Photograph of the corner - cube photosensor .", "label": "", "metadata": {}}
{"text": "Figure 3.2 shows a sketch of the sensor .It is comprised of three mutually orthogonal photodiodes ( PD ) , with PD1 lying in the yz - plane , PD2 lying in the xz - plane , and PD3 lying in the xy - plane .The device was first introduced by Jin and Holzman in [ 6].The basic parts of the structure are three reflective surfaces that are mutually orthogonal and oriented as an interior corner - cube orientation as shown in Figure 3.2 .The two angles , azimuthal angle \u03c6 and polar angle \u03b8 , are defined according to a spherical coordinate system , as shown in Figure 3.2 .", "label": "", "metadata": {}}
{"text": "The values of \u03c6 and \u03b8 can be determined from the values of the currents generated in 28 3.1 .OAOA for Indoor Positioning Incident light PD 1 PD 3 PD 2 z x y Azimuthal angle Polar angle \u03b8 \u03c6 Figure 3.2 : Sketch of the corner - cube photosensor .the three PDs .Photocurrents i1 , i2 and i3 are generated in PD1 , PD2 and PD3 , respec- tively , when beams of light from optical source A or optical source B strike the sensor ( see Figure 3.3 ) .The values of these photocurrents are propor- tional to the power of the incident light and also depend on the AOA of the incident light .", "label": "", "metadata": {}}
{"text": "( 3.5 ) Equations 3.4 and 3.5 may be used to calculate \u03c6 and \u03b8 from the measured value of the photodiode currents I1 , I2 and I3 .OAOA for Indoor Positioning 3.1.2 Determining Position It is clear that , for determining the position of the sensor , at least two optical sources are necessary .To acquire and process photocurrents con- tributed by different optical sources , a multi - frequency LED configuration is used [ 4].Figure 3.3 shows a hypothetical setup for determining the position of the sensor with respect to a known reference frame .", "label": "", "metadata": {}}
{"text": "Two optical sources are placed at two known positions in the reference frame , ( x1 , y1 , z1 ) and ( x2 , y2 , z2 ) .The OAOA sensor is placed at an arbitrary position ( x , y , z ) , which is to be determined .As shown in Figure 3.3 , two optical sources at two different co - ordinates are driven by two function generators operating at different frequencies .The modulation scheme used in the experiments is on - off keying , which is done by using a function generator to drive each LED light source with a square wave of different frequency .", "label": "", "metadata": {}}
{"text": "Inertial Navigation System the position of the sensor with respect to the reference frame by triangula- tion .More than two optical sources can be used for improving positional accuracy by providing redundant information . 3.2 Inertial Navigation System An inertial navigation system is a dead - reckoning navigation system , be- ing comprised of an inertial measurement unit and a navigation processor .An inertial measurement unit , which is comprised of a set of accelerometers , gyroscopes , and magnetometers is the main part of an inertial navigation system .This section introduces the necessary background for understand- ing inertial navigation systems by introducing inertial sensors , coordinate frames , rotation matrices , the initial alignment procedure , and the naviga- tion equations .", "label": "", "metadata": {}}
{"text": "In an effort to clarify the following discussion , the majority of the notation and conventions used in this section can be summarized as follows .To indicate the coordinate frame in which the components of a vector are given , a superscript is attached to the vector and to the components of the vector .As an example , the position vector r described in the navigation 32 3.2 .A rotation rate vector \u03c9abc represents the rotation rate of frame ' c ' , rel- ative to frame ' b ' , expressed in frame ' a ' .", "label": "", "metadata": {}}
{"text": "Coordinate transformation of vectors applies to angular velocity vectors as well .( 3.8 ) Rotation can not only be expressed by an angular velocity vector , but 33 3.2 .Inertial Navigation System also by a skew symmetric matrix containing the same vector components .The skew symmetric matrix is a very useful matrix in navigation compu- tation .( 3.11 )The point to be noted here is that the inner indices will be canceled out and the superscripts have to be the same .This means that only vectors in the same reference frame can be added or subtracted .", "label": "", "metadata": {}}
{"text": "However , in the case of navigation , the rotation of the Earth has a significant impact on the navigation computation since inertial sen- sors measure their motion with respect to a real inertial frame .However , the user would like to know their position with respect to the Earth .Navi- gation computation , thus deals with multiple coordinate frames which need to be defined clearly .All coordinate frames considered in this work form orthogonal right - handed basis sets .The remainder of this section defines the following coordinate frames used in navigation problems : Earth - centered inertial ( ECI ) frame , Earth- centered Earth - fixed ( ECEF ) frame , local navigation frame , and body frame [ 10 , 41].", "label": "", "metadata": {}}
{"text": "Inertial Navigation System Equator Equinox Up East N orth Greenwich meridian Ze , Zi Xn ZnY n \u03bb Xe Xi Y e Y i Earth rotation axis 360 - GMST \u03d5 Figure 3.4 : Coordinate frames .3.2.3 Rotation Matrix Computation The specific force measurement made by triaxial accelerometers in an IMU unit are expressed in the body frame .This raw measurement contains the components of the ' gravity offset ' , which needs to be subtracted from the raw measurement to find the actual velocity increments with respect to the navigation frame .However , the body frame is not aligned with the naviga- tion frame .", "label": "", "metadata": {}}
{"text": "Roll , pitch and yaw define the rotation of the body frame with respect to the navigation frame .( 3.15 )It should be noted that the sequence of the multiplication is very important .Multiplication of three rotation matrices resulting from a single set of roll , pitch and yaw in different sequences results in totally different rotation ma- trices .As discussed in the previous paragraph , knowing the roll , pitch and yaw , allows us to calculate the rotation matrix Rnb .( 3.19 ) Initial Alignment Computation One of the underlying assumptions of the INS mechanization equations is that the initial condition of the system is known .", "label": "", "metadata": {}}
{"text": "From the discussion above , it is clear that the rotation matrix Rnb can be calculated if the Euler angles r , p , and y are known , and vice versa .However , at the beginning of inertial navigation , neither is known and for this reason the INS must usually execute an initial alignment procedure to determine the initial value of the Euler angles .Where the IMU is stationary , self - alignment can be used to initialize roll and pitch with the help of accelerometer data , whereas heading or yaw is often initialized using a magnetic compass or magnetometer .", "label": "", "metadata": {}}
{"text": "In such a condition , the triaxial accelerometer measurements represent the components of the vertically upward antigravity force .Therefore , from the normalized accelerometer readings it is possible to determine the roll and 40 3.2 .For initial alignment , the IMU is kept static for around 30 seconds , and in that case , time averaged values of abx , a b y , and a b z are used instead of instantaneous values .Table 3.1 : Quadrant information for roll from acceleration signs .Roll quadrant Sign of aby Sign of a b z 1 + + 2 + - 3 - - 4 - + Table 3.2 : Quadrant information for pitch from acceleration signs .", "label": "", "metadata": {}}
{"text": "In [ 43 ] , lookup tables were constructed for North - East - Down ( NED ) axes conventions for the navigation frame .Table 41 3.2 .Inertial Navigation System 3.1 and Table 3.2 are the lookup tables required to resolve the quadrant for roll and pitch using the sign of the accelerometer measurement for the East- North - Up ( ENU ) convention ( which is used in this work ) of the navigation frame .A magnetometer is not an inertial sensor .However , it is an important part of an inertial navigation system using low grade inertial sensors .", "label": "", "metadata": {}}
{"text": "For this reason , magnetometers can be used for determining the heading of the IMU for a low cost INS .From this vector it is possible to calculate the yaw of the body frame with respect to the navigation frame , if the roll and pitch is already known .Inertial Navigation System Being a inverse trigonometric function , like roll and pitch , it is also impossible to uniquely determine the quadrant of the yaw angle just from Equation 3.24 .Similar to the roll and pitch angles , the quadrant information can be resolved from the signs of Xh and Yh [ 43].", "label": "", "metadata": {}}
{"text": "Table 3.3 : Quadrant information for yaw from magnetic field components signs .The local navigation frame formulation has the advantage that its axes are aligned to local East , North and up directions .In the local navigation implementation of the inertial navigation equations , the ECEF frame is used as the reference frame .This form of navigation equation has the advantage of providing a navigation solution in a form readily suited for the user [ 10].Inertial Navigation System However , in the case of indoor positioning , cartesian coordinates are more preferable as the final positioning output .", "label": "", "metadata": {}}
{"text": "In the above equations r\u0307e , r\u0307n , and r\u0307u represents the derivatives of re , rn , and ru , respectively .( 3.37 )However , the accelerometer components expressed in the local navigation frame can not directly provide local navigation frame velocity components of the moving body .To do so requires three factors to be taken into account .( 3.38 )The second factor is the change of orientation of the navigation frame with respect to the Earth .This change of orientation is due to the defini- tion of the local North , local East and local vertical directions .", "label": "", "metadata": {}}
{"text": "Inertial Navigation System direction is always tangential to the meridian , while the vertical direction is normal to the Earth 's surface at each instant .( 3.44 )Attitude Mechanization Equation The attitude angles of a moving body are determined by solving the time derivative equation of the transformation matrix .The angular velocity \u03c9bin consists of two parts .The first part is \u03c9 b ie , which accounts for the Earth rotation rate , and the second part is \u03c9ben , which accounts for the orientation change of the navigation frame .( 3.53 )Using all the equations above , we are now in a position to express the mechanization equation for all the necessary navigation states .", "label": "", "metadata": {}}
{"text": "The outputs are the curvilinear coordinates , three velocity components and three attitude components .( 3.54 )The square boxes in the above equation represents the input raw measure- 49 3.2 . ments found from the accelerometers and the gyroscopes .( 3.55 ) Solving these 1st order differential equations provides the navigation param- eters in the local navigation frame .Figure 3.5 , a visual form of Equation 3.54 , is a block diagram which shows the basic parts of an inertial navigation system .The inputs are then passed to the main algorithm which will be described shortly in the following section .", "label": "", "metadata": {}}
{"text": "Step 0 : Before Starting Determining the initial alignment of the IMU must be done before the INS algorithm begins .By using Equation 3.20 , Equation 3.21 , and Equation 3.24 we can determine the roll , pith and yaw of the IMU , respectively , before it goes into motion .For initial alignment , the IMU should ideally be stationary for a certain amount of time .Typically , a time span of 30 s is sufficient .The initial value of all the components of the velocity vector vn(t0 ) can be considered zero .Then \u03c9nen(t0 ) can be determined from Equation 3.39 .", "label": "", "metadata": {}}
{"text": "Step 1 : Velocity Calculation The measurements from the triaxial accelerometer , ab(tk ) , at time in- stant tk , are multiplied by the rotation matrix R n b ( tk ) .Then , according to Equation 3.42 , v\u0307n(tk ) is calculated and is then integrated to get the velocity 51 3.2 .( 3.58 ) Step 2 : Position Calculation By integrating the velocity vector , the position vector can be determined .However , to model the rotation matrix Rnb according to Equation 3.49 , six differential equations are needed .Solving the quaternion parameters requires only four dif- ferential equations to be solved .", "label": "", "metadata": {}}
{"text": "The updated rotation matrix is then used in the next stage to rotate the measurements from the accelerometers , which is resolved in the body frame to transform them into a quantity in the navigation frame .The entire algorithm from Step 1 to Step 3 is then repeated in the same way to find a continuous navigation solution . 3.3Proposed Integration Algorithm In this section , the proposed algorithm for the integrated OAOA / INS positioning solution is presented .The algorithm is based on some conven- tional GNSS / INS integration strategies .Different GNSS / INS integration architectures such as loosely coupled , tightly coupled , ultratightly coupled , and closely coupled are described in the literature .", "label": "", "metadata": {}}
{"text": "Proposed Integration Algorithm For integration purposes , the extended Kalman filter ( EKF ) is one of the most popular estimators [ 45].The EKF is here used to correct the INS trajectory with position updates from the OAOA positioning solution .The EKF is actually an adaptation of the linear Kalman filter ( LKF ) to nonlinear functions , and is necessary here given the nonlinear nature of the INS equations .An integration strategy can be either an open loop or closed loop , de- pending on the feedback provided to the INS mechanization block .", "label": "", "metadata": {}}
{"text": "On the other hand , in a closed looped system , error estimation from the EKF is fed back to the INS mecha- nization block .In an open loop system with low cost MEMS sensors , errors can grow unbounded in a very short period of time .Therefore , an error state Kalman filter is used to estimate the errors and the error estimates are fed back to the INS mechanization block .The basis of the error state EKF is the INS error state model , which can be obtained by the perturbation analysis of the INS mechanization equations described in Section 3.2.4 [ 46].", "label": "", "metadata": {}}
{"text": "Therefore , only the results are shown here .The above equations can be used to model the inertial errors .However , in a system using a low grade MEMS IMU , errors may grow unbounded and it is important to estimate the errors present in the sensor measurement .All types of accelerometers and gyroscopes exhibit biases , scale factors , cross - coupling errors , and random noise to a certain extent [ 10].Among all the errors , the accelerometer and gyroscope biases are the most significant and should be taken care of [ 48].", "label": "", "metadata": {}}
{"text": "It is independent of the underlying specific force or angular rate .In most cases bias is the dominant term in the overall error of an inertial instrument [ 10].In the above equations \u03b4ab and \u03b4\u03c9bib represent the errors in the accelerom- eter and gyroscope measurements respectively .Theoretically , these error terms are composed of a constant sensor bias , a temperature sensitivity effect , misalignment error , a scale factor and sensor noise [ 41].However , modeling all of the above errors in a Kalman filter is impractical .Therefore , both the accelerometer and gyroscope errors are considered to consist of only a bias term and noise .", "label": "", "metadata": {}}
{"text": "The parameters wa and w\u03c9 are the measurement noise of the specific force vector and angular rate vector , respectively .Similarly , for the triaxial gyroscope , the bias error model for the angular 58 3.3 .For both the accelerometer and the gyroscope error models , the white noise term w(t ) is of zero mean and unity variance .The error modeling of the magnetometer is often neglected because it only affects the calculation of the yaw angle in the body frame with respect to the navigation frame and this does not lead to any large errors in position estimation for short durations [ 43].", "label": "", "metadata": {}}
{"text": "Since GNSS is a very reliable positioning solution , a small heading error initiated by the magnetometer bias can be ignored without any significant performance degradation in the integrated system .However , for indoor positioning applications , the aiding positioning so- lution used in this work , namely OAOA , is not yet as reliable as GNSS .Moreover , a given amount of position error in an indoor environment may be considered to be more significant than the same in an outdoor environ- ment .Therefore , magnetometer error estimation is also necessary .The raw magnetometer measurements contain components from the mag- netic field of the navigation system , the magnetic field of surrounding equip- ment , in addition to the Earth 's magnetic field .", "label": "", "metadata": {}}
{"text": "Proposed Integration Algorithm A complex calibration method is available for calibrating the magnetometer [ 10].As stated earlier , the white noise term w(t ) is of zero mean and unity variance .Figure 3.6 depicts the basic block diagram showing the INS mechaniza- tion block which gets feedback from the EKF and the input to the block is compensated for the bias estimation by the EKF .In the next section the proposed algorithms for OAOA / INS integration are described .A detailed description of the Kalman filter algorithm is not discussed here but may be found in the literature [ 39 , 50].", "label": "", "metadata": {}}
{"text": "This is followed by a modified version of the loosely coupled and tightly coupled integration algorithms which use an error compensation block before the INS mechanization block .3.3.1 Loosely Coupled Integration In the case of GNSS / INS loosely coupled integration , the INS and GNSS operate as independent navigation systems .The navigation solution from each are blended using an estimator to form a third navigation solution [ 40].Following the basic architecture of the loosely coupled algorithm for GNSS / INS integration , a loosely coupled algorithm for OAOA / INS integra- tion is proposed .", "label": "", "metadata": {}}
{"text": "The IMU consists of a triaxial accelerometer , a triaxial gyroscope and a triaxial magnetometer which provide the raw accelerometer mea- surements a\u0303k+1 , the raw gyroscope measurements \u03c9\u0303k+1 , and the raw magnetometer measurements m\u0303k+1 .The subscript k + 1 denotes the 61 3.3 . current update cycle .The measurements from the accelerometer and the gyroscopes are then corrected using the bias estimate from the EKF which is based on information from the previous cycle and thus denoted by the subscript k in Figure 3.7 .As stated earlier , magnetometer error estimation is also necessary for indoor positioning and , therefore , is added to the EKF state vec- tor which provides significant performance improvement as shown in Chapter 4 .", "label": "", "metadata": {}}
{"text": "The estimated velocity errors are used to correct the velocity in the INS mechanization block .The INS mechanization block cal- 62 3.3 .The rotation matrix for the rotation from the body frame to the nav- igation frame , implemented using Euler angles , may become singular at times .Therefore , instead of using Euler angles as in [ 43 ] , quater- nion algebra is used to update the rotation matrix .Therefore , the EKF here is used for estimating the quaternion parameters in addi- tion to the estimation of attitude errors as in conventional INS / GNSS [ 10 , 43].", "label": "", "metadata": {}}
{"text": "The EKF estimated quaternion parameters are used for Qk in Equation 3.69 .For the INS mechanization block to begin , initial condition informa- tion is needed and this is provided by the OAOA processor block .In Figure 3.7 this information is represented by rnOAOAinitial .The OAOA sensor block provides a current from each of the three orthogonal photodiodes .The elements are termed IPD1k+1 , IPD2k+1 , and IPD3k+1 .The currents from these three photodiodes have com- ponents at different frequencies from each optical source .The com- ponents of the currents at the different frequencies are not shown in Figure 3.7 .", "label": "", "metadata": {}}
{"text": "The position vector , r nINS k+1 , 63 3.3 .Proposed Integration Algorithm calculated from the INS algorithm is then subtracted from the position vector rnOAOAk+1 , calculated from OAOA processor , and the difference is fed to the EKF as the observation vector .In addition to all the error state vectors , the quaternion parameter vector Qk is also estimated here and it has four components .If the magnetometer error states are added to the EKF states , the EKF here becomes a twenty two state extended Kalman filter .The estimated position error is used to correct the position output from the INS .", "label": "", "metadata": {}}
{"text": "The state vector for the EKF can be written 64 3.3 .( 3.83 )All components of this state vector are vectors containing three elements , except Qk , which has four quaternion parameters q1(tk ) , q2(tk ) , q3(tk ) , and q4(tk ) .This presents a problem for writing the system model for the EKF .( 3.85 ) Based on Equation 3.72 and on the error analysis of the accelerometer , gyroscope and magnetometer , the system model of the EKF can be written 65 3.3 .( 3.86 )Obtaining the Gauss - Markov model parameters for the sensor errors is an important task to this end .", "label": "", "metadata": {}}
{"text": "In static conditions , the triaxial accelerometer measures only the reaction force due to gravity , the gyroscope measures only the Earth 's rotation and the magnetometer measures hard- iron and soft - iron magnetic flux .All of the quantities are constant , at least for the length of the test considered .Therefore , it can be concluded that any variations in the measurements must be caused by variations in the sensor errors , which is to be modeled .The autocorrelation function of the raw data was computed as stated in [ 49 ] to determine the parameters for 66 3.3 .", "label": "", "metadata": {}}
{"text": "( 3.87 )For the loosely coupled system , the state vector and the observation vector have a linear relationship .( 3.88 )The algorithm for estimating the states of the EKF using the system model and measurement model , follows standard the EKF algorithm , which is available in any book on Kalman filtering [ 50 , 51].3.3.2 Tightly Coupled Integration In the case of GNSS / INS tightly coupled integration , raw GNSS ob- servations are passed directly to an EKF .The observation vector contains the GNSS processor 's pseudo - range and pseudo - range rate measurements [ 10].", "label": "", "metadata": {}}
{"text": "The key aspects of the proposed algorithm are described below and depicted in Figure 3.8 .The difference between the loosely coupled and the tightly coupled integration algorithms is in the observation vector .In loose integra- tion , the position vector , rnINSk+1 , calculated from the INS algorithm is subtracted from the position vector , rnOAOAk+1 , calculated from OAOA processor , and the difference is fed to the EKF as the observation vector .In the case of the tightly coupled system shown in Fig . 3.8 , however , the observation vector contains the differences between the OAOA sensor measured currents and current values predicted from the corrected inertial navigation solution .", "label": "", "metadata": {}}
{"text": "Proposed Integration Algorithm quencies depending on the number of light sources used .Using the estimated position vector determined by the INS algorithm and sim- ple trigonometry , similar current components can be calculated .In the case of the tightly coupled algorithm , the difference between the two current values is fed to the EKF as an observation vector .If N light sources are used for positioning , current from the each photo- diode will have N frequency components .IPD1 will have components IF1PD1 , I F2 PD1 , IF3PD1 , ... ... ... , I FN PD1 .", "label": "", "metadata": {}}
{"text": "Similar current components can be calculated by knowing the position vector of the sensor , determined by the INS algorithm .In the case of tightly coupled integration , these current differences comprise the observation vector for the EKF .EKF for Tightly Coupled Integration The EKF for the tightly coupled OAOA / INS integration has the same system model as the EKF used for loosely coupled integration .However , the measurement model in the tightly coupled case is different from that of the loosely coupled case .In the case of the loosely coupled algorithm , a linear relationship was available between the state vector and the observation vector .", "label": "", "metadata": {}}
{"text": "( 3.89 )The observation vector consists of the different frequency components of the current differences described above .( 3.90 ) Equation 3.89 does not represent a linear relationship between zk and xk .A linearization of this relationship is necessary for the Kalman filter algorithm to operate .According to [ 50 ] , the measurement matrix can be written as the Jacobian of the Taylor expansion of h(xk ) .Therefore , the measurement 70 3.3 .The differentials of Equation 3.91 are calculated numerically .The values of these currents generated in the photosensor depend on the AOAs of the light beams striking the photosensor , which in turn is a function of the position of the photosensor .", "label": "", "metadata": {}}
{"text": "Proposed Integration Algorithm 3.3.3 Integration Algorithms with Augmented Observation One of the major sources of error in inertial navigation systems are the different errors associated with the inertial sensors .Therefore , it is im- portant to compensate for the errors generated by noise present in the ac- celerometer , gyroscope and magnetometer measurements .For this reason , accelerometer bias , gyroscope bias and magnetometer bias errors are esti- mated in the EKF , and then used to correct the raw sensor measurements .However , the error estimation done in the EKF is based on information from the previous time epoch .", "label": "", "metadata": {}}
{"text": "By augmenting the observation vector by adding prior sensor bias estimation data and the quaternion vector , the overall performance of the positioning system can be improved .This is shown in Chapter 4 .The idea of augmented observations was introduced in [ 43].However , for this work , a modified version of the basic idea of augmenting the observation vector is used for the specific problem at hand .The key and novel features of the integration algorithm which includes an augmented observation vector are depicted in Figure 3.9 and described as follows .The EKF in the loosely coupled and tightly coupled strategies for 72 3.3 .", "label": "", "metadata": {}}
{"text": "This is then used to correct the raw measurements from the accelerometers , gyroscopes and magnetome- ter in the current cycle .In [ 43 ] a linear Kalman filter ( LKF ) was used to estimate the bias in the accelerometer and gyroscope prior to the bias estimation in the EKF .However , in the present work an LKF is used to estimate only the accelerometer bias using the current cycle measurement , which is then used to augment the observation vector of the EKF .The EKF used in loosely and tightly coupled integration estimates the quaternion vector , Q , which is provided as feedback to the INS mecha- nization block to determine the updated quaternion vector at the next time epoch according to Equation 3.66 .", "label": "", "metadata": {}}
{"text": "Proposed Integration Algorithm section does not have any observation for quaternion estimation .The quaternion parameters estimated from the raw measurements of the current cycle are used to augment the observation vector for the EKF .This helps the EKF to estimate the quaternion parameters based on the most up - to - date information .Prior Accelerometer Bias Estimation The EKF estimates the accelerometer bias solely from the system model using information from the previous cycle .This estimated bias is then used to correct the raw accelerometer measurement .The EKF does not have any information on the accelerometer error associated with the current cycle accelerometer data .", "label": "", "metadata": {}}
{"text": "In Figure 3.9 , the linear Kalman filter used for accelerometer prior bias estimation is named LKF .Proposed Integration Algorithm is the measurement noise vector .The accelerometer bias term required for the observation vector of the EKF can be calculated using the previously estimated accelerometer measurement a\u0302k and the state transition matrix Ak , as described in [ 43].The details for calculating the state transition matrix can be found in [ 43].The state transition matrix can be used for estimating the acceleration of the current cycle from the estimated acceleration of the previous cycle .", "label": "", "metadata": {}}
{"text": "( 3.96 )This estimated bias term is part of the EKF observation vector .Prior Quaternion Parameter Estimation The extended Kalman filter also estimates the quaternion vector Qk .However , the EKF estimates the quaternion parameters solely based on the system model because there is no observations for the quaternion parame- ters .By incorporating a prior estimate of Qk in the EKF observation vector , better estimation of the quaternion parameters is possible .The accelerom- eter and magnetometer measurements may be used to calculate roll , pitch and yaw according to Equation 3.20 , Equation 3.21 , and Equation 3.24 .", "label": "", "metadata": {}}
{"text": "The rotation matrix can be used for calculat- ing the quaternion vector according to Equation 3.71 , and as a result , this 75 3.3 . calculated quaternion vector is directly related to the observed accelerom- eter and magnetometer measurement at the current cycle .The calculated quaternion is added to the observation vector of the EKF .Loosely Coupled Algorithm with Augmented Observations The loosely coupled integration with augmented observations is shown in Figure 3.10 .The system model is the same as that discussed in Sec- tion 3.3.1 .However , the measurement model is not the same due to the augmented observation vector .", "label": "", "metadata": {}}
{"text": "( 3.98 )Given the matrices of Equation 3.97 and Equation 3.98 , as well as the system model and measurement model , the standard Kalman filter algo- rithm can be implemented to estimate the positioning solution .Tightly Coupled Algorithm with Augmented Observations The tightly coupled algorithm with augmented observations is depicted in Figure 3.11 .In this case the observation vector consists of the current difference values , instead of \u03b4rnk as found in the observation vector of the loosely coupled algorithm .The other elements of the observation vector remain the same as for loosely coupled integration .", "label": "", "metadata": {}}
{"text": "Therefore , the differentials are calculated numerically .Given the matrices of Equation 3.99 and Equation 3.100 , as well as the system model and measurement model , the standard Kalman filter algorithm found in any standard text [ 39 , 50 ] can be implemented to estimate the positioning solution . 79Chapter 4 Experimental Work and Results In this chapter the experimental results for the performance analysis of the proposed algorithms described in the previous chapter are discussed .The description of the necessary experimental setup is first presented fol- lowed by details of the data collection and data processing procedure .", "label": "", "metadata": {}}
{"text": "The limitations and future scope of the experiments are also dis- cussed in this chapter .4.1 Experiment 4.1.1 Data Collection For the proposed indoor positioning solution , inertial sensor data and data from the OAOA sensor are necessary .These data are then used by the proposed algorithm to calculate the positioning solution .Experiment Figure 4.1 : A commercial athletic performance sensor used as the IMU unit .IMU Data Collection In Figures 3.7 , 3.8 , 3.10 , and 3.11 the IMU block supplies raw accelerom- eter , gyroscope and magnetometer measurements to the INS mechanization block .", "label": "", "metadata": {}}
{"text": "This device contains accelerometers , gyroscopes and magnetometers along three orthogonal axes and is able to collect data at a frequency of 100 Hz .For collecting data with an IMU , motion is required and this is provided by the ' turntable ' shown in Figure 4.2 .The turntable is a circular rotating platform with a diameter of 60 cm .The IMU is mounted on the turntable and collects data as the turntable rotates .Experiment Diameter 60 cm Figure 4.2 : A DC motor turntable for creating a controlled motion .OAOA Data Collection The basic principle of the OAOA sensor was discussed in Chapter 3 .", "label": "", "metadata": {}}
{"text": "The new OAOA sensor is able to provide location information by determining the AOAs of the incident light from the light sources , with respect to a known reference frame .At the time of the research , the OAOA sensor was not able to collect continuous data while moving .Laboratory experiments were done in static conditions for determining the position of the sensor and the results were published in [ 4 , 5].For those experiments , several current measurements were taken for a particular position of the sensor and then averaged to find the current measurement for that particular position .", "label": "", "metadata": {}}
{"text": "For the time being , the OAOA 82 4.1 .sensor was able to provide positioning data only in static conditions . There-fore , for this work , simulated data is used for OAOA sensor observations for the case of a moving sensor .The nature of this simulated data is described in Section 4.1.2 .4.1.2 Experimental Setup Consider the hypothetical setup of Figure 4.3 which consists of the turntable and four optical sources at known coordinates .For this exper- iment the turntable is rotated at a constant angular velocity of 36 deg / sec .Therefore , the turntable makes one complete revolution in 10 seconds .", "label": "", "metadata": {}}
{"text": "Experiment a practical experiment with the OAOA sensor collecting data in a dynamic environment , the OAOA sensor and the IMU should be stacked together .In that case the OAOA sensor can sense the AOA of the incident light beams from the optical sources .The AOA values can later be used to calculate the position of the OAOA sensor .However , as stated earlier , the OAOA sen- sor is not yet ready to collect to data in a dynamic environment .Therefore , only the INS sensor is mounted on the turntable and the turntable is rotated at a constant velocity .", "label": "", "metadata": {}}
{"text": "For calculating theoretical AOA values , to use as simulated data , the geometry of the trajectory and the velocity of the INS module are required .For a known geometry ( circular in this case ) , the position of any moving object can be calculated using simple equations of motion .Since the geometry of the path and the velocity are already known , for any particular position of the IMU on the rotating turntable , theoretical AOA values for the four optical beacons can be calculated .These ' true ' AOA values are then corrupted with additive white Gaussian noise ( AWGN ) and become the simulated OAOA data .", "label": "", "metadata": {}}
{"text": "Therefore , for this work different OAOA update rates are used to investigate the effect of the OAOA update rate on the performance of the positioning solution .Figure 4.4 : Comparison between true and estimated trajectories .Performance Analysis and Discussion The simulated OAOA measurements are generated at update rates of 10 Hz and 5 Hz .These OAOA position measurements are used to update the 100 Hz INS positioning solution using the proposed algorithms described in Chapter 3 .Consequently , an OAOA update is provided to the INS position- ing process every 10 or 20 epochs .", "label": "", "metadata": {}}
{"text": "In this work , positioning is performed in a horizontal ( 2-D ) plane because the turntable is only able to provide a motion in 2-D space .However , this same algorithm is able to provide positioning solution in a three dimensional space .4.2 Performance Analysis and Discussion Figure 4.4(a ) shows the true trajectory ( determined by known geometry , which is a circle with 60 cm diameter in this case ) and the trajectory de- termined from the simulated and noise - corrupted OAOA values only .Note that no IMU data is used to produce the trajectories in Figure 4.4(a ) .", "label": "", "metadata": {}}
{"text": "The simulated OAOA position information is created by computing the theoretical AOA values with noise .As stated above , in this work only horizontal positioning is considered , which depends only on the azimuthal angles if a particular orientation of the sensor is considered .From [ 4 ] it is clear that azimuthal angle errors are relatively constant irrespective of the position of the photosensor , which means the 86 4.2 .Performance Analysis and Discussion errors in the azimuthal angle do not depend on the actual values of the azimuthal angle .Using these noise corrupted AOA measurements , the trajectory of Figure 4.4(a ) is obtained , where the maximum error is 7.34 cm .", "label": "", "metadata": {}}
{"text": "Figure 4.4(b ) shows the true trajectory and the trajectory determined by integrating INS and OAOA with the loosely coupled integration algorithm depicted in Figure 3.7 .The INS / OAOA trajectory exhibits a smooth tran- sition from one epoch to the next , as expected , given the use of the EKF .It is obvious from the comparison of Figure 4.4(a ) and Figure 4.4(b ) that the integrated system provides a better solution in terms of accuracy and smoothness .The tightly coupled integration system of Figure 3.8 provides a trajectory similar to that of Figure 4.4(b ) but with better accuracy .", "label": "", "metadata": {}}
{"text": "Therefore , the performance comparisons are quantified in tabular form as shown in Tables 4.1 , 4.2 , 4.3 , and 4.4 .Table 4.2 is similar to Table 4.1 but with a different update rate from the OAOA sensor , which is 5 Hz .Maximum errors and average errors are given for OAOA - only , loosely coupled , tightly coupled , loosely coupled with augmented observation and tightly coupled with aug- mented observation algorithms .For the results in Table 4.1 , the OAOA update is provided at every 10th sample of the INS data .For the OAOA- only case the maximum position error is 7.34 cm and average positioning error is 4.21 cm .", "label": "", "metadata": {}}
{"text": "The improvement in performance of the tightly coupled system is not evident when considering maximum error only .The maximum error may occur due to a large value of noise at a particular epoch .However , as expected , the improvement in the average error is evident for the tightly coupled system is only 1.67 cm , compared to an average error of 2.34 cm for the case of the loosely coupled 88 4.2 .Performance Analysis and Discussion system .The last two rows of Table 4.1 show the performance of the loosely coupled system and tightly coupled system with augmented observations , as depicted in Figure 3.10 and Figure 3.11 respectively .", "label": "", "metadata": {}}
{"text": "This may be due to the high update rate from the OAOA sensor .Due to the high update rate , there may be a little room for the better algorithms to show significant performance improvement since the INS solution is being updated by OAOA measurement so often .However , the performance improvement is evident in the case where update rate is lower , as will be shown below .That is , the OAOA data rate is 5 Hz .In this case the performance of every algorithm is worse than that shown 89 4.2 .Performance Analysis and Discussion in Table 4.1 .", "label": "", "metadata": {}}
{"text": "With a lower OAOA sensor update rate , the positioning solution is more dependent on the INS - only information which is susceptible to drift over time .Note here , the significant improvement in performance obtained by using the loosely coupled and tightly coupled algorithm with augmented observa- tions .This was not significant in the results of Table 4.1 where the update rate was higher .Therefore , it can be concluded that the loosely coupled and tightly coupled algorithms with augmented observations perform sig- nificantly better when update rate from the OAOA sensor is lower .In the case where the update rate is lower , the INS has to perform independently for a longer amount of time , which in turn allows the positioning solution to drift .", "label": "", "metadata": {}}
{"text": "Another important observation from Tables 4.1 and 4.2 is that in the case of augmented observations , the maximum error does not increase as much as the average error when the update rate was halved .When the update rate is halved , the average error for the loosely coupled system with augmented observations increases by 41 % , while the maximum error increases by only 25 % .For the tightly coupled system with augmented observations , the increase in the average error is 79 % , while the maximum error increases by only 10 % .Therefore , it can be concluded that the algo- rithms with augmented observations appear to bound the maximum error , which may be significant for some applications .", "label": "", "metadata": {}}
{"text": "Using these noise corrupted AOA measurements , only a similar trajectory as shown in Figure 4.4(a ) is obtained .In this case the maximum error is 10.13 cm , and the average error is 5.94 cm .Similar to Table 4.1 , Table 4.3 compares the OAOA - only , loosely cou- pled , tightly coupled , loosely coupled with augmented observations and tightly coupled with augmented observations algorithms , but with an in- creased amount of noise .As expected , the maximum errors and the average errors are increased compared to Table 4.1 .Note that in Table 4.3 , the tightly coupled system has better accuracy than the loosely coupled system , and that algorithms with augmented ob- 91 4.2 .", "label": "", "metadata": {}}
{"text": "This result is slightly different from the result shown in Table 4.1 , where the improvement is not signifi- ca nt for the algorithms with augmented observations .It can be concluded that with a higher amount of noise , the two algorithms with augmented ob- servations perform better compared to the algorithms without augmented observations .Due to the increased amount of noise , there is room for the algorithms with augmented observations to improve the performance by pro- viding a more accurate positioning solution .In the case of lower noise , the performance of the algorithms without augmented observations is compara- tively better , and therefore , it may not be possible to improve performance with the inclusion of augmented observations .", "label": "", "metadata": {}}
{"text": "The results of Table 4.4 are similar to that of Table 4.2 but with 92 4.2 .Performance Analysis and Discussion an increased amount of error ( as expected ) .The improved performance of the algorithms with augmented observations is also evident in this case .In addition , as observed when comparing Table 4.1 and 4.2 , the performance of the integration algorithm in Table 4.4 is worse than those in Table 4.3 due to a lower OAOA update rate for the results in Table 4.4 .IPS strategy Avg . error without bias estimation [ cm ] Avg .", "label": "", "metadata": {}}
{"text": "The results of Table 4.5 are obtained under the same experimental conditions as those of Table 4.1 .The first column is the average position error for all four algorithms without estimating the magnetometer bias .The second column is the average position error for all proposed algorithms with the magnetometer bias estimation .Magnetometer bias estimation improves the average positioning error of loosely coupled , tightly coupled , loosely coupled with augmented observa- 93 4.2 .Performance Analysis and Discussion tions , and tightly coupled with augmented observations algorithms by 3.7 % , 6.2 % , 5.2 % , and 7.0 % , respectively , compared to the case when magnetome- ter bias estimation is not performed .", "label": "", "metadata": {}}
{"text": "94Chapter 5 Conclusions and Future Work This research is based on a novel indoor positioning solution [ 4 ] , which was proposed in 2011 , based on AOA of light measured by a newly devised differential photosensor .However , an unobstructed LOS view between the optical source and photosensor is required given that the system is based on visible light .Anything blocking the LOS view between the source and sensor will destroy the integrity of the positioning system .Moreover , due to the independent measurement noise in the OAOA measurements , the resultant trajectory of the OAOA based positioning solution is not smooth .", "label": "", "metadata": {}}
{"text": "For outdoor positioning an inertial navigation system can be used as a backup navigation system in the case of GNSS outage .The problem at hand , being similar to GNSS outages in outdoor environments , led to the idea of an indoor positioning solution that combines INS and OAOA - based positioning to provide a more accurate and reliable indoor positioning solution .The objective of this research was to develop algorithms to integrate 95 5.1 .Developed Algorithms OAOA - based indoor positioning with INS based positioning to provide a more accurate and reliable positioning solution for indoor environments .", "label": "", "metadata": {}}
{"text": "In this chapter , all the key conclusions of this research are summarized .This is followed by recommendations for future work .5.1 Developed Algorithms For the four different algorithms developed to integrate OAOA - based positioning with INS - based positioning , an extended Kalman filter was used .The loosely coupled algorithm and tightly coupled algorithm were developed first .Then the observation vector for the EKF was augmented by adding an accelerometer bias estimate and quaternion vector estimate .This led to two more algorithms , namely , the loosely coupled algorithm with augmented observations and the tightly coupled system with augmented observations .", "label": "", "metadata": {}}
{"text": "Inclusion of the magnetometer bias estimation improves the average positioning error of the four algorithms by 3.7 % to 7 % .Since mathematical singularities may occur in the case of using Euler angles , quaternion algebra was used instead to update the rotation matrix .Therefore , the EKF was used here for estimating the quaternion parameters in addition to the estimation of the conventional parameters of an error state 96 5.1 .Developed Algorithms Kalman filter .The four proposed algorithms all performed better than the OAOA - only based indoor positioning solution .A maximum error of 7.34 cm and an average error of 4.21 cm for OAOA - only positioning was reduced to 3.15 cm and 2.34 cm , respectively , by using the loosely coupled integration algorithm .", "label": "", "metadata": {}}
{"text": "For the same experiment , the tightly coupled integration algorithm outperforms the loosely coupled algorithm by reducing the average error to 1.67 cm , an improvement of approximately 60 % .From all experiments conducted , it can be concluded that the tightly coupled system improves the average error by at least 14 % compared to the loosely coupled algorithm .The algorithms with augmented observations perform significantly bet- ter than those without augmented observations , where the OAOA update rate is low .An average position error of 4.89 cm is reduced to 3.11 cm by using loosely coupled algorithm with augmented observations compared to the loosely coupled algorithm without observation augmentation .", "label": "", "metadata": {}}
{"text": "For the tightly coupled system , this improvement in the average error is approximately 32.3 % .Improve- ment of performance by using augmented observations is also evident where overall performance is worse due to an increased amount of noise added to the OAOA simulated measurements .For a 97 5.2 .Limitations and Future Work tightly coupled algorithm this improvement is approximately 6 % .It can be concluded that if the update rate of the OAOA sensor is low , or if overall performance is worse due to an extended amount of noise in the simulated OAOA measurements , the algorithms with augmented observations perform significantly better .", "label": "", "metadata": {}}
{"text": "At the time of conducting the research , the newly devised OAOA sensor was not able to collect data in a dynamic environment .Therefore , simulated data for the OAOA sensor was used for experimental purposes .This also limited the experimental trajectory to be a path of known geometry .In this case , a turntable was used for the experiment and , hence , the trajectory was circular .Theoretical ( ' true ' ) positions for the OAOA sensor can be easily calculated given the rotation speed of the turntable .By adding the neces- sary circuitry to the OAOA sensor to collect data in a dynamic environment experiments could be conducted for arbitrary trajectories and arbitrary ve- locities .", "label": "", "metadata": {}}
{"text": "For this work , all algorithms were implemented on a computer with significant processing capacity .However , for a practical indoor position- ing solution working in real time , the microprocessor in the tracked device will most likely have limited computational capacity .Therefore , a study on the computational requirements of the proposed algorithms should be conducted .The computational complexity of the different algorithms may 98 5.2 .Limitations and Future Work limit their use in a indoor positioning system with limited computational capability .99 Bibliography [ 1 ] The Concise Oxford Dictionary , 9th ed .", "label": "", "metadata": {}}
{"text": "[ 2 ] M. Depsey , \" Indoor positioning systems in healthcare , \" in Radianse Inc. , White Paper , 2003 .[ 3 ] A. L. Yanying Gu and I. Niemegeers , \" A survey of indoor positioning systems for wireless personal networks , \" IEEE Communication Surveys & Tutorials , vol .11 , pp .13 - 32 , 2009 .[ 4 ] A. Arafa , X. Jin , and R. Klukas , \" A differential photosensor for indoor optical wireless positioing , \" in 24th International Technical Meeting of The Satellite Division of the Institute of Navigation ( ION GNSS 2011 ) , Portland , OR , 2011 .", "label": "", "metadata": {}}
{"text": "5 ] - , \" Wireless indoor optical positioning with a differential photosen-sor , \" IEEE Photonics Technology Letters , vol .24 , pp .1027 - 1029 , Jun 2012 .[ 6 ] X. Jin and J. F. Holzman , \" Differential retro - detection for remote sens- ing applications , \" IEEE Sensors Journal , vol .10 , no .12 , pp . 1883- 1887 , Dec. 2010 .[ 7 ] C. A. Patterson , R. R. Muntz , and C. M. Pancake , \" Challenges in location - aware computing , \" IEEE Pervasive Computing , vol .", "label": "", "metadata": {}}
{"text": "80 - 89 , 2003 .[ 8 ] J. Hightower and G. Borriello , \" Location sensing techniques , \" in Tech- nical Report UW CSE 2001 - 07 - 30 , Department of Computer Science and Engineering , University of Washington , 2001 .[ 9 ] K. Kaemarungsi and P. Krishnamurthy , \" Properties of indoor received signal strength for wlan location fingerprinting , \" in Proc . 1stAnnual International Conference on Mobile and Ubiquitous Systems : Network- ing and Services ( MobiQuitous 04 ) , Boston , Mass , USA , aug 2004 , pp .", "label": "", "metadata": {}}
{"text": "100 Bibliography [ 10 ] P. D. Groves , Principles of GNSS , Inertial , and Multisensor Integrated Navigation System .Boston : Artech House , 2008 .[ 11 ] M. Vossiek , L. Wiebking , P. Gulden , J. Wiehardt , C. Hoffmann , and P. Heide , \" Wireless local positioning , \" IEEE Microwave Magazine , vol .4 , pp .77 - 86 , Dec 2003 .[ 12 ] J. C. Chen , Y. C. Wang , C. S. Maa , and J. T. Chen , \" Network - side mobile position location using factor graphs , \" IEEE Trans .", "label": "", "metadata": {}}
{"text": "5 , no .10 , pp .46 - 52 , Oct 2006 .[ 13 ] R. Casas , D. Cuartielles , A. Marco , H. J. Gracia , and J. L. Falc , \" Hid- den issues in deploying an indoor location system , \" IEEE Pervasive Computing , vol .6 , no . 2 , pp .62 - 69 , 2007 .[14 ] X. Fernando , S. Krishnan , H. Sun , and K. Kazemi - Moud , \" Adaptive denoising at infrared wireless receivers , \" in Proc .SPIE , 2003 .", "label": "", "metadata": {}}
{"text": "4 , no .5 , pp .42 - 47 , Oct 1997 .[16 ] N. Priyantha , A. Chakraborty , and H. Balakrishnan , \" The cricket location- support system , \" in Proc .ACM Conference on Mobile Com- puting and Networking , 2000 .[17 ] N. B. Priyantha , The Cricket Indoor Location System .PhD thesis , MIT , 2005 .[ 18 ] ( 2008 )Sonitor system website .[Online].IEEE Workshop on Software Technologies for Future Embedded Systems , May 2003 .[20 ] M. S. H. Piontek and J. Kaiser , \" Improving the accuracy of ultrasound- based localisation systems , \" in Proc .", "label": "", "metadata": {}}
{"text": "[21 ] L. M. Ni and Y. Liu , \" Landmarc : Indoor location sensing using active RFID , \" in Proc .IEEE International Conference on Pervasive Comput- ing and Communications , 2003 , pp .407 - 416 .101 Bibliography [ 22 ] ( 2008 )Wherenet web site .[Online]. com / docentauthorware / WhereNet / intro / intro1 . asp [ 23 ] P. Bahl and V. Padmanabhan , \" RADAR : An in - building RF based user location and tracking system , \" in Proc .IEEE INFOCOM , vol .", "label": "", "metadata": {}}
{"text": "775 - 784 .[ 24 ] ( 2008 ) Ekahau .[Online].6th International Symposium on Satellite Navigation Technology Including Mobile Positioning and Location Services , 2003 .[26 ] T. Kitasuka , K. Hisazumi , T. Nakanishi , and A. Fukuda , \" Wips : Loca- tion and motion sensing technique of IEEE 802.11 devices , \" in Proc . 3rd International Conference on Information Technology and Applications ( ICITA05 ) , vol .2 , 2005 , pp .346 - 349 .[ 27 ] S. Kawakubo , A. Chansavang , S. Tanaka , T. Iwasaki , K. Sasaki , T. Hi- rota , H. Hosaka , and H. Ando , \" Wireless network system for indoor human positioning , \" in Proc . 1st", "label": "", "metadata": {}}
{"text": "[28 ] A. Genco , \" Three step bluetooth positioning , \" in Lecture Notes in Com- puter Science , vol .3479 , 2005 , pp .52 - 62 .[29 ] J. Hallberg , M. Nilsson , and K. Synnes , \" Positioning with bluetooth , \" in Proc . 10th International Conference on Telecommunications , 2003 .[ 30 ] M. Rodriguez , J. P. Pece , and C. J. Escudero , \" In - building location using bluetooth , \" in Proc .IWWAN , 2005 .[ 31 ] J. C. F. Michel , M. Christmann , M. Fiegert , P. Gulden , and M. Vossiek , \" Multisensor based indoor vehicle localization system for production and logistic , \" in Proc .", "label": "", "metadata": {}}
{"text": "553 - 558 .[ 32 ] F. Raab , E. B. Blood , T. O. Steiner , and H. R. Jones , \" Magnetic po- sition and orientation tracking system , \" IEEE Trans .Aerospace and Electronic Systems , vol .AES-15 , no .5 , pp .709 - 718 , Sep 1979 .102 Bibliography [ 33 ] J. Krumm , S. Harris , B. Meyers , B. Brumitt , M. Hale , and S. Shafer , \" Multi - camera multi - person tracking for easy living , \" in Proc . 3rd IEEE Intl Workshop Visual Surveillance , 2000 .", "label": "", "metadata": {}}
{"text": "34 ] D. Focken and R. Stiefelhagen , \" Towards vision - based 3-D people track- ing in a smart room , \" in Proc . 4thIEEE International Conference on Multimodal Interfaces , Oct 2002 .[ 35 ] A. Madhavapeddy , D. Scott , and R. Sharp , \" Context - aware comput- ing with sound , \" in Proc .5th International Conference on Ubiquitous Computing , oct 2003 .[36 ] N. El - Sheimy and X. Niu , \" The promise of mems to the navigation community , \" Inside GNSS , pp .", "label": "", "metadata": {}}
{"text": "[ 37 ] M. Petovello , C. O'Driscoll , and G. Lachapelle , \" Ultra - tight GPS / INS for carrier phase positioing in weak - signal environments , \" NATO RTO SET-104 Symposium on Military Capabilities Enabled by Advances in Navigation Sensors , Oct 2007 .[ 38 ] D. Titterton and J. Weston , Strapdown Inertial Navigation Technology , 2nd ed .Stevenage , U.K. : IEE , 2004 .[ 39 ] M. Grewal , L. Weill , and A. Andrews , Global Positioining Systems , Inertial Navigation , and Integration .Newyork , U.S. : Wiley , 2001 .", "label": "", "metadata": {}}
{"text": "40 ] Gebre - Egziabher , M. Petovello , and G. Lachapelle , \" Weighting gnss ob- servations and variations of GNSS / INS integration , \" GNSS Solutions : Inside GNSS , pp .26 - 33 , 2007 .[ 41 ] M. Petovello , Real - Time Integration of a Tactical - Grade IMU and GPS for High - Accuracy Positioning and Navigation .Ph.D. dissertation , Department of Geomatics Engineering , University of Calgary , 2003 .[42 ] R. V. Wong , Development of a RLG strapdown inertial survey system .Ph.D. dissertation , Department of Geomatics Engineering , University of Calgary , 1988 .", "label": "", "metadata": {}}
{"text": "43 ] F. Sadi , Jump Parameter Estimation with Low Cost MEMS Sensors and GPS for Action Sports Goggles .Master 's thesis , School of Engineering , University of British Columbia , Okanagan , 2011 .[44 ] K. P. Schwarz and M. Wei , Inertial Navigation Systems with Geodetic Applications .Partial Lecture Notes for ENGO 623 .Department of Geomatics Engineering , The University of Calgary .103 Bibliography [ 45 ] N. El - Sheimy , \" The potential of partial imus for land vehicle naviga- tion , \" InsideGNSS , Spring 2008 .[", "label": "", "metadata": {}}
{"text": "Master 's thesis , Department of Geomatics Engineering , University of Calgary , Feb. 2006 .[47 ] K. P. Schwarz and M. Wei , INS / GPS Integration for Geodetic Applica- tions .New York , NY . , USA : Walter de Gruyter .[ 48 ] K. J. Walchko and D. P. A. C. Mason , \" Inertial navigation , \" in Con- ference on Recent Advances in Robotics , 2002 .[49 ] S. Nassar , Improving the inertial navigation system ( INS ) error model for INS and INS / DGPS applications .", "label": "", "metadata": {}}
{"text": "[50 ] S. M. Kay , Fundamentals of Statistical Signal Processing : Estimation Theory .Prentice Hall PTR , Upper Saddle River , 1993 .[51 ] M. Grewal and A. Andrews , Kalman Filtering :Theory and Practice Using MATLAB .Wiley - Interscience Publications , 2001 .Citation Scheme : APA APA ( 5th Edition ) APA No DOI , No Issue BibTeX Chicago , Author , Date IEEE LexisNexis ( Guide Lluelles , 7th Edition ) Modern Language Association , With Url Turabian , Full Note Bibliography .Feedback on Open Collections Website .Open Collections is an initiative to bring together locally created and managed content from the University of British Columbia Library 's open access repositories .", "label": "", "metadata": {}}
{"text": "If you notice any bugs , display issues , or data issues - or just want to say hi - you 're in the right place !Thanks for visiting Open Collections .Sign up to receive free email alerts when patent applications with chosen keywords are published SIGN UP .Abstract : .The aspects enable a processor to concurrently execute a first serial language code embedding a second serial language code during a page load by a browser .A parser parses the first serial language code until a segment of the embedded second serial language code is encountered .", "label": "", "metadata": {}}
{"text": "Code generated by execution of second serial language code is evaluated to determine if it is well - formed , and partial rollback and re - parsing of the first serial language code is performed if the code is not well - formed .Concurrent parsing of first serial language code and execution of second language code , with partial roll back and reparsing when necessary , continues until the first language code has been parsed and the second serial language code has been executed .Claims : .The computing device of claim 1 , wherein means for storing the execution state package in a scripting language script queue comprises means for storing the execution state package in a rear terminal position of the scripting language script queue .", "label": "", "metadata": {}}
{"text": "The computing device of claim 1 , wherein means for obtaining the segment of scripting language from the scripting language script queue comprises means for extracting the segment of scripting language code from the execution state package stored in a front terminal of the scripting language script queue .The computing device of claim 1 , wherein means for storing the generated markup language comprises : means for inserting the generated markup language code into the received markup language code associated with the requested web page .The computing device of claim 1 , wherein the markup language is HTML .", "label": "", "metadata": {}}
{"text": "[ 0001 ] This application is a continuation of U.S. patent application Ser .No .13/106,064 entitled \" Concurrent Parsing and Processing of HTML and JavaScript \u00ae \" filed on May 12 , 2011 , the entire contents of which are hereby incorporated by reference for all purposes .[0002 ] This application is also related to U.S. patent application Ser .No .13/589,862 entitled \" Concurrent Parsing and Processing of HTML and JavaScript \u00ae \" filed Aug. 20 , 2012 .FIELD .[ 0003 ] The present invention relates to methods , systems , and devices for rendering HTML documents in a web browser , and more particularly to methods for concurrent parsing of HTML and processing of JAVASCRIPT \u00ae implemented in a mobile device processor .", "label": "", "metadata": {}}
{"text": "[0004 ] Dynamic scripting languages are a preferred development platform in computer programming and software development .In particular , JAVASCRIPT \u00ae , which may be embedded in Hyper - Text Markup Language ( HTML ) , is a popular development language for web pages and web applications .Dynamic scripting languages are designed for interactive execution ( scripting ) , and typically execute via interpretation , in which , at runtime , the scripts are parsed and analyzed before they are executed .As more and more features are demanded by users of web pages and web applications , the complexity and quantity of dynamic scripting languages embedded in HTML continues to increase .", "label": "", "metadata": {}}
{"text": "SUMMARY .[ 0005 ] The various aspects disclosed herein provide methods for concurrently executing an HTML parser and a JAVASCRIPT \u00ae execution engine during a page load operation in a browser .Most web pages contain JAVASCRIPT \u00ae code embedded within HTML code .Most browsers process the HTML code and the JAVASCRIPT \u00ae code sequentially ( e.g. , serially ) , as they are encountered during the parsing of the HTML code .Specifically , in current browsers , an HTML parser runs until it encounters a script tag , at which point it suspends its operations while a JAVASCRIPT \u00ae execution engine executes the contents of the script associated with that tag ( i.e. on the script text ) .", "label": "", "metadata": {}}
{"text": "This process is specified by standards and ensures that HTML code generated by execution of JAVASCRIPT \u00ae text is parsed in the proper order .However , this serial execution of the HTML and JAVASCRIPT \u00ae processes significantly slows down the process of loading and displaying a webpage .The various aspects allow the HTML parser and the JAVASCRIPT \u00ae engine to execute concurrently .Concurrent execution speeds page loading in a browser by not stalling the parsing of the HTML code while the JAVASCRIPT \u00ae scripts are fetched , loaded , parsed , and executed .[0007 ] In executing the markup language code in a processor , the various aspects provide for receiving a request to load a web page as well as markup language code ( including embedded scripting language code ) associated with the requested web page .", "label": "", "metadata": {}}
{"text": "The parsing may continue until a segment of the embedded scripting language code is encountered .Upon encountering a segment of the embedded scripting language code , the various aspects provide for packaging the scripting language code and parsing state information into an execution state package .In various aspects , the execution state package may be stored in a scripting language script queue and the parsing the received markup language code may be resumed .In various aspects , when it is determined that the generated markup language code is well formed , the generated markup language code may be stored in a memory .", "label": "", "metadata": {}}
{"text": "In various aspects , obtaining the segment of scripting language from the scripting language script queue may be initiated in response to an execution state package being stored in the scripting language script queue .In various aspects , obtaining a segment of scripting language from the scripting language script queue may include extracting the segment of scripting language code from the execution state package stored in a front terminal of the scripting language script queue .[0010 ] In various aspects , an obtained segment of scripting language may be executed independent of the concurrently executing parsing process .", "label": "", "metadata": {}}
{"text": "[ 0011 ] The various aspects provide for repeating the execution of one or more of the above mentioned operations until all markup language code has been parsed and all scripting language code has been executed .[ 0012 ]In various aspects , the storing the generated markup language may include inserting the generated markup language code into markup language code associated with the requested web page .In various aspects , the process of determining whether the markup language code generated from execution of the obtained segment of scripting language is well formed may include parsing the generated markup language code with a well formed parser .", "label": "", "metadata": {}}
{"text": "[ 0013 ] Some aspects include computing devices with means for accomplishing the operations of the foregoing methods .Further aspects include a computing device including memory and a processor coupled to the memory and configured with process - executable instructions to perform the operations of the foregoing methods .Further aspects include non - transitory computer readable storage medium having stored thereon processor - executable instructions configured to cause a computing device processor to perform the operations of the foregoing methods .BRIEF DESCRIPTION OF THE DRAWINGS .[ 0014 ]The accompanying drawings , which are incorporated herein and constitute part of this specification , illustrate exemplary aspects of the invention , and together with the general description given above and the detailed description given below , serve to explain the features of the invention .", "label": "", "metadata": {}}
{"text": "1 is a timing diagram that illustrates a method for controlling the interaction between HTML processing and JAVASCRIPT \u00ae processing during a page load operation in a browser .[ 0016 ] FIG .2 is a timing diagram that illustrates an alternative method for controlling the interaction between HTML processing and JAVASCRIPT \u00ae processing during a page load operation in which there is only a one - way dependency between the HTML parser and the JAVASCRIPT \u00ae engine .[0017 ]FIG .3 is a timing diagram that illustrates another alternative method for controlling the interaction between HTML processing and JAVASCRIPT \u00ae processing during a page load operation in which there is only a one - way dependency between the HTML parser and the JAVASCRIPT \u00ae engine .", "label": "", "metadata": {}}
{"text": "4 is a timing diagram that illustrates the processing times associated with each of the methods illustrated in FIGS . 1 - 3 . [ 0019 ]FIG .5 is a process flow diagram that illustrates an aspect method for controlling the interaction between HTML processing and JAVASCRIPT \u00ae processing during a page load operation .[ 0020 ] FIG .6 is a process block diagram of functional components suitable for use with the various aspects .[ 0021 ] FIG .7 is a cutaway perspective view of a mobile computing device suitable for use with the various aspects .", "label": "", "metadata": {}}
{"text": "FIG .8 is an illustration of an example computer suitable for use with the various aspects .DETAILED DESCRIPTION .[ 0023 ] The various aspects will be described in detail with reference to the accompanying drawings .Wherever possible , the same reference numbers will be used throughout the drawings to refer to the same or like parts .References made to particular examples and implementations are for illustrative purposes , and are not intended to limit the scope of the invention or the claims .[ 0024 ] The word \" exemplary \" is used herein to mean \" serving as an example , instance , or illustration . \"", "label": "", "metadata": {}}
{"text": "While the various aspects are particularly useful in mobile devices , such as cellular telephones , which may have limited processing power , the aspects are generally useful in any computing device that executes scripts and/or applications written in dynamic , scripting and/or markup languages .These terms may also refer to any language that runs on a managed runtime and is dynamically compiled .Examples of dynamic and scripting languages within the scope of this application include , for example , JAVASCRIPT \u00ae , PERL , PYTHON , and RUBY , as well as JAVA and other languages that may be developed in the future .", "label": "", "metadata": {}}
{"text": "Examples of markup languages include Scribe , Standard Generalized Markup Language ( SGML ) , Hyper - Text Markup Language ( HTML ) , Extensible Markup Language ( XML ) , and Extensible Hyper - Text Markup Language ( XHTML ) .[ 0028 ] The term \" queue \" is used generically in this application to refer to a linear data structure containing an ordered collection of objects .The principal operations on the queue are the addition of entities to the rear terminal position and removal of entities from the front terminal position .Queues are generally First - In - First - Out ( FIFO ) data structures , in which the first element added to the queue will be the first one to be removed .", "label": "", "metadata": {}}
{"text": "A linked list is a data structure that includes a sequence of objects containing a reference link to the next record in the sequence .Linked lists allow objects to be inserted and/or removed at any position in the list by modifying the reference links of one or more individual objects .Thus , the order of the linked items may be different from the order that the data items are stored in memory or on disk .[ 0029 ] For ease of reference , throughout this application , HTML is used as an exemplary markup language and JAVASCRIPT \u00ae is used as an exemplary dynamic scripting language .", "label": "", "metadata": {}}
{"text": "[ 0030 ] HTML is a markup language that implements the ISO / IEC 15445 standard .HTML may be characterized as a set of markup tags ( e.g. , annotations ) used to describe web pages such that they can be displayed by a software application , such as a web browser .HTML allows for the creation of structured documents by denoting structural semantics for text , such as headings , paragraphs , lists , links , quotes , and other items .[0031 ] JAVASCRIPT \u00ae is a dynamic , weakly typed , object - oriented scripting language that implements the ECMAScript language standard ( standardized by ECMA International in the ECMA-262 specification ) and/or the ISO / IEC 16262 standard .", "label": "", "metadata": {}}
{"text": "[ 0032 ] HTML can embed JAVASCRIPT \u00ae code capable of affecting the behavior and/or presentation of the containing HTML page .The embedded JAVASCRIPT \u00ae code may also generate additional HTML code , which can be inserted into the containing HTML page ( the HTML code in which the JAVASCRIPT \u00ae is embedded ) .JAVASCRIPT \u00ae may be used to embed functions into HTML code such that the functions interact with , and manipulate , the document object model ( DOM ) of the HTML page .DOM is a language - independent convention for representing and interacting with objects in HTML , and allows the JAVASCRIPT \u00ae code to have access to , and manipulate , the containing HTML page .", "label": "", "metadata": {}}
{"text": "To enable this , the HTML code ( including HTML code generated by execution of JAVASCRIPT \u00ae code ) current standards require the code to be parsed in sequential ( i.e. , serial ) order so as to avoid repeatedly evaluating and/or processing the same information .To ensure proper order , browsers typically require at least two different mechanisms , or processes , to interpret , parse , and execute the JAVASCRIPT \u00ae code and the containing HTML code .For example , to interpret and display an HTML web page having JAVASCRIPT \u00ae code embedded therein , web browsers must typically run an HTML parser that separates the HTML markup tags from the substantive content and a JAVASCRIPT \u00ae execution engine that parses and executes the embedded scripts .", "label": "", "metadata": {}}
{"text": "While the HTML parser is suspended , a JAVASCRIPT \u00ae engine is evoked to process the contents of the script ( i.e. script text ) associated with encountered tag .When the JAVASCRIPT \u00ae engine finishes executing the script text , it returns control back to the HTML parser , which restarts parsing the HTML code .This process is specified by standards ( e.g. , ECMAScript , ISO / IEC 16262 ) and ensures that the HTML code generated by execution of JAVASCRIPT \u00ae text is parsed in the proper ( i.e. , serial ) order .[ 0034 ] As mentioned above , the HTML parser typically runs until it encounters a JAVASCRIPT \u00ae tag , at which point it suspends its operations until the JAVASCRIPT \u00ae engine finishes executing the script text associated with the encountered tag .", "label": "", "metadata": {}}
{"text": "The serial nature of this process significantly slows down the process of loading a webpage .[ 0035 ] The various aspects provide methods for concurrently executing an HTML parser and a JAVASCRIPT \u00ae engine during a page load operation in a browser .As mentioned above , current browsers execute the HTML parser and the JAVASCRIPT \u00ae engine serially ( i.e. , one and then the other ) during the parsing of HTML code .These mechanisms allow the HTML parser and the JAVASCRIPT \u00ae engine to execute concurrently .Concurrent execution speeds up the process of loading and rendering a webpage because the HTML parser does not need to be stalled while the JAVASCRIPT \u00ae scripts are fetched , loaded , parsed , and executed .", "label": "", "metadata": {}}
{"text": "1 is a timeline of convention HTML and JAVASCRIPT \u00ae processing during a page load operation in a browser .Specifically , FIG .1 illustrates that the HTML processing and a JAVASCRIPT \u00ae processing are interdependent , and do not execute at the same time in a conventional browser .In the example illustrated in FIG .1 , the process of rendering a webpage may begin by issuing a request to a computing device for a desired page .In response , the computing device may initiate a HTML process 102 to begin executing tasks associated with a page load operation .", "label": "", "metadata": {}}
{"text": "0037 ]The JAVASCRIPT \u00ae processing unit initiates a JAVASCRIPT \u00ae process 104 to evaluate , parse , and execute the encountered script text .For example , the JAVASCRIPT \u00ae process 104 may begin issuing JAVASCRIPT \u00ae requests , parsing , and compiling the JAVASCRIPT \u00ae code , executing the compiled JAVASCRIPT \u00ae code , and/or generating HTML code .Once the JAVASCRIPT \u00ae process 104 completes its operations , any HTML code generated during execution of the scripts is inserted back into the original HTML document .The JAVASCRIPT \u00ae process 104 then transfers control back to the HTML processing unit , which restarts processing the HTML at the point it previously suspended its operations .", "label": "", "metadata": {}}
{"text": "0038 ]By stalling its operations , the HTML processing unit can ensure that the HTML code generated by the JAVASCRIPT \u00ae process 104 is parsed and checked for completeness .In this manner , the HTML processing unit can naturalize any negative impact that HTML code inserted by execution of the JAVASCRIPT \u00ae may have otherwise had on other portions of the HTML code .After all the HTML and embedded JAVASCRIPT \u00ae s are processed , the webpage may be rendered on a display of a computing device , such as on an electronic display of a mobile phone .", "label": "", "metadata": {}}
{"text": "1 , the HTML and JAVASCRIPT \u00ae processes are interdependent and must execute one after the other in a conventional browser .This serial execution is mandated by specifications set forth by the standards governing JAVASCRIPT \u00ae and HTML .Specifically , the standards specify that there is a mutual dependency between the HTML parser and the JAVASCRIPT \u00ae engine ( i.e. , the dependency runs in both directions between JAVASCRIPT \u00ae engine and the HTML parser ) .The specifications mandate this \" mutual dependency \" so as to avoid any conflicts that may arise between the HTML parser and the JAVASCRIPT \u00ae engine .", "label": "", "metadata": {}}
{"text": "[ 0040 ]As discussed above , specifications require the HTML and JAVASCRIPT \u00ae processes to be interdependent so as to avoid any conflicts that may arise between the HTML parser and the JAVASCRIPT \u00ae engine .Conflicts may arise because the JAVASCRIPT \u00ae specification allows the JAVASCRIPT \u00ae engine to generate new HTML code .This generated HTML code may change the state of the HTML parser and influence how the HTML parser parses the remaining HTML code in the document .[ 0041 ] The various aspects provide methods for processing HTML and JAVASCRIPT \u00ae so that there is only a one - way dependency between the HTML parser and the JAVASCRIPT \u00ae engine , thereby enabling concurrent parsing and execution of HTML and embedded JAVASCRIPT \u00ae .", "label": "", "metadata": {}}
{"text": "As mentioned above , the JAVASCRIPT \u00ae engine is dependent on the HTML parser because the HTML parser processes and builds portions of the code required by JAVASCRIPT \u00ae engine .However , in accordance with the various aspects , the dependence of the HTML parser on the JAVASCRIPT \u00ae engine may be broken , creating a one - way dependency between the HTML parser and the JAVASCRIPT \u00ae engine .[ 0042 ] FIG .2 illustrates timing of an alternative method for controlling the interaction between HTML processing and JAVASCRIPT \u00ae processing during a page load operation in which there is only a one - way dependency between the HTML parser and the JAVASCRIPT \u00ae engine .", "label": "", "metadata": {}}
{"text": "2 , the HTML processing unit may be configured to process all the HTML code upfront , with the JAVASCRIPT \u00ae processing unit being configured to wait until all the HTML has been processed by the HTML processing unit .This method enables portions of the processed HTML code to be pre - rendered in a browser so that a user can begin to view the contents of the page not affected by the embedded JAVASCRIPT \u00ae before all the required scripts are actually executed .However , in this alternative configuration the total time required to render the page , in its entirety , is the same as or slower than the method illustrated in FIG .", "label": "", "metadata": {}}
{"text": "This is because the JAVASCRIPT \u00ae engine must still wait until all HTML processing is complete before it can begin execution .Additionally , since the JAVASCRIPT \u00ae engine is typically initiated after the HTML processing unit , the JAVASCRIPT \u00ae engine may invalidate the HTML processing ( e.g. , HTML parsing ) , forcing the system to reparsing of the entire document and re - render the page .Additionally , since this alternative configuration is out - of - order serial parse , the parse is speculative and may have to be re - run after the execution of the JAVASCRIPT \u00ae engine .", "label": "", "metadata": {}}
{"text": "[ 0043 ] FIG .3 illustrates timing of execution of HTML and JAVASCRIPT \u00ae processing during a page load operation using an aspect method which enables the processes to execute concurrently .In the aspect methods the HTML processing and JAVASCRIPT \u00ae processing are executed concurrently , with processing broken up into processing units by the script tags appearing in the HTML code .In certain situations , after the JAVASCRIPT \u00ae scripts finish execution , the HTML code may have to be partially or totally reparsed based on the results of the JAVASCRIPT \u00ae execution .In any case , the total time required to render the entire page is significantly reduced .", "label": "", "metadata": {}}
{"text": "4 , which contrasts the processing times associated with the three methods illustrated in FIGS . 1 - 3 .Thus , a significant amount of time ( i.e. , s seconds ) may be saved by executing the HTML and JAVASCRIPT \u00ae processes concurrently .This enables concurrent execution of the HTML parser and the JAVASCRIPT \u00ae execution engine .In the various aspects the JAVASCRIPT \u00ae execution engine may determine whether results of execution of a particular JAVASCRIPT \u00ae invalidated a portion of the speculative HTML parse ( i.e. , the HTML parse that proceeded after a script tag was encountered ) .", "label": "", "metadata": {}}
{"text": "If the JAVASCRIPT \u00ae execution engine determines that the executed JAVASCRIPT \u00ae may have invalidated a portion of the speculative HTML parse , a portion of the HTML parse is discarded and the HTML parsing is rolled back to an appropriate location and the code reparsed .This ensures that any HTML code inserted by executed JAVASCRIPT \u00ae will be properly parsed .[ 0047 ] FIG .5 illustrates an aspect method 500 for controlling the interaction between HTML processing and JAVASCRIPT \u00ae processing during a page load operation so that the HTML processes can run concurrently with the JAVASCRIPT \u00ae processes .", "label": "", "metadata": {}}
{"text": "Thus , the state of execution may include the script 's execution context and the location of the script body , as well as other information identifying segments of code associated with the script tag .In various aspects , the packaging of the state of execution may involve the use of a pointer array .In these aspects , each pointer in the pointer array ( used to package the state of execution ) may point to a location in memory associated with a segment of code containing the encountered script tag .[0048 ] In various aspects , the JAVASCRIPT \u00ae execution engine may monitor the JAVASCRIPT \u00ae execution queue for actions , state changes , status updates , and/or to determine if the execution queue contains elements available for processing resulting from the execution of block 506 .", "label": "", "metadata": {}}
{"text": "In various aspects , any action , state change or status updates to the JAVASCRIPT \u00ae execution queue may trigger the JAVASCRIPT \u00ae execution engine to determine that the JAVASCRIPT \u00ae execution queue contains elements available for processing .In an aspect , only a predefined category of actions , state changes or status updates will trigger the JAVASCRIPT \u00ae execution engine .In any case , when the JAVASCRIPT \u00ae execution engine determines , or is otherwise informed , that there are elements available for processing , the saved state information may be extracted from the queue for the fetching , parsing , and execution operations .", "label": "", "metadata": {}}
{"text": "[ 0049 ] Meanwhile , the HTML parser may continue parsing the remaining portions of the HTML code in block 508 , while the JAVASCRIPT \u00ae engine executes the script in block 518 .In parsing the remaining portions of the HTML code , the HTML parser may continually evaluate the HTML code being parsed for additional script tags in determination step 510 .At determination block 512 the HTML parser may determine whether there is more HTLM code to parse , and if so , return to block 508 to continue parsing .[ 0050 ] While the HTML parser continues parsing and evaluates the HTML code , the JAVASCRIPT \u00ae engine may continue to pull and execute scripts from the JAVASCRIPT \u00ae execution queue in block 518 .", "label": "", "metadata": {}}
{"text": "When the JAVASCRIPT \u00ae execution engine encounters a document.write ( ) function , for example , in block 520 , the JAVASCRIPT \u00ae engine may execute the document.write ( ) function to generate and insert HTML code directly into the main HTML document in block 522 .It should be noted that the document.write ( ) function is a predefined function in JAVASCRIPT \u00ae that allows HTML text to be outputted into the document containing the script , and is used here for illustrative purposes only .Nothing in this application should be understood as limiting the scope to the document.write ( ) function , unless expressly recited in the claims .", "label": "", "metadata": {}}
{"text": "This insertion of generated HTML code may modify the DOM tree used by the HTML processes , which may create new nodes for the DOM tree , and annex the new nodes to the main DOM tree .[0052 ]After executing the write function in block 522 , the JAVASCRIPT \u00ae engine may parse the resulting buffer of HTML code produced by executing a write function call , for example , by using a well formed HTML parser ( WHP ) in block 524 .In determination block 526 , the JAVASCRIPT \u00ae engine may determine if the document is well formed .", "label": "", "metadata": {}}
{"text": "The state information used in this roll back operation will be that saved in block 506 for the script tag that resulted in the not well formed HTML document .For example , the roll back may proceed to a state of execution immediately preceding the script tag for the JAVASCRIPT \u00ae that resulted in the encountered problem .The HTML parser may use this loaded state information to roll back changes made by the JAVASCRIPT \u00ae execution engine , and to restart parsing the HTML code from the beginning of the loaded state package by returning to block 506 .", "label": "", "metadata": {}}
{"text": "This roll back ensures that any HTML code inserted by the executed JAVASCRIPT \u00ae will be properly parsed by the HTML parser .While this discards some of the parsed HTML , this roll back only occurs when the JAVASCRIPT \u00ae is not well formed , and thus should not greatly diminish the execution time savings enabled by concurrent execution of HTML and JAVASCRIPT \u00ae processes .To enable the JAVASCRIPT \u00ae engine to execute scripts in block 518 to 528 while the HTML parser speculatively parses the remaining HTML code , the scripts may be posted to and removed from the JAVASCRIPT \u00ae execution queue in first in / first out manner .", "label": "", "metadata": {}}
{"text": "[0058 ]The concurrent JAVASCRIPT \u00ae and HTML processes may continue until all the script tags have been processed and all HTML code has been parsed .In block 515 , the HTML parser may notify the JAVASCRIPT \u00ae execution engine by setting a \" parse complete \" flag readable by the JAVASCRIPT \u00ae engine .After waiting the predetermined amount of time , the HTML parser may return to determination block 516 to check whether the JAVASCRIPT \u00ae engine is still executing .Alternatively , the process may proceed to determination block 528 to determine whether the JAVASCRIPT \u00ae execution queue is empty .", "label": "", "metadata": {}}
{"text": "So , if this occurs while the HTML parser is waiting for script execution to complete , the HTML parser may notify the JAVASCRIPT \u00ae engine that its execution is no longer \" complete .\" In various aspects this may be accomplished by the HTML parser sending the JAVASCRIPT \u00ae engine a \" busy \" notification , or resetting the \" parse complete \" flag .The HTML parser then begins reparsing the HTML from roll back state as described above .[0062 ]FIG .6 illustrates exemplary functional modules that may be used for implementing the various aspects .", "label": "", "metadata": {}}
{"text": "The HTML parser engine 602 may receive as input string tokens 606 of HTML code , and parse the tokens 606 for annotations and substantive text as part of the overall HTML processing .The scripts 608 may then be stored in a memory , such as a script execution queue 614 .After executing the write function , WHP parser 610 may parse a resulting buffer of HTML code produced by the JAVASCRIPT \u00ae execution engine 604 executing the write function .In various aspects , the WHP parser 610 may be a XHTML parser .If the WHP parser 610 determines that the HTML code is not well formed , the parser 610 may notify the JAVASCRIPT \u00ae execution engine 604 , which in turn notifies the HTML parser 610 that an error has been encountered .", "label": "", "metadata": {}}
{"text": "In various aspects , the HTML parser may be modified to package up the context information ( including state information ) and post it in a JAVASCRIPT \u00ae queue .In various aspects , both the HTML parser and the JAVASCRIPT \u00ae engine may be modified to include a checker that allows each processing engine to determine whether the other processing engine has completed execution of the document .[0065 ] The various aspects are preferably implemented on a single processor and involve the concurrent execution of a single HTML process and a single JAVASCRIPT \u00ae process .However , it is contemplated that the various aspects may be implemented on any number of multi - task , multi - core , and/or multiprocessor systems .", "label": "", "metadata": {}}
{"text": "[ 0066 ]FIG .7 is a system block diagram of a receiver device suitable for use with any of the aspects .A typical receiver device 700 may include a processor 701 coupled to internal memory 702 , a display 703 , and to a speaker 764 .Additionally , the receiver device 700 may include an antenna 704 for sending and receiving electromagnetic radiation that may be connected to a wireless data link and/or cellular telephone transceiver 705 coupled to the processor 701 and a mobile multimedia broadcast receiver 706 coupled to the processor 701 .Receiver devices 700 typically also include menu selection buttons or rocker switches 708 for receiving user inputs .", "label": "", "metadata": {}}
{"text": "0067 ] The various aspect methods for currently executing HTML processes and JAVASCRIPT \u00ae processes and/or rendering the resulting webpage may be performed by portions of the processor 701 , memory 702 , and display 703 .Alternatively dedicated modules within or coupled to the receiver 700 may perform the aspect methods .[0068 ]The aspects described above may also be implemented within a variety of computing devices , such as a laptop computer 800 as illustrated in FIG .8 .Many laptop computers include a touch pad touch surface that serves as the computer 's pointing device , and thus may receive drag , scroll , and flick gestures similar to those implemented on mobile computing devices equipped with a touch screen display .", "label": "", "metadata": {}}
{"text": "The computer 800 may also include a floppy disc drive 804 and a compact disc ( CD ) drive 805 coupled to the processor 801 .In a notebook configuration , the computer housing includes the touchpad 807 , keyboard 808 , and the display 809 all coupled to the processor 801 .Other configurations of computing device may include a computer mouse or trackball coupled to the processor ( e.g. , via a USB input ) as are well known .[ 0069 ] The processors 701 , 801 may be any programmable microprocessor , microcomputer or multiple processor chip or chips that can be configured by software instructions ( applications ) to perform a variety of functions , including the functions of the various aspects described below .", "label": "", "metadata": {}}
{"text": "Typically , software applications may be stored in the internal memory 702 , 802 , 803 before they are accessed and loaded into the processor 701 , 801 .The processor 701 , 801 may include internal memory sufficient to store the application software instructions .[0070 ] The foregoing method descriptions and the process flow diagrams are provided merely as illustrative examples and are not intended to require or imply that the steps of the various aspects must be performed in the order presented .As will be appreciated by one of skill in the art the order of steps in the foregoing aspects may be performed in any order .", "label": "", "metadata": {}}
{"text": "Further , any reference to claim elements in the singular , for example , using the articles \" a , \" \" an \" or \" the \" is not to be construed as limiting the element to the singular .[ 0071 ] The various illustrative logical blocks , modules , circuits , and algorithm steps described in connection with the aspects disclosed herein may be implemented as electronic hardware , computer software , or combinations of both .To clearly illustrate this interchangeability of hardware and software , various illustrative components , blocks , modules , circuits , and steps have been described above generally in terms of their functionality .", "label": "", "metadata": {}}
{"text": "Skilled artisans may implement the described functionality in varying ways for each particular application , but such implementation decisions should not be interpreted as causing a departure from the scope of the present invention .A general - purpose processor may be a microprocessor , but , in the alternative , the processor may be any conventional processor , controller , microcontroller , or state machine .A processor may also be implemented as a combination of computing devices , e.g. , a combination of a DSP and a microprocessor , a plurality of microprocessors , one or more microprocessors in conjunction with a DSP core , or any other such configuration .", "label": "", "metadata": {}}
{"text": "The steps of a method or algorithm disclosed herein may be embodied in a processor - executable software module which may reside on a non - transitory computer - readable or processor - readable storage medium .Non - transitory computer - readable or processor - readable storage media may be any storage media that may be accessed by a computer or a processor .Disk and disc , as used herein , includes compact disc ( CD ) , laser disc , optical disc , digital versatile disc ( DVD ) , floppy disk , and blu - ray disc where disks usually reproduce data magnetically , while discs reproduce data optically with lasers .", "label": "", "metadata": {}}
{"text": "Additionally , the operations of a method or algorithm may reside as one or any combination or set of codes and/or instructions on a non - transitory processor - readable medium and/or computer - readable medium , which may be incorporated into a computer program product .[ 0074 ]The preceding description of the disclosed aspects is provided to enable any person skilled in the art to make or use the present invention .Various modifications to these aspects will be readily apparent to those skilled in the art , and the generic principles defined herein may be applied to other aspects without departing from the spirit or scope of the invention .", "label": "", "metadata": {}}
{"text": "ABSTRACT .Background : Consumer health vocabularies ( CHVs ) have been developed to aid consumer health informatics applications .This purpose is best served if the vocabulary evolves with consumers ' language .Objective : Our objective was to create a computer assisted update ( CAU ) system that works with live corpora to identify new candidate terms for inclusion in the open access and collaborative ( OAC ) CHV .Methods : The CAU system consisted of three main parts : a Web crawler and an HTML parser , a candidate term filter that utilizes natural language processing tools including term recognition methods , and a human review interface .", "label": "", "metadata": {}}
{"text": "The term filter selected 774 candidate terms , of which 237 were valid terms , that is , 1 valid term among every 3 or 4 candidates reviewed .Conclusion : The CAU system is effective for generating a list of candidate terms for human review during CHV development .KEYWORDS .Introduction .Controlled vocabularies play an important role in the development of biomedical informatics applications because data used by clinical , bibliometric , and research applications need to be coded for easy retrieval and analysis .Research and development activities have been carried out to provide standardized health vocabularies , for example , SNOMED ( Systematized Nomenclature of Medicine ) and LOINC ( Logical Observation Identifiers Names and Codes ) .", "label": "", "metadata": {}}
{"text": "Controlled vocabularies require maintenance and updating due to the continuing evolution of language itself [ 2 - 4 ] .This evolution has been seen for centuries in the regular update and revision of dictionaries [ 5 , 6 ] .Controlled vocabularies serving electronic applications are no exception .The demand for maintenance and updating of vocabularies is particularly high in areas related to ongoing research and development .As new findings emerge , new words are added to the vocabulary .In health care especially , there is a constant stream of new names ( eg , new medications , disorders , and tests ) [ 7 ] .", "label": "", "metadata": {}}
{"text": "For example , the term mass spectrometer was unheard of 30 years ago , but a number of lay people now could identify it as a piece of lab equipment .Although deoxyribonucleic acid may be confusing , DNA is in the vocabulary of school - aged children .The media also plays a role in term migration .For example , in 2009 , media coverage introduced new vocabulary words such as pandemic , swine flu , H1N1 , energy expenditure , and single - payer system into popular speech .Similarly , the meaning and popularity of health terms change or evolve in the lay use .", "label": "", "metadata": {}}
{"text": "To be effective , a CHV must keep pace with changes in the language used by consumers [ 1 ] .This paper describes a computer - assisted update ( CAU ) system that uses an online social network as a living corpus of health - related terms .The system parses and screens terms using the natural language processing ( NLP ) techniques of dictionary lookup and automatic term recognition .New candidate terms are thereby identified for inclusion in the open access and collaborative ( OAC ) CHV .Background .In this background section , we will first briefly review the prior research and current practice for updating controlled health vocabularies .", "label": "", "metadata": {}}
{"text": "Then , we will switch focus to provide background information on the OAC CHV research .Finally , we will describe the rationale behind using a live corpus with automated term identification for updating the OAC CHV .Updating Controlled Health Vocabularies .Prior research has found that nearly all large controlled health vocabularies have similar core maintenance procedures [ 8 ] .Bakhshi - Raiez et al describe a framework for the maintenance of controlled health vocabularies .They refer to controlled health vocabularies as medical terminology systems ( TSs ) .Their framework consists of four components .", "label": "", "metadata": {}}
{"text": "\" This covers the core activities of the maintenance process including : collection of proposals for changes , validation of the proposals for changes , implementation of changes , verification of changes , documentation of proposals and implemented changes , and version management .The three other components , namely \" process management , \" \" change specification , \" and \" editing tools \" act in support of \" execution . \" Bakhshi - Raiez et al conducted a survey of 37 TSs .They divided the group of TSs into quartiles based on the number of concepts included in each system .", "label": "", "metadata": {}}
{"text": "Quartile IV would include the OAC CHV , which has 58,319 concepts .The CAU system we describe here is designed to automate the production and collection of change proposals and then assist with the validation of those proposals .The current practice for the generation and collection of proposals for TS changes and their validation typically involves collecting proposals via email or Internet and having a team of specialists validate them .For example , there is a Web - based Semantic MediaWiki system for maintaining entries in the National Cancer Institute Metathesaurus [ 9 ] .The SPECIALIST Lexicon included in the Unified Medical Language System ( UMLS ) collects words from literature as well as multiple dictionaries [ 10 ] .", "label": "", "metadata": {}}
{"text": "In a personal communication , Stuart Nelson , the head of MeSH , estimated that 20 % of his time is devoted to updating and revision .There are also six full time MeSH analysts .Clearly , vocabulary maintenance is a labor - intensive process , one whose efficiency could be improved by the proposed CAU system .The first step to automation would be the generation and collection of proposals for changes , a step that lacks standardization in one - third of all large vocabularies ' maintenance procedures [ 8 ] .Automatic Term Recognition in the Biomedical Domain .", "label": "", "metadata": {}}
{"text": "ATR studies overlap with the discipline known as named entity recognition ( NER ) .ATR refers to systems that search for general types of terms as opposed to named entities .A term becomes a named entity when it is mapped to an ontology or dictionary of terms , which gives the term meaning in a context outside of the document in which it is found .General terms have no such wider meaning .Examples of biomedical NER systems include Termoid , MetaMap and Bio - tagger [ 14 - 16 ] .Examples of biomedical ATRs are Collier et al 's hidden Markov model for identifying gene names and gene products , as well as Frantzi et al 's \" C - value \" and Zeng et al 's \" termhood \" score [ 17 - 19 ] .", "label": "", "metadata": {}}
{"text": "The C - value equation uses part of speech - tagged data and restricts candidate terms to noun phrases .The best results are obtained with an open linguistic filter that returns noun phrases , which include multiple adjectives and nouns [ 18 ] .C - value is then calculated using the frequency of occurrence of the candidate term combined with its frequency of occurrence as part of other , longer candidate terms , along with the number of longer candidate terms and their lengths .Expanding upon the C - value , the termhood logistic regression equation ( termhood score ) was developed by Zeng et al to identify multi - word consumer health terms including those that are not noun phrases [ 19 ] .", "label": "", "metadata": {}}
{"text": "Zeng et al compared C - value and termhood score ratings using strings that had already been human reviewed and found that termhood score outperformed C - value on their dataset [ 19 ] .Consumer Health Vocabulary .The development of this CAU system is part of the OAC CHV research program .The OAC CHV was developed using a phased , distributed , user source - based approach [ 1 ] .These criteria guide the human review in this study ; the current version of the CHV contains 152,778 entries , representing 58,319 concepts .Live Corpora .", "label": "", "metadata": {}}
{"text": "Although most of the text corpora were collected from live sources such as patient email , online forums , query logs , and social networks [ 16 - 20 ] , they were treated as static datasets for analysis .In this study , we aimed to directly tap into the live sources .Due to the extremely fast growth of social network sites , including health - related social network sites and their public availability [ 21 ] , we chose to test the CAU system on the social networking site PatientsLikeMe .Our lab has a collaborative relationship with PatientsLikeMe , which facilitated permission to use the site .", "label": "", "metadata": {}}
{"text": "The site provides customized disease - specific outcome and visualization tools to help patients understand and share information about their condition [ 22 , 23 ] .The private pages of the site are designed for patients to enter symptoms and track their disease .The public pages , on the other hand , include information provided by the site management and excerpts of information shared by users .The public pages thus contain language used by professionals as well as lay people .An example of language used by professionals would be , \" ALS , or amyotrophic lateral sclerosis , is a neurodegenerative disease caused by the degeneration of motor neurons . \"", "label": "", "metadata": {}}
{"text": "The first thing that I thought might be your problem is malnutrition .Man , you 're losing weight crazy fast .I think you better consider getting peg tube if you desire .\" By sticking to the public pages , we plan on tapping into this social networking aspect of the site without breaching the privacy of the users .Methods .We devised the CAU system to mine Web content using a combination of NLP methods : dictionary - lookup , C - value ATR , and termhood ATR .The goal was to discover new health - related terms used by consumers but not yet included in our existing vocabulary .", "label": "", "metadata": {}}
{"text": "System Architecture .The CAU system architecture is shown in Figure 1 .It consists of three processing stages , stage 1 , stage 2 , and stage 3 .Stage 1 is the stage in which raw text is obtained , parsed , and n - grams , that is , groups of words , are extracted .This stage involves three substages : crawling , parsing , and n - gram extraction .Crawling .In the crawling substage , the system crawls public pages on the Web .Crawling consists of navigating to the home page , collecting all the links to other pages in a queue , navigating to those pages in turn , and adding any links found to the end of the queue .", "label": "", "metadata": {}}
{"text": "The remaining content of each page is processed by removing HTML tags , adding periods to the ends of text blocks followed by more than one new line , and saving the resultant text .Parsing .In the parsing substage , the system uses the open - source natural language processing application Health Information Text Extractor ( HITEx ) [ 24 ] to identify parts of speech , noun phrases , and named entities .HITEx is an NLP system , which contains an OpenNLP parser and uses MetaMap for NER .N - gram Extraction .In the n - gram extraction substage , the system extracts n - grams ( 1- to 7-grams ) with overlap .", "label": "", "metadata": {}}
{"text": "The n - grams are filtered to retain n - grams identified by HITEx as noun phrases , n - grams , which contain a verb ( ie , potential verb phrases ) , and n - grams that contain the word symptom .N - grams that include numbers or symbols are excluded at this point .This linguistic filtering strategy is based on Frantzi et al 's finding that the C - value ATR produced better results with an open linguistic filter [ 18 ] .A stop list ( ie , a list of terms that should be ignored ) was created from a list of the 1000 most common phrases in English ( eg , a little , a few , we like it very much ) [ 25 ] .", "label": "", "metadata": {}}
{"text": "Stage 2 is the stage in which further NLP techniques are used to identify candidate terms on the n - grams list .This stage consists of three substages , two dictionary - type look up stages , the UMLS / CHV filter substage and the VA medical record term filter substage , and one ATR stage , the ATR filter substage .UMLS / CHV Filter .Given our interest in discovering new terms , the n - grams are looked up in the current CHV list and the UMLS Metathesaurus .To insure the most up to date version of UMLS ( 2010AA ) was used , n - grams were checked using the UMLS Web service .", "label": "", "metadata": {}}
{"text": "VA Medical Record Term Filter .These records contain a broad spectrum of medical topics and note types .They are not limited to neurology or the three diseases .These records were obtained by another group in our department with internal review board ( IRB ) approval .IRB approval was given for a member of that group to compare terms to this database for us , returning a yes / no answer .All terms , which returned yes were entered into a database for future comparisons .We will refer to this database as the VA medical record term database .", "label": "", "metadata": {}}
{"text": "Calculated are two ATR scores , that is , termhood and C - value .The termhood score was calculated using the logistic regression equation described in Zeng et al [ 19 ] .The C - value is calculated using the equation described in Frantzi et al [ 18 ] .The third stage is the human ( expert ) review stage .In this stage , candidate terms are submitted for collaborative expert review .To aid this process , we created an interactive website for the OAC CHV .Approved reviewers can access the site and recommend URLs for inclusion in the crawl , review candidate terms , review recent candidate term comments , and review CHV preferred names .", "label": "", "metadata": {}}
{"text": "Reviewers can also comment on a candidate term without registering a vote .Each reviewer can vote for a term only once .The public may comment on the candidate terms on the CHV Wiki by browsing the term list , choosing candidate terms , and clicking the term on which they would like to comment .Evaluation .For the purposes of this paper , the final stage of collaborative human review was replaced by the creation of a valid term list , which functions as the gold standard for this study .The valid term list was manually extracted from the webpages by the first author and filtered to exclude terms already represented in the UMLS / CHV .", "label": "", "metadata": {}}
{"text": "Therefore , we restricted the processing by the system to those pages .To assess the accuracy of the valid term list , a panel of expert reviewers ( two physicians and two allied medical personnel ) reviewed 100 random non - CHV terms found in our VA medical record term database from the initial parse of the webpages .Each expert 's agreement with the gold standard valid term list was assessed using the balanced F - measure discussed in Hripcsak and Rothschild [ 26 ] .The F - values found were 0.94 , 0.86 , 0.94 , and 0.91 , indicating that terms chosen as valid were indeed valid and that valid terms were not being missed .", "label": "", "metadata": {}}
{"text": "Stage 1 .The parsing and n - gram extraction phases ( marked B and C in Figure 1 ) found 88,994 n - grams .The n - gram list contained all 651 terms from the valid term list .Stage 2 .In the UMLS / CHV filter phase 1045 ( 1 % of the total ) n - grams were found in the CHV / UMLS .The total number of non - CHV terms remained large at 87,949 .The VA medical record term filter phase filtered out most of the n - grams .It eliminated all but 923 n - grams ( 99 % reduction ) and all but 215 terms from the valid term list ( 67 % reduction ) .", "label": "", "metadata": {}}
{"text": "Other valid term list terms excluded were consumer terms ( eg , brain fog and loss of time ) , which may not typically be recorded in medical records .In the ATR filter phase , two filters were built by applying a threshold to the ATR scores .The first filter used was based on termhood score and was applied to each non - CH n - gram found in the VA medical record term database .From Figure 2 it can be seen that the number of terms above the threshold dropped gradually .The best yield of valid terms was achieved with thresholds between 3.4 and 3.6 .", "label": "", "metadata": {}}
{"text": "The excluded valid terms include terms such as asthenia symptom and breast - feeding .The second filter was based on C - value and was applied to all non - CHV n - grams .From Figure 3 it can be seen that the number of terms above this threshold also dropped gradually .The best yield of valid terms was found at a threshold of 15 ( 170 terms , 93.7 % reduction , with 62 from the valid term list , 90 % reduction ) , a 36 % yield .This yield was higher than the termhood with VA medical record term filter , but the number of candidate terms returned was much lower .", "label": "", "metadata": {}}
{"text": "When the C - value threshold was combined with the termhood threshold the number of candidate terms increased while keeping the valid term yield around 30 % , the number of terms remaining was 774 with 237 valid terms .Combining the filters caught 48 more valid terms over the termhood filter alone , including cold legs below knee , augmentative speech device , and acid reflux GER gastroesophageal reflu x. .The results are summarized in Table 1 .Table 2 contains a sample list of candidate terms identified .Discussion .Principal Result .The system and the experiment are a proof - of - concept for procuring new terms using living corpora and ATR to aid vocabulary maintenance .", "label": "", "metadata": {}}
{"text": "Following all the filtering , the reviewers found 1 valid term among every 3 or 4 candidate terms reviewed .This is considerably better than the initial n - gram list which would have returned on average 1 valid term for every 137 candidate terms .The system will become more efficient after each maintenance cycle .All candidate terms rejected for inclusion will be added to the stop list , which should decrease the number of candidate terms .For instance , following the experiment described in the paper we conducted a second crawl of 300 pages and obtained 240 candidate terms for human review with 71 potentially valid terms , which maintained a yield of 30 % ( 71/240 ) .", "label": "", "metadata": {}}
{"text": "There have been previously reported higher yields using C - value and termhood scores [ 18 , 19 ] .The yield , however , is sensitive to the data and task involved in each study .Spasic et al used C - value to extract terms from full - text journal articles with a reported yield of 61 % .However , they targeted all valid terms instead of new terms ( ie , terms not yet included in a vocabulary ) , which are fewer and harder to find .In our own previous study to identify new CHV terms , both termhood score and C - value score were used .", "label": "", "metadata": {}}
{"text": "The data set used in that study was the query log to MEDLINEPlus .Compared with query logs , PatientsLikeMe pages contain more \" noise \" ( ie , terms that are similar in structure to those we seek but are not health - related ) , which increases the number of candidate terms found .We chose not to use only either C - value or termhood scores alone on these data because the results produced were much lower than the 31 % we report here .Implications for the System .The results of this study point to the necessity of using both the termhood and C - value methods .", "label": "", "metadata": {}}
{"text": "This could be problematic , as consumer terms may not occur in physicians ' notes .Evidence for their absence is the drop in valid terms after VA medical record term filtering from 651 to 215 .C - value balances termhood by not requiring prefiltering .However , for C - value to generate a concise list , too many valid terms are excluded , only 62 out of 651 .An implication of this study specific to this type of system is the choice of threshold .We found empirically that a threshold of 3.6 for the termhood score and a threshold of 15 for the C - value score produced a list that retained enough valid terms while excluding enough invalid terms .", "label": "", "metadata": {}}
{"text": "Looking at Figure 1 , it can be seen that a termhood threshold of 4 produces a candidate term list which is 95 % valid terms .Unfortunately , the total number of valid terms found would be only 42 out of a possible 651 .We consider identifying only 6 % of the available terms too inefficient .Increasing the C - value threshold produces a similar result .While the valid term yield increases to 78 % , only 44 valid terms are identified .It is possible that these thresholds could be increased and the number of valid terms missed could be mitigated by processing an extremely large number of webpages .", "label": "", "metadata": {}}
{"text": "This system could potentially be used for vocabulary maintenance beyond CHV and even beyond the health domain .Since an increasingly large proportion of contemporary writing is published on the Internet , it is possible to crawl open - access journals , blogs , and Web news channels to identify new candidate terms for inclusion in a variety of vocabularies .This system could also potentially be used to track the evolution of lay health language .Once the system is up - to - date , each new set of updates will be representative of the changes occurring in consumer terminology .", "label": "", "metadata": {}}
{"text": "Limitations .A potential limitation of using the PatientsLikeMe website is the \" higher level \" language that occurs in the content produced by the site operators as opposed to the users .Higher level refers to language that is drawn directly from physicians ' vocabulary .In this case , it is likely that the term will be contained in the UMLS Metathesaurus and thus ignored in the collection of new terms .Additionally , this broader exposure to higher level language may cause increased migration of terms .The migration of such terms would be reflected in the frequency - of - use data that are used to recommend the name preferred for use in reference to the concept ( the consumer preferred CHV name ) .", "label": "", "metadata": {}}
{"text": "The CAU system is limited by errors in the parsing and filtering stages .Although part of speech and noun phrase parsing are relatively mature NLP technologies [ 27 ] , the parsing of webpages poses extra challenges due to the prevalence of incomplete and ungrammatical sentences .The parser used in the HITEx system , OpenNLP , is trained to work with general text .HITEx was developed for the processing of clinical notes , which may be more grammatical or adhere to a different subgrammar .The continuing development of the HITEx NER system incorporated into the CAU will allow it to take advantage of any advances in the parser or mapper associated with HITEx .", "label": "", "metadata": {}}
{"text": "The database could be enlarged with proper institutional review board approval .The use of C - value with the unfiltered terms also decreases the effect of this limitation .The two ATR methods [ 18 , 19 ] are also imperfect .Their performance could be improved by preselecting the text to the extent it is practical in the social network setting .There may be a way to target specific locations in the website or on the webpages , perhaps by searching for key section headings or HTML tags .Another limitation of the CAU system is the continuing need for human review .", "label": "", "metadata": {}}
{"text": "Our current development is far from reaching the goal of zero human review but not from the goal of minimizing reviewer time .The results of this method on corpora other than PatientsLikeMe require further studies .We found 309 potential terms with 72 terms valid for inclusion in the CHV , that is , a 23 % valid term yield .However , as previously discussed , the thresholds we chose impacted the yield .Future Research .One direction of our future efforts will be to further analyze the terms found and either map them to existing concepts or create new ones .", "label": "", "metadata": {}}
{"text": "It is therefore necessary to determine how to integrate them into the CHV .Since the majority of these new terms are synonyms of health concepts that already exist in the professional controlled vocabularies , it is a simple mapping to include them .However , some brand new concepts may be encountered , in which case we will utilize the characteristics of valid new consumer concepts described by Keselman et al [ 28 ] to help guide their inclusion .In the future , we also plan to explore public participation in the collaborative review phase .In addition to discovering new terms , we plan to use live corpora to estimate the familiarity of health terms and harvest explanations .", "label": "", "metadata": {}}
{"text": "Social network data can be used to provide a living corpus , which can be mined to provide new consumer health vocabulary terms .Using ATR and dictionary lookup can narrow the candidate terms discovered to produce a concise list , which allows the vocabulary to evolve with the language without requiring a large amount of human review time .Acknowledgments .This work was funded by a supplement to the National Institutes of Health ( NIH ) grant RO1 LM07222 .We would also like to acknowledge the JMIR reviewers whose ideas were incorporated into this paper .Cimino JJ .", "label": "", "metadata": {}}
{"text": "Methods Inf Med 1998 Nov;37(4 - 5):394 - 403 .[Medline ] .Bakhshi - Raiez F , Cornet R , de Keizer NF .Development and application of a framework for maintenance of medical terminological systems .J Am Med Inform Assoc 2008;15(5):687 - 700 .[CrossRef ] [ Medline ] .Krauthammer M , Nenadic G. Term identification in the biomedical literature .J Biomed Inform 2004 Dec;37(6):512 - 526 .[CrossRef ] [ Medline ] .Harkema H , Gaizauskas R , Hepple M , Roberts A , Roberts I , Davis N , et al .", "label": "", "metadata": {}}
{"text": "In : BioLink .2004 Presented at : HLT / NCAAL 2004 Workshop ; May 6 , 2004 ; Boston , MA .Aronson AR , Lang FM .An overview of MetaMap : historical perspective and recent advances .J Am Med Inform Assoc 2010 May 1;17(3):229 - 236 . [CrossRef ] [ Medline ] .Torii M , Hu Z , Wu CH , Liu H. BioTagger - GM : a gene / protein name recognition system .J Am Med Inform Assoc 2009;16(2):247 - 255 . [CrossRef ] [ Medline ] .Collier N , Nobata C , Tsujii J. Extraction the Names of Genes and Gene Products with a Hidden Markov Model .", "label": "", "metadata": {}}
{"text": "2000 Presented at : COLING 2000 , 18th International Conference on Computational Linguistics ; July 31-Aug 4 , 2000 ; Saarbruecken , Germany .[CrossRef ] .Frantzi KT , Ananiadou S , Mima H. Automatic term recognition of multi - word terms : the C - value / NC - value method .International Journal on Digital Libraries 2003;3(2):115 - 130 [ FREE Full text ] [ CrossRef ] .Zeng QT , Tse T , Divita G , Keselman A , Crowell J , Browne AC , et al .Term identification methods for consumer health vocabulary development .", "label": "", "metadata": {}}
{"text": "Spasi\u0107 I , Schober D , Sansone SA , Rebholz - Schuhmann D , Kell DB , Paton NW .Facilitating the development of controlled vocabularies for metabolomics technologies with text mining .BMC Bioinformatics 2008;9 Suppl 5:S5 [ FREE Full text ] [ CrossRef ] [ Medline ] .Frost JH , Massagli MP .Social uses of personal health information within PatientsLikeMe , an online patient community : what can happen when patients have access to one another 's data .J Med Internet Res 2008;10(3):e15 [ FREE Full text ] [ CrossRef ] [ Medline ] .", "label": "", "metadata": {}}
{"text": "Sharing health data for better outcomes on PatientsLikeMe .J Med Internet Res 2010;12(2):e19 [ FREE Full text ] [ CrossRef ] [ Medline ] .Zeng QT , Goryachev S , Weiss S , Sordo M , Murphy SN , Lazarus R. Extracting principal diagnosis , co - morbidity and smoking status for asthma research : evaluation of a natural language processing system .BMC Med Inform Decis Mak 2006;6:30 [ FREE Full text ] [ CrossRef ] [ Medline ] .Hripcsak G , Rothschild AS .Agreement , the f - measure , and reliability in information retrieval .", "label": "", "metadata": {}}
{"text": "CrossRef ] [ Medline ] .Nordstrom B , Ranta A. Advances in Natural Language Processing .In : Nordstrom B , Ranta A , editors .6th International Conference , GoTAL 2008 , Gothenburg , Sweden , August 25 - 27 , 2008 , Proceedings ( Lecture Notes in ... / Lecture Notes in Artificial Intelligence ) .Berlin , Germany : Springer ; 2008 .Keselman A , Smith CA , Divita G , Kim H , Browne AC , Leroy G , et al .Consumer health concepts that do not map to the UMLS : where do they fit ?", "label": "", "metadata": {}}
{"text": "CrossRef ] [ Medline ] .Edited by G Eysenbach ; submitted 25.08.10 ; peer - reviewed by L Slaughter , A Keselman , P Wicks , H Hochhiser ; comments to author 17.09.10 ; revised version received 22.02.11 ; accepted 29.03.11 ; published 17.05.11 .Copyright .\u00a9 Kristina M Doing - Harris , Qing Zeng - Treitler . char ( \u00b7 ) parser which consumes specified character or range of characters .many ( \u00b7 ) combinator which repeats specified parser from zero to infinite times .Example : \" char('a ' ) .many ( ) \" will match a string with any number of \" a \" -s . .", "label": "", "metadata": {}}
{"text": "How can I do that ?Edit : .May be I confused ya all .In my program a parser is a function ( or \" functor \" in terms of C++ ) which accepts a \" step \" and returns forest of \" steps \" .A \" step \" may be of OK type ( that means that parser has consumed part of input successfully ) and FAIL type ( that means the parser has encountered error ) .There are more types of steps but they are auxiliary .So when I parse input , I : .", "label": "", "metadata": {}}
{"text": "Give the initial Step to the complex Parser function .Filter TreeNodes with Steps , leaving only OK ones ( or with minimum FAIL - s if there were errors in input ) .It still is n't really clear to me just how GLR your implementation is .A traditional GLR parser has a monolithic parser table that incorporates information from the whole grammar .Are you doing that ? -Jason Orendorff Dec 9 ' 10 at 15:44 .4 Answers 4 .This poses a dilemma .Yet there is no way to produce the second parser 's behavior in terms of what the first one finds .", "label": "", "metadata": {}}
{"text": "Greedy matching would return matches sorted longest to shortest ; non - greedy , shortest to longest .The problem with this approach is that in case of errors in input such \" ? \" combinator becomes greedy .And unfortunately it will be right . -Lavir the Whiolet Dec 9 ' 10 at 19:39 .In a few words it is on principle impossible to implement error - recovery - friendly \" ? \" combinator which will not require explicit directions of what the \" ... ? \" z ' ) .many ( ) .Fix me if I am not right ( that it 's impossible on principle ) .", "label": "", "metadata": {}}
{"text": "Lavir the Whiolet Dec 9 ' 10 at 19:49 .The grammar seems to clearly rule out anything containing an X. - Jason Orendorff Dec 9 ' 10 at 20:44 . without bending the model at least a little .However there are probably many satisfactory ways to do so .All real - world parsers bend the base conceptual model somewhat .One of the strengths of combinatorial parsers ( and recursive descent parsers ) , over table - driven ones , is that they are so flexible .-Jason Orendorff Dec 9 ' 10 at 20:49 .", "label": "", "metadata": {}}
{"text": "I do n't know what a \" combinatorial GLR parser \" is , and I 'm unfamiliar with your notation so I 'm not quite sure how to interpret it .I assume this is some kind of curried function notation ?I 'm imagining your combinator rules are equivalent to definining a grammer in terms of terminal characters , where \" char('a ' ) .many \" corresponds to grammar rules : .GLR parsers , indeed , produce all possible parses .The key insight to GLR parsing is its psuedo - parallel processing of all possible parses .", "label": "", "metadata": {}}
{"text": "The fact that it is not hints what you have implemented is not a GLR parser .Error recovery with a GLR parser is possible , just as with any other parsing technology .In essence , delete the token , or insert one expected by a live parse .We then turn the GLR parser loose again .Only the valid parses ( e.g. , repairs ) will survive .If the current token can not be processed , the parser processing the stream with the token deleted survives .In the worst case , the GLR parser error recovery ends up throwing away all tokens to EOF .", "label": "", "metadata": {}}
{"text": "All simple parsers are GLR in fact , and their combinations are also GLR .-Lavir the Whiolet Dec 9 ' 10 at 8:13 .( some other thing ) \" .I do n't know how to make GLR parser to stop repeating \" something \" when \" some other thing \" is encountered .Darius Bacon suggested to mark appropriate parses whether they are produced by eager or lazy combinator , but I do n't know how reasonable error recovery can be added to such an algorithm . -Lavir the Whiolet Dec 9 ' 10 at 8:24 .", "label": "", "metadata": {}}
{"text": "Your simple parsers appear to be just \" is_member_character_set(char ) \" which is trivial to check .How is that GLR ?Where are the psuedo - parallel parses with shared forests ? -Ira Baxter Dec 9 ' 10 at 14:49 .I 'm writing parser with error recovery .Yes , \" char ( ... ) \" parser is trivial ... when there are no errors in input .When it encounters an error it splits into 2 - 3 alternatives ( with different ways of error recovering ) .-Lavir the Whiolet Dec 9 ' 10 at 18:59 .", "label": "", "metadata": {}}
{"text": "Then resolving the ambiguity is a matter of picking the parse you prefer .To do that , I suppose the elements of the parse forest need to be labeled according to what kind of combinator produced them , eager or lazy .( You ca n't resolve the ambiguity incrementally before you 've seen all the input , in general . )( This answer based on my dim memory and vague possible misunderstanding of GLR parsing .Hopefully someone expert will come by . )Non - greedy functionality is nothing more than a disambiguation mechanism .", "label": "", "metadata": {}}
{"text": "Non - greedy disambiguation behavior could be applied to the complete set of results provided by a generalized parser .Working left - to - right , filter the ambiguous sub - groups corresponding to a non - greedy operator to use the shortest match which still led to a successful parse of the remaining input .6 Answers 6 .That article from Aaron is very good for understanding , also I 'd recommend that you read maning Spring in Action book , they give very good examples on how the spring solves that problem it will definitely improve your understanding of this .", "label": "", "metadata": {}}
{"text": "I came accross this in this great book called Growing object oriented software guided by tests : .Coupling : .Elements are coupled if a change in one forces a change in the other .For example , if two classes inherit from a common parent , then a change in one class might require a change in the other .Think of a combo audio system : It 's tightly coupled because if we want to change from analog to digital radio , we must rebuild the whole system .If we assemble a system from separates , it would have low coupling and we could just swap out the receiver . \" Loosely \" coupled features ( i.e. , those with low coupling ) are easier to maintain .", "label": "", "metadata": {}}
{"text": "An element 's cohesion is a measure of whether its responsibilities form a meaningful unit .For example , a class that parses both dates and URLs is not coherent , because they 're unrelated concepts .Think of a machine that washes both clothes and dishes - it 's unlikely to do both well.2 At the other extreme , a class that parses only the punctuation in a URL is unlikely to be coherent , because it does n't represent a whole concept .To get anything done , the programmer will have to find other parsers for protocol , host , resource , and so on .", "label": "", "metadata": {}}
{"text": "Cohesion - related to the principle that a class / method should be responsible for one thing only i.e there are no stray methods that do n't belong in the encapsulation ; a method only does one thing .High / Low cohesion is the degree to which this holds .Coupling - how interdependent different parts of the system are .e.g how and where there are dependencies .If two classes make calls to methods of each other then they are tightly coupled , as changing one would mean having to change the other .Decoupling is the process of making something that was tightly coupled less so , or not at all .", "label": "", "metadata": {}}
{"text": "Coupling / cohesion are certainly not the same principle , but they have the common aim of making a system more flexible . -Robert May 21 ' 10 at 11:49 .What did you mean by ' all these terms mean the same thing ' ?I am not sure if I follow you on that one .As Robert pointed out , they indeed mean different things - Shravan May 21 ' 10 at 12:00 .Thanks , I 've improved my answer . -Aaron Digulla May 21 ' 10 at 12:15 .Here my thoughts on cohesion .", "label": "", "metadata": {}}
{"text": "Inside the module we have task .When those task are highly related to each other we say it has high cohesion .When those tasks are not related we say it has low cohesion .My best attempt to explain decoupling is that decoupling is the act of removing coupling .Low Coupling helps us get to high cohesion !Remember that we want our module to have related task and one single responsibility .But what is coupling ?Coupling is the degree of dependency on other modules to achieve our single responsibility for that module .So by low coupling we are saying that we are not very dependant on external modules hence we have high cohesion .", "label": "", "metadata": {}}
{"text": "Get it ?Other more decorated thinkers and groups say : .Cohesion is the degree to which the tasks performed by a single module are functionally related . \"IEEE , 1983 \" Cohesion is the \" glue \" that holds a module together .It can be thought of as the type of association among the component elements of a module .Generally , one wants the highest level of cohesion possible . \"Bergland , 1981 .A software component is said to exhibit a high degree of cohesion if the elements in that unit exhibit a high degree of functional relatedness .", "label": "", "metadata": {}}
{"text": "Sommerville , 1989 .decoupling allows the separation of object interaction from classes and inheritance into distinct layers of abstraction used to polymorphic - ally decouple the encapsulation which is the practice of using re - usable code to prevent discrete code modules from interacting with each other .Disc : Parsing , Selectional Restrictions .Directory .Right .The Boeing parser ( nicknamed the \" Sapir Parser \" now ) produces a total of 8 parses for the word sequence .Here they are : [ The player kicked the ball ] kicked him . ... subject ...", "label": "", "metadata": {}}
{"text": "Right .But it would have been easier for him to type in the sentence : The man sent the man sent him .This string has the same number of parses , but all the ambiguities are semantically felicitous .The problem with the original sentence was that it is semantically anomalous to have balls doing the kicking .Nevertheless , you want your syntactic parser to see all the possibilities in case it encounters \" the man sent ... \" type of situation .Some people may have trouble getting the distinction between postmodifier ' sent ' as an adjective and as a verb .", "label": "", "metadata": {}}
{"text": "I do not claim that these are all the possible parses , only the ones that our system has been programmed to generate .A number of comments and questions regarding the parsing of The player kicked the ball kicked him .Regarding the five possible parses of green boas.cogsci.uiuc.edu .( Georgia Green ) : .I can only get 3 of the 5 parses you claim are . valid - can you explain the others ?Your parses .are : .( 1 ) [ the player [ ( who ) kicked the ball ] ] kicked him .", "label": "", "metadata": {}}
{"text": "( where relativization is from subject position ) to . leave out the \" who \" or \" that \" - and I believe this is .generally the case ( please correct me if I am wrong ) : .( a ) [ the rat [ that the cat bit ] ] died .( a ' )[ the rat [ the cat bit ] ] died .( b ) [ the rat [ that bit the cat ] ] died .( 2 ) [ the player [ ( who was ) kicked the ball ] ] kicked him .", "label": "", "metadata": {}}
{"text": "( 3 ) the player kicked [ the ball [ ( that was ) kicked ( to ) him ] ] .Fine .( 4 ) the player kicked [ the ball [ ( that ) kicked him ] ] .Same comments as for ( 1 ) .( 5 ) the player complained that the ball kicked him .At the risk of making my ignorance public ( if it is n't already :-) .I must admit that I had to look up \" kick \" in the dictionary to .understand this meaning of the sentence .", "label": "", "metadata": {}}
{"text": "this meaning : . \" to show opposition , resentment , or discontent \" .( from Webster 's Seventh New Collegiate Dictionary , 1971 ) .this as a possible parse : .The player kicked the ball kicked him .The player kicked ( complained ) ( that ) the ball kicked him .I have never heard \" kick \" empoyed this way - is it perhaps not .very widely used these days ?( Herb Stahlke ) : .It could very well be that the term has \" undergone a semantic . shift \" .", "label": "", "metadata": {}}
{"text": "although perfectly grammatical , have a structure which \" fools \" .one into pursuing a straightforward analysis which turns out . to be incorrect - leading one down a garden path . . . .I must admit I have never heard of it being applied to island .violation structures - but then there 's a lot I have n't heard . of :-) .Can anyone enlighten us ?Regarding the third possible parse from maxwell jaars.sil.org : .Sounds good to me !I guess I was subconsciously thinking .that it had to be a sentence rather than just an NP .", "label": "", "metadata": {}}
{"text": "( alphonce cs.ubc.ca ) .The principal goal seems to be to get a generative grammar , of whatever stripe , to generate only sentences a speaker MIGHT actually use .Many generativists have rejected this goal , after initial flirtations with it some years ago .On the one hand , this rejection seems reasonable , since so much rests on what beliefs various speakers have about the world , rather than about language .On the other hand , languages do have ways of encoding these beliefs formally , and a grammar has to say SOMETHING about this .", "label": "", "metadata": {}}
{"text": "This can be done pretty easily , making a grammar \" portable \" from one speaker to another , from one knowledge system or belief system to another .I first proposed \" grammatical implicationals \" back in the mid 1970 's to do precisely this , in fact .Disregarding niceties of formulation , such implications take the form \" If you believe X , do Y \" Examples : 1 )If you believe the head denotes human - like objects , use \" who \" as the relative pronoun .The apparent oddity of such NP 's as \" the train who arrived late \" comes from the fact that it commits a speaker who has this grammatical belief about English to the belief that trains are human - like , a belief most of us do n't appear to share .", "label": "", "metadata": {}}
{"text": "A number of African languages show \" notional concord \" ; anaphors and concords are taken from a set of forms indicating animacy when the controlling referring expression , whatever its grammatical gender , is believed to denote an animate object .This is a grammatical fact .But there are mismatches between European and African belief - systems , so what actually gets SAID will vary .For instance , Temnes believe a certain kind of tree is animate ( capable of casting spells and the like ) .This is an anthropological fact .Temnes use animate concords in this case , which the grammar predicts when coupled with the belief - system of a Temne speaker .", "label": "", "metadata": {}}
