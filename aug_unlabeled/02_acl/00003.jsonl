{"text": "Classifying Human Voices by Using Hybrid SFX Time - Series Preprocessing and Ensemble Feature Selection . 1 Department of Computer and Information Science , University of Macau , Macau 2 School of Computer Science and Engineering , University of New South Wales , Kensington , NSW 2052 , Australia .Received 25 June 2013 ; Accepted 1 August 2013 .Copyright \u00a9 2013 Simon Fong et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}}
{"text": "Voice biometrics is one kind of physiological characteristics whose voice is different for each individual person .Due to this uniqueness , voice classification has found useful applications in classifying speakers ' gender , mother tongue or ethnicity ( accent ) , emotion states , identity verification , verbal command control , and so forth .In this paper , we adopt a new preprocessing method named Statistical Feature Extraction ( SFX ) for extracting important features in training a classification model , based on piecewise transformation treating an audio waveform as a time - series .Using SFX we can faithfully remodel statistical characteristics of the time - series ; together with spectral analysis , a substantial amount of features are extracted in combination .", "label": "", "metadata": {}}
{"text": "We focus on the comparison of effects of various popular data mining algorithms on multiple datasets .Our experiment consists of classification tests over four typical categories of human voice data , namely , Female and Male , Emotional Speech , Speaker Identification , and Language Recognition .The experiments yield encouraging results supporting the fact that heuristically choosing significant features from both time and frequency domains indeed produces better performance in voice classification than traditional signal processing techniques alone , like wavelets and LPC - to - CC .Introduction .Unlike fingerprints , iris , retina , and facial feature , our voice is a kind of bodily characteristics that is useful in speaker identification but it remains relatively unexplored .", "label": "", "metadata": {}}
{"text": "Voice biometrics plays a central role in many biometrics applications such as speaker verification , authentication , and access control management .Furthermore voice classification potentially can apply to interactive - voice - response system for detecting the moods and tones of customers , thereby guessing if the calls are of complaints or complement , for example .More examples of voice classification have been described in our previous work [ 1 ] which attempted to classify voice data by using hierarchical time - series clustering methods .The clustering method only separates voice data into distinct groups without knowing the labels of the groups .", "label": "", "metadata": {}}
{"text": "Voice classification has been studied intensively in the biometrics research community using digital signal processing methods .The signatures of the voice are expressed in numeric values in the frequency domain .There lie considerable challenges in attaining high accuracy in voice classification given the dynamic nature in the speech data , not only the contents within but also the diversity of human vocals and different ways of speeches .In this paper we tackle the classification challenges by modeling human voices as time - series in the form of stochastic signals .In contrast to deterministic signals that are rigidly periodic , stochastic signals are difficult to be modeled precisely by mathematical functions due to uncertainty in the parameters of the computational equations .", "label": "", "metadata": {}}
{"text": "As far as human voice is concerned , almost all of them are stochastic and nonstationary , meaning that their statistics are time dependent or time varying .Given such temporal data properties , human voice that is acquired continually from the time domain would be in the form of random time - series that often has a single variable ( amplitude in loudness ) over time .It is believed that the statistical characteristics are changing over time during a speech but they may form some specific patterns , so some inherent information can be derived from the time - series that are useful for classification .", "label": "", "metadata": {}}
{"text": "It is known that conventional data mining models can be deployed for classifying data with only multiple attributes .Previous work by other researchers who utilized wavelet transformation essentially converted temporal data to the representation of frequency domain format .For voice classification in this paper , elements of both time domain and frequency domain are used for obtaining the statistical characteristics of the time - series , and subsequently subject to model learning for classification that can be generically implemented by most of the available classification algorithms .Simulation experiments are carried out over four representative types of voice data or speeches being digitized for validating the efficacy of our proposed voice classification approach based on SFX and metaheuristic feature selection .", "label": "", "metadata": {}}
{"text": "Given the multiattributes which are derived from the original time - series via the preprocessing step , feature selection ( FS ) techniques could be applied prior to training a classification model .Our results indicate that superior performance could be achieved by using SFX and FS together over the original time - series for voice classification .The improvements are consistent over the four testing datasets with respect to the major performance indicators .The rest of the paper is structured as follows : The previous works on classifying voice data are reviewed in Section 2 ; specifically their time - series transformation and feature extraction techniques are highlighted .", "label": "", "metadata": {}}
{"text": "A set of comparative experiments is performed by using four kinds of voice datasets , and they are reported in Section 4 .Results that reinforce the efficacy of our new approach are shown in Section 5 .The performance evaluation is all - rounded by considering accuracy , Kappa statistic , precision , recall , .-measure , ROC area under curve , and time cost for each dataset .Section 6 concludes this research work and suggests some future works .Related Work .Human voice is stochastic , nonstationary , and bounded in frequency spectrum ; hence some suitable features could be quantitatively extracted from the voice data for further processing and analysis .", "label": "", "metadata": {}}
{"text": "Their performances , however , vary .Feature Extraction on Voice Data .Some useful features selected for the targeted acoustic surveillance are [ 3 ] weighted average delta energy ( . )The classifier model used by the authors is the sliding window Hidden Markov Model ( HMM ) .They obtained an average error rate at the range of 5%-20 % .Peeters discovered more detailed acoustic features for sound description [ 4 ] .These features can be roughly grouped into temporal , energy , spectral , harmonic , perceptual , and various features .The limitation is the expensive time and space costs of computation for such full kind of feature extraction .", "label": "", "metadata": {}}
{"text": "LPC consists of finding a time - based series of .-pole infinite impulse response ( IIR ) filters whose coefficients better adapt to the formants of a speech signal .The main idea behind LPC is that a sample of speech can be approximated as a linear combination of past speech samples [ 5 ] .The methods for calculating LPCs include covariance method , autocorrelation ( Durbin ) method , lattice method , inverse filter formulation , spectral estimation formulation , maximum likelihood method , and inner product method [ 6 ] .As a general practice of pattern recognition , the final predictor coefficients are never applied because of the high variance .", "label": "", "metadata": {}}
{"text": "Cepstral coefficients are the inverse Fourier transform representation of the log magnitude of the spectrum .The cepstral series represents a progressive approximation of the envelope of the signal [ 8 ] .MFCC offers the best performance within six coefficients ( the other five coefficients are Linear Prediction Coefficient , Linear Prediction Cepstral Coefficient , Linear Frequency Cepstral Coefficient , and Reflection Coefficient ) [ 9 ] .MFCC divided the speech into frames ( typically 20 ms for each frame ) , applied Discrete Fourier Transformation over every frame , retained the logarithm of the amplitude spectrum , smoothed the spectrum , and applied Discrete Cosine Transform [ 10 ] .", "label": "", "metadata": {}}
{"text": "One of them is weighted MFCC .To reduce the dimensions of feature vector while still retaining the advantages of delta and double delta features , the weighted MFCC coefficients equal the sum of MFCC coefficients , . are weights in real numbers [ 11 ] .An enhanced technique for feature recognition using Improved Features for Dynamic Time Warping ( DTW ) was applied as a classifier ; the accuracy was between 85 % and 98 % .Zhou et al . designed a new Kullback - Leibler distance ( KLD ) based weighting Perceptual Linear Prediction ( PLP ) algorithm for MFCC .", "label": "", "metadata": {}}
{"text": "The weight is the reciprocal of this distance [ 12 ] .The word error rate was below 25 % .Similar to LPC and MFCC , PLP modifies the short - term spectrum of the speech by several psychophysically based transformations .The basic steps of PLP contain spectral analysis , critical - band spectral resolution , equal - loudness preemphasis , intensity - loudness power law , autoregressive modeling , and practical considerations [ 13 ] .But PLP is vulnerable when spectral values are modified by the frequency response of the communication channel .Thus , by employing relative spectra filtering of log domain coefficients ( RASTA ) , we make PLP more robust to these distortions [ 14 ] .", "label": "", "metadata": {}}
{"text": "Linear algebra is the main technique .Karhunen - Loeve transformation and linear discriminant analysis were the feature extraction methods [ 15 ] .The error rate was lower than 30 % .Lee et al .proposed a new feature extraction method called independent component analysis ( ICA ) .The purpose of an ICA network is to calculate and extract independent components from speech segment by training .Meanwhile , the weight matrix holds the basic function coefficients from the speech segment .One assumption of ICA is that the observation is the linear combination of the independent components [ 16 ] .", "label": "", "metadata": {}}
{"text": "Our proposed method uses both statistical and spectral analysis for extracting all the possible features .Subsequently it selects useful features via a metaheuristic search .The qualified features are then used to reduce the vector dimensionality of training instances for building a classification model .The features from the temporal domain contain richer statistical information than only local maxima and local minima .Our method rides on the observed current trend of fusing information from both time and frequency domains .The merit is that a nonlinear relationship is represented by the spectrum of a spectrum , so only the useful features from the frequency domain in addition to other strong statistical features from the time - domain are encoded into the multidimensional vector which of course is limited in space .", "label": "", "metadata": {}}
{"text": "Data Mining Algorithms for Voice Classification .Some recent research tapped on the power of data mining algorithms for performing voice classification in various applications .For instance , a new method is proposed by the research team of Lee et al .[17 ] , for prescribing personalized medicine using vocal and facial features .It is a constitution diagnostic method based solely on the individual 's physical characteristics , irrespective of psychological traits , characteristics of clinical medicine , and genetic factors .They used Support Vector Machine ( SVM ) on a software package called LIBLINEAR ( L2-loss SVM dual type ) for doing voice classification .", "label": "", "metadata": {}}
{"text": "[ 18 ] investigated the possibility of automatically detecting the sound signatures of activities of daily living of an elderly patient using nonintrusive and reliable methods .A Gaussian mixture model ( GMM ) classifier was used to differentiate sound activities .Their experiments yielded encouraging results ; with recognition accuracies in the range 70 % to 100 % can be consistently obtained using different microphone - pair positions , under all but the most severe noise conditions .For biomedical applications , Chenausky et al . made an important contribution in acoustic analysis of Parkinson 's disease ( PD ) speech [ 19 ] .", "label": "", "metadata": {}}
{"text": "These were normalized by the controls ' standard deviation to represent distance from normal and combined into a composite measure .A feedback device that was developed from these findings could be useful to clinicians adjusting deep brain stimulation ( DBS ) parameters , as a means for ensuring they do not unwittingly choose DBS settings which impair patients ' communication .In our previous work in [ 1 ] , surveyed several approaches have been studied , such as Artificial Neural Networks ( ANN ) , Support Vector Machines ( SVMs ) , Hidden Markov Models ( HMMs ) , and Gaussian Mixture Models ( GMMs ) .", "label": "", "metadata": {}}
{"text": "A summary of the techniques by which majority of research works used was shown in [ 1 ] .In particular , an approach by using unsupervised clustering was described in [ 1 ] , where priori labeled samples are not required , and the characteristic groupings will be dedicated by the samples themselves .Voiceprints who share similar features will be placed into distinctive groups that represent some labels about the speakers .Subsequently a decision tree ( classifier ) can be built after studying and confirming the characteristic groups .Above all the methods a forementioned , encoding techniques from the frequency domains are used as sole features for modeling the voice samples .", "label": "", "metadata": {}}
{"text": "In this paper , we advocate combining features from both time and frequency domains , for a throughout coverage of all the voice data characteristics .Then feature selection is used to reduce the dimensionality of the training samples .This way , a minimum subset of relevant features is ensured , and they could be applied into most types of classification models without any limit of a specific type .Proposed Method in Constructing a Voice Classification Model .The SFX preprocessing methodology that is adopted in our research is efficient .Its main merit lies in its ability to transform voice data from one - dimensional to multidimensional features .", "label": "", "metadata": {}}
{"text": "The training dataset in a form of time - series get converted to multidimensional vectors via the preprocessing process , ready to be used for training a classification model .Given a large dimensionality , ensemble feature selection could be applied over the converted multidimensional vectors for refining the accuracy by retaining only some selected relevant features .In our case , a metaheuristic search method seems to perform very well given its efficient stochastic optimization .Its operational nature is dynamic , suitable for choosing features on the fly , considering that voice data could be potentially continuous .", "label": "", "metadata": {}}
{"text": "The model construction process is just a standard classification model learning in data mining ; for example , a decision tree is built by creating decision paths that map the conditions of the attribute values , as seen from the training samples , to the predicted classes .Once a classifier is trained by processing through the whole training dataset , it is ready to classify new unseen testing samples , and its performance can be measured .The feature selection process is generalized enough to be an ensemble where the winner takes all .During calibration , several feature selection algorithms are put into test , and the best performing one in our case is Feature Selection with Wolf Search Algorithm ( FS - WSA ) [ 20 ] .", "label": "", "metadata": {}}
{"text": "The main difference between our innovation and the others is highlighted in red in Figure 1 .We zoom into the details of preprocessing describing the operational flow from data perspective in Figures 2 and 3 , respectively , for SFX with and without FS .In a nutshell , the preprocessing methodology SFX is a way of transforming a two - dimensional time - series ( amplitude versus time ) into a multidimensional feature vector that has all the essential attributes sufficient to characterize the original time - series voice data .Information is taken from two domains , frequency and time , based on the original time - series .", "label": "", "metadata": {}}
{"text": "It is believed that having features obtained from both domains would yield an improved accuracy from the trained classification model due to thorough consideration of the characteristics , hence the representative features , from both domains .Effectively the preprocessing methodology SFX transforms a matrix of original time - series to a set of training instances which have specific attribute values for building a classification model .Assume .Feature Extraction from the Frequency Domain .Linear Prediction Coefficients to Cepstral the Coefficients , or Linear Prediction Coding to Cepstrum Coefficients ( LPC - to - CC ) is selected as the main feature extraction method from the frequency domain in our case .", "label": "", "metadata": {}}
{"text": "Then the air goes into the trachea , passing through the larynx .The larynx is a box - like organ and has two membranes named vocal folds .The voice is actually produced by the vibration of those vocal folds [ 21 ] .The acoustic theory of voice production assumes the voice production processes to be a linear system .The output of a linear system is produced based on the linear combination of its previous outputs and current and previous inputs [ 22 ] .It is the reason that LPC is chosen here for the purpose of encoding the voice data .", "label": "", "metadata": {}}
{"text": "It is always called linear prediction coding , which is a common tool widely used in speech processing for representing the spectral envelope of a signal in compressed form [ 23 ] .The cepstrum has a lot of advantages such as orthogonality , compactness , and source - filter separation ; meanwhile the LPC coefficients are much more susceptible to the precision of numerical numbers , which are less robust than cepstrum coefficients [ 25 ] .Thus it is often desirable to transform LPC .Feature Extraction from the Time Domain . that is characterized by a collection of attribute extracted from the time - series of the voice raw data with respect to the time domain .", "label": "", "metadata": {}}
{"text": "Descriptive Statistics .Suppose .In the statistical analysis of the time - series data , Autoregressive Moving Average models ( ARMA ) describes a stationary stochastic process based on two polynomials , one for the Auto - regression ( AR ) and the other for Moving Average ( MA ) [ 26 ] .With the parameter settings this model is usually notated as .Now we introduce another model for characterizing and modeling observed time - series : autoregressive conditional heteroskedasticity ( ARCH ) model .So that in the model , at any time point in this sequence , it will have a characteristic variance .", "label": "", "metadata": {}}
{"text": "With the parameter settings this model is usually referred to as the .Dynamic Time Warping Distance .Though descriptive statistics may give us the overall summary of time - series data and characterize a general shape of time - series data , they may not be able to capture the precise trend movements which are also known as the patterns of evolving lines .In particular we are interested in distinguishing the time - series which belong to one specific class from those that belong to another class .The difference of trend movements can be estimated by a technique called Dynamic Time Warping .", "label": "", "metadata": {}}
{"text": "DTW has been applied to many data objects like video , voice , audio , and graphics .Actually , DTW can explain and deal with any ordered set of data points by the format of linear combination [ 28 ] .In theory , DTW is most suitable for voice wave patterns because exact matching for such patterns often may not occur , and voice patterns may vary slightly in the time domain .DTW finds an optimal match between two sequences that allows for compressed sections of the sequences .In other words it allows some flexibility for matching two sequences that may vary slightly in speed or time .", "label": "", "metadata": {}}
{"text": "Particularly suitable DTW is for matching sequences that may have missing information or various lengths , on condition that the sequences are long enough for matching .Piecewise Transformation .So far along the time - domain , statistics are extracted from the whole piece of the time - series as well as the similarity in terms of distance between the test time - series and the mean of its peer group .For a finer level of information , a piecewise transformation is applied which is called Piecewise Linear Function ( PLF ) .A continuous time - series is converted into a collection of linear segments when PLF is applied on it .", "label": "", "metadata": {}}
{"text": "This is the key part of the research work because it contains our new contribution .Inspired by the financial analysis of stock market , residual and volatility are firstly imported in the application field of voice classification .Like historical volatility for one or more stocks over some specified trading days , we also believe that certain patterns of someone 's speech are involved in residual and volatility .Each sentence is read by wavread function in MATHLAB into a one dimension array as illustrated in Figure 2 .The starting and ending points of every time - series data are just the same as the beginning and ending points of each array , which means that all information is used without any redundancy .", "label": "", "metadata": {}}
{"text": "can be selected arbitrarily but sufficiently by the user .In our experiments , the average length of a sentence is ten words , and each word has a peak correspondingly .The mean length of the sampled time - series array is 100 k points .Without compromising the resolution and the complexity of feature space , we choose . to be 20 , thus we can cut a peak into two parts which represents up and down gradients .Then the continuous time - series voice data is partitioned equally into 20 pieces .In our experiment , we try to keep the length of every spoken sentence the same , being almost 10 k points after sampling .", "label": "", "metadata": {}}
{"text": "For each segment of the time - series , certain statistics that describe the trend and dynamics of the movement are extracted into the feature vector , that is , .Figure 8 : ( a )An example of sampled time - series voice data and its partition .( b )The amplified view of piecewise linear regression ( partly ) .Using this piecewise method , the features that are being extracted are statistics of each partition of the time - series .Table 1 shows a list of all statistics that can potentially be harvested from 20 partitions of a particular time - series .", "label": "", "metadata": {}}
{"text": "A calibration test is used to determine the optimal choice of the length of each piece ( interval ) such that the highest classification accuracy can be obtained .Different numbers of intervals have been tried continually for piecewise transformation , extracting the corresponding attributes and running the classifiers .As the results shown in Figure 9 , it was found that using 20 segments of each length yields the highest classification accuracy .The test was done preliminarily without FS and the results are averaged over all parameters .Experiment .In order to compare the effectiveness of the proposed time - series preprocessing method with the other existing methods , we test them on four different voice / speech datasets using nearly twenty popular and traditional classification algorithms in data mining .", "label": "", "metadata": {}}
{"text": "Four representative types of voice data are tested by the simulation experiments ; they are Female and Male ( FM )Dataset , Emotional Speech ( ES ) Dataset , Speaker Identification ( SI ) Dataset , and Language Recognition ( LR ) Dataset .Data Sources .FM .The FM dataset is downloaded from School of Information Technology and Electrical Engineering ( ITEE ) , University of Queensland , Australia , called VidTIMIT Audio - Video Dataset [ 29 ] .The dataset is made up of audio recordings of recited short sentences from 43 volunteers , among which 19 are females and 24 are males .", "label": "", "metadata": {}}
{"text": "10 sentences for every speaker .The first two sentences are all the same for each speaker , with the remaining eight that differ according to every individual .Here only the audio data is concerned and video data is discarded .ES .The ES dataset comes from the database of German emotional speech , developed at the Technical University , Institute for Speech and Communication , Department of Communication Science , Berlin , with Professor Sendlmeier .It was funded by the German Research Association DFG ( research project SE 462/3 - 1 ) [ 30 ] .", "label": "", "metadata": {}}
{"text": "It is comprised of seven basic emotions ( anger , happiness , sadness , fear , disgust , boredom , and neutral ) and only four major emotions are taken for the purpose of simplification .Ten professional native German actors with balance gender distribution ( 5 for each ) produced these emotional speeches , which containing 10 sentences with 5 short sentences and 5 longer ones .SI .The SI dataset is taken from the PDA speech database , owned by Yasunari Obuchi in March 2003 , Carnegie Mellon University ( CMU ) .The recording was done by CMU students and staff [ 31 ] .", "label": "", "metadata": {}}
{"text": "The type of that big microphone was an Optimus Nova 80 close - talk microphone .The type of small ones was Panasonic WM-55DC2 and they were mounted using a mock - up shown below .There are 16 speakers and each read about 50 sentences .LR .The LR dataset is generated through an approach called speech synthesis .The speech synthesizer software used here is Microsoft Text - to - Speech engine with many expansion packages [ 32 ] .Sentences of English , Cantonese , and Mandarin were widely selected from the area of frequently used daily conversations , daily news , educational reports , stories , scientific articles , ancient proses , poems and poetries , and so forth .", "label": "", "metadata": {}}
{"text": "The voice data is in the format of two - dimensional time - series , with an amplitude value in sound that varies over time ; examples are given in Figures 8(a ) and 8(b ) .The sampling rate or frequency of wave read process is 10 kHz .Group distributions of distinctive datasets are given in Table 2 .The FM dataset has only two classes , which is the simplest classification task in data mining .The rest of datasets contain more than two classes that make the classification task more difficult .The numbers of attributes or features for every dataset and instances for training and testing are listed in Table 3 .", "label": "", "metadata": {}}
{"text": "Visualization of parts of each group of the datasets , FM , ES , SI , and LR is displayed in Figures 10(a ) to 10(l ) .Inspecting by just naked eyes , one can see some distinctive differences between the waveforms of different classes .Figure 10 : ( a ) Visualization of FM dataset that belongs to the \" Female \" group .( b ) Visualization of FM dataset that belongs to the \" Male \" group .( c ) Visualization of ES dataset that belongs to the \" Anger \" group .( d ) Visualization of ES dataset that belongs to the \" Happiness \" group .", "label": "", "metadata": {}}
{"text": "( f ) Visualization of ES dataset that belongs to the \" Sadness \" group .( g ) Visualization of SI dataset that belongs to the \" Speaker 1 \" group .( h )Visualization of SI dataset that belongs to the \" Speaker 2 \" group .( i ) Visualization of SI dataset that belongs to the \" Speaker 3 \" group .( j )Visualization of LR dataset that belongs to the \" Cantonese \" group .( k ) Visualization of LR dataset that belongs to the \" English \" group .( l ) Visualization of LR dataset that belongs to the \" Mandarin \" group .", "label": "", "metadata": {}}
{"text": "Again , by just visual inspection , it can be observed that the voice data between different classes are apparently distinctive in the FM group and in the LR group .Common sense tells us that female speakers and male speakers have distinguishing vocal tones .Speeches of different languages also can be differentiated easily , as each language has its unique vowels and phonics .In contrast , the voice data of 16 unique speakers have certain overlaps in their feature values ; this implies that some speakers share similar voices which are not something very uncommon in real life .", "label": "", "metadata": {}}
{"text": "That shows the potential computational difficulty in classification between voices of different emotions .Figure 11 : ( a ) MD visualization of FM .( b ) MD visualization of ES .( c ) MD visualization of SI .( d ) MD visualization of LR .Algorithms Used in Comparison .Our experiments are performed by using popular and standard classification algorithms ( with their default parameters applied ) over the four sets of the above - mentioned voice data that are being handled by four preprocessing methods .A total of 20 classification algorithms are being used .", "label": "", "metadata": {}}
{"text": "In other words , the design of the voice classification model should be generic enough , and its efficacy should be independent from the choice of classifier .While the focus of the voice classification model is centered at the preprocessing steps which leverage the features from both time and frequency domains followed by feature selection for reducing the feature space dimension , classification algorithms can become flexible plug - and - play in our model design .LPC - to - CC .Only the cepstrum coefficients are used as the encoding result of time - series voice data .", "label": "", "metadata": {}}
{"text": "Wavelet .Only the 50-largest Harr wavelet coefficients are taken as converting the sequence from time domain to frequency domain .The number of decomposition level of Harr wavelet transform is 3 .SFX .Statistical Feature Extraction ( SFX ) converts the time - series voice data to a whole set of attributes with both frequency and time domains , using a collection of feature methods described in Section 3 .SFX + FS .Statistical Feature Extraction + Feature Selection ( SFX + FS ) is exactly the same as SFX except that the full set of features or attributes were filtered by using different feature reduction methods .", "label": "", "metadata": {}}
{"text": "Two facts are considered : mean accuracy and time cost .The compensation is made between time and accuracy , which means that we prefer a little bit lower accuracy and more on acceptable time cost .The optimal one was chosen as the final FS method .WSA .Wolf Search Algorithm ( WSA ) is a bioinspired heuristic optimization algorithm [ 33 ] .It naturally balances scouting the problem space in random groups ( breadth ) and searching for the solution individually ( depth ) .The pseudocode of WSA is given in Pseudocode 1 . CFS .", "label": "", "metadata": {}}
{"text": "It is that good feature subsets always have highly corresponding features , whereas there are uncorrelated features among the rest of them [ 36 ] .On the basis of that , CFS starts its work and evaluates features .The merit containing .MRMR .Maximum Relevance is normally referred to as subsets of data identified by feature selection which are relevant to the parameters .There often exist relevant but redundant components in those subsets .MRMR , known as Minimum Redundancy Maximum Relevance , however , attempts to detect those redundant subsets , find them out , and delete them .", "label": "", "metadata": {}}
{"text": "The testing results are shown in full in Table 5 .The computing environment is on a PC workstation , with Windows 7 Enterprise Edition , 64 bits , Intel Core i7 CPU , and 8 GB RAM .Results and Analysis .The objective of our experiments is to compare the performance of those four preprocessing methods on four kinds of voice datasets when a collection of data mining classifiers are applied .Our performance evaluation covers four main aspects : .Twenty popular classification algorithms were used on FM and LR datasets , which is regarded as a representative set of commonly used classifiers .", "label": "", "metadata": {}}
{"text": "Some attribute data contain infinitely small values .Results from some classifiers are not available because of the time limitation : it takes too much time for them to build a classification model when the number of attributes gets very large .As such , LibSVM is excluded from experiments involving ES and SI .NBTree and Conjunctive Rule are excluded from experiments over the dataset SI .For feature selection , the algorithm candidate that yields the highest accuracy is used in the subsequent experiments .Accuracy Comparison of Datasets .The accuracy of the classification result is the most significant criterion for evaluating the performance .", "label": "", "metadata": {}}
{"text": "This section shows total accuracies of four preprocessing methods on each voice dataset .Four sets of accuracy results and box plots for different dataset are presented in Figures 12(a ) to 12(d ) .Figure 12 : ( a ) FM boxplot and accuracy table .( b ) ES boxplot and accuracy table .( c ) SI boxplot and accuracy table .( d ) LR boxplot and accuracy table .From the aforementioned figures we find that the first two preprocessing methods , which are wavelet and LPC - to - CC , yielded a relatively nonstationary accuracy result on all four datasets .", "label": "", "metadata": {}}
{"text": "Conversely , LPC - to - CC was better for FM , ES , and SI .Recalling from Section 4.1.1 , we know that only the LR dataset is synthetic , which was produced by a Text - to - Speech engine .LPC - to - CC , known as a common voice encoding method , has a problem in obtaining the more realistic components : there are many transition frames that the LPC model fails to sort correctly [ 38 ] .Such inaccuracy of the model might be due to annoying artifacts like buzzes and tonal noises .", "label": "", "metadata": {}}
{"text": "Meanwhile , SFX and SFX + FS showed relatively more stable results than the first two .They really improved the accuracy a lot .By a contrast of SFX and SFX + FS , after feature selection , the main range ( .Figure 13 : Comparison of average accuracy for different voice datasets and different preprocessing methods .An interesting phenomenon is observed from Figure 13 -the accuracy fell a little after SFX compared to LPC - to - CC over FM dataset .However , from the methodology of SFX , we know that cepstral coefficients are involved in the attributes of SFX .", "label": "", "metadata": {}}
{"text": "FM has only binary classes ; the performances of the preprocessing methods differ very little compared to those in other datasets that have multiple classes .In particular , SI has 16 different classes ; the differences of performance between the preprocessing methods become obvious .Another considerable fact is also derived from Figure 12 on LR dataset - Wavelet seemed to have a better performance than what LPC - to - CC did .Besides the drawback of LPC encoding method , we can also consider other reasons .The inherent frequency of one 's speech is an important acoustic feature for identifying different individuals .", "label": "", "metadata": {}}
{"text": "Remember that the result of LPC - to - CC only contains 10 cepstral coefficients , and the number of target groups to be classified is 16 .It contains too few information for correct classification and wavelet provides relatively sufficient features .Considering the number of classes in each dataset together with the accuracy result , we can find that the accuracy of binary targets classification ( FM ) is higher than multiple targets classification ( ES ) and ( SI ) for the frequency - domain encoding methods .For the time - domain methods like SFX and SFX - FS , good accuracy still can be attained in multiclass classification as in SI where the frequency - domain methods underperform .", "label": "", "metadata": {}}
{"text": "An assumption is made before that , which is closed set and good distribution .If all possible instances belonging to each case fall into one of the classe , and each class contains statistically representative instances , then the performance of classification is good enough .For now , the boundary of every emotion in ES dataset is not clear ( which is already shown in Figure 11(b ) ) , so it does not meet the condition of closed set , and the result is worse than FM .For SI and LR , the features of each individual and language are discriminative enough to tell all classes apart , meaning that they are well distributed , so the results are better than FM .", "label": "", "metadata": {}}
{"text": "This section shows the accuracies of four datasets when every preprocessing method is applied on them , respectively .Four sets of accuracy results and radar charts by different preprocessing methods are shown in Figures 14(a ) to 14(d ) .Figure 14 : ( a ) Accuracy comparison of Wavelet preprocessing method .( b )Accuracy comparison of LPC - to - CC preprocessing method .( c ) Accuracy comparison of SFX preprocessing method .( d ) Accuracy comparison of SFX + FS preprocessing method .It can be seen that in general the classification algorithms produce consistent results when wavelet and LPC - to - CC preprocessing methods are used .", "label": "", "metadata": {}}
{"text": "Comparatively , SFX and SFX + FS yield a jagged outline for the curves of accuracy results in the radar chart , which can be seen in Figures 14(c ) and 14(d ) .Overall , Wavelet and LPC - to - CC show lower average accuracy than those in SFX and SFX + FS .Some classifiers produce exceptionally perfect accuracy on all the four datasets after statistical feature extraction and feature selection are applied .They are LMT and Multilayer Perceptron .The classifier model generated from LMT is a single tree with different shapes on basis of various types of training data .", "label": "", "metadata": {}}
{"text": "But the same thing is that the leaves are each logistic regression model which is quite capable for analysis of dataset with dependent features and bounded magnitudes of time - series .The algorithm is guaranteed that only relevant attributes are selected [ 40 ] .The result is much more intelligible and reasonable than a committee of multiple trees on voice classification .So under such kind of circumstance , LMT offers a better result than other tree classifiers .Multilayer Perceptron is a standard algorithm for any supervised learning task in data mining .The result is relatively better than any other classifiers , achieving almost 100 % accuracy but the time cost is higher and sometimes unacceptable .", "label": "", "metadata": {}}
{"text": "Based on Bayes ' theorem with strong independence assumptions , Na\u00efve Bayes acts as quite a simple classifier and it gets very widely adopted in many classification situations .But sometimes the relation between any pair of attributes is always dependent and the distribution of features is unknown in advance ; thus the performance of such a simple probabilistic classifier is bad and unstable .Overall Averaged Performance Comparison .For a throughout performance evaluation , performance consideration of other parameters is considered as well ; these include Kappa , Precision , Recall , F1 , and ROC , which are commonly used in assessing the quality of the classification models in data mining .", "label": "", "metadata": {}}
{"text": "The performance results pertaining to these indicators are averaged over all the four datasets and all the 20 classification algorithms .They are then shown in Section 5.3.6 together with the comparison of time cost .Kappa Statistic .Kappa statistic is widely used to measure variability between multiple observers .The meaning of Kappa statistic is how often multiobservers agree in terms of their interpretations .When two or more evaluators are checking the same data , Kappa statistic is assessed to show an agreement of evaluators when the same data categories are correctly assigned .As well known , simple agreement just between yes and no is poor because of the property of chance and arbitrary .", "label": "", "metadata": {}}
{"text": "The definition of Kappa statistic is given as follows : . is the hypothetical probability of chance agreement .When the application is classification , the measure of chance between the classification results and the true classes ( labeled categorical data class ) is assessed by Kappa statistic .It reflects the reliability of the evaluation of our classifier .Table 6 is the general criterion of evaluating Kappa statistic [ 42 ] .A comparison of different voice datasets and different preprocessing methods , in terms of average Kappa statistic , is shown in Figure 15 .Wavelet method is relatively unstable in datasets of FM , ES , and SI .", "label": "", "metadata": {}}
{"text": "SFX without FS , however , underperformed when compared to LPC - CC in FM and ES datasets which are relatively simple .SFX - FS shows its superiority in Kappa statistics in all datasets .Figure 15 : Comparison of average Kappa statistic for different voice datasets and different preprocessing methods .Precision .In pattern recognition and data mining , precision is the fraction of relevantly retrieved instances .In the situation of classifications , the terms positive and negative describe the classifier 's prediction results , and the terms true and false refer to whether the prediction results correspond to the fact or not [ 43 ] .", "label": "", "metadata": {}}
{"text": "Precision is concisely defined as \" of all the instances that were classified into a particular class , how many were actually belonged to that class ? \" In classification task , a perfect precision score for a particular class means that every instance classified into that class does indeed belong to that class ( but it says nothing about the number of instances from that class that were not classified correctly ) .As shown in Figure 16 , for example , SFX - FS when applied on LR dataset has the maximum precision score 0.88-that means 88 % of the instances that are classified into a particular indeed belong to that class .", "label": "", "metadata": {}}
{"text": "Wavelet method was unacceptable for all datasets except LR , for it has merely 0.59 , 0.42 , and 0.25 precision scores , respectively .The comparison with respect to precision scores is shown in Figure 16 .Recall .In pattern recognition and data mining , recall is defined as the fraction of relevantly retrieved instances .We can infer that the same part of both precision and recall is relevance , based on which they all make a measurement .Usually , precision and recall scores are not discussed in isolation and the relationship between them is inverse , indicating that one increases and the other decreases .", "label": "", "metadata": {}}
{"text": "In a classification task , recall is a criterion of the classification ability of a prediction model to select labeled instances from training and testing datasets .A recall of score 1.0 means that each instance from that particular class is labeled to this class and all are predicted correctly , and none shall be left out [ 44 ] .The recall scores defined loosely as \" of all the instances that are truly of a particular class , how many did we classify them into that class ? \" For example , as shown in Figure 17 , 86 % of instances are classified into the classes and they actually belonged to those classes .", "label": "", "metadata": {}}
{"text": "Again , the recall scores for Wavelet method are comparatively low except in the LR dataset it exceeds that of LPC - to - CC method .Having a low recall score means the classifier is conservative .SFX - FS is outperforming the rest of the methods in terms of recall scores .The comparison is shown in Figure 17 .As mentioned before , precision and recall scores should be taken into account simultaneously because they have a strong relation essentially .Consequentially , both are combined into a single measure , which is .measure is a derived effectiveness measurement .", "label": "", "metadata": {}}
{"text": "The best value is 1 and the worst is 0 .Figure 18 shows a comparison of average .-measure for different voice datasets and different preprocessing methods .ROC .A Receiver Operating Characteristic ( ROC ) is generated by plotting True Positive Rate ( TPR ) verse False Positive Rate ( FPR ) with many value settings of threshold .It is a graphical plot which illustrates the performance of sensitivity and specificity .TPR is also known as sensitivity , and FPR is one minus the specificity or true negative rate .A ROC space is defined by FPR and TPR as . representing the best prediction result .", "label": "", "metadata": {}}
{"text": "The AUC is an equivalent and simple replacement of ROC curve .ROC is useful for gaining insight into the decision - making ability of the model - how likely is the classification model to accurately predict the respective classes ?The AUC measures the discriminating ability of a classification model .The larger the AUC , the higher the likelihood that an actual positive case will be assigned a higher probability of being positive than an actual negative case .The AUC measure is especially useful for datasets with unbalanced target distribution ( one target class dominates the other ) .", "label": "", "metadata": {}}
{"text": "SFX + FS perform equally well in SI dataset and LR dataset with 0.94 AUC ; it is slightly higher than SFX and LPC - to - CC in FM and ES datasets .Wavelet has the lowest AUC in all datasets except LR where it is better than that of LPC - to - CC .Figure 19 : Comparison of average ROC AUC for different voice datasets and different preprocessing methods .Aggregated Results .The final results that are averaged and aggregated , from the individual results tested by using different datasets and different classification algorithms , are shown as follows .", "label": "", "metadata": {}}
{"text": "Table 8 : Overall Averaged Performance Comparison of Pre - processing Methods .From Table 8 , we can reach a conclusion that SFX with FS is indeed the most suitable preprocessing method for all types of voice datasets .It has a higher value across all performance indicators than the rest of the preprocessing methods .The accuracy and CPU time are evaluated across different feature selection algorithms ; the averaged results together with the amount of attributes before and after FS are shown in Table 9 .Table 9 : Overall averaged performance comparison of ensemble feature selections .", "label": "", "metadata": {}}
{"text": "WSA gives the second fewest number of attributes after feature selection , highest classification accuracy , and a compromising time cost with 31 seconds minimum .So to some extent WSA is a good choice of feature selection if time requirement is not a concern in training up a voice classification model .WSA is done at the cost of incurring extra time in doing the heuristic optimization on the feature subset .Table 9 shows the overall averaged time cost of each process step applied on different datasets .Piecewise transformation and DTW need much longer time than the other processes due to the computational complexity .", "label": "", "metadata": {}}
{"text": "Statistic measures are computed for each segment ( 20x ) for each time - series .WSA works as a stochastic iteration model , which progressively refines the performance and is superior to the other three FS methods but comes at a certain time cost .In contrast the classification model construction times in general are very short , with an average of less than two seconds .Please see Table 10 .The total time required for preprocessing voice data for classification ranges from slightly less than an hour to four hours and eighteen minutes , depending on the choice of preprocessing algorithms and complexity of the datasets .", "label": "", "metadata": {}}
{"text": "Conclusion and Future Works .Human voice is referred to as one of the bodily vital signs that could be measured , recorded , and analyzed as fluctuations of amplitude of sound loudness .Voice classification constitutes to a number of biometrics techniques of which the theories have been formulated , studied , and implemented in practical applications .Traditional classification algorithms from data mining domain , however , require the input of training data to be formatted in a data matrix where the columns represent features / attributes that characterize the voice data , and the rows are the instances of the voice data .", "label": "", "metadata": {}}
{"text": "In the literature , mainly the characteristics of voice data are acquired from the frequency domain , for example , LPC , cepstral coefficients , and MFCC .Those popular preprocessing methods have demonstrated significant advantages in transforming voice data which is in the form of time - series to signatures in the frequency domain .There exist possibilities that some useful attributes can be harvested from the time domain considering the temporal patterns of voice data that are supposedly distinctive from one another .A challenge to overcome is its expensive computational cost of time and large search space in the time domain .", "label": "", "metadata": {}}
{"text": "In particular , a time domain feature extraction technique called Statistics Feature Extraction ( SFX ) is presented .SFX utilizes piecewise transformation that partitions a whole time - series into segments and statistics features are extracted subsequently from each piece .Simulation experiments were conducted on classifying four types of voice data , namely , Female and Male , Emotional Speech , Speaker Identification , and Language Recognition into different groups by using SFX and its counterparts ( SFX and Feature Selection ) .The results showed that SFX is able to achieve a higher accuracy in the classification models for the four types of voice data .", "label": "", "metadata": {}}
{"text": "Besides , the feature selection result proves that a metaheuristic feature selection algorithm called Wolf Search ( WSA ) can achieve a global optimal feature subset for highest possible classification accuracy .As there is no free lunch in the world , WSA costs considerable amount of computational time .The precision of piecewise transformation segmentation can be one of the future works .If the number of segments is too large ( low resolution in time - series modeling ) , then it will lead to the low accuracy of feature extraction ; if the window is too small ( with very refined resolution ) , then a lot more computational costs are incurred .", "label": "", "metadata": {}}
{"text": "Some dynamic and incremental methods are opted for solving this calibration problem for estimating the correct length of segments .Furthermore the segment lengths can be variables that cope with the level of fluctuation of the voice data , dynamically .Acknowledgments .The authors are thankful for the financial support from the research grant \" Adaptive OVFDT with Incremental Pruning and ROC Corrective Learning for Data Stream Mining , \" Grant no .MYRG073(Y2-L2)-FST12-FCC , offered by the University of Macau , FST , and RDAO .References .S. Fong , \" Using hierarchical time series clustering algorithm and wavelet classifier for biometric voice classification , \" Journal of Biomedicine and Biotechnology , vol .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar .View at Publisher \u00b7 View at Google Scholar .C. F. Chan and W. M. E. Yu , \" An abnormal sound detection and classification system for surveillance applications , \" in Proceedings of the European Signal Processing Conference ( EUSIPCO ' 10 ) , pp . 1 - 2 , Aalborg , Denmark , August 2010 .G. Peeters , \" A large set of audio features for sound description ( similarity and classification ) in the cuidado project , \" CUIDADO Project Report , 2004 .View at Google Scholar .", "label": "", "metadata": {}}
{"text": "L. R. Rabiner and M. R. Sambur , \" Application of an LPC distance measure to the voiced - unvoiced - silence detection problem , \" IEEE Transactions on Acoustics , Speech , and Signal Processing , vol .25 , no .4 , pp .338 - 343 , 1977 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. R. Rabiner and R. W. Schafer , Digital Processing of Speech Signals , Prentice Hall , Englewood Cliffs , NJ , USA .G. Antoniol , V. F. Rollo , and G. Venturi , \" Linear Predictive Coding and Cepstrum coefficients for mining time variant information from software repositories , \" in Proceedings of the 2005 International Workshop on Mining Software Repositories , pp . 1 - 5 , July 2005 .", "label": "", "metadata": {}}
{"text": "N. Awasthy , J. P. Saini , and D. S. Chauhan , \" Spectral analysis of speech : a new technique , \" International Journal of Information and Communication Engineering , vol .2 , no . 1 , pp .19 - 28 , 2006 .View at Google Scholar .B. Logan , \" Mel frequency cepstral coefficients for music modeling , \" in Proceedings of the International Symposium on Music Information Retrieval , pp . 1 - 3 , 2000 .S. V. Chapaneri , \" Spoken digits recognition using weighted MFCC and improved features for dynamic time warping , \" International Journal of Computer Applications , vol .", "label": "", "metadata": {}}
{"text": "6 - 12 , 2012 .View at Google Scholar .View at Scopus . H. Hermansky , \" Perceptual linear predictive ( PLP ) analysis of speech , \" Journal of the Acoustical Society of America , vol .87 , no .4 , pp .1738 - 1752 , 1990 .View at Publisher \u00b7 View at Google Scholar .T. Nitta , \" Feature extraction for speech recognition based on orthogonal acoustic - feature planes and LDA , \" in Proceedings of the 1999 IEEE International Conference on Acoustics , Speech , and Signal Processing ( ICASSP-99 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Scopus .J. H. Lee , H. Y. Jung , T. W. Lee , and S. Y. Lee , \" Speech feature extraction using independent component analysis , \" in Proceedings of the IEEE Interntional Conference on Acoustics , Speech , and Signal Processing , pp .1631 - 1634 , June 2000 .View at Scopus .B. J. Lee , B. Ku , K. Park , K. H. Kim , and J. Y. Kim , \" A new method of diagnosing constitutional types based on vocal and facial features for personalized medicine , \" Journal of Biomedicine and Biotechnology , vol .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar . D. Maunder , J. Epps , E. Ambikairajah , and B. Celler , \" Robust sounds of activities of daily living classification in two - channel audio - based telemonitoring , \" International Journal of Telemedicine and Applications , vol .2013 , Article ID 696813 , 12 pages , 2013 .View at Publisher \u00b7 View at Google Scholar .S. Fong , \" Opportunities and challenges of integrating bio - inspired optimization and data mining algorithms , \" in Swarm Intelligence and Bioinspired Computation , chapter 18 , pp .", "label": "", "metadata": {}}
{"text": "View at Google Scholar .R. Daniloff , G. Schuckers , and L. Feth , The Physiology of Speech and Hearing : An Introduction , Prentice Hall , 1980 . A. V. Oppenheim and R. W. Schafer , Digital Signal Processing , Prentice Hall , Englewood Cliffs , NJ , USA , 1975 .J. G. Proakis and M. Salehi , Communication Systems Engineering , Prentice Hall , Upper Saddle River , NJ , USA , 2nd edition , 2002 . A. \u00d3. Cinn\u00e9ide , Linear Prediction : The Technique , Its Solution and Application to Speech , Dublin Institute of Technology , Dublin , Ireland .", "label": "", "metadata": {}}
{"text": "29 , no . 2 , pp .254 - 272 , 1981 .View at Google Scholar \u00b7 View at Scopus .G. Box , G. M. Jenkins , and G. C. Reinsel , Time Series Analysis : Forecasting and Control , Prentice - Hall , 3rd edition , 1994 .R. F. Engle , \" Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation , \" Econometrica , vol .50 , no .4 , pp .987 - 1007 , 1982 .View at Publisher \u00b7 View at Google Scholar .R. Tang and S. Fong , \" Wolf search algorithm with ephemeral memory , \" in Proceedings of the 7th International Conference on Digital Information Management ( ICDIM ' 12 ) , pp . 1 - 3 , University of Macau , Macau , China , August 2012 .", "label": "", "metadata": {}}
{"text": "477 - 489 , 2006 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . H.Peng , F. Long , and C. Ding , \" Feature selection based on mutual information : criteria of max - dependency , max - relevance , and min - redundancy , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .27 , no . 8 , pp .1226 - 1238 , 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. A. Osman , A. Nasser , H. M. Magboub , and S. A. Alfandi , \" Speech compression using LPC and wavelet , \" in Proceedings of the 2nd International Conference on Computer Engineering and Technology ( ICCET ' 10 ) , vol .", "label": "", "metadata": {}}
{"text": "92 - 99 , April 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . A. G. Janecek , W. N. Gansterer , M. A. Demel , and G. F. Ecker , \" On the relationship between feature selection and classification accuracy , \" JMLR Workshop and Conference Proceedings , vol .4 , pp .90 - 105 , 2008 .View at Google Scholar .J. Carletta , \" Squibs and discussions : assessing agreement on classification tasks : the kappa statistic , \" Computational Linguistics , vol .22 , no . 2 , pp .", "label": "", "metadata": {}}
{"text": "View at Google Scholar \u00b7 View at Scopus . A. J. Viera and J. M. Garrett , \" Understanding interobserver agreement : the kappa statistic , \" Family Medicine , vol .37 , no .5 , pp .360 - 363 , 2005 .View at Google Scholar \u00b7 View at Scopus .P. M. W. David , \" Evaluation : from precision , recall and F - factor to ROC , informedness , markedness & correlation , \" Journal of Machine Learning Technologies , vol .2 , no . 1 , pp .37 - 63 , 2011 .", "label": "", "metadata": {}}
{"text": "P. Baldi , S. Brunak , Y. Chauvin , C. A. F. Andersen , and H. Nielsen , \" Assessing the accuracy of prediction algorithms for classification : an overview , \" Bioinformatics , vol .16 , no .5 , pp .412 - 424 , 2000 .View at Google Scholar \u00b7 View at Scopus G. Heigold , I. Moreno , S. Bengio , and N. Shazeer .End - to - end text - dependent speaker verification .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2016 . [ .", "label": "", "metadata": {}}
{"text": "Such an approach will result in simple and efficient systems , requiring little domain - specific knowledge and making few model assumptions .We implement the idea by formulating the problem as a single neural network architecture , including the estimation of a speaker model on only a few utterances , and evaluate it on our internal \" Ok Google \" benchmark for text - dependent speaker verification .The proposed approach appears to be very effective for big data applications like ours that require highly accurate , easy - to - maintain systems with a small footprint .O. Vinyals , S. Bengio , and M. Kudlur .", "label": "", "metadata": {}}
{"text": "In International Conference on Learning Representations , ICLR , 2016 . [ .Sequences have become first class citizens in supervised learning thanks to the resurgence of recurrent neural networks .Many complex tasks that require mapping from or to a sequence of observations can now be formulated with the sequence - to - sequence ( seq2seq ) framework which employs the chain rule to efficiently represent the joint probability of sequences .In many cases , however , variable sized inputs and/or outputs might not be naturally expressed as sequences .In this paper , we first show using various examples that the order in which we organize input and/or output data matters significantly when learning an underlying model .", "label": "", "metadata": {}}
{"text": "In addition , we propose a loss which , by searching over possible orders during training , deals with the lack of structure of output sets .We show empirical evidence of our claims regarding ordering , and on the modifications to the seq2seq framework on benchmark language modeling and parsing tasks , as well as two artificial tasks - sorting numbers and estimating the joint probability of unknown graphical models .S. Bengio , O. Vinyals , N. Jaitly , and N. Shazeer .Scheduled sampling for sequence prediction with recurrent neural networks .In Advances In Neural Information Processing Systems , NIPS , 2015 .", "label": "", "metadata": {}}
{"text": "Recurrent Neural Networks can be trained to produce sequences of tokens given some input , as exemplified by recent results in machine translation and image captioning .The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current ( recurrent ) state and the previous token .At inference , the unknown previous token is then replaced by a token generated by the model itself .This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence .We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token , towards a less guided scheme which mostly uses the generated token instead .", "label": "", "metadata": {}}
{"text": "Moreover , it was used successfully in our winning entry to the MSCOCO image captioning challenge , 2015 .V. Ramanathan , J. Deng , C. Li , W. Han , Z. Li , K. Gu , Y. Song , S. Bengio , C. Rosenberg , and F.-F. Li .Learning semantic relationships for better action retrieval in images .In IEEE Conference on Computer Vision and Pattern Recognition , CVPR , 2015 .[ .Human actions capture a wide variety of interactions between people and objects .As a result , the set of possible actions is extremely large and it is difficult to obtain sufficient training examples for all actions .", "label": "", "metadata": {}}
{"text": "A single action is often composed of other smaller actions and is exclusive of certain others .We would like our method to reason about such relationships and extrapolate unobserved actions from known actions .Hence , we propose a novel neural network framework which jointly extracts the relationship between actions and uses them for training better action recognition models .Our model incorporates linguistic , visual and logical consistency based cues to effectively identify theses relationships .We train and test our model on a new largescale image dataset of human actions under two settings with 27 K and 2 K actions .", "label": "", "metadata": {}}
{"text": "O. Vinyals , A. Toshev , S. Bengio , and D. Erhan .Show and tell : A neural image caption generator .In IEEE Conference on Computer Vision and Pattern Recognition , CVPR , 2015 . [ .Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing .In this paper , we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image .", "label": "", "metadata": {}}
{"text": "Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions .Our model is often quite accurate , which we verify both qualitatively and quantitatively .For instance , while the current state - of - the - art BLEU-1 score ( the higher the better ) on the Pascal dataset is 25 , our approach yields 59 , to be compared to human performance around 69 .We also show BLEU-1 score improvements on Flickr30k , from 56 to 66 , and on SBU , from 19 to 28 .", "label": "", "metadata": {}}
{"text": "Word embeddings for speech recognition .In Proceedings of the 15th Conference of the International Speech Communication Association , Interspeech , 2014 .[ .Speech recognition systems have used the concept of states as a way to decompose words into sub - word units for decades .As the number of such states now reaches the number of words used to train acoustic models , it is interesting to consider approaches that relax the assumption that words are made of states .We present here an alternative construction , where words are projected into a continuous embedding space where words that sound alike are nearby in the Euclidean sense .", "label": "", "metadata": {}}
{"text": "Initial experiments using a lattice rescoring approach and model combination on a large realistic dataset show improvements in word error rate .J. Deng , N. Ding , Y. Jia , A. Frome , K. Murphy , S. Bengio , Y. Li , H. Neven , and H. Adam .Large - scale object classification using label relation graphs .In Proceedings of the European Conference on Computer Vision , ECCV , 2014 . [ .In this paper we study how to perform object classification in a principled way that exploits the rich structure of real world labels .", "label": "", "metadata": {}}
{"text": "We introduce Hierarchy and Exclusion ( HEX ) graphs , a new formalism that captures semantic relations between any two labels applied to the same object : mutual exclusion , overlap and subsumption .We then provide rigorous theoretical analysis that illustrates properties of HEX graphs such as consistency , equivalence , and computational implications of the graph structure .Next , we propose a probabilistic classification model based on HEX graphs and show that it enjoys a number of desirable properties .Finally , we evaluate our method using a large - scale benchmark .Empirical results demonstrate that our model can significantly improve object classification by exploiting the label relations .", "label": "", "metadata": {}}
{"text": "Training highly multiclass classifiers .Journal of Machine Learning Research , JMLR , 15:1461 - 1492 , 2014 .[ .Classification problems with thousands or more classes often have a large variance in the confusability between classes , and we show that the more - confusable classes add more noise to the empirical loss that is minimized during training .We propose an online solution that reduces the effect of highly confusable classes in training the classifier parameters , and focuses the training on pairs of classes that are easier to differentiate at any given time in the training .", "label": "", "metadata": {}}
{"text": "Experiments on ImageNet benchmark datasets and proprietary image recognition problems with 15,000 to 97,000 classes show substantial gains in classification accuracy compared to one - vs - all linear SVMs and Wsabie .J. Lee , S. Bengio , S. Kim , G. Lebanon , and Y. Singer .Local collaborative ranking .In International World Wide Web Conference , WWW , 2014 .[ .Personalized recommendation systems are used in a wide variety of applications such as electronic commerce , social networks , web search , and more .Collaborative filtering approaches to recommendation systems typically assume that the rating matrix ( e.g. , movie ratings by viewers ) is low - rank .", "label": "", "metadata": {}}
{"text": "Concretely , we assume that the rating matrix is low - rank within certain neighborhoods of the metric space defined by ( user , item ) pairs .We combine a recent approach for local low - rank approximation based on the Frobenius norm with a general empirical risk minimization for ranking losses .Our experiments indicate that the combination of a mixture of local low - rank matrices each of which was trained to minimize a ranking loss outperforms many of the currently used state - of - the - art recommendation systems .Moreover , our method is easy to parallelize , making it a viable approach for large scale real - world rank - based recommendation systems .", "label": "", "metadata": {}}
{"text": "Zero - shot learning by convex combination of semantic embeddings .In International Conference on Learning Representations , ICLR , 2014 .[ .Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces .In some cases the embedding space is trained jointly with the image transformation .In other cases the semantic embedding space is established by an independent natural language processing task , and then the image transformation into that space is learned in a second stage .Proponents of these image embedding systems have stressed their advantages over the traditional classification framing of image understanding , particularly in terms of the promise for zero - shot learning - the ability to correctly annotate images of previously unseen object categories .", "label": "", "metadata": {}}
{"text": "Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors , and requires no additional training .We show that this simple and direct method confers many of and indeed outperforms state of the art methods on the ImageNet zero - shot learning task .S. Bengio , L. Deng , H. Larochelle , H. Lee , and R. Salakhutdinov .Guest editors ' introduction : Special section on learning deep architectures .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 35:1795 - 1797 , 2013 . [ . H. Elmlund , D. Elmlund , and S. Bengio .", "label": "", "metadata": {}}
{"text": "Structure , 21:1299 - 1306 , 2013 . [ .Low - dose electron microscopy of cryo - preserved individual biomolecules ( single - particle cryo - EM ) is a powerful tool for obtaining information about the structure and dynamics of large macromolecular assemblies .Acquiring images with low dose reduces radiation damage , preserves atomic structural details , but results in low signal - to - noise ratio of the individual images .The projection directions of the two - dimensional images are random and unknown .The grand challenge is to achieve the precise three - dimensional ( 3D ) alignment of many ( tens of thousands to millions ) noisy projection images , which may then be combined to obtain a faithful 3D map .", "label": "", "metadata": {}}
{"text": "DeViSE : A deep visual - semantic embedding model .In Advances In Neural Information Processing Systems , NIPS , 2013 . [ .Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories .This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows .One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions .In this paper we present a new deep visual - semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text .", "label": "", "metadata": {}}
{"text": "Semantic knowledge improves such zero - shot predictions achieving hit rates of up to 18 % across thousands of novel labels never seen by the visual model .M. Stevens , S. Bengio , and Y. Singer .Efficient learning of sparse ranking functions .In B. Scholkopf , Z. Luo , and V. Vovk , editors , Empirical Inference .Springer , 2013 .Algorithms for learning to rank can be inefficient when they employ risk functions that use structural information .We describe and analyze a learning algorithm that efficiently learns a ranking function using a domination loss .", "label": "", "metadata": {}}
{"text": "In that context , we propose an efficient coordinate descent approach that scales linearly with the number of examples .We then present an extension that incorporates regularization thus extending Vapnik\u00bfs notion of regularized empirical risk minimization to ranking learning .We also discuss an extension to the case of multi - values feedback .Experiments performed on several benchmark datasets and large scale Google internal dataset demonstrate the effectiveness of learning algorithm in constructing compact models while retaining the empirical performance accuracy .S. Bengio .Large scale visual semantic extraction .In Frontiers of Engineering - Reports on Leading - Edge Engineering from the 2011 Symposium , 2012 .", "label": "", "metadata": {}}
{"text": "In the large scale setting , there could be millions of images to process and hundreds of thousands of potential distinct annotations .In order to achieve such a task we propose to build a so - called \" embedding space \" , into which both images and annotations can be automatically projected .In such a space , one can then find the nearest annotations to a given image , or annotations similar to a given annotation .One can even build a visio - semantic tree from these annotations , that corresponds to how concepts ( annotations ) are similar to each other with respect to their visual characteristics .", "label": "", "metadata": {}}
{"text": "C. Dimitrakakis and S. Bengio .Phoneme and sentence - level ensembles for speech recognition .EURASIP Journal on Audio , Speech , and Music Processing , 2011 , 2011 .[ .We address the question of whether and how boosting and bagging can be used for speech recognition .In order to do this , we compare two different boosting schemes , one at the phoneme level and one at the utterance level , with a phoneme - level bagging scheme .We control for many parameters and other choices , such as the state inference scheme used .", "label": "", "metadata": {}}
{"text": "We thus conclude that bagging methods , which have so far been overlooked in favour of boosting , should be examined more closely as a potentially useful ensemble learning technique for speech recognition .J. Weston , S. Bengio , and P. Hamel .Multi - tasking with joint semantic spaces for large - scale music annotation and retrieval .Journal of New Music Research , 40:337 - 348 , 2011 .[ .Music prediction tasks range from predicting tags given a song or clip of audio , predicting the name of the artist , or predicting related songs given a song , clip , artist name or tag .", "label": "", "metadata": {}}
{"text": "In realistically sized databases , the number of songs is measured in the hundreds of thousands or more , and the number of artists in the tens of thousands or more , providing a considerable challenge to standard machine learning techniques .In this work , we propose a method that scales to such datasets which attempts to capture the semantic similarities between the database items by modeling audio , artist names , and tags in a single low - dimensional semantic embedding space .This choice of space is learnt by optimizing the set of prediction tasks of interest jointly using multi - task learning .", "label": "", "metadata": {}}
{"text": "Our method also outperforms the baseline methods tried and , in comparison to them , is faster and consumes less memory .We also demonstrate how our method learns an interpretable model , where the semantic space captures well the similarities of interest .J. Weston , S. Bengio , and N. Usunier .Wsabie : Scaling up to large vocabulary image annotation .In Proceedings of the International Joint Conference on Artificial Intelligence , IJCAI , 2011 .[ .Image annotation datasets are becoming larger and larger , with tens of millions of images and tens of thousands of possible annotations .", "label": "", "metadata": {}}
{"text": "Our method , called Wsabie , both outperforms several baseline methods and is faster and consumes less memory .S. Bengio .Statistical machine learning for HCI .In J.-P. Thiran , F. Marqu\u00e9s , and H. Bourlard , editors , Multimodal Signal Processing : Theory and Applications for Human - Computer Interaction , pages 7 - 23 .Academic Press , 2010 .This chapter introduces the main concepts of statistical machine learning , as they are pivot in most algorithms tailored for multimodal signal processing .In particular , the chapter will cover a general introduction to machine learning and how it is used in classification , regression and density estimation .", "label": "", "metadata": {}}
{"text": "S. Bengio , J. Weston , and D. Grangier .Label embedding trees for large multi - class tasks .In Advances in Neural Information Processing Systems , NIPS , 2010 .[ .Multi - class classification becomes challenging at test time when the number of classes is very large and testing against every possible class can become computationally infeasible .This problem can be alleviated by imposing ( or learning ) a structure over the set of classes .We propose an algorithm for learning a tree - structure of classifiers which , by optimizing the overall tree loss , provides superior accuracy to existing tree labeling methods .", "label": "", "metadata": {}}
{"text": "Large scale online learning of image similarity through ranking .Journal of Machine Learning Research , JMLR , 11:1109 - 1135 , 2010 .[ .Learning a measure of similarity between pairs of objects is an important generic problem in machine learning .It is particularly useful in large scale applications like searching for an image that is similar to a given image or finding videos that are relevant to a given video .In these tasks , users look for objects that are not only visually similar but also semantically related to a given object .Unfortunately , the approaches that exist today for learning such semantic similarity do not scale to large datasets .", "label": "", "metadata": {}}
{"text": "The current paper presents OASIS , an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations .OASIS is an online dual approach using the passive - aggressive family of learning algorithms with a large margin criterion and an efficient hinge loss cost .Our experiments show that OASIS is both fast and accurate at a wide range of scales : for a dataset with thousands of images , it achieves better results than existing state - of - the - art methods , while being an order of magnitude faster .For large , web scale , datasets , OASIS can be trained on more than two million images from 150 K text queries within 3 days on a single CPU .", "label": "", "metadata": {}}
{"text": "This suggests that query independent similarity could be accurately learned even for large scale datasets that could not be handled before .D. Erhan , Y. Bengio , A. Courville , P.-A. Manzagol , P. Vincent , and S. Bengio .Why does unsupervised pre - training help deep learning ?Journal of Machine Learning Research , JMLR , 11:625 - 660 , 2010 .[ .Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto - encoder variants , with impressive results obtained in several areas , mostly on vision and language data sets .", "label": "", "metadata": {}}
{"text": "Even though these new algorithms have enabled training deep models , many questions remain as to the nature of this difficult learning problem .The main question investigated here is the following : how does unsupervised pre - training work ?Answering this questions is important if learning in deep architectures is to be further improved .We propose several explanatory hypotheses and test them through extensive simulations .We empirically show the influence of pre - training with respect to architecture depth , model capacity , and number of training examples .The experiments confirm and clarify the advantage of unsupervised pre - training .", "label": "", "metadata": {}}
{"text": "R. F. Lyon , M. Rehn , S. Bengio , T. C. Walters , and G. Chechik .Sound retrieval and ranking using sparse auditory representations .Neural Computation , 22(9):2390 - 2416 , 2010 .[ .To create systems that understand the sounds that humans are exposed to in everyday life , we need to represent sounds with features that can discriminate among many different sound classes .Here , we use a sound - ranking framework to quantitatively evaluate such representations in a large scale task .We have adapted a machine - vision method , the \" passive - aggressive model for image retrieval \" ( PAMIR ) , which efficiently learns a linear mapping from a very large sparse feature space to a large query - term space .", "label": "", "metadata": {}}
{"text": "We tested auditory models that use adaptive pole - zero filter cascade ( PZFC ) auditory filterbank and sparse - code feature extraction from stabilized auditory images via multiple vector quantizers .In addition to auditory image models , we also compare a family of more conventional Mel - Frequency Cepstral Coefficient ( MFCC ) front ends .The experimental results show a significant advantage for the auditory models over vector - quantized MFCCs .Ranking thousands of sound files with a query vocabulary of thousands of words , the best precision at top-1 was 73 % and the average precision was 35 % , reflecting a 18 % improvement over the best competing MFCC frontend .", "label": "", "metadata": {}}
{"text": "Large scale image annotation : Learning to rank with joint word - image embeddings .In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases , ECML - PKDD , 2010 .Best Paper Award in Machine Learning [ .Image annotation datasets are becoming larger and larger , with tens of millions of images and tens of thousands of possible annotations .We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low - dimensional joint embedding space for both images and annotations .", "label": "", "metadata": {}}
{"text": "We also demonstrate how our method learns an interpretable model , where annotations with alternate spellings or even languages are close in the embedding space .Hence , even when our model does not predict the exact annotation given by a human labeler , it often predicts similar annotations , a fact that we try to quantify by measuring the newly introduced \" sibling \" precision metric , where our method also obtains excellent results .J. Weston , S. Bengio , and N. Usunier .Large scale image annotation : Learning to rank with joint word - image embeddings .", "label": "", "metadata": {}}
{"text": "[ .Image annotation datasets are becoming larger and larger , with tens of millions of images and tens of thousands of possible annotations .We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low - dimensional joint embedding space for both images and annotations .Our method both outperforms several baseline methods and , in comparison to them , is faster and consumes less memory .We also demonstrate how our method learns an interpretable model , where annotations with alternate spellings or even languages are close in the embedding space .", "label": "", "metadata": {}}
{"text": "S. Bengio and J. Keshet .Introduction .In J. Keshet and S. Bengio , editors , Automatic Speech and Speaker Recognition : Large Margin and Kernel Methods , pages 3 - 10 .Wiley , 2009 .One of the most natural communication tools used by humans is their voice .It is hence natural that a lot of research has been devoted to analyzing and understanding human uttered speech for various applications .The most obvious one is automatic speech recognition , where the goal is to transcribe a recorded speech utterance into its corresponding sequence of words .", "label": "", "metadata": {}}
{"text": "The aim of this book is to introduce the speech researcher community to radically different approaches based on more recent kernel based machine learning methods .S. Bengio , F. Pereira , Y. Singer , and D. Strelow .Group sparse coding .In Advances in Neural Information Processing Systems , NIPS .MIT Press , 2009 .[ .Bag - of - words document representations are often used in text , image and video processing .While it is relatively easy to determine a suitable word dictionary for text documents , there is no simple mapping from raw images or videos to dictionary terms .", "label": "", "metadata": {}}
{"text": "More robust approaches have been proposed recently that represent each visual descriptor as a sparse weighted combination of dictionary words .While favoring a sparse representation at the level of visual descriptors , those methods however do not ensure that images have sparse representation .In this work , we use mixed - norm regularization to achieve sparsity at the image level as well as a small overall dictionary .This approach can also be used to encourage using the same dictionary words for all the images in a class , providing a discriminative signal in the construction of image representations .", "label": "", "metadata": {}}
{"text": "G. Chechik , V. Sharma , U. Shalit , and S. Bengio .Large - scale online learning of image similarity through ranking : Extended abstract .In 4th Iberian Conference on Pattern Recognition and Image Analysis IbPRIA , 2009 .[ .Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning .Pairwise similarity plays a crucial role in classification algorithms like nearest neighbors , and is practically important for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video .", "label": "", "metadata": {}}
{"text": "Unfortunately , current approaches for learning semantic similarity are limited to small scale datasets , because their complexity grows quadratically with the sample size , and because they impose costly positivity constraints on the learned similarity functions .To address real - world large - scale AI problem , like learning similarity over all images on the web , we need to develop new algorithms that scale to many samples , many classes , and many features .The current abstract presents OASIS , an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations .", "label": "", "metadata": {}}
{"text": "Our experiments show that OASIS is both fast and accurate at a wide range of scales : for a dataset with thousands of images , it achieves better results than existing state - of - the - art methods , while being an order of magnitude faster .Comparing OASIS with different symmetric variants , provides unexpected insights into the effect of symmetry on the quality of the similarity .For large , web scale , datasets , OASIS can be trained on more than two million images from 150 K text queries within two days on a single CPU .", "label": "", "metadata": {}}
{"text": "This suggests that query - independent similarity could be accurately learned even for large - scale datasets that could not be handled before .G. Chechik , V. Sharma , U. Shalit , and S. Bengio .An online algorithm for large scale image similarity learning .In Advances in Neural Information Processing Systems , NIPS .MIT Press , 2009 .[ .Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning .It stands in the core of classification methods like kernel machines , and is particularly useful for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video .", "label": "", "metadata": {}}
{"text": "Unfortunately , current approaches for learning similarity do not scale to large datasets , especially when imposing metric constraints on the learned similarity .We describe OASIS , a method for learning pairwise similarity that is fast and scales linearly with the number of objects and the number of non - zero features .Scalability is achieved through online learning of a bilinear model over sparse representations using a large margin criterion and an efficient hinge loss cost .OASIS is accurate at a wide range of scales : on a standard benchmark with thousands of images , it is more precise than state - of - the - art methods , and faster by orders of magnitude .", "label": "", "metadata": {}}
{"text": "The non - metric similarities learned by OASIS can be transformed into metric similarities , achieving higher precisions than similarities that are learned as metrics in the first place .This suggests an approach for learning a metric from data that is larger by orders of magnitude than was handled before .D. Erhan , P.-A. Manzagol , Y. Bengio , S. Bengio , and P. Vincent .The difficulty of training deep architectures and the effect of unsupervised pre - training .In D. van Dyk and M. Wellings , editors , Proceedings of The Twelfth International Conference on Artificial Intelligence and Statistics , AISTATS , volume 5 of JMLR Workshop and Conference Procedings , pages 153 - 160 , 2009 .", "label": "", "metadata": {}}
{"text": "Whereas theoretical work suggests that deep architectures might be more efficient at representing highly - varying functions , training deep architectures was unsuccessful until the recent advent of algorithms based on unsupervised pre - training .Even though these new algorithms have enabled training deep models , many questions remain as to the nature of this difficult learning problem .Answering these questions is important if learning in deep architectures is to be further improved .We attempt to shed some light on these questions through extensive simulations .The experiments confirm and clarify the advantage of unsupervised pre - training .", "label": "", "metadata": {}}
{"text": "We empirically show the influence of pre - training with respect to architecture depth , model capacity , and number of training examples .D. Grangier , J. Keshet , and S. Bengio .Discriminative keyword spotting .In J. Keshet and S. Bengio , editors , Automatic Speech and Speaker Recognition : Large Margin and Kernel Methods , pages 175 - 194 .Wiley , 2009 .This chapter introduces a discriminative method for detecting and spotting keywords in spoken utterances .Given a word represented as a sequence of phonemes and a spoken utterance , the keyword spotter predicts the best time span of the phoneme sequence in the spoken utterance along with a confidence .", "label": "", "metadata": {}}
{"text": "The problem of keyword spotting training is formulated as a discriminative task where the model parameters are chosen so the utterance in which the keyword is spoken would have higher confidence than any other spoken utterance in which the keyword is not spoken .It is shown theoretically and empirically that the proposed training method resulted with a high area under the Receiver Operating Characteristic ( ROC ) curve , the most common measure to evaluate keyword spotters .We present an iterative algorithm to train the keyword spotter efficiently .The proposed approach contrasts with standard spotting strategies based on Hidden Markov Models ( HMMs ) , for which the training procedure does not maximize a loss directly related to the spotting performance .", "label": "", "metadata": {}}
{"text": "J. Keshet and S. Bengio , editors .Automatic Speech and Speaker Recognition : Large Margin and Kernel Methods .Wiley , 2009 .This is the first book dedicated to uniting research related to speech and speaker recognition based on the recent advances in large margin and kernel methods .The first part of the book presents theoretical and practical foundations of large margin and kernel methods , from Support Vector Machines to large margin methods for structured learning .The second part of the book is dedicated to acoustic modeling of continuous speech recognizers , where the grounds for practical large margin sequence learning are set .", "label": "", "metadata": {}}
{"text": "The last part of the book is dedicated to the application of keyword spotting , speaker verification and spectral clustering .The book is an important reference to researchers and practitioners in the field of modern speech and speaker recognition .The purpose of the book is twofold : first , to set the theoretical foundation of large margin and kernel methods relevant to the speech recognition domain ; second , to propose a practical guide on implementation of these methods to the speech recognition domain .The reader is presumed to have basic knowledge of large margin and kernel methods and of basic algorithms in speech and speaker recognition .", "label": "", "metadata": {}}
{"text": "Discriminative keyword spotting .Speech Communication , 51:317 - 329 , 2009 .[ .This paper proposes a new approach for keyword spotting , which is based on large margin and kernel methods rather than on HMMs .Unlike previous approaches , the proposed method employs a discriminative learning procedure , in which the learning phase aims at achieving a high area under the ROC curve , as this quantity is the most common measure to evaluate keyword spotters .The keyword spotter we devise is based on mapping the input acoustic representation of the speech utterance along with the target keyword into a vector space .", "label": "", "metadata": {}}
{"text": "We describe a simple iterative algorithm for training the keyword spotter and discuss its formal properties , showing theoretically that it attains high area under the ROC curve .Experiments on read speech with the TIMIT corpus show that the resulted discriminative system outperforms the conventional context - independent HMM - based system .Further experiments using the TIMIT trained model , but tested on both read ( HTIMIT , WSJ ) and spontaneous speech ( OGI - Stories ) , show that without further training or adaptation to the new corpus our discriminative system outperforms the conventional context - independent HMM - based system .", "label": "", "metadata": {}}
{"text": "Kernel - based text - independent speaker verification .In J. Keshet and S. Bengio , editors , Automatic Speech and Speaker Recognition : Large Margin and Kernel Methods , pages 195 - 220 .Wiley , 2009 .The goal of a person authentication system is to certify / attest the claimed identity of a user .When this authentication is based on the voice of the user , without respect to what the user exactly said , the system is called a text - independent speaker verification system .Speaker verification systems are increasingly often used to secure personal information , particularly for mobile phone based applications .", "label": "", "metadata": {}}
{"text": "The most common approach to this task is based on Gaussian Mixture Models ( GMMs ) ( Reynolds et al .2000 ) , which do not take into account any temporal information .GMMs have been intensively used thanks to their good performance , especially with the use of the Maximum a posteriori ( MAP ) ( Gauvain and Lee 1994 ) adaptation algorithm .This approach is based on the density estimation of an impostor data distribution , followed by its adaptation to a specific client data set .Note that the estimation of these densities is not the final goal of speaker verification systems , which is rather to discriminate the client and impostor classes ; hence discriminative approaches might appear good candidates for this task as well .", "label": "", "metadata": {}}
{"text": "In order to use SVMs or any other discriminant approaches for speaker verification , several modifications of the classical techniques need to be performed .The purpose of this chapter is to present an overview of discriminant approaches that have been used successfully for the task of text - independent speaker verification , to analyze their differences from and their similarities to each other and to classical generative approaches based on GMMs . J.-F. Paiement , S. Bengio , and D. Eck .Probabilistic models for melodic prediction .Artificial Intelligence Journal , 173(14):1266 - 1274 , 2009 .[ .", "label": "", "metadata": {}}
{"text": "The choice of a particular representation for chords has a strong impact on statistical modeling of the dependence between chord symbols and the actual sequences of notes in polyphonic music .Melodic prediction is used in this paper as a benchmark task to evaluate the quality of four chord representations using two probabilistic model architectures derived from Input / Output Hidden Markov Models ( IOHMMs ) .Likelihoods and conditional and unconditional prediction error rates are used as complementary measures of the quality of each of the proposed chord representations .We observe empirically that different chord representations are optimal depending on the chosen evaluation metric .", "label": "", "metadata": {}}
{"text": "J.-F. Paiement , Y. Grandvalet , and S. Bengio .Predictive models for music .Connection Science , 21(2 & 3):253 - 272 , 2009 .[ .Modeling long - term dependencies in time series has proved very difficult to achieve with traditional machine learning methods .This problem occurs when considering music data .In this paper , we introduce predictive models for melodies .We decompose melodic modeling into two subtasks .We first propose a rhythm model based on the distributions of distances between subsequences .Then , we define a generative model for melodies given chords and rhythms based on modeling sequences of Narmour features .", "label": "", "metadata": {}}
{"text": "Using a similar evaluation procedure , the proposed melodic model consistently outperforms an Input / Output Hidden Markov Model .Furthermore , these models are able to generate realistic melodies given appropriate musical contexts .M. Rehn , R. F. Lyon , S. Bengio , T. C. Walters , and G. Chechik .Sound ranking using auditory sparse - code representations .In ICML 2009 Workshop on Sparse Method for Music Audio , 2009 .[ .The task of ranking sounds from text queries is a good test application for machine - hearing techniques , and particularly for comparison and evaluation of alternative sound representations in a large - scale setting .", "label": "", "metadata": {}}
{"text": "Using this system allows us to focus on comparison of different auditory front ends and different ways of extracting sparse features from high - dimensional auditory images .In addition to two main auditory - image models , we also include and compare a family of more conventional Mel - Frequency Cepstral Coefficients ( MFCC ) front ends .The experimental results show a significant advantage for the auditory models over vector - quantized MFCCs .The two auditory models tested use the adaptive pole - zero filter cascade ( PZFC ) auditory filterbank and sparse - code feature extraction from stabilized auditory images via multiple vector quantizers .", "label": "", "metadata": {}}
{"text": "Using ranking precision - at - top - k performance measures , the best results are about 72 % top-1 precision and 35 % average precision , using a test corpus of thousands of sound files and a query vocabulary of hundreds of words .G. Chechik , E. Ie , M. Rehn , S. Bengio , and D. Lyon .Large - scale content - based audio retrieval from text queries .In ACM International Conference on Multimedia Information Retrieval , MIR , 2008 .[ .In content - based audio retrieval , the goal is to find sound recordings ( audio documents ) based on their acoustic features .", "label": "", "metadata": {}}
{"text": "We handle generic sounds , including a wide variety of sound effects , animal vocalizations and natural scenes .We test a scalable approach based on a passive - aggressive model for image retrieval ( PAMIR ) , and compare it to two state - of - the - art approaches ; Gaussian mixture models ( GMM ) and support vector machines ( SVM ) .We test our approach on two large real - world datasets : a collection of short sound effects , and a noisier and larger collection of user - contributed user - labeled recordings ( 25 K files , 2000 terms vocabulary ) .", "label": "", "metadata": {}}
{"text": "For instance , a positive document is retrieved in the first position of the ranking more than half the time , and on average there are more than 4 positive documents in the first 10 retrieved , for both datasets .PAMIR completed both training and retrieval of all data in less than 6 hours for both datasets , on a single machine .It was one to three orders of magnitude faster than the competing approaches .This approach should therefore scale to much larger datasets in the future . D. Grangier and S. Bengio .A discriminative kernel - based model to rank images from text queries .", "label": "", "metadata": {}}
{"text": "[ .This paper introduces a discriminative model for the retrieval of images from text queries .Our approach formalizes the retrieval task as a ranking problem , and introduces a learning procedure optimizing a criterion related to the ranking performance .The proposed model hence addresses the retrieval problem directly and does not rely on an intermediate image annotation task , which contrasts with previous research .Moreover , our learning procedure builds upon recent work on the online learning of kernel - based classifiers .This yields an efficient , scalable algorithm , which can benefit from recent kernels developed for image comparison .", "label": "", "metadata": {}}
{"text": "Further analysis of the results shows that our model is especially advantageous over difficult queries such as queries with few relevant pictures or multiple - word queries .J.-F. Paiement , Y. Grandvalet , S. Bengio , and D. Eck .A distance model for rhythms .In International Conference on Machine Learning , ICML , 2008 .[ .Modeling long - term dependencies in time series has proved very difficult to achieve with traditional machine learning methods .This problem occurs when considering music data .In this paper , we introduce a model for rhythms based on the distributions of distances between subsequences .", "label": "", "metadata": {}}
{"text": "The proposed model consistently outperforms a standard Hidden Markov Model in terms of conditional prediction accuracy on two different music databases . H. Paugam - Moisy , R. Martinez , and S. Bengio .Delay learning and polychronization for reservoir computing .Neurocomputing , 71(7 - 9):1143 - 1158 , 2008 .[ .We propose a multi - timescale learning rule for spiking neuron networks , in the line of the recently emerging field of reservoir computing .The reservoir is a network model of spiking neurons , with random topology and driven by STDP ( Spike - Time - Dependent Plasticity ) , a temporal Hebbian unsupervised learning mode , biologically observed .", "label": "", "metadata": {}}
{"text": "The network processing and the resulting performance can be explained by the concept of polychronization , proposed by Izhikevich ( 2006 , Neural Computation , 18:2 ) , on physiological grounds .The model emphasizes that polychronization can be used as a tool for exploiting the computational power of synaptic delays and for monitoring the topology and activity of a spiking neuron network .S. Bengio and J. Mari\u00e9thoz .Biometric person authentication is a multiple classifier problem .In M. Haindl , J. Kittler , and F. Roli , editors , 7th International Workshop on Multiple Classifier Systems , MCS , Lecture Notes in Computer Science , volume LNCS 4472 .", "label": "", "metadata": {}}
{"text": "[ .Several papers have already shown the interest of using multiple classifiers in order to enhance the performance of biometric person authentication systems .We explain hereafter this perspective , and according to it , we propose some ways to take advantage of it , ranging from more parameter sharing to similarity learning . D. Grangier and S. Bengio .Learning the inter - frame distance for discriminative template - based keyword detection .In Proceedings of the 10th European Conference on Speech Communication and Technology , Eurospeech - Interspeech , 2007 .[ .This paper proposes a discriminative approach to template - based keyword detection .", "label": "", "metadata": {}}
{"text": "The proposed algorithm estimates the distance from data , with the objective to produce a detector maximizing the Area Under the receiver operating Curve ( AUC ) , i.e. the standard evaluation measure for the keyword detection problem .The experiments performed over a large corpus , SpeechDatII , suggest that our model is effective compared to an HMM system , e.g. the proposed approach reaches 93.8 % of averaged AUC compared to 87.9 % for the HMM .J. Keshet , D. Grangier , and S. Bengio .Discriminative keyword spotting .In ISCA Research Workshop on Non Linear Speech Processing , NOLISP , 2007 .", "label": "", "metadata": {}}
{"text": "This paper proposes a new approach for keyword spotting , which is not based on HMMs .The proposed method employs a new discriminative learning procedure , in which the learning phase aims at maximizing the area under the ROC curve , as this quantity is the most common measure to evaluate keyword spotters .The keyword spotter we devise is based on non - linearly mapping the input acoustic representation of the speech utterance along with the target keyword into an abstract vector space .Building on techniques used for large margin methods for predicting whole sequences , our keyword spotter distills to a classifier in the abstract vector - space which separates speech utterances in which the keyword was uttered from speech utterances in which the keyword was not uttered .", "label": "", "metadata": {}}
{"text": "Experiments with the TIMIT corpus show that our method outperforms the conventional HMM - based approach .J. Mari\u00e9thoz and S. Bengio .A kernel trick for sequences applied to text - independent speaker verification systems .Pattern Recognition , 40:2315 - 2324 , 2007 .[ .This paper present a principled SVM based speaker verification system .We propose a new framework and a new sequence kernel that can make use of any Mercer kernel at the frame level .An extension of the sequence kernel based on the Max operator is also proposed .The new system is compared to state - of - the - art GMM and other SVM based systems found in the literature on the Banca and Polyvar databases .", "label": "", "metadata": {}}
{"text": "Finally , the new proposed framework clarifies previous SVM based systems and suggests interesting future research directions .J.-F. Paiement , Y. Grandvalet , S. Bengio , and D. Eck .A generative model for rhythms .In NIPS Workshop on Brain , Music and Cognition , 2007 .[ .Modeling music involves capturing long - term dependencies in time series , which has proved very difficult to achieve with traditional statistical methods .The same problem occurs when only considering rhythms .In this paper , we introduce a generative model for rhythms based on the distributions of distances between subsequences .", "label": "", "metadata": {}}
{"text": "The proposed model consistently outperforms a standard Hidden Markov Model in terms of conditional prediction accuracy on two different music databases . H. Paugam - Moisy , R. Martinez , and S. Bengio .A supervised learning approach based on STDP and polychronization in spiking neuron networks .In European Symposium on Artificial Neural Networks , ESANN , 2007 .[ .We propose a network model of spiking neurons , without preimposed topology and driven by STDP ( Spike - Time - Dependent Plasticity ) , a temporal Hebbian unsupervised learning mode , biologically observed .The model is further driven by a supervised learning algorithm , based on a margin criterion , that has effect on the synaptic delays linking the network to the output neurons , with classification as a goal task .", "label": "", "metadata": {}}
{"text": "The model emphasizes the computational capabilities of this concept .N. Poh and S. Bengio .Estimating the confidence interval of expected performance curve in biometric authentication using joint bootstrap .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2007 .[ .Evaluating biometric authentication performance is a complex task because the performance depends on the user set size , composition and the choice of samples .We propose to reduce the performance dependency of these three factors by deriving appropriate confidence intervals .In this study , we focus on deriving a confidence region based on the recently proposed Expected Performance Curve ( EPC ) .", "label": "", "metadata": {}}
{"text": "Instead , an EPC selects thresholds based on the training set and applies them on the test set .The proposed technique is useful , for example , to quote realistic upper and lower bounds of the decision cost function used in the NIST annual speaker evaluation .A coverage is the proportion of the unseen EPC covered by the derived confidence interval .N. Poh , A. Martin , and S. Bengio .Performance generalization in biometric authentication using joint user - specific and sample bootstraps .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 29(3):492 - 498 , 2007 .", "label": "", "metadata": {}}
{"text": "Biometric authentication performance is often depicted by a decision error trade - off ( DET ) curve .We show that this curve is dependent on the choice of samples available , the demographic composition and the number of users specific to a database .We propose a two - step bootstrap procedure to take into account of the three mentioned sources of variability .This is an extension to the Bolle 's bootstrap subset technique .Preliminary experiments on the NIST2005 and XM2VTS benchmark databases are encouraging , e.g. , the average result across all 24 systems evaluated on NIST2005 indicates that one can predict , with more than 75 % of DET coverage , an unseen DET curve with 8 times more users .", "label": "", "metadata": {}}
{"text": "S. Renals , S. Bengio , and J. G. Fiscus , editors .Machine Learning for Multimodal Interaction : Third International Workshop , MLMI'2006 .volume 4299 of Lecture Notes in Computer Science .Springer - Verlag , 2007 .[ .This book contains a selection of refereed papers presented at the 3rd Workshop on Machine Learning for Multimodal Interaction ( MLMI 2006 ) , held in Bethesda MD , USA during May 1\u00ad4 , 2006 .In addition to the main workshop , MLMI 2006 was co - located with the 4th NIST Meeting Recognition Workshop .This workshop was centered on the Rich Transcription 2006 Spring Meeting Recognition ( RT-06 ) evaluation of speech technologies within the meeting domain .", "label": "", "metadata": {}}
{"text": "These areas included human\u00adhuman communication modeling , speech and visual processing , multimodal processing , fusion and fission , human\u00adcomputer interaction , and the modeling of discourse and dialog , with an emphasis on the application of machine learning .Out of the submitted full papers , about 50 % were accepted for publication in the present volume , after authors had been invited to take review comments and conference feedback into account .S. Sonnenburg , M. L. Braun , C. Soon Ong , S Bengio , L. Bottou , G. Holmes , Y. LeCun , K.-R. M\u00fcller , F. Pereira , C. E. Rasmussen , G. R\u00e4tsch , B. Sch\u00f6lkopf , A. Smola , P. Vincent , J. Weston , and R. Williamson .", "label": "", "metadata": {}}
{"text": "Journal of Machine Learning Research , JMLR , 8:2443 - 2466 , 2007 .[ .Open source tools have recently reached a level of maturity which makes them suitable for building large - scale real - world systems .At the same time , the field of machine learning has developed a large body of powerful learning algorithms for diverse applications .However , the true potential of these methods is not utilized , since existing implementations are not openly shared , resulting in software with low usability , and weak interoperability .We argue that this situation can be significantly improved by increasing incentives for researchers to publish their software under an open source model .", "label": "", "metadata": {}}
{"text": "We believe that a resource of peer reviewed software accompanied by short articles would be highly valuable to both the machine learning and the general scientific community . D. Zhang and S. Bengio .Exploring contextual information in a layered framework for group action recognition .In IEEE International Conference on Multimedia & Expo , ICME , 2007 .[ .Contextual information is important for sequence modeling .Hidden Markov models ( HMMs ) and extensions , which have been widely used for sequence modeling , make simplifying , often unrealistic assumptions on the conditional independence of observations given the class labels , thus can not accommodate overlapping features or long - term contextual information .", "label": "", "metadata": {}}
{"text": "The first two methods are based on state alpha and gamma posteriors ( as usually referred to in the HMM formalism ) .The third method is based on conditional random fields ( CRFs ) , a conditional model that relaxes the independent assumption on the observations required by HMMs for computational tractability .We illustrate our methods with the application of recognizing group actions in meetings .Experiments and comparison with standard HMM baseline showed the validity of the proposed approach .F. Cardinaux , C. Sanderson , and S. Bengio .User authentication via adapted statistical models of face images .", "label": "", "metadata": {}}
{"text": "[ .It has been previously demonstrated that systems based on local features and relatively complex statistical models , namely 1D Hidden Markov Models ( HMMs ) and pseudo-2D HMMs , are suitable for face recognition .Recently , a simpler statistical model , namely the Gaussian Mixture Model ( GMM ) , was also shown to perform well .In much of the literature devoted to these models , the experiments were performed with controlled images ( manual face localization , controlled lighting , background , pose , etc ) .However , a practical recognition system has to be robust to more challenging conditions .", "label": "", "metadata": {}}
{"text": "We extend the GMM approach through the use of local features with embedded positional information , increasing performance without sacrificing its low complexity .Furthermore , we show that the traditionally used Maximum Likelihood ( ML ) training approach has problems estimating robust model parameters when there is only a few training images available .Considerably more precise models can be obtained through the use of Maximum a Posteriori ( MAP ) training .We also show that face recognition techniques which obtain good performance on manually located faces do not necessarily obtain good performance on automatically located faces , indicating that recognition techniques must be designed from the ground up to handle imperfect localization .", "label": "", "metadata": {}}
{"text": "The best trade - off in terms of authentication time , robustness and discrimination performance is achieved by the extended GMM approach .O. Glickman , I. Dagan , M. Keller , S. Bengio , and W. Daelemans .Investigating lexical substitution scoring for subtitle generation .In Tenth Conference on Computational Natural Language Learning , CONLL , 2006 .[ .This paper investigates an isolated setting of the lexical substitution task of replacing words with their synonyms .In particular , we examine this problem in the setting of subtitle generation and evaluate state of the art scoring methods that predict the validity of a given substitution .", "label": "", "metadata": {}}
{"text": "The major findings suggest that distributional similarity provides a useful complementary estimate for the likelihood that two Wordnet synonyms are indeed substitutable , while proper modeling of contextual constraints is still a challenging task for future research . D. Grangier and S. Bengio .A neural network to retrieve images from text queries .In Proceedings of the 16th International Conference on Artificial Neural Networks : Biological Inspirations , ICANN , Lecture Notes in Computer Science , volume LNCS 4132 .Springer - Verlag , 2006 .[ .This work presents a neural network for the retrieval of images from text queries .", "label": "", "metadata": {}}
{"text": "Both modules are trained jointly to minimize a loss related to the retrieval performance .This approach is shown to be advantageous when compared to previous models relying on unsupervised feature extraction : average precision over Corel queries reaches 26.2 % for our model , which should be compared to 21.6 % for PAMIR , the best alternative . D. Grangier , F. Monay , and S. Bengio .A discriminative approach for the retrieval of images from text queries .In European Conference on Machine Learning , ECML , Lecture Notes in Computer Science , volume LNCS 4212 .", "label": "", "metadata": {}}
{"text": "[ .This work proposes a new approach to the retrieval of images from text queries .Contrasting with previous work , this method relies on a discriminative model : the parameters are selected in order to minimize a loss related to the ranking performance of the model , i.e. its ability to rank the relevant pictures above the non - relevant ones when given a text query .In order to minimize this loss , we introduce an adaptation of the recently proposed Passive - Aggressive algorithm .The generalization performance of this approach is then compared with alternative models over the Corel dataset .", "label": "", "metadata": {}}
{"text": "Learning to retrieve images from text queries with a discriminative model .In International Workshop on Adaptive Multimedia Retrieval , AMR , 2006 .[ .This work presents a discriminative model for the retrieval of pictures from text queries .The core idea of this approach is to minimize a loss directly related to the retrieval performance of the model .For that purpose , we rely on a ranking loss which has recently been successfully applied to text retrieval problems .The experiments performed over the Corel dataset show that our approach compares favorably with generative models that constitute the state - of - the - art ( e.g. our model reaches 21.6 % mean average precision with Blob and SIFT features , compared to 16.7 % for PLSA , the best alternative ) .", "label": "", "metadata": {}}
{"text": "Discriminative kernel - based phoneme sequence recognition .In Proceedings of the International Conference on Spoken Language Processing , Interspeech - ICSLP , 2006 .[ .We describe a new method for phoneme sequence recognition given a speech utterance , which is not based on the HMM .In contrast to HMM - based approaches , our method uses a discriminative kernel - based training procedure in which the learning process is tailored to the goal of minimizing the Levenshtein distance between the predicted phoneme sequence and the correct sequence .The phoneme sequence predictor is devised by mapping the speech utterance along with a proposed phoneme sequence to a vector - space endowed with an inner - product that is realized by a Mercer kernel .", "label": "", "metadata": {}}
{"text": "We describe an iterative algorithm for learning the phoneme sequence recognizer and further describe an efficient implementation of it .We present initial encouraging experimental results with the TIMIT and compare the proposed method to an HMM - based approach . H. Ketabdar , J. Vepa , S. Bengio , and H. Bourlard .Posterior based keyword spotting with a priori thresholds .In Proceedings of the International Conference on Spoken Language Processing , Interspeech - ICSLP , 2006 .[ .In this paper , we propose a new posterior based scoring approach for keyword and non keyword ( garbage ) elements .", "label": "", "metadata": {}}
{"text": "The state posteriors are then integrated into keyword and garbage posteriors for every frame .These posteriors are used to make a decision on detection of the keyword at each frame .The frame level decisions are then accumulated ( in this case , by counting ) to make a global decision on having the keyword in the utterance .In this way , the contribution of possible outliers are minimized , as opposed to the conventional Viterbi decoding approach which accumulates likelihoods .Experiments on keywords from the Conversational Telephone Speech ( CTS ) and Numbers'95 databases are reported .", "label": "", "metadata": {}}
{"text": "Using more informative posterior probabilities for speech recognition .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2006 .[ .In this paper , we present initial investigations towards boosting posterior probability based speech recognition systems by estimating more informative posteriors taking into account acoustic context ( e.g. , the whole utterance ) , as well as possible prior information ( such as phonetic and lexical knowledge ) .These posteriors are estimated based on HMM state posterior probability definition ( typically used in standard HMMs training ) .This approach provides a new , principled , theoretical framework for hierarchical estimation / use of more informative posteriors integrating appropriate context and prior knowledge .", "label": "", "metadata": {}}
{"text": "On the OGI numbers database , this resulted in significant performance improvement , compared to using MLP estimated posteriors for decoding ( hybrid HMM / ANN approach ) for clean and more specially for noisy speech .The system is also shown to be much less sensitive to tuning factors ( such as phone deletion penalty , language model scaling ) compared to the standard HMM / ANN and HMM / GMM systems , thus practically it does not need to be tuned to achieve the best possible performance .M. Liwicki , A. Schlapbach , H. Bunke , S. Bengio , J. Mari\u00e9thoz , and J. Richiardi .", "label": "", "metadata": {}}
{"text": "In H. Bunke and A. L. Spitz , editors , Document Analysis Systems VII : 7th International Workshop , DAS , Lecture Notes in Computer Science , volume LNCS 3872 , pages 186 - 195 .Springer - Verlag , 2006 .[ .In this paper we present a text independent on - line writer identification system based on Gaussian Mixture Models ( GMMs ) .This system has been developed in the context of research on Smart Meeting Rooms .The GMMs in our system are trained using two sets of features extracted from a text line .", "label": "", "metadata": {}}
{"text": "It consists of information gathered for each recorded point of the handwriting , while the second feature set contains features extracted from each stroke .While both feature sets perform very favorably , the stroke - based feature set outperforms the point - based feature set in our experiments .We achieve a writer identification rate of 100 % for writer sets with up to 100 writers .Increasing the number of writers to 200 , the identification rate decreases to 94.75 % .J. Mari\u00e9thoz and S. Bengio .A max kernel for text - independent speaker verification systems .", "label": "", "metadata": {}}
{"text": "[ .In this paper , we present a principled SVM based speaker verification system .A general approach is developed that enables the use of any kernel at the frame level .An extension of his approach using the Max operator is then proposed .The new system is then compared to state - of - the - art GMM and other SVM based systems found in the literature on the Polyvar database .It is found that the new system outperforms , most of the time , the other systems , statistically significantly .J.-F. Paiement , D. Eck , and S. Bengio .", "label": "", "metadata": {}}
{"text": "In L. Lamontagne and M. Marchand , editors , Advances in Artificial Intelligence : 19th Conference of the Canadian Society for Computational Studies of Intelligence , Canadian AI , Lecture Notes in Computer Science , volume LNCS 4013 , pages 218 - 229 .Springer - Verlag , 2006 .[ .We propose a representation for musical chords that allows us to include domain knowledge in probabilistic models .We then introduce a graphical model for harmonization of melodies that considers every structural components in chord notation .We show empirically that root notes progressions exhibit global dependencies that can be better captured with a tree structure related to the meter than with a simple dynamical HMM that concentrates on local dependencies .", "label": "", "metadata": {}}
{"text": "The trained probabilistic models can be sampled to generate very interesting chord progressions given other polyphonic music components such as melody or root note progressions .N. Poh and S. Bengio .Chimeric users to construct fusion classifiers in biometric authentication tasks : An investigation .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2006 .[ .While the privacy problem is indeed solved using chimeric users , it is still an open question of how such chimeric database can be efficiently used .For instance , the following two questions arise : i )", "label": "", "metadata": {}}
{"text": "Based on a considerable amount of empirical biometric person authentication experiments ( 21 real - user data sets and up to 21 \u00d71000 chimeric data sets and two fusion operators ) , our previous study [ Poh and Bengio , MLMI'05 ] answers no to the first question .The current study aims to answer the second question .Considering the possibly expensive cost involved in collecting the real - user multimodal data , our proposed approach is thus useful to construct a trainable fusion classifier while at the same time being able to overcome the problem of small size training data .", "label": "", "metadata": {}}
{"text": "Database , protocol and tools for evaluating score - level fusion algorithms in biometric authentication .Pattern Recognition , 39(2):223 - 233 , 2006 .[ .Fusing the scores of several biometric systems is a very promising approach to improve the overall system 's accuracy .Despite many works in the literature , it is surprising that there is no coordinate d effort in making a benchmark database available .It should be noted that fusion in this context consists not only of multimodal fusion , but also intramodal fusion , i.e. , fusing systems using the same biometric modality but different features , or same features but using different classifiers .", "label": "", "metadata": {}}
{"text": "This paper describes a database of scores taken from experiments carried out on the XM2VTS face and speaker verification database .It then proposes several fusion protocols and provides some state - of - the - art tools to evaluate the fusion performance .N. Poh , S. Bengio , and A. Ross .Revisiting Doddington 's zoo : A systematic method to assess user - dependent variabilities .In Second Workshop on Multimodal User Authentication , MMUA , 2006 .[ .While the privacy problem is indeed solved using chimeric users , it is still an open question of how such chimeric database can be efficiently used .", "label": "", "metadata": {}}
{"text": "Is the performance measured on a chimeric database a good predictor of that measured on a real - user database ? , and , ii ) can a chimeric database be exploited to improve the generalization performance of a fusion operator on a real - user database ?Based on a considerable amount of empirical biometric person authentication experiments ( 21 real - user data sets and up to 21 \u00d71000 chimeric data sets and two fusion operators ) , our previous study [ ? ] answers no to the first question .The current study aims to answer the second question .", "label": "", "metadata": {}}
{"text": "Graph - based invariant manifolds for invariant pattern recognition with kernel methods .In International Conference on Pattern Recognition , ICPR , 2006 .[ .We present here an approach for applying the technique of modeling data transformation manifolds for invariant learning with kernel methods .The approach is based on building a kernel function on the graph modeling the invariant manifold .It provides a way for taking into account nearly arbitrary transformations of the input samples .The approach is verified experimentally on the task of optical character recognition , providing state - of - the - art performance on harder problem settings . A. Pozdnoukhov and S. Bengio .", "label": "", "metadata": {}}
{"text": "Pattern Recognition Letters , 27(10):1087 - 1097 , 2006 .[ .This paper presents a general method for incorporating prior knowledge into kernel methods such as support vector machines .It applies when the prior knowledge can be formalized by the description of an object around each sample of the training set , assuming that all points in the given object share the same desired class .A number of implementation techniques of this method , based on hard geometrical objects and soft objects based on distributions are considered .Tangent vectors are extensively used for object construction .", "label": "", "metadata": {}}
{"text": "The method could establish a foundation for an information retrieval and person identification systems . A. Pozdnoukhov and S. Bengio .Semi - supervised kernel methods for regression estimation .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2006 .[ .The paper presents a semi - supervised kernel method for regression estimation in the presence of unlabeled patterns .The method exploits a recently proposed data - dependent kernel which is constructed in order to represent the inner geometry of the data .This kernel is implemented into Kernel Regression methods ( SVR , KRR ) .", "label": "", "metadata": {}}
{"text": "The influence of the parameters on the model properties was evaluated experimentally .One artificial and two real - world datasets were used to demonstrate the performance of the proposed algorithm .S. Renals and S. Bengio , editors .Machine Learning for Multimodal Interaction : Second International Workshop , MLMI'2005 . volume 3869 of Lecture Notes in Computer Science .Springer - Verlag , 2006 .[ .This book contains a selection of refereed papers presented at the Second Workshop on Machine Learning for Multimodal Interaction ( MLMI 2005 ) , held in Edinburgh , Scotland , during 11 - 13 July 2005 .", "label": "", "metadata": {}}
{"text": "In addition to the main workshop , MLMI 2005 hosted the NIST ( US National Institute of Standards and Technology )Meeting Recognition Workshop .This workshop ( the third such sponsored by NIST ) was centered on the Rich Transcription 2005 Spring Meeting Recognition ( RT-05 ) evaluation of speech technologies within the meeting domain .Building on the success of the RT-04 spring evaluation , the RT-05 evaluation continued the speech - to - text and speaker diarization evaluation tasks and added two new evaluation tasks : speech activity detection and source localization .The motivation for creating such a forum , which could be perceived as a number of papers from different research disciplines , evolved from an actual need that arose from these projects and the strong motivation of their partners for such a multidisciplinary workshop . Y. Rodriguez , F. Cardinaux , S. Bengio , and J. Mari\u00e9thoz .", "label": "", "metadata": {}}
{"text": "Image and Vision Computing , 24(8):882 - 893 , 2006 .[ .The purpose of Face localization is to determine the coordinates of a face in a given image .It is a fundamental research area in computer vision because it serves , as a necessary first step in any face processing system , such as automatic face recognition , face tracking or expression analysis .Most of these techniques assume , in general , that the face region has been perfectly localized .Therefore , their performances depend widely on the accuracy of the face localization process .", "label": "", "metadata": {}}
{"text": "We first show the influence of localization errors on the face verification task and then empirically demonstrate the problems of current localization performance measures when applied to this task .In order to properly evaluate the performance of a face localization algorithm , we then propose to embed the final application ( here face verification ) into the performance measuring process .Using two benchmark databases , BANCA and XM2VTS , we proceed by showing empirically that our proposed method to evaluate localization algorithms better matches the final verification performance .C. Sanderson , S. Bengio , and Y. Gao .", "label": "", "metadata": {}}
{"text": "Pattern Recognition , 39(2):288 - 302 , 2006 .[ .We address the pose mismatch problem which can occur in face verification systems that have only a single ( frontal ) face image available for training .In the framework of a Bayesian classifier based on mixtures of gaussians , the problem is tackled through extending each frontal face model with artificially synthesized models for non - frontal views .The synthesis methods are based on several implementations of Maximum Likelihood Linear Regression ( MLLR ) , as well as standard multi - variate linear regression ( LinReg ) .", "label": "", "metadata": {}}
{"text": "The synthesis and extension approach is evaluated by applying it to two face verification systems : a holistic system ( based on PCA - derived features ) and a local feature system ( based on DCT - derived features ) .The results further suggest that extending frontal models considerably reduces errors . D. Zhang , D. Gatica - Perez , S. Bengio , and I. McCowan .Modeling individual and group actions in meetings with layered HMMs .IEEE Transactions on Multimedia , 8(3):509 - 520 , 2006 .[ .We address the problem of recognizing sequences of human interaction patterns in meetings , with the goal of structuring them in semantic terms .", "label": "", "metadata": {}}
{"text": "By defining a proper set of individual actions , group actions can be modeled as a two - layer process , one that models basic individual activities from low - level audio - visual features , and another one that models the interactions .We propose a two - layer Hidden Markov Model ( HMM ) framework that implements such concept in a principled manner , and that has advantages over previous works .First , by decomposing the problem hierarchically , learning is performed on low - dimensional observation spaces , which results in simpler models .Second , our framework is easier to interpret , as both individual and group actions have a clear meaning , and thus easier to improve .", "label": "", "metadata": {}}
{"text": "Our framework is general and extensible , and we illustrate it with a set of eight group actions , using a public five - hour meeting corpus .Experiments and comparison with a single - layer HMM baseline system show its validity . D. Zhang , D. Gatica - Perez , D. Roy , and S. Bengio .Modeling interactions from email communication .In IEEE International Conference on Multimedia & Expo , ICME , 2006 .[ .Email plays an important role as a medium for the spread of information , ideas , and influence among its users .", "label": "", "metadata": {}}
{"text": "The proposed framework is built on the influence model and the probabilistic latent semantic analysis ( PLSA ) language model .This paper makes two contributions .First , we model interactions between email users using the semantic content of email body , instead of email header .Second , our framework models not only email topic dynamics of individual email users , but also the interactions within a group of individuals .Experiments on the Enron email corpus show some interesting results that are potentially useful to discover the hierarchy of the Enron organization .S. Bengio and H. Bourlard , editors .", "label": "", "metadata": {}}
{"text": "volume 3361 of Lecture Notes in Computer Science .Springer - Verlag , 2005 . [ .This book contains a selection of refereed papers presented at the First Workshop on Machine Learning for Multimodal Interaction ( MLMI'04 ) , held in Martigny , Switzerland , from June 21 - 23 , 2004 .The workshop was organized and sponsored jointly by three European projects , AMI , PASCAL and M4 , as well as a Swiss national research network , IM2 .It brings together researchers from different communities working around the common theme of advanced machine learning algorithms for processing and structuring multimodal human interaction in meetings .", "label": "", "metadata": {}}
{"text": "The conference program covered a wide range of areas related to machine learning applied to multimodal interaction - and more specifically to multi - modal meeting processing .S. Bengio and H. Bourlard .Multi channel sequence processing .In J. Winkler , M. Niranjan , and N. Lawrence , editors , Deterministic and Statistical Methods in Machine Learning : First International Workshop , Lecture Notes in Artificial Intelligence , volume LNAI 3635 , pages 22 - 36 .Springer - Verlag , 2005 . [ .This paper summarizes some of the current research challenges arising from multi - channel sequence processing .", "label": "", "metadata": {}}
{"text": "Some of these problems can already be tackled by one of the many statistical approaches towards sequence modeling .However , several challenging research issues are still open , such as taking into account asynchrony and correlation between several feature streams , or handling the underlying growing complexity .In this framework , we discuss here two novel approaches , which recently started to be investigated with success in the context of large multimodal problems .These include the asynchronous HMM , providing a principled approach towards the processing of multiple feature streams , and the layered HMM approach , providing a good formalism for decomposing large and complex ( multi - stream ) problems into layered architectures .", "label": "", "metadata": {}}
{"text": "S. Bengio , J. Mari\u00e9thoz , and M. Keller .The expected performance curve .In International Conference on Machine Learning , ICML , Workshop on ROC Analysis in Machine Learning , 2005 . [ .In several research domains concerned with classification tasks , curves like ROC are often used to assess the quality of a particular model or to compare two or more models with respect to various operating points .Researchers also often publish some statistics coming from the ROC , such as the so - called break - even point or equal error rate .The purpose of this paper is to first argue that these measures can be misleading in a machine learning context and should be used with care .", "label": "", "metadata": {}}
{"text": "Furthermore , we show how to use adequately a non - parametric statistical test in order to produce EPCs with confidence intervals or assess the statistical significant difference between two models under various settings .C. Dimitrakakis and S. Bengio .Boosting word error rates .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , pages 501 - 504 , 2005 .[ .We apply boosting techniques to the problem of word error rate minimisation in speech recognition .This is achieved through a new definition of sample error for boosting and a training procedure for hidden Markov models .", "label": "", "metadata": {}}
{"text": "Furthermore , for each sentence example we define a probability distribution in time that represents our belief that an error has been made at that particular frame .This is used to weigh the frames of each sentence in the boosting framework .We present preliminary results on the well - known Numbers 95 database that indicate the importance of this temporal probability distribution .C. Dimitrakakis and S. Bengio .Gradient - based estimates of return distributions .In PASCAL Workshop on Principled Methods of Trading Exploration and Exploitation , 2005 .[ .We present a general method for maintaining estimates of the distribution of parameters in arbitrary models .", "label": "", "metadata": {}}
{"text": "While this approach is similar to other techniques that maintain a confidence measure for action - values , it nevertheless offers an insight into current techniques and hints at potential avenues of further research .C. Dimitrakakis and S. Bengio .Online adaptive policies for ensemble classifiers .Neurocomputing , 64:211 - 221 , 2005 .[ .Ensemble algorithms can improve the performance of a given learning algorithm through the combination of multiple base classifiers into an ensemble .In this paper we attempt to train and combine the base classifiers using an adaptive policy .This policy is learnt through a Q - learning inspired technique .", "label": "", "metadata": {}}
{"text": "Extracting information from multimedia meeting collections .In 7th ACM SIGMM International Workshop on Multimedia Information Retrieval , MIR , 2005 . [ .In this paper , we present a succint overview of recent approaches in this field , largely influenced by our own experiences .We first review some of the existing and potential needs for users of multimedia meeting information systems .We then summarize recent work on various research areas addressing some of these requirements .In more detail , we describe our work on automatic analysis of human interaction patterns from audio - visual sensors , discussing open issues in this domain . D. Gatica - Perez , I. McCowan D. Zhang , and S. Bengio .", "label": "", "metadata": {}}
{"text": "In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , pages 489 - 492 , 2005 .[ .Finding relevant segments in meeting recordings is important for summarization , browsing , and retrieval purposes .In this paper , we define relevance as the interest - level that meeting participants manifest as a group during the course of their interaction ( as perceived by an external observer ) , and investigate the automatic detection of segments of high - interest from audio - visual cues .This is motivated by the assumption that there is a relationship between segments of interest to participants , and those of interest to the end user , e.g. of a meeting browser .", "label": "", "metadata": {}}
{"text": "On a 50-meeting corpus , recorded in a room equipped with multiple cameras and microphones , we found that the annotations generated by multiple people exhibit a good degree of consistency , providing a stable ground - truth for automatic methods .For the automatic detection of high - interest segments , we investigate a methodology based on Hidden Markov Models ( HMMs ) and a number of audio and visual features .Single- and multi - stream approaches were studied .Using precision and recall as performance measures , the results suggest that ( i ) the automatic detection of group interest - level is promising , and ( ii ) while audio in general constitutes the predominant modality in meetings , the use of a multi - modal approach is beneficial .", "label": "", "metadata": {}}
{"text": "Machine learning for automatic environmental mapping : when and how ?In G. Dubois , editor , Automatic mapping algorithms for routine and emergency monitoring data .Report on the Spatial Interpolation Comparison ( SIC2004 ) exercise , pages 123 - 138 .Office for Official Publications of the European Communities , Luxembourg , 2005 . [ .This paper discusses the opportunity of using Machine Learning techniques in an automatic environmental mapping context , as was the case for the SIC2004 exercise .First , the Machine Learning methodology is quickly described and compared to Geostatistics .From there , some clues about when to apply Machine Learning are proposed , and what outcomes can be expected from this choice .", "label": "", "metadata": {}}
{"text": "This illustrates some potential drawbacks of SVR and MLP for applications such as SIC2004 . Y. Grandvalet , J. Mari\u00e9thoz , and S. Bengio .A probabilistic interpretation of SVMs with an application to unbalanced classification .In Advances in Neural Information Processing Systems , NIPS 18 .MIT Press , 2005 . [ .In this paper , we show that the hinge loss can be interpreted as the neg - log - likelihood of a semi - parametric model of posterior probabilities .From this point of view , SVMs represent the parametric component of a semi - parametric model fitted by a maximum a posteriori estimation procedure .", "label": "", "metadata": {}}
{"text": "Unlike previous proposals , the suggested mapping is interval - valued , providing a set of posterior probabilities compatible with each SVM score .This framework offers a new way to adapt the SVM optimization problem when decisions result in unequal losses .Experiments on an unbalanced classification loss show improvements over state - of - the - art procedures . D. Grangier and S. Bengio .Exploiting hyperlinks to learn a retrieval model .In Proceedings of the NIPS 2005Workshop on Learning to Rank , 2005 . [ .Information Retrieval ( IR ) aims at solving a ranking problem : given a query q and a corpus C , the documents of C should be ranked such that the documents relevant to q appear above the others .", "label": "", "metadata": {}}
{"text": "However , such data are especially expensive to label , thus , as an alternative , we propose to rely on hyperlink data which convey analogous semantic relationships .We then empirically show that a measure sim inferred from hyperlinked documents can actually outperform the state - of - the - art Okapi approach , when applied over a non - hyperlinked retrieval corpus . D. Grangier and S. Bengio .Inferring document similarity from hyperlinks .In Proceedings of the Conference on Information and Knowledge Management , CIKM , 2005 . [ .Assessing semantic similarity between text documents is a crucial aspect in Information Retrieval systems .", "label": "", "metadata": {}}
{"text": "Two sets of experiments on different corpora show that this function compares favorably with OKAPI matching on document retrieval tasks .M. Keller and S. Bengio .A neural network for text representation .In Proceedings of the 15th International Conference on Artificial Neural Networks : Biological Inspirations , ICANN , Lecture Notes in Computer Science , volume LNCS 3697 , pages 667 - 672 .Springer - Verlag , 2005 . [ .Text categorization and retrieval tasks are often based on a good representation of textual data .Departing from the classical vector space model , several probabilistic models have been proposed recently , such as PLSA .", "label": "", "metadata": {}}
{"text": "Experiments performed on two information retrieval tasks using the TDT2 database and the TREC-8 and 9 sets of queries yielded a better performance for the proposed neural network model , as compared to PLSA and the classical TFIDF representations .M. Keller , S. Bengio , and S. Y. Wong .Benchmarking non - parametric statistical tests .In Advances in Neural Information Processing Systems , NIPS 18 .MIT Press , 2005 . [ .Although non - parametric tests have already been proposed for that purpose , statistical significance tests for non - standard measures ( different from the classification error ) are less often used in the literature .", "label": "", "metadata": {}}
{"text": "More precisely , using a very large dataset to estimate the whole \" population \" , we analyzed the behavior of several statistical test , varying the class unbalance , the compared models , the performance measure , and the sample size .The main result is that providing big enough evaluation sets non - parametric tests are relatively reliable in all conditions . H. Ketabdar , H. Bourlard , and S. Bengio .Hierarchical multi - stream posterior based speech recognition system .In Machine Learning for Multimodal Interactions : Second International Workshop , MLMI , Lecture Notes in Computer Science , volume LNCS 3869 , 2005 . [ .", "label": "", "metadata": {}}
{"text": "This approach provides a new , principled , theoretical framework for hierarchical estimation / use of posteriors , multi - stream feature combination , and integrating appropriate context and prior knowledge in posterior estimates .In the present work , we used the resulting gamma posteriors as features for a standard HMM / GMM layer .On the OGI Digits database and on a reduced vocabulary version ( 1000 words ) of the DARPA Conversational Telephone Speech - to - text ( CTS ) task , this resulted in significant performance improvement , compared to the state - of - the - art Tandem systems . H. Ketabdar , J. Vepa , S. Bengio , and H. Bourlard .", "label": "", "metadata": {}}
{"text": "In Proceedings of the 9th European Conference on Speech Communication and Technology , Eurospeech - Interspeech , 2005 . [ .Local state or phone posterior probabilities are often investigated as local scores ( e.g. , hybrid HMM / ANN systems ) or as transformed acoustic features ( e.g. , \" Tandem \" ) to improve speech recogni tion systems .In this paper , we present initial results towards boosting these approaches by improving posterior estimat es , using acoustic context ( e.g. , as available in the whole utterance ) , as well as possible prior information ( such as topological constraints ) .", "label": "", "metadata": {}}
{"text": "In the present work , we used the resulting posteriors as local scores in a Viter bi decoder .On the OGI Numbers'95 database , this resulted in improved recognition performance , compared to a state - of - the - art hybrid HMM / ANN system .J. Mari\u00e9thoz and S. Bengio .A unified framework for score normalization techniques applied to text independent speaker verification .IEEE Signal Processing Letters , 12(7):532 - 535 , 2005 . [ .The purpose of this paper is to unify several of the state - of - the - art score normalization techniques applied to text - independent speaker verification systems .", "label": "", "metadata": {}}
{"text": "The two well - known Z- and T - normalization techniques can be easily interpreted in this framework as different ways to estimate score distributions .This is useful as it helps to understand the various assumptions behind these well - known score normalization techniques , and opens the door for yet more complex solutions .Finally , some experiments on the Switchboard database are performed in order to illustrate the validity of the new proposed framework .I. McCowan , D. Gatica - Perez , S. Bengio , G. Lathoud , M. Barnard , and D. Zhang .Automatic analysis of multimodal group actions in meetings .", "label": "", "metadata": {}}
{"text": "This paper investigates the recognition of group actions in meetings .A statistical framework is proposed in which group actions result from the interactions of the individual participants .The group actions are modelled using different HMM - based approaches , where the observations are provided by a set of audio - visual features monitoring the actions of individuals .Experiments demonstrate the importance of taking interactions into account in modelling the group actions .It is also shown that the visual modality contains useful information , even for predominantly audio - based events , motivating a multimodal approach to meeting analysis .", "label": "", "metadata": {}}
{"text": "A probabilistic model for chord progressions .In International Conference on Music Information Retrieval , ISMIR , 2005 .[ .Chord progressions are the building blocks from which tonal music is constructed .Inferring chord progressions is thus an essential step towards modeling long term dependencies in music .In this paper , a distributed representation for chords is designed such that Euclidean distances roughly correspond to psychoacoustic dissimilarities .Estimated probabilities of chord substitutions are derived from this representation and are used to introduce smoothing in graphical models observing chord progressions .Parameters in the graphical models are learnt with the EM algorithm and the classical Junction Tree algorithm is used for inference .", "label": "", "metadata": {}}
{"text": "Both perceptual and statistical evidence show that binary trees related to meter are well suited to capture chord dependencies .J.-F. Paiement , D. Eck , S. Bengio , and D. Barber .A graphical model for chord progressions embedded in a psychoacoustic space .In International Conference on Machine Learning , ICML , 2005 .[ .Chord progressions are the building blocks from which tonal music is constructed .Inferring chord progressions is thus an essential step towards modeling long term dependencies in music .In this paper , a distributed representation for chords is designed such that Euclidean distances roughly correspond to psychoacoustic dissimilarities .", "label": "", "metadata": {}}
{"text": "Various model architectures are compared in terms of conditional out - of - sample likelihood .Both perceptual and statistical evidence show that binary trees related to meter are well suited to capture chord dependencies .N. Poh and S. Bengio .Can chimeric persons be used in multimodal biometric authentication experiments ?In S. Renals and S. Bengio , editors , Machine Learning for Multimodal Interactions : Second International Workshop , MLMI , volume LNCS 3869 .Springer - Verlag , 2005 .[ .Combining multiple information sources , typically from several data streams is a very promising approach , both in experiments and to some extents in various real - life applications .", "label": "", "metadata": {}}
{"text": "Due to lack of large true multimodal biometric datasets , the biometric trait of a user from a database is often combined with another different biometric trait of yet another user , thus creating a so - called a chimeric user .In the literature , this practice is justified based on the fact that the underlying biometric traits to be combined are assumed to be independent of each other given the user .To the best of our knowledge , there is no literature that approves or disapproves such practice .The experimental results suggest that for a large proportion of the experiments , such practice is indeed questionable .", "label": "", "metadata": {}}
{"text": "EER of fixed and trainable fusion classifiers : A theoretical study with application to biometric authentication tasks .In N. C. Oza , R. Polikar , and J. Kittler , editors , 6th International Workshop on Multiple Classifier Systems , MCS , Lecture Notes in Computer Science , volume LNCS 3541 , pages 74 - 85 .Springer - Verlag , 2005 .[ .Biometric authentication is a process of verifying an identity claim using a person 's behavioural and physiological characteristics .Due to the vulnerability of the system to environmental noise and variation caused by the user , fusion of several biometric - enabled systems is identified as a promising solution .", "label": "", "metadata": {}}
{"text": "How exactly do correlation and imbalance nature of base - system performance affect the fixed rules and trainable classifiers ?We study these joint aspects using the commonly used error measurement in biometric authentication , namely Equal Error Rate ( EER ) .Similar to several previous studies in the literature , the central assumption used here is that the class - dependent scores of a biometric system are approximately normally distributed .However , different from them , the novelty of this study is to make a direct link between the EER measure and the fusion schemes mentioned .", "label": "", "metadata": {}}
{"text": "In particular , it is found that weighted sum can provide the best generalisation performance when its weights are estimated correctly .It also has the additional advantage that score normalisation prior to fusion is not needed , contrary to the rest of fixed fusion rules .N. Poh and S. Bengio .F - ratio client - dependent normalisation for biometric authentication tasks .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , pages 721 - 724 , 2005 . [ .This study investigates a new client - dependent normalisation to improve biometric authentication systems .", "label": "", "metadata": {}}
{"text": "Such normalisation is intended to adjust the variation across different client models .We propose \" F - ratio \" normalisation , or F - Norm , applied to face and speaker authentication systems .This normalisation requires only that as few as two client - dependent accesses are available ( the more the better ) .Different from previous normalisation techniques , F - Norm considers the client and impostor distributions simultaneously .We show that F - ratio is a natural choice because it is directly associated to Equal Error Rate .It has the effect of centering the client and impostor distributions such that a global threshold can be easily found .", "label": "", "metadata": {}}
{"text": "This parameter can be optimised to maximise the class dispersion ( the degree of separability between client and impostor distributions ) while the aforementioned normalisation techniques can not .The results of 13 unimodal experiments carried out on the XM2VTS multimodal database show that such normalisation is advantageous over Z - Norm , client - dependent threshold normalisation or no normalisation .N. Poh and S. Bengio .How do correlation and variance of base classifiers affect fusion in biometric authentication tasks ?IEEE Transactions on Signal Processing , 53(11):4384 - 4396 , 2005 .[ .Combining multiple information sources such as subbands , streams ( with different features ) and multi modal data has been shown to be a very promising trend , both in experiments and to some extents in real - life biometric authentication applications .", "label": "", "metadata": {}}
{"text": "Often , scores are assumed to be independent .In this paper , we explicitly consider this factor using a theoretical model , called Variance Reduction - Equal Error Rate ( VR - EER ) analysis .To achieve lower EER , smaller correlation and average variance of base - experts , and larger mean difference are desirable .Furthermore , analysing any of these factors independently , e.g. focusing on correlation alone , could be miss - leading .Experimental results on the BANCA multimodal database confirm our findings using VR - EER analysis .We analysed four commonly encountered scenarios in biometric authentication which include fusing correlated / uncorrelated base - experts of similar / different performances .", "label": "", "metadata": {}}
{"text": "One of the most important findings is that positive correlation \" hurts \" fusion while negative correlation ( greater \" diversity \" , which measures the spread of prediction score with respect to the fused score ) , improves fusion .However , by linking the concept of ambiguity decomposition to classification problem , it is found that diversity is not sufficient to be an evaluation criterion ( to compare several fusion systems ) , unless measures are taken to normalise the ( class - dependent ) variance .N. Poh and S. Bengio .Improving fusion with margin - derived confidence in biometric authentication tasks .", "label": "", "metadata": {}}
{"text": "Springer - Verlag , 2005 . [ .This study investigates a new confidence criterion to improve fusion via a linear combination of scores of several biometric authentication systems .This confidence is based on the margin of making a decision , which answers the question , \" after observing the score of a given system , what is the confidence ( or risk ) associated to that given access ? \"In the context of multimodal and intramodal fusion , such information proves valuable because the margin information can determine which of the systems should be given higher weights .", "label": "", "metadata": {}}
{"text": "The results of 32 fusion experiments carried out on the XM2VTS multimodal database show that fusion using margin ( product of margin and expert opinion ) is superior over fusion without the margin information ( i.e. , the original expert opinion ) .Furthermore , combining both sources of information increases fusion performance further .N. Poh and S. Bengio .A novel approach to combining client - dependent and confidence information in multimodal biometrics .In T. Kanade , A. Jain , and N. K. Ratha , editors , 5th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 3546 , pages 1120 - 1129 .", "label": "", "metadata": {}}
{"text": "The issues of fusion with client - dependent and confidence information have been well studied separately in biometric authentication .In this study , we propose to take advantage of both sources of information in a discriminative framework .Initially , each source of information is processed on a per expert basis ( plus on a per client basis for the first information and on a per example basis for the second information ) .Then , both sources of information are combined using a second - level classifier , across different experts .Although the formulation of such two - step solution is not new , the novelty lies in the way the sources of prior knowledge are incorporated prior to fusion using the second - level classifier .", "label": "", "metadata": {}}
{"text": "Our framework that we call \" Prior Knowledge Incorporation \" has the advantage of using the standard machine learning algorithms .N. Poh and S. Bengio .A score - level fusion benchmark database for biometric authentication .In T. Kanade , A. Jain , and N. K. Ratha , editors , 5th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 3546 , pages 474 - 483 .Springer - Verlag , 2005 .[ .Fusing the scores of several biometric systems is a very promising approach to improve the overall system 's accuracy .", "label": "", "metadata": {}}
{"text": "It should be noted that fusion in this context consists not only of multimodal fusion , but also intramodal fusion , i.e. , fusing systems using the same biometric modality but different features , or same features but using different classifiers .Building baseline systems from scratch often prevents researchers from putting more efforts in understanding the fusion problem .This paper describes a database of scores taken from experiments carried out on the XM2VTS face and speaker verification database .It then proposes several fusion protocols and provides some state - of - the - art tools to evaluate the fusion performance .", "label": "", "metadata": {}}
{"text": "Kernel matching pursuit for large datasets .Pattern Recognition , 38(12):2385 - 2390 , 2005 .[ .Kernel Matching Pursuit is a greedy algorithm for building an approximation of a discriminant function as a linear combination of some basis functions selected from a kernel - induced dictionary .Here we propose a modification of the Kernel Matching Pursuit algorithm that aim s at making the method practical for large datasets .Starting from an approximating algorithm , the Weak Greedy Algorithm , we introduce a stochastic method for reducing the search space at each iteration .Then we study the implications of using an approximate algorithm and we show how one can control the trade - off between the accuracy and the need for resources .", "label": "", "metadata": {}}
{"text": "Improving kernel classifiers for object categorization problems .In International Conference on Machine Learning , ICML , Workshop on Learning with Partially Classified Training Data , 2005 . [ .This paper presents an approach for improving the performance of kernel classifiers applied to object categorization problems .The approach is based on the use of distributions centered around each training points , which are exploited for inter - class invariant image representation with local invariant features .Furthermore , we propose an extensive use of unlabeled images for improving the SVM - based classifier .C. Sanderson , F. Cardinaux , and S. Bengio .", "label": "", "metadata": {}}
{"text": "In IEEE International Conference on Information Technology and Applications , ICITA , pages 638 - 643 , 2005 . [ .In much of the literature devoted to face recognition , experiments are performed with controlled images ( e.g. manual face localization , controlled lighting , background and pose ) .However , a practical recognition system has to be robust to more challenging conditions .In this paper we first evaluate , on the relatively difficult BANCA database , the discrimination accuracy , robustness and complexity of Gaussian Mixture Model ( GMM ) , 1D- and pseudo-2D Hidden Markov Model ( HMM ) based systems , using both manual and automatic face localization .", "label": "", "metadata": {}}
{"text": "Experiments show that good accuracy on manually located faces is not necessarily indicative of good accuracy on automatically located faces ( which are imperfectly located ) .The deciding factor is shown to be the degree of constraints placed on spatial relations between face parts .Methods which utilize rigid constraints have poor robustness compared to methods which have relaxed constraints .Furthermore , we show that while the pseudo-2D HMM approach has the best overall accuracy , classification time on current hardware makes it impractical .The best trade - off in terms of complexity , robustness and discrimination accuracy is achieved by the extended GMM approach . D. Zhang , D. Gatica - Perez , S. Bengio , and I. McCowan .", "label": "", "metadata": {}}
{"text": "In IEEE Conference on Computer Vision and Pattern Recognition , CVPR , 2005 .[ .We address the problem of temporal unusual event detection .Unusual events are characterized by a number of features ( rarity , unexpectedness , and relevance ) that limit the application of traditional supervised model - based approaches .We propose a semi - supervised adapted Hidden Markov Model ( HMM ) framework , in which usual event models are first learned from a large amount of ( commonly available ) training data , while unusual event models are learned by Bayesian adaptation in an unsupervised manner .", "label": "", "metadata": {}}
{"text": "We show that such a framework can address problems due to the scarcity of training data and the difficulty in pre - defining unusual events .Experiments on audio , visual , and audio - visual data streams illustrate its effectiveness , compared with both supervised and unsupervised baseline methods . D. Zhang , D. Gatica - Perez , S. Bengio , and I. McCowan .Semi - supervised meeting event recognition with adapted HMMs .In IEEE International Conference on Multimedia Expo , ICME , pages 611 - 618 , 2005 . [ .This paper investigates the use of unlabeled data to help labeled data for audio - visual event recognition in meetings .", "label": "", "metadata": {}}
{"text": "Instead of directly training one model for each event , we first train a well - estimated general event model for all events using both labeled and unlabeled data , and then adapt the general model to each specific event model using its own labeled data .We illustrate the proposed approach with a set of eight audio - visual events defined in meetings .Experiments and comparison with the fully - supervised baseline method show the validity of the proposed semi - supervised approach . D. Zhang , D. Gatica - Perez , S. Bengio , and D. Roy .", "label": "", "metadata": {}}
{"text": "In Advances in Neural Information Processing Systems , NIPS 18 .MIT Press , 2005 .[ .We present a model that learns the influence of interacting Markov chains within a team .The proposed model is a dynamic Bayesian network ( DBN ) with a two - level structure : individual - level and group - level .Individual level models actions of each player , and the group - level models actions of the team as a whole .Experiments on synthetic multi - player games and a multi - party meeting corpus show the effectiveness of the proposed model .", "label": "", "metadata": {}}
{"text": "Multimodal speech processing using asynchronous hidden markov models .Information Fusion , 5(2):81 - 89 , 2004 .[ .This paper advocates that for some multimodal tasks involving more than one stream of data representing the same sequence of events , it might sometimes be a good idea to be able to desynchronize the streams in order to maximize their joint likelihood .We thus present a novel Hidden Markov Model architecture to model the joint probability of pairs of asynchronous sequences describing the same sequence of events .An Expectation - Maximization algorithm to train the model is presented , as well as a Viterbi decoding algorithm , which can be used to obtain the optimal state sequence as well as the alignment between the two sequences .", "label": "", "metadata": {}}
{"text": "Robust performances under various noise conditions were obtained in both cases . S. Bengio and J. Mari\u00e9thoz .The expected performance curve : a new assessment measure for person authentication .In Proceedings of Odyssey 2004 : The Speaker and Language Recognition Workshop , 2004 .[ .ROC and DET curves are often used in the field of person authentication to assess the quality of a model or even to compare several models .We argue in this paper that this measure can be misleading as it compares performance measures that can not be reached simultaneously by all systems .", "label": "", "metadata": {}}
{"text": "These curves enable the comparison between several systems according to a criterion , decided by the application , which is used to set thresholds according to a separate validation set .A free sofware is available to compute these curves .A real case study is used throughout the paper to illustrate it .Finally , note that while this study was done on an authentication problem , it also applies to most 2-class classification tasks .S. Bengio and J. Mari\u00e9thoz .A statistical significance test for person authentication .In Proceedings of Odyssey 2004 : The Speaker and Language Recognition Workshop , 2004 .", "label": "", "metadata": {}}
{"text": "Assessing whether two models are statistically significantly different from each other is a very important step in research , although it has unfortunately not received enough attention in the field of person authentication .We show in this paper how to adapt one of these tests in order to compute a confidence interval around one HTER measure or to assess the statistical significantness of the difference between two HTER measures .We also compare our technique with other solutions that are sometimes used in the literature and show why they yield often too optimistic results ( resulting in false statements about statistical significantness ) . H. Bourlard , S. Bengio , M. Magimai Doss , Q. Zhu , B. Mesot , and N. Morgan .", "label": "", "metadata": {}}
{"text": "In Proceedings of the DARPA EARS ( Effective , Affordable , Reusable , Speech - to - text ) Rich Transcription ( RT'04 )Workshop , 2004 .[ .Local state ( or phone ) posterior probabilities are often investigated as local classifiers ( e.g. , hybrid HMM / ANN systems ) or as transformed acoustic features ( e.g. , \" Tandem \" ) towards improved speech recognition systems .Initial results on several speech ( as well as other multimodal ) tasks resulted in significant improvements .In this paper , we present recognition results on Numbers'95 and on a reduced vocabulary version ( 1000 words ) of the DARPA Conversational Telephone Speech - to - text ( CTS ) task .", "label": "", "metadata": {}}
{"text": "Face verification using adapted generative models .In International Conference on Automatic Face and Gesture Recognition , FG , pages 825 - 830 , 2004 .[ .It has been shown previously that systems based on local features and relatively complex generative models , namely 1D Hidden Markov Models ( HMMs ) and pseudo-2D HMMs , are suitable for face recognition ( here we mean both identification and verification ) .Recently a simpler generative model , namely the Gaussian Mixture Model ( GMM ) , was also shown to perform well .In this paper we first propose to increase the performance of the GMM approach ( without sacrificing its simplicity ) through the use of local features with embedded positional information ; we show that the performance obtained is comparable to 1D HMMs .", "label": "", "metadata": {}}
{"text": "S. Chiappa and S. Bengio .HMM and IOHMM modeling of EEG rhythms for asynchronous BCI systems .In European Symposium on Artificial Neural Networks , ESANN , 2004 .[ .We compare the use of two Markovian models , HMMs and IOHMMs , to discriminate between three mental tasks for brain computer interface systems using an asynchronous protocol .We show that IOHMMs outperform HMMs but that , probably due to the lack of any prior information on the state dynamics , no practical advantage in the use of these models over their static counterparts is obtained .", "label": "", "metadata": {}}
{"text": "A gentle hessian for efficient gradient descent .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 5 , pages 517 - 520 , 2004 .[ .Several second - order optimization methods for gradient descent algorithms have been proposed over the years , but they usually need to compute the inverse of the Hessian of the cost function ( or an approximation of this inverse ) during training .In most cases , this leads to an O ( n 2 ) cost in time and space per iteration , where n is the number of parameters , which is prohibitive for large n .", "label": "", "metadata": {}}
{"text": "Based on a second order analysis , we show that a block - diagonal Hessian yields an easier optimization problem than a full Hessian .We also show that the condition of block - diagonality in common machine learning models can be achieved by simply selecting an appropriate training criterion .Finally , we propose a version of the SVM criterion applied to MLPs , which verifies the aspects highlighted in this second order analysis , but also yields very good generalization performance in practice , taking advantage of the margin effect .Several empirical comparisons on two benchmark datasets are given to illustrate this approach .", "label": "", "metadata": {}}
{"text": "Links between perceptrons , MLPs and SVMs .In International Conference on Machine Learning , ICML , 2004 .[ .We propose to study links between three important classification algorithms : Perceptrons , Multi - Layer Perceptrons ( MLPs ) and Support Vector Machines ( SVMs ) .We first study ways to control the capacity of Perceptrons ( mainly regularization parameters and early stopping ) , using the margin idea introduced with SVMs .After showing that under simple conditions a Perceptron is equivalent to an SVM , we show it can be computationally expensive in time to train an SVM ( and thus a Perceptron ) with stochastic gradient descent , mainly because of the margin maximization term in the cost function .", "label": "", "metadata": {}}
{"text": "These ideas are extended afterward to the case of MLPs .Moreover , under some assumptions it also appears that MLPs are a kind of mixture of SVMs , maximizing the margin in the hidden layer space .Finally , we present a very simple MLP based on the previous findings , which yields better performances in generalization and speed than the other models . F. de Wet , K. Weber , L. Boves , B. Cranen , S. Bengio , and H. Bourlard .Evaluation of formant - like features for automatic speech recognition .Journal of the Acoustical Society of America ( JASA ) , 116(3):1781 - 1792 , 2004 .", "label": "", "metadata": {}}
{"text": "This study investigates possibilities to find a low - dimensional , formant - related physical representation of speech signals , which is suitable for automatic speech recognition .This aim is motivated by the fact that formants are known to be discriminant features for speech recognition .Combinations of automatically extracted formant - like features and state - of - the - art , noise - robust features have previously been shown to be more robust in adverse conditions than state - of - the - art features alone .However , it is not clear how these automatically extracted formant - like features behave in comparison with true formants .", "label": "", "metadata": {}}
{"text": "The speech data and hand - labeled formants that were used in this study are a subset of the American English vowels database presented in [ Hillenbrand et al ., J. Acoust .Soc .Am .97 , 3099 - 3111 ( 1995)].Classification performance was measured on the original , clean data as well as in ( simulated ) adverse conditions .In combination with standard automatic speech recognition methods , the classification performance of the robust formant and HMM2 features compare very well to the performance of the hand - labeled formants .", "label": "", "metadata": {}}
{"text": "Boosting HMMs with an application to speech recognition .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 5 , pages 621 - 624 , 2004 .[ .Boosting is a general method for training an ensemble of classifiers with a view to improving performance relative to that of a single classifier .While the original AdaBoost algorithm has been defined for classification tasks , the current work examines its applicability to sequence learning problems .In particular , different methods for training HMMs on sequences and for combining their output are investigated in the context of automatic speech recognition .", "label": "", "metadata": {}}
{"text": "Online policy adaptation for ensemble classifiers .In European Symposium on Artificial Neural Networks , ESANN , 2004 .[ .Ensemble algorithms can improve the performance of a given learning algorithm through the combination of multiple base classifiers into an ensemble .In this paper , the idea of using an adaptive policy for training and combining the base classifiers is put forward .The effectiveness of this approach for online learning is demonstrated by experimental results on several UCI benchmark databases .M. Magimai Doss , S. Bengio , and H. Bourlard .Joint decoding for phoneme - grapheme continuous speech recognition .", "label": "", "metadata": {}}
{"text": "[ .Standard ASR systems typically use phoneme as the subword units .Preliminary studies have shown that the performance of the ASR system could be improved by using grapheme as additional subword units .In this paper , we investigate such a system where the word models are defined in terms of two different subword units , i.e. , phoneme and grapheme .During training , models for both the subword units are trained , and then during recognition either both or just one subword unit is used .We have studied this system for a continuous speech recognition task in American English language .", "label": "", "metadata": {}}
{"text": "M. Keller and S. Bengio .Theme topic mixture model : A graphical model for document representation .In PASCAL Workshop on Learning Methods for Text Understanding and Mining , 2004 .[ .Automatic Text Processing tasks , documents are usually represented in the bag - of - word space .However , this representation does not take into account the possible relations between words .We propose here a review of a family of document density estimation models for representing documents .Inside this family we derive another possible model : the Theme Topic Mixture Model ( TTMM ) .", "label": "", "metadata": {}}
{"text": "Topics link words to each other and Themes gather documents with particular distribution over the topics .An experiment reports the performance of the different models in this family over a common task .I. McCowan , D. Gatica - Perez , S. Bengio , D. Moore , and H. Bourlard .Towards computer understanding of human interactions .In Machine Learning for Multimodal Interaction : First International Workshop , MLMI , Lecture Notes in Computer Science , volume LNCS 3361 , pages 56 - 75 .Springer - Verlag , 2004 .[ .People meet in order to interact - disseminating information , making decisions , and creating new ideas .", "label": "", "metadata": {}}
{"text": "Based on this view , this article presents an approach in which relevant information content of a meeting is identified from a variety of audio and visual sensor inputs and statistical models of interacting people .We present a framework for computer observation and understanding of interacting people , and discuss particular tasks within this framework , issues in the meeting context , and particular algorithms that we have adopted .We also comment on current developments and the future challenges in automatic meeting analysis .Face authentication test on the BANCA database .In International Conference on Pattern Recognition , ICPR , volume 4 , pages 523 - 532 , 2004 .", "label": "", "metadata": {}}
{"text": "This paper details the results of a Face Authentication Test ( FAT2004 ) held in conjunction with the 17th International Conference on Pattern Recognition .The contest was held on the publicly available BANCA database according to a defined protocol .The competition also had a sequestered part in which institutions had to submit their algorithms for independent testing . 13 different verification algorithms from 10 institutions submitted results .Also , a standard set of face recognition software packages from the Internet were used to provide a baseline performance measure .Face authentication competition on the BANCA database .", "label": "", "metadata": {}}
{"text": "Springer - Verlag , 2004 .[ .This paper details the results of a face verification competition held in conjunction with the First International Conference on Biometric Authe ntication .The contest was held on the publically available BANCA database according to a defined protocol .Six different verification algorithms from 4 academic and commercial institutions submitted results .Also , a standard set of face recognition software from the internet was used to provide a baseline performance measure .N. Poh and S. Bengio .Noise - robust multi - stream fusion for text - independent speaker authentication .", "label": "", "metadata": {}}
{"text": "[ .Multi - stream approaches have proven to be very successful in speech recognition tasks and to a certain extent in speaker authentication tasks .In this study we propose a noise - robust multi - stream text - independent speaker authentication system .This system has two steps : first train the stream experts under clean conditions and then train the combination mechanism to merge the scores of the stream experts under both clean and noisy conditions .The idea here is to take advantage of the rather predictable reliability and diversity of streams under different conditions .", "label": "", "metadata": {}}
{"text": "An important finding is that a trade - off is often necessary between the overall good performance under all conditions ( clean and noisy ) and good performance under clean conditions .To reconcile this trade - off , we propose to give more emphasis or prior to clean conditions , thus , resulting in a combination mechanism that does not deteriorate under clean conditions ( as compared to the best stream ) yet is robust to noisy conditions .N. Poh and S. Bengio .Towards predicting optimal subsets of base classifiers in biometric authentication tasks .In S. Bengio and H. Bourlard , editors , Machine Learning for Multimodal Interactions : First International Workshop , MLMI , Lecture Notes in Computer Science , volume LNCS 3361 , pages 159 - 172 .", "label": "", "metadata": {}}
{"text": "[ .Combining multiple information sources , typically from several data streams is a very promising approach , both in experiments and to some extend in various real - life applications .However , combining too many systems ( base - experts ) will also increase both hardware and computation costs .One way to selecting a subset of optimal base - experts out of N is to carry out the experiments explicitly .There are 2 N -1 possible combinations .In this paper , we propose an analytical solution to this task when weighted sum fusion mechanism is used .", "label": "", "metadata": {}}
{"text": "It has a complexity that is additive between the number of examples and the number of possible combinations while the conventional approach , using brute - force experimenting , is multiplicative between these two terms .Hence , our approach will scale better with large fusion problems .Experiments on the BANCA multi - modal database verified our approach .While we will consider here fusion in the context of identity verification via biometrics , or simply biometric authentication , it can also have an important impact in meetings because this a priori information can assist in retrieving highlights in meeting analysis as in \" who said what \" .", "label": "", "metadata": {}}
{"text": "Development in fusion of identity verification will provide insights into how fusion in meetings can be done .The ability to predict fusion performance is another important step towards understanding the fusion problem .N. Poh and S. Bengio .Why do multi - stream , multi - band and multi - modal approaches work on biometric user authentication tasks ?In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 5 , pages 893 - 896 , 2004 .[ .Multi - band , multi - stream and multi - modal approaches have proven to be very successful both in experiments and in real - life applications , among which speech recognition and biometric authentication are of particular interest here .", "label": "", "metadata": {}}
{"text": "In this paper , we attempt to cast a light onto the latter subject .While there exists literature discussing this aspect , a study on the relationship between correlation , variance reduction and Equal Error Rate ( often used in biometric authentication ) has not been treated theoretically as done here , using the mean operator .Our findings suggest that combining several experts using the mean operator , Multi - Layer - Perceptrons and Support Vector Machines always perform better than the average performance of the underlying experts .Furthermore , in practice , most combined experts using the methods mentioned above perform better than the best underlying expert .", "label": "", "metadata": {}}
{"text": "Spectral subband centroids as complementary features for speaker authentication .In International Conference on Biometric Authentication , ICBA , Lecture Notes in Computer Science , volume LNCS 3072 , pages 631 - 639 .Springer - Verlag , 2004 .[ .Most conventional features used in speaker authentication are based on estimation of spectral envelopes in one way or another , e.g. , Mel - scale Filterbank Cepstrum Coefficients ( MFCCs ) , Linear - scale Filterbank Cepstrum Coefficients ( LFCCs ) and Relative Spectral Perceptual Linear Prediction ( RASTA - PLP ) .In this study , Spectral Subband Centroids ( SSCs ) are examined .", "label": "", "metadata": {}}
{"text": "Tangent vector kernels for invariant image classification with SVMs .In International Conference on Pattern Recognition , ICPR , volume 3 , pages 486 - 489 , 2004 .[ .This paper presents an application of the general sample - to - object approach to the problem of invariant image classification .The approach results in defining new SVM kernels based on tangent vectors that take into account prior information on known invariances .Real data of face images are used for experiments .The presented approach integrates virtual sample and tangent distance methods .We observe a significant increase in performance with respect to standard approaches .", "label": "", "metadata": {}}
{"text": "Estimating the quality of face localization for face verification .In IEEE International Conference on Image Processing , ICIP , pages 581 - 584 , 2004 .[ .Face localization is the process of finding the exact position of a face in a given image .This can be useful in several applications such as face tracking or person authentication .The purpose of this paper is to show that the error made during the localization process may have different impacts depending on the final application .Hence in order to evaluate the performance of a face localization algorithm , we propose to embed the final application ( here face verification ) into the performance measuring process .", "label": "", "metadata": {}}
{"text": "We show on the BANCA database that our proposed measure best matches the final verification results when comparing several localization algorithms , on various performance measures currently used in face localization .C. Sanderson and S. Bengio .Extrapolating single view face models for multi - view recognition .In International Conference on Intelligente Sensors , Sensor Networks and Information Processings , ISSNIP , pages 581 - 586 , 2004 .[ .Performance of face recognition systems can be adversely affected by mismatches between training and test poses , especially when there is only one training image available .", "label": "", "metadata": {}}
{"text": "The synthesis methods are based on several implementations of Maximum Likelihood Linear Regression ( MLLR ) , as well as standard multi - variate linear regression ( LinReg ) .All synthesis techniques utilize prior information on how face models for the frontal view are related to face models for non - frontal views .The synthesis and extension approach is evaluated by applying it to two face verification systems : PCA based ( holistic features ) and DCTmod2 based ( local features ) .For the DCTmod2 based system , the results show that synthesis via a new MLLR implementation obtains better performance than synthesis based on traditional MLLR ( due to a lower number of free parameters ) .", "label": "", "metadata": {}}
{"text": "C. Sanderson and S. Bengio .Statistical transformations of frontal models for non - frontal face verification .In IEEE International Conference on Image Processing , ICIP , pages 585 - 588 , 2004 .[ .All techniques rely on prior information and learn how a generic face model for the frontal view is related to generic models at non - frontal views .Experiments on the FERET database suggest that that the proposed MLS technique is more suitable than MLLR ( due to a lower number of free parameters ) and UBMdiff ( due to lack of heuristics ) .", "label": "", "metadata": {}}
{"text": "Offline recognition of unconstrained handwritten texts using HMMs and statistical language models .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 26(6):709 - 720 , 2004 .[ .This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts .The only assumption made about the data is that it is written in English .This allows the application of Statistical Language Models in order to improve the performance of our system .Several experiments have been performed using both single and multiple writer data .Lexica of variable size ( from 10,000 to 50,000 words ) have been used .", "label": "", "metadata": {}}
{"text": "An experimental setup to correctly deal with unconstrained text recognition is proposed .D. Zhang , D. Gatica - Perez , S. Bengio , I. McCowan , and G. Lathoud .Modeling individual and group actions in meetings : a two - layer hmm framework .In IEEE Workshop on Event Mining at the Conference on Computer Vision and Pattern Recognition , CVPR , 2004 .[ .We address the problem of recognizing sequences of human interaction patterns in meetings , with the goal of structuring them in semantic terms .The investigated patterns are inherently group - based ( defined by the individual activities of meeting participants , and their interplay ) , and multimodal ( as captured by cameras and microphones ) .", "label": "", "metadata": {}}
{"text": "We propose a two - layer Hidden Markov Model ( HMM ) framework that implements such concept in a principled manner , and that between has advantages over previous works .First , by decomposing the problem hierarchically , learning is performed on low - dimensional observation spaces , which results in simpler models .Second , our framework is easier to interpret , as both individual and group actions have a clear meaning , and thus easier to improve .Third , different HMM models can be used in each layer , to better reflect the nature of each subproblem .", "label": "", "metadata": {}}
{"text": "Experiments and comparison with a single - layer HMM baseline system show its validity . D. Zhang , D. Gatica - Perez , S. Bengio , I. McCowan , and G. Lathoud .Multimodal group action clustering in meetings .In ACM Multimedia Workshop on Video Surveillance and Sensor Networks , 2004 .[ .We address the problem of clustering multimodal group actions in meetings using a two - layer HMM framework .Meetings are structured as sequences of group actions .Our approach aims at creating one cluster for each group action , where the number of group actions and the action boundaries are unknown a priori .", "label": "", "metadata": {}}
{"text": "A number of options that explicitly model certain aspects of the data ( e.g. , asynchrony ) were considered .The second layer models the group actions using unsupervised HMM learning .The two layers are linked by a set of probability - based features produced by the individual action layer as input to the group action layer .The methodology was assessed on a set of multimodal turn - taking group actions , using a public five - hour meeting corpus .The results show that the use of multiple modalities and the layered framework are advantageous , compared to various baseline methods . E. Bailly - Bailli\u00e8re , S. Bengio , F. Bimbot , M. Hamouz , J. Kittler , J. Mari\u00e9thoz , J. Matas , K. Messer , V. Popovici , F. Por\u00e9e , B. Ruiz , and J.-P. Thiran .", "label": "", "metadata": {}}
{"text": "In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 625 - 638 .Springer - Verlag , 2003 .[ .In this paper we describe the acquistion and content of a new large , realistic and challenging multi - modal database intended for training and testing multi - modal verification systems .The BANCA database was captured in four European languages in two modalities ( face and voice ) .For recording , both high and low quality microphones and cameras were used .", "label": "", "metadata": {}}
{"text": "In total 208 people were captured , half men and half women .In this paper we also describe a protocol for evaluating verification algorithms on the database .M. Barnard , J.-M. Odobez , and S. Bengio .Multi - modal audio - visual event recognition for football analysis .In IEEE Workshop on Neural Networks for Signal Processing , NNSP , pages 469 - 478 , 2003 .[ .The recognition of events within multi - modal data is a challenging problem .In this paper we focus on the recognition of events by using both audio and video data .", "label": "", "metadata": {}}
{"text": "Specifically we look at the recognition of play and break sequences in football and the segmentation of football games based on these two events .Recognising relatively simple semantic events such as this is an important step towards full automatic indexing of such video material .These experiments were done using approximately 3 hours of data from two games of the Euro96 competition .We propose that modelling the audio and video streams separately for each sequence and fusing the decisions from each stream should yield an accurate and robust method of segmenting multi - modal data .S. Bengio .", "label": "", "metadata": {}}
{"text": "In S. Becker , S. Thrun , and K. Obermayer , editors , Advances in Neural Information Processing Systems , NIPS 15 , pages 1237 - 1244 .MIT Press , 2003 .[ .This paper presents a novel Hidden Markov Model architecture to model the joint probability of pairs of asynchronous sequences describing the same event .It is based on two other Markovian models , namely Asynchronous Input / Output Hidden Markov Models and Pair Hidden Markov Models .An EM algorithm to train the model is presented , as well as a Viterbi decoder that can be used to obtain the optimal state sequence as well as the alignment between the two sequences .", "label": "", "metadata": {}}
{"text": "S. Bengio .Multimodal authentication using asynchronous HMMs .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 770 - 777 .Springer - Verlag , 2003 .[ .It has often been shown that using multiple modalities to authenticate the identity of a person is more robust than using only one .Various combination techniques exist and are often performed at the level of the output scores of each modality system .In this paper , we present a novel HMM architecture able to model the joint probability distribution of pairs of asynchronous sequences ( such as speech and video streams ) describing the same event .", "label": "", "metadata": {}}
{"text": "Results on the M2VTS database show robust performances of the system under various audio noise conditions , when compared to other state - of - the - art techniques . H. Bourlard , S. Bengio , and K. Weber .Towards robust and adaptive speech recognition models .In M. Johnson , S. Khudanpur , M. Ostendorf , and R. Rosenfeld , editors , Mathematical Foundations of Speech and Language Processing , Institute for Mathematics and its Applications ( IMA ) Series , Volume 138 , pages 169 - 189 .Springer - Verlag , 2003 .[ .In this paper , we discuss a family of new Automatic Speech Recognition ( ASR ) approaches , which somewhat deviate from the usual ASR approaches but which have recently been shown to be more robust to nonstationary noise , without requiring specific adaptation or \" multi - style \" training .", "label": "", "metadata": {}}
{"text": "As a further extension to multi - stream ASR , we will finally introduce a new approach , referred to as HMM2 , where the HMM emission probabilities are estimated via state specific feature based HMMs responsible for merging the stream information and modeling their possible correlation .R. Collobert , Y. Bengio , and S. Bengio .Scaling large learning problems with hard parallel mixtures .International Journal on Pattern Recognition and Artificial Intelligence ( IJPRAI ) , 17(3):349 - 365 , 2003 .[ .A challenge for statistical learning is to deal with large data sets , e.g. in data mining .", "label": "", "metadata": {}}
{"text": "A probabilistic extension and the use of a set of generative models allows representing the gater so that all pieces of the model are locally trained .For SVMs , time complexity appears empirically to locally grow linearly with the number of examples , while generalization performance can be enhanced .For the probabilistic version of the algorithm , the iterative algorithm provably goes down in a cost function that is an upper bound on the negative log - likelihood .J. Czyz , S. Bengio , C. Marcel , and L. Vandendorpe .Scalability analysis of audio - visual person identity verification .", "label": "", "metadata": {}}
{"text": "Springer - Verlag , 2003 .[ .In this work , we present a multimodal identity verification system based on the fusion of the face image and the text independent speech data of a person .The system conciliates the monomodal face and speaker verification algorithms by fusing their respective scores .In order to assess the authentication system at different scales , the performance is evaluated at various sizes of the face and speech user template .The user template size is a key parameter when the storage space is limited like in a smart card .Our experimental results show that the multimodal fusion allows to reduce significantly the user template size while keeping a satisfactory level of performance .", "label": "", "metadata": {}}
{"text": "M. Magimai Doss , T. A. Stephenson , H. Bourlard , and S. Bengio .Phoneme - grapheme based speech recognition system .In IEEE Automatic Speech Recognition and Understanding Workshop , ASRU , pages 94 - 98 , 2003 .[ .State - of - the - art ASR systems typically use phoneme as the subword units .In this paper , we investigate a system where the word models are defined in - terms of two different subword units , i.e. , phonemes and graphemes .We train models for both the subword units , and then perform decoding using either both or just one subword unit .", "label": "", "metadata": {}}
{"text": "The results from our studies show that there is good potential in using grapheme as auxiliary subword units . D. Gatica - Perez , I. McCowan , M. Barnard , S. Bengio , and H. Bourlard .On automatic annotation of meeting databases .In IEEE International Conference on Image Processing , ICIP , volume 3 , pages 629 - 632 , 2003 .[ .In this paper , we discuss meetings as an application domain for multimedia content analysis .Meeting databases are a rich data source suitable for a variety of audio , visual and multi - modal tasks , including speech recognition , people and action recognition , and information retrieval .", "label": "", "metadata": {}}
{"text": "In order to develop an automatic annotation system in a principled manner , it is essential to have a well - defined task , a standard corpus and an objective performance measure .In this work we address each of these issues to automatically annotate events based on participant interactions .N. Gilardi and S. Bengio .Comparison of four machine learning algorithms for spatial data analysis .In G. Dubois , J. Malczewski , and M. DeCort , editors , Mapping radioactivity in the environment - Spatial Interpolation Comparison 97 , pages 222 - 237 .Office for Official Publications of the European Communities , Luxembourg , 2003 .", "label": "", "metadata": {}}
{"text": "This chapter proposes a clear methodology on how to use machine learning algorithms for spatial data analysis in order to avoid any bias and eventually obtain fair estimation of their performance on new data .Four different machine learning algorithms are presented , namely multilayer perceptrons ( MLP ) , mixture of experts ( ME ) , support vector regression ( SVR ) and a local version of the latter ( local SVR ) .Evaluation criteria adapted to geostatistical problems are also presented in order to compare adequately different models on the same dataset .Finally , an experimental comparison is given on the SIC97 dataset as well as an analysis of the results . Q. Le and S. Bengio .", "label": "", "metadata": {}}
{"text": "In International Conference on Artificial Neural Networks , ICANN / ICONIP , Lecture Notes in Computer Science , volume LNCS 2714 , pages 443 - 451 .Springer Verlag , 2003 .[ .Generative Gaussian Mixture Models ( GMMs ) are known to be the dominant approach for modeling speech sequences in text independent speaker verification applications because of their scalability , good performance and their ability in handling variable size sequences .On the other hand , because of their discriminative properties , models like Support Vector Machines ( SVMs ) usually yield better performance in static classification problems and can construct flexible decision boundaries .", "label": "", "metadata": {}}
{"text": "A cross - validation method is also used in the baseline system to increase the number of client scores in the training phase , which enhances the results of the SVM models .Experiments carried out on the XM2VTS and PolyVar databases confirm the interest of this hybrid approach .I. McCowan , S. Bengio , D. Gatica - Perez , G. Lathoud , F. Monay , D. Moore , P. Wellner , and H. Bourlard .Modeling human interaction in meetings .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 4 , pages 748 - 751 , 2003 .", "label": "", "metadata": {}}
{"text": "This paper investigates the recognition of group actions in meetings by modeling the joint behaviour of participants .Many meeting actions , such as presentations , discussions and consensus , are characterised by similar or complementary behaviour across participants .Recognising these meaningful actions is an important step towards the goal of providing effective browsing and summarisation of processed meetings .In this work , a corpus of meetings was collected in a room equipped with a number of microphones and cameras .The corpus was labeled in terms of a predefined set of meeting actions characterised by global behaviour .", "label": "", "metadata": {}}
{"text": "Initial results on the corpus demonstrate the ability of the system to recognise the set of meeting actions .I. McCowan , D. Gatica - Perez , S. Bengio , D. Moore , and H. Bourlard .Towards computer understanding of human interactions .In Ambient Intelligence , Lecture Notes in Computer Science , volume LNCS 2875 , pages 235 - 251 , Eindhoven , 2003 .Springer - Verlag .[ .People meet in order to interact - disseminating information , making decisions , and creating new ideas .Automatic analysis of meetings is therefore important from two points of view : extracting the information they contain , and understanding human interaction processes .", "label": "", "metadata": {}}
{"text": "We present a framework for computer observation and understanding of interacting people , and discuss particular tasks within this framework , issues in the meeting context , and particular algorithms that we have adopted .We also comment on current developments and the future challenges in automatic meeting analysis .Face verification competition on the XM2VTS database .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 964 - 974 .Springer - Verlag , 2003 .[ .N. Poh and S. Bengio .", "label": "", "metadata": {}}
{"text": "In IEEE Multimodal User Authentication Workshop , 2003 .[ .In this paper , several approaches that can be used to improve biometric authentication applications are proposed .The idea is inspired by the ensemble approach , i.e. , the use of several classifiers to solve a problem .Compared to using only one classifier , the ensemble of classifiers has the advantage of reducing the overall variance of the system .Instead of using multiple classifiers , we propose here to examine other possible means of variance reduction ( VR ) , namely through the use of multiple synthetic samples , different extractors ( features ) and biometric modalities .", "label": "", "metadata": {}}
{"text": "It is found empirically that VR via modalities is the best technique , followed by VR via extractors , VR via classifiers and VR via synthetic samples .This order of effectiveness is due to the corresponding degree of independence of the combined objects ( in decreasing order ) .The theoretical and empirical findings show that the combined experts via VR techniques always perform better than the average of their participating experts .Furthermore , in practice , most combined experts perform better than any of their participating experts .N. Poh , S. Marcel , and S. Bengio .", "label": "", "metadata": {}}
{"text": "In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 3 , pages 233 - 236 , 2003 .[ .In this paper , we present a simple yet effective way to improve a face verification system by generating multiple virtual samples from the unique image corresponding to an access request .These images are generated using simple geometric transformations .This method is often used during training to improve accuracy of a neural network model by making it robust against minor translation , scale and orientation change .The main contribution of this paper is to introduce such method during testing .", "label": "", "metadata": {}}
{"text": "By merging these scores using a simple mean operator , we show that the variance of merged scores is decreased by a factor between 1 and N .An experiment is carried out on the XM2VTS database which achieves new state - of - the - art performances .C. Sanderson and S. Bengio .Augmenting frontal face models for non - frontal verification .In IEEE Multimodal User Authentication Workshop , 2003 .[ .In this work we propose to address the problem of non - frontal face verification when only a frontal training image is available ( e.g. a passport photograph ) by augmenting a client 's frontal face model with artificially synthesized models for non - frontal views .", "label": "", "metadata": {}}
{"text": "Both techniques rely on a priori information and learn how face models for the frontal view are related to face models at a non - frontal view .The synthesis and augmentation approach is evaluated by applying it to two face verification systems : Principal Component Analysis ( PCA ) based and DCTmod2 ( Sanderson et al , 2003 ) based ; the two systems are a representation of holistic and non - holistic approaches , respectively .C. Sanderson and S. Bengio .Robust features for frontal authentication in difficult image conditions .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 495 - 504 .", "label": "", "metadata": {}}
{"text": "[ .In this paper we extend the recently proposed DCT - mod2 feature extraction technique ( which utilizes polynomial coefficients derived from 2D DCT coefficients obtained from horizontally & vertically neighbouring blocks ) via the use of various windows and diagonally neighbouring blocks .We also propose enhanced PCA , where traditional PCA feature extraction is combined with DCT - mod2 .Results using test images corrupted by a linear and a non - linear illumination change , white Gaussian noise and compression artefacts , show that use of diagonally neighbouring blocks and windowing is detrimental to robustness against illumination changes while being useful for increasing robustness against white noise and compression artefacts .", "label": "", "metadata": {}}
{"text": "C. Sanderson , S. Bengio , H. Bourlard , J. Mari\u00e9thoz , R. Collobert , M.F. BenZeghiba , F. Cardinaux , and S. Marcel .Speech & face based biometric authentication at IDIAP .In International Conference on Multimedia and Expo , ICME , volume 3 , pages 1 - 4 , 2003 .[ .We present an overview of recent research at IDIAP on speech & face based biometric authentication .This paper covers user - customised passwords , adaptation techniques , confidence measures ( for use in fusion of audio & visual scores ) , face verification in difficult image conditions , as well as other related research issues .", "label": "", "metadata": {}}
{"text": "Offline recognition of large vocabulary cursive handwritten text .In International Conference on Document Analysis and Recognition , ICDAR , pages 1101 - 1105 , 2003 .[ .This paper presents a system for the offline recognition of cursive handwritten lines of text .The system is based on continuous density HMMs and Statistical Language Models .The system recognizes data produced by a single writer .No a - priori knowledge is used about the content of the text to be recognized .Changes in the experimental setup with respect to the recognition of single words are highlighted .", "label": "", "metadata": {}}
{"text": "K. Weber , S. Ikbal , S. Bengio , and H. Bourlard .Robust speech recognition and feature extraction using HMM2 .Computer , Speech and Language , 17(2 - 3):195 - 211 , 2003 .[ .This paper presents the theoretical basis and preliminary experimental results of a new HMM model , referred to as HMM2 , which can be considered as a mixture of HMMs .In this new model , the emission probabilities of the temporal ( primary ) HMM are estimated through secondary , state specific , HMMs working in the acoustic feature space .", "label": "", "metadata": {}}
{"text": "Such a model has several potential advantages , such as a more flexible modeling of the time / frequency structure of the speech signal .When working with spectral features , such a system can also perform nonlinear spectral warping , effectively implementing a form of nonlinear vocal tract normalization .Furthermore , it will be shown that HMM2 can be used to extract noise robust features , supposed to correspond to formant regions , which can be used as extra features for traditional HMM recognizers to improve their performance .These issues are evaluated in the present paper , and different experimental results are reported on the Numbers95 database .", "label": "", "metadata": {}}
{"text": "Confidence measures for multimodal identity verification .Information Fusion , 3(4):267 - 276 , 2002 .[ .Multimodal fusion for identity verification has already shown great improvement compared to unimodal algorithms .In this paper , we propose to integrate confidence measures during the fusion process .We present a comparison of three different methods to generate such confidence information from unimodal identity verification systems .These methods can be used either to enhance the performance of a multimodal fusion algorithm or to obtain a confidence level on the decisions taken by the system .All the algorithms are compared on the same benchmark database , namely XM2VTS , containing both speech and face information .", "label": "", "metadata": {}}
{"text": "Hidden markov models and other finite state automata for sequence processing .In Michael A. Arbib , editor , The Handbook of Brain Theory and Neural Networks , Second Edition .The MIT Press , 2002 .[ .R. Collobert , S. Bengio , and Y. Bengio .A parallel mixture of SVMs for very large scale problems .Neural Computation , 14(5):1105 - 1114 , 2002 .[ .Support Vector Machines ( SVMs ) are currently the state - of - the - art models for many classification problems but they suffer from the complexity of their training algorithm which is at least quadratic with respect to the number of examples .", "label": "", "metadata": {}}
{"text": "The present paper proposes a new mixture of SVMs that can be easily implemented in parallel and where each SVM is trained on a small subset of the whole dataset .Experiments on a large benchmark dataset ( Forest ) yielded significant time improvement ( time complexity appears empirically to locally grow linearly with the number of examples ) .In addition , and that is a surprise , a significant improvement in generalization was observed .R. Collobert , S. Bengio , and Y. Bengio .A parallel mixture of SVMs for very large scale problems .In T.G. Dietterich , S. Becker , and Z. Ghahramani , editors , Advances in Neural Information Processing Systems , NIPS 14 , pages 633 - 640 .", "label": "", "metadata": {}}
{"text": "[ .Support Vector Machines ( SVMs ) are currently the state - of - the - art models for many classification problems but they suffer from the complexity of their training algorithm which is at least quadratic with respect to the number of examples .Hence , it is hopeless to try to solve real - life problems having more than a few hundreds of thousands examples with SVMs .The present paper proposes a new mixture of SVMs that can be easily implemented in parallel and where each SVM is trained on a small subset of the whole dataset .", "label": "", "metadata": {}}
{"text": "In addition , and that is a surprise , a significant improvement in generalization was observed on Forest .R. Collobert , Y. Bengio , and S. Bengio .Scaling large learning problems with hard parallel mixtures .In S. Lee and A. Verri , editors , International Workshop on Pattern Recognition with Support Vector Machines , SVM , Lecture Notes in Computer Science , volume LNCS 2388 , pages 8 - 23 .Springer - Verlag , 2002 .[ .A challenge for statistical learning is to deal with large data sets , e.g. in data mining .", "label": "", "metadata": {}}
{"text": "A probabilistic extension and the use of a set of generative models allows representing the gater so that all pieces of the model are locally trained .For SVMs , time complexity appears empirically to locally grow linearly with the number of examples , while generalization performance can be enhanced .For the probabilistic version of the algorithm , the iterative algorithm provably goes down in a cost function that is an upper bound on the negative log - likelihood .N. Gilardi , S. Bengio , and M. Kanevski .Conditional gaussian mixture models for environmental risk mapping .", "label": "", "metadata": {}}
{"text": "[ .This paper proposes the use of Gaussian Mixture Models to estimate conditional probability density functions in an environmental risk mapping context .A conditional Gaussian Mixture Model has been compared to the geostatistical method of Sequential Gaussian Simulations and shows good performances in reconstructing local PDF .The data sets used for this comparison are parts of the digital elevation model of Switzerland . S. Marcel and S. Bengio .Improving face verification using skin color information .In Proceedings of the 16th International Conference on Pattern Recognition , ICPR , volume 2 , pages 11 - 15 .", "label": "", "metadata": {}}
{"text": "[ .The performance of face verification systems has steadily improved over the last few years , mainly focusing on models rather than on feature processing .State - of - the - art methods often use the gray - scale face image as input .In this paper , we propose to use an additional feature to the face image : the skin color .The new feature set is tested on a benchmark database , namely XM2VTS , using a simple discriminant artificial neural network .Results show that the skin color information improves the performance .S. Marcel , C. Marcel , and S. Bengio .", "label": "", "metadata": {}}
{"text": "In COST275 Workshop on the advent of Biometrics on the Internet , 2002 .[ .The performance of face verification systems has steadily improved over the last few years , mainly focusing on models rather than on feature processing .State - of - the - art methods often use the gray - scale face image as input .In this paper , we propose to use an additional feature to the face image : the skin color .The new feature set is tested on a benchmark database , namely XM2VTS , using a simple discriminant artificial neural network .", "label": "", "metadata": {}}
{"text": "J. Mari\u00e9thoz and S. Bengio .A comparative study of adaptation methods for speaker verification .In Proceedings of the International Conference on Spoken Language Processing , ICSLP , 2002 .[ .Real - life speaker verification systems are often implemented using client model adaptation methods , since the amount of data available for each client is often too low to consider plain Maximum Likelihood methods .While the Bayesian Maximum A Posteriori ( MAP ) adaptation method is commonly used in speaker verification , other methods have proven to be successful in related domains such as speech recognition .", "label": "", "metadata": {}}
{"text": "All three methods are compared to the more classical Maximum Likelihood method , and results are given for a subset of the 1999 NIST Speaker Recognition Evaluation database .N. Poh , S. Bengio , and J. Korczak .A multi - sample multi - source model for biometric authentication .In IEEE Workshop on Neural Networks for Signal Processing , NNSP , pages 375 - 384 , 2002 .[ .In this study , two techniques that can improve the authentication process are examined : ( i ) multiple samples and ( ii ) multiple biometric sources .", "label": "", "metadata": {}}
{"text": "By using the average operator , both the theoretical and empirical results show that integrating as many samples and as many biometric sources as possible can improve the overall reliability of the system .This strategy is called multi - sample multi - source approach .This strategy was tested on a real - life database using neural networks trained in one - versus - all configuration . A. Vinciarelli and S. Bengio .Offline cursive word recognition using continuous density hidden markov models trained with PCA or ICA features .In Proceedings of the 16th International Conference on Pattern Recognition , ICPR , volume 3 , pages 81 - 84 .", "label": "", "metadata": {}}
{"text": "[ .This work presents an Offline Cursive Word Recognition System dealing with single writer samples .The system was a continuous density hiddden Markov model trained using either the raw data , or data transformed using Principal Component Analysis or Independent Component Analysis .Both techniques significantly improved the recognition rate of the system .Preprocessing , normalization and feature extraction are described in detail as well as the training technique adopted .Several experiments were performed using a publicly available database .The accuracy obtained is the highest presented in the literature over the same data . A. Vinciarelli and S. Bengio .", "label": "", "metadata": {}}
{"text": "In Proceedings of the 8th International Conference on Frontiers in Handwriting Recognition , pages 287 - 291 , 2002 .[ .This work presents the application of HMM adaptation techniques to the problem of Off - Line Cursive Script Recognition .Instead of training a new model for each writer , one first creates a unique model with a mixed database and then adapts it for each different writer using his own small dataset . A. Vinciarelli and S. Bengio .Writer adaptation techniques in HMM based off - line cursive script recognition .Pattern Recognition Letters , 23(8):905 - 916 , 2002 .", "label": "", "metadata": {}}
{"text": "This work presents the application of HMM adaptation techniques to the problem of Off - Line Cursive Script Recognition .Instead of training a new model for each writer , one first creates a unique model with a mixed database and then adapts it for each different writer using his own small dataset .K. Weber , S. Bengio , and H. Bourlard .Increasing speech recognition noise robustness with HMM2 .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 1 , pages 929 - 932 , 2002 .[ .The purpose of this paper is to investigate the behavior of HMM2 models for the recognition of noisy speech .", "label": "", "metadata": {}}
{"text": "As formant regions are known to be robust in adverse conditions , HMM2 seems particularly promising for improving speech recognition robustness .Here , we review different variants of the HMM2 approach with respect to their application to noise - robust automatic speech recognition .K. Weber , F. de Wet , B. Cranen , L. Boves , S. Bengio , and H. Bourlard .Evaluation of formant - like features for ASR .In Proceedings of the International Conference on Spoken Language Processing , ICSLP , 2002 .[ .This paper investigates possibilities to automatically find a low - dimensional , formant - related physical representation of the speech signal , which is suitable for automatic speech recognition ( ASR ) .", "label": "", "metadata": {}}
{"text": "Combinations of automatically extracted formant - like features and ' conventional ' , noise - robust , state - of - the - art features ( such as MFCCs including spectral subtraction and cepstral mean subtraction ) have previously been shown to be more robust in adverse conditions than state - of - the - art features alone .However , it is not clear how these automatically extracted formant - like features behave in comparison with true formants .The purpose of this paper is to investigate two methods to automatically extract formant - like features , and to compare these features to hand - labeled formant tracks as well as to standard MFCCs in terms of their performance on a vowel classification task .", "label": "", "metadata": {}}
{"text": "Learning the decision function for speaker verification .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 1 , pages 425 - 428 , 2001 .[ .This paper explores the possibility to replace the usual thresholding decision rule of log likelihood ratios used in speaker verification systems by more complex and discriminant decision functions based for instance on Linear Regression models or Support Vector Machines .Current speaker verification systems , based on generative models such as HMMs or GMMs , can indeed easily be adapted to use such decision functions .", "label": "", "metadata": {}}
{"text": "New approaches towards robust and adaptive speech recognition .In T.K. Leen , T.G. Dietterich , and V. Tresp , editors , Advances in Neural Information Processing Systems , NIPS 13 , pages 751 - 757 .MIT Press , 2001 .[ .In this paper , we discuss some new research directions in automatic speech recognition ( ASR ) , and which somewhat deviate from the usual approaches .More specifically , we will motivate and briefly describe new approaches based on multi - stream and multi / band ASR .As a further extension to multi - stream ASR , we will finally introduce a new approach , referred to as HMM2 , where the HMM emission probabilities are estimated via state specific feature based HMMs responsible for merging the stream information and modeling their possible correlation .", "label": "", "metadata": {}}
{"text": "SVMTorch : Support vector machines for large - scale regression problems .Journal of Machine Learning Research , JMLR , 1:143 - 160 , 2001 .[ .Support Vector Machines ( SVMs ) for regression problems are trained by solving a quadratic optimization problem which needs on the order of l square memory and time resources to solve , where l is the number of training examples .With this algorithm , one can now efficiently solve large - scale regression problems ( more than 20000 examples ) .Comparisons with Nodelib , another publicly available SVM algorithm for large - scale regression problems from Flake and Lawrence ( 2000 ) yielded significant time improvements .", "label": "", "metadata": {}}
{"text": "J.-L. DesGranges , P. Agin , and S. Bengio .The use of predictive models of breeding bird assemblages for assessing and monitoring forest bird diversity .In A. Franc , O. Laroussinie , and T. Karjalainen , editors , Criteria and Indicators for Sustainable Forest Management at the Forest Management Unit Level , volume 38 , pages 181 - 200 .European Forest Institute Proceedings , 2001 .K. Weber , S. Bengio , and H. Bourlard .HMM2- extraction of formant features and their use for robust ASR .In Proceedings of the European Conference on Speech Communication and Technology , EUROSPEECH , 2001 .", "label": "", "metadata": {}}
{"text": "As recently introduced , an HMM2 can be considered as a particular case of an HMM mixture in which the HMM emission probabilities ( usually estimated through Gaussian mixtures or an artificial neural network ) are modeled by state - dependent , feature - based HMM ( referred to as frequency HMM ) .A general EM training algorithm for such a structure has already been developed .While the fact that this architecture is able to automatically extract meaningful formant information is interesting by itself , empirical results will also show the robustness of these features to noise , and their potential to enhance state - of - the - art noise - robust HMM - based ASR .", "label": "", "metadata": {}}
{"text": "Speech recognition using advanced HMM2 features .In Proceedings of the Automatic Speech Recognition and Understanding Workshop , ASRU , pages 65 - 68 , 2001 .[ .HMM2 is a particular hidden Markov model where state emission probabilities of the temporal ( primary ) HMM are modeled through ( secondary ) state - dependent frequency - based HMMs .As shown previously , a secondary HMM can also be used to extract robust ASR features .Here , we further investigate this novel approach towards using a full HMM2 as feature extractor , working in the spectral domain , and extracting robust formant - like features for standard ASR system .", "label": "", "metadata": {}}
{"text": "To further improve the HMM2 system , we complement the initial spectral energy vectors with frequency information .Finally , adding temporal information to the HMM2 feature vector yields further improvements .These conclusions are experimentally validated on the Numbers95 database , where word error rates of 15 % , using only a 4-dimensional feature vector ( 3 formant - like parameters and one time index ) were obtained .S. Bengio and Y. Bengio .Taking on the curse of dimensionality in joint distributions using neural networks .IEEE Transaction on Neural Networks , special issue on data mining and knowledge discovery , 11(3):550 - 557 , 2000 .", "label": "", "metadata": {}}
{"text": "The curse of dimensionality is severe when modeling high - dimensional discrete data : the number of possible combinations of the variables explodes exponentially .The neural network can be interpreted as a graphical model without hidden random variables , but in which the conditional distributions are tied through the hidden units .The connectivity of the neural network can be pruned by using dependency tests between the variables ( thus reducing significantly the number of parameters ) .Experiments on modeling the distribution of several discrete data sets show statistically significant improvements over other methods such as naive Bayes and comparable Bayesian networks , and show that significant improvements can be obtained by pruning the network . Y. Bengio and S. Bengio .", "label": "", "metadata": {}}
{"text": "In S.A. Solla , T.K. Leen , and K.-R. M\u00fcller , editors , Advances in Neural Information Processing Systems , NIPS 12 , pages 400 - 406 .MIT Press , 2000 .[ .The curse of dimensionality is severe when modeling high - dimensional discrete data : the number of possible combinations of the variables explodes exponentially .The neural network can be interpreted as a graphical model without hidden random variables , but in which the conditional distributions are tied through the hidden units .The connectivity of the neural network can be pruned by using dependency tests between the variables .", "label": "", "metadata": {}}
{"text": "N. Gilardi and S. Bengio .Local machine learning models for spatial data analysis .Journal of Geographic Information and Decision Analysis , 4(1):11 - 28 , 2000 .[ .In this paper , we compare different machine learning algorithms applied to non stationary spatial data analysis .We show that models taking into account local variability of the data are better than models which are trained globally on the whole dataset .T. A. Stephenson , H. Bourlard , S. Bengio , and A. C. Morris .Automatic speech recognition using dynamic Bayesian networks with both acoustic and articulatory variables .", "label": "", "metadata": {}}
{"text": "[ .Current technology for automatic speech recognition ( ASR ) uses hidden Markov models ( HMMs ) that recognize spoken speech using the acoustic signal .However , no use is made of the causes of the acoustic signal : the articulators .We present here a dynamic Bayesian network ( DBN ) model that utilizes an additional variable for representing the state of the articulators .A particular strength of the system is that , while it uses measured articulatory data during its training , it does not need to know these values during recognition .As Bayesian networks are not used often in the speech community , we give an introduction to them .", "label": "", "metadata": {}}
{"text": "Recognition results are given , showing that a system with both acoustics and inferred articulatory positions performs better than a system with only acoustics .K. Weber , S. Bengio , and H. Bourlard .HMM2- a novel approach to HMM emission probability estimation .In Proceedings of the International Conference on Speech and Language Processing , ICSLP , Beijing , China , October 2000 .[ .In this paper , we discuss and investigate a new method to estimate local emission probabilities in the framework of hidden Markov models ( HMM ) .Each feature vector is considered to be a sequence and is supposed to be modeled by yet another HMM .", "label": "", "metadata": {}}
{"text": "There is a variety of possible topologies of such HMM2 systems , e.g. incorporating trellis or ergodic HMM structures .Preliminary HMM2 speech recognition experiments on cepstral and spectral features yielded worse results than state - of - the - art systems .However , we believe that HMM2 systems have a lot of potential advantages and are therefore worth investigating further .S. Bengio .Int\u00e9gration des syst\u00e8mes tutoriels traditionnels et des syst\u00e8mes tutoriels intelligents .Master 's thesis , D\u00e9partement d'Informatique et de Recherche Op\u00e9rationnelle , Universit\u00e9 de Montr\u00e9al , 1989 .S. Bengio .Optimisation d'une r\u00e8gle d'apprentissage pour r\u00e9seaux de neurones artificiels .", "label": "", "metadata": {}}
{"text": "Universit\u00e9 de Montr\u00e9al , 1993 .[ . djvu ] .S. Bengio and Y. Bengio .An EM algorithm for asynchronous input / output hidden markov models .In Proceedings of the International Conference on Neural Information Processing , ICONIP , Hong Kong , 1996 .[ .In learning tasks in which input sequences are mapped to output sequences , it is often the case that the input and output sequences are not synchronous .For example , in speech recognition , acoustic sequences are longer than phoneme sequences .Input / Output Hidden Markov Models have already been proposed to represent the distribution of an output sequence given an input sequence of the same length .", "label": "", "metadata": {}}
{"text": "S. Bengio , Y. Bengio , and J. Cloutier .Use of genetic programming for the search of a new learning rule for neural networks .In Proceedings of the First Conference on Evolutionary Computation , IEEE World Congress on Computational Intelligence , volume 1 , pages 324 - 327 , 1994 .[ . S. Bengio , Y. Bengio , and J. Cloutier .On the search for new learning rules for ANNs .Neural Processing Letters , 2(4):26 - 30 , 1995 . [ .In this paper , we present a framework where a learning rule can be optimized within a parametric learning rule space .", "label": "", "metadata": {}}
{"text": "We corroborate the results of this study with practical experiments .S. Bengio , Y. Bengio , J. Cloutier , and J. Gecsei .Aspects th\u00e9oriques de l'optimisation d'une r\u00e8gle d'apprentissage .In Actes de la conf\u00e9rence Neuro - N\u00eemes 1992 , N\u00eemes , France , 1992 .[ . djvu ] .S. Bengio , Y. Bengio , J. Cloutier , and J. Gecsei .On the optimization of a synaptic learning rule .In Conference on Optimality in Biological and Artificial Networks , Dallas , USA , 1992 .[ . djvu ] .S. Bengio , Y. Bengio , J. Cloutier , and J. Gecsei .", "label": "", "metadata": {}}
{"text": "In S. Gielen and B. Kappen , editors , Proceedings of the International Conference on Artificial Neural Networks , ICANN'93 , pages 502 - 502 , Amsterdam , Nederlands , 1993 .Springer - Verlag .[ . djvu ] .S. Bengio , Y. Bengio , J. Cloutier , and J. Gecsei .On the optimization of a synaptic learning rule .In D. S. Levine and W. R. Elsberry , editors , Optimality in Biological and Artificial Networks ? , pages 265 - 287 .Lawrence Erlbaum Associates , 1997 .[ . djvu ] .S. Bengio , Y. Bengio , J. Robert , and G. B\u00e9langer .", "label": "", "metadata": {}}
{"text": "Neural Computation , 11(5):1199 - 1209 , 1999 .[ .This paper presents a new application of stochastic adaptive learning algorithms to the computation of strategic equilibria in auctions .The proposed approach addresses the problems of tracking a moving target and balancing exploration ( of action space ) versus exploitation ( of better modeled regions of action space ) .Neural networks are used to represent a stochastic decision model for each bidder .Experiments confirm the correctness and usefulness of the approach .S. Bengio , G. Brassard , Y. Desmedt , C. Goutier , and J.-J. Quisquater .", "label": "", "metadata": {}}
{"text": "Journal of Cryptology , 4(3):175 - 183 , 1991 .In this paper we demonstrate that widely known identification systems , such as the public - file - based Feige - Fiat - Shamir scheme , can be insecure if proper care is not taken with their implementation .We suggest possible solutions .On the other hand , identity - based versions of the Feige - Fiat - Shamir scheme are conceptually more complicated than necessary .S. Bengio , F. Clerot , A. Gravey , and D. Collobert .Dynamical resource reservation schemes in an ATM network using neural network - based traffic prediction .", "label": "", "metadata": {}}
{"text": "Kluwer B. V. , 1997 .[ .The performances of predictor - based in service renegotiation are evaluated in terms of renegotiation errors and reserved bandwidth for the the DBR traffic handling capability and are shown to be very encouraging for the use of connectionist prediction techniques for the management of bursty traffics in ATM networks .S. Bengio , F. Fessant , and D. Collobert .A connectionist system for medium - term horizon time series prediction .In International Workshop on Applications of Neural Networks to Telecommunications , IWANNT , Stockholm , Sweden , 1995 .[ . djvu ] .", "label": "", "metadata": {}}
{"text": "Use of modular architectures for time series prediction .Neural Processing Letters , 3(2):101 - 106 , 1996 .[ . S. Bengio , C. Frasson , and J. Gecsei .Integrating traditional and intelligent computerized tutoring .In Fourth International Symposium on Computer and Information Sciences , Cesme , Turkey , 1989 . Y. Bengio and S. Bengio .Training asynchronous input / output hidden markov models .In AAAI Spring Symposium on Computational Issues in Learning Models of Dynamical Systems , 1996 .[ . djvu ] . Y. Bengio , S. Bengio , and J. Cloutier .", "label": "", "metadata": {}}
{"text": "In Proceedings of the International Joint Conference on Neural Networks , IJCNN , volume 2 , pages 969 - 974 , Seattle , USA , 1991 .[ . Y. Bengio , S. Bengio , J.-F. Isabelle , and Y. Singer .Shared context probabilistic transducers .In Advances in Neural Information Processing Systems , NIPS 10 , 1998 .[ .Recently , a model for supervised learning of probabilistic transducers represented by suffix trees was introduced .However , this algorithm tends to build very large trees , requiring very large amounts of computer memory .In this paper , we propose a new , more compact , transducer model in which one shares the parameters of distributions associated to contexts yielding similar conditional output distributions .", "label": "", "metadata": {}}
{"text": "A neural network to detect homologies in proteins .In Advances in Neural Information Processing Systems , NIPS 2 , San Mateo , CA , USA , 1990 .Morgan Kaufmann .[ . Y. Desmedt , C. Goutier , and S. Bengio .Special uses and abuses of the Fiat - Shamir passport protocol .In Advances in Cryptology , Crypto , Lecture Notes in Computer Science , volume LNCS 293 , pages 21 - 39 , Santa Barbara , USA , 1988 .Springer Verlag .[ .If the physical description of a person would be unique and adequately used and tested , then the security of the fiat - shamir scheme is not based on zero - knowledge . otherwise some new frauds exist .", "label": "", "metadata": {}}
{"text": "this technique can be used by a terrorist sponsoring country to communicate 500 new words of secret information each time a tourist passport is verified .a non - trivial solution to avoid these subliminal channel problems is presented .the notion of relative zero - knowledge is introduced .F. Fessant , S. Bengio , and D. Collobert .On the prediction of solar activity using different neural network models .Annales Geophysicae , 14:20 - 26 , 1996 .[ .J.-Y. Potvin and S. Bengio .The vehicle routing problem with time windows - part II : Genetic search .", "label": "", "metadata": {}}
{"text": "[ . S. Bengio , J. Dean , D. Erhan , E. Ie , Q. Le , A. Rabinovich , J. Shlens , and Y. Singer .Using web co - occurrence statistics for improving image categorization .Technical Report 1312.5697 , ArXiv , 2013 . [ .Object recognition and localization are important tasks in computer vision .The focus of this work is the incorporation of contextual information in order to improve object recognition and localization .For instance , it is natural to expect not to see an elephant to appear in the middle of an ocean .", "label": "", "metadata": {}}
{"text": "By merely counting the number of times nouns ( such as elephants , sharks , oceans , etc . ) co - occur in web documents , we obtain a good estimate of expected co - occurrences in visual data .We then cast the problem of combining textual co - occurrence statistics with the predictions of image - based classifiers as an optimization problem .The resulting optimization problem serves as a surrogate for our inference procedure .Albeit the simplicity of the resulting optimization problem , it is effective in improving both recognition and localization accuracy .Concretely , we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets . D. Grangier and S. Bengio .", "label": "", "metadata": {}}
{"text": "Technical Report IDIAP - RR 06 - 15 , IDIAP , 2006 .[ .This work proposes a new approach to the retrieval of images from text queries .Contrasting with previous work , this method relies on a discriminative approach : the parameters are selected in order to minimize a loss related to the ranking performance of the model , i.e. its ability to rank the relevant pictures above the non - relevant ones when given a text query .In order to minimize this loss , we introduce an adaptation of the recently proposed Passive - Aggressive algorithm .", "label": "", "metadata": {}}
{"text": "These experiments show that our method outperforms the current state - of - the - art approaches , e.g. the average precision over Corel test data is 21.6 % for our model versus 16.7 % for the best alternative , Probabilistic Latent Semantic Analysis .M. Keller and S. Bengio .A multitask learning approach to document representation using unlabeled data .Technical Report IDIAP - RR 06 - 44 , IDIAP , 2006 .[ .Text categorization is intrinsically a supervised learning task , which aims at relating a given text document to one or more predefined categories .", "label": "", "metadata": {}}
{"text": "We present in this paper a method that takes advantage of huge amounts of unlabeled text documents available in digital format , to counter balance the relatively smaller available amount of labeled text documents .Experimental results on Reuters RCV1 suggest that , as expected , performance over the labeled task increases as the amount of unlabeled data increases .D. Grangier and S. Bengio .A discriminative decoder for the recognition of phoneme sequences .Technical Report IDIAP - RR 05 - 67 , IDIAP , 2005 . [ .In this report , we propose a discriminative decoder for the recognition of phoneme sequences , i.e. the identification of the uttered phoneme sequence from a speech recording .", "label": "", "metadata": {}}
{"text": "J. Mari\u00e9thoz and S. Bengio .Can a professional imitator fool a gmm - based speaker verification system ?Technical Report IDIAP - RR 05 - 61 , IDIAP , 2005 . [ .This paper presents an attempt at assessing empirically how a state - of - the - art text - independent speaker verification system behaves when confronted to imposting attempts from a professional imitator who perfectly knows how to imitate in particular the clients he tried to impost .Empirical evidence show that , fortunately , current speaker verification systems are indeed robust to such attempts , even when humans are not able to discriminate between true and imposting accesses ( a website with some examples is provided to convince the reader ) .", "label": "", "metadata": {}}
{"text": "This study thus represents a first step in assessing a speaker verification system against true , informed , impostors . A. Pozdnoukhov and S. Bengio .A kernel classifier for distributions .Technical Report IDIAP - RR 05 - 32 , IDIAP , 2005 . [ .This paper presents a new algorithm for classifying distributions .The algorithm combines the principle of margin maximization and a kernel trick , applied to distributions .Thus , it combines the discriminative power of support vector machines and the well - developed framework of generative models .It can be applied to a number of real - life tasks which include data represented as distributions .", "label": "", "metadata": {}}
{"text": "We illustrate this approach in details for the case of Gaussian distributions , using a toy problem .We also present experiments devoted to the real - life problem of invariant image classification . D. Zhang , D. Gatica - Perez , D. Roy , and S. Bengio .Modeling interactions from email communication .Technical Report IDIAP - RR 05 - 51 , IDIAP , 2005 .[ .Email plays an important role as a medium for the spread of information , ideas , and influence among its users .We present a framework to learn topic - based interactions between pairs of email users , i.e. , the extent to which the email topic dynamics of one user are likely to be affected by the others .", "label": "", "metadata": {}}
{"text": "This paper makes two contributions .First , we model interactions between email users using the semantic content of email body , instead of email header .Second , our framework models not only email topic dynamics of individual email users , but also the interactions within a group of individuals .Experiments on the Enron email corpus show some interesting results that are potentially useful to discover the hierarchy of the Enron organization .We also present an email visualization and retrieval system which could not only search for relevant emails , but also for the relevant email users .", "label": "", "metadata": {}}
{"text": "Sequence classification with input - output hidden markov models .Technical Report IDIAP - RR 04 - 13 , IDIAP , 2004 .[ .We present a training and testing method for Input - Output Hidden Markov Model that is particularly suited for classification of sequences in which class information accumulates over time .We discuss two such cases : the discrimination of mental tasks from sequences of EEG features , common in Brain Computer Interface research , and phoneme classification from sequences of acoustic features for speech recognition .The objective function is modified so that training focuses on the improvement of classification accuracy .", "label": "", "metadata": {}}
{"text": "C. Dimitrakakis and S. Bengio .Estimates of parameter distributions for optimal action selection .Technical Report IDIAP - RR 04 - 72 , IDIAP , 2004 .[ .We present a general method for maintaining estimates of the distribution of parameters in arbitrary models .This is then applied to the estimation of probability distributions over actions in value - based reinforcement learning .While this approach is similar to other techniques that maintain a confidence measure for action - values , it nevertheless offers a new insight into current techniques and reveals potential avenues of further research .", "label": "", "metadata": {}}
{"text": "Significance tests for bizarre measures in 2-class classification tasks .Technical Report IDIAP - RR 04 - 34 , IDIAP , 2004 .[ .Statistical significance tests are often used in machine learning to compare the performance of two learning algorithms or two models .However , in most cases , one of the underlying assumptions behind these tests is that the error measure used to assess the performance of one model / algorithm is computed as the sum of errors obtained on each example of the test set .This is however not the case for several well - known measures such as F 1 , used in text categorization , or DCF , used in person authentication .", "label": "", "metadata": {}}
{"text": "We furthermore assess the quality of these tests on a real - life large dataset .C. Sanderson and S. Bengio .Statistical transformation techniques for face verification using faces rotated in depth .Technical Report IDIAP - RR 04 - 04 , IDIAP , 2004 .[ .In the framework of a Bayesian classifier based on mixtures of gaussians , we address the problem of non - frontal face verification ( when only a single ( frontal ) training image is available ) by extending each frontal face model with artificially synthesized models for non - frontal views .", "label": "", "metadata": {}}
{"text": "All synthesis techniques rely on prior information and learn how face models for the frontal view are related to face models for non - frontal views .The synthesis and extension approach is evaluated by applying it to two face verification systems : PCA based ( holistic features ) and DCTmod2 based ( local features ) .The results further suggest that extending frontal models considerably reduces errors .R. Collobert and S. Bengio .A new margin - based criterion for efficient gradient descent .Technical Report IDIAP - RR 03 - 16 , IDIAP , 2003 .[ .", "label": "", "metadata": {}}
{"text": "Moreover , these methods are usually not easy to implement .Many enhancements have also been proposed in order to overcome these problems , but most of them still cost O ( n 2 ) in time per iteration .Instead of trying to solve a hard optimization problem using complex second - order tricks , we propose to modify the problem itself in order to optimize a simpler one , by simply changing the cost function used during training .Furthermore , we will argue that analyzing the Hessian resulting from the choice of various cost functions is very informative and could help in the design of new machine learning algorithms .", "label": "", "metadata": {}}
{"text": "Several empirical comparisons on two benchmark data sets are given to justify this approach .M. Keller and S. Bengio .Textual data representation .Technical Report IDIAP - RR 03 - 49 , IDIAP , 2003 .[ .We address in this report the problem of representing formally textual data .First , this problem is replaced in the context of automatic text processing .Then , the weaknesses of the basic document representation , i.e. the bag - of - words representation , are explained and some state - of - the - art methods claiming to overcome these weaknesses are reviewed .", "label": "", "metadata": {}}
{"text": "J. Mari\u00e9thoz and S. Bengio .An alternative to silence removal for text - independent speaker verification .Technical Report IDIAP - RR 03 - 51 , IDIAP , 2003 .[ .State - of - the - art text independent speaker verification systems use silence / speech detectors to get rid of silence frames which are considered to be non discriminative .This paper explores a possible replacement to this silence / speech detector by considering each Gaussian of a GMM as modeling a specific speech class and by using discriminant models like SVMs and MLPs in order to fuse the corresponding class - specific scores to obtain a final decision .", "label": "", "metadata": {}}
{"text": "N. Poh and S. Bengio .Variance reduction techniques in biometric authentication .Technical Report IDIAP - RR 03 - 17 , IDIAP , 2003 .[ .In this paper , several approaches that can be used to improve biometric authentication applications are proposed .The idea is inspired by the ensemble approach , i.e. , the use of several classifiers to solve a problem .Compared to using only one classifier , the ensemble of classifiers has the advantage of reducing the overall variance of the system .Instead of using multiple classifiers , we propose here to examine other possible means of variance reduction ( VR ) , namely through the use of multiple real samples , synthetic samples , different extractors ( features ) and biometric modalities .", "label": "", "metadata": {}}
{"text": "This order of effectiveness is due to the corresponding degree of independence of the combined objects ( in decreasing order ) .The theoretical and empirical findings show that the combined experts via VR techniques always perform better than the average of their participating experts .Furthermore , in practice , most combined experts perform better than any of their participating experts . A. Pozdnoukhov and S. Bengio .From samples to objects in kernel methods .Technical Report IDIAP - RR 03 - 29 , IDIAP , 2003 .[ .This paper presents a general method for incorporating prior knowledge into kernel methods .", "label": "", "metadata": {}}
{"text": "Two implementation techniques of this method , based on analytical kernel jittering and the vicinal risk minimization principle , are considered .Empirical results on one artificial dataset and one real dataset based on EEG signals demonstrate the performance of the proposed method .R. Collobert , S. Bengio , and J. Mari\u00e9thoz .Torch : a modular machine learning software library .Technical Report IDIAP - RR 02 - 46 , IDIAP , 2002 .[ .Many scientific communities have expressed a growing interest in machine learning algorithms recently , mainly due to the generally good results they provide , compared to traditional statistical or AI approaches .", "label": "", "metadata": {}}
{"text": "We thus present in this paper a new machine learning software library in which most state - of - the - art algorithms have already been implemented and are available in a unified framework , in order for scientists to be able to use them , compare them , and even extend them .More interestingly , this library is freely available under a BSD license and can be retrieved on the web by everyone . Q. Le and S. Bengio .Hybrid generative - discriminative models for speech and speaker recognition .Technical Report IDIAP - RR 02 - 06 , IDIAP , 2002 .", "label": "", "metadata": {}}
{"text": "Generative probability models such as Hidden Markov Models are usually used for modeling sequences of data because of their ability to handle variable size sequences and missing information .On the other hand , because of their discriminative properties , discriminative models like Support Vector Machines ( SVMs ) usually yield better performance in classification problem and can construct flexible decision boundaries .An ideal classifier should have all the power of these two complementary approaches .A series of recent papers has suggested some techniques for mixing generative models and discriminative models .In one of them a fixed size vector ( the Fisher score ) containing sufficient statistics of a sequence is computed for a previously trained HMM and can then be used as input to a discriminative model for classification .", "label": "", "metadata": {}}
{"text": "F. Por\u00e9e , J. Mari\u00e9thoz , S. Bengio , and F. Bimbot .The BANCA database and experimental protocol for speaker verification .Technical Report IDIAP - RR 02 - 13 , IDIAP , 2002 .[ .Identity verification has become a very important research topic recently , particularly using methods based on the face or the voice of the individuals .In the context of the BANCA european project , a novel multi - modal database was recently recorded , spanning 5 european languages , 2 modalities ( face and voice ) , 2 microphones , 2 cameras and almost 300 individuals .", "label": "", "metadata": {}}
{"text": "Transforming the feature vectors to improve HMM based cursive word recognition systems .Technical Report IDIAP - RR 02 - 32 , IDIAP , 2002 .[ .Although many Offline Cursive Word Recognition systems are based on HMMs , no attention was ever paid , to our knowledge , to the fact that the feature vectors are typically not in the most suitable form for modeling .They are most of the time correlated and embedded in a space of dimension higher than their Intrinsic Dimension .This leads to several problems and has a negative influence on the performance .", "label": "", "metadata": {}}
{"text": "In this work , we used Principal Component Analysis ( linear and nonlinear ) and Independent Component Analysis .A reduction of the error rate by up to 30.3 % ( over single writer data ) and 16.2 % ( over multiple writer samples ) is shown to be achieved .K. Weber , S. Bengio , and H. Bourlard .A pragmatic view of the application of HMM2 for ASR .Technical Report IDIAP - RR 01 - 23 , IDIAP , 2001 .[ .This report investigates the HMM2 approach recently introduced in the framework of automatic speech recognition .", "label": "", "metadata": {}}
{"text": "The application of HMM2 to the speech signal is motivated by numerous potential advantages .However , speech recognition results did not show the expected performance improvements .In this paper , the HMM2 approach is pragmatically analyzed and evaluated on speech data , revealing some problems and suggesting potential solutions .S. Bengio , H. Bourlard , and K. Weber .An EM algorithm for HMMs with emission distributions represented by HMMs .Technical Report IDIAP - RR 00 - 11 , IDIAP , Martigny , Switzerland , 2000 .[ .A novel approach to represent emission distributions of Hidden Markov Models is presented in this paper .", "label": "", "metadata": {}}
{"text": "This representation , referred here as HMM 2 , could enable the model to more accurately represent feature correlations with fewer parameters than standard HMMs .A full derivation of an EM algorithm is given in order to globally train all the HMM 2 parameters .Preliminary experiments on speech data show promising results .R. Collobert and S. Bengio .On the convergence of SVMTorch , an algorithm for large - scale regression problems .Technical Report IDIAP - RR 00 - 24 , IDIAP , Martigny , Switzerland , 2000 .[ .Recently , many researchers have proposed decomposition algorithms for SVM regression problems .", "label": "", "metadata": {}}
{"text": "This convergence proof is in fact mainly based on the convergence proof given by Keerthi and Gilbert for their SVM classification algorithm .R. Collobert and S. Bengio .Support vector machines for large - scale regression problems .Technical Report IDIAP - RR 00 - 17 , IDIAP , Martigny , Switzerland , 2000 .[ .Support Vector Machines ( SVMs ) for regression problems are trained by solving a quadratic optimization problem which needs on the order of l 2 memory and time resources to solve , where l is the number of training examples . , which is similar to SVM - Light proposed by Joachims for classification problems , but adapted to regression problems .", "label": "", "metadata": {}}
{"text": "Comparisons with Nodelib , another SVM algorithm for large - scale regression problems from Flake and Lawrence yielded significant time improvements .S. Bengio , G. Brassard , Y. Desmedt , C. Goutier , and J.-J. Quisquater .Aspects and importance of secure implementations of identification systems .Technical Report Manuscript M209 , Philips Research Laboratory , Brussel , Belgium , 1987 .S. Bengio and C. Frasson .Utilisation d'EAO dans des syst\u00e8mes d'EIAO .Technical Report 651 , D\u00e9partement d'Informatique et de Recherche Op\u00e9rationnelle , Universit\u00e9 de Montr\u00e9al , Montreal ( QC ) Canada , 1988 . A. Gravey , S. Bengio , D. Collobert , and F. Clerot .", "label": "", "metadata": {}}
{"text": "Technical Report NT / LAA / EIA/132 , France T\u00e9l\u00e9com CNET , Lannion , France , 1996 .J.-Y. Potvin and S. Bengio .A genetic based heuristic for the vehicle routing problem with time windows .Technical Report CRT-953 , Centre de Recherche sur les Transports , Universit\u00e9 de Montr\u00e9al , 1994 .S. Bengio .An asynchronous hidden markov model for audio - visual speech recognition .In S. Becker , S. Thrun , and K. Obermayer , editors , Advances in Neural Information Processing Systems , NIPS 15 , pages 1237 - 1244 .MIT Press , 2003 .", "label": "", "metadata": {}}
{"text": "This paper presents a novel Hidden Markov Model architecture to model the joint probability of pairs of asynchronous sequences describing the same event .It is based on two other Markovian models , namely Asynchronous Input / Output Hidden Markov Models and Pair Hidden Markov Models .An EM algorithm to train the model is presented , as well as a Viterbi decoder that can be used to obtain the optimal state sequence as well as the alignment between the two sequences .The model has been tested on an audio - visual speech recognition task using the M2VTS database and yielded robust performances under various noise conditions .", "label": "", "metadata": {}}
{"text": "Multimodal speech processing using asynchronous hidden markov models .Information Fusion , 5(2):81 - 89 , 2004 .[ .This paper advocates that for some multimodal tasks involving more than one stream of data representing the same sequence of events , it might sometimes be a good idea to be able to desynchronize the streams in order to maximize their joint likelihood .We thus present a novel Hidden Markov Model architecture to model the joint probability of pairs of asynchronous sequences describing the same sequence of events .An Expectation - Maximization algorithm to train the model is presented , as well as a Viterbi decoding algorithm , which can be used to obtain the optimal state sequence as well as the alignment between the two sequences .", "label": "", "metadata": {}}
{"text": "Robust performances under various noise conditions were obtained in both cases . S. Bengio .Statistical machine learning for HCI .In J.-P. Thiran , F. Marqu\u00e9s , and H. Bourlard , editors , Multimodal Signal Processing : Theory and Applications for Human - Computer Interaction , pages 7 - 23 .Academic Press , 2010 .This chapter introduces the main concepts of statistical machine learning , as they are pivot in most algorithms tailored for multimodal signal processing .In particular , the chapter will cover a general introduction to machine learning and how it is used in classification , regression and density estimation .", "label": "", "metadata": {}}
{"text": "S. Bengio and Y. Bengio .An EM algorithm for asynchronous input / output hidden markov models .In Proceedings of the International Conference on Neural Information Processing , ICONIP , Hong Kong , 1996 .[ .In learning tasks in which input sequences are mapped to output sequences , it is often the case that the input and output sequences are not synchronous .For example , in speech recognition , acoustic sequences are longer than phoneme sequences .Input / Output Hidden Markov Models have already been proposed to represent the distribution of an output sequence given an input sequence of the same length .", "label": "", "metadata": {}}
{"text": "S. Bengio , H. Bourlard , and K. Weber .An EM algorithm for HMMs with emission distributions represented by HMMs .Technical Report IDIAP - RR 00 - 11 , IDIAP , Martigny , Switzerland , 2000 .[ .A novel approach to represent emission distributions of Hidden Markov Models is presented in this paper .Whereas they are usually estimated with Gaussian mixtures or neural networks , we propose to estimate them with another HMM , but in feature space .This representation , referred here as HMM 2 , could enable the model to more accurately represent feature correlations with fewer parameters than standard HMMs .", "label": "", "metadata": {}}
{"text": "Preliminary experiments on speech data show promising results .S. Bengio and J. Keshet .Introduction .In J. Keshet and S. Bengio , editors , Automatic Speech and Speaker Recognition : Large Margin and Kernel Methods , pages 3 - 10 .Wiley , 2009 .One of the most natural communication tools used by humans is their voice .It is hence natural that a lot of research has been devoted to analyzing and understanding human uttered speech for various applications .The most obvious one is automatic speech recognition , where the goal is to transcribe a recorded speech utterance into its corresponding sequence of words .", "label": "", "metadata": {}}
{"text": "The aim of this book is to introduce the speech researcher community to radically different approaches based on more recent kernel based machine learning methods . Y. Bengio and S. Bengio .Training asynchronous input / output hidden markov models .In AAAI Spring Symposium on Computational Issues in Learning Models of Dynamical Systems , 1996 .[ . djvu ] . H. Bourlard and S. Bengio .Hidden markov models and other finite state automata for sequence processing .In Michael A. Arbib , editor , The Handbook of Brain Theory and Neural Networks , Second Edition .The MIT Press , 2002 .", "label": "", "metadata": {}}
{"text": "Towards using hierarchical posteriors for flexible automatic speech recognition systems .In Proceedings of the DARPA EARS ( Effective , Affordable , Reusable , Speech - to - text ) Rich Transcription ( RT'04 )Workshop , 2004 .[ .Local state ( or phone ) posterior probabilities are often investigated as local classifiers ( e.g. , hybrid HMM / ANN systems ) or as transformed acoustic features ( e.g. , \" Tandem \" ) towards improved speech recognition systems .Initial results on several speech ( as well as other multimodal ) tasks resulted in significant improvements .", "label": "", "metadata": {}}
{"text": "New approaches towards robust and adaptive speech recognition .In T.K. Leen , T.G. Dietterich , and V. Tresp , editors , Advances in Neural Information Processing Systems , NIPS 13 , pages 751 - 757 .MIT Press , 2001 .[ .In this paper , we discuss some new research directions in automatic speech recognition ( ASR ) , and which somewhat deviate from the usual approaches .More specifically , we will motivate and briefly describe new approaches based on multi - stream and multi / band ASR .As a further extension to multi - stream ASR , we will finally introduce a new approach , referred to as HMM2 , where the HMM emission probabilities are estimated via state specific feature based HMMs responsible for merging the stream information and modeling their possible correlation . H. Bourlard , S. Bengio , and K. Weber .", "label": "", "metadata": {}}
{"text": "In M. Johnson , S. Khudanpur , M. Ostendorf , and R. Rosenfeld , editors , Mathematical Foundations of Speech and Language Processing , Institute for Mathematics and its Applications ( IMA ) Series , Volume 138 , pages 169 - 189 .Springer - Verlag , 2003 .[ .In this paper , we discuss a family of new Automatic Speech Recognition ( ASR ) approaches , which somewhat deviate from the usual ASR approaches but which have recently been shown to be more robust to nonstationary noise , without requiring specific adaptation or \" multi - style \" training .", "label": "", "metadata": {}}
{"text": "As a further extension to multi - stream ASR , we will finally introduce a new approach , referred to as HMM2 , where the HMM emission probabilities are estimated via state specific feature based HMMs responsible for merging the stream information and modeling their possible correlation . F. de Wet , K. Weber , L. Boves , B. Cranen , S. Bengio , and H. Bourlard .Evaluation of formant - like features for automatic speech recognition .Journal of the Acoustical Society of America ( JASA ) , 116(3):1781 - 1792 , 2004 .[ .This study investigates possibilities to find a low - dimensional , formant - related physical representation of speech signals , which is suitable for automatic speech recognition .", "label": "", "metadata": {}}
{"text": "Combinations of automatically extracted formant - like features and state - of - the - art , noise - robust features have previously been shown to be more robust in adverse conditions than state - of - the - art features alone .However , it is not clear how these automatically extracted formant - like features behave in comparison with true formants .The purpose of this paper is to investigate two methods to automatically extract formant - like features , i.e. robust formants and HMM2 features , and to compare these features to hand - labeled formants as well as to mel - frequency cepstral coefficients in terms of their performance on a vowel classification task .", "label": "", "metadata": {}}
{"text": ", J. Acoust .Soc .Am .97 , 3099 - 3111 ( 1995)].Classification performance was measured on the original , clean data as well as in ( simulated ) adverse conditions .In combination with standard automatic speech recognition methods , the classification performance of the robust formant and HMM2 features compare very well to the performance of the hand - labeled formants .C. Dimitrakakis and S. Bengio .Boosting HMMs with an application to speech recognition .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 5 , pages 621 - 624 , 2004 .", "label": "", "metadata": {}}
{"text": "Boosting is a general method for training an ensemble of classifiers with a view to improving performance relative to that of a single classifier .While the original AdaBoost algorithm has been defined for classification tasks , the current work examines its applicability to sequence learning problems .In particular , different methods for training HMMs on sequences and for combining their output are investigated in the context of automatic speech recognition .C. Dimitrakakis and S. Bengio .Boosting word error rates .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , pages 501 - 504 , 2005 .", "label": "", "metadata": {}}
{"text": "We apply boosting techniques to the problem of word error rate minimisation in speech recognition .This is achieved through a new definition of sample error for boosting and a training procedure for hidden Markov models .For this purpose we define a sample error for sentence examples related to the word error rate .Furthermore , for each sentence example we define a probability distribution in time that represents our belief that an error has been made at that particular frame .This is used to weigh the frames of each sentence in the boosting framework .We present preliminary results on the well - known Numbers 95 database that indicate the importance of this temporal probability distribution .", "label": "", "metadata": {}}
{"text": "Phoneme and sentence - level ensembles for speech recognition .EURASIP Journal on Audio , Speech , and Music Processing , 2011 , 2011 .[ .We address the question of whether and how boosting and bagging can be used for speech recognition .In order to do this , we compare two different boosting schemes , one at the phoneme level and one at the utterance level , with a phoneme - level bagging scheme .We control for many parameters and other choices , such as the state inference scheme used .In an unbiased experiment , we clearly show that the gain of boosting methods compared to a single hidden Markov model is in all cases only marginal , while bagging significantly outperforms all other methods .", "label": "", "metadata": {}}
{"text": "M. Magimai Doss , S. Bengio , and H. Bourlard .Joint decoding for phoneme - grapheme continuous speech recognition .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 1 , pages 177 - 180 , 2004 .[ .Standard ASR systems typically use phoneme as the subword units .Preliminary studies have shown that the performance of the ASR system could be improved by using grapheme as additional subword units .In this paper , we investigate such a system where the word models are defined in terms of two different subword units , i.e. , phoneme and grapheme .", "label": "", "metadata": {}}
{"text": "We have studied this system for a continuous speech recognition task in American English language .Our studies show that grapheme information used along with phoneme information improves the performance of ASR .M. Magimai Doss , T. A. Stephenson , H. Bourlard , and S. Bengio .Phoneme - grapheme based speech recognition system .In IEEE Automatic Speech Recognition and Understanding Workshop , ASRU , pages 94 - 98 , 2003 .[ .State - of - the - art ASR systems typically use phoneme as the subword units .In this paper , we investigate a system where the word models are defined in - terms of two different subword units , i.e. , phonemes and graphemes .", "label": "", "metadata": {}}
{"text": "We have studied this system for American English language where there is weak correspondence between the grapheme and phoneme .The results from our studies show that there is good potential in using grapheme as auxiliary subword units . D. Grangier and S. Bengio .Learning the inter - frame distance for discriminative template - based keyword detection .In Proceedings of the 10th European Conference on Speech Communication and Technology , Eurospeech - Interspeech , 2007 .[ .This paper proposes a discriminative approach to template - based keyword detection .We introduce a method to learn the distance used to compare acoustic frames , a crucial element for template matching approaches .", "label": "", "metadata": {}}
{"text": "The experiments performed over a large corpus , SpeechDatII , suggest that our model is effective compared to an HMM system , e.g. the proposed approach reaches 93.8 % of averaged AUC compared to 87.9 % for the HMM .D. Grangier , J. Keshet , and S. Bengio .Discriminative keyword spotting .In J. Keshet and S. Bengio , editors , Automatic Speech and Speaker Recognition : Large Margin and Kernel Methods , pages 175 - 194 .Wiley , 2009 .This chapter introduces a discriminative method for detecting and spotting keywords in spoken utterances .Given a word represented as a sequence of phonemes and a spoken utterance , the keyword spotter predicts the best time span of the phoneme sequence in the spoken utterance along with a confidence .", "label": "", "metadata": {}}
{"text": "The problem of keyword spotting training is formulated as a discriminative task where the model parameters are chosen so the utterance in which the keyword is spoken would have higher confidence than any other spoken utterance in which the keyword is not spoken .It is shown theoretically and empirically that the proposed training method resulted with a high area under the Receiver Operating Characteristic ( ROC ) curve , the most common measure to evaluate keyword spotters .We present an iterative algorithm to train the keyword spotter efficiently .The proposed approach contrasts with standard spotting strategies based on Hidden Markov Models ( HMMs ) , for which the training procedure does not maximize a loss directly related to the spotting performance .", "label": "", "metadata": {}}
{"text": "G. Heigold , I. Moreno , S. Bengio , and N. Shazeer .End - to - end text - dependent speaker verification .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2016 . [ .In this paper we present a data - driven , integrated approach to speaker verification , which maps a test utterance and a few reference utterances directly to a single score for verification and jointly optimizes the system 's components using the same evaluation protocol and metric as at test time .Such an approach will result in simple and efficient systems , requiring little domain - specific knowledge and making few model assumptions .", "label": "", "metadata": {}}
{"text": "The proposed approach appears to be very effective for big data applications like ours that require highly accurate , easy - to - maintain systems with a small footprint .J. Keshet and S. Bengio , editors .Automatic Speech and Speaker Recognition : Large Margin and Kernel Methods .Wiley , 2009 .This is the first book dedicated to uniting research related to speech and speaker recognition based on the recent advances in large margin and kernel methods .The first part of the book presents theoretical and practical foundations of large margin and kernel methods , from Support Vector Machines to large margin methods for structured learning .", "label": "", "metadata": {}}
{"text": "The third part introduces large margin methods for discriminative language modeling .The last part of the book is dedicated to the application of keyword spotting , speaker verification and spectral clustering .The book is an important reference to researchers and practitioners in the field of modern speech and speaker recognition .The purpose of the book is twofold : first , to set the theoretical foundation of large margin and kernel methods relevant to the speech recognition domain ; second , to propose a practical guide on implementation of these methods to the speech recognition domain .The reader is presumed to have basic knowledge of large margin and kernel methods and of basic algorithms in speech and speaker recognition .", "label": "", "metadata": {}}
{"text": "Discriminative keyword spotting .In ISCA Research Workshop on Non Linear Speech Processing , NOLISP , 2007 .[ .This paper proposes a new approach for keyword spotting , which is not based on HMMs .The proposed method employs a new discriminative learning procedure , in which the learning phase aims at maximizing the area under the ROC curve , as this quantity is the most common measure to evaluate keyword spotters .The keyword spotter we devise is based on non - linearly mapping the input acoustic representation of the speech utterance along with the target keyword into an abstract vector space .", "label": "", "metadata": {}}
{"text": "We describe a simple iterative algorithm for learning the keyword spotter and discuss its formal properties .Experiments with the TIMIT corpus show that our method outperforms the conventional HMM - based approach .J. Keshet , D. Grangier , and S. Bengio .Discriminative keyword spotting .Speech Communication , 51:317 - 329 , 2009 .[ .This paper proposes a new approach for keyword spotting , which is based on large margin and kernel methods rather than on HMMs .Unlike previous approaches , the proposed method employs a discriminative learning procedure , in which the learning phase aims at achieving a high area under the ROC curve , as this quantity is the most common measure to evaluate keyword spotters .", "label": "", "metadata": {}}
{"text": "Building on techniques used for large margin and kernel methods for predicting whole sequences , our keyword spotter distills to a classifier in this vector - space , which separates speech utterances in which the keyword is uttered from speech utterances in which the keyword is not uttered .We describe a simple iterative algorithm for training the keyword spotter and discuss its formal properties , showing theoretically that it attains high area under the ROC curve .Experiments on read speech with the TIMIT corpus show that the resulted discriminative system outperforms the conventional context - independent HMM - based system .", "label": "", "metadata": {}}
{"text": "J. Keshet , S. Shalev - Shwartz , S. Bengio , Y. Singer , and D. Chazan .Discriminative kernel - based phoneme sequence recognition .In Proceedings of the International Conference on Spoken Language Processing , Interspeech - ICSLP , 2006 .[ .We describe a new method for phoneme sequence recognition given a speech utterance , which is not based on the HMM .In contrast to HMM - based approaches , our method uses a discriminative kernel - based training procedure in which the learning process is tailored to the goal of minimizing the Levenshtein distance between the predicted phoneme sequence and the correct sequence .", "label": "", "metadata": {}}
{"text": "Building on large margin techniques for predicting whole sequences , we are able to devise a learning algorithm which distills to separating the correct phoneme sequence from all other sequences .We describe an iterative algorithm for learning the phoneme sequence recognizer and further describe an efficient implementation of it .We present initial encouraging experimental results with the TIMIT and compare the proposed method to an HMM - based approach . H. Ketabdar , H. Bourlard , and S. Bengio .Hierarchical multi - stream posterior based speech recognition system .In Machine Learning for Multimodal Interactions : Second International Workshop , MLMI , Lecture Notes in Computer Science , volume LNCS 3869 , 2005 . [ .", "label": "", "metadata": {}}
{"text": "This approach provides a new , principled , theoretical framework for hierarchical estimation / use of posteriors , multi - stream feature combination , and integrating appropriate context and prior knowledge in posterior estimates .In the present work , we used the resulting gamma posteriors as features for a standard HMM / GMM layer .On the OGI Digits database and on a reduced vocabulary version ( 1000 words ) of the DARPA Conversational Telephone Speech - to - text ( CTS ) task , this resulted in significant performance improvement , compared to the state - of - the - art Tandem systems . H. Ketabdar , J. Vepa , S. Bengio , and H. Bourlard .", "label": "", "metadata": {}}
{"text": "In Proceedings of the 9th European Conference on Speech Communication and Technology , Eurospeech - Interspeech , 2005 . [ .Local state or phone posterior probabilities are often investigated as local scores ( e.g. , hybrid HMM / ANN systems ) or as transformed acoustic features ( e.g. , \" Tandem \" ) to improve speech recogni tion systems .In this paper , we present initial results towards boosting these approaches by improving posterior estimat es , using acoustic context ( e.g. , as available in the whole utterance ) , as well as possible prior information ( such as topological constraints ) .", "label": "", "metadata": {}}
{"text": "In the present work , we used the resulting posteriors as local scores in a Viter bi decoder .On the OGI Numbers'95 database , this resulted in improved recognition performance , compared to a state - of - the - art hybrid HMM / ANN system . H. Ketabdar , J. Vepa , S. Bengio , and H. Bourlard .Posterior based keyword spotting with a priori thresholds .In Proceedings of the International Conference on Spoken Language Processing , Interspeech - ICSLP , 2006 .[ .In this paper , we propose a new posterior based scoring approach for keyword and non keyword ( garbage ) elements .", "label": "", "metadata": {}}
{"text": "The state posteriors are then integrated into keyword and garbage posteriors for every frame .These posteriors are used to make a decision on detection of the keyword at each frame .The frame level decisions are then accumulated ( in this case , by counting ) to make a global decision on having the keyword in the utterance .In this way , the contribution of possible outliers are minimized , as opposed to the conventional Viterbi decoding approach which accumulates likelihoods .Experiments on keywords from the Conversational Telephone Speech ( CTS ) and Numbers'95 databases are reported .", "label": "", "metadata": {}}
{"text": "Using more informative posterior probabilities for speech recognition .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2006 .[ .In this paper , we present initial investigations towards boosting posterior probability based speech recognition systems by estimating more informative posteriors taking into account acoustic context ( e.g. , the whole utterance ) , as well as possible prior information ( such as phonetic and lexical knowledge ) .These posteriors are estimated based on HMM state posterior probability definition ( typically used in standard HMMs training ) .This approach provides a new , principled , theoretical framework for hierarchical estimation / use of more informative posteriors integrating appropriate context and prior knowledge .", "label": "", "metadata": {}}
{"text": "On the OGI numbers database , this resulted in significant performance improvement , compared to using MLP estimated posteriors for decoding ( hybrid HMM / ANN approach ) for clean and more specially for noisy speech .The system is also shown to be much less sensitive to tuning factors ( such as phone deletion penalty , language model scaling ) compared to the standard HMM / ANN and HMM / GMM systems , thus practically it does not need to be tuned to achieve the best possible performance .J. Mari\u00e9thoz , S. Bengio , and Y. Grandvalet .", "label": "", "metadata": {}}
{"text": "In J. Keshet and S. Bengio , editors , Automatic Speech and Speaker Recognition : Large Margin and Kernel Methods , pages 195 - 220 .Wiley , 2009 .The goal of a person authentication system is to certify / attest the claimed identity of a user .When this authentication is based on the voice of the user , without respect to what the user exactly said , the system is called a text - independent speaker verification system .Speaker verification systems are increasingly often used to secure personal information , particularly for mobile phone based applications .", "label": "", "metadata": {}}
{"text": "The most common approach to this task is based on Gaussian Mixture Models ( GMMs ) ( Reynolds et al .2000 ) , which do not take into account any temporal information .GMMs have been intensively used thanks to their good performance , especially with the use of the Maximum a posteriori ( MAP ) ( Gauvain and Lee 1994 ) adaptation algorithm .This approach is based on the density estimation of an impostor data distribution , followed by its adaptation to a specific client data set .Note that the estimation of these densities is not the final goal of speaker verification systems , which is rather to discriminate the client and impostor classes ; hence discriminative approaches might appear good candidates for this task as well .", "label": "", "metadata": {}}
{"text": "In order to use SVMs or any other discriminant approaches for speaker verification , several modifications of the classical techniques need to be performed .The purpose of this chapter is to present an overview of discriminant approaches that have been used successfully for the task of text - independent speaker verification , to analyze their differences from and their similarities to each other and to classical generative approaches based on GMMs .T. A. Stephenson , H. Bourlard , S. Bengio , and A. C. Morris .Automatic speech recognition using dynamic Bayesian networks with both acoustic and articulatory variables .", "label": "", "metadata": {}}
{"text": "[ .Current technology for automatic speech recognition ( ASR ) uses hidden Markov models ( HMMs ) that recognize spoken speech using the acoustic signal .However , no use is made of the causes of the acoustic signal : the articulators .We present here a dynamic Bayesian network ( DBN ) model that utilizes an additional variable for representing the state of the articulators .A particular strength of the system is that , while it uses measured articulatory data during its training , it does not need to know these values during recognition .As Bayesian networks are not used often in the speech community , we give an introduction to them .", "label": "", "metadata": {}}
{"text": "Recognition results are given , showing that a system with both acoustics and inferred articulatory positions performs better than a system with only acoustics .K. Weber , S. Bengio , and H. Bourlard .HMM2- a novel approach to HMM emission probability estimation .In Proceedings of the International Conference on Speech and Language Processing , ICSLP , Beijing , China , October 2000 .[ .In this paper , we discuss and investigate a new method to estimate local emission probabilities in the framework of hidden Markov models ( HMM ) .Each feature vector is considered to be a sequence and is supposed to be modeled by yet another HMM .", "label": "", "metadata": {}}
{"text": "There is a variety of possible topologies of such HMM2 systems , e.g. incorporating trellis or ergodic HMM structures .Preliminary HMM2 speech recognition experiments on cepstral and spectral features yielded worse results than state - of - the - art systems .However , we believe that HMM2 systems have a lot of potential advantages and are therefore worth investigating further .K. Weber , S. Bengio , and H. Bourlard .HMM2- extraction of formant features and their use for robust ASR .In Proceedings of the European Conference on Speech Communication and Technology , EUROSPEECH , 2001 .", "label": "", "metadata": {}}
{"text": "As recently introduced , an HMM2 can be considered as a particular case of an HMM mixture in which the HMM emission probabilities ( usually estimated through Gaussian mixtures or an artificial neural network ) are modeled by state - dependent , feature - based HMM ( referred to as frequency HMM ) .A general EM training algorithm for such a structure has already been developed .While the fact that this architecture is able to automatically extract meaningful formant information is interesting by itself , empirical results will also show the robustness of these features to noise , and their potential to enhance state - of - the - art noise - robust HMM - based ASR .", "label": "", "metadata": {}}
{"text": "A pragmatic view of the application of HMM2 for ASR .Technical Report IDIAP - RR 01 - 23 , IDIAP , 2001 .[ .This report investigates the HMM2 approach recently introduced in the framework of automatic speech recognition .HMM2 can be seen as a mixture of HMMs , where a conventional primary HMM ( processing a time series of speech data ) is supported on a lower level by a secondary HMM , working along the frequency dimension of a temporal segment of speech .The application of HMM2 to the speech signal is motivated by numerous potential advantages .", "label": "", "metadata": {}}
{"text": "In this paper , the HMM2 approach is pragmatically analyzed and evaluated on speech data , revealing some problems and suggesting potential solutions .K. Weber , S. Bengio , and H. Bourlard .Speech recognition using advanced HMM2 features .In Proceedings of the Automatic Speech Recognition and Understanding Workshop , ASRU , pages 65 - 68 , 2001 .[ .HMM2 is a particular hidden Markov model where state emission probabilities of the temporal ( primary ) HMM are modeled through ( secondary ) state - dependent frequency - based HMMs .As shown previously , a secondary HMM can also be used to extract robust ASR features .", "label": "", "metadata": {}}
{"text": "HMM2 performs a nonlinear , state - dependent frequency warping , and it is shown that the resulting frequency segmentation actually contains particularly discriminant features .To further improve the HMM2 system , we complement the initial spectral energy vectors with frequency information .Finally , adding temporal information to the HMM2 feature vector yields further improvements .These conclusions are experimentally validated on the Numbers95 database , where word error rates of 15 % , using only a 4-dimensional feature vector ( 3 formant - like parameters and one time index ) were obtained .K. Weber , S. Bengio , and H. Bourlard .", "label": "", "metadata": {}}
{"text": "In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 1 , pages 929 - 932 , 2002 .[ .The purpose of this paper is to investigate the behavior of HMM2 models for the recognition of noisy speech .It has previously been shown that HMM2 is able to model dynamically important structural information inherent in the speech signal , often corresponding to formant positions / tracks .As formant regions are known to be robust in adverse conditions , HMM2 seems particularly promising for improving speech recognition robustness .Here , we review different variants of the HMM2 approach with respect to their application to noise - robust automatic speech recognition .", "label": "", "metadata": {}}
{"text": "Evaluation of formant - like features for ASR .In Proceedings of the International Conference on Spoken Language Processing , ICSLP , 2002 .[ .This paper investigates possibilities to automatically find a low - dimensional , formant - related physical representation of the speech signal , which is suitable for automatic speech recognition ( ASR ) .This aim is motivated by the fact that formants have been shown to be discriminant features for ASR .Combinations of automatically extracted formant - like features and ' conventional ' , noise - robust , state - of - the - art features ( such as MFCCs including spectral subtraction and cepstral mean subtraction ) have previously been shown to be more robust in adverse conditions than state - of - the - art features alone .", "label": "", "metadata": {}}
{"text": "The purpose of this paper is to investigate two methods to automatically extract formant - like features , and to compare these features to hand - labeled formant tracks as well as to standard MFCCs in terms of their performance on a vowel classification task .K. Weber , S. Ikbal , S. Bengio , and H. Bourlard .Robust speech recognition and feature extraction using HMM2 .Computer , Speech and Language , 17(2 - 3):195 - 211 , 2003 .[ .This paper presents the theoretical basis and preliminary experimental results of a new HMM model , referred to as HMM2 , which can be considered as a mixture of HMMs .", "label": "", "metadata": {}}
{"text": "Thus , while the primary HMM is performing the usual time warping and integration , the secondary HMMs are responsible for extracting / modeling the possible feature dependencies , while performing frequency warping and integration .Such a model has several potential advantages , such as a more flexible modeling of the time / frequency structure of the speech signal .When working with spectral features , such a system can also perform nonlinear spectral warping , effectively implementing a form of nonlinear vocal tract normalization .Furthermore , it will be shown that HMM2 can be used to extract noise robust features , supposed to correspond to formant regions , which can be used as extra features for traditional HMM recognizers to improve their performance .", "label": "", "metadata": {}}
{"text": "The BANCA database and evaluation protocol .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 625 - 638 .Springer - Verlag , 2003 .[ .In this paper we describe the acquistion and content of a new large , realistic and challenging multi - modal database intended for training and testing multi - modal verification systems .The BANCA database was captured in four European languages in two modalities ( face and voice ) .For recording , both high and low quality microphones and cameras were used .", "label": "", "metadata": {}}
{"text": "In total 208 people were captured , half men and half women .In this paper we also describe a protocol for evaluating verification algorithms on the database .M. Barnard , J.-M. Odobez , and S. Bengio .Multi - modal audio - visual event recognition for football analysis .In IEEE Workshop on Neural Networks for Signal Processing , NNSP , pages 469 - 478 , 2003 .[ .The recognition of events within multi - modal data is a challenging problem .In this paper we focus on the recognition of events by using both audio and video data .", "label": "", "metadata": {}}
{"text": "Specifically we look at the recognition of play and break sequences in football and the segmentation of football games based on these two events .Recognising relatively simple semantic events such as this is an important step towards full automatic indexing of such video material .These experiments were done using approximately 3 hours of data from two games of the Euro96 competition .We propose that modelling the audio and video streams separately for each sequence and fusing the decisions from each stream should yield an accurate and robust method of segmenting multi - modal data .S. Bengio .", "label": "", "metadata": {}}
{"text": "In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 770 - 777 .Springer - Verlag , 2003 .[ .It has often been shown that using multiple modalities to authenticate the identity of a person is more robust than using only one .Various combination techniques exist and are often performed at the level of the output scores of each modality system .In this paper , we present a novel HMM architecture able to model the joint probability distribution of pairs of asynchronous sequences ( such as speech and video streams ) describing the same event .", "label": "", "metadata": {}}
{"text": "Results on the M2VTS database show robust performances of the system under various audio noise conditions , when compared to other state - of - the - art techniques .S. Bengio .Multimodal speech processing using asynchronous hidden markov models .Information Fusion , 5(2):81 - 89 , 2004 .[ .This paper advocates that for some multimodal tasks involving more than one stream of data representing the same sequence of events , it might sometimes be a good idea to be able to desynchronize the streams in order to maximize their joint likelihood .We thus present a novel Hidden Markov Model architecture to model the joint probability of pairs of asynchronous sequences describing the same sequence of events .", "label": "", "metadata": {}}
{"text": "The model was tested on two audio - visual speech processing tasks , namely speech recognition and text - dependent speaker verification , both using the M2VTS database .Robust performances under various noise conditions were obtained in both cases . S. Bengio .Statistical machine learning for HCI .In J.-P. Thiran , F. Marqu\u00e9s , and H. Bourlard , editors , Multimodal Signal Processing : Theory and Applications for Human - Computer Interaction , pages 7 - 23 .Academic Press , 2010 .This chapter introduces the main concepts of statistical machine learning , as they are pivot in most algorithms tailored for multimodal signal processing .", "label": "", "metadata": {}}
{"text": "Following this introduction , two particularly well known models will be presented , together with their associated learning algorithm : support vector machines , which are well - known for classification tasks , and hidden Markov models , which are tailored for sequence processing tasks such as speech recognition .S. Bengio and H. Bourlard , editors .Machine Learning for Multimodal Interaction : First International Workshop , MLMI'2004 .volume 3361 of Lecture Notes in Computer Science .Springer - Verlag , 2005 . [ .This book contains a selection of refereed papers presented at the First Workshop on Machine Learning for Multimodal Interaction ( MLMI'04 ) , held in Martigny , Switzerland , from June 21 - 23 , 2004 .", "label": "", "metadata": {}}
{"text": "It brings together researchers from different communities working around the common theme of advanced machine learning algorithms for processing and structuring multimodal human interaction in meetings .The motivation for creating such forum , which could be perceived as a number of papers from different research disciplines , evolved from an actual need that arose from these projects and the strong motivation of their partners for such a multi - disciplinary workshop .The conference program covered a wide range of areas related to machine learning applied to multimodal interaction - and more specifically to multi - modal meeting processing .", "label": "", "metadata": {}}
{"text": "Multi channel sequence processing .In J. Winkler , M. Niranjan , and N. Lawrence , editors , Deterministic and Statistical Methods in Machine Learning : First International Workshop , Lecture Notes in Artificial Intelligence , volume LNAI 3635 , pages 22 - 36 .Springer - Verlag , 2005 . [ .This paper summarizes some of the current research challenges arising from multi - channel sequence processing .Indeed , multiple real life applications involve simultaneous recording and analysis of multiple information sources , which may be asynchronous , have different frame rates , exhibit different stationarity properties , and carry complementary ( or correlated ) information .", "label": "", "metadata": {}}
{"text": "However , several challenging research issues are still open , such as taking into account asynchrony and correlation between several feature streams , or handling the underlying growing complexity .In this framework , we discuss here two novel approaches , which recently started to be investigated with success in the context of large multimodal problems .These include the asynchronous HMM , providing a principled approach towards the processing of multiple feature streams , and the layered HMM approach , providing a good formalism for decomposing large and complex ( multi - stream ) problems into layered architectures .", "label": "", "metadata": {}}
{"text": "S. Bengio , C. Marcel , S. Marcel , and J. Mari\u00e9thoz .Confidence measures for multimodal identity verification .Information Fusion , 3(4):267 - 276 , 2002 .[ .Multimodal fusion for identity verification has already shown great improvement compared to unimodal algorithms .In this paper , we propose to integrate confidence measures during the fusion process .We present a comparison of three different methods to generate such confidence information from unimodal identity verification systems .These methods can be used either to enhance the performance of a multimodal fusion algorithm or to obtain a confidence level on the decisions taken by the system .", "label": "", "metadata": {}}
{"text": "Results show that some confidence measures did improve statistically significantly the performance , while other measures produced reliable confidence levels over the fusion decisions .J. Czyz , S. Bengio , C. Marcel , and L. Vandendorpe .Scalability analysis of audio - visual person identity verification .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 752 - 760 .Springer - Verlag , 2003 .[ .In this work , we present a multimodal identity verification system based on the fusion of the face image and the text independent speech data of a person .", "label": "", "metadata": {}}
{"text": "In order to assess the authentication system at different scales , the performance is evaluated at various sizes of the face and speech user template .The user template size is a key parameter when the storage space is limited like in a smart card .Our experimental results show that the multimodal fusion allows to reduce significantly the user template size while keeping a satisfactory level of performance .Experiments are performed on the newly recorded multimodal database BANCA .D. Gatica - Perez , I. McCowan , M. Barnard , S. Bengio , and H. Bourlard .On automatic annotation of meeting databases .", "label": "", "metadata": {}}
{"text": "[ .In this paper , we discuss meetings as an application domain for multimedia content analysis .Meeting databases are a rich data source suitable for a variety of audio , visual and multi - modal tasks , including speech recognition , people and action recognition , and information retrieval .We specifically focus on the task of semantic annotation of audio - visual ( AV ) events , where annotation consists of assigning labels ( event names ) to the data .In order to develop an automatic annotation system in a principled manner , it is essential to have a well - defined task , a standard corpus and an objective performance measure .", "label": "", "metadata": {}}
{"text": "Extracting information from multimedia meeting collections .In 7th ACM SIGMM International Workshop on Multimedia Information Retrieval , MIR , 2005 . [ .In this paper , we present a succint overview of recent approaches in this field , largely influenced by our own experiences .We first review some of the existing and potential needs for users of multimedia meeting information systems .We then summarize recent work on various research areas addressing some of these requirements .In more detail , we describe our work on automatic analysis of human interaction patterns from audio - visual sensors , discussing open issues in this domain . D. Gatica - Perez , I. McCowan D. Zhang , and S. Bengio .", "label": "", "metadata": {}}
{"text": "In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , pages 489 - 492 , 2005 .[ .Finding relevant segments in meeting recordings is important for summarization , browsing , and retrieval purposes .In this paper , we define relevance as the interest - level that meeting participants manifest as a group during the course of their interaction ( as perceived by an external observer ) , and investigate the automatic detection of segments of high - interest from audio - visual cues .This is motivated by the assumption that there is a relationship between segments of interest to participants , and those of interest to the end user , e.g. of a meeting browser .", "label": "", "metadata": {}}
{"text": "On a 50-meeting corpus , recorded in a room equipped with multiple cameras and microphones , we found that the annotations generated by multiple people exhibit a good degree of consistency , providing a stable ground - truth for automatic methods .For the automatic detection of high - interest segments , we investigate a methodology based on Hidden Markov Models ( HMMs ) and a number of audio and visual features .Single- and multi - stream approaches were studied .Using precision and recall as performance measures , the results suggest that ( i ) the automatic detection of group interest - level is promising , and ( ii ) while audio in general constitutes the predominant modality in meetings , the use of a multi - modal approach is beneficial .", "label": "", "metadata": {}}
{"text": "Modeling human interaction in meetings .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 4 , pages 748 - 751 , 2003 .[ .This paper investigates the recognition of group actions in meetings by modeling the joint behaviour of participants .Many meeting actions , such as presentations , discussions and consensus , are characterised by similar or complementary behaviour across participants .Recognising these meaningful actions is an important step towards the goal of providing effective browsing and summarisation of processed meetings .In this work , a corpus of meetings was collected in a room equipped with a number of microphones and cameras .", "label": "", "metadata": {}}
{"text": "In experiments , audio and visual features for each participant are extracted from the raw data and the interaction of participants is modeled using HMM - based approaches .Initial results on the corpus demonstrate the ability of the system to recognise the set of meeting actions .I. McCowan , D. Gatica - Perez , S. Bengio , G. Lathoud , M. Barnard , and D. Zhang .Automatic analysis of multimodal group actions in meetings .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 27(3):305 - 317 , 2005 . [ .This paper investigates the recognition of group actions in meetings .", "label": "", "metadata": {}}
{"text": "The group actions are modelled using different HMM - based approaches , where the observations are provided by a set of audio - visual features monitoring the actions of individuals .Experiments demonstrate the importance of taking interactions into account in modelling the group actions .It is also shown that the visual modality contains useful information , even for predominantly audio - based events , motivating a multimodal approach to meeting analysis .I. McCowan , D. Gatica - Perez , S. Bengio , D. Moore , and H. Bourlard .Towards computer understanding of human interactions .In Ambient Intelligence , Lecture Notes in Computer Science , volume LNCS 2875 , pages 235 - 251 , Eindhoven , 2003 .", "label": "", "metadata": {}}
{"text": "[ .People meet in order to interact - disseminating information , making decisions , and creating new ideas .Automatic analysis of meetings is therefore important from two points of view : extracting the information they contain , and understanding human interaction processes .Based on this view , this article presents an approach in which relevant information content of a meeting is identified from a variety of audio and visual sensor inputs and statistical models of interacting people .We present a framework for computer observation and understanding of interacting people , and discuss particular tasks within this framework , issues in the meeting context , and particular algorithms that we have adopted .", "label": "", "metadata": {}}
{"text": "I. McCowan , D. Gatica - Perez , S. Bengio , D. Moore , and H. Bourlard .Towards computer understanding of human interactions .In Machine Learning for Multimodal Interaction : First International Workshop , MLMI , Lecture Notes in Computer Science , volume LNCS 3361 , pages 56 - 75 .Springer - Verlag , 2004 .[ .People meet in order to interact - disseminating information , making decisions , and creating new ideas .Automatic analysis of meetings is therefore important from two points of view : extracting the information they contain , and understanding human interaction processes .", "label": "", "metadata": {}}
{"text": "We present a framework for computer observation and understanding of interacting people , and discuss particular tasks within this framework , issues in the meeting context , and particular algorithms that we have adopted .We also comment on current developments and the future challenges in automatic meeting analysis .N. Poh and S. Bengio .Why do multi - stream , multi - band and multi - modal approaches work on biometric user authentication tasks ?In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 5 , pages 893 - 896 , 2004 .", "label": "", "metadata": {}}
{"text": "Multi - band , multi - stream and multi - modal approaches have proven to be very successful both in experiments and in real - life applications , among which speech recognition and biometric authentication are of particular interest here .However , there is a lack of a theoretical study to justify why and how they work , when one combines the streams at the feature or classifier score levels .In this paper , we attempt to cast a light onto the latter subject .While there exists literature discussing this aspect , a study on the relationship between correlation , variance reduction and Equal Error Rate ( often used in biometric authentication ) has not been treated theoretically as done here , using the mean operator .", "label": "", "metadata": {}}
{"text": "Furthermore , in practice , most combined experts using the methods mentioned above perform better than the best underlying expert .N. Poh and S. Bengio .F - ratio client - dependent normalisation for biometric authentication tasks .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , pages 721 - 724 , 2005 . [ .This study investigates a new client - dependent normalisation to improve biometric authentication systems .There exists many client - de - pendent score normalisation techniques applied to speaker authentication , such as Z - Norm , D - Norm and T - Norm .", "label": "", "metadata": {}}
{"text": "We propose \" F - ratio \" normalisation , or F - Norm , applied to face and speaker authentication systems .This normalisation requires only that as few as two client - dependent accesses are available ( the more the better ) .Different from previous normalisation techniques , F - Norm considers the client and impostor distributions simultaneously .We show that F - ratio is a natural choice because it is directly associated to Equal Error Rate .It has the effect of centering the client and impostor distributions such that a global threshold can be easily found .", "label": "", "metadata": {}}
{"text": "This parameter can be optimised to maximise the class dispersion ( the degree of separability between client and impostor distributions ) while the aforementioned normalisation techniques can not .The results of 13 unimodal experiments carried out on the XM2VTS multimodal database show that such normalisation is advantageous over Z - Norm , client - dependent threshold normalisation or no normalisation .N. Poh and S. Bengio .How do correlation and variance of base classifiers affect fusion in biometric authentication tasks ?IEEE Transactions on Signal Processing , 53(11):4384 - 4396 , 2005 .[ .Combining multiple information sources such as subbands , streams ( with different features ) and multi modal data has been shown to be a very promising trend , both in experiments and to some extents in real - life biometric authentication applications .", "label": "", "metadata": {}}
{"text": "Often , scores are assumed to be independent .In this paper , we explicitly consider this factor using a theoretical model , called Variance Reduction - Equal Error Rate ( VR - EER ) analysis .To achieve lower EER , smaller correlation and average variance of base - experts , and larger mean difference are desirable .Furthermore , analysing any of these factors independently , e.g. focusing on correlation alone , could be miss - leading .Experimental results on the BANCA multimodal database confirm our findings using VR - EER analysis .We analysed four commonly encountered scenarios in biometric authentication which include fusing correlated / uncorrelated base - experts of similar / different performances .", "label": "", "metadata": {}}
{"text": "One of the most important findings is that positive correlation \" hurts \" fusion while negative correlation ( greater \" diversity \" , which measures the spread of prediction score with respect to the fused score ) , improves fusion .However , by linking the concept of ambiguity decomposition to classification problem , it is found that diversity is not sufficient to be an evaluation criterion ( to compare several fusion systems ) , unless measures are taken to normalise the ( class - dependent ) variance .N. Poh and S. Bengio .Chimeric users to construct fusion classifiers in biometric authentication tasks : An investigation .", "label": "", "metadata": {}}
{"text": "[ .While the privacy problem is indeed solved using chimeric users , it is still an open question of how such chimeric database can be efficiently used .For instance , the following two questions arise : i )Is the performance measured on a chimeric database a good predictor of that measured on a real - user database ? , and , ii ) can a chimeric database be exploited to improve the generalization performance of a fusion operator on a real - user database ?Based on a considerable amount of empirical biometric person authentication experiments ( 21 real - user data sets and up to 21 \u00d71000 chimeric data sets and two fusion operators ) , our previous study [ Poh and Bengio , MLMI'05 ] answers no to the first question .", "label": "", "metadata": {}}
{"text": "Considering the possibly expensive cost involved in collecting the real - user multimodal data , our proposed approach is thus useful to construct a trainable fusion classifier while at the same time being able to overcome the problem of small size training data .N. Poh and S. Bengio .Database , protocol and tools for evaluating score - level fusion algorithms in biometric authentication .Pattern Recognition , 39(2):223 - 233 , 2006 .[ .Fusing the scores of several biometric systems is a very promising approach to improve the overall system 's accuracy .Despite many works in the literature , it is surprising that there is no coordinate d effort in making a benchmark database available .", "label": "", "metadata": {}}
{"text": "Building baseline systems from scratch often prevents researchers from putting more efforts in understanding the fusion problem .This paper describes a database of scores taken from experiments carried out on the XM2VTS face and speaker verification database .It then proposes several fusion protocols and provides some state - of - the - art tools to evaluate the fusion performance .N. Poh , S. Bengio , and A. Ross .Revisiting Doddington 's zoo : A systematic method to assess user - dependent variabilities .In Second Workshop on Multimodal User Authentication , MMUA , 2006 .[ .", "label": "", "metadata": {}}
{"text": "For instance , the following two questions arise : i )Is the performance measured on a chimeric database a good predictor of that measured on a real - user database ? , and , ii ) can a chimeric database be exploited to improve the generalization performance of a fusion operator on a real - user database ?Based on a considerable amount of empirical biometric person authentication experiments ( 21 real - user data sets and up to 21 \u00d71000 chimeric data sets and two fusion operators ) , our previous study [ ? ] answers no to the first question .", "label": "", "metadata": {}}
{"text": "Considering the possibly expensive cost involved in collecting the real - user multimodal data , our proposed approach is thus useful to construct a trainable fusion classifier while at the same time being able to overcome the problem of small size training data .S. Renals and S. Bengio , editors .Machine Learning for Multimodal Interaction : Second International Workshop , MLMI'2005 . volume 3869 of Lecture Notes in Computer Science .Springer - Verlag , 2006 .[ .This book contains a selection of refereed papers presented at the Second Workshop on Machine Learning for Multimodal Interaction ( MLMI 2005 ) , held in Edinburgh , Scotland , during 11 - 13 July 2005 .", "label": "", "metadata": {}}
{"text": "In addition to the main workshop , MLMI 2005 hosted the NIST ( US National Institute of Standards and Technology )Meeting Recognition Workshop .This workshop ( the third such sponsored by NIST ) was centered on the Rich Transcription 2005 Spring Meeting Recognition ( RT-05 ) evaluation of speech technologies within the meeting domain .Building on the success of the RT-04 spring evaluation , the RT-05 evaluation continued the speech - to - text and speaker diarization evaluation tasks and added two new evaluation tasks : speech activity detection and source localization .The motivation for creating such a forum , which could be perceived as a number of papers from different research disciplines , evolved from an actual need that arose from these projects and the strong motivation of their partners for such a multidisciplinary workshop .", "label": "", "metadata": {}}
{"text": "Machine Learning for Multimodal Interaction : Third International Workshop , MLMI'2006 .volume 4299 of Lecture Notes in Computer Science .Springer - Verlag , 2007 .[ .This book contains a selection of refereed papers presented at the 3rd Workshop on Machine Learning for Multimodal Interaction ( MLMI 2006 ) , held in Bethesda MD , USA during May 1\u00ad4 , 2006 .In addition to the main workshop , MLMI 2006 was co - located with the 4th NIST Meeting Recognition Workshop .This workshop was centered on the Rich Transcription 2006 Spring Meeting Recognition ( RT-06 ) evaluation of speech technologies within the meeting domain .", "label": "", "metadata": {}}
{"text": "These areas included human\u00adhuman communication modeling , speech and visual processing , multimodal processing , fusion and fission , human\u00adcomputer interaction , and the modeling of discourse and dialog , with an emphasis on the application of machine learning .Out of the submitted full papers , about 50 % were accepted for publication in the present volume , after authors had been invited to take review comments and conference feedback into account . D. Zhang and S. Bengio .Exploring contextual information in a layered framework for group action recognition .In IEEE International Conference on Multimedia & Expo , ICME , 2007 .", "label": "", "metadata": {}}
{"text": "Contextual information is important for sequence modeling .Hidden Markov models ( HMMs ) and extensions , which have been widely used for sequence modeling , make simplifying , often unrealistic assumptions on the conditional independence of observations given the class labels , thus can not accommodate overlapping features or long - term contextual information .In this paper , we introduce a principled layered framework with three implementation methods that take into account contextual information ( as available in the whole or part of the sequence ) .The first two methods are based on state alpha and gamma posteriors ( as usually referred to in the HMM formalism ) .", "label": "", "metadata": {}}
{"text": "We illustrate our methods with the application of recognizing group actions in meetings .Experiments and comparison with standard HMM baseline showed the validity of the proposed approach . D. Zhang , D. Gatica - Perez , S. Bengio , and I. McCowan .Semi - supervised adapted HMMs for unusual event detection .In IEEE Conference on Computer Vision and Pattern Recognition , CVPR , 2005 .[ .We address the problem of temporal unusual event detection .Unusual events are characterized by a number of features ( rarity , unexpectedness , and relevance ) that limit the application of traditional supervised model - based approaches .", "label": "", "metadata": {}}
{"text": "The proposed framework has an iterative structure , which adapts a new unusual event model at each iteration .We show that such a framework can address problems due to the scarcity of training data and the difficulty in pre - defining unusual events .Experiments on audio , visual , and audio - visual data streams illustrate its effectiveness , compared with both supervised and unsupervised baseline methods . D. Zhang , D. Gatica - Perez , S. Bengio , and I. McCowan .Semi - supervised meeting event recognition with adapted HMMs .In IEEE International Conference on Multimedia Expo , ICME , pages 611 - 618 , 2005 . [ .", "label": "", "metadata": {}}
{"text": "To deal with situations in which it is difficult to collect enough labeled data to capture event characteristics , but collecting a large amount of unlabeled data is easy , we present a semi - supervised framework using HMM adaptation techniques .Instead of directly training one model for each event , we first train a well - estimated general event model for all events using both labeled and unlabeled data , and then adapt the general model to each specific event model using its own labeled data .We illustrate the proposed approach with a set of eight audio - visual events defined in meetings .", "label": "", "metadata": {}}
{"text": "Modeling individual and group actions in meetings with layered HMMs .IEEE Transactions on Multimedia , 8(3):509 - 520 , 2006 .[ .We address the problem of recognizing sequences of human interaction patterns in meetings , with the goal of structuring them in semantic terms .The investigated patterns are inherently group - based ( defined by the individual activities of meeting participants , and their interplay ) , and multimodal ( as captured by cameras and microphones ) .By defining a proper set of individual actions , group actions can be modeled as a two - layer process , one that models basic individual activities from low - level audio - visual features , and another one that models the interactions .", "label": "", "metadata": {}}
{"text": "First , by decomposing the problem hierarchically , learning is performed on low - dimensional observation spaces , which results in simpler models .Second , our framework is easier to interpret , as both individual and group actions have a clear meaning , and thus easier to improve .Third , different HMM models can be used in each layer , to better reflect the nature of each subproblem .Our framework is general and extensible , and we illustrate it with a set of eight group actions , using a public five - hour meeting corpus .Experiments and comparison with a single - layer HMM baseline system show its validity . D. Zhang , D. Gatica - Perez , S. Bengio , I. McCowan , and G. Lathoud .", "label": "", "metadata": {}}
{"text": "In IEEE Workshop on Event Mining at the Conference on Computer Vision and Pattern Recognition , CVPR , 2004 .[ .We address the problem of recognizing sequences of human interaction patterns in meetings , with the goal of structuring them in semantic terms .The investigated patterns are inherently group - based ( defined by the individual activities of meeting participants , and their interplay ) , and multimodal ( as captured by cameras and microphones ) .By defining a proper set of individual actions , group actions can be modeled as a two - layer process , one that models basic individual activities from low - level audio - visual features , and another one that models the interactions .", "label": "", "metadata": {}}
{"text": "First , by decomposing the problem hierarchically , learning is performed on low - dimensional observation spaces , which results in simpler models .Second , our framework is easier to interpret , as both individual and group actions have a clear meaning , and thus easier to improve .Third , different HMM models can be used in each layer , to better reflect the nature of each subproblem .Our framework is general and extensible , and we illustrate it with a set of eight group actions , using a public five - hour meeting corpus .Experiments and comparison with a single - layer HMM baseline system show its validity . D. Zhang , D. Gatica - Perez , S. Bengio , I. McCowan , and G. Lathoud .", "label": "", "metadata": {}}
{"text": "In ACM Multimedia Workshop on Video Surveillance and Sensor Networks , 2004 .[ .We address the problem of clustering multimodal group actions in meetings using a two - layer HMM framework .Meetings are structured as sequences of group actions .Our approach aims at creating one cluster for each group action , where the number of group actions and the action boundaries are unknown a priori .In our framework , the first layer models typical actions of individuals in meetings using supervised HMM learning and low - level audio - visual features .A number of options that explicitly model certain aspects of the data ( e.g. , asynchrony ) were considered .", "label": "", "metadata": {}}
{"text": "The two layers are linked by a set of probability - based features produced by the individual action layer as input to the group action layer .The methodology was assessed on a set of multimodal turn - taking group actions , using a public five - hour meeting corpus .The results show that the use of multiple modalities and the layered framework are advantageous , compared to various baseline methods . D. Zhang , D. Gatica - Perez , D. Roy , and S. Bengio .Modeling interactions from email communication .In IEEE International Conference on Multimedia & Expo , ICME , 2006 .", "label": "", "metadata": {}}
{"text": "Email plays an important role as a medium for the spread of information , ideas , and influence among its users .We present a framework to learn topic - based interactions between pairs of email users , i.e. , the extent to which the email topic dynamics of one user are likely to be affected by the others .The proposed framework is built on the influence model and the probabilistic latent semantic analysis ( PLSA ) language model .This paper makes two contributions .First , we model interactions between email users using the semantic content of email body , instead of email header .", "label": "", "metadata": {}}
{"text": "Experiments on the Enron email corpus show some interesting results that are potentially useful to discover the hierarchy of the Enron organization . E. Bailly - Bailli\u00e8re , S. Bengio , F. Bimbot , M. Hamouz , J. Kittler , J. Mari\u00e9thoz , J. Matas , K. Messer , V. Popovici , F. Por\u00e9e , B. Ruiz , and J.-P. Thiran .The BANCA database and evaluation protocol .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 625 - 638 .", "label": "", "metadata": {}}
{"text": "[ .In this paper we describe the acquistion and content of a new large , realistic and challenging multi - modal database intended for training and testing multi - modal verification systems .The BANCA database was captured in four European languages in two modalities ( face and voice ) .For recording , both high and low quality microphones and cameras were used .The subjects were recorded in three different scenarios , controlled , degraded and adverse over a period of three months .In total 208 people were captured , half men and half women .", "label": "", "metadata": {}}
{"text": "S. Bengio .Multimodal authentication using asynchronous HMMs .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 770 - 777 .Springer - Verlag , 2003 .[ .It has often been shown that using multiple modalities to authenticate the identity of a person is more robust than using only one .Various combination techniques exist and are often performed at the level of the output scores of each modality system .In this paper , we present a novel HMM architecture able to model the joint probability distribution of pairs of asynchronous sequences ( such as speech and video streams ) describing the same event .", "label": "", "metadata": {}}
{"text": "Results on the M2VTS database show robust performances of the system under various audio noise conditions , when compared to other state - of - the - art techniques .S. Bengio .Multimodal speech processing using asynchronous hidden markov models .Information Fusion , 5(2):81 - 89 , 2004 .[ .This paper advocates that for some multimodal tasks involving more than one stream of data representing the same sequence of events , it might sometimes be a good idea to be able to desynchronize the streams in order to maximize their joint likelihood .We thus present a novel Hidden Markov Model architecture to model the joint probability of pairs of asynchronous sequences describing the same sequence of events .", "label": "", "metadata": {}}
{"text": "The model was tested on two audio - visual speech processing tasks , namely speech recognition and text - dependent speaker verification , both using the M2VTS database .Robust performances under various noise conditions were obtained in both cases .S. Bengio , C. Marcel , S. Marcel , and J. Mari\u00e9thoz .Confidence measures for multimodal identity verification .Information Fusion , 3(4):267 - 276 , 2002 .[ .Multimodal fusion for identity verification has already shown great improvement compared to unimodal algorithms .In this paper , we propose to integrate confidence measures during the fusion process .", "label": "", "metadata": {}}
{"text": "These methods can be used either to enhance the performance of a multimodal fusion algorithm or to obtain a confidence level on the decisions taken by the system .All the algorithms are compared on the same benchmark database , namely XM2VTS , containing both speech and face information .Results show that some confidence measures did improve statistically significantly the performance , while other measures produced reliable confidence levels over the fusion decisions .S. Bengio and J. Mari\u00e9thoz .Learning the decision function for speaker verification .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 1 , pages 425 - 428 , 2001 .", "label": "", "metadata": {}}
{"text": "This paper explores the possibility to replace the usual thresholding decision rule of log likelihood ratios used in speaker verification systems by more complex and discriminant decision functions based for instance on Linear Regression models or Support Vector Machines .Current speaker verification systems , based on generative models such as HMMs or GMMs , can indeed easily be adapted to use such decision functions .Experiments on both text dependent and text independent tasks always yielded performance improvements and sometimes significantly .S. Bengio and J. Mari\u00e9thoz .The expected performance curve : a new assessment measure for person authentication .", "label": "", "metadata": {}}
{"text": "[ .ROC and DET curves are often used in the field of person authentication to assess the quality of a model or even to compare several models .We argue in this paper that this measure can be misleading as it compares performance measures that can not be reached simultaneously by all systems .We propose instead new curves , called Expected Performance Curves ( EPC ) .These curves enable the comparison between several systems according to a criterion , decided by the application , which is used to set thresholds according to a separate validation set .", "label": "", "metadata": {}}
{"text": "A real case study is used throughout the paper to illustrate it .Finally , note that while this study was done on an authentication problem , it also applies to most 2-class classification tasks .S. Bengio and J. Mari\u00e9thoz .A statistical significance test for person authentication .In Proceedings of Odyssey 2004 : The Speaker and Language Recognition Workshop , 2004 .[ .Assessing whether two models are statistically significantly different from each other is a very important step in research , although it has unfortunately not received enough attention in the field of person authentication .", "label": "", "metadata": {}}
{"text": "We also compare our technique with other solutions that are sometimes used in the literature and show why they yield often too optimistic results ( resulting in false statements about statistical significantness ) .S. Bengio , J. Mari\u00e9thoz , and M. Keller .The expected performance curve .In International Conference on Machine Learning , ICML , Workshop on ROC Analysis in Machine Learning , 2005 . [ .In several research domains concerned with classification tasks , curves like ROC are often used to assess the quality of a particular model or to compare two or more models with respect to various operating points .", "label": "", "metadata": {}}
{"text": "The purpose of this paper is to first argue that these measures can be misleading in a machine learning context and should be used with care .Instead , we propose to use the Expected Performance Curves ( EPC ) which provide unbiased estimates of performance at various operating points .Furthermore , we show how to use adequately a non - parametric statistical test in order to produce EPCs with confidence intervals or assess the statistical significant difference between two models under various settings .F. Cardinaux , C. Sanderson , and S. Bengio .Face verification using adapted generative models .", "label": "", "metadata": {}}
{"text": "[ .It has been shown previously that systems based on local features and relatively complex generative models , namely 1D Hidden Markov Models ( HMMs ) and pseudo-2D HMMs , are suitable for face recognition ( here we mean both identification and verification ) .Recently a simpler generative model , namely the Gaussian Mixture Model ( GMM ) , was also shown to perform well .In this paper we first propose to increase the performance of the GMM approach ( without sacrificing its simplicity ) through the use of local features with embedded positional information ; we show that the performance obtained is comparable to 1D HMMs .", "label": "", "metadata": {}}
{"text": "F. Cardinaux , C. Sanderson , and S. Bengio .User authentication via adapted statistical models of face images .IEEE Transactions on Signal Processing , 54(1):361 - 373 , 2006 .[ .It has been previously demonstrated that systems based on local features and relatively complex statistical models , namely 1D Hidden Markov Models ( HMMs ) and pseudo-2D HMMs , are suitable for face recognition .Recently , a simpler statistical model , namely the Gaussian Mixture Model ( GMM ) , was also shown to perform well .In much of the literature devoted to these models , the experiments were performed with controlled images ( manual face localization , controlled lighting , background , pose , etc ) .", "label": "", "metadata": {}}
{"text": "In this article we evaluate , on the relatively difficult BANCA database , the performance , robustness and complexity of GMM and HMM based approaches , using both manual and automatic face localization .We extend the GMM approach through the use of local features with embedded positional information , increasing performance without sacrificing its low complexity .Furthermore , we show that the traditionally used Maximum Likelihood ( ML ) training approach has problems estimating robust model parameters when there is only a few training images available .Considerably more precise models can be obtained through the use of Maximum a Posteriori ( MAP ) training .", "label": "", "metadata": {}}
{"text": "Finally , we show that while the pseudo-2D HMM approach has the best overall performance , authentication time on current hardware makes it impractical .The best trade - off in terms of authentication time , robustness and discrimination performance is achieved by the extended GMM approach .J. Czyz , S. Bengio , C. Marcel , and L. Vandendorpe .Scalability analysis of audio - visual person identity verification .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 752 - 760 .", "label": "", "metadata": {}}
{"text": "[ .In this work , we present a multimodal identity verification system based on the fusion of the face image and the text independent speech data of a person .The system conciliates the monomodal face and speaker verification algorithms by fusing their respective scores .In order to assess the authentication system at different scales , the performance is evaluated at various sizes of the face and speech user template .The user template size is a key parameter when the storage space is limited like in a smart card .Our experimental results show that the multimodal fusion allows to reduce significantly the user template size while keeping a satisfactory level of performance .", "label": "", "metadata": {}}
{"text": "G. Heigold , I. Moreno , S. Bengio , and N. Shazeer .End - to - end text - dependent speaker verification .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2016 . [ .In this paper we present a data - driven , integrated approach to speaker verification , which maps a test utterance and a few reference utterances directly to a single score for verification and jointly optimizes the system 's components using the same evaluation protocol and metric as at test time .Such an approach will result in simple and efficient systems , requiring little domain - specific knowledge and making few model assumptions .", "label": "", "metadata": {}}
{"text": "The proposed approach appears to be very effective for big data applications like ours that require highly accurate , easy - to - maintain systems with a small footprint .M. Keller , J. Mari\u00e9thoz , and S. Bengio .Significance tests for bizarre measures in 2-class classification tasks .Technical Report IDIAP - RR 04 - 34 , IDIAP , 2004 .[ .Statistical significance tests are often used in machine learning to compare the performance of two learning algorithms or two models .However , in most cases , one of the underlying assumptions behind these tests is that the error measure used to assess the performance of one model / algorithm is computed as the sum of errors obtained on each example of the test set .", "label": "", "metadata": {}}
{"text": "We propose here a practical methodology to either adapt the existing tests or develop non - parametric solutions for such bizarre measures .We furthermore assess the quality of these tests on a real - life large dataset .Q. Le and S. Bengio .Hybrid generative - discriminative models for speech and speaker recognition .Technical Report IDIAP - RR 02 - 06 , IDIAP , 2002 .[ .Generative probability models such as Hidden Markov Models are usually used for modeling sequences of data because of their ability to handle variable size sequences and missing information .", "label": "", "metadata": {}}
{"text": "An ideal classifier should have all the power of these two complementary approaches .A series of recent papers has suggested some techniques for mixing generative models and discriminative models .In one of them a fixed size vector ( the Fisher score ) containing sufficient statistics of a sequence is computed for a previously trained HMM and can then be used as input to a discriminative model for classification .The purpose of this project is thus to study , experiment , enhance and adapt these new approaches of integrating discriminative models such as SVM into generative models for sequence processing problems , such as speaker and speech recognition .", "label": "", "metadata": {}}
{"text": "Client dependent GMM - SVM models for speaker verification .In International Conference on Artificial Neural Networks , ICANN / ICONIP , Lecture Notes in Computer Science , volume LNCS 2714 , pages 443 - 451 .Springer Verlag , 2003 .[ .Generative Gaussian Mixture Models ( GMMs ) are known to be the dominant approach for modeling speech sequences in text independent speaker verification applications because of their scalability , good performance and their ability in handling variable size sequences .On the other hand , because of their discriminative properties , models like Support Vector Machines ( SVMs ) usually yield better performance in static classification problems and can construct flexible decision boundaries .", "label": "", "metadata": {}}
{"text": "A cross - validation method is also used in the baseline system to increase the number of client scores in the training phase , which enhances the results of the SVM models .Experiments carried out on the XM2VTS and PolyVar databases confirm the interest of this hybrid approach .M. Liwicki , A. Schlapbach , H. Bunke , S. Bengio , J. Mari\u00e9thoz , and J. Richiardi .Writer identification for smart meeting room systems .In H. Bunke and A. L. Spitz , editors , Document Analysis Systems VII : 7th International Workshop , DAS , Lecture Notes in Computer Science , volume LNCS 3872 , pages 186 - 195 .", "label": "", "metadata": {}}
{"text": "[ .In this paper we present a text independent on - line writer identification system based on Gaussian Mixture Models ( GMMs ) .This system has been developed in the context of research on Smart Meeting Rooms .The GMMs in our system are trained using two sets of features extracted from a text line .The first feature set is similar to feature sets used in signature verification systems before .It consists of information gathered for each recorded point of the handwriting , while the second feature set contains features extracted from each stroke .While both feature sets perform very favorably , the stroke - based feature set outperforms the point - based feature set in our experiments .", "label": "", "metadata": {}}
{"text": "Increasing the number of writers to 200 , the identification rate decreases to 94.75 % .S. Marcel and S. Bengio .Improving face verification using skin color information .In Proceedings of the 16th International Conference on Pattern Recognition , ICPR , volume 2 , pages 11 - 15 .IEEE Computer Society Press , 2002 .[ .The performance of face verification systems has steadily improved over the last few years , mainly focusing on models rather than on feature processing .State - of - the - art methods often use the gray - scale face image as input .", "label": "", "metadata": {}}
{"text": "The new feature set is tested on a benchmark database , namely XM2VTS , using a simple discriminant artificial neural network .Results show that the skin color information improves the performance .S. Marcel , C. Marcel , and S. Bengio .A state - of - the - art neural network for robust face verification .In COST275 Workshop on the advent of Biometrics on the Internet , 2002 .[ .The performance of face verification systems has steadily improved over the last few years , mainly focusing on models rather than on feature processing .State - of - the - art methods often use the gray - scale face image as input .", "label": "", "metadata": {}}
{"text": "The new feature set is tested on a benchmark database , namely XM2VTS , using a simple discriminant artificial neural network .Results show that the skin color information improves the performance and that the proposed model achieves robust state - of - the - art results .J. Mari\u00e9thoz and S. Bengio .A comparative study of adaptation methods for speaker verification .In Proceedings of the International Conference on Spoken Language Processing , ICSLP , 2002 .[ .Real - life speaker verification systems are often implemented using client model adaptation methods , since the amount of data available for each client is often too low to consider plain Maximum Likelihood methods .", "label": "", "metadata": {}}
{"text": "This paper proposes an experimental comparison between three well - known adaptation methods , namely MAP , Maximum Likelihood Linear Regression , and finally EigenVoices .All three methods are compared to the more classical Maximum Likelihood method , and results are given for a subset of the 1999 NIST Speaker Recognition Evaluation database .J. Mari\u00e9thoz and S. Bengio .An alternative to silence removal for text - independent speaker verification .Technical Report IDIAP - RR 03 - 51 , IDIAP , 2003 .[ .State - of - the - art text independent speaker verification systems use silence / speech detectors to get rid of silence frames which are considered to be non discriminative .", "label": "", "metadata": {}}
{"text": "Experiments on the NIST 2000 database yielded statistically significantly better performance for the new model as compared to our best baseline system involving a silence / speech detector , without having to rely on uncertain hypotheses .J. Mari\u00e9thoz and S. Bengio .A unified framework for score normalization techniques applied to text independent speaker verification .IEEE Signal Processing Letters , 12(7):532 - 535 , 2005 . [ .The purpose of this paper is to unify several of the state - of - the - art score normalization techniques applied to text - independent speaker verification systems .", "label": "", "metadata": {}}
{"text": "The two well - known Z- and T - normalization techniques can be easily interpreted in this framework as different ways to estimate score distributions .This is useful as it helps to understand the various assumptions behind these well - known score normalization techniques , and opens the door for yet more complex solutions .Finally , some experiments on the Switchboard database are performed in order to illustrate the validity of the new proposed framework .J. Mari\u00e9thoz and S. Bengio .A max kernel for text - independent speaker verification systems .In Second Workshop on Multimodal User Authentication , MMUA , 2006 .", "label": "", "metadata": {}}
{"text": "In this paper , we present a principled SVM based speaker verification system .A general approach is developed that enables the use of any kernel at the frame level .An extension of his approach using the Max operator is then proposed .The new system is then compared to state - of - the - art GMM and other SVM based systems found in the literature on the Polyvar database .It is found that the new system outperforms , most of the time , the other systems , statistically significantly .J. Mari\u00e9thoz and S. Bengio .", "label": "", "metadata": {}}
{"text": "Pattern Recognition , 40:2315 - 2324 , 2007 .[ .This paper present a principled SVM based speaker verification system .We propose a new framework and a new sequence kernel that can make use of any Mercer kernel at the frame level .An extension of the sequence kernel based on the Max operator is also proposed .The new system is compared to state - of - the - art GMM and other SVM based systems found in the literature on the Banca and Polyvar databases .The new system outperforms , most of the time , the other systems , statistically significantly .", "label": "", "metadata": {}}
{"text": "Face authentication test on the BANCA database .In International Conference on Pattern Recognition , ICPR , volume 4 , pages 523 - 532 , 2004 .[ .This paper details the results of a Face Authentication Test ( FAT2004 ) held in conjunction with the 17th International Conference on Pattern Recognition .The contest was held on the publicly available BANCA database according to a defined protocol .The competition also had a sequestered part in which institutions had to submit their algorithms for independent testing . 13 different verification algorithms from 10 institutions submitted results .Also , a standard set of face recognition software packages from the Internet were used to provide a baseline performance measure .", "label": "", "metadata": {}}
{"text": "In International Conference on Biometric Authentication , ICBA , Lecture Notes in Computer Science , volume LNCS 3072 , pages 8 - 15 .Springer - Verlag , 2004 .[ .This paper details the results of a face verification competition held in conjunction with the First International Conference on Biometric Authe ntication .The contest was held on the publically available BANCA database according to a defined protocol .Six different verification algorithms from 4 academic and commercial institutions submitted results .Also , a standard set of face recognition software from the internet was used to provide a baseline performance measure .", "label": "", "metadata": {}}
{"text": "In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 964 - 974 .Springer - Verlag , 2003 .[ .N. Poh and S. Bengio .Non - linear variance reduction techniques in biometric authentication .In IEEE Multimodal User Authentication Workshop , 2003 .[ .In this paper , several approaches that can be used to improve biometric authentication applications are proposed .The idea is inspired by the ensemble approach , i.e. , the use of several classifiers to solve a problem .", "label": "", "metadata": {}}
{"text": "Instead of using multiple classifiers , we propose here to examine other possible means of variance reduction ( VR ) , namely through the use of multiple synthetic samples , different extractors ( features ) and biometric modalities .The scores are combined using the average operator , Multi - Layer Perceptron and Support Vector Machines .It is found empirically that VR via modalities is the best technique , followed by VR via extractors , VR via classifiers and VR via synthetic samples .This order of effectiveness is due to the corresponding degree of independence of the combined objects ( in decreasing order ) .", "label": "", "metadata": {}}
{"text": "Furthermore , in practice , most combined experts perform better than any of their participating experts .N. Poh and S. Bengio .Variance reduction techniques in biometric authentication .Technical Report IDIAP - RR 03 - 17 , IDIAP , 2003 .[ .In this paper , several approaches that can be used to improve biometric authentication applications are proposed .The idea is inspired by the ensemble approach , i.e. , the use of several classifiers to solve a problem .Compared to using only one classifier , the ensemble of classifiers has the advantage of reducing the overall variance of the system .", "label": "", "metadata": {}}
{"text": "It is found empirically that VR via modalities is the best technique , followed by VR via real samples , VR via extractors , VR via classifiers and VR via synthetic samples .This order of effectiveness is due to the corresponding degree of independence of the combined objects ( in decreasing order ) .The theoretical and empirical findings show that the combined experts via VR techniques always perform better than the average of their participating experts .Furthermore , in practice , most combined experts perform better than any of their participating experts .N. Poh and S. Bengio .", "label": "", "metadata": {}}
{"text": "In Proceedings of Odyssey 2004 : The Speaker and Language Recognition Workshop , 2004 .[ .Multi - stream approaches have proven to be very successful in speech recognition tasks and to a certain extent in speaker authentication tasks .In this study we propose a noise - robust multi - stream text - independent speaker authentication system .This system has two steps : first train the stream experts under clean conditions and then train the combination mechanism to merge the scores of the stream experts under both clean and noisy conditions .The idea here is to take advantage of the rather predictable reliability and diversity of streams under different conditions .", "label": "", "metadata": {}}
{"text": "An important finding is that a trade - off is often necessary between the overall good performance under all conditions ( clean and noisy ) and good performance under clean conditions .To reconcile this trade - off , we propose to give more emphasis or prior to clean conditions , thus , resulting in a combination mechanism that does not deteriorate under clean conditions ( as compared to the best stream ) yet is robust to noisy conditions .N. Poh and S. Bengio .Towards predicting optimal subsets of base classifiers in biometric authentication tasks .In S. Bengio and H. Bourlard , editors , Machine Learning for Multimodal Interactions : First International Workshop , MLMI , Lecture Notes in Computer Science , volume LNCS 3361 , pages 159 - 172 .", "label": "", "metadata": {}}
{"text": "[ .Combining multiple information sources , typically from several data streams is a very promising approach , both in experiments and to some extend in various real - life applications .However , combining too many systems ( base - experts ) will also increase both hardware and computation costs .One way to selecting a subset of optimal base - experts out of N is to carry out the experiments explicitly .There are 2 N -1 possible combinations .In this paper , we propose an analytical solution to this task when weighted sum fusion mechanism is used .", "label": "", "metadata": {}}
{"text": "It has a complexity that is additive between the number of examples and the number of possible combinations while the conventional approach , using brute - force experimenting , is multiplicative between these two terms .Hence , our approach will scale better with large fusion problems .Experiments on the BANCA multi - modal database verified our approach .While we will consider here fusion in the context of identity verification via biometrics , or simply biometric authentication , it can also have an important impact in meetings because this a priori information can assist in retrieving highlights in meeting analysis as in \" who said what \" .", "label": "", "metadata": {}}
{"text": "Development in fusion of identity verification will provide insights into how fusion in meetings can be done .The ability to predict fusion performance is another important step towards understanding the fusion problem .N. Poh and S. Bengio .Why do multi - stream , multi - band and multi - modal approaches work on biometric user authentication tasks ?In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 5 , pages 893 - 896 , 2004 .[ .Multi - band , multi - stream and multi - modal approaches have proven to be very successful both in experiments and in real - life applications , among which speech recognition and biometric authentication are of particular interest here .", "label": "", "metadata": {}}
{"text": "In this paper , we attempt to cast a light onto the latter subject .While there exists literature discussing this aspect , a study on the relationship between correlation , variance reduction and Equal Error Rate ( often used in biometric authentication ) has not been treated theoretically as done here , using the mean operator .Our findings suggest that combining several experts using the mean operator , Multi - Layer - Perceptrons and Support Vector Machines always perform better than the average performance of the underlying experts .Furthermore , in practice , most combined experts using the methods mentioned above perform better than the best underlying expert .", "label": "", "metadata": {}}
{"text": "Can chimeric persons be used in multimodal biometric authentication experiments ?In S. Renals and S. Bengio , editors , Machine Learning for Multimodal Interactions : Second International Workshop , MLMI , volume LNCS 3869 .Springer - Verlag , 2005 .[ .Combining multiple information sources , typically from several data streams is a very promising approach , both in experiments and to some extents in various real - life applications .A system that uses more than one behavioral and physiological characteristics to verify whether a person is who he / she claims to be is called a multimodal biometric authentication system .", "label": "", "metadata": {}}
{"text": "In the literature , this practice is justified based on the fact that the underlying biometric traits to be combined are assumed to be independent of each other given the user .To the best of our knowledge , there is no literature that approves or disapproves such practice .The experimental results suggest that for a large proportion of the experiments , such practice is indeed questionable .N. Poh and S. Bengio .EER of fixed and trainable fusion classifiers : A theoretical study with application to biometric authentication tasks .In N. C. Oza , R. Polikar , and J. Kittler , editors , 6th International Workshop on Multiple Classifier Systems , MCS , Lecture Notes in Computer Science , volume LNCS 3541 , pages 74 - 85 .", "label": "", "metadata": {}}
{"text": "[ .Biometric authentication is a process of verifying an identity claim using a person 's behavioural and physiological characteristics .Due to the vulnerability of the system to environmental noise and variation caused by the user , fusion of several biometric - enabled systems is identified as a promising solution .In the literature , various fixed rules ( e.g. min , max , median , mean ) and trainable classifiers ( e.g. linear combination of scores or weighted sum ) are used to combine the scores of several base - systems .How exactly do correlation and imbalance nature of base - system performance affect the fixed rules and trainable classifiers ?", "label": "", "metadata": {}}
{"text": "Similar to several previous studies in the literature , the central assumption used here is that the class - dependent scores of a biometric system are approximately normally distributed .However , different from them , the novelty of this study is to make a direct link between the EER measure and the fusion schemes mentioned .Both synthetic and real experiments ( with as many as 256 fusion experiments carried out on the XM2VTS benchmark score - level fusion data sets ) verify our proposed theoretical modeling of EER of the two families of combination scheme .In particular , it is found that weighted sum can provide the best generalisation performance when its weights are estimated correctly .", "label": "", "metadata": {}}
{"text": "N. Poh and S. Bengio .F - ratio client - dependent normalisation for biometric authentication tasks .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , pages 721 - 724 , 2005 . [ .This study investigates a new client - dependent normalisation to improve biometric authentication systems .There exists many client - de - pendent score normalisation techniques applied to speaker authentication , such as Z - Norm , D - Norm and T - Norm .Such normalisation is intended to adjust the variation across different client models .", "label": "", "metadata": {}}
{"text": "This normalisation requires only that as few as two client - dependent accesses are available ( the more the better ) .Different from previous normalisation techniques , F - Norm considers the client and impostor distributions simultaneously .We show that F - ratio is a natural choice because it is directly associated to Equal Error Rate .It has the effect of centering the client and impostor distributions such that a global threshold can be easily found .Another difference is that F - Norm actually \" interpolates \" between client - independent and client - dependent information by introducing a mixture parameter .", "label": "", "metadata": {}}
{"text": "The results of 13 unimodal experiments carried out on the XM2VTS multimodal database show that such normalisation is advantageous over Z - Norm , client - dependent threshold normalisation or no normalisation .N. Poh and S. Bengio .How do correlation and variance of base classifiers affect fusion in biometric authentication tasks ?IEEE Transactions on Signal Processing , 53(11):4384 - 4396 , 2005 .[ .Combining multiple information sources such as subbands , streams ( with different features ) and multi modal data has been shown to be a very promising trend , both in experiments and to some extents in real - life biometric authentication applications .", "label": "", "metadata": {}}
{"text": "Often , scores are assumed to be independent .In this paper , we explicitly consider this factor using a theoretical model , called Variance Reduction - Equal Error Rate ( VR - EER ) analysis .To achieve lower EER , smaller correlation and average variance of base - experts , and larger mean difference are desirable .Furthermore , analysing any of these factors independently , e.g. focusing on correlation alone , could be miss - leading .Experimental results on the BANCA multimodal database confirm our findings using VR - EER analysis .We analysed four commonly encountered scenarios in biometric authentication which include fusing correlated / uncorrelated base - experts of similar / different performances .", "label": "", "metadata": {}}
{"text": "One of the most important findings is that positive correlation \" hurts \" fusion while negative correlation ( greater \" diversity \" , which measures the spread of prediction score with respect to the fused score ) , improves fusion .However , by linking the concept of ambiguity decomposition to classification problem , it is found that diversity is not sufficient to be an evaluation criterion ( to compare several fusion systems ) , unless measures are taken to normalise the ( class - dependent ) variance .N. Poh and S. Bengio .Improving fusion with margin - derived confidence in biometric authentication tasks .", "label": "", "metadata": {}}
{"text": "Springer - Verlag , 2005 . [ .This study investigates a new confidence criterion to improve fusion via a linear combination of scores of several biometric authentication systems .This confidence is based on the margin of making a decision , which answers the question , \" after observing the score of a given system , what is the confidence ( or risk ) associated to that given access ? \"In the context of multimodal and intramodal fusion , such information proves valuable because the margin information can determine which of the systems should be given higher weights .", "label": "", "metadata": {}}
{"text": "The results of 32 fusion experiments carried out on the XM2VTS multimodal database show that fusion using margin ( product of margin and expert opinion ) is superior over fusion without the margin information ( i.e. , the original expert opinion ) .Furthermore , combining both sources of information increases fusion performance further .N. Poh and S. Bengio .A novel approach to combining client - dependent and confidence information in multimodal biometrics .In T. Kanade , A. Jain , and N. K. Ratha , editors , 5th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 3546 , pages 1120 - 1129 .", "label": "", "metadata": {}}
{"text": "The issues of fusion with client - dependent and confidence information have been well studied separately in biometric authentication .In this study , we propose to take advantage of both sources of information in a discriminative framework .Initially , each source of information is processed on a per expert basis ( plus on a per client basis for the first information and on a per example basis for the second information ) .Then , both sources of information are combined using a second - level classifier , across different experts .Although the formulation of such two - step solution is not new , the novelty lies in the way the sources of prior knowledge are incorporated prior to fusion using the second - level classifier .", "label": "", "metadata": {}}
{"text": "Our framework that we call \" Prior Knowledge Incorporation \" has the advantage of using the standard machine learning algorithms .N. Poh and S. Bengio .A score - level fusion benchmark database for biometric authentication .In T. Kanade , A. Jain , and N. K. Ratha , editors , 5th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 3546 , pages 474 - 483 .Springer - Verlag , 2005 .[ .Fusing the scores of several biometric systems is a very promising approach to improve the overall system 's accuracy .", "label": "", "metadata": {}}
{"text": "It should be noted that fusion in this context consists not only of multimodal fusion , but also intramodal fusion , i.e. , fusing systems using the same biometric modality but different features , or same features but using different classifiers .Building baseline systems from scratch often prevents researchers from putting more efforts in understanding the fusion problem .This paper describes a database of scores taken from experiments carried out on the XM2VTS face and speaker verification database .It then proposes several fusion protocols and provides some state - of - the - art tools to evaluate the fusion performance .", "label": "", "metadata": {}}
{"text": "Chimeric users to construct fusion classifiers in biometric authentication tasks : An investigation .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2006 .[ .While the privacy problem is indeed solved using chimeric users , it is still an open question of how such chimeric database can be efficiently used .For instance , the following two questions arise : i )Is the performance measured on a chimeric database a good predictor of that measured on a real - user database ? , and , ii ) can a chimeric database be exploited to improve the generalization performance of a fusion operator on a real - user database ?", "label": "", "metadata": {}}
{"text": "The current study aims to answer the second question .Considering the possibly expensive cost involved in collecting the real - user multimodal data , our proposed approach is thus useful to construct a trainable fusion classifier while at the same time being able to overcome the problem of small size training data .N. Poh and S. Bengio .Database , protocol and tools for evaluating score - level fusion algorithms in biometric authentication .Pattern Recognition , 39(2):223 - 233 , 2006 .[ .Fusing the scores of several biometric systems is a very promising approach to improve the overall system 's accuracy .", "label": "", "metadata": {}}
{"text": "It should be noted that fusion in this context consists not only of multimodal fusion , but also intramodal fusion , i.e. , fusing systems using the same biometric modality but different features , or same features but using different classifiers .Building baseline systems from scratch often prevents researchers from putting more efforts in understanding the fusion problem .This paper describes a database of scores taken from experiments carried out on the XM2VTS face and speaker verification database .It then proposes several fusion protocols and provides some state - of - the - art tools to evaluate the fusion performance .", "label": "", "metadata": {}}
{"text": "Estimating the confidence interval of expected performance curve in biometric authentication using joint bootstrap .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2007 .[ .Evaluating biometric authentication performance is a complex task because the performance depends on the user set size , composition and the choice of samples .We propose to reduce the performance dependency of these three factors by deriving appropriate confidence intervals .In this study , we focus on deriving a confidence region based on the recently proposed Expected Performance Curve ( EPC ) .An EPC is different from the conventional DET or ROC curve because an EPC assumes that the test class - conditional ( client and impostor ) score distributions are unknown and this includes the choice of the decision threshold for various operating points .", "label": "", "metadata": {}}
{"text": "The proposed technique is useful , for example , to quote realistic upper and lower bounds of the decision cost function used in the NIST annual speaker evaluation .A coverage is the proportion of the unseen EPC covered by the derived confidence interval .N. Poh , S. Bengio , and J. Korczak .A multi - sample multi - source model for biometric authentication .In IEEE Workshop on Neural Networks for Signal Processing , NNSP , pages 375 - 384 , 2002 .[ .In this study , two techniques that can improve the authentication process are examined : ( i ) multiple samples and ( ii ) multiple biometric sources .", "label": "", "metadata": {}}
{"text": "By using the average operator , both the theoretical and empirical results show that integrating as many samples and as many biometric sources as possible can improve the overall reliability of the system .This strategy is called multi - sample multi - source approach .This strategy was tested on a real - life database using neural networks trained in one - versus - all configuration .N. Poh , S. Bengio , and A. Ross .Revisiting Doddington 's zoo : A systematic method to assess user - dependent variabilities .In Second Workshop on Multimodal User Authentication , MMUA , 2006 .", "label": "", "metadata": {}}
{"text": "While the privacy problem is indeed solved using chimeric users , it is still an open question of how such chimeric database can be efficiently used .For instance , the following two questions arise : i )Is the performance measured on a chimeric database a good predictor of that measured on a real - user database ? , and , ii ) can a chimeric database be exploited to improve the generalization performance of a fusion operator on a real - user database ?Based on a considerable amount of empirical biometric person authentication experiments ( 21 real - user data sets and up to 21 \u00d71000 chimeric data sets and two fusion operators ) , our previous study [ ? ] answers no to the first question .", "label": "", "metadata": {}}
{"text": "Considering the possibly expensive cost involved in collecting the real - user multimodal data , our proposed approach is thus useful to construct a trainable fusion classifier while at the same time being able to overcome the problem of small size training data .N. Poh , S. Marcel , and S. Bengio .Improving face authentication using virtual samples .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 3 , pages 233 - 236 , 2003 .[ .In this paper , we present a simple yet effective way to improve a face verification system by generating multiple virtual samples from the unique image corresponding to an access request .", "label": "", "metadata": {}}
{"text": "This method is often used during training to improve accuracy of a neural network model by making it robust against minor translation , scale and orientation change .The main contribution of this paper is to introduce such method during testing .By generating N images from one single image and propagating them to a trained network model , one obtains N scores .By merging these scores using a simple mean operator , we show that the variance of merged scores is decreased by a factor between 1 and N .An experiment is carried out on the XM2VTS database which achieves new state - of - the - art performances .", "label": "", "metadata": {}}
{"text": "Performance generalization in biometric authentication using joint user - specific and sample bootstraps .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 29(3):492 - 498 , 2007 .[ .Biometric authentication performance is often depicted by a decision error trade - off ( DET ) curve .We show that this curve is dependent on the choice of samples available , the demographic composition and the number of users specific to a database .We propose a two - step bootstrap procedure to take into account of the three mentioned sources of variability .This is an extension to the Bolle 's bootstrap subset technique .", "label": "", "metadata": {}}
{"text": "Furthermore , our finding suggests that with more data available , the confidence intervals become smaller and hence more useful .N. Poh , C. Sanderson , and S. Bengio .Spectral subband centroids as complementary features for speaker authentication .In International Conference on Biometric Authentication , ICBA , Lecture Notes in Computer Science , volume LNCS 3072 , pages 631 - 639 .Springer - Verlag , 2004 .[ .Most conventional features used in speaker authentication are based on estimation of spectral envelopes in one way or another , e.g. , Mel - scale Filterbank Cepstrum Coefficients ( MFCCs ) , Linear - scale Filterbank Cepstrum Coefficients ( LFCCs ) and Relative Spectral Perceptual Linear Prediction ( RASTA - PLP ) .", "label": "", "metadata": {}}
{"text": "These features are the centroid frequency in each subband .F. Por\u00e9e , J. Mari\u00e9thoz , S. Bengio , and F. Bimbot .The BANCA database and experimental protocol for speaker verification .Technical Report IDIAP - RR 02 - 13 , IDIAP , 2002 .[ .Identity verification has become a very important research topic recently , particularly using methods based on the face or the voice of the individuals .In the context of the BANCA european project , a novel multi - modal database was recently recorded , spanning 5 european languages , 2 modalities ( face and voice ) , 2 microphones , 2 cameras and almost 300 individuals .", "label": "", "metadata": {}}
{"text": "Estimating the quality of face localization for face verification .In IEEE International Conference on Image Processing , ICIP , pages 581 - 584 , 2004 .[ .Face localization is the process of finding the exact position of a face in a given image .This can be useful in several applications such as face tracking or person authentication .The purpose of this paper is to show that the error made during the localization process may have different impacts depending on the final application .Hence in order to evaluate the performance of a face localization algorithm , we propose to embed the final application ( here face verification ) into the performance measuring process .", "label": "", "metadata": {}}
{"text": "We show on the BANCA database that our proposed measure best matches the final verification results when comparing several localization algorithms , on various performance measures currently used in face localization . Y. Rodriguez , F. Cardinaux , S. Bengio , and J. Mari\u00e9thoz .Measuring the performance of face localization systems .Image and Vision Computing , 24(8):882 - 893 , 2006 .[ .The purpose of Face localization is to determine the coordinates of a face in a given image .It is a fundamental research area in computer vision because it serves , as a necessary first step in any face processing system , such as automatic face recognition , face tracking or expression analysis .", "label": "", "metadata": {}}
{"text": "Therefore , their performances depend widely on the accuracy of the face localization process .The purpose of this paper is to mainly show that the error made during the localization process may have different impacts on the final application .We first show the influence of localization errors on the face verification task and then empirically demonstrate the problems of current localization performance measures when applied to this task .In order to properly evaluate the performance of a face localization algorithm , we then propose to embed the final application ( here face verification ) into the performance measuring process .", "label": "", "metadata": {}}
{"text": "C. Sanderson and S. Bengio .Augmenting frontal face models for non - frontal verification .In IEEE Multimodal User Authentication Workshop , 2003 .[ .In this work we propose to address the problem of non - frontal face verification when only a frontal training image is available ( e.g. a passport photograph ) by augmenting a client 's frontal face model with artificially synthesized models for non - frontal views .In the framework of a Gaussian Mixture Model ( GMM ) based classifier , two techniques are proposed for the synthesis : UBMdiff and LinReg .", "label": "", "metadata": {}}
{"text": "The synthesis and augmentation approach is evaluated by applying it to two face verification systems : Principal Component Analysis ( PCA ) based and DCTmod2 ( Sanderson et al , 2003 ) based ; the two systems are a representation of holistic and non - holistic approaches , respectively .C. Sanderson and S. Bengio .Robust features for frontal authentication in difficult image conditions .In 4th International Conference on Audio- and Video - Based Biometric Person Authentication , AVBPA , Lecture Notes in Computer Science , volume LNCS 2688 , pages 495 - 504 .Springer - Verlag , 2003 .", "label": "", "metadata": {}}
{"text": "In this paper we extend the recently proposed DCT - mod2 feature extraction technique ( which utilizes polynomial coefficients derived from 2D DCT coefficients obtained from horizontally & vertically neighbouring blocks ) via the use of various windows and diagonally neighbouring blocks .We also propose enhanced PCA , where traditional PCA feature extraction is combined with DCT - mod2 .Results using test images corrupted by a linear and a non - linear illumination change , white Gaussian noise and compression artefacts , show that use of diagonally neighbouring blocks and windowing is detrimental to robustness against illumination changes while being useful for increasing robustness against white noise and compression artefacts .", "label": "", "metadata": {}}
{"text": "C. Sanderson and S. Bengio .Extrapolating single view face models for multi - view recognition .In International Conference on Intelligente Sensors , Sensor Networks and Information Processings , ISSNIP , pages 581 - 586 , 2004 .[ .Performance of face recognition systems can be adversely affected by mismatches between training and test poses , especially when there is only one training image available .We address this problem by extending each statistical frontal face model with artificially synthesized models for non - frontal views .The synthesis methods are based on several implementations of Maximum Likelihood Linear Regression ( MLLR ) , as well as standard multi - variate linear regression ( LinReg ) .", "label": "", "metadata": {}}
{"text": "The synthesis and extension approach is evaluated by applying it to two face verification systems : PCA based ( holistic features ) and DCTmod2 based ( local features ) .For the DCTmod2 based system , the results show that synthesis via a new MLLR implementation obtains better performance than synthesis based on traditional MLLR ( due to a lower number of free parameters ) .The results further show that extending frontal models considerably reduces errors .C. Sanderson and S. Bengio .Statistical transformation techniques for face verification using faces rotated in depth .Technical Report IDIAP - RR 04 - 04 , IDIAP , 2004 .", "label": "", "metadata": {}}
{"text": "In the framework of a Bayesian classifier based on mixtures of gaussians , we address the problem of non - frontal face verification ( when only a single ( frontal ) training image is available ) by extending each frontal face model with artificially synthesized models for non - frontal views .The synthesis methods are based on several implementations of Maximum Likelihood Linear Regression ( MLLR ) , as well as standard multi - variate linear regression ( LinReg ) .All synthesis techniques rely on prior information and learn how face models for the frontal view are related to face models for non - frontal views .", "label": "", "metadata": {}}
{"text": "The results further suggest that extending frontal models considerably reduces errors .C. Sanderson and S. Bengio .Statistical transformations of frontal models for non - frontal face verification .In IEEE International Conference on Image Processing , ICIP , pages 585 - 588 , 2004 .[ .All techniques rely on prior information and learn how a generic face model for the frontal view is related to generic models at non - frontal views .Experiments on the FERET database suggest that that the proposed MLS technique is more suitable than MLLR ( due to a lower number of free parameters ) and UBMdiff ( due to lack of heuristics ) .", "label": "", "metadata": {}}
{"text": "C. Sanderson , S. Bengio , H. Bourlard , J. Mari\u00e9thoz , R. Collobert , M.F. BenZeghiba , F. Cardinaux , and S. Marcel .Speech & face based biometric authentication at IDIAP .In International Conference on Multimedia and Expo , ICME , volume 3 , pages 1 - 4 , 2003 .[ .We present an overview of recent research at IDIAP on speech & face based biometric authentication .This paper covers user - customised passwords , adaptation techniques , confidence measures ( for use in fusion of audio & visual scores ) , face verification in difficult image conditions , as well as other related research issues .", "label": "", "metadata": {}}
{"text": "C. Sanderson , S. Bengio , and Y. Gao .On transforming statistical models for non - frontal face verification .Pattern Recognition , 39(2):288 - 302 , 2006 .[ .We address the pose mismatch problem which can occur in face verification systems that have only a single ( frontal ) face image available for training .In the framework of a Bayesian classifier based on mixtures of gaussians , the problem is tackled through extending each frontal face model with artificially synthesized models for non - frontal views .The synthesis methods are based on several implementations of Maximum Likelihood Linear Regression ( MLLR ) , as well as standard multi - variate linear regression ( LinReg ) .", "label": "", "metadata": {}}
{"text": "The synthesis and extension approach is evaluated by applying it to two face verification systems : a holistic system ( based on PCA - derived features ) and a local feature system ( based on DCT - derived features ) .The results further suggest that extending frontal models considerably reduces errors .C. Sanderson , F. Cardinaux , and S. Bengio .On accuracy / robustness / complexity trade - offs in face verification .In IEEE International Conference on Information Technology and Applications , ICITA , pages 638 - 643 , 2005 . [ .In much of the literature devoted to face recognition , experiments are performed with controlled images ( e.g. manual face localization , controlled lighting , background and pose ) .", "label": "", "metadata": {}}
{"text": "In this paper we first evaluate , on the relatively difficult BANCA database , the discrimination accuracy , robustness and complexity of Gaussian Mixture Model ( GMM ) , 1D- and pseudo-2D Hidden Markov Model ( HMM ) based systems , using both manual and automatic face localization .We also propose to extend the GMM approach through the use of local features with embedded positional information , increasing accuracy without sacrificing its low complexity .Experiments show that good accuracy on manually located faces is not necessarily indicative of good accuracy on automatically located faces ( which are imperfectly located ) .", "label": "", "metadata": {}}
{"text": "Methods which utilize rigid constraints have poor robustness compared to methods which have relaxed constraints .Furthermore , we show that while the pseudo-2D HMM approach has the best overall accuracy , classification time on current hardware makes it impractical .The best trade - off in terms of complexity , robustness and discrimination accuracy is achieved by the extended GMM approach . S. Bengio .Large scale visual semantic extraction .In Frontiers of Engineering - Reports on Leading - Edge Engineering from the 2011 Symposium , 2012 .Image annotation is the task of providing textual semantic to new images , by ranking a large set of possible annotations according to how they correspond to a given image .", "label": "", "metadata": {}}
{"text": "In order to achieve such a task we propose to build a so - called \" embedding space \" , into which both images and annotations can be automatically projected .In such a space , one can then find the nearest annotations to a given image , or annotations similar to a given annotation .One can even build a visio - semantic tree from these annotations , that corresponds to how concepts ( annotations ) are similar to each other with respect to their visual characteristics .Such a tree will be different from semantic - only trees , such as WordNet , which do not take into account the visual appearance of concepts .", "label": "", "metadata": {}}
{"text": "Taking on the curse of dimensionality in joint distributions using neural networks .IEEE Transaction on Neural Networks , special issue on data mining and knowledge discovery , 11(3):550 - 557 , 2000 .[ .The curse of dimensionality is severe when modeling high - dimensional discrete data : the number of possible combinations of the variables explodes exponentially .The neural network can be interpreted as a graphical model without hidden random variables , but in which the conditional distributions are tied through the hidden units .The connectivity of the neural network can be pruned by using dependency tests between the variables ( thus reducing significantly the number of parameters ) .", "label": "", "metadata": {}}
{"text": "S. Bengio , J. Weston , and D. Grangier .Label embedding trees for large multi - class tasks .In Advances in Neural Information Processing Systems , NIPS , 2010 .[ .Multi - class classification becomes challenging at test time when the number of classes is very large and testing against every possible class can become computationally infeasible .This problem can be alleviated by imposing ( or learning ) a structure over the set of classes .We propose an algorithm for learning a tree - structure of classifiers which , by optimizing the overall tree loss , provides superior accuracy to existing tree labeling methods . Y. Bengio and S. Bengio .", "label": "", "metadata": {}}
{"text": "In S.A. Solla , T.K. Leen , and K.-R. M\u00fcller , editors , Advances in Neural Information Processing Systems , NIPS 12 , pages 400 - 406 .MIT Press , 2000 .[ .The curse of dimensionality is severe when modeling high - dimensional discrete data : the number of possible combinations of the variables explodes exponentially .The neural network can be interpreted as a graphical model without hidden random variables , but in which the conditional distributions are tied through the hidden units .The connectivity of the neural network can be pruned by using dependency tests between the variables .", "label": "", "metadata": {}}
{"text": "G. Chechik , E. Ie , M. Rehn , S. Bengio , and D. Lyon .Large - scale content - based audio retrieval from text queries .In ACM International Conference on Multimedia Information Retrieval , MIR , 2008 .[ .In content - based audio retrieval , the goal is to find sound recordings ( audio documents ) based on their acoustic features .This content - based approach differs from retrieval approaches that index media files using metadata such as file names and user tags .We handle generic sounds , including a wide variety of sound effects , animal vocalizations and natural scenes .", "label": "", "metadata": {}}
{"text": "We test our approach on two large real - world datasets : a collection of short sound effects , and a noisier and larger collection of user - contributed user - labeled recordings ( 25 K files , 2000 terms vocabulary ) .We find that all three methods achieved very good retrieval performance .For instance , a positive document is retrieved in the first position of the ranking more than half the time , and on average there are more than 4 positive documents in the first 10 retrieved , for both datasets .PAMIR completed both training and retrieval of all data in less than 6 hours for both datasets , on a single machine .", "label": "", "metadata": {}}
{"text": "This approach should therefore scale to much larger datasets in the future .G. Chechik , V. Sharma , U. Shalit , and S. Bengio .Large - scale online learning of image similarity through ranking : Extended abstract .In 4th Iberian Conference on Pattern Recognition and Image Analysis IbPRIA , 2009 .[ .Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning .Pairwise similarity plays a crucial role in classification algorithms like nearest neighbors , and is practically important for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video .", "label": "", "metadata": {}}
{"text": "Unfortunately , current approaches for learning semantic similarity are limited to small scale datasets , because their complexity grows quadratically with the sample size , and because they impose costly positivity constraints on the learned similarity functions .To address real - world large - scale AI problem , like learning similarity over all images on the web , we need to develop new algorithms that scale to many samples , many classes , and many features .The current abstract presents OASIS , an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations .", "label": "", "metadata": {}}
{"text": "Our experiments show that OASIS is both fast and accurate at a wide range of scales : for a dataset with thousands of images , it achieves better results than existing state - of - the - art methods , while being an order of magnitude faster .Comparing OASIS with different symmetric variants , provides unexpected insights into the effect of symmetry on the quality of the similarity .For large , web scale , datasets , OASIS can be trained on more than two million images from 150 K text queries within two days on a single CPU .", "label": "", "metadata": {}}
{"text": "This suggests that query - independent similarity could be accurately learned even for large - scale datasets that could not be handled before .G. Chechik , V. Sharma , U. Shalit , and S. Bengio .An online algorithm for large scale image similarity learning .In Advances in Neural Information Processing Systems , NIPS .MIT Press , 2009 .[ .Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning .It stands in the core of classification methods like kernel machines , and is particularly useful for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video .", "label": "", "metadata": {}}
{"text": "Unfortunately , current approaches for learning similarity do not scale to large datasets , especially when imposing metric constraints on the learned similarity .We describe OASIS , a method for learning pairwise similarity that is fast and scales linearly with the number of objects and the number of non - zero features .Scalability is achieved through online learning of a bilinear model over sparse representations using a large margin criterion and an efficient hinge loss cost .OASIS is accurate at a wide range of scales : on a standard benchmark with thousands of images , it is more precise than state - of - the - art methods , and faster by orders of magnitude .", "label": "", "metadata": {}}
{"text": "The non - metric similarities learned by OASIS can be transformed into metric similarities , achieving higher precisions than similarities that are learned as metrics in the first place .This suggests an approach for learning a metric from data that is larger by orders of magnitude than was handled before .G. Chechik , V. Sharma , U. Shalit , and S. Bengio .Large scale online learning of image similarity through ranking .Journal of Machine Learning Research , JMLR , 11:1109 - 1135 , 2010 .[ .Learning a measure of similarity between pairs of objects is an important generic problem in machine learning .", "label": "", "metadata": {}}
{"text": "In these tasks , users look for objects that are not only visually similar but also semantically related to a given object .Unfortunately , the approaches that exist today for learning such semantic similarity do not scale to large datasets .This is both because typically their CPU and storage requirements grow quadratically with the sample size , and because many methods impose complex positivity constraints on the space of learned similarity functions .The current paper presents OASIS , an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations .OASIS is an online dual approach using the passive - aggressive family of learning algorithms with a large margin criterion and an efficient hinge loss cost .", "label": "", "metadata": {}}
{"text": "For large , web scale , datasets , OASIS can be trained on more than two million images from 150 K text queries within 3 days on a single CPU .On this large scale dataset , human evaluations showed that 35 % of the ten nearest neighbors of a given test image , as found by OASIS , were semantically relevant to that image .This suggests that query independent similarity could be accurately learned even for large scale datasets that could not be handled before .R. Collobert and S. Bengio .On the convergence of SVMTorch , an algorithm for large - scale regression problems .", "label": "", "metadata": {}}
{"text": "[ .Recently , many researchers have proposed decomposition algorithms for SVM regression problems .In a previous paper , we also proposed such an algorithm , named SVMTorch .This convergence proof is in fact mainly based on the convergence proof given by Keerthi and Gilbert for their SVM classification algorithm .R. Collobert and S. Bengio .Support vector machines for large - scale regression problems .Technical Report IDIAP - RR 00 - 17 , IDIAP , Martigny , Switzerland , 2000 .[ .Support Vector Machines ( SVMs ) for regression problems are trained by solving a quadratic optimization problem which needs on the order of l 2 memory and time resources to solve , where l is the number of training examples . , which is similar to SVM - Light proposed by Joachims for classification problems , but adapted to regression problems .", "label": "", "metadata": {}}
{"text": "Comparisons with Nodelib , another SVM algorithm for large - scale regression problems from Flake and Lawrence yielded significant time improvements .R. Collobert and S. Bengio .SVMTorch : Support vector machines for large - scale regression problems .Journal of Machine Learning Research , JMLR , 1:143 - 160 , 2001 .[ .Support Vector Machines ( SVMs ) for regression problems are trained by solving a quadratic optimization problem which needs on the order of l square memory and time resources to solve , where l is the number of training examples .With this algorithm , one can now efficiently solve large - scale regression problems ( more than 20000 examples ) .", "label": "", "metadata": {}}
{"text": "Finally , based on a recent paper from Lin ( 2000 ) , we show that a convergence proof exists for our algorithm .R. Collobert and S. Bengio .A new margin - based criterion for efficient gradient descent .Technical Report IDIAP - RR 03 - 16 , IDIAP , 2003 .[ .During the last few decades , several papers were published about second - order optimization methods for gradient descent based learning algorithms .Moreover , these methods are usually not easy to implement .Many enhancements have also been proposed in order to overcome these problems , but most of them still cost O ( n 2 ) in time per iteration .", "label": "", "metadata": {}}
{"text": "Furthermore , we will argue that analyzing the Hessian resulting from the choice of various cost functions is very informative and could help in the design of new machine learning algorithms .For instance , we propose in this paper a version of the Support Vector Machines criterion applied to Multi Layer Perceptrons , which yields very good training and generalization performance in practice .Several empirical comparisons on two benchmark data sets are given to justify this approach .R. Collobert and S. Bengio .A gentle hessian for efficient gradient descent .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 5 , pages 517 - 520 , 2004 .", "label": "", "metadata": {}}
{"text": "Several second - order optimization methods for gradient descent algorithms have been proposed over the years , but they usually need to compute the inverse of the Hessian of the cost function ( or an approximation of this inverse ) during training .In most cases , this leads to an O ( n 2 ) cost in time and space per iteration , where n is the number of parameters , which is prohibitive for large n .We propose instead a study of the Hessian before training .Based on a second order analysis , we show that a block - diagonal Hessian yields an easier optimization problem than a full Hessian .", "label": "", "metadata": {}}
{"text": "Finally , we propose a version of the SVM criterion applied to MLPs , which verifies the aspects highlighted in this second order analysis , but also yields very good generalization performance in practice , taking advantage of the margin effect .Several empirical comparisons on two benchmark datasets are given to illustrate this approach .R. Collobert and S. Bengio .Links between perceptrons , MLPs and SVMs .In International Conference on Machine Learning , ICML , 2004 .[ .We propose to study links between three important classification algorithms : Perceptrons , Multi - Layer Perceptrons ( MLPs ) and Support Vector Machines ( SVMs ) .", "label": "", "metadata": {}}
{"text": "After showing that under simple conditions a Perceptron is equivalent to an SVM , we show it can be computationally expensive in time to train an SVM ( and thus a Perceptron ) with stochastic gradient descent , mainly because of the margin maximization term in the cost function .We then show that if we remove this margin maximization term , the learning rate or the use of early stopping can still control the margin .These ideas are extended afterward to the case of MLPs .Moreover , under some assumptions it also appears that MLPs are a kind of mixture of SVMs , maximizing the margin in the hidden layer space .", "label": "", "metadata": {}}
{"text": "R. Collobert , S. Bengio , and Y. Bengio .A parallel mixture of SVMs for very large scale problems .Neural Computation , 14(5):1105 - 1114 , 2002 .[ .Support Vector Machines ( SVMs ) are currently the state - of - the - art models for many classification problems but they suffer from the complexity of their training algorithm which is at least quadratic with respect to the number of examples .Hence , it is hopeless to try to solve real - life problems having more than a few hundreds of thousands examples with SVMs .", "label": "", "metadata": {}}
{"text": "Experiments on a large benchmark dataset ( Forest ) yielded significant time improvement ( time complexity appears empirically to locally grow linearly with the number of examples ) .In addition , and that is a surprise , a significant improvement in generalization was observed .R. Collobert , S. Bengio , and Y. Bengio .A parallel mixture of SVMs for very large scale problems .In T.G. Dietterich , S. Becker , and Z. Ghahramani , editors , Advances in Neural Information Processing Systems , NIPS 14 , pages 633 - 640 .MIT Press , 2002 .", "label": "", "metadata": {}}
{"text": "Support Vector Machines ( SVMs ) are currently the state - of - the - art models for many classification problems but they suffer from the complexity of their training algorithm which is at least quadratic with respect to the number of examples .Hence , it is hopeless to try to solve real - life problems having more than a few hundreds of thousands examples with SVMs .The present paper proposes a new mixture of SVMs that can be easily implemented in parallel and where each SVM is trained on a small subset of the whole dataset .", "label": "", "metadata": {}}
{"text": "In addition , and that is a surprise , a significant improvement in generalization was observed on Forest .R. Collobert , S. Bengio , and J. Mari\u00e9thoz .Torch : a modular machine learning software library .Technical Report IDIAP - RR 02 - 46 , IDIAP , 2002 .[ .Many scientific communities have expressed a growing interest in machine learning algorithms recently , mainly due to the generally good results they provide , compared to traditional statistical or AI approaches .However , these machine learning algorithms are often complex to implement and to use properly and efficiently .", "label": "", "metadata": {}}
{"text": "More interestingly , this library is freely available under a BSD license and can be retrieved on the web by everyone .R. Collobert , Y. Bengio , and S. Bengio .Scaling large learning problems with hard parallel mixtures .In S. Lee and A. Verri , editors , International Workshop on Pattern Recognition with Support Vector Machines , SVM , Lecture Notes in Computer Science , volume LNCS 2388 , pages 8 - 23 .Springer - Verlag , 2002 .[ .A challenge for statistical learning is to deal with large data sets , e.g. in data mining .", "label": "", "metadata": {}}
{"text": "A probabilistic extension and the use of a set of generative models allows representing the gater so that all pieces of the model are locally trained .For SVMs , time complexity appears empirically to locally grow linearly with the number of examples , while generalization performance can be enhanced .For the probabilistic version of the algorithm , the iterative algorithm provably goes down in a cost function that is an upper bound on the negative log - likelihood .R. Collobert , Y. Bengio , and S. Bengio .Scaling large learning problems with hard parallel mixtures .", "label": "", "metadata": {}}
{"text": "[ .A challenge for statistical learning is to deal with large data sets , e.g. in data mining .The training time of ordinary Support Vector Machines is at least quadratic , which raises a serious research challenge if we want to deal with data sets of millions of examples .A probabilistic extension and the use of a set of generative models allows representing the gater so that all pieces of the model are locally trained .For SVMs , time complexity appears empirically to locally grow linearly with the number of examples , while generalization performance can be enhanced .", "label": "", "metadata": {}}
{"text": "J. Deng , N. Ding , Y. Jia , A. Frome , K. Murphy , S. Bengio , Y. Li , H. Neven , and H. Adam .Large - scale object classification using label relation graphs .In Proceedings of the European Conference on Computer Vision , ECCV , 2014 . [ .In this paper we study how to perform object classification in a principled way that exploits the rich structure of real world labels .We develop a new model that allows encoding of flexible relations between labels .We introduce Hierarchy and Exclusion ( HEX ) graphs , a new formalism that captures semantic relations between any two labels applied to the same object : mutual exclusion , overlap and subsumption .", "label": "", "metadata": {}}
{"text": "Next , we propose a probabilistic classification model based on HEX graphs and show that it enjoys a number of desirable properties .Finally , we evaluate our method using a large - scale benchmark .Empirical results demonstrate that our model can significantly improve object classification by exploiting the label relations . A. Frome , G. Corrado , J. Shlens , S. Bengio , J. Dean , M. Ranzato , and T. Mikolov .DeViSE : A deep visual - semantic embedding model .In Advances In Neural Information Processing Systems , NIPS , 2013 . [ .Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories .", "label": "", "metadata": {}}
{"text": "One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions .In this paper we present a new deep visual - semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text .We demonstrate that this model matches state - of - the - art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors , and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training .", "label": "", "metadata": {}}
{"text": "A discriminative kernel - based model to rank images from text queries .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 30(8):1371 - 1384 , 2008 .[ .This paper introduces a discriminative model for the retrieval of images from text queries .Our approach formalizes the retrieval task as a ranking problem , and introduces a learning procedure optimizing a criterion related to the ranking performance .The proposed model hence addresses the retrieval problem directly and does not rely on an intermediate image annotation task , which contrasts with previous research .Moreover , our learning procedure builds upon recent work on the online learning of kernel - based classifiers .", "label": "", "metadata": {}}
{"text": "The experiments performed over stock photography data show the advantage of our discriminative ranking approach over state - of - the - art alternatives ( e.g. our model yields 26.3 % average precision over the Corel dataset , which should be compared to 22.0 % , for the best alternative model evaluated ) .Further analysis of the results shows that our model is especially advantageous over difficult queries such as queries with few relevant pictures or multiple - word queries .D. Grangier , F. Monay , and S. Bengio .Learning to retrieve images from text queries with a discriminative model .", "label": "", "metadata": {}}
{"text": "[ .This work presents a discriminative model for the retrieval of pictures from text queries .The core idea of this approach is to minimize a loss directly related to the retrieval performance of the model .For that purpose , we rely on a ranking loss which has recently been successfully applied to text retrieval problems .The experiments performed over the Corel dataset show that our approach compares favorably with generative models that constitute the state - of - the - art ( e.g. our model reaches 21.6 % mean average precision with Blob and SIFT features , compared to 16.7 % for PLSA , the best alternative ) .", "label": "", "metadata": {}}
{"text": "Training highly multiclass classifiers .Journal of Machine Learning Research , JMLR , 15:1461 - 1492 , 2014 .[ .Classification problems with thousands or more classes often have a large variance in the confusability between classes , and we show that the more - confusable classes add more noise to the empirical loss that is minimized during training .We propose an online solution that reduces the effect of highly confusable classes in training the classifier parameters , and focuses the training on pairs of classes that are easier to differentiate at any given time in the training .", "label": "", "metadata": {}}
{"text": "Experiments on ImageNet benchmark datasets and proprietary image recognition problems with 15,000 to 97,000 classes show substantial gains in classification accuracy compared to one - vs - all linear SVMs and Wsabie .M. Keller , S. Bengio , and S. Y. Wong .Benchmarking non - parametric statistical tests .In Advances in Neural Information Processing Systems , NIPS 18 .MIT Press , 2005 . [ .Although non - parametric tests have already been proposed for that purpose , statistical significance tests for non - standard measures ( different from the classification error ) are less often used in the literature .", "label": "", "metadata": {}}
{"text": "More precisely , using a very large dataset to estimate the whole \" population \" , we analyzed the behavior of several statistical test , varying the class unbalance , the compared models , the performance measure , and the sample size .The main result is that providing big enough evaluation sets non - parametric tests are relatively reliable in all conditions .M. Norouzi , T. Mikolov , S. Bengio , Y. Singer , J. Shlens , A. Frome , G. S. Corrado , and J. Dean .Zero - shot learning by convex combination of semantic embeddings .", "label": "", "metadata": {}}
{"text": "[ .Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces .In some cases the embedding space is trained jointly with the image transformation .In other cases the semantic embedding space is established by an independent natural language processing task , and then the image transformation into that space is learned in a second stage .Proponents of these image embedding systems have stressed their advantages over the traditional classification framing of image understanding , particularly in terms of the promise for zero - shot learning - the ability to correctly annotate images of previously unseen object categories .", "label": "", "metadata": {}}
{"text": "Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors , and requires no additional training .We show that this simple and direct method confers many of and indeed outperforms state of the art methods on the ImageNet zero - shot learning task .M. Rehn , R. F. Lyon , S. Bengio , T. C. Walters , and G. Chechik .Sound ranking using auditory sparse - code representations .In ICML 2009 Workshop on Sparse Method for Music Audio , 2009 .[ .The task of ranking sounds from text queries is a good test application for machine - hearing techniques , and particularly for comparison and evaluation of alternative sound representations in a large - scale setting .", "label": "", "metadata": {}}
{"text": "Using this system allows us to focus on comparison of different auditory front ends and different ways of extracting sparse features from high - dimensional auditory images .In addition to two main auditory - image models , we also include and compare a family of more conventional Mel - Frequency Cepstral Coefficients ( MFCC ) front ends .The experimental results show a significant advantage for the auditory models over vector - quantized MFCCs .The two auditory models tested use the adaptive pole - zero filter cascade ( PZFC ) auditory filterbank and sparse - code feature extraction from stabilized auditory images via multiple vector quantizers .", "label": "", "metadata": {}}
{"text": "Using ranking precision - at - top - k performance measures , the best results are about 72 % top-1 precision and 35 % average precision , using a test corpus of thousands of sound files and a query vocabulary of hundreds of words .M. Stevens , S. Bengio , and Y. Singer .Efficient learning of sparse ranking functions .In B. Scholkopf , Z. Luo , and V. Vovk , editors , Empirical Inference .Springer , 2013 .Algorithms for learning to rank can be inefficient when they employ risk functions that use structural information .", "label": "", "metadata": {}}
{"text": "This loss is designed for problems in which we need to rank a small number of positive examples over a vast number of negative examples .In that context , we propose an efficient coordinate descent approach that scales linearly with the number of examples .We then present an extension that incorporates regularization thus extending Vapnik\u00bfs notion of regularized empirical risk minimization to ranking learning .We also discuss an extension to the case of multi - values feedback .Experiments performed on several benchmark datasets and large scale Google internal dataset demonstrate the effectiveness of learning algorithm in constructing compact models while retaining the empirical performance accuracy .", "label": "", "metadata": {}}
{"text": "Multi - tasking with joint semantic spaces for large - scale music annotation and retrieval .Journal of New Music Research , 40:337 - 348 , 2011 .[ .Music prediction tasks range from predicting tags given a song or clip of audio , predicting the name of the artist , or predicting related songs given a song , clip , artist name or tag .That is , we are interested in every semantic relationship between the different musical concepts in our database .In realistically sized databases , the number of songs is measured in the hundreds of thousands or more , and the number of artists in the tens of thousands or more , providing a considerable challenge to standard machine learning techniques .", "label": "", "metadata": {}}
{"text": "This choice of space is learnt by optimizing the set of prediction tasks of interest jointly using multi - task learning .Our single model learnt by training on the joint objective function is shown experimentally to have improved accuracy over training on each task alone .Our method also outperforms the baseline methods tried and , in comparison to them , is faster and consumes less memory .We also demonstrate how our method learns an interpretable model , where the semantic space captures well the similarities of interest .J. Weston , S. Bengio , and N. Usunier .", "label": "", "metadata": {}}
{"text": "In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases , ECML - PKDD , 2010 .Best Paper Award in Machine Learning [ .Image annotation datasets are becoming larger and larger , with tens of millions of images and tens of thousands of possible annotations .We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low - dimensional joint embedding space for both images and annotations .", "label": "", "metadata": {}}
{"text": "We also demonstrate how our method learns an interpretable model , where annotations with alternate spellings or even languages are close in the embedding space .Hence , even when our model does not predict the exact annotation given by a human labeler , it often predicts similar annotations , a fact that we try to quantify by measuring the newly introduced \" sibling \" precision metric , where our method also obtains excellent results .J. Weston , S. Bengio , and N. Usunier .Large scale image annotation : Learning to rank with joint word - image embeddings .", "label": "", "metadata": {}}
{"text": "[ .Image annotation datasets are becoming larger and larger , with tens of millions of images and tens of thousands of possible annotations .We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low - dimensional joint embedding space for both images and annotations .Our method both outperforms several baseline methods and , in comparison to them , is faster and consumes less memory .We also demonstrate how our method learns an interpretable model , where annotations with alternate spellings or even languages are close in the embedding space .", "label": "", "metadata": {}}
{"text": "J. Weston , S. Bengio , and N. Usunier .Wsabie : Scaling up to large vocabulary image annotation .In Proceedings of the International Joint Conference on Artificial Intelligence , IJCAI , 2011 .[ .Image annotation datasets are becoming larger and larger , with tens of millions of images and tens of thousands of possible annotations .We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at the top of the ranked list of annotations for a given image and learning a low - dimensional joint embedding space for both images and annotations .", "label": "", "metadata": {}}
{"text": "Offline cursive word recognition using continuous density hidden markov models trained with PCA or ICA features .In Proceedings of the 16th International Conference on Pattern Recognition , ICPR , volume 3 , pages 81 - 84 .IEEE Computer Society Press , 2002 .[ .This work presents an Offline Cursive Word Recognition System dealing with single writer samples .The system was a continuous density hiddden Markov model trained using either the raw data , or data transformed using Principal Component Analysis or Independent Component Analysis .Both techniques significantly improved the recognition rate of the system .", "label": "", "metadata": {}}
{"text": "Several experiments were performed using a publicly available database .The accuracy obtained is the highest presented in the literature over the same data . A. Vinciarelli and S. Bengio .Transforming the feature vectors to improve HMM based cursive word recognition systems .Technical Report IDIAP - RR 02 - 32 , IDIAP , 2002 .[ .Although many Offline Cursive Word Recognition systems are based on HMMs , no attention was ever paid , to our knowledge , to the fact that the feature vectors are typically not in the most suitable form for modeling .They are most of the time correlated and embedded in a space of dimension higher than their Intrinsic Dimension .", "label": "", "metadata": {}}
{"text": "By applying some transforms it is possible to solve , or at least to attenuate , such problems resulting in data easier to model and in systems with higher recognition rate .In this work , we used Principal Component Analysis ( linear and nonlinear ) and Independent Component Analysis .A reduction of the error rate by up to 30.3 % ( over single writer data ) and 16.2 % ( over multiple writer samples ) is shown to be achieved . A. Vinciarelli and S. Bengio .Writer adaptation techniques in HMM based off - line cursive script recognition .", "label": "", "metadata": {}}
{"text": "[ .This work presents the application of HMM adaptation techniques to the problem of Off - Line Cursive Script Recognition .Instead of training a new model for each writer , one first creates a unique model with a mixed database and then adapts it for each different writer using his own small dataset . A. Vinciarelli and S. Bengio .Writer adaptation techniques in HMM based off - line cursive script recognition .Pattern Recognition Letters , 23(8):905 - 916 , 2002 .[ .This work presents the application of HMM adaptation techniques to the problem of Off - Line Cursive Script Recognition .", "label": "", "metadata": {}}
{"text": "Offline recognition of large vocabulary cursive handwritten text .In International Conference on Document Analysis and Recognition , ICDAR , pages 1101 - 1105 , 2003 .[ .This paper presents a system for the offline recognition of cursive handwritten lines of text .The system is based on continuous density HMMs and Statistical Language Models .The system recognizes data produced by a single writer .No a - priori knowledge is used about the content of the text to be recognized .Changes in the experimental setup with respect to the recognition of single words are highlighted .", "label": "", "metadata": {}}
{"text": "Offline recognition of unconstrained handwritten texts using HMMs and statistical language models .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 26(6):709 - 720 , 2004 .[ .This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts .The only assumption made about the data is that it is written in English .This allows the application of Statistical Language Models in order to improve the performance of our system .Several experiments have been performed using both single and multiple writer data .Lexica of variable size ( from 10,000 to 50,000 words ) have been used .", "label": "", "metadata": {}}
{"text": "An experimental setup to correctly deal with unconstrained text recognition is proposed .R. Collobert and S. Bengio .On the convergence of SVMTorch , an algorithm for large - scale regression problems .Technical Report IDIAP - RR 00 - 24 , IDIAP , Martigny , Switzerland , 2000 .[ .Recently , many researchers have proposed decomposition algorithms for SVM regression problems .In a previous paper , we also proposed such an algorithm , named SVMTorch .This convergence proof is in fact mainly based on the convergence proof given by Keerthi and Gilbert for their SVM classification algorithm .", "label": "", "metadata": {}}
{"text": "Support vector machines for large - scale regression problems .Technical Report IDIAP - RR 00 - 17 , IDIAP , Martigny , Switzerland , 2000 .[ .Support Vector Machines ( SVMs ) for regression problems are trained by solving a quadratic optimization problem which needs on the order of l 2 memory and time resources to solve , where l is the number of training examples . , which is similar to SVM - Light proposed by Joachims for classification problems , but adapted to regression problems .With this algorithm , one can now efficiently solve large - scale regression problems ( more than 20000 examples ) .", "label": "", "metadata": {}}
{"text": "R. Collobert and S. Bengio .SVMTorch : Support vector machines for large - scale regression problems .Journal of Machine Learning Research , JMLR , 1:143 - 160 , 2001 .[ .Support Vector Machines ( SVMs ) for regression problems are trained by solving a quadratic optimization problem which needs on the order of l square memory and time resources to solve , where l is the number of training examples .With this algorithm , one can now efficiently solve large - scale regression problems ( more than 20000 examples ) .Comparisons with Nodelib , another publicly available SVM algorithm for large - scale regression problems from Flake and Lawrence ( 2000 ) yielded significant time improvements .", "label": "", "metadata": {}}
{"text": "R. Collobert , S. Bengio , and Y. Bengio .A parallel mixture of SVMs for very large scale problems .Neural Computation , 14(5):1105 - 1114 , 2002 .[ .Support Vector Machines ( SVMs ) are currently the state - of - the - art models for many classification problems but they suffer from the complexity of their training algorithm which is at least quadratic with respect to the number of examples .Hence , it is hopeless to try to solve real - life problems having more than a few hundreds of thousands examples with SVMs .", "label": "", "metadata": {}}
{"text": "Experiments on a large benchmark dataset ( Forest ) yielded significant time improvement ( time complexity appears empirically to locally grow linearly with the number of examples ) .In addition , and that is a surprise , a significant improvement in generalization was observed . Y. Grandvalet , J. Mari\u00e9thoz , and S. Bengio .A probabilistic interpretation of SVMs with an application to unbalanced classification .In Advances in Neural Information Processing Systems , NIPS 18 .MIT Press , 2005 . [ .In this paper , we show that the hinge loss can be interpreted as the neg - log - likelihood of a semi - parametric model of posterior probabilities .", "label": "", "metadata": {}}
{"text": "This connection enables to derive a mapping from SVM scores to estimated posterior probabilities .Unlike previous proposals , the suggested mapping is interval - valued , providing a set of posterior probabilities compatible with each SVM score .This framework offers a new way to adapt the SVM optimization problem when decisions result in unequal losses .Experiments on an unbalanced classification loss show improvements over state - of - the - art procedures . D. Grangier and S. Bengio .A discriminative kernel - based model to rank images from text queries .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 30(8):1371 - 1384 , 2008 .", "label": "", "metadata": {}}
{"text": "This paper introduces a discriminative model for the retrieval of images from text queries .Our approach formalizes the retrieval task as a ranking problem , and introduces a learning procedure optimizing a criterion related to the ranking performance .The proposed model hence addresses the retrieval problem directly and does not rely on an intermediate image annotation task , which contrasts with previous research .Moreover , our learning procedure builds upon recent work on the online learning of kernel - based classifiers .This yields an efficient , scalable algorithm , which can benefit from recent kernels developed for image comparison .", "label": "", "metadata": {}}
{"text": "Further analysis of the results shows that our model is especially advantageous over difficult queries such as queries with few relevant pictures or multiple - word queries .J. Keshet , D. Grangier , and S. Bengio .Discriminative keyword spotting .In ISCA Research Workshop on Non Linear Speech Processing , NOLISP , 2007 .[ .This paper proposes a new approach for keyword spotting , which is not based on HMMs .The proposed method employs a new discriminative learning procedure , in which the learning phase aims at maximizing the area under the ROC curve , as this quantity is the most common measure to evaluate keyword spotters .", "label": "", "metadata": {}}
{"text": "Building on techniques used for large margin methods for predicting whole sequences , our keyword spotter distills to a classifier in the abstract vector - space which separates speech utterances in which the keyword was uttered from speech utterances in which the keyword was not uttered .We describe a simple iterative algorithm for learning the keyword spotter and discuss its formal properties .Experiments with the TIMIT corpus show that our method outperforms the conventional HMM - based approach .J. Keshet , D. Grangier , and S. Bengio .Discriminative keyword spotting .Speech Communication , 51:317 - 329 , 2009 .", "label": "", "metadata": {}}
{"text": "This paper proposes a new approach for keyword spotting , which is based on large margin and kernel methods rather than on HMMs .Unlike previous approaches , the proposed method employs a discriminative learning procedure , in which the learning phase aims at achieving a high area under the ROC curve , as this quantity is the most common measure to evaluate keyword spotters .The keyword spotter we devise is based on mapping the input acoustic representation of the speech utterance along with the target keyword into a vector space .Building on techniques used for large margin and kernel methods for predicting whole sequences , our keyword spotter distills to a classifier in this vector - space , which separates speech utterances in which the keyword is uttered from speech utterances in which the keyword is not uttered .", "label": "", "metadata": {}}
{"text": "Experiments on read speech with the TIMIT corpus show that the resulted discriminative system outperforms the conventional context - independent HMM - based system .Further experiments using the TIMIT trained model , but tested on both read ( HTIMIT , WSJ ) and spontaneous speech ( OGI - Stories ) , show that without further training or adaptation to the new corpus our discriminative system outperforms the conventional context - independent HMM - based system .J. Keshet , S. Shalev - Shwartz , S. Bengio , Y. Singer , and D. Chazan .Discriminative kernel - based phoneme sequence recognition .", "label": "", "metadata": {}}
{"text": "[ .We describe a new method for phoneme sequence recognition given a speech utterance , which is not based on the HMM .In contrast to HMM - based approaches , our method uses a discriminative kernel - based training procedure in which the learning process is tailored to the goal of minimizing the Levenshtein distance between the predicted phoneme sequence and the correct sequence .The phoneme sequence predictor is devised by mapping the speech utterance along with a proposed phoneme sequence to a vector - space endowed with an inner - product that is realized by a Mercer kernel .", "label": "", "metadata": {}}
{"text": "We describe an iterative algorithm for learning the phoneme sequence recognizer and further describe an efficient implementation of it .We present initial encouraging experimental results with the TIMIT and compare the proposed method to an HMM - based approach . Q. Le and S. Bengio .Hybrid generative - discriminative models for speech and speaker recognition .Technical Report IDIAP - RR 02 - 06 , IDIAP , 2002 .[ .Generative probability models such as Hidden Markov Models are usually used for modeling sequences of data because of their ability to handle variable size sequences and missing information .", "label": "", "metadata": {}}
{"text": "An ideal classifier should have all the power of these two complementary approaches .A series of recent papers has suggested some techniques for mixing generative models and discriminative models .In one of them a fixed size vector ( the Fisher score ) containing sufficient statistics of a sequence is computed for a previously trained HMM and can then be used as input to a discriminative model for classification .The purpose of this project is thus to study , experiment , enhance and adapt these new approaches of integrating discriminative models such as SVM into generative models for sequence processing problems , such as speaker and speech recognition .", "label": "", "metadata": {}}
{"text": "Client dependent GMM - SVM models for speaker verification .In International Conference on Artificial Neural Networks , ICANN / ICONIP , Lecture Notes in Computer Science , volume LNCS 2714 , pages 443 - 451 .Springer Verlag , 2003 .[ .Generative Gaussian Mixture Models ( GMMs ) are known to be the dominant approach for modeling speech sequences in text independent speaker verification applications because of their scalability , good performance and their ability in handling variable size sequences .On the other hand , because of their discriminative properties , models like Support Vector Machines ( SVMs ) usually yield better performance in static classification problems and can construct flexible decision boundaries .", "label": "", "metadata": {}}
{"text": "A cross - validation method is also used in the baseline system to increase the number of client scores in the training phase , which enhances the results of the SVM models .Experiments carried out on the XM2VTS and PolyVar databases confirm the interest of this hybrid approach .J. Mari\u00e9thoz and S. Bengio .A kernel trick for sequences applied to text - independent speaker verification systems .Pattern Recognition , 40:2315 - 2324 , 2007 .[ .This paper present a principled SVM based speaker verification system .We propose a new framework and a new sequence kernel that can make use of any Mercer kernel at the frame level .", "label": "", "metadata": {}}
{"text": "The new system is compared to state - of - the - art GMM and other SVM based systems found in the literature on the Banca and Polyvar databases .The new system outperforms , most of the time , the other systems , statistically significantly .Finally , the new proposed framework clarifies previous SVM based systems and suggests interesting future research directions .V. Popovici , S. Bengio , and J.-P. Thiran .Kernel matching pursuit for large datasets .Pattern Recognition , 38(12):2385 - 2390 , 2005 .[ .Kernel Matching Pursuit is a greedy algorithm for building an approximation of a discriminant function as a linear combination of some basis functions selected from a kernel - induced dictionary .", "label": "", "metadata": {}}
{"text": "Starting from an approximating algorithm , the Weak Greedy Algorithm , we introduce a stochastic method for reducing the search space at each iteration .Then we study the implications of using an approximate algorithm and we show how one can control the trade - off between the accuracy and the need for resources .Finally we present some experiments performed on a large dataset that support our approach and illustrate its applicability . A. Pozdnoukhov and S. Bengio .From samples to objects in kernel methods .Technical Report IDIAP - RR 03 - 29 , IDIAP , 2003 .", "label": "", "metadata": {}}
{"text": "This paper presents a general method for incorporating prior knowledge into kernel methods .It applies when the prior knowledge can be formalized by the description of an object around each sample of the training set , assuming that all points in the given object share the same desired class .Two implementation techniques of this method , based on analytical kernel jittering and the vicinal risk minimization principle , are considered .Empirical results on one artificial dataset and one real dataset based on EEG signals demonstrate the performance of the proposed method . A. Pozdnoukhov and S. Bengio .", "label": "", "metadata": {}}
{"text": "In International Conference on Pattern Recognition , ICPR , volume 3 , pages 486 - 489 , 2004 .[ .This paper presents an application of the general sample - to - object approach to the problem of invariant image classification .The approach results in defining new SVM kernels based on tangent vectors that take into account prior information on known invariances .Real data of face images are used for experiments .The presented approach integrates virtual sample and tangent distance methods .We observe a significant increase in performance with respect to standard approaches .The experiments also illustrate ( as expected ) that prior knowledge becomes more important as the amount of training data decreases . A. Pozdnoukhov and S. Bengio .", "label": "", "metadata": {}}
{"text": "In International Conference on Machine Learning , ICML , Workshop on Learning with Partially Classified Training Data , 2005 . [ .This paper presents an approach for improving the performance of kernel classifiers applied to object categorization problems .The approach is based on the use of distributions centered around each training points , which are exploited for inter - class invariant image representation with local invariant features .Furthermore , we propose an extensive use of unlabeled images for improving the SVM - based classifier . A. Pozdnoukhov and S. Bengio .Graph - based invariant manifolds for invariant pattern recognition with kernel methods .", "label": "", "metadata": {}}
{"text": "[ .We present here an approach for applying the technique of modeling data transformation manifolds for invariant learning with kernel methods .The approach is based on building a kernel function on the graph modeling the invariant manifold .It provides a way for taking into account nearly arbitrary transformations of the input samples .The approach is verified experimentally on the task of optical character recognition , providing state - of - the - art performance on harder problem settings . A. Pozdnoukhov and S. Bengio .Invariances in kernel methods : From samples to objects .Pattern Recognition Letters , 27(10):1087 - 1097 , 2006 .", "label": "", "metadata": {}}
{"text": "This paper presents a general method for incorporating prior knowledge into kernel methods such as support vector machines .It applies when the prior knowledge can be formalized by the description of an object around each sample of the training set , assuming that all points in the given object share the same desired class .A number of implementation techniques of this method , based on hard geometrical objects and soft objects based on distributions are considered .Tangent vectors are extensively used for object construction .Empirical results on one artificial dataset and two real datasets of electro - encephalogram signals and face images demonstrate the usefulness of the proposed method .", "label": "", "metadata": {}}
{"text": "Semi - supervised kernel methods for regression estimation .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , 2006 .[ .The paper presents a semi - supervised kernel method for regression estimation in the presence of unlabeled patterns .The method exploits a recently proposed data - dependent kernel which is constructed in order to represent the inner geometry of the data .This kernel is implemented into Kernel Regression methods ( SVR , KRR ) .Experimental results aim to highlight the properties of the method and its advantages as compared to fully supervised approaches .", "label": "", "metadata": {}}
{"text": "One artificial and two real - world datasets were used to demonstrate the performance of the proposed algorithm .S. Bengio .Large scale visual semantic extraction .In Frontiers of Engineering - Reports on Leading - Edge Engineering from the 2011 Symposium , 2012 .Image annotation is the task of providing textual semantic to new images , by ranking a large set of possible annotations according to how they correspond to a given image .In the large scale setting , there could be millions of images to process and hundreds of thousands of potential distinct annotations .", "label": "", "metadata": {}}
{"text": "In such a space , one can then find the nearest annotations to a given image , or annotations similar to a given annotation .One can even build a visio - semantic tree from these annotations , that corresponds to how concepts ( annotations ) are similar to each other with respect to their visual characteristics .Such a tree will be different from semantic - only trees , such as WordNet , which do not take into account the visual appearance of concepts .S. Bengio and G. Heigold .Word embeddings for speech recognition .In Proceedings of the 15th Conference of the International Speech Communication Association , Interspeech , 2014 .", "label": "", "metadata": {}}
{"text": "Speech recognition systems have used the concept of states as a way to decompose words into sub - word units for decades .As the number of such states now reaches the number of words used to train acoustic models , it is interesting to consider approaches that relax the assumption that words are made of states .We present here an alternative construction , where words are projected into a continuous embedding space where words that sound alike are nearby in the Euclidean sense .We show how embeddings can still allow to score words that were not in the training dictionary .", "label": "", "metadata": {}}
{"text": "S. Bengio , J. Mari\u00e9thoz , and M. Keller .The expected performance curve .In International Conference on Machine Learning , ICML , Workshop on ROC Analysis in Machine Learning , 2005 . [ .In several research domains concerned with classification tasks , curves like ROC are often used to assess the quality of a particular model or to compare two or more models with respect to various operating points .Researchers also often publish some statistics coming from the ROC , such as the so - called break - even point or equal error rate .The purpose of this paper is to first argue that these measures can be misleading in a machine learning context and should be used with care .", "label": "", "metadata": {}}
{"text": "Furthermore , we show how to use adequately a non - parametric statistical test in order to produce EPCs with confidence intervals or assess the statistical significant difference between two models under various settings .S. Bengio , F. Pereira , Y. Singer , and D. Strelow .Group sparse coding .In Advances in Neural Information Processing Systems , NIPS .MIT Press , 2009 .[ .Bag - of - words document representations are often used in text , image and video processing .While it is relatively easy to determine a suitable word dictionary for text documents , there is no simple mapping from raw images or videos to dictionary terms .", "label": "", "metadata": {}}
{"text": "More robust approaches have been proposed recently that represent each visual descriptor as a sparse weighted combination of dictionary words .While favoring a sparse representation at the level of visual descriptors , those methods however do not ensure that images have sparse representation .In this work , we use mixed - norm regularization to achieve sparsity at the image level as well as a small overall dictionary .This approach can also be used to encourage using the same dictionary words for all the images in a class , providing a discriminative signal in the construction of image representations .", "label": "", "metadata": {}}
{"text": "S. Bengio , J. Weston , and D. Grangier .Label embedding trees for large multi - class tasks .In Advances in Neural Information Processing Systems , NIPS , 2010 .[ .Multi - class classification becomes challenging at test time when the number of classes is very large and testing against every possible class can become computationally infeasible .This problem can be alleviated by imposing ( or learning ) a structure over the set of classes .We propose an algorithm for learning a tree - structure of classifiers which , by optimizing the overall tree loss , provides superior accuracy to existing tree labeling methods .", "label": "", "metadata": {}}
{"text": "Large - scale content - based audio retrieval from text queries .In ACM International Conference on Multimedia Information Retrieval , MIR , 2008 .[ .In content - based audio retrieval , the goal is to find sound recordings ( audio documents ) based on their acoustic features .This content - based approach differs from retrieval approaches that index media files using metadata such as file names and user tags .We handle generic sounds , including a wide variety of sound effects , animal vocalizations and natural scenes .We test a scalable approach based on a passive - aggressive model for image retrieval ( PAMIR ) , and compare it to two state - of - the - art approaches ; Gaussian mixture models ( GMM ) and support vector machines ( SVM ) .", "label": "", "metadata": {}}
{"text": "We find that all three methods achieved very good retrieval performance .For instance , a positive document is retrieved in the first position of the ranking more than half the time , and on average there are more than 4 positive documents in the first 10 retrieved , for both datasets .PAMIR completed both training and retrieval of all data in less than 6 hours for both datasets , on a single machine .It was one to three orders of magnitude faster than the competing approaches .This approach should therefore scale to much larger datasets in the future .", "label": "", "metadata": {}}
{"text": "Large - scale online learning of image similarity through ranking : Extended abstract .In 4th Iberian Conference on Pattern Recognition and Image Analysis IbPRIA , 2009 .[ .Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning .Pairwise similarity plays a crucial role in classification algorithms like nearest neighbors , and is practically important for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video .In these tasks , users look for objects that are both visually similar and semantically related to a given object .", "label": "", "metadata": {}}
{"text": "To address real - world large - scale AI problem , like learning similarity over all images on the web , we need to develop new algorithms that scale to many samples , many classes , and many features .The current abstract presents OASIS , an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations .OASIS is an online dual approach using the passive - aggressive family of learning algorithms with a large margin criterion and an efficient hinge loss cost .Our experiments show that OASIS is both fast and accurate at a wide range of scales : for a dataset with thousands of images , it achieves better results than existing state - of - the - art methods , while being an order of magnitude faster .", "label": "", "metadata": {}}
{"text": "For large , web scale , datasets , OASIS can be trained on more than two million images from 150 K text queries within two days on a single CPU .Human evaluations showed that 35 % of the ten top images ranked by OASIS were semantically relevant to a query image .This suggests that query - independent similarity could be accurately learned even for large - scale datasets that could not be handled before .G. Chechik , V. Sharma , U. Shalit , and S. Bengio .An online algorithm for large scale image similarity learning .", "label": "", "metadata": {}}
{"text": "MIT Press , 2009 .[ .Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning .It stands in the core of classification methods like kernel machines , and is particularly useful for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video .In these tasks , users look for objects that are not only visually similar but also semantically related to a given object .Unfortunately , current approaches for learning similarity do not scale to large datasets , especially when imposing metric constraints on the learned similarity .", "label": "", "metadata": {}}
{"text": "Scalability is achieved through online learning of a bilinear model over sparse representations using a large margin criterion and an efficient hinge loss cost .OASIS is accurate at a wide range of scales : on a standard benchmark with thousands of images , it is more precise than state - of - the - art methods , and faster by orders of magnitude .On 2.7 million images collected from the web , OASIS can be trained within 3 days on a single CPU .The non - metric similarities learned by OASIS can be transformed into metric similarities , achieving higher precisions than similarities that are learned as metrics in the first place .", "label": "", "metadata": {}}
{"text": "G. Chechik , V. Sharma , U. Shalit , and S. Bengio .Large scale online learning of image similarity through ranking .Journal of Machine Learning Research , JMLR , 11:1109 - 1135 , 2010 .[ .Learning a measure of similarity between pairs of objects is an important generic problem in machine learning .It is particularly useful in large scale applications like searching for an image that is similar to a given image or finding videos that are relevant to a given video .In these tasks , users look for objects that are not only visually similar but also semantically related to a given object .", "label": "", "metadata": {}}
{"text": "This is both because typically their CPU and storage requirements grow quadratically with the sample size , and because many methods impose complex positivity constraints on the space of learned similarity functions .The current paper presents OASIS , an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations .OASIS is an online dual approach using the passive - aggressive family of learning algorithms with a large margin criterion and an efficient hinge loss cost .Our experiments show that OASIS is both fast and accurate at a wide range of scales : for a dataset with thousands of images , it achieves better results than existing state - of - the - art methods , while being an order of magnitude faster .", "label": "", "metadata": {}}
{"text": "On this large scale dataset , human evaluations showed that 35 % of the ten nearest neighbors of a given test image , as found by OASIS , were semantically relevant to that image .This suggests that query independent similarity could be accurately learned even for large scale datasets that could not be handled before . A. Frome , G. Corrado , J. Shlens , S. Bengio , J. Dean , M. Ranzato , and T. Mikolov .DeViSE : A deep visual - semantic embedding model .In Advances In Neural Information Processing Systems , NIPS , 2013 . [ .", "label": "", "metadata": {}}
{"text": "This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows .One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions .In this paper we present a new deep visual - semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text .We demonstrate that this model matches state - of - the - art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors , and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training .", "label": "", "metadata": {}}
{"text": "O. Glickman , I. Dagan , M. Keller , S. Bengio , and W. Daelemans .Investigating lexical substitution scoring for subtitle generation .In Tenth Conference on Computational Natural Language Learning , CONLL , 2006 .[ .This paper investigates an isolated setting of the lexical substitution task of replacing words with their synonyms .In particular , we examine this problem in the setting of subtitle generation and evaluate state of the art scoring methods that predict the validity of a given substitution .The paper evaluates two context independent models and two contextual models .The major findings suggest that distributional similarity provides a useful complementary estimate for the likelihood that two Wordnet synonyms are indeed substitutable , while proper modeling of contextual constraints is still a challenging task for future research . D. Grangier and S. Bengio .", "label": "", "metadata": {}}
{"text": "In Proceedings of the NIPS 2005Workshop on Learning to Rank , 2005 . [ .Information Retrieval ( IR ) aims at solving a ranking problem : given a query q and a corpus C , the documents of C should be ranked such that the documents relevant to q appear above the others .This task is generally performed by ranking the documents d in C according to their similarity with respect to q , sim ( q , d ) .However , such data are especially expensive to label , thus , as an alternative , we propose to rely on hyperlink data which convey analogous semantic relationships .", "label": "", "metadata": {}}
{"text": "Inferring document similarity from hyperlinks .In Proceedings of the Conference on Information and Knowledge Management , CIKM , 2005 . [ .Assessing semantic similarity between text documents is a crucial aspect in Information Retrieval systems .In this work , we propose to use hyperlink information to derive a similarity measure that can then be applied to compare any text documents , with or without hyperlinks .Two sets of experiments on different corpora show that this function compares favorably with OKAPI matching on document retrieval tasks . D. Grangier and S. Bengio .A neural network to retrieve images from text queries .", "label": "", "metadata": {}}
{"text": "Springer - Verlag , 2006 .[ .This work presents a neural network for the retrieval of images from text queries .The proposed network is composed of two main modules : the first one extracts a global picture representation from local block descriptors while the second one aims at solving the retrieval problem from the extracted representation .Both modules are trained jointly to minimize a loss related to the retrieval performance .This approach is shown to be advantageous when compared to previous models relying on unsupervised feature extraction : average precision over Corel queries reaches 26.2 % for our model , which should be compared to 21.6 % for PAMIR , the best alternative . D. Grangier and S. Bengio .", "label": "", "metadata": {}}
{"text": "In Proceedings of the 10th European Conference on Speech Communication and Technology , Eurospeech - Interspeech , 2007 .[ .This paper proposes a discriminative approach to template - based keyword detection .We introduce a method to learn the distance used to compare acoustic frames , a crucial element for template matching approaches .The proposed algorithm estimates the distance from data , with the objective to produce a detector maximizing the Area Under the receiver operating Curve ( AUC ) , i.e. the standard evaluation measure for the keyword detection problem .The experiments performed over a large corpus , SpeechDatII , suggest that our model is effective compared to an HMM system , e.g. the proposed approach reaches 93.8 % of averaged AUC compared to 87.9 % for the HMM . D. Grangier and S. Bengio .", "label": "", "metadata": {}}
{"text": "IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 30(8):1371 - 1384 , 2008 .[ .This paper introduces a discriminative model for the retrieval of images from text queries .Our approach formalizes the retrieval task as a ranking problem , and introduces a learning procedure optimizing a criterion related to the ranking performance .The proposed model hence addresses the retrieval problem directly and does not rely on an intermediate image annotation task , which contrasts with previous research .Moreover , our learning procedure builds upon recent work on the online learning of kernel - based classifiers .", "label": "", "metadata": {}}
{"text": "The experiments performed over stock photography data show the advantage of our discriminative ranking approach over state - of - the - art alternatives ( e.g. our model yields 26.3 % average precision over the Corel dataset , which should be compared to 22.0 % , for the best alternative model evaluated ) .Further analysis of the results shows that our model is especially advantageous over difficult queries such as queries with few relevant pictures or multiple - word queries .D. Grangier , F. Monay , and S. Bengio .A discriminative approach for the retrieval of images from text queries .", "label": "", "metadata": {}}
{"text": "Springer - Verlag , 2006 .[ .This work proposes a new approach to the retrieval of images from text queries .Contrasting with previous work , this method relies on a discriminative model : the parameters are selected in order to minimize a loss related to the ranking performance of the model , i.e. its ability to rank the relevant pictures above the non - relevant ones when given a text query .In order to minimize this loss , we introduce an adaptation of the recently proposed Passive - Aggressive algorithm .The generalization performance of this approach is then compared with alternative models over the Corel dataset .", "label": "", "metadata": {}}
{"text": "Learning to retrieve images from text queries with a discriminative model .In International Workshop on Adaptive Multimedia Retrieval , AMR , 2006 .[ .This work presents a discriminative model for the retrieval of pictures from text queries .The core idea of this approach is to minimize a loss directly related to the retrieval performance of the model .For that purpose , we rely on a ranking loss which has recently been successfully applied to text retrieval problems .The experiments performed over the Corel dataset show that our approach compares favorably with generative models that constitute the state - of - the - art ( e.g. our model reaches 21.6 % mean average precision with Blob and SIFT features , compared to 16.7 % for PLSA , the best alternative ) .", "label": "", "metadata": {}}
{"text": "Training highly multiclass classifiers .Journal of Machine Learning Research , JMLR , 15:1461 - 1492 , 2014 .[ .Classification problems with thousands or more classes often have a large variance in the confusability between classes , and we show that the more - confusable classes add more noise to the empirical loss that is minimized during training .We propose an online solution that reduces the effect of highly confusable classes in training the classifier parameters , and focuses the training on pairs of classes that are easier to differentiate at any given time in the training .", "label": "", "metadata": {}}
{"text": "Experiments on ImageNet benchmark datasets and proprietary image recognition problems with 15,000 to 97,000 classes show substantial gains in classification accuracy compared to one - vs - all linear SVMs and Wsabie .M. Keller and S. Bengio .Textual data representation .Technical Report IDIAP - RR 03 - 49 , IDIAP , 2003 .[ .We address in this report the problem of representing formally textual data .First , this problem is replaced in the context of automatic text processing .Then , the weaknesses of the basic document representation , i.e. the bag - of - words representation , are explained and some state - of - the - art methods claiming to overcome these weaknesses are reviewed .", "label": "", "metadata": {}}
{"text": "M. Keller and S. Bengio .Theme topic mixture model : A graphical model for document representation .In PASCAL Workshop on Learning Methods for Text Understanding and Mining , 2004 .[ .Automatic Text Processing tasks , documents are usually represented in the bag - of - word space .However , this representation does not take into account the possible relations between words .We propose here a review of a family of document density estimation models for representing documents .Inside this family we derive another possible model : the Theme Topic Mixture Model ( TTMM ) .", "label": "", "metadata": {}}
{"text": "Topics link words to each other and Themes gather documents with particular distribution over the topics .An experiment reports the performance of the different models in this family over a common task .M. Keller and S. Bengio .A neural network for text representation .In Proceedings of the 15th International Conference on Artificial Neural Networks : Biological Inspirations , ICANN , Lecture Notes in Computer Science , volume LNCS 3697 , pages 667 - 672 .Springer - Verlag , 2005 . [ .Text categorization and retrieval tasks are often based on a good representation of textual data .", "label": "", "metadata": {}}
{"text": "In this paper , we propose the use of a neural network based , non - probabilistic , solution , which captures jointly a rich representation of words and documents .Experiments performed on two information retrieval tasks using the TDT2 database and the TREC-8 and 9 sets of queries yielded a better performance for the proposed neural network model , as compared to PLSA and the classical TFIDF representations .J. Lee , S. Bengio , S. Kim , G. Lebanon , and Y. Singer .Local collaborative ranking .In International World Wide Web Conference , WWW , 2014 .", "label": "", "metadata": {}}
{"text": "Personalized recommendation systems are used in a wide variety of applications such as electronic commerce , social networks , web search , and more .Collaborative filtering approaches to recommendation systems typically assume that the rating matrix ( e.g. , movie ratings by viewers ) is low - rank .In this paper , we examine an alternative approach in which the rating matrix is locally low - rank .Concretely , we assume that the rating matrix is low - rank within certain neighborhoods of the metric space defined by ( user , item ) pairs .We combine a recent approach for local low - rank approximation based on the Frobenius norm with a general empirical risk minimization for ranking losses .", "label": "", "metadata": {}}
{"text": "Moreover , our method is easy to parallelize , making it a viable approach for large scale real - world rank - based recommendation systems .R. F. Lyon , M. Rehn , S. Bengio , T. C. Walters , and G. Chechik .Sound retrieval and ranking using sparse auditory representations .Neural Computation , 22(9):2390 - 2416 , 2010 .[ .To create systems that understand the sounds that humans are exposed to in everyday life , we need to represent sounds with features that can discriminate among many different sound classes .Here , we use a sound - ranking framework to quantitatively evaluate such representations in a large scale task .", "label": "", "metadata": {}}
{"text": "Using this approach we compare different auditory front ends and different ways of extracting sparse features from high - dimensional auditory images .We tested auditory models that use adaptive pole - zero filter cascade ( PZFC ) auditory filterbank and sparse - code feature extraction from stabilized auditory images via multiple vector quantizers .In addition to auditory image models , we also compare a family of more conventional Mel - Frequency Cepstral Coefficient ( MFCC ) front ends .The experimental results show a significant advantage for the auditory models over vector - quantized MFCCs .Ranking thousands of sound files with a query vocabulary of thousands of words , the best precision at top-1 was 73 % and the average precision was 35 % , reflecting a 18 % improvement over the best competing MFCC frontend .", "label": "", "metadata": {}}
{"text": "Zero - shot learning by convex combination of semantic embeddings .In International Conference on Learning Representations , ICLR , 2014 .[ .Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces .In some cases the embedding space is trained jointly with the image transformation .In other cases the semantic embedding space is established by an independent natural language processing task , and then the image transformation into that space is learned in a second stage .Proponents of these image embedding systems have stressed their advantages over the traditional classification framing of image understanding , particularly in terms of the promise for zero - shot learning - the ability to correctly annotate images of previously unseen object categories .", "label": "", "metadata": {}}
{"text": "Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors , and requires no additional training .We show that this simple and direct method confers many of and indeed outperforms state of the art methods on the ImageNet zero - shot learning task .M. Rehn , R. F. Lyon , S. Bengio , T. C. Walters , and G. Chechik .Sound ranking using auditory sparse - code representations .In ICML 2009 Workshop on Sparse Method for Music Audio , 2009 .[ .The task of ranking sounds from text queries is a good test application for machine - hearing techniques , and particularly for comparison and evaluation of alternative sound representations in a large - scale setting .", "label": "", "metadata": {}}
{"text": "Using this system allows us to focus on comparison of different auditory front ends and different ways of extracting sparse features from high - dimensional auditory images .In addition to two main auditory - image models , we also include and compare a family of more conventional Mel - Frequency Cepstral Coefficients ( MFCC ) front ends .The experimental results show a significant advantage for the auditory models over vector - quantized MFCCs .The two auditory models tested use the adaptive pole - zero filter cascade ( PZFC ) auditory filterbank and sparse - code feature extraction from stabilized auditory images via multiple vector quantizers .", "label": "", "metadata": {}}
{"text": "Using ranking precision - at - top - k performance measures , the best results are about 72 % top-1 precision and 35 % average precision , using a test corpus of thousands of sound files and a query vocabulary of hundreds of words .M. Stevens , S. Bengio , and Y. Singer .Efficient learning of sparse ranking functions .In B. Scholkopf , Z. Luo , and V. Vovk , editors , Empirical Inference .Springer , 2013 .Algorithms for learning to rank can be inefficient when they employ risk functions that use structural information .", "label": "", "metadata": {}}
{"text": "This loss is designed for problems in which we need to rank a small number of positive examples over a vast number of negative examples .In that context , we propose an efficient coordinate descent approach that scales linearly with the number of examples .We then present an extension that incorporates regularization thus extending Vapnik\u00bfs notion of regularized empirical risk minimization to ranking learning .We also discuss an extension to the case of multi - values feedback .Experiments performed on several benchmark datasets and large scale Google internal dataset demonstrate the effectiveness of learning algorithm in constructing compact models while retaining the empirical performance accuracy .", "label": "", "metadata": {}}
{"text": "Multi - tasking with joint semantic spaces for large - scale music annotation and retrieval .Journal of New Music Research , 40:337 - 348 , 2011 .[ .Music prediction tasks range from predicting tags given a song or clip of audio , predicting the name of the artist , or predicting related songs given a song , clip , artist name or tag .That is , we are interested in every semantic relationship between the different musical concepts in our database .In realistically sized databases , the number of songs is measured in the hundreds of thousands or more , and the number of artists in the tens of thousands or more , providing a considerable challenge to standard machine learning techniques .", "label": "", "metadata": {}}
{"text": "This choice of space is learnt by optimizing the set of prediction tasks of interest jointly using multi - task learning .Our single model learnt by training on the joint objective function is shown experimentally to have improved accuracy over training on each task alone .Our method also outperforms the baseline methods tried and , in comparison to them , is faster and consumes less memory .We also demonstrate how our method learns an interpretable model , where the semantic space captures well the similarities of interest .J. Weston , S. Bengio , and N. Usunier .", "label": "", "metadata": {}}
{"text": "In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases , ECML - PKDD , 2010 .Best Paper Award in Machine Learning [ .Image annotation datasets are becoming larger and larger , with tens of millions of images and tens of thousands of possible annotations .We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low - dimensional joint embedding space for both images and annotations .", "label": "", "metadata": {}}
{"text": "We also demonstrate how our method learns an interpretable model , where annotations with alternate spellings or even languages are close in the embedding space .Hence , even when our model does not predict the exact annotation given by a human labeler , it often predicts similar annotations , a fact that we try to quantify by measuring the newly introduced \" sibling \" precision metric , where our method also obtains excellent results .J. Weston , S. Bengio , and N. Usunier .Wsabie : Scaling up to large vocabulary image annotation .In Proceedings of the International Joint Conference on Artificial Intelligence , IJCAI , 2011 .", "label": "", "metadata": {}}
{"text": "Image annotation datasets are becoming larger and larger , with tens of millions of images and tens of thousands of possible annotations .We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at the top of the ranked list of annotations for a given image and learning a low - dimensional joint embedding space for both images and annotations .Our method , called Wsabie , both outperforms several baseline methods and is faster and consumes less memory .N. Gilardi and S. Bengio .Local machine learning models for spatial data analysis .", "label": "", "metadata": {}}
{"text": "[ .In this paper , we compare different machine learning algorithms applied to non stationary spatial data analysis .We show that models taking into account local variability of the data are better than models which are trained globally on the whole dataset .N. Gilardi and S. Bengio .Comparison of four machine learning algorithms for spatial data analysis .In G. Dubois , J. Malczewski , and M. DeCort , editors , Mapping radioactivity in the environment - Spatial Interpolation Comparison 97 , pages 222 - 237 .Office for Official Publications of the European Communities , Luxembourg , 2003 .", "label": "", "metadata": {}}
{"text": "This chapter proposes a clear methodology on how to use machine learning algorithms for spatial data analysis in order to avoid any bias and eventually obtain fair estimation of their performance on new data .Four different machine learning algorithms are presented , namely multilayer perceptrons ( MLP ) , mixture of experts ( ME ) , support vector regression ( SVR ) and a local version of the latter ( local SVR ) .Evaluation criteria adapted to geostatistical problems are also presented in order to compare adequately different models on the same dataset .Finally , an experimental comparison is given on the SIC97 dataset as well as an analysis of the results .", "label": "", "metadata": {}}
{"text": "Machine learning for automatic environmental mapping : when and how ?In G. Dubois , editor , Automatic mapping algorithms for routine and emergency monitoring data .Report on the Spatial Interpolation Comparison ( SIC2004 ) exercise , pages 123 - 138 .Office for Official Publications of the European Communities , Luxembourg , 2005 . [ .This paper discusses the opportunity of using Machine Learning techniques in an automatic environmental mapping context , as was the case for the SIC2004 exercise .First , the Machine Learning methodology is quickly described and compared to Geostatistics .From there , some clues about when to apply Machine Learning are proposed , and what outcomes can be expected from this choice .", "label": "", "metadata": {}}
{"text": "This illustrates some potential drawbacks of SVR and MLP for applications such as SIC2004 .N. Gilardi , S. Bengio , and M. Kanevski .Conditional gaussian mixture models for environmental risk mapping .In IEEE Workshop on Neural Networks for Signal Processing , NNSP , pages 777 - 786 , 2002 .[ .This paper proposes the use of Gaussian Mixture Models to estimate conditional probability density functions in an environmental risk mapping context .A conditional Gaussian Mixture Model has been compared to the geostatistical method of Sequential Gaussian Simulations and shows good performances in reconstructing local PDF .", "label": "", "metadata": {}}
{"text": "A connectionist system for medium - term horizon time series prediction .In International Workshop on Applications of Neural Networks to Telecommunications , IWANNT , Stockholm , Sweden , 1995 .[ . djvu ] .S. Bengio , F. Fessant , and D. Collobert .Use of modular architectures for time series prediction .Neural Processing Letters , 3(2):101 - 106 , 1996 .[ . F. Fessant , S. Bengio , and D. Collobert .On the prediction of solar activity using different neural network models .Annales Geophysicae , 14:20 - 26 , 1996 .[ . A. Gravey , S. Bengio , D. Collobert , and F. Clerot .", "label": "", "metadata": {}}
{"text": "Technical Report NT / LAA / EIA/132 , France T\u00e9l\u00e9com CNET , Lannion , France , 1996 .C. Dimitrakakis and S. Bengio .Boosting HMMs with an application to speech recognition .In IEEE International Conference on Acoustic , Speech , and Signal Processing , ICASSP , volume 5 , pages 621 - 624 , 2004 .[ .Boosting is a general method for training an ensemble of classifiers with a view to improving performance relative to that of a single classifier .While the original AdaBoost algorithm has been defined for classification tasks , the current work examines its applicability to sequence learning problems .", "label": "", "metadata": {}}
{"text": "C. Dimitrakakis and S. Bengio .Online policy adaptation for ensemble classifiers .In European Symposium on Artificial Neural Networks , ESANN , 2004 .[ .Ensemble algorithms can improve the performance of a given learning algorithm through the combination of multiple base classifiers into an ensemble .In this paper , the idea of using an adaptive policy for training and combining the base classifiers is put forward .The effectiveness of this approach for online learning is demonstrated by experimental results on several UCI benchmark databases .C. Dimitrakakis and S. Bengio .Boosting word error rates .", "label": "", "metadata": {}}
{"text": "[ .We apply boosting techniques to the problem of word error rate minimisation in speech recognition .This is achieved through a new definition of sample error for boosting and a training procedure for hidden Markov models .For this purpose we define a sample error for sentence examples related to the word error rate .Furthermore , for each sentence example we define a probability distribution in time that represents our belief that an error has been made at that particular frame .This is used to weigh the frames of each sentence in the boosting framework .", "label": "", "metadata": {}}
{"text": "C. Dimitrakakis and S. Bengio .Online adaptive policies for ensemble classifiers .Neurocomputing , 64:211 - 221 , 2005 .[ .Ensemble algorithms can improve the performance of a given learning algorithm through the combination of multiple base classifiers into an ensemble .In this paper we attempt to train and combine the base classifiers using an adaptive policy .This policy is learnt through a Q - learning inspired technique .Its effectiveness for an essentially supervised task is demonstrated by experimental results on several UCI benchmark databases .S. Chiappa and S. Bengio .HMM and IOHMM modeling of EEG rhythms for asynchronous BCI systems .", "label": "", "metadata": {}}
{"text": "[ .We compare the use of two Markovian models , HMMs and IOHMMs , to discriminate between three mental tasks for brain computer interface systems using an asynchronous protocol .We show that IOHMMs outperform HMMs but that , probably due to the lack of any prior information on the state dynamics , no practical advantage in the use of these models over their static counterparts is obtained .M. Keller and S. Bengio .Theme topic mixture model : A graphical model for document representation .In PASCAL Workshop on Learning Methods for Text Understanding and Mining , 2004 .", "label": "", "metadata": {}}
{"text": "Automatic Text Processing tasks , documents are usually represented in the bag - of - word space .However , this representation does not take into account the possible relations between words .We propose here a review of a family of document density estimation models for representing documents .Inside this family we derive another possible model : the Theme Topic Mixture Model ( TTMM ) .This model assumes two types of relations among textual data .Topics link words to each other and Themes gather documents with particular distribution over the topics .An experiment reports the performance of the different models in this family over a common task .", "label": "", "metadata": {}}
{"text": "Probabilistic models for melodic prediction .Artificial Intelligence Journal , 173(14):1266 - 1274 , 2009 .[ .Chord progressions are the building blocks from which tonal music is constructed .The choice of a particular representation for chords has a strong impact on statistical modeling of the dependence between chord symbols and the actual sequences of notes in polyphonic music .Melodic prediction is used in this paper as a benchmark task to evaluate the quality of four chord representations using two probabilistic model architectures derived from Input / Output Hidden Markov Models ( IOHMMs ) .Likelihoods and conditional and unconditional prediction error rates are used as complementary measures of the quality of each of the proposed chord representations .", "label": "", "metadata": {}}
{"text": "Also , representing chords only by their roots appears to be a good compromise in most of the reported experiments .J.-F. Paiement , D. Eck , and S. Bengio .A probabilistic model for chord progressions .In International Conference on Music Information Retrieval , ISMIR , 2005 .[ .Chord progressions are the building blocks from which tonal music is constructed .Inferring chord progressions is thus an essential step towards modeling long term dependencies in music .In this paper , a distributed representation for chords is designed such that Euclidean distances roughly correspond to psychoacoustic dissimilarities .", "label": "", "metadata": {}}
{"text": "Parameters in the graphical models are learnt with the EM algorithm and the classical Junction Tree algorithm is used for inference .Various model architectures are compared in terms of conditional out - of - sample likelihood .Both perceptual and statistical evidence show that binary trees related to meter are well suited to capture chord dependencies .J.-F. Paiement , D. Eck , and S. Bengio .Probabilistic melodic harmonization .In L. Lamontagne and M. Marchand , editors , Advances in Artificial Intelligence : 19th Conference of the Canadian Society for Computational Studies of Intelligence , Canadian AI , Lecture Notes in Computer Science , volume LNCS 4013 , pages 218 - 229 .", "label": "", "metadata": {}}
{"text": "[ .We propose a representation for musical chords that allows us to include domain knowledge in probabilistic models .We then introduce a graphical model for harmonization of melodies that considers every structural components in chord notation .We show empirically that root notes progressions exhibit global dependencies that can be better captured with a tree structure related to the meter than with a simple dynamical HMM that concentrates on local dependencies .However , a local model seems to be sufficient for generating proper harmonizations when root notes progressions are provided .The trained probabilistic models can be sampled to generate very interesting chord progressions given other polyphonic music components such as melody or root note progressions .", "label": "", "metadata": {}}
{"text": "A graphical model for chord progressions embedded in a psychoacoustic space .In International Conference on Machine Learning , ICML , 2005 .[ .Chord progressions are the building blocks from which tonal music is constructed .Inferring chord progressions is thus an essential step towards modeling long term dependencies in music .In this paper , a distributed representation for chords is designed such that Euclidean distances roughly correspond to psychoacoustic dissimilarities .Parameters in the graphical models are learnt with the EM algorithm and the classical Junction Tree algorithm .Various model architectures are compared in terms of conditional out - of - sample likelihood .", "label": "", "metadata": {}}
{"text": "J.-F. Paiement , Y. Grandvalet , and S. Bengio .Predictive models for music .Connection Science , 21(2 & 3):253 - 272 , 2009 .[ .Modeling long - term dependencies in time series has proved very difficult to achieve with traditional machine learning methods .This problem occurs when considering music data .In this paper , we introduce predictive models for melodies .We decompose melodic modeling into two subtasks .We first propose a rhythm model based on the distributions of distances between subsequences .Then , we define a generative model for melodies given chords and rhythms based on modeling sequences of Narmour features .", "label": "", "metadata": {}}
{"text": "Using a similar evaluation procedure , the proposed melodic model consistently outperforms an Input / Output Hidden Markov Model .Furthermore , these models are able to generate realistic melodies given appropriate musical contexts .J.-F. Paiement , Y. Grandvalet , S. Bengio , and D. Eck .A generative model for rhythms .In NIPS Workshop on Brain , Music and Cognition , 2007 .[ .Modeling music involves capturing long - term dependencies in time series , which has proved very difficult to achieve with traditional statistical methods .The same problem occurs when only considering rhythms .", "label": "", "metadata": {}}
{"text": "A specific implementation of the model when considering Hamming distances over a simple rhythm representation is described .The proposed model consistently outperforms a standard Hidden Markov Model in terms of conditional prediction accuracy on two different music databases . J.-F. Paiement , Y. Grandvalet , S. Bengio , and D. Eck .A distance model for rhythms .In International Conference on Machine Learning , ICML , 2008 .[ .Modeling long - term dependencies in time series has proved very difficult to achieve with traditional machine learning methods .This problem occurs when considering music data .", "label": "", "metadata": {}}
{"text": "A specific implementation of the model when considering Hamming distances over a simple rhythm representation is described .The proposed model consistently outperforms a standard Hidden Markov Model in terms of conditional prediction accuracy on two different music databases . D. Zhang , D. Gatica - Perez , S. Bengio , and D. Roy .Learning influence among interacting markov chains .In Advances in Neural Information Processing Systems , NIPS 18 .MIT Press , 2005 .[ .We present a model that learns the influence of interacting Markov chains within a team .The proposed model is a dynamic Bayesian network ( DBN ) with a two - level structure : individual - level and group - level .", "label": "", "metadata": {}}
{"text": "Experiments on synthetic multi - player games and a multi - party meeting corpus show the effectiveness of the proposed model .S. Bengio , L. Deng , H. Larochelle , H. Lee , and R. Salakhutdinov .Guest editors ' introduction : Special section on learning deep architectures .IEEE Transactions on Pattern Analysis and Machine Intelligence ( PAMI ) , 35:1795 - 1797 , 2013 . [ . D. Erhan , Y. Bengio , A. Courville , P.-A. Manzagol , P. Vincent , and S. Bengio .Why does unsupervised pre - training help deep learning ?Journal of Machine Learning Research , JMLR , 11:625 - 660 , 2010 .", "label": "", "metadata": {}}
{"text": "Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto - encoder variants , with impressive results obtained in several areas , mostly on vision and language data sets .The best results obtained on supervised learning tasks involve an unsupervised learning component , usually in an unsupervised pre - training phase .Even though these new algorithms have enabled training deep models , many questions remain as to the nature of this difficult learning problem .The main question investigated here is the following : how does unsupervised pre - training work ?", "label": "", "metadata": {}}
{"text": "We propose several explanatory hypotheses and test them through extensive simulations .We empirically show the influence of pre - training with respect to architecture depth , model capacity , and number of training examples .The experiments confirm and clarify the advantage of unsupervised pre - training .The results suggest that unsupervised pre - training guides the learning towards basins of attraction of minima that support better generalization from the training data set ; the evidence from these results supports a regularization explanation for the effect of pre - training .D. Erhan , P.-A. Manzagol , Y. Bengio , S. Bengio , and P. Vincent .", "label": "", "metadata": {}}
{"text": "In D. van Dyk and M. Wellings , editors , Proceedings of The Twelfth International Conference on Artificial Intelligence and Statistics , AISTATS , volume 5 of JMLR Workshop and Conference Procedings , pages 153 - 160 , 2009 .[ .Whereas theoretical work suggests that deep architectures might be more efficient at representing highly - varying functions , training deep architectures was unsuccessful until the recent advent of algorithms based on unsupervised pre - training .Even though these new algorithms have enabled training deep models , many questions remain as to the nature of this difficult learning problem .", "label": "", "metadata": {}}
{"text": "We attempt to shed some light on these questions through extensive simulations .The experiments confirm and clarify the advantage of unsupervised pre - training .They demonstrate the robustness of the training procedure with respect to the random initialization , the positive effect of pre - training in terms of optimization and its role as a regularizer .We empirically show the influence of pre - training with respect to architecture depth , model capacity , and number of training examples .V. Ramanathan , J. Deng , C. Li , W. Han , Z. Li , K. Gu , Y. Song , S. Bengio , C. Rosenberg , and F.-F. Li .", "label": "", "metadata": {}}
{"text": "In IEEE Conference on Computer Vision and Pattern Recognition , CVPR , 2015 .[ .Human actions capture a wide variety of interactions between people and objects .As a result , the set of possible actions is extremely large and it is difficult to obtain sufficient training examples for all actions .However , we could compensate for this sparsity in supervision by leveraging the rich semantic relationship between different actions .A single action is often composed of other smaller actions and is exclusive of certain others .We would like our method to reason about such relationships and extrapolate unobserved actions from known actions .", "label": "", "metadata": {}}
{"text": "Our model incorporates linguistic , visual and logical consistency based cues to effectively identify theses relationships .We train and test our model on a new largescale image dataset of human actions under two settings with 27 K and 2 K actions .We show a significant improvement in mean AP compared to different baseline methods including the state - of - the - art HEX - graph approach from Deng et al . .O. Vinyals , S. Bengio , and M. Kudlur .Order matters : Sequence to sequence for sets .In International Conference on Learning Representations , ICLR , 2016 . [ .", "label": "", "metadata": {}}
{"text": "Many complex tasks that require mapping from or to a sequence of observations can now be formulated with the sequence - to - sequence ( seq2seq ) framework which employs the chain rule to efficiently represent the joint probability of sequences .In many cases , however , variable sized inputs and/or outputs might not be naturally expressed as sequences .In this paper , we first show using various examples that the order in which we organize input and/or output data matters significantly when learning an underlying model .We then discuss an extension of the seq2seq framework that goes beyond sequences and handles input sets in a principled way .", "label": "", "metadata": {}}
{"text": "We show empirical evidence of our claims regarding ordering , and on the modifications to the seq2seq framework on benchmark language modeling and parsing tasks , as well as two artificial tasks - sorting numbers and estimating the joint probability of unknown graphical models .O. Vinyals , A. Toshev , S. Bengio , and D. Erhan .Show and tell : A neural image caption generator .In IEEE Conference on Computer Vision and Pattern Recognition , CVPR , 2015 . [ .Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing .", "label": "", "metadata": {}}
{"text": "The model is trained to maximize the likelihood of the target description sentence given the training image .Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions .Our model is often quite accurate , which we verify both qualitatively and quantitatively .For instance , while the current state - of - the - art BLEU-1 score ( the higher the better ) on the Pascal dataset is 25 , our approach yields 59 , to be compared to human performance around 69 .We also show BLEU-1 score improvements on Flickr30k , from 56 to 66 , and on SBU , from 19 to 28 .", "label": "", "metadata": {}}
{"text": "Abstract .Many features have been proposed for speech - based emotion recognition , and a majority of them are frame based or statistics estimated from frame - based features .Temporal information is typically modelled on a per utterance basis , with either functionals of frame - based features or a suitable back - end .This paper investigates an approach that combines both , with the use of temporal contours of parameters extracted from a three - component model of speech production as features in an automatic emotion recognition system using a hidden Markov model ( HMM)-based back - end .", "label": "", "metadata": {}}
{"text": "Specifically , linear approximations to temporal contours of formant frequencies , glottal parameters and pitch are used to model short - term temporal information over individual segments of voiced speech .This is followed by the use of HMMs to model longer - term temporal information contained in sequences of voiced segments .Listening tests were conducted to validate the use of linear approximations in this context .Automatic emotion classification experiments were carried out on the Linguistic Data Consortium emotional prosody speech and transcripts corpus and the FAU Aibo corpus to validate the proposed approach .Keywords .Emotion recognition Paralinguistic information Pitch contours Formant contours Glottal spectrum Temporal information LDC emotional prosody speech corpus .", "label": "", "metadata": {}}
{"text": "The online version of this article ( doi : 10 .1186/\u200b1687 - 4722 - 2013 - 19 ) contains supplementary material , which is available to authorized users .Introduction .Human speech is an acoustic waveform generated by the vocal apparatus , whose parameters are modulated by the speaker to convey information .The physical characteristics and the mental state of the speaker also determine how these parameters are affected and , consequently , how speech conveys the intended , and on occasion unintended , information .Even though knowledge about how these parameters characterise the information is not explicitly available , the human brain is able to decipher this information from the resulting speech signal , including the emotional state of the speaker .", "label": "", "metadata": {}}
{"text": "It would be impossible to list all of them ; however , approaches that use linguistic cues [ 10 , 11 ] are not as common as those that make use of low - level acoustic and prosodic cues .The most commonly used acoustic and prosodic features tend to be those based on cepstral coefficients , pitch , intensity and speech rate .The standard speech production model ( source - filter model ) [ 12 ] , widely used in speech processing literature , is the model that underpins most low - level feature extraction algorithms .However , almost universally , a simplifying assumption is made about the shape of the glottal pulses .", "label": "", "metadata": {}}
{"text": "Section 2 explores the estimation of glottal parameters without making such an assumption .The standard speech production model is also a short - term spectral model , and almost all low - level features tend to be short - term frame - based features incapable of capturing long - term temporal information .In this paper we explore a combination of both approaches .Short - term temporal information is captured by the front - end , and longer - term temporal information is modelled by the back - end .Section 5.2 reports the results of a listening test carried out to validate the use of linear approximations of glottal parameter contours , conducted in a similar manner to a previous listening test carried out to validate the use of linear approximations to pitch contours [ 21 ] .", "label": "", "metadata": {}}
{"text": "The glottal source parameters .Glottal flow models .In the well - established and commonly used speech production model [ 12 ] , the glottal flow that serves as the input to the vocal tract is modelled as the response of a filter .The shape of this response ( glottal pulse shape ) has been associated with certain characteristics of speech that are subsumed under the cover term voice quality [ 22 ] .The importance of appropriate glottal models in the synthesis of natural sounding speech has been well established [ 22 , 23 ] , and the modification of glottal voice quality factors has been shown to be significant for the synthesis of emotional ( expressive ) speech [ 24 ] .", "label": "", "metadata": {}}
{"text": "Stylised glottal flow derivative magnitude spectrum , after the work of Doval et al .[ 32 ] .Estimation of glottal spectral parameters .However , numerous techniques have been proposed over the years that are based on the properties of the glottal flow signal [ 33 - 38 ] .The iterative adaptive inverse filtering ( IAIF ) method [ 33 ] was used to estimate the glottal flow derivative in the work reported in this paper .The IAIF method can be used pitch synchronously ( with variable window lengths based on pitch ) or asynchronously ( with fixed windows ) .", "label": "", "metadata": {}}
{"text": "Given an estimate of the glottal flow derivative , it is proposed that the best stylised fit to its magnitude spectral envelope ( Figure 1 ) , in terms of minimum mean squared error , can be estimated via brute force search of the three - dimensional parameter space .The choice of a brute force search was made purely due to the simplicity of the search algorithm even though it is not efficient .This approach was considered acceptable since the glottal parameters themselves are the focus of the work reported in this paper and not their estimation algorithms .", "label": "", "metadata": {}}
{"text": "G .F . g .A . g .F .c .A . g .g . g .A . g .g . g .c .A . g . g .c .c . m .In the experiments reported in this paper , all computations were carried out on discrete values of f , corresponding to the discrete Fourier transform coefficients computed from each frame of speech .This mean squared error was computed for all possible combinations of F g , A g and F c with the search space spanning all possible values of the three parameters with a resolution of 30 values for each parameter .", "label": "", "metadata": {}}
{"text": "F .^ .g .A .^ .g .F .^ .c . , that gave the lowest mean squared error was then selected as the best fit : .F .^ .g .A .^ .g .F .^ .c . arg .min .Fg .Ag .Fc .G .^ .G .Fg .Ag .Fc .An overview of the glottal spectral parameter estimation method is given in Figure 2 .This indicates that the spectrum fitting process is robust , to a certain extent , to errors in the glottal flow derivative estimation process that result from incomplete removal of the formant structure , particularly in terms of identifying the glottal formant .", "label": "", "metadata": {}}
{"text": "Therefore , F c was ignored and only the glottal formant frequency and magnitudes , F g and A g , were used in the automatic classification results reported in this paper .These frequency domain parameters are related to the more commonly utilised time domain parameters such as the open quotient and speed quotient [ 32 ] .However , the frequency domain parameters can be obtained by fitting the linearly stylised spectrum as outlined , which is conceptually simpler than the time domain curve fitting methods required to estimate the time domain parameters .Parameter contours .As previously mentioned , the study aims to capture short - term temporal information in the front - end prior to modelling longer - term information with the back - end .", "label": "", "metadata": {}}
{"text": "Parameter contours are representative of these variations over an entire utterance and are characterised by a much longer duration when compared with descriptions provided by deltas and shifted deltas .The most common and probably best studied is the pitch ( F 0 ) contour , which is essentially pitch as a function of time , and its use in an automatic emotion recognition ( AER ) framework was the focus of a previous study [ 21 ] .The idea of such stylisation can be extended to the other parameters , such as the glottal formant and magnitude and formant frequencies and magnitude as well .", "label": "", "metadata": {}}
{"text": "This is done to ensure that a single three - dimensional vector can describe an entire contour for each voiced segment .Approximating parameter contours .( a ) Estimated F 0 contour .( b )Linear approximation of F 0 contour .( c )Linear model parameters - \u03c4 , s and b ( or m ) .A small variation to the representation of the linear approximation to the contours involves the use of the value of the midpoint ( m ) of the contour instead of the initial values .In general , any parameter that varies with time within an utterance can be linearly stylised for compact representation and ease of analysis .", "label": "", "metadata": {}}
{"text": "Hence , an utterance can be compactly represented as a sequence of vectors , V : .V .N .where N is the number of voiced segments in the utterance , and \u03bd ( i ) is a vector corresponding to the i th voiced segment , . i .s .F . i .b .F . i .s .F . i .b .F .i .M .i .F .F .F .A .A .A .F . g .A . g .", "label": "", "metadata": {}}
{"text": "Note that the lengths of the contours are identical for all model parameters within each voiced segment .Hence , only one element , \u03c4 ( i ) , in each vector is required to represent the contour length .Thus , \u03bd ( i ) is a 2 K + 1 dimensional vector , where K is the number of parameters chosen ( from P ) to represent each voiced segment , when slope and initial offset ( or midpoint ) are both used to represent a contour .If the slope values of some or all parameters are dropped , the vector has a lower dimension .", "label": "", "metadata": {}}
{"text": "Parameter contour examples for the phrase ' two thousand one ' .Elements of the source - filter model - based speech characterisation including glottal parameters .Emotional speech corpora .The experiments reported in this paper were performed using one of two databases , namely , the Emotional Prosody Speech and Transcripts corpus ( herein referred to as the LDC corpus ) [ 42 ] and the German FAU Aibo corpus [ 43 ] .The two databases have significant differences , with the LDC corpus containing ' acted ' emotional speech collected from seven professional actors with the speech comprising preselected , semantically neutral phrases .", "label": "", "metadata": {}}
{"text": "Moreover , the emotional categories present in both corpora are different , with the LDC corpus emphasising high - intensity ' prototypical ' emotions and the Aibo corpus focussing on low - intensity ' non - prototypical ' emotions .In addition , the LDC corpus contains English speech while the Aibo corpus contains German speech .LDC emotional speech and transcripts corpus .The Emotional Prosody Speech and Transcripts corpus contain audio recordings , recorded at a sampling rate of 22,050 Hz , and the corresponding transcripts ( word level transcripts that lack time stamps ) .The recordings were made by professional actors reading a series of semantically neutral utterances consisting of dates and numbers , spanning 14 distinct emotion categories , selected based on a German study [ 44 ] , and a ' neutral ' category that does not involve any emotional state .", "label": "", "metadata": {}}
{"text": "These five emotional classes are neutral , anger , happiness , sadness and boredom .Four female and three male actors participated in the creation of this database and were provided with descriptions of each emotional context , including situational examples adapted from those used in the German study .Flashcards were used to display series of four syllable dates and numbers to be uttered in the appropriate emotional category .During the recording , the actors repeated each phrase as many times as necessary until they were satisfied that the emotion was expressed and then moved onto the next phrase .", "label": "", "metadata": {}}
{"text": "This provided about 8 to 12 utterances per speaker for each of the five emotional categories .FAU Aibo emotion corpus .The German FAU Aibo Emotion Corpus [ 43 ] consists of spontaneous emotionally coloured children 's speech with recordings of 51 German children ( 30 females and 21 males ) aged between 10 and 13 from two different schools .The speech signals were recorded at a sampling rate of 48 kHz with 16-bit quantisation and then down - sampled to a rate of 16 kHz .The children were given different tasks where they had to direct Sony 's dog - like robot Aibo to certain objects and along given ' parcours ' .", "label": "", "metadata": {}}
{"text": "However , Aibo was remote - controlled from behind the scenes and at certain positions it was made to disobey or act in some manner not instructed by the child ' controlling ' it in order to elicit an emotionally coloured response from the child .It is important to note that the real purpose of the data collection experiment , the elicitation of the emotions , was not known to the children , and none of them realised that Aibo was remote - controlled .The recorded speech data was then annotated independently at the word level by five listeners using 11 emotional categories .", "label": "", "metadata": {}}
{"text": "The emotional categories assigned to each word in the chunk by all five listeners were combined heuristically to generate a single emotion label for the chunk .Validating linear approximations - listening test .Listening tests were conducted to determine whether linear approximations to pitch contour segments and glottal parameter contour segments retained sufficient information about the emotions being expressed .More complex models of formant contours will result in less error and consequently less distortion at the cost of a larger number of parameters .The use of more complex models may be investigated in the future .Speech re - synthesis .", "label": "", "metadata": {}}
{"text": "A synthesis method based on a non - stationary AM - FM type representation of speech , which is very close to the sinusoidal representation [ 46 ] , was used .This method was chosen since all the estimated parameter contours , particularly the pitch contour , can be directly incorporated without any further processing : . s .t . k .N .V . kf .t .t .G . kf .t .t . sin .t . kf . d\u03c4 .The pitch contours were estimated using the RAPT algorithm [ 47 ] , and the vocal tract and glottal spectra were estimated using the pitch synchronous IAIF algorithm [ 33 ] .", "label": "", "metadata": {}}
{"text": "Based on these linear approximations , the glottal contribution to the amplitudes of the pitch harmonics , G ( f , t ) , was computed as per the stylised glottal flow derivative spectrum ( Figure 1 ) used to estimate the glottal parameters .Thus , the parameters of the re - synthesised speech samples were identical to those of the original samples except for the glottal parameters , allowing for a subjective evaluation of the linear approximation to these parameter contours .It should be noted that the representation of speech as a sum of harmonic sinusoids used in this re - synthesis method holds only for voiced speech and was only applied to segments where pitch estimates were available .", "label": "", "metadata": {}}
{"text": "This was deemed acceptable , since the automatic emotion recognition system utilised only voiced segments , as is common with most other emotion recognition systems .Subjective evaluation .A listening test was conducted to determine whether linear approximations to glottal parameter contours are able to retain emotion - specific information .Fourteen untrained listeners were involved in this test .For each listener , 30 speech utterances were drawn at random from the LDC corpus such that there were 6 utterances from each of the five emotions ( neutral , anger , sadness , happiness and boredom ) .", "label": "", "metadata": {}}
{"text": "All 60 utterances were then presented to the listener in random order and for each he / she was asked to pick one out of the five emotional categories that they could associate with the utterance .Their decisions were then analysed to determine for how many of the 30 possible pairs the listener selected the same emotion for both utterances .The decisions of all 14 listeners were then combined to compute the percentage of speech samples for which listeners associated the same emotion with both the original and re - synthesised version .The number of pairs where the listener assigned the same emotion to both versions , out of a maximum possible of 30 , is given ( as percentages ) in Figure 5 .", "label": "", "metadata": {}}
{"text": "This is in agreement with the results of a previous listening test that suggested linear approximations to pitch parameter contours preserve a significant amount of emotion - specific information [ 21 ] .Percentage of pairs for which both versions were assigned the same emotion by the listener .Each listener was given 30 pairs , one version using actual contours of and one using linear approximations to F g , A g and F c .The fractions of utterances assigned to each of the five labels were 36.2 % ( neutral ) , 20 % ( anger ) , 15.7 % ( sadness ) , 10.2 % ( happiness ) and 17.9 % ( boredom ) .", "label": "", "metadata": {}}
{"text": "Automatic classification system .The front - end .In addition to subjective evaluations , the usefulness of linear approximations to speech parameter contours to automatic classification systems was evaluated .The front - end of these systems represents the linear approximation to each parameter ( P ) contour in a voiced segment ( i ) by its slope ( s P ( i ) ) and initial value ( b P ( i ) ) , as explained in Section 3 .Each utterance is then represented as a sequence of N such vectors , .V .N . , ( where N is the number of voiced segments in the utterance ) by the front - end .", "label": "", "metadata": {}}
{"text": "The choice of back - end is dictated by the requirement that it should be capable of modelling utterances represented by a sequence of vectors to capture longer - term temporal information , and hence hidden Markov models ( HMMs ) were chosen .There is less agreement , however , on the optimal number of states for these HMMs , with some studies suggesting four states [ 48 , 49 ] and others suggesting thirty - two or more [ 13 , 14 ] .However , in the system described in this paper , the parameters of the linear approximations to these contours describe the temporal evolution within each voiced segment , and the states of the HMM only describe the change across different segments .", "label": "", "metadata": {}}
{"text": "The number of states in each HMM determines how much of the variations in the contours between voiced segments in an utterance are modelled , which , in turn , depend on how many voiced segments are present in each utterance .A three - state HMM has sufficiently many states to model the variation in the initial , central and terminal segments of the utterance without over - fitting and losing the ability to generalise .Preliminary experiments on the LDC corpus supported this choice .Each state utilised a 4-mixture Gaussian mixture model .For experiments performed on the FAU Aibo corpus , the number of states and mixtures were picked based on a preliminary search and the results are discussed in Section 7.2 .", "label": "", "metadata": {}}
{"text": "Previously , a modified feature warping technique was proposed as a means of speaker normalisation [ 50 ] and was applied to all features in experiments reported in this paper unless otherwise stated .GMM - based classification system .In order to facilitate comparisons to help determine the significance of temporal information contained in parameter contours as opposed to the statistical distributions of parameter values , another classification system based on Gaussian mixture models ( GMMs ) was set up .The features used by this system are the frame - based values of the source - filter model parameters ( F 0 , A g , F g , A 1 - 3 , F 1 - 3 ) obtained prior to approximating their contours with straight lines .", "label": "", "metadata": {}}
{"text": "Experimental results .LDC corpus .The automatic classification systems setup for a five - emotion ( neutral , anger , sadness , happiness and boredom ) classification problem on the LDC corpus was implemented in a speaker - independent configuration .All experiments were repeated seven times in a ' leave - one - out ' manner , using data from one of the seven speakers as the test set in turn , and data from the other six speakers as the training set .The accuracies reported are the means of the seven trials .Classification experiments were performed using the HMM - based system using features based on pitch contour , glottal parameter contours and formant contours individually .", "label": "", "metadata": {}}
{"text": "The confusion matrices corresponding to these six experiments are given in Tables 1 , 2 , 3 , 4 , 5 and 6 .Emotion classification experiments were also performed using a GMM - based system with pitch , glottal parameter and formant parameter values as features in order to compare systems that model temporal information contained in linear contour approximations to those that modelled only the statistical distributions of the parameter values .A summary of the overall accuracies obtained from these experiments is given in Table 7 .These results indicate that the contour modelling approach is better than the static distribution modelling approach for pitch and glottal parameters .", "label": "", "metadata": {}}
{"text": "Consequently , their contours can be expected to be complementary ( unless the back - end models identical information from the different parameter contours in each voiced segment ) .This suggests that a system , such as the HMM - based one , can be used to model all the contours by simply concatenating the contour descriptors ( either slope , initial value or midpoint value or some combination of them ) to form the feature vector .It should be noted that while a static modelling approach was better than the contour modelling one for vocal tract parameters , the vocal tract parameters would still contribute towards a combined system if they are complementary to pitch and glottal parameters .", "label": "", "metadata": {}}
{"text": "The classification accuracies obtained are reported in Table 8 .This system uses the S - I description for pitch contours and the midpoint value ( MP ) description for glottal and vocal parameter contours , i.e. the feature vector corresponding to the i th voiced segment is given by .i . i .s .F . i .b .F .i . m .F . g .i . m .A . g .i . m .F .i . m .A .i . m .F .i . m .", "label": "", "metadata": {}}
{"text": "i . m .F .i . m .A . i . . .Table 8 .Confusion matrix for the HMM - based system using all parameter contours , .i . i .s .F . i .b .F .i . m .F . g .i . m .A . g .i . m .F .i . m .A .i . m .F .i . m .A .i . m .F .i . m .A . i .", "label": "", "metadata": {}}
{"text": "The overall accuracy obtained by 11 human listeners was 63.6 % .A comparison of this accuracy to the different automatic emotion classification systems mentioned above is summarised in Table 9 .In addition to determine the effect of longer - term temporal modelling afforded by the hidden Markov models , a one - state HMM system , identical in all other ways to the proposed system , was implemented and its performance is also included in Table 9 .Finally , a GMM ( 128-mixtures)-based system , trained on mel frequency cepstral coefficients ( MFCCs ) and \u0394MFCCs , was also implemented for comparison .", "label": "", "metadata": {}}
{"text": "The classification accuracies obtained by the system making use of all the model parameter contours is higher than the accuracies obtained by any of the individual systems , as expected .It should also be noted that the emotion - specific classification accuracies ( diagonal elements of the confusion matrix ) are all higher than 55 % , indicating that the system does not suffer from any inherent bias against one or more of the emotions .Moreover , the performance of the combined system compares very well with the human classification performance .Also , the automatic ( GMM - based ) system that did not make use of any temporal information had an overall classification accuracy of 59.0 % .", "label": "", "metadata": {}}
{"text": "FAU Aibo corpus .Similar to the experiments performed on the LDC corpus , those performed on the FAU Aibo corpus were constructed as a five - class emotion classification problem .The emotions involved , however , were different ( Anger , Emphatic , Neutral , Positive and Rest ) as outlined in Section 4.2 .The training and test sets for these classification experiments were taken as given in the guidelines to the INTERSPEECH 2009 Emotion Challenge [ 45 ] .Also in accordance with these guidelines , the metric used to quantify performance was the unweighted average recall ( UAR ) which should take into account relative imbalances in the number of occurrences of the different emotional states .", "label": "", "metadata": {}}
{"text": "The features used in these systems were identical to those used in the experiment used to obtain the results in Table 8 , i.e. .i . i .s .F . i .b .F .i . m .F . g .i . m .A . g .i . m .F .i . m .A .i . m .F .i . m .A .i . m .F .i . m .A . i .Consistently , the best UARs were obtained by systems using two - state HMMs .", "label": "", "metadata": {}}
{"text": "Using this back - end configuration , a series of experiments were carried out to compare the performances of systems that modelled temporal contours of pitch and glottal parameters and vocal tract parameters with the performances of systems that modelled only static distributions .GMM - based systems were used to model distributions without taking into account temporal contours .These experiments also compared the S - I representation to the MP representation for all three parameters and the results are summarised in Table 10 .This comparison is identical to the one carried out on the LDC corpus and reported in Table 7 .", "label": "", "metadata": {}}
{"text": "Summary of overall accuracies for systems evaluated on FAU Aibo corpus .It can be seen that the trends observed in the LDC corpus match the ones in these results .Similar to the results in Table 7 , systems that make use of temporal information ( HMM - based ) outperform the static system ( GMM ) when pitch and glottal parameters are considered , but not when vocal tract parameters are considered .Following this comparison , another experiment was performed to determine the best feature set .This would , in turn , reveal the best performance possible given the system setup and indicate what information is utilised .", "label": "", "metadata": {}}
{"text": "The five highest UARs obtained and the corresponding feature sets are reported in Table 11 .Table 11 also includes the UAR obtained when the standard parameter contour feature set was used by the system .Table 11 .Top 5 UARs obtained on the Aibo corpus and the corresponding feature set utilised .i .b .F .i . m .F .i . m .A . g .i .s .F . i .b .F . i . s .A . i .b .A . i .", "label": "", "metadata": {}}
{"text": "s .F . i .b .F .i . m .F . g .i . m .A . g .i . m .F .i . m .A . i .i . i .s .F .i . m .F .i . m .A . g .i . m .F .i . m .A . i .i . i .s .F .i . m .F . g .i . m .A . g .", "label": "", "metadata": {}}
{"text": "F .i . m .A . i .i . i .s .F . i .b .F .i . m .F . g .i . m .A . g .i . m .F .i . m .F .i . m .F .i . m .A .i . m .A .i . m .A . i . i .The trends in the feature sets corresponding to the five setups reported in Table 11 are potentially more interesting than the UARs themselves .", "label": "", "metadata": {}}
{"text": "This is in agreement with the systems evaluated on the LDC corpus ( Tables 1 , 2 , 4 and 5 ) .Also of interest is that these results suggest that information about the first formant is significantly more important than information about the second and third formants .However , classification tests indicated that this does not hold for the LDC corpus where dropping information about the second and third formants caused the classification accuracy to reduce from 62.6 % to 57.5 % .The reason for this difference in experimental results obtained from the two databases is not clear , but it could be due to the subtlety of the emotional states in the Aibo corpus or the fact that the languages spoken in both databases are different .", "label": "", "metadata": {}}
{"text": "Commonly automatic emotion recognition systems capture spectral information with frame - based information and temporal information by either computing a range of functionals over all the frame - level features in an utterance or by using a suitable back - end to model temporal variations of these frame - level features .In this paper we explore a combined approach , extracting ' short - term ' temporal information in the front - end and modelling ' longer - term ' temporal information with the back - end .The work also has the advantage of not requiring explicit separation of speech into utterances .", "label": "", "metadata": {}}
{"text": "By estimating glottal spectral parameter contours , the system is not constrained by the assumption that the glottal spectrum can be modelled as the response of a system with a fixed transfer function .Earlier work had indicated that linear approximations to pitch contours were acceptable for the purpose of emotion classification , and another listening test conducted as part of the work reported in this paper revealed that similar approximations to glottal parameter contours were acceptable as well .The paper also includes the classification accuracies obtained when tested on the German FAU Aibo Emotion Corpus on the five - class emotion classification problem originally outlined in the INTERSPEECH 2009 Emotion Challenge .", "label": "", "metadata": {}}
{"text": "Further , the choice of using linear approximations to model temporal information within voiced speech segments , while the simplest , may not be optimal and is an avenue for future work .Declarations .Authors ' original submitted files for images .Below are the links to the authors ' original submitted files for images .Competing interests .The authors declare that they have no competing interests .Authors ' Affiliations .The School of Electrical Engineering and Telecommunications , The University of New South Wales .References .Barra R , Montero JM , Macias - Guarasa J , D'Haro LF , San - Segundo R , Cordoba R : Prosodic and segmental rubrics in emotion identification , in Proceedings of the 2006 IEEE .", "label": "", "metadata": {}}
{"text": "Borchert M , Dusterhoft A : Emotions in speech - experiments with prosody and quality features in speech for use in categorical and dimensional emotion recognition environments , in Proceedings of 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering ( IEEE NLP - KE'05 ) .IEEE : Piscataway ; 2005:147 - 151 .Lugger M , Yang B : An incremental analysis of different feature groups in speaker independent emotion recognition , in Proceedings of the 16th International Congress of Phonetic Sciences , Saarbruecken , August 2007 .IEEE : Washington ; 2007 .pp .", "label": "", "metadata": {}}
{"text": "Pantic M , Rothkrantz LJM : Toward an affect - sensitive multimodal human - computer interaction .Proc IEEE 2003 , 91 : 1370 - 1390 .10.1109/JPROC.2003.817122 View Article .Ververidis D , Kotropoulos C : Emotional speech recognition : resources , features , and methods .Speech Communication 2006 , 48 : 1162 - 1181 .10.1016/j.specom.2006.04.003 View Article .Vidrascu L , Devillers L : Five emotion classes detection in real - world call center data : the use of various types of paralinguistic features , in Proceedings of International Workshop on Paralinguistic Speech - 2007 .", "label": "", "metadata": {}}
{"text": "Yacoub S , Simske S , Lin X , Burns J : Recognition of emotions in interactive voice response systems , in Proceedings of the 8th European Conference on Speech Communication and Technology , EUROSPEECH 2003 - INTERSPEECH 2003 .Geneva September 2003 , 1 - 4 : 729 - 732 .Bitouk D , Verma R , Nenkova A : Class - level spectral features for emotion recognition .Speech Communication 2010 , 52 : 613 - 625 .10.1016/j.specom.2010.02.010 View Article .El Ayadi M , Kamel MS , Karray F : Survey on speech emotion recognition : features , classification schemes , and databases .", "label": "", "metadata": {}}
{"text": "10.1016/j.patcog.2010.09.020 MATH View Article .Lee C , Narayanan S , Pieraccini R : Combining acoustic and language information for emotion recognition , in Seventh International Conference on Spoken Language Processing .Denver : September ; 2002:873 - 876 .Schuller B , Batliner A , Steidl S , Seppi D : Emotion recognition from speech : putting ASR in the loop , in Proceedings of IEEE International Conference on Acoustics , Speech and Signal Processing , ICASSP 2009 .IEEE :Piscataway ; 2009:4585 - 4588 .View Article .Fant G : Acoustic Theory of Speech Production .", "label": "", "metadata": {}}
{"text": "Schuller B , Rigoll G , Lang M : Hidden Markov model - based speech emotion recognition , in Proceedings of International Conference on Acoustics .IEEE , New York , 2003 : Speech , and Signal Processing , ( ICASSP'03 ) .vol 2 2nd edn ; 2003:1 - 4 .Nogueiras A , Moreno A , Bonafonte A , Mari\u00f1o J : Speech emotion recognition using hidden Markov models , in Proceedings of EUROSPEECH-2001 .Scandinavia : EUROSPEECH ; 2001:2679 - 2682 .Schuller B , Seppi D , Batliner A , Maier A , Steidl S : Towards more reality in the recognition of emotional speech , in Proceedings IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP 2007 ) , Honolulu , April 2007 .", "label": "", "metadata": {}}
{"text": "IEEE :Piscataway ; 2007:941 - 944 .Vlasenko B , Schuller B , Wendemuth A , Rigoll G : Frame vs. turn - level : emotion recognition from speech considering static and dynamic processing , in Affective Computing and Intelligent Interaction .Springer Berlin , Heidelberg , 2007 : Frame vs. turn - level : emotion recognition from speech considering static and dynamic processing , in Affective Computing and Intelligent Interaction ; 2007:139 - 147 .Planet S , Iriondo I , Socor\u00f3 J , Monzo C , Adell J : GTM - URL contribution to the INTERSPEECH 2009 Emotion Challenge , in Proceedings of the 10th Annual Conference of the International Speech Communication Association ( INTERSPEECH-2009 ) .", "label": "", "metadata": {}}
{"text": "Wu S , Falk TH , Chan W - Y : Automatic speech emotion recognition using modulation spectral features .Speech Communication 2011 , 53 : 768 - 785 .10.1016/j.specom.2010.08.013 View Article .Dumouchel P , Dehak N , Attabi Y , Dehak R , Boufaden N : Cepstral and long - term features for emotion recognition , in Proceedings of the 10th Annual Conference of the International Speech Communication Association ( INTERSPEECH-2009 ) .Brighton September 2009 , 6 - 10 : 344 - 347 .Moriyama T , Ozawa S : Emotion recognition and synthesis system on speech , in IEEE International Conference on Multimedia Computing and Systems , 1999 vol 1 . 1st edition .", "label": "", "metadata": {}}
{"text": "Sethu V , Ambikairajah E , Epps J : Pitch contour parameterisation based on linear stylisation for emotion recognition , in Proceedings of the 10th Annual Conference of the International Speech Communication Association ( INTERSPEECH-2009 ) .Brighton September 2009 , 6 - 10 : 2011 - 2014 .Childers DG , Lee CK : Vocal quality factors : analysis , synthesis , and perception .J. Acoust .Soc .Am .10.1121/1.402044 View Article .Cabral J , Renals S , Richmond K , Yamagishi J : Towards an improved modeling of the glottal source in statistical parametric speech synthesis , in 6th ISCA Workshop on Speech Synthesis .", "label": "", "metadata": {}}
{"text": "D'Alessandro C , Doval B : Voice quality modification for emotional speech synthesis , in Proceedings of the 8th European Conference on Speech Communication and Technology .Geneva : EUROSPEECH 2003 - INTERSPEECH 2003 ; 2003:1653 - 1656 .He L , Lech M , Allen N : On the importance of glottal flow spectral energy for the recognition of emotions in speech , in Proceedings of the 11th Annual Conference of the International Speech Communication Association , INTERSPEECH 2010 .Makuhari , Chiba , Japan September 2010 , 26 - 30 : 2346 - 2349 .Tao J , Kang Y : Features importance analysis for emotional speech classification , in Affective Computing and Intelligent Interaction .", "label": "", "metadata": {}}
{"text": "Rui S , Moore E : JF Torres , Investigating glottal parameters for differentiating emotional categories with similar prosodics , in IEEE International Conference on Acoustics , Speech and Signal Processing , ICASSP 2009 .New York : IEEE ; 2009:4509 - 4512 .Fant G , Liljencrants J , Lin Q : A four - parameter model of glottal flow .STL - QPSR 1985 , 4 : 1 - 13 .Rosenberg AE : Effect of glottal pulse shape on the quality of natural vowels .J. Acoust .Soc .Am .10.1121/1.1912389 View Article .Klatt DH , Klatt LC : Analysis , synthesis , and perception of voice quality variations among female and male talkers .", "label": "", "metadata": {}}
{"text": "Soc .Am .10.1121/1.398894View Article .Veldhuis R : A computationally efficient alternative for the Liljencrants - Fant model and its perceptual evaluation .J. Acoust .Soc .Am .10.1121/1.421103 View Article .Doval B : C d'Alessandro , N Henrich .The spectrum of glottal flow models .Acta Acustica united with Acustica 2006 , 92 : 1026 - 1046 .Alku P : Glottal wave analysis with pitch synchronous iterative adaptive inverse filtering , in Proceedings of the EUROSPEECH-1991 .Mechanicsburg : ICSA ; 1991:1081 - 1084 .Cabral J , Renals S , Richmond K , Yamagishi J : Glottal spectral separation for parametric speech synthesis , in Proceedings of INTERSPEECH-2008 .", "label": "", "metadata": {}}
{"text": "Frohlich M , Michaelis D , Strube HW : SIM - simultaneous inverse filtering and matching of a glottal flow model for acoustic speech signals .J. Acoust .Soc .Am .10.1121/1.1379076 View Article .Hui - Ling L : JO Smith III , Joint estimation of vocal tract filter and glottal source waveform via convex optimization , in 1999 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics .IEEE :Piscataway ; 1999:79 - 82 .Riegelsberger EL , Krishnamurthy AK : Glottal source estimation : methods of applying the LF - model to inverse filtering , in 1993 IEEE International Conference on Acoustics , Speech , and Signal Processing , ICASSP-93 , vol 2 . 2nd edition .", "label": "", "metadata": {}}
{"text": "Piscataway ; 1993 .pp .542 - 545 .Vincent D , Rosec O , Chonavel T : Estimation of LF glottal source parameters based on an ARX model , in Proceedings of INTERSPEECH 2005 - EUROSPEECH , 9th European Conference on Speech Communication and Technology .Lisbon September 2005 , 4 - 8 : 333 - 336 .Naylor PA , Anastasis K , Jon G , Mike B : Estimation of glottal closure instants in voiced speech using the DYPSA algorithm .IEEE Transactions on Audio , Speech , and Language Processing 2007 , 15 : 34 - 43 .", "label": "", "metadata": {}}
{"text": "Wang D , Narayanan S : Piecewise linear stylization of pitch via wavelet analysis , in Proceedings of INTERSPEECH 2005 - EUROSPEECH , 9th European Conference on Speech Communication and Technology .Lisbon September 2005 , 4 - 8 : 3277 - 3280 .Ravuri S : DPW Ellis , Stylization of pitch with syllable - based linear segments , in IEEE International Conference on Acoustics , Speech and Signal Processing , ICASSP 2008 .IEEE :Piscataway ; 2008:3985 - 3988 .View Article .Steidl S : Automatic Classification of Emotion - Related User States in Spontaneous Children 's Speech .", "label": "", "metadata": {}}
{"text": "Banse R , Scherer K : Acoustic profiles in vocal emotion expression .J. Pers .Soc .Psychol .View Article .Schuller B , Steidl S , Batliner A : The INTERSPEECH 2009 Emotion Challenge , in INTERSPEECH-2009 .Brighton : ISCA ; 2009:312 - 315 .McAulay R , Quatieri T : Speech analysis / synthesis based on a sinusoidal representation .Acoustics , Speech and Signal Processing , IEEE Transactions on 1986 , 34 : 744 - 754 .10.1109/TASSP.1986.1164910 View Article .Talkin D : A robust algorithm for pitch tracking ( RAPT ) , in Speech Coding and Synthesis .", "label": "", "metadata": {}}
{"text": "Nwe TL , Foo SW , De LC : Silva , Speech emotion recognition using hidden Markov models .Speech Communication 2003 , 41 : 603 - 623 .10.1016/S0167 - 6393(03)00099 - 2 View Article .Huang R , Ma C : Toward a speaker - independent real - time affect detection system , in 18thInternational Conference on Pattern Recognition ICPR 2006 .Volume 1 .New York : IEEE ; 2006:1204 - 1207 .Sethu V , Ambikairajah E , Epps J : Speaker normalisation for speech - based emotion detection , in 15th International Conference on Digital Signal Processing , 2007 .", "label": "", "metadata": {}}
{"text": "Piscataway ; 2007:611 - 614 .Copyright .\u00a9 Sethu et al . ; licensee Springer .This article is published under license to BioMed Central Ltd. ASA 127th Meeting M.I.T. 1994 June 6 - 10 .2pSP43 .Phonetic transition modeling for continuous speech recognition .Michael Phillips .James Glass .Spoken Language Systems Group , Lab . for Comput .Sci . , MIT , 545 Technology Sq . , Cambridge , MA 02139 .Currently , most speech recognition architectures model the speech signal as a nonoverlapping sequence of phonetic segments .A set of phonetic models is created that attempt to capture the acoustic - phonetic properties of individual phones , but do not explicitly model the transition between phones .", "label": "", "metadata": {}}
{"text": "While context - dependent phonetic modeling may capture some of this information , it is likely that more explicit models of phonetic transitions could offer performance improvements .In this talk , the use of phonetic transition models will be discussed within the context of summit , a segment - based continuous speech recognition system [ Zue et al . , ' ' Acoustic Segmentation and Phonetic Classification in the summit Speech Recognition System , ' ' Proc .ICASSP 89 , pp .389 - -392 , Glasgow , Scotland ( 1989)].The transition models use a feature vector based on Mel - frequency spectral coefficients ( MFSC 's ) .", "label": "", "metadata": {}}
{"text": "For example , in one configuration a total of eight averages were used which spanned a total time interval of 150 ms .In order to reduce the number of dimensions , a principal component analysis was performed .A set of diagonal Gaussian models is used to model the transitions .The models were tested by applying them to the N - Best sentence hypotheses from the recognition system .Each of the N - Best hypotheses is rescored using a linear combination ( optimized on training data ) of the segment and transition scores .Initial experiments have resulted in 10%--20 % reductions in word error rates .", "label": "", "metadata": {}}
{"text": "We address air - writing recognition problems in two companion papers .Part 2 addresses detecting and recognizing air - writing activities that are embedded in a continuous motion trajectory without delimitation .Detection of intended writing activities among superfluous finger movements unrelated to letters or words presents a challenge that needs to be treated separately from the traditional problem of pattern recognition .We first present a dataset that contains a mixture of writing and nonwriting finger motions in each recording .The LEAP from Leap Motion is used for marker - free and glove - free finger tracking .", "label": "", "metadata": {}}
{"text": "Consecutive writing events are converted into a writing segment .The recognition performance is further evaluated based on the detected writing segment .Our main contribution is to build an air - writing system encompassing both detection and recognition stages and to give insights into how the detected writing segments affect the recognition result .With leave - one - out cross validation , the proposed system achieves an overall segment error rate of 1.15 % for word - based recognition and 9.84 % for letter - based recognition .No preview \u00b7 Article \u00b7 Nov 2015 \u00b7 IEEE Transactions on Human - Machine Systems .", "label": "", "metadata": {}}
{"text": "Air - writing differs from conventional handwriting ; the latter contains the pen - up - pen - down motion , while the former lacks such a delimited sequence of writing events .We address air - writing recognition problems in a pair of companion papers .In Part I , recognition of characters or words is accomplished based on six - degree - of - freedom hand motion data .We address air - writing on two levels : motion characters and motion words .Isolated air - writing characters can be recognized similar to motion gestures although with increased sophistication and variability .", "label": "", "metadata": {}}
{"text": "A hidden Markov model is used for air - writing modeling and recognition .We show that motion data along dimensions beyond a 2-D trajectory can be beneficially discriminative for air - writing recognition .We investigate the relative effectiveness of various feature dimensions of optical and inertial tracking signals and report the attainable recognition performance correspondingly .The proposed system achieves a word error rate of 0.8 % for word - based recognition and 1.9 % for letter - based recognition .We also subjectively and objectively evaluate the effectiveness of air - writing and compare it with text input using a virtual keyboard .", "label": "", "metadata": {}}
{"text": "No preview \u00b7 Article \u00b7 Nov 2015 \u00b7 IEEE Transactions on Human - Machine Systems .[ Show abstract ] [ Hide abstract ] ABSTRACT : We describe the acoustic gaits - the natural human gait quantitative characteristics derived from the sound of footsteps as the person walks normally .Based on the statistical analysis of the parameter estimates , we show that the spatio - temporal parameters and gait characteristics obtained using the acoustic gait profile can consistently and reliably estimate a subset of clinical and biometric gait parameters currently in use for standardized gait assessments .We conclude that the Teager - Kaiser energy operator provides the most consistent gait parameter estimates showing the least variation across different sessions and zones .", "label": "", "metadata": {}}
{"text": "This is in contrast to the expensive and intrusive systems currently used in laboratory gait analysis such as the force plates , pressure mats and wearable sensors , some of which may change the gait parameters that are being measured .No preview \u00b7 Article \u00b7 Mar 2015 \u00b7 IEEE transactions on bio - medical engineering .[ Show abstract ] [ Hide abstract ] ABSTRACT :In this work , we propose recurrent deep neural networks ( DNNs ) for robust automatic speech recognition ( ASR ) .Full recurrent connections are added to certain hidden layer of a conventional feedforward DNN and allow the model to capture the temporal dependency in deep representations .", "label": "", "metadata": {}}
{"text": "We evaluate the proposed recurrent DNN architecture under the hybrid setup on both the 2nd CHiME challenge ( track 2 ) and Aurora-4 tasks .Experimental results on the CHiME challenge data show that the proposed system can obtain consistent 7 % relative WER improvements over the DNN systems , achieving state - of - the - art performance without front - end preprocessing , speaker adaptive training or multiple decoding passes .For the experiments on Aurora-4 , the proposed system achieves 4 % relative WER improvement over a strong DNN baseline system .[ Show abstract ] [ Hide abstract ] ABSTRACT :", "label": "", "metadata": {}}
{"text": "The main idea is to adapt the fundamental MCE criteria to reflect the cost - sensitive notion in that errors on keywords are much more significant than errors on non - keywords in an automatic speech recognition task .The notion of cost sensitivity leads to emphasis of keyword models in parameter optimization .Then we present a system which takes advantage of the weighted finite - state transducer ( WFST ) framework to efficiently implement the non - uniform MCE .To enhance the approach of non - uniform error cost minimization for keyword spotting , we further formulate a technique called \" adaptive boosted non - uniform MCE \" which incorporates the idea of boosting .", "label": "", "metadata": {}}
{"text": "Experimental results show our framework can achieve consistent and significant spotting performance gains over both the maximum likelihood estimation ( MLE ) baseline and conventional discriminatively - trained systems with uniform error cost .No preview \u00b7 Article \u00b7 Jan 2014 \u00b7 IEEE / ACM Transactions on Audio , Speech , and Language Processing .[ Show abstract ] [ Hide abstract ] ABSTRACT :In this paper , we propose a novel acoustic modeling framework , synchronous HMM , which takes full advantage of the capacity of the heterogeneous data sources and achieves an optimal balance between modeling accuracy and robustness .", "label": "", "metadata": {}}
{"text": "The substates have the capability to register long - span non - phonetic attributes , which are integrally called speech scenes in this study .The hierarchical modeling scheme allows an accurate description of probability distribution of speech units in different speech scenes .To address the data sparsity problem , a decision - based clustering algorithm is presented to determine the set of speech scenes and to tie the substate parameters .Moreover , we propose the multiplex Viterbi algorithm to efficiently decode the synchronous HMMs within a search space of the same size as for the standard HMMs .", "label": "", "metadata": {}}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT :In this work , we present a complete framework of discriminative training using non - uniform criteria for keyword spotting , adaptive boosted non - uniform minimum classification error ( MCE ) for keyword spotting on spontaneous speech .To further boost the spotting performance and tackle the potential issue of over - training in the non - uniform MCE proposed in our prior work , we make two improvements to the fundamental MCE optimization procedure .Furthermore , motivated by AdaBoost , we introduce an adaptive scheme to embed error cost functions together with model combinations during the decoding stage .", "label": "", "metadata": {}}
{"text": "In this work , we propose latent semantic rational kernels ( LSRK ) for topic spotting on spontaneous conversational speech .Rather than mapping the input weighted finite - state transducers ( WFSTs ) onto a high dimensional n - gram feature space as in n - gram rational kernels , the proposed LSRK maps the WFSTs onto a latent semantic space .Moreover , with the LSRK framework , all available external knowledge can be flexibly incorporated to boost the topic spotting performance .The experiments we conducted on a spontaneous conversational task , Switchboard , show that our method can achieve significant performance gain over the baselines from 27.33 % to 57.56 % accuracy and almost double the classification accuracy over the n - gram rational kernels in all cases .", "label": "", "metadata": {}}
{"text": "Their perception combines signatures from spectral and temporal domains , among others , yet traditionally their analysis is focused on the frame based spectral properties .We consider the problem of sound analysis from perceptual perspective and investigate the temporal properties of a \" footsteps \" sound , which is a particularly challenging from the time - frequency analysis viewpoint .We identify the irregular repetition of the self similarity and the sense of duration as significant to its perceptual quality and extract features using the Teager - Kaiser energy operator .We build an acoustic event detection system for \" footsteps \" which shows promising results for detection in cross - environmental conditions when compared with conventional approach .", "label": "", "metadata": {}}
{"text": "Due to the flexibility of SBR , the decorrelation performance as measured by the coherence can be matched with other conventional decorrelation procedures .Given the same degree of decorrelation , we have shown previously that SBR achieves superior audio quality compared to other procedures .We show in this paper that SBR also provides higher stereophonic AEC performance in a very noisy condition , where the performance is evaluated by decomposing the true echo return loss enhancement and the misalignment per sub - band to better demonstrate the superiority of our decorrelation procedure over other methods .[ Show abstract ] [ Hide abstract ] ABSTRACT : It is well established that a decorrelation procedure is required in a multi - channel acoustic echo control system to mitigate the so - called non - uniqueness problem .", "label": "", "metadata": {}}
{"text": "In this paper , we analyze with rigor the performance behavior of DBR in terms of coherence reduction and the resultant misalignment of an adaptive filter .We derive closed - form expressions for the performance bounds and validate the theoretical analysis with simulation .[ Show abstract ] [ Hide abstract ] ABSTRACT : A 6D motion gesture is represented by a 3D spatial trajectory and augmented by another three dimensions of orientation .Using different tracking technologies , the motion can be tracked explicitly with the position and orientation or implicitly with the acceleration and angular speed .", "label": "", "metadata": {}}
{"text": "Our main contribution is to investigate the relative effectiveness of various feature dimensions for motion gesture recognition in both user - dependent and user - independent cases .We introduce a statistical feature - based classifier as the baseline and propose an HMM - based recognizer , which offers more flexibility in feature selection and achieves better performance in recognition accuracy than the baseline system .Our motion gesture database which contains both explicit and implicit motion information allows us to compare the recognition performance of different tracking signals on a common ground .This study also gives an insight into the attainable recognition rate with different tracking devices , which is valuable for the system designer to choose the proper tracking technology .", "label": "", "metadata": {}}
{"text": "The regression parameters are usually shared among sets of Gaussians in HMMs where the Gaussian clusters are represented by a tree .This paper realizes a fully Bayesian treatment of linear regression for HMMs considering this regression tree structure by using variational techniques .This paper analytically derives the variational lower bound of the marginalized log - likelihood of the linear regression .By using the variational lower bound as an objective function , we can algorithmically optimize the tree structure and hyper - parameters of the linear regression rather than heuristically tweaking them as tuning parameters .Experiments on large vocabulary continuous speech recognition confirm the generalizability of the proposed approach , especially when the amount of adaptation data is limited .", "label": "", "metadata": {}}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : This paper introduces an approach to cluster and suppress acoustic echo signals in hands - free , full - duplex speech communication systems .We employ the instantaneous recursive estimate of the magnitude squared coherence ( MSC ) of the echo line signal and the microphone signal , and model it with a two - component Beta mixture distribution .Since we consider the case of multiple microphone pickup , we further integrate the normalized recording vector as location feature into the proposed approach to achieve reliable soft decisions on the echo presence .", "label": "", "metadata": {}}
{"text": "Simulation evaluations of the proposed method show that it can achieve significant echo suppression performance .[ Show abstract ] [ Hide abstract ] ABSTRACT : We have recently proposed the stranded HMM to achieve a more accurate representation of heterogeneous data .As opposed to the regular Gaussian mixture HMM , the stranded HMM explicitly models the relationships among the mixture components .The transitions among mixture components encode possible trajectories of acoustic features for speech units .Accurately representing the underlying transition structure is crucial for the stranded HMM to produce an optimal recognition performance .In this paper , we propose to learn the stranded HMM structure by imposing sparsity constraints .", "label": "", "metadata": {}}
{"text": "The experimental results showed that a significant improvement in model sparsity can be obtained with a slight sacrifice of the recognition accuracy .While iterative estimation of noise means in a generalized EM framework has been widely known , we demonstrate that such approaches are variants of the Gauss - Newton method .Furthermore , we propose a novel noise variance estimation algorithm that is consistent with the Gauss - Newton principle .The formulation of the Gauss - Newton method reduces the noise estimation problem to determining the Jacobians of the corrupted speech parameters .For sampling - based compensations , we present two methods , sample Jacobian average ( SJA ) and cross - covariance ( XCOV ) , to evaluate these Jacobians .", "label": "", "metadata": {}}
{"text": "The first is to fit a Gaussian mixture model ( GMM ) model to artificially corrupted samples , and the second is to perform speech recognition on the Aurora 2 database .The significant performance improvements confirm the efficacy of the Gauss - Newton method to estimating the noise parameters of the nonlinear compensation models .No preview \u00b7 Article \u00b7 Oct 2012 \u00b7 IEEE Transactions on Audio Speech and Language Processing .[ Show abstract ] [ Hide abstract ] ABSTRACT :In this paper , we present a general algorithmic framework based on WFSTs for implementing a variety of discriminative training methods , such as MMI , MCE , and MPE / MWE .", "label": "", "metadata": {}}
{"text": "The transducers are processed into a two - layer hierarchy : at a high level , it is analogous to a word lattice , and each word transition embodies an HMM - state subgraph for that word at a lower level .This hierarchy combined with the appropriate customization of the transducers leads to a flexible implementation for all of the training criteria being discussed .The effectiveness of the framework is verified on two speech recognition tasks : Resource Management , and AT&T SCANMail , an internal voicemail - to - text task .[ Show abstract ] [ Hide abstract ] ABSTRACT : This work focuses on a comparative study of discriminative training using non - uniform criteria for cross - layer acoustic modeling .", "label": "", "metadata": {}}
{"text": "To facilitate this comparative study , we implement both augmented DT frameworks under the same umbrella , using the error cost derived from the same cross - layer confusion matrix .Experiments on a large vocabulary task WSJ0 demonstrated the effectiveness of both DT frameworks with the formulated non - uniform error cost embedded .Several preliminary investigations on the effect of the dynamic range of error cost are also presented .[ Show abstract ] [ Hide abstract ] ABSTRACT : As the ubiquitous access to vast and remote information sources from portable devices becomes commonplace , the need from users to perform searches in keyboard - unfriendly situations grows substantially , thus triggering the increased demand of voice search sessions .", "label": "", "metadata": {}}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : The Bayes decision theory is the foundation of the classical statistical pattern recognition approach , with the expected error as the performance objective .For most pattern recognition problems , the \" error \" is conventionally assumed to be binary , i.e. , 0 or 1 , equivalent to error counting , independent of the specifics of the error made by the system .The term \" error rate \" is thus long considered the prevalent system performance measure .This performance measure , nonetheless , may not be satisfactory in many practical applications .", "label": "", "metadata": {}}
{"text": "In this paper , we propose an extended framework for the speech recognition problem with non - uniform classification / recognition error cost which can be controlled by the system designer .In particular , we address the issue of system model optimization when the cost of a recognition error is class dependent .We formulate the problem in the framework of the minimum classification error ( MCE ) method , after appropriate generalization to integrate the class - dependent error cost into one consistent objective function for optimization .We present a variety of training scenarios for automatic speech recognition under this extended framework .", "label": "", "metadata": {}}
{"text": "Preview \u00b7 Article \u00b7 Mar 2012 \u00b7 IEEE Transactions on Audio Speech and Language Processing A method and system for processing messages within the framework of an integrated message system .Recipients of messages in an integrated messaging system are provided with an authentic impression of the received message .Method and system for processing messages within the framework of an integrated message system US 7809117 B2 .R\u00e9sum\u00e9 .A method and system for processing messages within the framework of an integrated message system .Recipients of messages in an integrated messaging system are provided with an authentic impression of the received message .", "label": "", "metadata": {}}
{"text": "Language detection and dictation system is provided .The message contents of the incoming message as well as its segments and parameters are simultaneously utilized to generate additional information regarding the sender and the information , which is suitable to give the recipient an impression of the received message in the most authentic form possible . sound data , image data , messages with other types of media in connection with the instantaneous message , and data derived from additional information sources ; . data that were stored within the framework of previous messages of the sender in a sender data area for acquired and/or ascertained sender data ; and .", "label": "", "metadata": {}}
{"text": "The method as recited in .claim 1 , wherein , to translate the instantaneous message , the language of the message and/or a segment of the message is determined according to the relation .The method as recited in .The method as recited in .claim 1 , wherein the control of the individual translation modules of the translation module with decision matrix is implemented via the decision matrix into which both the result of the detection of the source language and the ascertained target language are input automatically .The method as recited in .claim 1 , wherein , in addition to the data resulting from the translation of the message , additional information is provided to the recipient of the message which is ascertained by utilizing principles of associate knowledge management .", "label": "", "metadata": {}}
{"text": "The method as recited in .The method as recited in .The method as recited in .The method as recited in .claim 1 , wherein the data regarding the most probable emotional state of the sender of the message is used to classify the messages in a priority list pertaining to the incoming messages .The method as recited in .The method as recited in .A system for processing messages within the framework of an integrated messaging system , comprising : . at least one translation system with automatic foreign language detection ; . at least one module for prosodic analysis of speaker emotions ; . at least one module for semantic analysis of sender emotions ; . at least one data memory with information regarding the languages that are able to be processed by the available emotion - analysis module and/or the translation module(s ) ; . at least one data memory with sample data and/or dynamic / static parameters and/or parameter linkages for analyzing collected sender information ; . at least one sender data area for acquired and/or ascertained sender data to which the data ascertained via the aforementioned module are supplied ; and .", "label": "", "metadata": {}}
{"text": "a module for language identification / language detection with the aid of a text , having access to an ASR module with algorithms for language detection ; .The system as recited in . claim 13 , wherein the classification block to which all data including supplementary data of a message are supplied according to the data type , is made up of .a message classification module in which the messages are sorted according to their message type ; . a linking matrix , which is connected to the message classification module and which is configured as assignment matrix ( n : m ) for different classes / categories ; and .", "label": "", "metadata": {}}
{"text": "FIELD OF THE INVENTION .BACKGROUND INFORMATION .Depending on the system structure , voice messages are often stored here as attachments of text messages ( e - mail attachments together with sender information ( such as sender identification ( e.g. , CLI , etc . ) ) , arrival time , etc . .These systems have at their disposal deterministic grammars ( e.g. , nuance grammar specification language ) or grammars based on internal statistics ( e.g. , Scansoft ) .pdf ) .A foreign language detection based on algorithms from speech - signal processing may be implemented by , for example , analyzing the frequency at which phonemes occur in a spoken utterance , which are provided by a phoneme - based speech detector .", "label": "", "metadata": {}}
{"text": "The method apparently includes the steps of receiving incoming telephone messages and detecting language in the incoming telephone messages by searching the incoming telephone messages for at least one previously defined information category .If a previously predefined information category is found in the detected language , the information is reproduced for the user .And , single - language systems are not always able to be used if , for instance , messages in different languages are involved .However , this and similar methods fail to take into account that the received voice messages may have been recorded in a language other than the one required for the recipient .", "label": "", "metadata": {}}
{"text": "Also available is classifying messages both according to acquired supplementary data and according to their contents , and to categorize them in accordance with the mailbox owner 's or the system operator 's intentions .Reference European patent no . 1298872 purportedly refers to a method for processing messages in a unified messaging system where different message categories are defined so that each message in a unified messaging system is able to be assigned to a rule that is part of at least one category .For example , the message category may include categories that are assigned to specific types or formats , as well as categories that are freely definable .", "label": "", "metadata": {}}
{"text": "This approach , too , fails to take a possible multi - linguality of incoming messages into account .Reference US 2002/0069048 presents some general ideas for translating messages with output in an audio format , without a detection of the source language having been described in greater detail .Such approaches have the disadvantage that during the dialogue with the system the message recipient is obliged to explain in cumbersome detail in what target languages he wishes the audio output of each individual message to occur .Also available are approaches that are based on detecting various sensor data and their transmission via a telecommunication network .", "label": "", "metadata": {}}
{"text": "SUMMARY OF THE INVENTION .Exemplary embodiments and/or methods of the present invention provide recipients of messages in an integrated messaging system with the most authentic impression of the message possible .This may apply both to the message itself , which is to be offered to the user in comprehensible form , and to additional information in connection with the message and message sender that can not be gathered explicitly from the message itself .Exemplary embodiments and/or methods also may solve the specific problem that the incoming message is a message expressed in a language that is unknown to the recipient .", "label": "", "metadata": {}}
{"text": "At the same time , the solution is aimed at improving the structuring of message groups and at improving the navigation within the messages itself .Exemplary embodiments and/or methods of the present inventions offer the messages to the recipient in the most authentic manner possible and as a real experience , engaging as many of the recipient 's senses as possible .This may increase the performance especially for a group of persons that is active on an international level for the most part .This may apply specifically to persons working in international management or in areas of international research , development and culture .", "label": "", "metadata": {}}
{"text": "The term message segment is understood to denote a part or an information unit of a message document such as a sentence , a sentence sequence , a word , a word sequence , a bit sequence , a paragraph , a paragraph sequence , or an attachment .Message segments may have an identical and/or different format , for instance an audio format , a text format , a video format , an image format , or also other possible formats .A link is possible as well .An identification within the meaning of the present invention may be made up of one and/or a plurality of classes .", "label": "", "metadata": {}}
{"text": "IMEI ( international mobile equipment identity ) .Telecard number .SIM card ( subscriber identity module ) smart card ; .the transaction identification for the communication transaction ; . biometrical identification such as .fingerprint .voice print .iris .Exemplary embodiments and/or methods of the present invention may provide that , in a first step , messages arriving via an integrated messaging system are translated into a language specified or preset by the recipient .To this end , incoming voice messages , for example , after conversion into source - text information by a speech recognition and dictation system , may be automatically translated into a desired target language and then made available to the user .", "label": "", "metadata": {}}
{"text": "In exemplary embodiments and/or methods , storing and/or collecting corresponding information such as , for example , the mailbox owner 's preferred target language , in an owner data area 170 .The owner data area is a memory area for acquired and/or ascertained owner data such as the ID code , user identification , mother tongue , desired target language , preferred TTS voice , preferred playback speed , target call numbers and search keywords for important messages .The setting may be made via a Web interface and browser , for example , by voice input in a multi - modal or uni - modal manner , or by e - mail via mailbox 30 of the mailbox owner .", "label": "", "metadata": {}}
{"text": "Language - evaluation module 100 , utilizing all available information , is used for the ultimate determination of the source language of an incoming message .Additional language - evaluation module 100 is required since the use of automatic methods based on language detection by the application of methods of language - signal processing or methods that are based on language detection on the basis of a text , may lead to false results .False results in the above sense may occur , for example , if a German message is spoken by a speaker inexperienced in German phonetics , or in texts with mixed languages .", "label": "", "metadata": {}}
{"text": "For these reasons , the sender data area for acquired and/or ascertained sender data 60 may be configured to store not only the parameters explicitly entered by the mailbox owner but also parameters that the system ascertains from the incoming messages of the sender .This can be , among other things , the most likely language spoken , the ascertained gender of the message sender , the ascertained emotional disposition of the message sender and/or the age category of the message sender .In further embodiments and/or methods , an additional development of the memory area for acquired and/or ascertained sender data 60 is to retain or store the history of ascertained sender data for later analysis .", "label": "", "metadata": {}}
{"text": "The linking of messages by an individual receiver mailbox itself or by its sender CLI , as well as other sorting criteria such as the receiving time , are available in the related art .Exemplary embodiments and/or methods of the present invention now allow a linking of messages according to their content in a manner that goes beyond the individual mailbox , if appropriate .A considerably simplified classification of messages results from the expansion of the sender addresses / sender information ( CLI , HLR , e - mail address , time information ) by brief , abstracting content descriptions such as class names .", "label": "", "metadata": {}}
{"text": "Supplementing messages within the messaging system by these data allows both more refined search criteria within individual message classes and the creation of novel message classes .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 shows a block diagram of an embodiment of the present invention .FIG .2 shows an architecture for an embodiment of an exemplary development of classification block 500 .DETAILED DESCRIPTION OF THE DRAWINGS .The exemplary embodiment that is described with the aid of .FIGS . 1 and 2 requires , for example , an integrated messaging system designed as a mailbox system .", "label": "", "metadata": {}}
{"text": "Hereinafter , the solution will be described in connection with mailbox 30 of a mailbox owner .Supplementary messages are to be understood as supplementary information such as additional text , image and video information as well as information of other media types ( also media - spanning types ) .The same also applies to data relating to the sender of the message , which had been compiled previously already and were transmitted via communication network 20 .For example , the emotional disposition , the preferred language , the probable gender , age or age group of the sender may be recorded in the sender data area for acquired and/or ascertained sender data 60 .", "label": "", "metadata": {}}
{"text": "Translation system 190 may be made up of a large number of products / translation systems of different manufacturers .An automatic selection of the language combination , and thus the required translation module , takes place by the implemented source and target language determination .If a directly required combination is not available , it is automatically searched for a possible interlingua combination .In the following , exemplary translation system 190 is described in greater detail .Here , the algorithm always determines the language that delivers a maximum value for a predefined function for the given message or for the segment of a message at the given time .", "label": "", "metadata": {}}
{"text": "W CLI -weighting factor for the country code of a message ( such as +49 for Germany ) in combination with a specific language Lx .W LD -weighting factor for the language detection by application of speech - signal processing methods ( 80 ) .W T -weighting factor for language detection on the basis of a text ( 90 ) .W H -weighting factor for the languages determined from previous messages of a sender .W n -weighting factor for additional input parameters of ( 100 ) , among them image and video , for instance .", "label": "", "metadata": {}}
{"text": "C LD -confidence value ascertained by 80 ( such as probability ) of the language determined by 80 .C T -confidence value determined by 90 ( such as probability ) of the language ascertained by 90 .N H Number of values for L x previously ascertained for a sender number of the language values previously ascertained for a sender .C n -confidence value ( such as probability ) of source language Lx ascertained by additional methods .The weighting coefficients may be given individual pre - adjustment values either by the system administrator and/or the mailbox owner .", "label": "", "metadata": {}}
{"text": "In the module for language detection 90 , the language detection is implemented on the basis of a text .If no confidence value is determined for a supported language , the value is assumed to be 0 ( zero ) , for example .If only the language is determined as the result of a module , without the provision of a confidence value , some other fixed value such as 1 ( one ) may be assumed as confidence .The mentioned function is implemented for each source language supported by the system .The particular language for which the maximum value is achieved according to the previously mentioned algorithm will be considered the source language .", "label": "", "metadata": {}}
{"text": "The translation module with decision matrix 130 is connected both with at least one input module for source languages 110 having source languages S 1 to Sn , and with at least one output module for target languages having target languages S 1 to Sm .The decision matrix of translation module 130 also may have an n - dimensional design .The control of the individual translation modules of the translation module with decision matrix 130 is implemented via the decision matrix of translation module 130 into which both the result of the detection of the source language and the ascertained target language are input automatically .", "label": "", "metadata": {}}
{"text": "Due to the source and target languages being determined according to the aforementioned principles , an automatic selection of the language combination(s ) takes place , and , thus , also a selection of the translation module required for the translation .A resulting lower translation quality also may be acceptable .Knowledge management systems may be understood as , for example , search engines as well as associative knowledge management systems .If the original message was a text message , perhaps including an unspecified attachment , the text message is supplemented by supplementary text 40 a translated into the target language , if available , or the text in the target language will be included in the supplementary data record .", "label": "", "metadata": {}}
{"text": "This allows selection of the correct pronunciation dictionary for the individual language in a subsequent multilingual reproduction of the texts of this message via speech synthesis .This search for specific characteristics may be utilized to filter out undesired voice messages ( e.g. , voice spam ) .Corresponding internal deletion parameters and parameter linkages that make further analysis of the contents unnecessary may be generated on the basis of the results .If the operator of the integrated messaging system detects the generation of such parameters and/or parameter linkages in a multitude of its mailbox owners , it may use these to generate universally valid parameters and/or parameter linkages in the data memory with sample data 260 .", "label": "", "metadata": {}}
{"text": "According to the present invention , the system shown in .FIG .1 also may be utilized to record probable emotional states and/or probable age groups and/or the gender of the sender of a message .The gender and/or age of the sender of the message are / is determined via at least one module for speaker classification 200 .As additional basis of a system for ascertaining the most probable emotional state of a caller - such system becoming more refined in the course of usage - corresponding statistical data of the caller , which are stored in the sender data area for acquired and/or ascertained sender data 60 , are analyzed .", "label": "", "metadata": {}}
{"text": "Selected profile data are also able to be generated by the system and/or be provided with supplementary information ( for example , probability values , confidences ) .This applies in a similar manner to the age group determination and to the analysis of emotions via the module for prosodic analysis of speaker emotions 210 and the module for semantic analysis of sender emotions 220 , respectively .If appropriate , decision module 180 includes source - text forwarding to mailbox 30 for voice messages and/or further analysis .If the source language is identical to the target language , no translation will be provided .", "label": "", "metadata": {}}
{"text": "If no analysis module is available for the selected source language , translation system 190 begins a search for translation modules that provide as result a language that is suitable for the semantic textual emotion analysis .The ascertained probable emotional state of the message sender together with the possibly ascertained information regarding age group and/or gender and/or time information is recorded in the sender 's data record for further statistical analysis .Universally valid parameters and/or parameter linkages for analyzing sender information are specified both statically , by the system administrator , and are ascertained by analyzing a multitude of parameter sets of the mailboxes of other mailbox owners 270 in the integrated messaging system .", "label": "", "metadata": {}}
{"text": "Such parameter linkages may be used , for example , to determine the gender from the speaker classification and first name of the sender ( if available ) .Such parameter linkages may read , for example : .Instead of the international prefix it is also possible to use some other identification in this context .A universally valid parameter thus is valid for all mailboxes 30 , and is used for messages of a specific owner .The aforedescribed parameters and/or parameter linkages , which are able to be entered permanently by the administrator of the system or by the mailbox owner , are also referred to as static parameters .", "label": "", "metadata": {}}
{"text": "Such a generation of parameter linkages might be carried out in the following manner , for example : . the following new parameter linkage being generated : .The confidence values may be scaled differently in different systems .In addition to general parameters , exemplary embodiments and/or methods further may involve defining and/or generating mailbox - internal , static and dynamic parameters and their linkages .These parameters are generated solely on the basis of mailbox - internal data or entered by the owner , and they apply only to the messages of the mailbox owner , it being possible in some cases that external , universally valid parameter linkages are overwritten by internal parameter linkages .", "label": "", "metadata": {}}
{"text": "As already described , there are dynamic and static parameters .In addition , default parameters are set when initializing the system in the first step .These default parameters may be overwritten by dynamic , system - generated parameters .These in turn are able to be overwritten by static parameters that result from permanent inputs of the mailbox owner or the system administrator .The probable emotional state may also be used to prioritize messages .Ascertained sender data may be utilized for parameter control , for example , to select the voice in the synthetic reproduction of text messages ( speech synthesis , text - to - speech ) .", "label": "", "metadata": {}}
{"text": "The available data are utilized as search parameters .Furthermore , the system must be robust with respect to faults , and error - tolerant .It may happen , for example , that the same sender is administered multiple times in the system if , for example , he has left only a voicemail and an e - mail without leaving the call number .This may be done not only for an individual mailbox but for all sender data records of the sender data area for acquired and/or ascertained sender data ( 60 ) of the system 's mailboxes .", "label": "", "metadata": {}}
{"text": "The classification may occur either according to the specifications of the mailbox owner and/or according to the specifications of the system operator .The generated supplementary data may be combined into message groups ( clusters ) which are able to be processed jointly .Message groups may be combined according to the predefined priorities , for instance according to sending date , sender identification ( such as CLI , sender ID ) .Another possibility for grouping / classifying / clustering is to analyze the content types of different messages and/or message segments .Some methods for automatic ( textual ) annotation of image , video , sound , and other recordings , or for converting supplementary measured sensor values into corresponding text information which , in combination , reflect the contents of the messages , are available .", "label": "", "metadata": {}}
{"text": "This also makes it possible to assign a message to a plurality of classes / categories .For example , an image message could be assigned both to the class / category \" portrait \" ( on the basis of the content ) , and to the class / category \" vacation \" ( on the basis of a date occurring during vacation ) .The linkages then may be stored as result in an index database 300 configured as memory component having indexes of the messages of different classes / categories , and/or they are stored in a memory area for supplementary information of individual messages 52 .", "label": "", "metadata": {}}
{"text": "New possibilities for adapting and optimizing utilized technologies ( i.e. , .FIG .1 ) result from the large number of data obtained via classification and knowledge management and their linkings in integrated messaging systems and/or from additional linkages whose data come from external sources which were accessed via Internet / Intranet ( 21 ) .Furthermore , with the aid of a module for classifying and/or comparing with available data of similar classes 400 , the results of the language detection can be classified and compared to older detection results ( text including possible N - best lists ) of the same message class .", "label": "", "metadata": {}}
{"text": "These words / word combinations and/or phoneme sequences previously unknown to the system are thus able to be utilized as key for additional linkages .As described earlier , an image message may be assigned both to the \" portrait \" class / category and the \" vacation \" class / category .As a result , the linkages are then stored in an index database 300 which is assigned to the mailbox system operator , and/or they are stored in the memory area for supplementary information of individual messages 52 of the mailbox owner .To support the additional application of associative knowledge management , in an effort to simplify the search for messages of specific categories , the sender information ( user identifications such as sender ID , CLI , HLR .", "label": "", "metadata": {}}
{"text": "A similar method for optimizing translation results , utilizing old data from the translation results of a message class that contain , for instance , pairs of word combinations / word sequences in different languages , may be used .Furthermore , it is an obvious thing to utilize data for location determination , for example , via GPS , Galileo , and data regarding temperature , humidity and brightness for the classification of messages as well ( see also .FIG .2 ) .Some of these media types may also be generated within the system , as supplementary information .", "label": "", "metadata": {}}
{"text": "Systems for acquiring various sensor data and their transmission via a telecommunication network are available .If these data are now transmitted together with messages left and received in a memory area for supplementary information of individual messages 52 , this will result both in new classification possibilities within the messaging system and in more refined search criteria within individual message classes .The operator may thus use the wealth of messages and their contents in the messaging system to play the role of contact provider for the acquisition of contents .All messages that include corresponding GPS data , for example , may be included in the class \" Naples \" as well .", "label": "", "metadata": {}}
{"text": "The available classification rules may also be used to filter out unwanted messages ( such as spam ) .Due to the structures introduced by the present invention , this applies not only to pure text messages , but to the message types described in .FIG .2 as well .An acoustical marking may be implemented by , for example , . a ) changing the voice , the volume and/or the prosody during reproduction of texts via text - to - speech systems ; .c ) signal tones ; or .d ) a combination of the mentioned methods .", "label": "", "metadata": {}}
{"text": "If such a response has been generated by the system , the message left is amended by a report to this effect , so that the mailbox owner is notified of the automatic mailing of the answer .This may be done via a voice recording and/or a text message and/or via other media ( SMS , MMS , animation , image , smiley , etc . ) .The system has an additional connection to a data network such as Internet / Intranet 21 .This also allows a semantic analysis to be implemented in order to evaluate external documents that provide additional information regarding the available data in the system , for instance the address data .", "label": "", "metadata": {}}
{"text": "This can be done both with a time offset by sending an answer message to the sender , and in real time by a spoken dialogue , immediately upon leaving a voice mail .In this case , the asynchronous communication between at least two partners supported by a messaging system is converted into a synchronous communication .Standard responses or parts of such for specific received message classes and/or their segments may be stored in various formats for this purpose , for example , in the memory for static and dynamic parameter linkages for analyzing sender and owner information 290 .", "label": "", "metadata": {}}
{"text": "Additional automatically generated responses of the system following analysis of the content of received message documents and/or their segments may include : . a ) generating and sending at least one message document in response ; .b ) generating and sending at least one data file ; .e ) Combinations of the responses listed under a ) , b ) , c ) or d ) .For example , the system may already generate proposals for responses and offer them to the mailbox owner .Learning to Classify Text .Detecting patterns is a central part of Natural Language Processing .", "label": "", "metadata": {}}
{"text": "Frequent use of will is indicative of news text ( 3 ) .These observable patterns - word structure and word frequency - happen to correlate with particular aspects of meaning , such as tense and topic .But how did we know where to start looking , which aspects of form to associate with which aspects of meaning ?The goal of this chapter is to answer the following questions : .How can we identify particular features of language data that are salient for classifying it ?How can we construct models of language that can be used to perform language processing tasks automatically ?", "label": "", "metadata": {}}
{"text": "Along the way we will study some important machine learning techniques , including decision trees , naive Bayes ' classifiers , and maximum entropy classifiers .We will gloss over the mathematical and statistical underpinnings of these techniques , focusing instead on how and when to use them ( see the Further Readings section for more technical background ) .Before looking at these methods , we first need to appreciate the broad scope of this topic .1 Supervised Classification .Classification is the task of choosing the correct class label for a given input .In basic classification tasks , each input is considered in isolation from all other inputs , and the set of labels is defined in advance .", "label": "", "metadata": {}}
{"text": "Deciding whether an email is spam or not .Deciding what the topic of a news article is , from a fixed list of topic areas such as \" sports , \" \" technology , \" and \" politics . \"Deciding whether a given occurrence of the word bank is used to refer to a river bank , a financial institution , the act of tilting to the side , or the act of depositing something in a financial institution .The basic classification task has a number of interesting variants .For example , in multi - class classification , each instance may be assigned multiple labels ; in open - class classification , the set of labels is not defined in advance ; and in sequence classification , a list of inputs are jointly classified .", "label": "", "metadata": {}}
{"text": "The framework used by supervised classification is shown in 1.1 .Figure 1.1 : Supervised Classification .( a )During training , a feature extractor is used to convert each input value to a feature set .These feature sets , which capture the basic information about each input that should be used to classify it , are discussed in the next section .Pairs of feature sets and labels are fed into the machine learning algorithm to generate a model .( b )During prediction , the same feature extractor is used to convert unseen inputs to feature sets .", "label": "", "metadata": {}}
{"text": "In the rest of this section , we will look at how classifiers can be employed to solve a wide variety of tasks .Our discussion is not intended to be comprehensive , but to give a representative sample of tasks that can be performed with the help of text classifiers . 1.1Gender Identification .In 4 we saw that male and female names have some distinctive characteristics .Names ending in a , e and i are likely to be female , while names ending in k , o , r , s and t are likely to be male .", "label": "", "metadata": {}}
{"text": "The first step in creating a classifier is deciding what features of the input are relevant , and how to encode those features .For this example , we 'll start by just looking at the final letter of a given name .The following feature extractor function builds a dictionary containing relevant information about a given name : .The returned dictionary , known as a feature set , maps from feature names to their values .Feature names are case - sensitive strings that typically provide a short human - readable description of the feature , as in the example ' last_letter ' .", "label": "", "metadata": {}}
{"text": "Note .Most classification methods require that features be encoded using simple value types , such as booleans , numbers , and strings .But note that just because a feature has a simple type , this does not necessarily mean that the feature 's value is simple to express or compute .Indeed , it is even possible to use very complex and informative values , such as the output of a second supervised classifier , as features .Now that we 've defined a feature extractor , we need to prepare a list of examples and corresponding class labels .", "label": "", "metadata": {}}
{"text": "The training set is used to train a new \" naive Bayes \" classifier .We will learn more about the naive Bayes classifier later in the chapter .For now , let 's just test it out on some names that did not appear in its training data : .Observe that these character names from The Matrix are correctly classified .Although this science fiction movie is set in 2199 , it still conforms with our expectations about names and genders .We can systematically evaluate the classifier on a much larger quantity of unseen data : .", "label": "", "metadata": {}}
{"text": "This listing shows that the names in the training set that end in \" a \" are female 33 times more often than they are male , but names that end in \" k \" are male 32 times more often than they are female .These ratios are known as likelihood ratios , and can be useful for comparing different feature - outcome relationships .Note .Your Turn : Modify the gender_features ( ) function to provide the classifier with features encoding the length of the name , its first letter , and any other features that seem like they might be informative .", "label": "", "metadata": {}}
{"text": "When working with large corpora , constructing a single list that contains the features of every instance can use up a large amount of memory .In these cases , use the function nltk.classify.apply_features , which returns an object that acts like a list but does not store all the feature sets in memory : . 1.2Choosing The Right Features .Selecting relevant features and deciding how to encode them for a learning method can have an enormous impact on the learning method 's ability to extract a good model .Much of the interesting work in building a classifier is deciding what features might be relevant , and how we can represent them .", "label": "", "metadata": {}}
{"text": "Typically , feature extractors are built through a process of trial - and - error , guided by intuitions about what information is relevant to the problem .It 's common to start with a \" kitchen sink \" approach , including all the features that you can think of , and then checking to see which features actually are helpful .We take this approach for name gender features in 1.2 .def gender_features2 ( name ) : . lower ( ) . lower ( ) for letter in ' abcdefghijklmnopqrstuvwxyz ' : . count(letter ) .return features .", "label": "", "metadata": {}}
{"text": "py ) : Figure 1.2 : A Feature Extractor that Overfits Gender Features .The feature sets returned by this feature extractor contain a large number of specific features , leading to overfitting for the relatively small Names Corpus .This problem is known as overfitting , and can be especially problematic when working with small training sets .Once an initial set of features has been chosen , a very productive method for refining the feature set is error analysis .First , we select a development set , containing the corpus data for creating the model .This development set is then subdivided into the training set and the dev - test set .", "label": "", "metadata": {}}
{"text": "The test set serves in our final evaluation of the system .For reasons discussed below , it is important that we employ a separate dev - test set for error analysis , rather than just using the test set .The division of the corpus data into different subsets is shown in 1.3 .Figure 1.3 : Organization of corpus data for training supervised classifiers .The corpus data is divided into two sets : the development set , and the test set .The development set is often further subdivided into a training set and a dev - test set .", "label": "", "metadata": {}}
{"text": "Using the dev - test set , we can generate a list of the errors that the classifier makes when predicting name genders : .We can then examine individual error cases where the model predicted the wrong label , and try to determine what additional pieces of information would allow it to make the right decision ( or which existing pieces of information are tricking it into making the wrong decision ) .The feature set can then be adjusted accordingly .The names classifier that we have built generates about 100 errors on the dev - test corpus : .", "label": "", "metadata": {}}
{"text": "For example , names ending in yn appear to be predominantly female , despite the fact that names ending in n tend to be male ; and names ending in ch are usually male , even though names that end in h tend to be female .We therefore adjust our feature extractor to include features for two - letter suffixes : .Rebuilding the classifier with the new feature extractor , we see that the performance on the dev - test dataset improves by almost 2 percentage points ( from 76.5 % to 78.2 % ) : .This error analysis procedure can then be repeated , checking for patterns in the errors that are made by the newly improved classifier .", "label": "", "metadata": {}}
{"text": "But once we 've used the dev - test set to help us develop the model , we can no longer trust that it will give us an accurate idea of how well the model would perform on new data .It is therefore important to keep the test set separate , and unused , until our model development is complete .At that point , we can use the test set to evaluate how well our model will perform on new input values . 1.3 Document Classification .In 1 , we saw several examples of corpora where documents have been labeled with categories .", "label": "", "metadata": {}}
{"text": "First , we construct a list of documents , labeled with the appropriate categories .For this example , we 've chosen the Movie Reviews Corpus , which categorizes each review as positive or negative .words(fileid ) ) , category ) ... for category in movie_reviews . categories ( ) ... for fileid in movie_reviews .Next , we define a feature extractor for documents , so the classifier will know which aspects of the data it should pay attention to ( 1.4 ) .For document topic identification , we can define a feature for each word , indicating whether the document contains that word .", "label": "", "metadata": {}}
{"text": "We can then define a feature extractor that simply checks whether each of these words is present in a given document . words ( ) ) .return features . words ( ' pos / cv957_8737 .The reason that we compute the set of all words in a document in , rather than just checking if word in document , is that checking whether a word occurs in a set is much faster than checking whether it occurs in a list ( 4.7 ) .Now that we 've defined our feature extractor , we can use it to train a classifier to label new movie reviews ( 1.5 ) .", "label": "", "metadata": {}}
{"text": "And once again , we can use show_most_informative_features ( ) to find out which features the classifier found to be most informative . 1.4 Part - of - Speech Tagging .In 5 .we built a regular expression tagger that chooses a part - of - speech tag for a word by looking at the internal make - up of the word .However , this regular expression tagger had to be hand - crafted .Instead , we can train a classifier to work out which suffixes are most informative .Let 's begin by finding out what the most common suffixes are : .", "label": "", "metadata": {}}
{"text": "Feature extraction functions behave like tinted glasses , highlighting some of the properties ( colors ) in our data and making it impossible to see other properties .The classifier will rely exclusively on these highlighted properties when determining how to label inputs .In this case , the classifier will make its decisions based only on information about which of the common suffixes ( if any ) a given word has .Now that we 've defined our feature extractor , we can use it to train a new \" decision tree \" classifier ( to be discussed in 4 ): .", "label": "", "metadata": {}}
{"text": "Here , we can see that the classifier begins by checking whether a word ends with a comma - if so , then it will receive the special tag \" , \" .Next , the classifier checks if the word ends in \" the \" , in which case it 's almost certainly a determiner .This \" suffix \" gets used early by the decision tree because the word \" the \" is so common .Continuing on , the classifier checks if the word ends in \" s \" .1.5 Exploiting Context .By augmenting the feature extraction function , we could modify this part - of - speech tagger to leverage a variety of other word - internal features , such as the length of the word , the number of syllables it contains , or its prefix .", "label": "", "metadata": {}}
{"text": "But contextual features often provide powerful clues about the correct tag - for example , when tagging the word \" fly , \" knowing that the previous word is \" a \" will allow us to determine that it is functioning as a noun , not a verb .In order to accommodate features that depend on a word 's context , we must revise the pattern that we used to define our feature extractor .Instead of just passing in the word to be tagged , we will pass in a complete ( untagged ) sentence , along with the index of the target word .", "label": "", "metadata": {}}
{"text": "Example 1.6 ( code_suffix_pos_tag . py ) : Figure 1.6 : A part - of - speech classifier whose feature detector examines the context in which a word appears in order to determine which part of speech tag should be assigned .In particular , the identity of the previous word is included as a feature .It is clear that exploiting contextual features improves the performance of our part - of - speech tagger .For example , the classifier learns that a word is likely to be a noun if it comes immediately after the word \" large \" or the word \" gubernatorial \" .", "label": "", "metadata": {}}
{"text": "In general , simple classifiers always treat each input as independent from all other inputs .In many contexts , this makes perfect sense .For example , decisions about whether names tend to be male or female can be made on a case - by - case basis .However , there are often cases , such as part - of - speech tagging , where we are interested in solving classification problems that are closely related to one another .1.6 Sequence Classification .In order to capture the dependencies between related classification tasks , we can use joint classifier models , which choose an appropriate labeling for a collection of related inputs .", "label": "", "metadata": {}}
{"text": "One sequence classification strategy , known as consecutive classification or greedy sequence classification , is to find the most likely class label for the first input , then to use that answer to help find the best label for the next input .The process can then be repeated until all of the inputs have been labeled .This strategy is demonstrated in 1.7 .First , we must augment our feature extractor function to take a history argument , which provides a list of the tags that we 've predicted for the sentence so far .Each tag in history corresponds with a word in sentence .", "label": "", "metadata": {}}
{"text": "Thus , while it is possible to look at some features of words to the right of the target word , it is not possible to look at the tags for those words ( since we have n't generated them yet ) .Having defined a feature extractor , we can proceed to build our sequence classifier .During training , we use the annotated tags to provide the appropriate history to the feature extractor , but when tagging new sentences , we generate the history list based on the output of the tagger itself . def pos_features ( sentence , i , history ) : . return features class ConsecutivePosTagger ( nltk .", "label": "", "metadata": {}}
{"text": "history.append(tag ) .history.append(tag ) .return zip(sentence , history ) .1.7 Other Methods for Sequence Classification .One shortcoming of this approach is that we commit to every decision that we make .For example , if we decide to label a word as a noun , but later find evidence that it should have been a verb , there 's no way to go back and fix our mistake .One solution to this problem is to adopt a transformational strategy instead .Transformational joint classifiers work by creating an initial assignment of labels for the inputs , and then iteratively refining that assignment in an attempt to repair inconsistencies between related inputs .", "label": "", "metadata": {}}
{"text": "Another solution is to assign scores to all of the possible sequences of part - of - speech tags , and to choose the sequence whose overall score is highest .This is the approach taken by Hidden Markov Models .Hidden Markov Models are similar to consecutive classifiers in that they look at both the inputs and the history of predicted tags .However , rather than simply finding the single best tag for a given word , they generate a probability distribution over tags .These probabilities are then combined to calculate probability scores for tag sequences , and the tag sequence with the highest probability is chosen .", "label": "", "metadata": {}}
{"text": "Given a tag set with 30 tags , there are about 600 trillion ( 30 10 ) ways to label a 10-word sentence .In order to avoid considering all these possible sequences separately , Hidden Markov Models require that the feature extractor only look at the most recent tag ( or the most recent n tags , where n is fairly small ) .Given that restriction , it is possible to use dynamic programming ( 4.7 ) to efficiently find the most likely tag sequence .In particular , for each consecutive word index i , a score is computed for each possible current and previous tag .", "label": "", "metadata": {}}
{"text": "2 Further Examples of Supervised Classification .2.1 Sentence Segmentation .Sentence segmentation can be viewed as a classification task for punctuation : whenever we encounter a symbol that could possibly end a sentence , such as a period or a question mark , we have to decide whether it terminates the preceding sentence .The first step is to obtain some data that has already been segmented into sentences and convert it into a form that is suitable for extracting features : .Here , tokens is a merged list of tokens from the individual sentences , and boundaries is a set containing the indexes of all sentence - boundary tokens .", "label": "", "metadata": {}}
{"text": "tokens[i-1].Based on this feature extractor , we can create a list of labeled featuresets by selecting all the punctuation tokens , and tagging whether they are boundary tokens or not : . ? ! ' ] Using these featuresets , we can train and evaluate a punctuation classifier : .To use this classifier to perform sentence segmentation , we simply check each punctuation mark to see whether it 's labeled as a boundary ; and divide the list of words at the boundary marks .The listing in 2.1 shows how this can be done . def segment_sentences ( words ) : . sents.append(words[start:i+1 ] ) . sents.append(words[start : ] ) .", "label": "", "metadata": {}}
{"text": "When processing dialogue , it can be useful to think of utterances as a type of action performed by the speaker .This interpretation is most straightforward for performative statements such as \" I forgive you \" or \" I bet you ca n't climb that hill .\" But greetings , questions , answers , assertions , and clarifications can all be thought of as types of speech - based actions .Recognizing the dialogue acts underlying the utterances in a dialogue can be an important first step in understanding the conversation .The NPS Chat Corpus , which was demonstrated in 1 , consists of over 10,000 posts from instant messaging sessions .", "label": "", "metadata": {}}
{"text": "\" We can therefore use this data to build a classifier that can identify the dialogue act types for new instant messaging posts .The first step is to extract the basic messaging data .We will call xml_posts ( ) to get a data structure representing the XML annotation for each post : .Next , we 'll define a simple feature extractor that checks what words the post contains : .Finally , we construct the training and testing data by applying the feature extractor to each post ( using post.get ( ' class ' ) to get a post 's dialogue act type ) , and create a new classifier : . 2.3 Recognizing Textual Entailment .", "label": "", "metadata": {}}
{"text": "To date , there have been four RTE Challenges , where shared development and test data is made available to competing teams .Here are a couple of examples of text / hypothesis pairs from the Challenge 3 development dataset .The label True indicates that the entailment holds , and False , that it fails to hold .Challenge 3 , Pair 34 ( True ) .T : Parviz Davudi was representing Iran at a meeting of the Shanghai Co - operation Organisation ( SCO ) , the fledgling association that binds Russia , China and four former Soviet republics of central Asia together to fight terrorism .", "label": "", "metadata": {}}
{"text": "Challenge 3 , Pair 81 ( False ) .T :According to NC Articles of Organization , the members of LLC company are H. Nelson Beavers , III , H. Chester Beavers and Jennie Beavers Stewart .H : Jennie Beavers Stewart is a share - holder of Carolina Analytical Laboratory .It should be emphasized that the relationship between text and hypothesis is not intended to be logical entailment , but rather whether a human would conclude that the text provides reasonable evidence for taking the hypothesis to be true .We can treat RTE as a classification task , in which we try to predict the True / False label for each pair .", "label": "", "metadata": {}}
{"text": "In the ideal case , we would expect that if there is an entailment , then all the information expressed by the hypothesis should also be present in the text .Conversely , if there is information found in the hypothesis that is absent from the text , then there will be no entailment .Not all words are equally important - Named Entity mentions such as the names of people , organizations and places are likely to be more significant , which motivates us to extract distinct information for word s and ne s ( Named Entities ) .", "label": "", "metadata": {}}
{"text": "def rte_features ( rtepair ) : . return features .Example 2.2 ( code_rte_features . py ) : Figure 2.2 : \" Recognizing Text Entailment \" Feature Extractor .The RTEFeatureExtractor class builds a bag of words for both the text and the hypothesis after throwing away some stopwords , then calculates overlap and difference .To illustrate the content of these features , we examine some attributes of the text / hypothesis Pair 34 shown earlier : .These features indicate that all important words in the hypothesis are contained in the text , and thus there is some evidence for labeling this as True .", "label": "", "metadata": {}}
{"text": "Although this figure is not very impressive , it requires significant effort , and more linguistic processing , to achieve much better results . 2.4Scaling Up to Large Datasets .Python provides an excellent environment for performing basic text processing and feature extraction .If you plan to train classifiers with large amounts of training data or a large number of features , we recommend that you explore NLTK 's facilities for interfacing with external machine learning packages .Once these packages have been installed , NLTK can transparently invoke them ( via system calls ) to train classifier models significantly faster than the pure - Python classifier implementations .", "label": "", "metadata": {}}
{"text": "3 Evaluation .In order to decide whether a classification model is accurately capturing a pattern , we must evaluate that model .The result of this evaluation is important for deciding how trustworthy the model is , and for what purposes we can use it .Evaluation can also be an effective tool for guiding us in making future improvements to the model . 3.1 The Test Set .Most evaluation techniques calculate a score for a model by comparing the labels that it generates for the inputs in a test set ( or evaluation set ) with the correct labels for those inputs .", "label": "", "metadata": {}}
{"text": "When building the test set , there is often a trade - off between the amount of data available for testing and the amount available for training .For classification tasks that have a small number of well - balanced labels and a diverse test set , a meaningful evaluation can be performed with as few as 100 evaluation instances .But if a classification task has a large number of labels , or includes very infrequent labels , then the size of the test set should be chosen to ensure that the least frequent label occurs at least 50 times .", "label": "", "metadata": {}}
{"text": "When large amounts of annotated data are available , it is common to err on the side of safety by using 10 % of the overall data for evaluation .Another consideration when choosing the test set is the degree of similarity between instances in the test set and those in the development set .The more similar these two datasets are , the less confident we can be that evaluation results will generalize to other datasets .For example , consider the part - of - speech tagging task .At one extreme , we could create the training set and test set by randomly assigning sentences from a data source that reflects a single genre ( news ) : .", "label": "", "metadata": {}}
{"text": "The training set and test set are taken from the same genre , and so we can not be confident that evaluation results would generalize to other genres .What 's worse , because of the call to random.shuffle ( ) , the test set contains sentences that are taken from the same documents that were used for training .If there is any consistent pattern within a document - say , if a given word appears with a particular part - of - speech tag especially frequently - then that difference will be reflected in both the development set and the test set .", "label": "", "metadata": {}}
{"text": "If we want to perform a more stringent evaluation , we can draw the test set from documents that are less closely related to those in the training set : .If we build a classifier that performs well on this test set , then we can be confident that it has the power to generalize well beyond the data that it was trained on .3.2 Accuracy .The simplest metric that can be used to evaluate a classifier , accuracy , measures the percentage of inputs in the test set that the classifier correctly labeled .The function nltk.classify.accuracy ( ) will calculate the accuracy of a classifier model on a given test set : . format(nltk.classify.accuracy(classifier , test_set ) ) ) 0.75 .", "label": "", "metadata": {}}
{"text": "For example , consider a classifier that determines the correct word sense for each occurrence of the word bank .If we evaluate this classifier on financial newswire text , then we may find that the financial - institution sense appears 19 times out of 20 .In that case , an accuracy of 95 % would hardly be impressive , since we could achieve that accuracy with a model that always returns the financial - institution sense .However , if we instead evaluate the classifier on a more balanced corpus , where the most frequent word sense has a frequency of 40 % , then a 95 % accuracy score would be a much more positive result .", "label": "", "metadata": {}}
{"text": "Another instance where accuracy scores can be misleading is in \" search \" tasks , such as information retrieval , where we are attempting to find documents that are relevant to a particular task .Since the number of irrelevant documents far outweighs the number of relevant documents , the accuracy score for a model that labels every document as irrelevant would be very close to 100 % .It is therefore conventional to employ a different set of measures for search tasks , based on the number of items in each of the four categories shown in 3.1 : .", "label": "", "metadata": {}}
{"text": "True negatives are irrelevant items that we correctly identified as irrelevant .False positives ( or Type I errors ) are irrelevant items that we incorrectly identified as relevant .False negatives ( or Type II errors ) are relevant items that we incorrectly identified as irrelevant .Given these four numbers , we can define the following metrics : .Precision , which indicates how many of the items that we identified were relevant , is TP/(TP+FP ) .Recall , which indicates how many of the relevant items that we identified , is TP/(TP+FN ) .The F - Measure ( or F - Score ) , which combines the precision and recall to give a single score , is defined to be the harmonic mean of the precision and recall : ( 2 \u00d7 Precision \u00d7 Recall ) / ( Precision + Recall ) .", "label": "", "metadata": {}}
{"text": "When performing classification tasks with three or more labels , it can be informative to subdivide the errors made by the model based on which types of mistake it made .A confusion matrix is a table where each cell [ i , j ] indicates how often label j was predicted when the correct label was i .In the following example , we generate a confusion matrix for the bigram tagger developed in 4 : .The confusion matrix indicates that common errors include a substitution of NN for JJ ( for 1.6 % of words ) , and of NN for NNS ( for 1.5 % of words ) .", "label": "", "metadata": {}}
{"text": "XXX explain use of \" reference \" in the legend above .3.5 Cross - Validation .In order to evaluate our models , we must reserve a portion of the annotated data for the test set .As we already mentioned , if the test set is too small , then our evaluation may not be accurate .However , making the test set larger usually means making the training set smaller , which can have a significant impact on performance if a limited amount of annotated data is available .One solution to this problem is to perform multiple evaluations on different test sets , then to combine the scores from those evaluations , a technique known as cross - validation .", "label": "", "metadata": {}}
{"text": "For each of these folds , we train a model using all of the data except the data in that fold , and then test that model on the fold .Even though the individual folds might be too small to give accurate evaluation scores on their own , the combined evaluation score is based on a large amount of data , and is therefore quite reliable .A second , and equally important , advantage of using cross - validation is that it allows us to examine how widely the performance varies across different training sets .If we get very similar scores for all N training sets , then we can be fairly confident that the score is accurate .", "label": "", "metadata": {}}
{"text": "4 Decision Trees .In the next three sections , we 'll take a closer look at three machine learning methods that can be used to automatically build classification models : decision trees , naive Bayes classifiers , and Maximum Entropy classifiers .As we 've seen , it 's possible to treat these learning methods as black boxes , simply training models and using them for prediction without understanding how they work .But there 's a lot to be learned from taking a closer look at how these learning methods select models based on the data in a training set .", "label": "", "metadata": {}}
{"text": "And an understanding of the generated models can allow us to extract information about which features are most informative , and how those features relate to one another .A decision tree is a simple flowchart that selects labels for input values .This flowchart consists of decision nodes , which check feature values , and leaf nodes , which assign labels .To choose the label for an input value , we begin at the flowchart 's initial decision node , known as its root node .This node contains a condition that checks one of the input value 's features , and selects a branch based on that feature 's value .", "label": "", "metadata": {}}
{"text": "We continue following the branch selected by each node 's condition , until we arrive at a leaf node which provides a label for the input value .4.1 shows an example decision tree model for the name gender task .Once we have a decision tree , it is straightforward to use it to assign labels to new input values .What 's less straightforward is how we can build a decision tree that models a given training set .But before we look at the learning algorithm for building decision trees , we 'll consider a simpler task : picking the best \" decision stump \" for a corpus .", "label": "", "metadata": {}}
{"text": "It contains one leaf for each possible feature value , specifying the class label that should be assigned to inputs whose features have that value .In order to build a decision stump , we must first decide which feature should be used .The simplest method is to just build a decision stump for each possible feature , and see which one achieves the highest accuracy on the training data , although there are other alternatives that we will discuss below .Once we 've picked a feature , we can build the decision stump by assigning a label to each leaf based on the most frequent label for the selected examples in the training set ( i.e. , the examples where the selected feature has that value ) .", "label": "", "metadata": {}}
{"text": "We begin by selecting the overall best decision stump for the classification task .We then check the accuracy of each of the leaves on the training set .Leaves that do not achieve sufficient accuracy are then replaced by new decision stumps , trained on the subset of the training corpus that is selected by the path to the leaf .4.1 Entropy and Information Gain .As was mentioned before , there are several methods for identifying the most informative feature for a decision stump .One popular alternative , called information gain , measures how much more organized the input values become when we divide them up using a given feature .", "label": "", "metadata": {}}
{"text": "In particular , entropy is defined as the sum of the probability of each label times the log probability of that same label : .Figure 4.2 : The entropy of labels in the name gender prediction task , as a function of the percentage of names in a given set that are male .For example , 4.2 shows how the entropy of labels in the name gender prediction task depends on the ratio of male to female names .Note that if most input values have the same label ( e.g. , if P(male ) is near 0 or near 1 ) , then entropy is low .", "label": "", "metadata": {}}
{"text": "P(l ) is small ) .On the other hand , if the input values have a wide variety of labels , then there are many labels with a \" medium \" frequency , where neither P(l ) nor log 2P(l ) is small , so the entropy is high .4.3 demonstrates how to calculate the entropy of a list of labels .import math def entropy ( labels ) : .Once we have calculated the entropy of the original set of input values ' labels , we can determine how much more organized the labels become once we apply the decision stump .", "label": "", "metadata": {}}
{"text": "The information gain is then equal to the original entropy minus this new , reduced entropy .The higher the information gain , the better job the decision stump does of dividing the input values into coherent groups , so we can build decision trees by selecting the decision stumps with the highest information gain .Another consideration for decision trees is efficiency .The simple algorithm for selecting decision stumps described above must construct a candidate decision stump for every possible feature , and this process must be repeated for every node in the constructed decision tree .A number of algorithms have been developed to cut down on the training time by storing and reusing information about previously evaluated examples .", "label": "", "metadata": {}}
{"text": "To begin with , they 're simple to understand , and easy to interpret .This is especially true near the top of the decision tree , where it is usually possible for the learning algorithm to find very useful features .Decision trees are especially well suited to cases where many hierarchical categorical distinctions can be made .For example , decision trees can be very effective at capturing phylogeny trees .However , decision trees also have a few disadvantages .One problem is that , since each branch in the decision tree splits the training data , the amount of training data available to train nodes lower in the tree can become quite small .", "label": "", "metadata": {}}
{"text": "One solution to this problem is to stop dividing nodes once the amount of training data becomes too small .Another solution is to grow a full decision tree , but then to prune decision nodes that do not improve performance on a dev - test .A second problem with decision trees is that they force features to be checked in a specific order , even when features may act relatively independently of one another .For example , when classifying documents into topics ( such as sports , automotive , or murder mystery ) , features such as hasword(football ) are highly indicative of a specific label , regardless of what other the feature values are .", "label": "", "metadata": {}}
{"text": "And since the number of branches increases exponentially as we go down the tree , the amount of repetition can be very large .A related problem is that decision trees are not good at making use of features that are weak predictors of the correct label .Since these features make relatively small incremental improvements , they tend to occur very low in the decision tree .But by the time the decision tree learner has descended far enough to use these features , there is not enough training data left to reliably determine what effect they should have .", "label": "", "metadata": {}}
{"text": "The fact that decision trees require that features be checked in a specific order limits their ability to exploit features that are relatively independent of one another .The naive Bayes classification method , which we 'll discuss next , overcomes this limitation by allowing all features to act \" in parallel . \"5 Naive Bayes Classifiers .In naive Bayes classifiers , every feature gets a say in determining which label should be assigned to a given input value .To choose a label for an input value , the naive Bayes classifier begins by calculating the prior probability of each label , which is determined by checking frequency of each label in the training set .", "label": "", "metadata": {}}
{"text": "The label whose likelihood estimate is the highest is then assigned to the input value .5.1 illustrates this process .Figure 5.1 : An abstract illustration of the procedure used by the naive Bayes classifier to choose the topic for a document .In the training corpus , most documents are automotive , so the classifier starts out at a point closer to the \" automotive \" label .But it then considers the effect of each feature .In this example , the input document contains the word \" dark , \" which is a weak indicator for murder mysteries , but it also contains the word \" football , \" which is a strong indicator for sports documents .", "label": "", "metadata": {}}
{"text": "Individual features make their contribution to the overall decision by \" voting against \" labels that do n't occur with that feature very often .In particular , the likelihood score for each label is reduced by multiplying it by the probability that an input value with that label would have the feature .The overall effect will be to reduce the score of the murder mystery label slightly more than the score of the sports label , and to significantly reduce the automotive label with respect to the other two labels .This process is illustrated in 5.2 and 5.3 .", "label": "", "metadata": {}}
{"text": "Naive Bayes begins by calculating the prior probability of each label , based on how frequently each label occurs in the training data .Every feature then contributes to the likelihood estimate for each label , by multiplying it by the probability that input values with that label will have that feature .The resulting likelihood score can be thought of as an estimate of the probability that a randomly selected value from the training set would have both the given label and the set of features , assuming that the feature probabilities are all independent .5.1 Underlying Probabilistic Model .", "label": "", "metadata": {}}
{"text": "We 'll return to some of the consequences of this assumption at the end of this section .This simplifying assumption , known as the naive Bayes assumption ( or independence assumption ) makes it much easier to combine the contributions of the different features , since we do n't need to worry about how they should interact with one another .Figure 5.3 : A Bayesian Network Graph illustrating the generative process that is assumed by the naive Bayes classifier .To generate a labeled input , the model first chooses a label for the input , then it generates each of the input 's features based on that label .", "label": "", "metadata": {}}
{"text": "Note .If we want to generate a probability estimate for each label , rather than just choosing the most likely label , then the easiest way to compute P(features ) is to simply calculate the sum over labels of P(features , label ) : . 5.2 Zero Counts and Smoothing .However , this simple approach can become problematic when a feature never occurs with a given label in the training set .Thus , the input will never be assigned this label , regardless of how well the other features fit the label .In particular , just because we have n't seen a feature / label combination occur in the training set , does n't mean it 's impossible for that combination to occur .", "label": "", "metadata": {}}
{"text": "For example , the Expected Likelihood Estimation for the probability of a feature given a label basically adds 0.5 to each count(f , label ) value , and the Heldout Estimation uses a heldout corpus to calculate the relationship between feature frequencies and feature probabilities .The nltk.probability module provides support for a wide variety of smoothing techniques .5.3 Non - Binary Features .We have assumed here that each feature is binary , i.e. that each input either has a feature or does not .Label - valued features ( e.g. , a color feature which could be red , green , blue , white , or orange ) can be converted to binary features by replacing them with binary features such as \" color - is - red \" .", "label": "", "metadata": {}}
{"text": "5.4 The Naivete of Independence .The reason that naive Bayes classifiers are called \" naive \" is that it 's unreasonable to assume that all features are independent of one another ( given the label ) .In particular , almost all real - world problems contain features with varying degrees of dependence on one another .If we had to avoid any features that were dependent on one another , it would be very difficult to construct good feature sets that provide the required information to the machine learning algorithm .So what happens when we ignore the independence assumption , and use the naive Bayes classifier with features that are not independent ?", "label": "", "metadata": {}}
{"text": "To see how this can occur , consider a name gender classifier that contains two identical features , f 1 and f 2 .In other words , f 2 is an exact copy of f 1 , and contains no new information .When the classifier is considering an input , it will include the contribution of both f 1 and f 2 when deciding which label to choose .Thus , the information content of these two features will be given more weight than it deserves .Of course , we do n't usually build naive Bayes classifiers that contain two identical features .", "label": "", "metadata": {}}
{"text": "For example , the features ends - with(a ) and ends - with(vowel ) are dependent on one another , because if an input value has the first feature , then it must also have the second feature .For features like these , the duplicated information may be given more weight than is justified by the training set .5.5 The Cause of Double - Counting .The reason for the double - counting problem is that during training , feature contributions are computed separately ; but when using the classifier to choose labels for new inputs , those feature contributions are combined .", "label": "", "metadata": {}}
{"text": "We could then use those interactions to adjust the contributions that individual features make .To make this more precise , we can rewrite the equation used to calculate the likelihood of a label , separating out the contribution made by each feature ( or label ) : .Here , w[label ] is the \" starting score \" for a given label , and w[f , label ] is the contribution made by a given feature towards a label 's likelihood .We call these values w[label ] and w[f , label ] the parameters or weights for the model .", "label": "", "metadata": {}}
{"text": "However , in the next section , we 'll look at a classifier that considers the possible interactions between these parameters when choosing their values .6 Maximum Entropy Classifiers .The Maximum Entropy classifier uses a model that is very similar to the model employed by the naive Bayes classifier .But rather than using probabilities to set the model 's parameters , it uses search techniques to find a set of parameters that will maximize the performance of the classifier .In particular , it looks for the set of parameters that maximizes the total likelihood of the training corpus , which is defined as : .", "label": "", "metadata": {}}
{"text": "Therefore , Maximum Entropy classifiers choose the model parameters using iterative optimization techniques , which initialize the model 's parameters to random values , and then repeatedly refine those parameters to bring them closer to the optimal solution .These iterative optimization techniques guarantee that each refinement of the parameters will bring them closer to the optimal values , but do not necessarily provide a means of determining when those optimal values have been reached .Because the parameters for Maximum Entropy classifiers are selected using iterative optimization techniques , they can take a long time to learn .This is especially true when the size of the training set , the number of features , and the number of labels are all large .", "label": "", "metadata": {}}
{"text": "Some iterative optimization techniques are much faster than others .When training Maximum Entropy models , avoid the use of Generalized Iterative Scaling ( GIS ) or Improved Iterative Scaling ( IIS ) , which are both considerably slower than the Conjugate Gradient ( CG ) and the BFGS optimization methods .6.1 The Maximum Entropy Model .The Maximum Entropy classifier model is a generalization of the model used by the naive Bayes classifier .Like the naive Bayes model , the Maximum Entropy classifier calculates the likelihood of each label for a given input value by multiplying together the parameters that are applicable for the input value and label .", "label": "", "metadata": {}}
{"text": "In contrast , the Maximum Entropy classifier model leaves it up to the user to decide what combinations of labels and features should receive their own parameters .In particular , it is possible to use a single parameter to associate a feature with more than one label ; or to associate more than one feature with a given label .This will sometimes allow the model to \" generalize \" over some of the differences between related labels or features .Each combination of labels and features that receives its own parameter is called a joint - feature .", "label": "", "metadata": {}}
{"text": "Note .In literature that describes and discusses Maximum Entropy models , the term \" features \" often refers to joint - features ; the term \" contexts \" refers to what we have been calling ( simple ) features .Typically , the joint - features that are used to construct Maximum Entropy models exactly mirror those that are used by the naive Bayes model .In particular , a joint - feature is defined for each label , corresponding to w [ label ] , and for each combination of ( simple ) feature and label , corresponding to w [ f , label ] .", "label": "", "metadata": {}}
{"text": "The intuition that motivates Maximum Entropy classification is that we should build a model that captures the frequencies of individual joint - features , without making any unwarranted assumptions .An example will help to illustrate this principle .Suppose we are assigned the task of picking the correct word sense for a given word , from a list of ten possible senses ( labeled A - J ) .At first , we are not told anything more about the word or the senses .There are many probability distributions that we could choose for the ten senses , such as : .", "label": "", "metadata": {}}
{"text": "On the other hand , distributions ( ii ) and ( iii ) reflect assumptions that are not supported by what we know .One way to capture this intuition that distribution ( i ) is more \" fair \" than the other two is to invoke the concept of entropy .In the discussion of decision trees , we described entropy as a measure of how \" disorganized \" a set of labels was .In particular , if a single label dominates then entropy is low , but if the labels are more evenly distributed then entropy is high .", "label": "", "metadata": {}}
{"text": "In general , the Maximum Entropy principle states that , among the distributions that are consistent with what we know , we should choose the distribution whose entropy is highest .Next , suppose that we are told that sense A appears 55 % of the time .Once again , there are many distributions that are consistent with this new piece of information , such as : .But again , we will likely choose the distribution that makes the fewest unwarranted assumptions - in this case , distribution ( v ) .Finally , suppose that we are told that the word \" up \" appears in the nearby context 10 % of the time , and that when it does appear in the context there 's an 80 % chance that sense A or C will be used .", "label": "", "metadata": {}}
{"text": "Furthermore , the remaining probabilities appear to be \" evenly distributed .\" Throughout this example , we have restricted ourselves to distributions that are consistent with what we know ; among these , we chose the distribution with the highest entropy .This is exactly what the Maximum Entropy classifier does as well .In particular , for each joint - feature , the Maximum Entropy model calculates the \" empirical frequency \" of that feature - i.e. , the frequency with which it occurs in the training set .It then searches for the distribution which maximizes entropy , while still predicting the correct frequency for each joint - feature .", "label": "", "metadata": {}}
{"text": "An important difference between the naive Bayes classifier and the Maximum Entropy classifier concerns the type of questions they can be used to answer .The naive Bayes classifier is an example of a generative classifier , which builds a model that predicts P(input , label ) , the joint probability of a ( input , label ) pair .As a result , generative models can be used to answer the following questions : .How likely is a given input value with a given label ?What is the most likely label for an input that might have one of two values ( but we do n't know which ) ?", "label": "", "metadata": {}}
{"text": "Thus , conditional models can still be used to answer questions 1 and 2 .However , conditional models can not be used to answer the remaining questions 3 - 6 .However , this additional power comes at a price .Because the model is more powerful , it has more \" free parameters \" which need to be learned .However , the size of the training set is fixed .Thus , when using a more powerful model , we end up with less data that can be used to train each parameter 's value , making it harder to find the best parameter values .", "label": "", "metadata": {}}
{"text": "However , if we do need answers to questions like 3 - 6 , then we have no choice but to use a generative model .The difference between a generative model and a conditional model is analogous to the difference between a topographical map and a picture of a skyline .Although the topographical map can be used to answer a wider variety of questions , it is significantly more difficult to generate an accurate topographical map than it is to generate an accurate skyline .7 Modeling Linguistic Patterns .Classifiers can help us to understand the linguistic patterns that occur in natural language , by allowing us to create explicit models that capture those patterns .", "label": "", "metadata": {}}
{"text": "Either way , these explicit models serve two important purposes : they help us to understand linguistic patterns , and they can be used to make predictions about new language data .The extent to which explicit models can give us insights into linguistic patterns depends largely on what kind of model is used .Some models , such as decision trees , are relatively transparent , and give us direct information about which factors are important in making decisions and about which factors are related to one another .Other models , such as multi - level neural networks , are much more opaque .", "label": "", "metadata": {}}
{"text": "But all explicit models can make predictions about new \" unseen \" language data that was not included in the corpus used to build the model .These predictions can be evaluated to assess the accuracy of the model .Once a model is deemed sufficiently accurate , it can then be used to automatically predict information about new language data .These predictive models can be combined into systems that perform many useful language processing tasks , such as document classification , automatic translation , and question answering .7.1 What do models tell us ?It 's important to understand what we can learn about language from an automatically constructed model .", "label": "", "metadata": {}}
{"text": "Descriptive models capture patterns in the data but they do n't provide any information about why the data contains those patterns .For example , as we saw in 3.1 , the synonyms absolutely and definitely are not interchangeable : we say absolutely adore not definitely adore , and definitely prefer not absolutely prefer .In contrast , explanatory models attempt to capture properties and relationships that cause the linguistic patterns .For example , we might introduce the abstract concept of \" polar verb \" , as one that has an extreme meaning , and categorize some verb like adore and detest as polar .", "label": "", "metadata": {}}
{"text": "In summary , descriptive models provide information about correlations in the data , while explanatory models go further to postulate causal relationships .Most models that are automatically constructed from a corpus are descriptive models ; in other words , they can tell us what features are relevant to a given pattern or construction , but they ca n't necessarily tell us how those features and patterns relate to one another .If our goal is to understand the linguistic patterns , then we can use this information about which features are related as a starting point for further experiments designed to tease apart the relationships between features and patterns . 8 Summary .", "label": "", "metadata": {}}
{"text": "Supervised classifiers use labeled training corpora to build models that predict the label of an input based on specific features of that input .Supervised classifiers can perform a wide variety of NLP tasks , including document classification , part - of - speech tagging , sentence segmentation , dialogue act type identification , and determining entailment relations , and many other tasks .When training a supervised classifier , you should split your corpus into three datasets : a training set for building the classifier model ; a dev - test set for helping select and tune the model 's features ; and a test set for evaluating the final model 's performance .", "label": "", "metadata": {}}
{"text": "Otherwise , your evaluation results may be unrealistically optimistic .Decision trees are automatically constructed tree - structured flowcharts that are used to assign labels to input values based on their features .Although they 're easy to interpret , they are not very good at handling cases where feature values interact in determining the proper label .In naive Bayes classifiers , each feature independently contributes to the decision of which label should be used .This allows feature values to interact , but can be problematic when two or more features are highly correlated with one another .", "label": "", "metadata": {}}
{"text": "Most of the models that are automatically constructed from a corpus are descriptive - they let us know which features are relevant to a given patterns or construction , but they do n't give any information about causal relationships between those features and patterns .9 Further Reading .Many of the machine learning algorithms discussed in this chapter are numerically intensive , and as a result , they will run slowly when coded naively in Python .For information on increasing the efficiency of numerically intensive algorithms in Python , see ( Kiusalaas , 2005 ) .Examples of these challenge competitions include CoNLL Shared Tasks , the ACE competitions , the Recognizing Textual Entailment competitions , and the AQUAINT competitions .", "label": "", "metadata": {}}
{"text": "Find out what type and quantity of annotated data is required for developing such systems .Why do you think a large amount of data is required ?Begin by splitting the Names Corpus into three subsets : 500 words for the test set , 500 words for the dev - test set , and the remaining 6900 words for the training set .Then , starting with the example name gender classifier , make incremental improvements .Use the dev - test set to check your progress .Once you are satisfied with your classifier , check its final performance on the test set .", "label": "", "metadata": {}}
{"text": "Is this what you 'd expect ?It contains data for four words : hard , interest , line , and serve .Choose one of these four words , and load the corresponding data : .Using this dataset , build a classifier that predicts the correct sense tag for a given instance .Can you explain why these particular features are informative ?Do you find any of them surprising ?Using the same training and test data , and the same feature extractor , build three classifiers for the task : a decision tree , a naive Bayes classifier , and a Maximum Entropy classifier .", "label": "", "metadata": {}}
{"text": "How do you think that your results might be different if you used a different feature extractor ?What features are relevant in this distinction ?Build a classifier that predicts when each word should be used .However , dialog acts are highly dependent on context , and some sequences of dialog act are much more likely than others .For example , a ynQuestion dialog act is much more likely to be answered by a yanswer than by a greeting .Make use of this fact to build a consecutive classifier for labeling dialog acts .Be sure to consider what features might be useful .", "label": "", "metadata": {}}
{"text": "However , many words occur very infrequently , and some of the most informative words in a document may never have occurred in our training data .One solution is to make use of a lexicon , which describes how different words relate to one another .Using WordNet lexicon , augment the movie review document classifier presented in this chapter to use features that generalize the words that appear in a document , making it more likely that they will match words found in the training data .Each instance in the corpus is encoded as a PPAttachment object : .", "label": "", "metadata": {}}
{"text": "Using this sub - corpus , build a classifier that attempts to predict which preposition is used to connect a given pair of nouns .For example , given the pair of nouns \" team \" and \" researchers , \" the classifier should predict the preposition \" of \" .Explore this issue by looking at corpus data ; writing programs as needed . \" ... \" Segmental hidden Markov models \" ( SHMMs ) are intended to overcome important speech - modelling limitations of the conventional - HMM approach by representing sequences ( or segments ) of features and incorporating the concept of trajectories to describe how features change over time .", "label": "", "metadata": {}}
{"text": "\" Segmental hidden Markov models \" ( SHMMs ) are intended to overcome important speech - modelling limitations of the conventional - HMM approach by representing sequences ( or segments ) of features and incorporating the concept of trajectories to describe how features change over time .A novel feature of the approach presented in this paper is that extra - segmental variability between different examples of a sub - phonemic speech segment is modelled separately from intra - segmental variability within any one example .The extra - segmental component of the model is represented in terms of variability in the trajectory parameters , and these models are therefore referred to as \" probabilistic - trajectory segmental HMMs \" ( PTSHMMs ) .", "label": "", "metadata": {}}
{"text": "Experiments have demonstrated that , for any given feature set , a linear PTSHMM can substantially reduce the error rate in comparison with a conventional HMM , both for a connected - digit recognition task and for a phonetic classification task .Performance benefits have been demonstrated from incorporating a linear trajectory description and additionally from modelling variability in the mid - point parameter . \" ...This paper addresses the time - series modelling of high dimensional data .Currently , the hidden Markov model ( HMM ) is the most popular and successful model especially in speech recognition .", "label": "", "metadata": {}}
{"text": "This paper addresses the time - series modelling of high dimensional data .Currently , the hidden Markov model ( HMM ) is the most popular and successful model especially in speech recognition .However , there are well known shortcomings in HMMs particularly in the modelling of the correlation between successive observation vectors ; that is , inter - frame correlation .Standard diagonal covariance matrix HMMs also lack the modelling of the spatial correlation in the feature vectors ; that is , intra - frame correlation .Several other time - series models have been proposed recently especially in the segment model framework to address the inter - frame correlation problem such as Gauss - Markov and dynamical system segment models .", "label": "", "metadata": {}}
{"text": "All these models can be regarded as belonging to the broad class of generalised linear Gaussian models .Linear Gaussian models ( LGM ) are popular as many forms may be trained efficiently using the expectation maximisation algorithm .In this paper , several LGMs and generalised LGMs are reviewed .The models can be roughly categorised into four combinations according to two different state evolution and two different observation processes .The state evolution process can be based on a discrete finite state machine such as in the HMMs or a linear first - order Gauss - Markov process such as in the traditional linear dynamical systems .", "label": "", "metadata": {}}
{"text": "General HMMs and schemes proposed to improve their performance such as STC can be regarded as special cases in this framework . \" ...Declaration This dissertation is the result of my own work and includes nothing that is the outcome of work done in collaboration .It has not been submitted in whole or in part for a degree at any other university .Some of the work has been published previously in conference proceedings [ 66,69 ] , two ... \" .Declaration This dissertation is the result of my own work and includes nothing that is the outcome of work done in collaboration .", "label": "", "metadata": {}}
{"text": "Some of the work has been published previously in conference proceedings [ 66,69 ] , two journal articles [ 36,68 ] , two workshop papers [ 35,67 ] and a tech - nical report [ 65].The length of this thesis including appendices , bibliography , footnotes , tables and equations is approximately 60,000 words .This thesis contains 27 figures and 20 tables .i . ... aches have been proposed for extending the range of dependencies modelled by both generative and discriminative statistical models .For discriminative models , latent - variable extensions such as ... . \" ...", "label": "", "metadata": {}}
{"text": "Although these approaches have been successful , they can not easily incorporate complex modeling strategies that may further improve speech recognition performance ... \" .Currently , most approaches to speech recognition are frame - based in that they represent speech as a temporal sequence of feature vectors .Although these approaches have been successful , they can not easily incorporate complex modeling strategies that may further improve speech recognition performance .In contrast , segment - based approaches represent speech as a temporal graph of feature vectors and facilitate the incorporation of a wide range of modeling strategies .", "label": "", "metadata": {}}
{"text": "This thesis . \" ...Currently the most popular acoustic model for speech recognition is the hidden Markov model ( HMM ) .However , HMMs are based on a series of assumptions some of which are known to be poor .In particular , the assumption that successive speech frames are conditionally independent given the discrete stat ... \" .Currently the most popular acoustic model for speech recognition is the hidden Markov model ( HMM ) .However , HMMs are based on a series of assumptions some of which are known to be poor .In particular , the assumption that successive speech frames are conditionally independent given the discrete state that generated them is not a good assumption for speech recognition .", "label": "", "metadata": {}}
{"text": "State space models are based on a continuous state vector evolving through time according to a state evo- .... mance , mathematically this technique conflicts with the independence assumption .This independence assumption is widely thought to be the major drawback of the use of HMMs for speech recognition ( eg .State space models may be used to address the shortcomings of HMM based speech recognition .State space models are based on a hidden continuous state evolution process and an observation process wh ... . \" ...This report describes an attempt at capturing segmental transition information for speech recognition tasks .", "label": "", "metadata": {}}
{"text": "In approaches such as recurren ... \" .This report describes an attempt at capturing segmental transition information for speech recognition tasks .The slowly varying dynamics of spectral trajectories carries much discriminant information that is very crudely modelled by traditional approaches such as HMMs .In approaches such as recurrent neural networks there is the hope , but not the convincing demonstration , that such transitional information could be captured .The method presented here starts from the very different position of explicitly capturing the trajectory of short time spectral parameter vectors on a subspace in which the temporal sequence information is preserved .", "label": "", "metadata": {}}
{"text": "On this subspace , we attempt a parametric modelling of the trajectory , and compute a distance metric to perform classification of diphones .We use the principal curves method of Hastie and Stuetzle and the Generative Topographic map ( GTM ... . ... acoustic trajectories for word segments reporting superior results over traditional HMMs on a limited task recognising 36 CVC words .Although all approaches try to circumvent the frame independence assumption within a segment and repo ... . by Ashvin Kannan , Mari Ostendorf - in Proc .Int&apos;l .Conf . on Acoust . , Speech and Signal Proc , 1993 . \" ...", "label": "", "metadata": {}}
{"text": "We investigate the issues that are involved in trade - offs between trajectory and mixture modeling in segment - based word re ... \" .This paper presents a mechanism for implementing mixtures at a phone - subsegment ( microsegment ) level for continuous word recognition based on the Stochastic Segment Model ( SSM ) .We investigate the issues that are involved in trade - offs between trajectory and mixture modeling in segment - based word recognition .Experimental results are reported on DARPA 's speakerindependent Resource Management corpus .INTRODUCTION In earlier work , the Stochastic Segment Model ( SSM ) [ 1 , 2 ] has been shown to be a viable alternative to the Hidden Markov Model ( HMM ) for representing variable - duration phones .", "label": "", "metadata": {}}
{"text": "Typically , the model assumes that segme ... . ... istic mapping specifies which region corresponds to each observation vector .Initial experiments with contextindependent ( CI ) phone classification suggested that microsegment models provided a significant gain over the standard SSM ... . \" ...The HMM assumption of conditional independence of observations causes a variety of problems for speech - recognition applications .Previous attempts to construct acoustic models that remove this assumption have suffered from a significant increase in the number of parameters to train .Another weakness ... \" .The HMM assumption of conditional independence of observations causes a variety of problems for speech - recognition applications .", "label": "", "metadata": {}}
{"text": "Another weakness of current acoustic models is that they do not account for the origin of derived features ( estimated derivatives ) .We show how to both remove the independence assumption and properly account for derived features , with little or no increase in the number of parameters to train , by applying the principle of maximum entropy .We also show that ignoring the origins of derived features in training HMM acoustic models can lead to severe distortions of the effective language model .Evaluation of our maxent model on a simple problem cuts an already - low error rate in half compared to an equivalent HMM with the same number of parameters . .", "label": "", "metadata": {}}
{"text": "This model introduces a vector of continuous hidden state variables .The evolution of the state vector may be viewed as a ...[ Show abstract ] [ Hide abstract ] ABSTRACT : This paper presents a mesh - based approach for D face recognition using a novel local shape descriptor and a SIFT - like matching process .Both maximum and minimum curvatures estimated in the 3D Gaussian scale space are employed to detect salient points .The subsequent matching step then robustly associates corresponding points of two facial surfaces , leading to much more matched points between different scans of a same person than the ones of different persons .", "label": "", "metadata": {}}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : 3D face models accurately capture facial surfaces , making it possible for precise description of facial activities .In this paper , we present a novel mesh - based method for 3D facial expression recognition using two local shape descriptors .To characterize shape information of the local neighborhood of facial landmarks , we calculate the weighted statistical distributions of surface differential quantities , including histogram of mesh gradient ( HoG ) and histogram of shape index ( HoS ) .Normal cycle theory based curvature estimation method is employed on 3D face models along with the common cubic fitting curvature estimation method for the purpose of comparison .", "label": "", "metadata": {}}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : Three - dimensional face landmarking aims at automatically localizing facial landmarks and has a wide range of applications ( e.g. , face recognition , face tracking , and facial expression analysis ) .Existing methods assume neutral facial expressions and unoccluded faces .In this paper , we propose a general learning - based framework for reliable landmark localization on 3-D facial data under challenging conditions ( i.e. , facial expressions and occlusions ) .Our approach relies on a statistical model , called 3-D statistical facial feature model , which learns both the global variations in configurational relationships between landmarks and the local variations of texture and geometry around each landmark .", "label": "", "metadata": {}}
{"text": "Results from experiments on three publicly available 3-D face databases ( FRGC , BU-3-DFE , and Bosphorus ) demonstrate the effectiveness of our approach , in terms of landmarking accuracy and robustness , in the presence of expressions and occlusions .Full - text \u00b7 Article \u00b7 May 2011 \u00b7 IEEE transactions on systems , man , and cybernetics .Part B , Cybernetics : a publication of the IEEE Systems , Man , and Cybernetics Society .[ Show abstract ] [ Hide abstract ] ABSTRACT :In this paper , we focus on one of the ImageCLEF tasks that LIRIS - Imagine research group participated : visual concept detection and annotation .", "label": "", "metadata": {}}
{"text": "The results have shown that combination of our textural features and visual features can improve the performance significantly .[ Show abstract ] [ Hide abstract ] ABSTRACT :In this paper we present the results of the 3D Shape Retrieval Contest 2011 ( SHREC'11 ) track on face model retrieval .The aim of this track is to evaluate the performance of 3D shape retrieval algorithms that can operate on 3D face models .The benchmark dataset consists of 780 3D face scans of 130 individuals .Four groups have participated in the track with 14 method variations in total .", "label": "", "metadata": {}}
{"text": "Action units deform facial appearance simultaneously in landmark locations and local texture as well as geometry on 3D faces .Thus , it is necessary to extract features from multiple facial modalities to characterize these deformations comprehensively .In order to fuse the contribution of the discriminative power from all features efficiently , we propose to use our extended statistical facial feature models ( SEAM ) to generate feature instances corresponding to AU class for each feature .Then the similarity between each feature on a face and its instances are evaluated so that a set of similarity scores are obtained .", "label": "", "metadata": {}}
{"text": "Experiments on the Bosphorus database show its state - of - the - art performance .[ Show abstract ] [ Hide abstract ] ABSTRACT : The Local Binary Pattern ( LBP ) operator is a computationally efficient yet powerful feature for analyzing local texture structures .In this paper , we propose six novel multi - scale color LBP operators in order to increase photometric invariance property and discriminative power of the original LBP operator .The experimental results on the PASCAL VOC 2007 image benchmark show significant accuracy improvement by the proposed operators as compared with both the original LBP and other popular texture descriptors such as Gabor filter .", "label": "", "metadata": {}}
{"text": "In this paper we propose a novel approach to perform expression recognition automatically and flexibly by combining a Bayesian Belief Net ( BBN ) and Statistical facial feature models ( SFAM ) .A novel BBN is designed for the specific problem with our proposed parameter computing method .By learning global variations in face landmark configuration ( morphology ) and local ones in terms of texture and shape around landmarks , morphable Statistic Facial feature Model ( SFAM ) allows not only to perform an automatic landmarking but also to compute the belief to feed the BBN .Tested on the public 3D face expression database BU-3DFE , our automatic approach allows to recognize expressions successfully , reaching an average recognition rate over 82 % .", "label": "", "metadata": {}}
{"text": "Methods so far developed for pure 2D texture images were shown sensitive to lighting condition changes .In this paper , we present a statistical model - based technique for accurate 3D face landmarking , thus using an \u00c2\u00bfanalysis by synthesis\u00c2 \u00bf approach .Our model learns from a training set both variations of global face shapes as well as the local ones in terms of scale - free texture and range patches around each landmark .Given a shape instance , local regions of a new face can be approximated by synthesizing texture and range instances using respectively the texture and range models .", "label": "", "metadata": {}}
{"text": "Experimented on more than 1860 face models from FRGC datasets , our method achieves an average of locating errors less than 7 mm for 15 feature points .Compared with a curvature analysis - based method also developed within our team , this learning - based method enables localization of more facial landmarks with a general better accuracy at the cost of a learning step .[ Show abstract ] [ Hide abstract ] ABSTRACT :In this paper , we introduce a new approach for partial 3D face recognition , which makes use of shape decomposition over the rigid part of a face .", "label": "", "metadata": {}}
{"text": "In our work we investigate several classifiers as well as several shape descriptors for recognition purposes .Recognition tests on a subset of the FRGC data set show approximately 80 % rank - one recognition rate using only the eyes and nose part of the face .[ Show abstract ] [ Hide abstract ] ABSTRACT :In this paper we present a conformal mapping - based ap - proach for 3D face recognition .The proposed approach makes use of conformal UV parameterization for mapping purpose and Shape Index decomposition for similarity mea - surement .Indeed , according to conformal geometry theory , each 3D surface with disk topology can be mapped onto a 2D domain through a global optimization , resulting in a diffeomorphism , i.e. , one - to - one and onto .", "label": "", "metadata": {}}
{"text": "To deal with facial expressions , the M\u00f6bius transformation of UV conformal space has been used to ' compress ' face mimic region .Rasterized images are used as an input for ( 2D ) 2 P CA recognition algorithm .Experimented on 62 subjects randomly selected from the FRGC dataset v2 which includes different facial expres - sions , the proposed method displays a 86.43 % , 97.65 % and 69.38 rank - one recognition rate in respectively Neutral vs. All , Neutral vs. Neutral and Neutral vs. Expression scenar - ios .[ Show abstract ] [ Hide abstract ] ABSTRACT : While it is very hard to achieve automatic sports competition key moments detection only based on visual analysis , we propose in this paper automatic highlights detection based on an audio classifier .", "label": "", "metadata": {}}
{"text": "The proposed approach was evaluated on soccer and tennis videos , though our technique has no restriction on the sports ' type .It is shown that audio - based highlights detection can be effective for tennis segmentation since 97.5 % of end - of - serves were correctly classified .Goals can be detected in soccer videos using audio analysis as well .An intelligent sports - videos player is proposed based on the audio analysis permitting the user to navigate through key moments in a sports video .[ Show abstract ] [ Hide abstract ] ABSTRACT : 3D face landmarking aims at automatic localization of 3D facial features and has a wide range of applications , including face recognition , face tracking , facial expression analysis .", "label": "", "metadata": {}}
{"text": "In this paper , we propose a learning - based approach for reliable locating of face landmarks in 3D. Our approach relies on a statistical model , called 3D Statistical Facial feAture Model(SFAM ) in the paper , which learns both global variations in 3D face morphology and local ones around the 3D face landmarks in terms of local texture and shape .Experimented on FRGC v1.0 dataset , our approach shows its effectiveness and achieves 99.09 % of locating accuracy in 10 mm precision .The mean error and standard deviation of each landmark are respectively less than 5 mm and 4 .", "label": "", "metadata": {}}
{"text": "Most works in the literature rely on moving object detection and tracking , assuming that all moving objects are people .In this paper , we present our people counting approach based on face detection , tracking and trajectory classification .While we have used a standard face detector , we achieve face tracking combining a new scale invariant Kalman filter with kernel based tracking algorithm .From each potential face trajectory an angle histogram of neighboring points is then extracted .Finally , an Earth Mover 's Distance - based K - NN classification discriminates true face trajectories from the false ones .", "label": "", "metadata": {}}
{"text": "[ Show abstract ] [ Hide abstract ] ABSTRACT : This paper introduces audio scenes and audio chapters in movies and presents an efficient algorithm for automatically structuring a video based on the audio stream only .The automatic solution to audio scene and chapter segmentation is evaluated on manually segmented videos .[ Show abstract ] [ Hide abstract ] ABSTRACT : This paper presents a novel approach for visual object classification .Based on Gestalt theory , we propose to extract features from coarse regions carrying visually significant information such as line segments and/or color and to include neighborhood information in them .", "label": "", "metadata": {}}
{"text": "Moreover we show that by separating features extracted from different sources in different \" channels \" , which are then combined using a late fusion strategy , we can limit the impact of feature dimensionality and actually improve classification accuracy .[ Show abstract ] [ Hide abstract ] ABSTRACT :A digital picture generally contains tens of thousands of colors .Therefore , most image processing applications first need to apply a color reduction scheme before performing further sophisticated analysis operations such as segmentation .While a lot of color reduction techniques exist in the literature , they are mainly designed for image compression and are unfortunately not suited for many image processing operations ( e.g. segmentation ) as they tend to alter image color structure and distribution .", "label": "", "metadata": {}}
{"text": "We also advocate for the use of perceptually accurate metrics for evaluation .Experimental results on a diversified dataset of images selected from the internet show that our technique performs well compared to other color reduction schemes .[ Show abstract ] [ Hide abstract ] ABSTRACT : The audio channel conveys rich clues for content - based multimedia indexing .Interesting audio analysis includes , besides widely known speech recognition and speaker identification problems , speech / music segmentation , speaker gender detection , special effect recognition such as gun shots or car pursuit , and so on .", "label": "", "metadata": {}}
{"text": "While most audio analysis techniques in the literature are problem specific , we propose in this paper a general framework for audio classification .The proposed technique uses a perceptually motivated model of the human perception of audio classes in the sense that it makes a judicious use of certain psychophysical results and relies on a neural network for classification .The classification accuracies of the proposed technique are comparable to those obtained by problem specific techniques while offering the basis of a general approach for audio classification .[ Show abstract ] [ Hide abstract ] ABSTRACT : This paper presents a method for mobile face detection and tracking in media streaming applications .", "label": "", "metadata": {}}
{"text": "Various aspects on mobile phone use are considered in order to record a profile on a mobile media streaming user .The profile is generated by analysing pictures of mobile phone users and screenshots of their devices .The mobile face detection model is based on the optimised version of robust real - time object detection algorithm .Our optimisation enables to reduce the computational complexity of the original version in 4 times .We also describe the tracking mode in which the system achieves a near real - time frame rate ( 45 12 fps depending on the video complexity ) .", "label": "", "metadata": {}}
{"text": "We describe the construction of the low bit - rate video coder that uses face detection and tracking to segment foreground / background object and encode them with a different bit - rate .We also describe a framework for smart videoconferences and experimental results on low bit - rate image coding for this application .No preview \u00b7 Article \u00b7 Jan 2007 \u00b7 International Journal of Wireless and Mobile Computing Techniques are provided to classify patterns in isogenous pattern sources .Techniques are provided to determine a computationally inexpensive upperbound on the true score or joint probability of the field label and field features over all field labels .", "label": "", "metadata": {}}
{"text": "Abstract .Techniques are provided to classify patterns in isogenous pattern sources .Techniques are provided to determine a computationally inexpensive upperbound on the true score or joint probability of the field label and field features over all field labels .Candidate field labels associated with promising upperbound scores are dynamically queued .True scores are computed for a subset of the candidates fields resulting in reduced computations to determine a field label .Techniques are also provided to determine optimal variables for any system with shared constraints .A method of style conscious field classification comprising the steps of : . determining candidate field labels in an isogenous pattern source ; . determining an ordering of candidate field labels and associated upperbound scores in a list ; . while a determined true score for the candidate field label with the highest upperbound scorethe upperbound score for all other candidate field labels in the list .", "label": "", "metadata": {}}
{"text": "claim 1 , wherein the ordering of field labels is at least one of ascending and descending .The method of .claim 1 , wherein the list is at least one of an array , an associative array , a list , a linked list and a heap .The method of .claim 1 , wherein the isogenous patterns are at least one of audio , video , image and textual patterns .The method of .claim 4 , wherein the at least one audio , video , image and textual patterns are linearly oriented .A system for style conscious field classification comprising : . a input / output circuit for receiving candidate fields labels from an isogenous pattern source ; . a processor that determines candidate field labels in an isogenous source and determines an ordering of candidate field labels and associated upperbound scores in a list ; . while a determined true score for the candidate field label with the highest upperbound scorethe upperbound score for all other candidate field labels in the , list .", "label": "", "metadata": {}}
{"text": "claim 6 , wherein the ordering of field labels is at least one of ascending and descending .The system of .claim 6 , wherein the list is at least one of an array , an associative array , a list , a linked list and a heap .The system of .claim 6 , wherein the isogenous patterns are at least one of audio , video , image and textual patterns .The system of .claim 9 , wherein the at least one audio , video , image and textual patterns are linearly oriented .Computer readable storage medium comprising : computer readable program code embodied on the computer readable storage medium , the computer readable program code usable to program a computer to a method of style conscious field classification for recognizing a candidate label comprising the steps of : . determining candidate field labels in an isogenous pattern source ; . determining an ordering of candidate field labels and associated upperbound scores in a list ; . while a determined true score for the candidate field label with the highest upperbound score .", "label": "", "metadata": {}}
{"text": "A method of style conscious field classification comprising the steps of : . determining candidate field labels in an isogenous pattern source ; . determining an ordering of candidate field labels and associated lowerbound scores in a list ; . returning the determined candidate field label as the recognized field when the lowest true score .A method of .claim 1 , wherein candidate field labels are not all sorted and only added to an ordered list as necessary .A system for style conscious field classification comprising : . a input / output circuit for receiving fields labels from an isogenous pattern source ; . a processor that determines candidate field labels in an isogenous source and determines an ordering of candidate field labels and associated lowerbound scores in a list ; .", "label": "", "metadata": {}}
{"text": "claim 6 , wherein candidate field labels are not all sorted and only added to an ordered list as necessary .Description .INCORPORATION BY REFERENCE .This Application incorporates by reference : entitled \" DOCUMENT IMAGE DECODING USING AN INTEGRATED STOCHASTIC LANGUAGE MODEL \" by A. Popak et al ., filed May 12 , 2000 as U.S. patent application Ser .No . 09/570,730 ; in its entirety .BACKGROUND OF THE INVENTION .Field of Invention .This invention relates to techniques for style conscious field classification of isogenous patterns .Description of Related Art .Conventional recognition systems have difficulty correctly classifying less than optimal patterns of text images .", "label": "", "metadata": {}}
{"text": "Due to dependencies among patterns in the field , these conventional systems require optimization of a field score over all possible field labels .However , the determination of joint probabilities of the field label and field - features over all field labels is computationally expensive .Moreover , the number of computations necessary to determine a field label increases exponentially with increasing field - length .This limits the application of these conventional systems for longer fields and larger texts .SUMMARY OF THE INVENTION .The systems and methods according to this invention provide for style conscious field classification of isogenous or common origin patterns .", "label": "", "metadata": {}}
{"text": "Systems and methods according to this invention compute an upperbound value of the true score of a field label .Candidate field labels with promising upperbound values are dynamically queued .The systems and methods according to this invention determine an upper bound on the field - label conditional field - feature likelihood , for a subset of all possible field labels .The systems and methods according to this invention provide for optimization of any variables with shared or joined constraints .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is an overview showing an exemplary style conscious field classification system , according to this invention ; .", "label": "", "metadata": {}}
{"text": "2 is an exemplary pattern recognition flowchart showing pattern recognition based on an exemplary method of style conscious field classification according to this invention ; .FIG .3 is an expanded flowchart of an exemplary method of style conscious field classification according to this invention ; .FIG .4 is an exemplary style conscious field classification system according to this invention ; .FIG .5 shows an exemplary data structure for storing current label information according to this invention ; .FIG .6 shows exemplary successor labels according to this invention ; .FIG .7 shows an exemplary data structure for storing current - best label information according to this invention ; .", "label": "", "metadata": {}}
{"text": "8 shows an exemplary data structure for storing priority queue information according to this invention ; .FIG .9 shows an exemplary portion of a text pattern ; .FIG .10 shows an exemplary portion of an audio pattern ; .FIG .11 shows an exemplary portion of a video pattern ; .FIG .12 shows an exemplary data structure for storing patterns associated with a field ; .FIG .13 shows an exemplary data structure for storing factorizable upperbound contribution values associated with patterns in a field according to this invention .DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS .", "label": "", "metadata": {}}
{"text": "1 is an overview showing an exemplary style conscious field classification system according to this invention .The information repository 300 contains text image patterns 1000 , audio patterns 1001 and video patterns 1002 .In a first exemplary embodiment according to this invention , a user of web - enabled personal computer 400 forwards a request for the optical character recognition of text image 1000 to the style conscious field classification based OCR system 103 .The text image patterns 1000 stored in information repository 300 may include PNG , TIFF , J - PEG , GIF , Adobe PDF image files and/or any known or later developed image format .", "label": "", "metadata": {}}
{"text": "The style conscious field classification based OCR system 103 recognizes text associated with the text image patterns .For example , the style conscious field classification based OCR system 103 exploits the fact that character bitmaps in word generally share the same font .Since patterns of a class are likely to be rendered less variedly by a single source than by multiple sources , this information can be used to improve the classification process .Style consistency modeling can be divided into weak and strong style consistency .Weak style consistency includes indicating how \" a \" is written the same way each time by the same author .", "label": "", "metadata": {}}
{"text": "For example , how \" a \" looks depends on how \" b \" looks .Strong style consistency is especially useful when the fields are not long enough for conventional classification systems to determine the parent style .The style conscious field classification based OCR system 103 uses these determined interdependencies to improve classification .After recognizing the text associated with the text patterns , the style conscious field classification system 103 forwards the recognized text to the personal computer 400 via communications links 99 .In various other exemplary embodiments of this invention , style field classification based field recognition may be used in conjunction with optical character recognition systems without departing from the scope of this invention .", "label": "", "metadata": {}}
{"text": "Character recognition is then determined by the style conscious field classification based OCR system 103 as discussed above .It will be apparent that in various other exemplary embodiments according to this invention , the style conscious classification system 100 may be located within web - enabled portable device 600 and/or form part of a handwriting recognition circuit and/or software routine within web - enabled portable device 600 .For example , a style conscious field classification based handwriting recognition system ( not shown ) may be included within web - enabled portable device 600 to improve the recognition of handwritten patterns .", "label": "", "metadata": {}}
{"text": "In various other exemplary embodiments of this invention , a generalized style conscious field classification system 100 placed at any location accessible via communications links 99 is used to recognize patterns in various types of isogenous information .In a third exemplary embodiment according to this invention , a user of phone 500 may initiate a speech based request for text image patterns 1000 stored in information repository 300 .The audio patterns of the speech based request are forwarded to the style conscious field classification based audio recognition system 102 .Sampled features in the signal frames of the speech segments are used to recognize phonemes and/or words .", "label": "", "metadata": {}}
{"text": "The recognized audio text corresponding to the speech request is then forwarded to the information repository 300 .The object of the voice or speech request , the text image patterns 1000 , are then forwarded to a display device associated with the user .It will be apparent that the display device may include a facsimile machine , a text to speech synthesizer or any known or later developed method of output or display .It should be noted that the style conscious field classification system 100 may also be incorporated directly within phone 500 , placed within information repository 300 or placed at any location accessible via communications links 99 .", "label": "", "metadata": {}}
{"text": "The request is forwarded to the style conscious field classification based visual object recognition system 101 .For example , a user of web - enabled personal computer 400 may request the recognition of a corporate logo , insignia or other visual object in the video patterns of a movie .The style conscious field classification based visual object recognition system 101 recognizes visual objects in the video patterns of the movie and attempts to determine all instances of the specific corporate logo or insignia .Various other embodiments of the systems and methods of this invention may be used to automatically determine objects and/or user actions or responses in a computer monitored or smart environment .", "label": "", "metadata": {}}
{"text": "The style conscious field classification based visual object recognition system 101 exploits the style consistency in video patterns to improve visual object recognition despite camera angle changes , focus and other changes within the video patterns 1002 .In various other exemplary embodiments of this invention , indices into the video patterns may be returned indicating all video locations containing the recognized visual objects .In various other exemplary embodiments of this invention directed to audio patterns processing , the style conscious field classification based audio recognition system 102 is used to filter telephone , television , radio and other audio patterns for keywords .", "label": "", "metadata": {}}
{"text": "FIG .2 is an exemplary pattern recognition flowchart showing pattern recognition based on an exemplary method of style conscious field classification according to this invention .The process starts at step S 100 and continues immediately to step S 110 where the source of patterns is selected .As discussed above , the patterns may be selected from any isogenous source .For example , the text image patterns output from scanning of textual information , audio telephone conversations , radio and television audio broadcasts and video patterns such as television broadcasts , movies in MPEG , motion - JPEG , real - video or any other known or later developed source of isogenous patterns .", "label": "", "metadata": {}}
{"text": "In step S 120 , a first field within the isogenous patterns is selected .For example , if the isogenous patterns are text image patterns , the first field is likely to be a word composed of discrete characters .The field is selected and control continues to step S 130 .For speech based audio patterns , phonemes and/or speech utterances are determined .The contribution of the candidate pattern labels to the factorizable upperbound score are determined for each position in the field in step S 130 .In various exemplary embodiments according to this invention , the contribution of each pattern label is determined and stored in an array in memory or any known or later developed method of storing information .", "label": "", "metadata": {}}
{"text": "In step S 140 of an exemplary embodiment according to this invention , each candidate pattern label is re - labeled using the sorted index offsets as labels .However , it will be apparent that re - labeling of candidate fields is used merely to facilitate discussion of the various candidate field labels .Thus , in various other exemplary embodiments , the candidate field labels may be used directly without departing from the scope of this invention .Control then continues to step S 150 .In step S 150 , a field label is determined using a style conscious field the exemplary method of style conscious field classification shown in the expanded flowchart of .", "label": "", "metadata": {}}
{"text": "3 .After the field label is determined in step S 150 , control continues to step S 160 .In step S 160 , a determination is made whether the last field in the pattern source has been reached .If the current field is not the last field , control continues to step S 170 where the next field in the pattern source is determined .After the next field in the pattern source is determined , control continues to step S 130 and steps S 130 -S 160 are repeated until the last field in the pattern source is determined .", "label": "", "metadata": {}}
{"text": "FIG .3 is an expanded flowchart of an exemplary method of style conscious field classification according to this invention .Index labels used to label candidate fields are used here merely for discussion purposes .Any method of labeling candidate field labels may be used in the practice of this invention .The ordering of candidate pattern - labels is according to their contribution to an upperbound score as discussed later .The exemplary style conscious field classification starts at step S 200 and immediately continues to step S 210 where a current label , a current - best label and a priority queue are initialized .", "label": "", "metadata": {}}
{"text": "In step S 220 , the successor labels of the current label are determined .The successors of the current label are determined by increasing each successive index position by one , until a maximum number of classes C is reached .After the successor labels of the current label are determined , control continues to step S 230 .The priority queue of labels is merged with the previously determined successors of the current label in step S 230 .For example , a factorizable upperbound score may be determined for each successor label entry to be added to the priority queue .", "label": "", "metadata": {}}
{"text": "Successor label entries are then merged into the priority queue based on the determined factorizable upperbound score for each associated successor label .This ensures that the head or first label element of the priority queue is associated with the highest factorizable upperbound score .It should be noted that the term factorizable refers to the ability to express the upperbound as a combination of terms each of which depends one exactly one position in the field .For example , in various exemplary embodiments according to this invention , operations such as addition , multiplication and the like may also be used to practice the invention .", "label": "", "metadata": {}}
{"text": "In step S 240 , the true score of the current best - label is determined .In one exemplary embodiment according to this invention , the true score is determined based on the formula for the field - label conditional field - feature probability as follows : . f .c .c . ...c .L . )p .x .x .x .L .c .c .c .L . ) k .K .p . k .l .L .p .x .l .c .", "label": "", "metadata": {}}
{"text": "After the field label conditional field - feature probabilities are determined , control continues to step S 250 .In step S 250 , a factorizable upperbound score is determined for the first element or head of the priority queue .In one of the exemplary embodiments of this invention , the factorizable upperbound is determined based on a field - label conditional field - feature likelihood as follows : . f .c .c .L . ) max . k .l .L .p .x .l .c .l . k . )", "label": "", "metadata": {}}
{"text": "c .c .L . )l .L . max . k .p .x .l .c .l . k . )Inequality ( 3 ) then yields an easily factorizable upperbound for the true score for any field label .After the factorizable upperbound score is determined for the label at the head of the priority queue , control continues to step S 260 .In step S 260 , a determination is made whether the true score of the current - best label , determined in step S 240 , is less than the factorizable upperbound of the head element of the priority queue determined in step S 250 .", "label": "", "metadata": {}}
{"text": "Otherwise control continues to step S 340 where the best label is set equal to the current - best label .The best label is then returned as the most likely classification of the label .Control continues to step S 350 and the process immediately returns to step S 160 of .FIG .2 .In step S 270 , the value of the current label is set equal to the value of the head of the priority queue in step S 270 .Control then continues to step S 280 .In step S 280 , the head of the priority queue is removed from the queue .", "label": "", "metadata": {}}
{"text": "Control continues to step S 290 .The successors of the current label are determined in step S 290 .As discussed above , the successors of the current label are determined by increasing successive index positions by one position each time until the maximum number of classes is reached .Control continues to step S 300 where the adjusted priority queue is merged with the determined successors of the current label based on factorizable upperbound scores determined for each of the current label successors .Control continues to step S 310 .In step S 310 , true scores the current label and the current - best label are determined based on formula ( 1 ) as discussed above .", "label": "", "metadata": {}}
{"text": "A determination is then made in step S 320 whether the true score for the current label is greater than the true score of the current - best label .If it is determined that the true score of the current label is less than or equal to the true score of the current - best label , control jumps immediately to step S 240 and the steps S 240 -S 320 are repeated .If it is determined in step S 320 that the true score for the current label is greater than the true score for the current - best label , control continues to step S 330 where the current - best label is set equal to the current label .", "label": "", "metadata": {}}
{"text": "The exemplary method for style conscious field classification ends when it is determined in step S 260 that the score for the current - best label is less than the factorizable upperbound of the head element of the priority queue .Control then continues to step S 350 and returns immediately to step S 170 of .FIG .2 where the next pattern field is selected for classification .FIG .4 shows an exemplary style conscious field classification system 100 .The style conscious field classification system 100 is connected via communications links 99 to the information repository 300 containing text image patterns 1000 , a web - enabled personal computer 400 containing text image patterns 1000 , a phone 500 and a web - enabled portable device 600 .", "label": "", "metadata": {}}
{"text": "In various other exemplary embodiments according to this invention , the text image patterns 1000 contained in information repository 300 are forwarded via communications links 99 to the style conscious field classification system 100 .However , it will be apparent that the style conscious field classification system 100 may be located at any point accessible via communications links 99 or may be incorporated directly into a device such as phone 500 and/or web - enabled portable device 600 .The processor 20 retrieves the text image 1000 from input / output circuit 10 of the style field classification system 100 and stores the text image 1000 in memory 30 .", "label": "", "metadata": {}}
{"text": "The contributions of candidate pattern labels to the factorizable upperbound score for each position within the field are determined .In various exemplary embodiments according to this invention , the contribution of each pattern label is stored in memory 30 as an array or the like .The processor 20 then optionally re - labels each candidate pattern based on the sorted index offsets as labels .The current label and current - best label data structures are initialized .For example , a list data structure may be used to store current label and current - best label information in an easily accessible data structure .", "label": "", "metadata": {}}
{"text": "As discussed above , the initialization of the priority queue may set the number of labels in the queue to zero by adding a NIL value indicator to the priority queue .It will be apparent that the current label , current - best label and priority queue data structures are merely exemplary and that any known or later developed data structure useful in holding and accessing the current label , current - best label and priority queue information may be used .The processor 20 transfers the current label information stored in current label data structure of memory 30 to the successor determining circuit 40 .", "label": "", "metadata": {}}
{"text": "As discussed above , the current label successors are determined by successively increasing each index label by one until the maximum number of classes is reached .The processor 20 then merges the determined successors of the current label by activating the merging circuit 80 with the priority queue information based on the factorizable upperbound score obtained by activating the factorizable upperbound determining circuit 90 .The true score determining circuit 50 is then activated to determine the true score value of the current - best label .The processor 20 activates the priority queue head determining circuit 60 to determine the head element of the priority queue data structure .", "label": "", "metadata": {}}
{"text": "The processor 20 then compares the score of the current - best label to the factorizable upperbound score of the head element .If processor 20 determines that the true score of the current - best label is greater than the factorizable upperbound of the head element , then the best label has been determined and processing ends .Otherwise , processor 20 sets the value of the current label data structure equal to the previously determined value of the head element of the priority queue .The head element of the priority queue is then removed from the priority queue .", "label": "", "metadata": {}}
{"text": "The merging circuit 80 is then activated to merge the determined successors of the current label with the field labels in the priority queue .The score determining circuit 50 is activated with the current label stored in the current label data structure of memory 30 .The true score determining circuit 50 is also activated with the current - best label stored in the current - best label data structure of memory 30 .The determined current label score and the current - best label score are then compared by processor 20 .If processor 20 determines that the true score of the current label is greater than the true score of the current - best label , the value of the current - best label is set to the value of the current label .", "label": "", "metadata": {}}
{"text": "The best label is then set equal to the current - best label .The process continues for successive fields within the source patterns of text image 1000 until no further patterns remain to be processed .The cumulative determined best labels are the determined recognized text .FIG .5 shows an exemplary data structure for storing current label information according to this invention .The exemplary current label data structure 700 is comprised of a label portion 701 and associated upperbound portion 702 .The values indicate the best , second best and best candidate patterns .The current label data structure 700 contains an upperbound score of \" 0.07 \" in the upperbound portion 702 .", "label": "", "metadata": {}}
{"text": "It will be apparent that the upperbound scores are easily determined based on accumulations of previously determined upperbound scores associated with the respective candidate patterns for each position in the field .FIG .6 shows the exemplary determination of successor labels according to this invention .For example , the first position in the first row is incremented by one , until the maximum number of classes is reached .In the example , the number 2 is the maximum number of classes .The second position is then selected and similarly incremented until the maximum number of classes is reached .", "label": "", "metadata": {}}
{"text": "It will be apparent that the maximum number of classes may take various values depending on the pattern source and the patterns to be classified .FIG .7 shows an exemplary data structure for storing current - best label information according to this invention .The exemplary current - best label data structure 700 is comprised of a label portion 701 and associated upperbound portion 702 .These values indicate the current - best candidate field label is associated with the second best , best and best candidate patterns in the first , second and third positions of the candidate field .", "label": "", "metadata": {}}
{"text": "The \" 0.3 \" value of the upperbound portion is the product form of the upperbound score .It will be apparent that the upperbound scores are easily determined based on accumulations of previously determined contributions to the upperbound score associated with each respective candidate pattern label .FIG .8 shows an exemplary data structure for storing priority queue information according to this invention .The priority queue data structure 1100 comprises label portions 701 and upperbound portions 702 .The priority queue data structure 1100 has a head portion 1101 or first element and a tail portion 1103 .", "label": "", "metadata": {}}
{"text": "The tail portion 1103 of the priority queue data structure 1100 comprises field label portions 701 and associated upperbound portions 702 for each succeeding element of the priority queue data structure 1100 after the head element .The head portion 1101 and tail portion 1103 of the priority queue data structure 1100 are ordered based on the value of the associated upperbound portion 702 .As discussed above , the upperbound score is easily determined through accumulations of associated candidate patterns .FIG .9 shows an exemplary portion of a text image .Recognized and adjusted text is determined based on the text image 1000 .", "label": "", "metadata": {}}
{"text": "10 shows an exemplary portion of audio information 1001 .Recognized and adjusted audio information is determined based on the audio information 1001 .For example , the audio information 1001 contains a portion of a broadcast television commercial transcript .The recognized and adjusted text determined using this invention facilitates monitoring of a product advertising campaign by identifying \" XYZ corporation \" in the audio broadcast .FIG .11 shows an exemplary portion of video information 1002 .The Recognized and adjusted video object information is determined based on the video information 1002 .For example , video objects in a television broadcast are recognized and monitored for the \" XYZ Corp \" logo .", "label": "", "metadata": {}}
{"text": "12 shows an exemplary data structure for storing patterns associated with a field .For example , the label index associated with the field \" ere \" is shown .The second row corresponds to the second best candidate patterns for each position .FIG .13 shows an exemplary data structure for storing factorizable upperbound contribution values associated with patterns in a field , according to this invention .The first column portion of the exemplary data structure store the ordered position of the candidate pattern based on contributions to the upperbound score .For example , the first row contains all best candidate entries .", "label": "", "metadata": {}}
{"text": "The third column is the contribution to the factorizable upperbound score of the second column value .The field position and contribution to upperbound score are repeated for each position in the current field .It will be apparent however , that various other data structures may also be used to store factorizable upperbound contribution values associated with the candidate pattern labels in a field without departing from the scope of this invention .For example , the first row contains the ordered position value \" 1 \" indicating the best candidate pattern values .The best candidate pattern label in the first field position is \" e \" which makes a contribution of \" 0.99 \" to the upperbound score .", "label": "", "metadata": {}}
{"text": "The best candidate pattern label for the third field position is an \" a \" which makes a contribution of \" 0.85 \" to the factorizable upperbound .As discussed above , the values may be accumulated using addition , multiplication or any suitable function without departing from the scope of this invention .Each of the circuits 10 - 20 and 40 - 90 of the system for style conscious field classification 100 outlined above can be implemented as portions of a suitably programmed general - purpose computer .The particular form each of the circuits 10 - 20 and 40 - 90 of the system for style conscious field classification 100 outlined above will take is a design choice and will be obvious and predictable to those skilled in the art .", "label": "", "metadata": {}}
{"text": "In this case , the system for style conscious field classification 100 and/or each of the various circuits discussed above can each be implemented as one or more routines embedded in the communications network , as a resource residing on a server , or the like .As shown in .FIG .3 , memory 30 can be implemented using any appropriate combination of alterable , volatile or non - volatile memory or non - alterable , or fixed memory .The alterable memory , whether volatile or non - volatile , can be implemented using any one or more of static or dynamic RAM , a floppy disk and disk drive , a write - able or rewrite - able optical disk and disk drive , a hard drive , flash memory or the like .", "label": "", "metadata": {}}
{"text": "The communication links 99 shown in .In general , the communication links 99 can be any known or later developed connection system or structure usable to connect devices and facilitate communication .Further , it should be appreciated that the communication links 99 can be a wired or wireless links to a network .The network can be a local area network , a wide area network , an intranet , the Internet , or any other distributed processing and storage network .While this invention has been described in conjunction with the exemplary embodiments outlined above , it is evident that many alternatives , modifications and variations will be apparent to those skilled in the art .", "label": "", "metadata": {}}
