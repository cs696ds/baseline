{"text": "Figure 3 . 2-D 2-class data , along with first LDA basis vector and first PCA basis vector .The classes would be well separated by a projection onto the first LDA basis vector , but poorly separated by a projection onto the first PCA basis vector .Figure 16 .Accuracies of NLDA1 and NLDA2 with various dimensionality reduced features based on 1-state ( top panel ) and 3-state HMMs ( bottom panel ) .The NLDA1 features without PCA are always 48 dimensions .Figure 17 .Accuracies of the NLDA1 and NLDA2 features using 1-state ( top panel ) and 3-state HMMs ( bottom panel ) with various numbers of mixtures .", "label": "", "metadata": {}}
{"text": "Recognition accuracies of the NLDA dimensionality reduced features using the state level targets . \"( CR ) \" and \" ( FA ) \" indicate the training targets obtained with the constant length ratio and forced alignment respectively .Nonlinear Dimensionality Reduction Methods for Use with Automatic Speech Recognition .Stephen A. Zahorian 1 and Hongbing Hu 1 .Introduction .For nearly a century , researchers have investigated and used mathematical techniques for reducing the dimensionality of vector valued data used to characterize categorical data with the goal of preserving \" information \" or discriminability of the different categories in the reduced dimensionality data .", "label": "", "metadata": {}}
{"text": "Both PCA and LDA are based on linear , i.e. matrix multiplication , transformations .For the case of PCA , the transformation is based on minimizing mean square error between original data vectors and data vectors that can be estimated from the reduced dimensionality data vectors .For the case of LDA , the transformation is based on minimizing a ratio of \" between class variance \" to \" within class variance \" with the goal of reducing data variation in the same class and increasing the separation between classes .There are newer versions of these methods such as Heteroscedastic Discriminant Analysis ( HDA ) ( Kumar & Andreou , 1998 ; Saon et al . , 2000 ) .", "label": "", "metadata": {}}
{"text": "In this chapter , a class of nonlinear transformations is presented both from a theoretical and experimental point of view .Theoretically , the nonlinear methods have the potential to be more \" efficient \" than linear methods , that is , give better representations with fewer dimensions .In addition , some examples are shown from experiments with Automatic Speech Recognition ( ASR ) where the nonlinear methods in fact perform better , resulting in higher ASR accuracy than obtained with either the original speech features , or linearly reduced feature sets .Two nonlinear transformation methods , along with several variations , are presented .", "label": "", "metadata": {}}
{"text": "Thus this method is patterned after PCA .In the second method , referred to as nonlinear LDA ( NLDA ) , the goal of the nonlinear transformation is to maximize discriminability of categories of data .Thus the method is patterned after LDA .In all cases , the dimensionality reduction is accomplished with a Neural Network ( NN ) , which internally encodes data with a reduced number of dimensions .The differences in the methods depend on error criteria used to train the network , the architecture of the network , and the extent to which the reduced dimensions are \" hidden \" in the neural network .", "label": "", "metadata": {}}
{"text": "Thus , in one sense , the recognizer is a hybrid neural network / Hidden Markov Model ( NN / HMM ) recognizer .However , the neural network step is used for the task of nonlinear dimensionality reduction and is independent of the HMM .It is shown that the NLDA approach performs better than the NLPCA approach in terms of recognition accuracy .It is also shown that speech recognition accuracy can be as high as or even higher using reduced dimensionality features versus original features , with \" properly \" trained systems .Background .Both approaches are used .", "label": "", "metadata": {}}
{"text": "Therefore it seems unlikely that increased database size alone is a good approach to improved ASR accuracies by training with more and more features .In this chapter , some techniques are presented for reducing feature dimensionality while preserving category ( i.e. , phonetic for the case of speech ) discriminability .Since the techniques presented for reducing dimensionality are statistically based , these methods also are subject to \" curse of dimensionality \" issues .However , since this dimensionality reduction can be done at the very front end of a speech recognition system , with fewer model parameters tuned than in an overall recognition system , the \" curse \" can be less of a problem .", "label": "", "metadata": {}}
{"text": "Principal Components Analysis ( PCA ) .Principal Components Analysis ( PCA ) , also known as the Karhunen - Loeve Transform ( KLT ) , has been known of and in use for nearly a century ( Fodor , 2002 ; Duda et al . , 2001 ) , as a linear method for dimensionality reduction .Operationally , PCA can be described as follows : .Let .X .[ .x .x .x .n . ]T be an n -dimensional ( column ) feature vector , and .Y .[ .", "label": "", "metadata": {}}
{"text": "y .y . m . ]T be an m -dimensional ( column ) feature vector , obtained as the linear transform of X , using the n by m transformation matrix A , i.e. .Y .A .T .X .Let .X .^ .B .Y be an approximation to .X .Note that .X .Y and .X .^ can all be viewed as ( column ) vector - valued random variables .The goal of PCA is to determine A and B , such that .", "label": "", "metadata": {}}
{"text": "X .X .^ . ) is minimized .That is , .X .^ should approximate X as well as possible , in a mean square error sense .As has been shown in several references ( for example , Duda et al . , 2001 ) , this seemingly intractable problem has a very straightforward solution , provided X is zero mean and multivariate Gaussian .The rows of transformation A T have been shown to be the eigenvectors of the covariance matrix of X , corresponding to the m largest eigenvalues of this matrix .", "label": "", "metadata": {}}
{"text": "Thus the \" forward \" and \" reverse \" transformations are transposes of each other .The components of Y are uncorrelated .Furthermore the expected value of this normalized mean square error between original and re - estimated X vectors can be shown to equal the ratio of the sum of \" unused \" eignevalues to the sum of all eigenvalues .The columns of A are called the principal components basis vectors and the components of Y are called the principal components .If the underlying assumption of zero mean multivariate Gaussian random variables is satisfied , then this method of feature reduction generally performs very well .", "label": "", "metadata": {}}
{"text": "The principal components \" account for \" or explain the maximum amount of variance of the original data .Figure 1 shows an example of scatter plot of 2-D multivariate data and the resulting orientation of the first primary principal components basis vector .As expected this basis vector , represented by a straight line , is oriented along the axis with maximum data variation .Figure 1 .Scatter plot of 2-D multivariate Gaussian data and first principal components basis vector .Line is a good fit to data .Figure 2 depicts data which is primarily aligned with a U shaped curve in a 2-D space , and the resulting straight line ( PCA ) basis vector fit to this data .", "label": "", "metadata": {}}
{"text": "In fact , since the data primarily follows a curved path in the 2-D space , no linear transform method , resulting in a straight line subspace , will be a good way to approximate the data with one dimension .Figure 2 .Scatter plot of 2-D multivariate Gaussian data and first principal components basis vector .No straight line can be a good fit to this data .Linear Discriminant Analysis ( LDA ) .Linear transforms for the purpose of reducing dimensionality while preserving discriminability between pre - defined categories have also long been known about and used ( Wang & Paliwal , 2003 ) , and are usually referred to as Linear Discriminant Analysis ( LDA ) .", "label": "", "metadata": {}}
{"text": "That is .Y .A .T .X , where X , Y are again column vectors as for PCA .The big difference is in how A is computed .For LDA , it has been shown that the columns of A correspond to the m largest eigenvalues of .S .W .S .B , where S W is the within class covariance matrix and S B is the between class covariance matrix .Often S B is computed as the covariance of the category means ; alternatively , it is sometimes computed as the \" grand \" covariance matrix over all data , ignoring category labels , identical to the covariance matrix used to compute PCA basis vectors .", "label": "", "metadata": {}}
{"text": "The explicit assumption for LDA is that the within class covariance of each category is the same , which is rarely true in practice .Nevertheless , for many practical classification problems , features reduced by LDA often are as effective or even advantageous to original higher dimensional features .Figure 3 depicts 2-D 2-class data , and shows the first PCA basis vector as well as the first LDA basis vector .Clearly , for this example , the two basis vectors are quite different , and clearly the projection of data onto the first LDA basis vector would be more effective for separating the two categories than data projected onto the first PCA basis vector .", "label": "", "metadata": {}}
{"text": "The classes would be well separated by a projection onto the first LDA basis vector , but poorly separated by a projection onto the first PCA basis vector .Heteroscedastic Discriminant Analysis ( HDA ) .Another linear transformation technique , related to linear discriminant analysis , but which accounts for the ( very common ) case where within class covariance matrices are not the same for all classes , is called Heterocscedastic Discriminant Analysis ( HDA ) ( Saon et al . , 2000 ) .The process for HDA is described in some detail by Saon et al . , and illustrated in terms of its ability to better separate ( as compared to LDA ) data in reduced dimensionality subspaces , when the covariance properties of the individual classes are different .", "label": "", "metadata": {}}
{"text": "There is no known closed form solution for minimizing the objective function required to solve for the transformation - rather a complex numerically based gradient search is required .More fundamentally , with actual speech data , HDA alone was found to perform far worse than LDA .Nevertheless , if an additional transform , called the Maximum Likelihood Linear Transform ( MLLT ) ( Gopinath , 1998 ) was used after HDA , then overall performance was found to be the best among the methods tested by Saon et al .However , ASR accuracies obtained with a combination of LDA and MLLT were nearly as good as those obtained with HDA and MLLT .", "label": "", "metadata": {}}
{"text": "Nonlinear dimensionality reduction .If the data are primarily clustered on curved subspaces embedded in high dimensionality feature spaces , linear transformations for feature dimensionality reduction are not well suited .For example , the data depicted in Figure 2 would be better approximated by its position with respect to a curved U - shape line rather the straight line obtained with linear PCA .( Bishop et al .1998 ) discusses several theoretical methods for determining these curved subspaces ( manifolds ) within higher dimensionality spaces .Another general method , and the one illustrated and explored in more detail in this chapter , is based on a \" bottleneck \" neural network ( Kramer , 1991 ) .", "label": "", "metadata": {}}
{"text": "The general network configuration is shown in Figure 4 .Figure 4 .Architecture of Bottleneck Neural Network .If data lies along a single curved line in a higher dimensionality space , 1 node in the bottleneck layer should be sufficient .If data lies on a curved surface embedded in a higher dimensionality space , 2 nodes in the bottleneck layer should be sufficient .Nonlinear Principal Components Analysis ( NLPCA ) .Since the final NN outputs are created from the internal NN representations at the bottleneck layer , the bottleneck outputs can be viewed as the reduced dimensionality version of the data .", "label": "", "metadata": {}}
{"text": "NLPCA is first illustrated by an example depicted in Figure 5 .For this case , 2-D pseudo random data was created to lie along a U shaped curve , similar to the data depicted in Figure 2 .A neural network ( 2 - 5 - 1 - 5 - 2 ) was then trained as an identify map .The numbers in parentheses refer to the number of nodes at each layer , proceeding from input to output .All hidden nodes and output nodes had a bipolar sigmoidal activation function .After training with backpropagation , all data were transformed by the neural network .", "label": "", "metadata": {}}
{"text": "Clearly , the data have been projected to a curved U shaped line , as would be expected for the best line fit to the original data .Figure 5 .Plot of input and output data for pseudo - random 2-D data .The output data ( red line ) is reconstructed data obtained after passing the input data through the trained neural network .In Figure 6 , NLPCA is illustrated by data which falls on a 2-D surface embedded in a 3-D space .For this case , 2-D data pseudo random data are created , but confined to lie on the surface of a 2-D Gaussian shaped surface , as depicted in the left panel of Figure 6 .", "label": "", "metadata": {}}
{"text": "After training , the outputs of the neural network are plotted in the right panel of Figure 6 .Clearly the neural network \" learned \" a 2-D internal representation , at the bottleneck layer , from which it could reconstruct the original data .Figure 6 .Input and output plot of the 3-D Gaussian before ( left ) and after ( right ) using neural network for NLPCA .Nonlinear Discriminant Analysis ( NLDA ) .Fortunately , only a minor modification to NLPCA is needed to form NLDA .The same bottleneck network architecture is used , but trained to recognize categories rather than as an identity map .", "label": "", "metadata": {}}
{"text": "Nonlinear dimensionality reduction architecture .In a previous work ( Zahorian et al . , 2007 ) , NLPCA was applied to an isolated vowel classification task , and the nonlinear method based on neural networks was experimentally compared with linear methods for reducing the dimensionality of speech features .A summary of this work is presented in Section 4.5 .In contrast , the nonlinear technique NLDA based on minimizing classification error was quite effective for improving accuracy .The general form of the NLDA transformer and its relationship to the HMM recognizer are depicted in Figure 7 .", "label": "", "metadata": {}}
{"text": "The outputs of the network are further ( optionally ) processed by PCA to create transformed features to be the inputs of an HMM recognizer .Note that in this usage , \" outputs \" may be from the final outputs or from one of the internal hidden layers .Figure 7 .Overview of the NLDA transformation for speech recognition .The multilayer bottleneck neural network employed in NLDA contains an input layer , hidden layers including the bottleneck layer , and an output layer .The numbers of nodes in the input and output layers respectively correspond to the dimensions of the input features and the number of categories in the training target data .", "label": "", "metadata": {}}
{"text": "The number of hidden layers was experimentally determined as well as the number of nodes included in those layers .However , most typically three hidden layers were used .Two NLDA approaches were investigated as different layers of networks are used to obtain dimensionality reduced data .NLDA1 .In the first approach , which is referred to as NLDA1 , the transformed features are produced from the final output layer of the network .This approach is similar to the use of tandem neural networks used in some automatic speech recognition studies ( Hermansky & Sharma , 2000 ; Ellis et al . , 2001 ) .", "label": "", "metadata": {}}
{"text": "Figure 8 .Use of network outputs in NLDA1 . NLDA2 .Figure 9 illustrates the use of network outputs in NLDA2 .These two versions of NLDA were experimentally tested , with and without PCA following the neural network transformer , with some variations of the nonlinearities in the networks .The dimensionality of the reduced feature space is determined only by the number of nodes in the middle layer .Therefore , an arbitrary number of reduced dimensions can be obtained , independent of the input feature dimensions and the nature of the training targets .A lower dimensional representation of the input features is easily obtained by simply deploying fewer nodes in the middle layer than the input layer .", "label": "", "metadata": {}}
{"text": "In contrast with NLDA1 where dimensionality reduction is assigned to PCA , for NLDA2 , since the dimensionality reduction can be accomplished with the neural network only , the linear PCA is used specifically for reducing the feature correlation .Figure 9 .Middle layer outputs used as dimensionality reduced features in NLDA2 .Neural networks .In optimizing the design of a neural network , an important consideration is the number of hidden layers and an appropriate number of hidden nodes in each layer .A neural network with no hidden layers can form only simple decision regions , which is not suitable for highly nonlinear and complex speech features .", "label": "", "metadata": {}}
{"text": "However , the recognition accuracy is often degraded .The more hidden nodes a network has , the more complex a decision surface can be formed , and thus better classification accuracy can be expected ( Meng , 2006 ) .Generally , the number of hidden nodes is empirically determined by a combination of accuracy and computational considerations , as applied to a particular application .Another important consideration is selecting an activation function , or the nonlinearity of a node .Typical choices include a linear activation function , a unipolar sigmoid function and a bipolar sigmoid function as illustrated in Figure 10 .", "label": "", "metadata": {}}
{"text": "For example , with training targets assigned the values of \" 0 \" and \" 1 \" , a sigmoid function with the outputs in the range of [ 0 , 1 ] is a good candidate for the output layer .Most typically a mean square error , between the desired output and actual output of the NN , is the objective function that is minimized in NN training .As another powerful approach , the softmax function takes all the nodes in a layer into account and calculates the output of a node as a posterior probability .", "label": "", "metadata": {}}
{"text": "Moreover , equipped with various nonlinearities , the neural network is expected to have a stronger discriminative capability and thus it is enabled to cope with more complex data .Figure 10 .Illustrations of a linear activation function ( left ) , a unipolar sigmoid function ( middle ) and a bipolar sigmoid function ( right ) .The weights of the neural network are estimated using the backpropagation algorithm to minimize the distance between the scaled input features and target data .The update of the weights in each layer depends on the activation function of that layer , thus the network learning can be designed to perform different updates when dissimilar activation functions are used .", "label": "", "metadata": {}}
{"text": "In order to avoid this , the input data of neural networks is often scaled so that all feature components have the same mean ( zero ) and variance ( so that range of values is approximately \u00b1 1 ) .Investigation of basic issues .Note that unlike phonetic recognition experiments , for the case of classification , the timing labels in the database are explicitly used for both training and testing .Thus classification is \" easier \" than recognition , and accuracies typically higher , since phone boundaries are known in advance and used .In this first series of experiments , classification experiments were conducted using PCA , LDA , NLPCA , and NLDA2 transformations , as well as the original features .", "label": "", "metadata": {}}
{"text": "All the test sentences ( 1680 sentences ) were used to extract a total of 11,625 vowel tokens for testing .For each vowel token , 39 DCTC - DCS features were computed using 13 DCTC terms and 3 DCS terms .For all cases , including original features , and all versions of the transformed features , a neural network classifier with 100 hidden nodes and 10 output nodes , trained with backpropagation , was used as the classifier .In addition , a Bayesian maximum likelihood Mahalanobis distance based Gaussian assumption classifier ( MXL ) was used for evaluation .", "label": "", "metadata": {}}
{"text": "The number of hidden nodes in the second hidden layer was varied from 1 to 39 , according to the dimensionality being evaluated .For the case of NLDA2 , the network used for dimensionality reduction was also a classifier .For the sake of consistency , the outputs of the hidden nodes from the bottleneck neural network were used as features for a classifier , using either another neural network or the MXL classifier .[ 1 ] - In these initial experiments , the bottleneck neural network outputs were not additionally transformed with PCA .Experiment 1 .", "label": "", "metadata": {}}
{"text": "Figure 11 shows the results based on the neural network and MXL classifiers for each transformation method in terms of classification accuracy , as the number of features varies from 1 to 39 .For both the neural network and MXL classifiers , highest accuracy was obtained with NLDA2 , especially with a small numbers of features .For the MXL classifier , NLDA2 features result in approximately 10 % higher classification accuracies as compared to all other features .For both the neural network and MXL classifiers , accuracy with NLPCA features was very similar to that obtained with linear PCA .", "label": "", "metadata": {}}
{"text": "However , with a neural network classifier and much higher dimensionality features , all feature sets perform similarly in terms of classification accuracy .As just illustrated , dimensionality reduction is not necessarily advantageous in terms of accuracy for classifiers trained with enough data and the \" right \" classifier .However , for the case of complex automatic speech recognition systems , there is generally not enough training data .Experiment 2 .To simulate lack of training data , another experiment was conducted .In this experiment , the training data was separated into two groups , with about 50 % in each group .", "label": "", "metadata": {}}
{"text": "Figure 11 .Classification accuracies of neural network ( top panel ) and MXL ( bottom panel ) classifiers with various types of features .The results obtained with the neural network and MXL classifiers using 10 % of the group 2 training data ( that is , 5 % of the overall training data ) are shown in Figure 12 .The numbers of features evaluated are 1 , 2 4 , 8 , 16 and 32 .For both the neural network and MXL classifiers , NLDA2 clearly performs much better than the other transformations or the original features .", "label": "", "metadata": {}}
{"text": "Category labels for discriminatively based transformations .For all discriminatively based transformations , either linear or nonlinear , an implicit assumption is that training data exists which has been labeled according to category .For the case of classification , such as the experiments just described , this labeled data is needed anyway , for both training and test data , to conduct classification experiments ; thus the need for category labeled data is not any extra burden .However , for other cases , such as the phonetic recognition experiments described in the remainder of this chapter , there may or may not be easily available and suitable labeled training data .", "label": "", "metadata": {}}
{"text": "Figure 12 .Classification accuracies of neural network ( top panel ) and MXL ( bottom panel ) classifiers using 10 % of group 2 training data for training classifier .Phonetic - level targets .The training of the neural network ( NLDA1 and NLDA2 ) requires category information for creating training targets .For the case of databases such as TIMIT , the data is labeled using 61 phone categories , and the starting point for training discriminative transformations would seem to be these phonetic labels .In the neural network training , these are referred to as targets .", "label": "", "metadata": {}}
{"text": "The targets can also be viewed as multidimensional vectors , with a value of \" 1 \" for the target category and \" 0s \" for the non - target categories .Figure 13 illustrates a sequence of phoneme training targets for the TIMIT database using 48 phoneme categories .These vectors have 48 dimensions and each vector consists of only one peak value to indicate the category .Note that , in the TIMIT case , other reasonable choices for targets would be 61 ( the number of phone label categories ) , or 39 ( the number of collapses phone categories ) .", "label": "", "metadata": {}}
{"text": "Figure 13 .Training target vectors of the neural network .State - level targets .Due to the nonstationarity of speech signals , a speech signal varies even in a very short time interval ( e.g. a phoneme ) .For speech recognition tasks , instead of phone level training targets , state ( as in hidden states of an HMM ) dependent targets could be advantageous in training a versatile network for more highly discriminative speech features .However , the boundaries between states in a phoneme are likely to be indistinct ; even more importantly , from a practical perspective is that , unlike phonemes , the ( HMM ) state boundaries are unknown in advance of training .", "label": "", "metadata": {}}
{"text": "This boundary information may be in error due to the nature of unclear state boundaries and the lack of a reliable estimation approach .Therefore , in the discriminative training process , \" do n't cares \" were used to account for this lack of precision in determining state boundaries .In the neural network training process , the errors of output nodes corresponding to \" do n't cares \" are not computed and thus these \" do n't cares \" have no effect on weight updates .The state training targets with \" do n't cares \" uses \" do n't care \" states for each phoneme model , so that one neural network trained with the targets can generate state dependent outputs .", "label": "", "metadata": {}}
{"text": "As time progresses during a phone , the \" 1 \" moves from state 1 to state 2 , to state 3 .Figure 14 .Figure 15 .Illustration of the state level training targets with \" do n't cares . \"The -1 values are used to denote \" do n't cares . \"Two approaches are used to determine state boundaries .The second approach determines state boundaries using the HMM - based Viterbi alignment based on already trained HMMs .As illustrated in one of the experiments presented later , the state dependent targets were shown to perform better than phone level targets .", "label": "", "metadata": {}}
{"text": "Evaluation of feature reduction methods with phonetic recognition experiments .Given the high dimensionality of speech feature spaces used for automatic speech recognition , typically 39 or more , it is not feasible to visualize the distribution of data in feature space .It is possible that a reduced dimensionality subspace obtained by linear methods , such as PCA or LDA , forms an effective , or at least adequate subspace for implementing automatic speech recognition systems with a reduced dimensionality feature space .Note that if PCA or LDA do perform well , these methods would be preferred to the nonlinear methods , due to the much simpler implementation methods and the corresponding need for less data .", "label": "", "metadata": {}}
{"text": "The comparisons of these various methods can only be done experimentally .TIMIT database .The database used for all experiments reported in the remainder of this chapter is TIMIT .The TIMIT database was developed in the early 1980 's for expediting acoustic - phonetic ASR research ( Garofolo et al . , 1993 ; Zue et al , 1990 ) .It consists of recordings of 10 sentences from each of 630 speakers , or 6300 sentences total .Of the text material in the database , two dialect sentences ( SA sentences ) were designed to expose the specific variants of the speakers and were read by all 630 speakers .", "label": "", "metadata": {}}
{"text": "Each speaker read 5 of these sentences and each text was spoken by 7 different speakers .A total of 1890 phonetically - diverse sentences ( SI sentences ) were selected from existing text sources to add diversity in sentence types and phonetic contexts .Each speaker read 3 of these sentences , with each text being read only by a single speaker .All sentences are phonetically labeled with start and stop times for each phoneme .The database is further divided into a suggested training set ( 4620 sentences , 462 speakers ) and suggested test set ( 1680 sentences , 168 speakers ) .", "label": "", "metadata": {}}
{"text": "Similarly , most researchers have not used the SA sentences for ASR experiments , since the identical phonetic contexts ( every speaker read the same sentences for the SA sentences ) , were thought be non representative of everyday speech .[ 2 ] - Most , but not all researchers , have used the recommended training and test sets .For all ASR experiments reported in this chapter , the SA sentences were removed , the recommended training and test sets were used , and the phone set was collapsed to the same 39 phones used in most ASR experiments with TIMIT .", "label": "", "metadata": {}}
{"text": "Thus NTIMIT is more bandlimited ( approximately 300Hz to 3400 Hz ) , more noisy , but has the identical \" raw \" speech .DCTC / DCSC speech features .The modified DCTC is used for representing speech spectra , and the modified DCSC is used to represent spectral trajectories .Each DCTC is represented by a DCSC expansion over time ; thus the total number of features equals the number of DCTC terms times the number of DCSC terms .The number of DCTCs used was 13 , and number of DCS terms was varied from 4 to 7 , for a total number of features ranging from 52 to 91 .", "label": "", "metadata": {}}
{"text": "Additionally , as a control , one experiment was conducted with Mel - frequency Cepstral Coefficients ( MFCCs ) ( Davis & Mermelstein , 1980 ) , since these MFCC features are most typically used in ASR experiments .A total of 39 features including 13 MFCC features , delta terms , and delta - delta terms were extracted from both the training and test data .Hidden Markov Models ( HMMs ) .Left - to - right Markov models with no skip were used and a total of 48 monophone HMMs were created from the training data using the HTK toolbox ( Verion 3.4 ) ( Young et al . , 2006 ) .", "label": "", "metadata": {}}
{"text": "Various numbers of states and mixtures were evaluated as described in the following experiments .In all cases diagonal covariance matrices were used .For final evaluations of accuracy , some of these 48 monophones were combined to create the \" standard \" set of 39 phone categories .Experiment with various reduced dimensions .The first experiment was conducted to evaluate the two NLDA versions with various dimensions in the reduced feature space with and without the use of PCA .As input features , 13 DCTCs , computed with 8 ms frames and 2 ms spacing , were represented with 6 DCSCs over a 500 ms block , for a total of 78 features ( 13 DCTCs x 6 DCSCs ) .", "label": "", "metadata": {}}
{"text": "The features which were dimensionality reduced by PCA and LDA alone were also evaluated for the purpose of comparison .Figure 16 shows recognition accuracies of dimensionality reduced features using 1-state and 3-state HMMs with 3 mixtures per state .Note that the NLDA1 features without the PCA process are always 48 dimensions .Compared to the PCA and LDA reduced features , the NLDA1 and NLDA2 features performed considerably better for both the 1-state and 3-state HMMs .For the case of 3-state HMMs , the transformed features reduced to 24 dimensions resulted in the highest accuracy of 69.3 % for NLDA1 .", "label": "", "metadata": {}}
{"text": "The recognition accuracies were further improved by about 3 % with PCA reduced dimensionality features versus the NLDA features for most cases , showing the effectiveness of PCA in de - correlating the network outputs .The accuracies obtained with the original 78 features , and 3 mixture HMMs , are approximately 58 % ( 1 state models ) and 63 % ( 3 state models ) .NLDA1 and NLDA2 experiment with various HMM configurations .The aim of the second experiment is a more thorough evaluation of NLDA1 and NLDA2 using a varying number of states and mixtures in HMMs .", "label": "", "metadata": {}}
{"text": "The 48 phoneme level targets were used in the training of the network .The features which are the direct outputs of the network without PCA processing were also evaluated .Figure 17 shows accuracies using 1-state and 3-state HMMs with a varying number of mixtures per state .NLDA2 performed better than NLDA1 for all conditions -- approximately 2 % higher accuracy .The NLDA2 transformed features resulted in the highest accuracy of 73.4 % with 64 mixtures , which is about 1.5 % higher than the original features for the same condition .The use of PCA improves accuracy on the order of 2 % to 10 % , depending on the conditions .", "label": "", "metadata": {}}
{"text": "The superiority of the NLDA transformed features is more significant when a small number of mixtures are used .For example , the NLDA2 features modeled by 3-state HMMs with 3 mixtures resulted in an accuracy of 69.4 % versus 63.2 % for the original features .Figure 16 .Figure 17 .Accuracies of the NLDA1 and NLDA2 features using 1-state ( top panel ) and 3-state HMMs ( bottom panel ) with various numbers of mixtures .These results imply that the middle layer outputs of a neural network are able to better represent original features in a dimensionality - reduced space than are the outputs of the final output layer .", "label": "", "metadata": {}}
{"text": "Experiments with large network training .The results of the previous experiment showed large performance advantages for NLDA2 over NLDA1 and the original features , when using either a small number of features , or a \" small \" HMM .However , if all original features were used , and a 3- state HMM with a large number of mixtures were used , there was very little advantage of NLDA2 , in terms of phonetic recognition accuracy .Therefore , an additional experiment was performed , using the state level targets with \" do n't cares , \" as mentioned previously , and a very large neural network for transforming features .", "label": "", "metadata": {}}
{"text": "The expanded neural networks had 144 output nodes and were iteratively trained .For both NLDA1 and NLDA2 , the networks were configured with 78 - 500 - 36 - 500 - 144 nodes , going from input to output .Figure 18 .Recognition accuracies of the NLDA dimensionality reduced features using the state level targets . \"( CR ) \" and \" ( FA ) \" indicate the training targets obtained with the constant length ratio and forced alignment respectively .As shown in Figure 18 , both NLDA1 and NLDA2 using the expanded targets lead to a significant increase in accuracy .", "label": "", "metadata": {}}
{"text": "The use of forced alignment for state boundaries resulted in the highest accuracy of 75.0 % with 64 mixtures .However , the best result using the much simpler constant ratio method is only marginally lower at 74.9 % .Similar experiments , with all identical conditions except using either phone level targets , or state level targets without \" do n't cares \" resulted in about 2 % lower accuracies .These results imply that the use of \" do n't cares \" is able to reduce errors introduced by inaccurate determination of state boundaries .Comparing these results with those from Figure 17 , the NLDA2 features in a reduced 36-dimensional space achieved a substantial improvement versus the original features , especially when a small number of mixtures were used .", "label": "", "metadata": {}}
{"text": "MFCC experiments .For comparison , 39-dimensional MFCC features ( 12 coefficients plus energy with the delta and acceleration terms ) were reduced to 36 dimensions with the same configurations and evaluated .The results followed the same trend , but the accuracies were about 4 % lower than those of the DCTC - DCSC features for all cases , for example , 70.7 % with NLDA2 using forced alignment and 32 mixtures .Conclusions .Nonlinear dimensionality reduction methods , based on the general nonlinear mapping abilities of neural networks , can be useful for capturing most of the information from high dimensional spectral / temporal features , using a much smaller number of features .", "label": "", "metadata": {}}
{"text": "The neural network features also should be linearly transformed with a principal components transform in order to be effective for use by a Hidden Markov Model .For use with a multi - hidden - state Hidden Markov Model , the nonlinear transform should be trained with state - specific targets , but using \" do n't cares , \" to account for imprecise information about state boundaries .In future work , linear transforms other than principal components analysis , such as heteroscedastic linear transforms followed by maximum likelihood linear transforms , should be explored for post processing of the nonlinear transforms .", "label": "", "metadata": {}}
{"text": "References . 2 - S. B. Davis , P. Mermelstein , 1980 Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences , IEEE Trans . on Acoustics , Speech and Signal Processing , 28 357 366 .TIMIT Acoustic - Phonetic Continuous Speech Corpus .21 - S. A. Zahorian , D. Qian , A. J. Jagharghi , 1991 Acoustic - phonetic transformations for improved speaker - independent isolated word recognition .Proc .ICASSP'91 , 561 564 .Toronto , Ontario , Canada , May 14 - 17 , 1991 .22 - S. Zahorian , P. Silsbee , X. Wang , 1997 Phone Classification with Segmental Features and a Binary - Pair Partitioned Neural Network Classifier .", "label": "", "metadata": {}}
{"text": "ICASSP ' 97 , 1011 1014 , Munich , Germany , April 21 - 24 , 1997 .23 - S. A. Zahorian , A. M. Zimmer , F. Meng , 2002 Vowel Classification for Computer - based Visual Feedback for Speech Training for the Hearing Impaired , Proc .ICSLP 2002 , 973 976 , Denver , CO , Sept. 16 - 20 , 2002 .24 - S. A. Zahorian , T. Singh , H. Hu , 2007 Dimensionality Reduction of Speech Features using Nonlinear Principal Components Analysis .Proc .INTERSPEECH ' 07 , 1134 1137 , Antwerb , Belgium , Aug. 27 - 31 , 2007 .", "label": "", "metadata": {}}
{"text": "A Tutorial , Institute for Signal and Information Processing , Department of Electrical and Computer Engineering , Mississippi State University .Secure Telemedicine : Biometrics for Remote and Continuous Patient Verification .Received 3 February 2012 ; Accepted 23 October 2012 .Academic Editor : Tin - Yu Wu .Copyright \u00a9 2012 Foteini Agrafioti et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .Abstract .The technological advancements in the field of remote sensing have resulted in substantial growth of the telemedicine industry .", "label": "", "metadata": {}}
{"text": "The sensing apparatus , that a patient may employ at home , collects and transmits vital signals to medical centres which respond with treatment decisions despite the lack of solid authentication of the transmitter 's identity .In essence , remote monitoring increases the risks of identity fraud in health care .This paper proposes a biometric identification solution suitable for continuous monitoring environments .The system uses the electrocardiogram ( ECG ) signal in order to extract unique characteristics which allow to discriminate users .In security , ECG falls under the category of medical biometrics , a relatively young but promising field of biometric security solutions .", "label": "", "metadata": {}}
{"text": "The effects of psychological changes on the ECG waveform are taken into consideration for the design of a robust biometric system that can identify users based on cardiac signals despite physical or emotional variations .Introduction .For a number of severe diseases such as diabetes , hypertension , or respiratory disorders , where hospitalization might not always be justified or needed , home care is traditionally preferred .Moreover , the visit of a medical practitioner to the patient 's home is not necessarily an efficient solution either .Home telemonitoring is now a reality , addressing the above problem very effectively , that is , it is not only cost - efficient but can also reach isolated communities and allow for 24 hr reporting on the patient 's status .", "label": "", "metadata": {}}
{"text": "Due to the lack of physical presence at the time of collection of the medical information ( e.g. , vital signals ) , the identity of the user that transmits the respective information is uncertain .Typically , every monitoring device is assigned with a unique ID ( e.g. , a serial code ) in order to identify the transmitter .However , this only partially solves the problem since such a strategy identifies the device but not the person that utilizes it .What is needed is a means for authentication that is directly linked to the user and which can identify that person continuously .", "label": "", "metadata": {}}
{"text": "Neither of these two approaches can solve efficiently the problem of remote authentication , since they can not be performed in a continuous manner .It is not practical to ask a user to be password authenticated during monitoring sessions .Furthermore , the above entities can be easily stolen or forgotten .Biometric security was introduced as an alternative to this problem .Linking identities with bodily characteristics that can not be forgotten or easily stolen provides airtight security .In this work , the ECG signal is proposed for identity authentication in remote monitoring settings .The rationale behind this choice is that this signal is very likely to be collected routinely in such environments as it is typically used for medical diagnosis of several cardiac and noncardiac conditions .", "label": "", "metadata": {}}
{"text": "From a security point of view , ECG falls under the category of medical biometrics , that is , physiological characteristics that are typically used within health care environments for clinical diagnoses .However , there is evidence that some of these vital signals such as the ECG , phonocardiogram ( PCG ) , photoplethysmogram ( PPG ) , and blood volume pressure ( BVP ) carry information which is unique for every individual [ 1 - 5 ] .With the advances in the sensing technology , the potential of using these signals for biometric recognition is great .", "label": "", "metadata": {}}
{"text": "The ECG biometric provides inherent liveness detection which has computational advantages , since most of the existing modalities would require additional mechanisms to validate the liveness of the sensor 's reading .In addition , ECG is naturally immune to falsification or replay attacks , as it is extremely difficult to steal and inject someone 's ECG into a biometric system .Heart signals are universal , stable over a large period of time , and sufficiently unique .The intersubject variability comes from the fact that ECG pictures the electrophysiological variations of the myocardium and is affected by factors such as the heart mass orientation , conductivity of cardiac muscles and activation order [ 6 , 7 ] .", "label": "", "metadata": {}}
{"text": "Factors that affect the ECG waveform can be classified as physiological or psychological .While a heart rate increase due to exercise decreases the ECG \" period \" ( in reality this signal is quasiperiodic ) , emotions may also change the ECG waveform .While the interaction between physiological and psychological factors on the ECG signal is obscure , there is evidence that emotional activity directly impacts the ECG waveform [ 9 - 11 ] .This aspect of the ECG is very important when deploying it for biometric recognition , because it can significantly affect the overall accuracy .", "label": "", "metadata": {}}
{"text": "The objective of this work is to first demonstrate that changes in the psychological status of a subject can potentially affect the ECG biometric template and second to provide a solution to this problem for welfare monitoring applications .While emotional activity can compromise the stability and robustness of a biometric template , prior works have concentrated on the effects of just physical activity .In this work , a template updating methodology is proposed to automatically adjust to the psychological status of a user in order to treat false rejections .The Electrocardiogram ( ECG ) .The ECG is one of the most widely used signals in health care .", "label": "", "metadata": {}}
{"text": "In essence , this signal describes the electrical activity of the heart over time and pictures the sequential depolarization and repolarization of the different muscles that form the myocardium . wave describes the depolarization of the right and left atria .The amplitude of this wave is relatively small , because the atrial muscle mass is limited .The QRS complex is the largest of three since it represents the depolarization of the right and left ventricles , which are the chambers with the most substantial mass in the heart .Finally , the . wave may vary .Although it is usually observed about 300 ms after the QRS complex , it may appear closer to the QRS complex at rapid rates and further away at slow rates [ 12 ] .", "label": "", "metadata": {}}
{"text": "While the effects of physical activity on the ECG signal are well established , the reactivity to psychological changes is more obscure .The autonomic nervous system ( ANS ) has nerve endings within the cardiac muscle which play a major role in the cardiac output because they affect the rhythm at which the muscle pumps blood .The fibers of the sympathetic system run along the atria and the ventricles and when activated stimulate the cardiac muscle to increase the heart rate .On the other hand , the parasympathetic system reduces the cardiac workload .In the presence of a mental stressor specifically , the sympathetic system dominates the parasympathetic , resulting in the following reactivity effects [ 13 ] .", "label": "", "metadata": {}}
{"text": "( 2 ) Contractility : during every contraction the fibers of the heart shorten more , compared to the case during homeostasis , thereby increasing the force of contraction .( 3 ) Conduction rate : the natural pacemaker , the SA node , is forced to conduct faster .( 4 ) Excitability : during sympathetic stimulation , the person has increased perceptiveness to internal and external stimuli , which increases the irritability of the cardiac muscle and possibly lead to ectopic beats .( 5 ) Dilation of coronary blood vessels : the diameter of the coronary blood vessels increases , followed by increased blood flow to the cardiac muscle .", "label": "", "metadata": {}}
{"text": "This work demonstrates that the effects of psychological activity on the ECG waveform are significant enough to endanger biometric accuracy .ECG in Biometric Recognition .Prior works in the ECG biometric recognition field can be categorized as either fiducial points dependent or independent .Fiducials are specific points of interest on an ECG heart beat such as the onset and the offset of the heart beat waves .Fiducial - based approaches rely on local features of the heart beats for biometric template design , such as the temporal or amplitude difference between consecutive fiducial points .On the other hand , fiducial points independent approaches treat the ECG signal or isolated heart beats holistically and extract features statistically based on the overall morphology of the waveform .", "label": "", "metadata": {}}
{"text": "While fiducial - oriented features risk to miss identifying information hidden behind the overall morphology of the biometric modality , holistic approaches deal with a large amount of redundant information that needs to be eliminated .The challenge in the latter case is to remove this information in a way that the intrasubject variability is minimized and the intersubject is maximized .For the ECG case , detecting fiducial points is a very obscure process due to the high variability of the signal .In fact , there is no universally acknowledged rule that can guide this detection [ 7 ] .", "label": "", "metadata": {}}
{"text": "Among the earliest works in the area is Biel et al . 's [ 14 ] proposal , in 2001 , for a fiducial feature extraction algorithm , which demonstrated the feasibility of using ECG signals for human identification .The standard 12 lead system was used to record signals from 20 subjects of various ages .Kyoso and Uchiyama [ 15 ] proposed four fiducial - based features for ECG biometric recognition , that is , the . wave duration , PQ interval , QRS complex , and QT durations and achieved 94.2 % biometric accuracy .In 2002 , Shen et al .", "label": "", "metadata": {}}
{"text": "16 ] reported an ECG - based recognition method with seven fiducial - based features that relate to the QRS complex .The underlying idea was that this wave is less affected by varying heart rates and thus is appropriate for biometric recognition .More complete biometric recognition tests were reported in 2004 , by Israel et al .[ 1 ] .This work presented the three clear stages of ECG biometric recognition , that is , preprocessing , feature extraction and classification .In addition , a variety of experimental settings are described in [ 1 ] such as examination of variations due to electrode placement and physical stress .", "label": "", "metadata": {}}
{"text": "An identification rate of 97.6 % was achieved over recordings of 10 individuals .Kim et al .[ 18 ] proposed a method to normalize time domain features by upsampling the heart beats .In a similar manner , Saechia et al . , [ 19 ] normalized to healthy durations and then divided into three subsequences : . wave .The Fourier transform was applied on a heart beat itself and all three subsequences .Zhang and Wei [ 20 ] suggested 14 commonly used features from ECG heart beats on which a PCA was applied to reduce dimensionality .", "label": "", "metadata": {}}
{"text": "Singh and Gupta [ 21 ] proposed a way to delineate the . waveforms for accurate feature extraction .Ting and Salleh [ 23 ] described in 2010 a nonlinear dynamical model to represent the ECG in a state space form with the posterior states inferred by an extended Kalman filter .Another fiducial - based method was proposed by Tawfik et al .[ 24 ] .In this work , the ECG segment between the QRS complex and the . wave was first extracted and normalized in the time domain by using Framingham correction formula or by assuming constant QT interval .", "label": "", "metadata": {}}
{"text": "In summary , although a number of fiducial - based approaches have been reported for ECG - based biometrics , accurate localization of fiducial points remains a big challenge .This ambiguity risks the accuracy of the respective recognizers which require the precise location of such points .In the likely event of failing to adequately determine the locations of these points , fiducial approaches would rather reject the heart beat and require an extra reading , rather than risking the accuracy of their decision .This , however , results in increased rejection rates .Fiducial - Independent Approaches .", "label": "", "metadata": {}}
{"text": "Among the earliest is Plataniotis et al . 's [ 25 ] proposal for an autocorrelation-( AC- ) based feature extractor .With the objective of capturing the repetitive pattern of ECG , the authors suggested the AC of an ECG segment as a way to avoid fiducial points detection .W\u00fcbbeler et al .[ 4 ] have also reported an ECG - based human recognizer by extracting biometric features from a combination of leads I , II , and III , that is , a two - dimensional heart vector also known as the characteristic of the ECG .", "label": "", "metadata": {}}
{"text": "[26 ] .A heart beat was normalized and compared with its estimate , which was previously constructed from itself and the templates from a claimed identity .Chan et al .[ 27 ] reported ECG signal collection from the fingers by asking the participants to hold two electrode pads with their thumb and index finger .The wavelet distance was used as the similarity measure with a classification accuracy of 89.1 % , which outperformed other methods such as the percent residual distance and the correlation coefficient .Chiu et al .[28 ] proposed the use of DWT on heuristically isolated pulses .", "label": "", "metadata": {}}
{"text": "The DWT was used for feature extraction and the Euclidean distance as the similarity measure .Fatemian and Hatzinakos [ 29 ] also suggested the wavelet transform to denoise and delineate the ECG signals , followed by a process wherein every heart beat was resampled , normalized , aligned , and averaged to create one strong template per subject .A correlation analysis was directly applied to test heart beats and the template since the gallery size was greatly reduced .The spectrogram was employed in [ 30 ] to transform the ECG into a set of time - frequency bins which were modeled by independent normal distributions .", "label": "", "metadata": {}}
{"text": "Ye et al .[5 ] applied the discrete wavelet transform ( DWT ) and independent component analysis ( ICA ) on ECG heart beat segments to obtain 118 and 18 features , respectively .The feature vectors were concatenated .The dimensionality of the feature space was subsequently reduced from 136 to 26 using PCA which retained 99 % of the data 's variance .Coutinho et al .[ 31 ] isolated the heart beats and performed an 8-bit uniform quantization to map the ECG samples to strings from a 256-symbol alphabet .", "label": "", "metadata": {}}
{"text": "It is clear from the above that a large variety of fiducial - independent techniques have been proposed for ECG biometric analysis .While some approaches are more computationally intensive than others , or they operate on heart beats rather than finite ECG segments , there are practically a number of open issues in the literature with regard to ECG biometrics .Among the most prominent ones is the question of signal stability , or permanence , with time .The majority of prior works did not examine the evolution of the ECG signal with time .To some extent , the sources of intrasubject variability of the ECG signal have been ignored .", "label": "", "metadata": {}}
{"text": "The Autocorrelation / Linear Discriminant Analysis Method .ECG biometrics is essentially a pattern recognition problem , comprised of three distinct steps , that is , preprocessing , feature extraction , and classification .Preprocessing The ECG data in raw format contain both high ( powerline interference ) and low frequency noise ( baseline wander ) that needs to be eliminated .Baseline wander is caused by low frequency components that force the signal to extend away from the isoelectric line .The source of this kind of artifacts is respiration , body movement , or inadequate electrode attachment .", "label": "", "metadata": {}}
{"text": "To reduce the effects of noise , a butterworth bandpass filter of order 4 is used .Based on the spectral properties of each wave in the heart beat , the cut - off frequencies of the filter are 1 Hz and 40 Hz .The order of the filter and the passband frequencies are selected based on empirical results [ 34 , 35 ] .Feature Extraction As mentioned before , the core of the proposed feature extraction method is the autocorrelation ( AC ) of ECG signals .The rationale for AC is that it captures the repetitive property of the ECG signal in a way that only significant , iterative components contribute to the waveform , that is , the . wave .", "label": "", "metadata": {}}
{"text": "The syllogism behind AC with respect to fiducial points detection is that it blends , into a sequence of sums of products , ECG samples that would otherwise need to be subjected to fiducial detection .Furthermore , the AC allows a shift invariant representation of similarity features over multiple cycles .The AC can be computed as .Even though the major contributors to the AC are the three characteristic waves , normalization is required because large variations in amplitudes appear , even among the windows of the same subject .In addition , only a segment of the AC vector propagates to LDA , as defined between the zero lag instance and up to approximately the length of the . wave and the QRS complex .", "label": "", "metadata": {}}
{"text": "An AC vector can be used directly for classification .However , it is important to further reduce the intrasubject variability in order to control false rejection .In addition , depending on the sampling frequency of the ECG signal , the dimensionality of an AC window can be considerably high .For these reasons the linear discriminant analysis ( LDA ) is recruited for dimensionality reduction .The LDA is a well - known machine learning method for feature extraction .Supervised learning is performed in a transform domain so that the AC vector 's dimensionality is reduced and the classes are better separable .", "label": "", "metadata": {}}
{"text": "( i ) Let .It is important to note that ECG biometrics benefit from supervised machine learning approaches more than other biometric modalities .This is because of this signal 's dynamic and time - dependent nature which leads the biometric to exhibit higher intraclass variability than traditional biometric modalities .With the LDA one can essentially control false acceptance and false rejection .Classification For biometric matching , input and gallery templates are associated using the Euclidean distance as a measure of dissimilarity , while the final decision is made upon voting of .Template Destabilization due to Emotions .", "label": "", "metadata": {}}
{"text": "In the ECG case , such factors may be physiological , psychological , or environmental .Muscle contraction and movement , body fluids , and powerline interference are examples of environmental factors , that is , whose effect on the signal is added after its generation .Typical noise filters , such as the Butterworth suffice in addressing such artifacts .A healthy physiological change is usually expressed by a change in the heart rate .From a medical point of view this is , a well - studied effect .From a biometric security perspective this variation may be addressed by exploring aspects of the signal that remain unaltered , that is , the . wave and the QRS complex [ 7 ] .", "label": "", "metadata": {}}
{"text": "However , the effects of psychology on the ECG signal are not as well defined .While this signal has been employed in affective computing [ 10 , 11 , 36 - 42 ] in most of these cases the heart rate was used in order to determine the arousal levels .The ECG waveform ( not just the heart rate ) was also examined for valence classification in [ 9 ] .It was demonstrated that it is possible to detect specific emotions from the ECG signal as long as the emotional stimuli are active .( Active stimuli engage the subject in the emotion induction process ( e.g. , video gaming , reading , singing ) .", "label": "", "metadata": {}}
{"text": "In home telemonitoring environments active arousal is unavoidable as emotional stimulation is present in everyday activities .It is therefore important to investigate whether the emotional changes on the ECG can compromise the respective biometric template or not .In [ 2 ] , it was shown that over long recording periods , while subjects are performing every - day working activities , the ECG biometric template may destabilize , that is , change to a degree that endangers security .While the experimental procedures reported in [ 2 ] were not emotion specific , it was concluded that psychology is the underlying cause of variation on the ECG signal .", "label": "", "metadata": {}}
{"text": "The reader should note that the above two objectives do not directly encompass methods to detect or classify specific emotions .While experimental procedures have been designed in order to trigger specific emotional response , determining which emotion is experienced is beyond the scope of the current work and has been addressed separately [ 9 ] .Emotion Elicitation and ECG Signals .The following experiment was conducted at the Affect and Cognition Laboratory of the University of Toronto .The purpose was to elicit active mental arousal using a commercial video game .In practice the experiment attempted to have the player gradually immersed , by increasingly concentrating in order to meet the game requirements .", "label": "", "metadata": {}}
{"text": "The subjects got motivated with deception , by letting them know that the purpose of the experiment is to measure game completion time .All participants were seated in front of a computer screen and presented with a short introduction to the video game .A five - minute pilot game was played , for the participant to learn and be adjusted to the game .During that time , no physiological response was monitored .When the subject felt comfortable with the process , the ECG sensor was placed and the main game was initiated .In total 43 volunteers participated in this study .", "label": "", "metadata": {}}
{"text": "Depending on the familiarity of the subject with game playing , the duration of the experiment varied between 20 and 45 minutes .During the game , ECG was monitored using Hidalgo 's equivital sensor , which is portable and wireless .Unobtrusiveness was very important for the subjects to be naturally immersed in the game .ECG was recorded from the chest and digitized at 256 Hz .Because of the stochastic nature of the game and the unforeseeable order of events that can take place , arousal annotation was self - determined .For this reason , a video of the player 's facial expressions was captured during the game ( synchronous to ECG ) .", "label": "", "metadata": {}}
{"text": "Figure 1 shows an example of such a self - assessment video , while Figure 2 illustrates the data labeling scheme .Figure 2 : Data labeling for the active arousal experiment .The FEELTRACE is a continuous arousal indication .Template Updating .The underlying idea of the proposed approach is to update the ECG biometric template at instances of destabilization due to psychological changes .An alternative to this solution would be to preenrol a subject with a number of different templates along the spectrum of emotional responses .However , this is not a practical solution since it is not feasible to induce such conditions on demand or ensure that one indeed succeeded in doing so .", "label": "", "metadata": {}}
{"text": "In the proposed system , the user can be enrolled once , by submitting his / her ECG signal irrespective of the psychological status .In return , during normal operation , when the system detects that the existing biometric template has been destabilized , that is , results in low - quality matching with newly captured ECG segments , a new biometric template is created to replace the first .Therefore , the objective of the subsequent analysis is to update the biometric template at instances corresponding to the destabilization or decoherence of the correlation scores among consecutive ECG readings and the biometric template .", "label": "", "metadata": {}}
{"text": "The same approach is adopted in the current analysis ; however the objective of the present work is to associate instances of destabilization with psychological changes .The proposed system constructs variable - length accumulated durations of ECG segments based on some fundamental time duration .The accumulated segments need to be coherent , that is , exhibit high correlation with each other ( intraburst correlation ) .When decoherence is observed , template update is initiated based on the latest ECG segments .In practice , there is a tradeoff between frequency of template updates and computational complexity .", "label": "", "metadata": {}}
{"text": "On the other hand , infrequent template updating may cause inadequate system performance in terms of increased false rejection .To efficiently address this problem , a minimum time duration is forced over which the system makes a decision about whether the template needs to be updated .In an extreme case one can define this minimum duration to be equal to the smallest time resolution in the system , that is , the fundamental duration ( 5 seconds for the AC / LDA algorithm ) .However , this is computationally inefficient , and therefore the updating instances need to be strategically chosen .", "label": "", "metadata": {}}
{"text": "The following iterative description can be made .corresponds to time duration of 5 seconds .This duration is chosen to acceptably accommodate the time resolution requirement of the AC / LDA algorithm .Now suppose that , at the current iteration , the current burst , . , which means that with high confidence each burst corresponds to either high or low arousal .The reader should note that the purpose of this work is not to automatically detect emotional states .Emotional confidence is calculated as an a posteriori validation to demonstrate the coincidence of instances of emotional change and biometric template destabilization .", "label": "", "metadata": {}}
{"text": "The performance of the proposed algorithm for template updating was evaluated on emotion - annotated ECG signals .ECG readings are available for the duration of the video game , as previously described in Section 6 .The first few seconds of every reading were used for initialization , that is , the design of an initial biometric template .Then in the sequel , the correlation of this template with subsequent ECG readings was determined and , if not sufficient , the template was updated .The number of template updates within the 30 min gaming session varies for different individuals .", "label": "", "metadata": {}}
{"text": "Even though this measure relies on the subjects ' self - reports and discrepancies are expected , the average state confidence for the bursts is 96.47 % .This performance is illustrative of the accuracy of detecting homogeneous emotional states , which leads to successful template updating .Now , consider the original problem of biometric recognition when a burst is terminated due to decoherence the system performs a template update .While the above results show that each burst corresponds to either high arousal or low arousal , the question that naturally arises is the following : do two consecutive bursts correspond to opposite arousal labels ?", "label": "", "metadata": {}}
{"text": "The average state confidence is 96.47 % .In practice , the template updating algorithm is not only affected by emotional states .A burst may be interrupted due to one of the following three reasons .( 1 )A state change , that is , a transition from one psychological state to another .( 2 ) Buffer overflow , that is , when . was set to 10 minutes .( 3 ) Noise artifacts ( e.g. , due to a sudden movement ) , that are not sufficiently treated by the filter .Nevertheless , a template update is necessary in all cases .", "label": "", "metadata": {}}
{"text": "To quantify the verification accuracy after template updating , the false acceptance ( FA ) and rejection ( FR ) rates are estimated for every individual separately .Table 1 lists the equal error rates ( EER depicts the error rate at which the probability of false acceptance equal that of false rejection ) that were achieved with this treatment , for all subjects in the active arousal dataset .The average equal error rate in this case is 3.96 % .It should be noted that the baseline system performance that is without template updating results in 15 % EER .", "label": "", "metadata": {}}
{"text": "In each simulation FA was computed with comparisons of the updated template of one individual against the remaining subjects in the database . , that is , the threshold on the correlation coefficient that is used to determine burst coherency .As this threshold increases , stronger coherence is imposed on the bursts , leading to smaller EER , as shown in Figure 5 .However , this is achieved at the expense of more frequent template updating needed ( i.e. , higher cost and complexity ) .Conclusion .In this work , a novel identity recognition system based on the ECG signal has been presented .", "label": "", "metadata": {}}
{"text": "In such settings , the ECG is typically collected among other vital signals and used for diagnosis and treatment decisions .Relying authentication on the very same modality not only increases security and convenience but also enhances user privacy since no other credentials are required to perform this task .This technology has significant advantages , most of which arise from the fact that ECG is a body - internal signal .For instance , ECG - enabled biometric systems can automatically and inherently assess the \" liveness \" of the biometric reading .This is not the case with traditional biometric modalities ( e.g. , iris or fingerprint ) which require additional computational effort to assess the liveness of the sensor reading .", "label": "", "metadata": {}}
{"text": "This paper addressed the problem of intrasubject variability of the ECG signal due to psychological changes .It was demonstrated that a biometric signature designed at a particular time may not allow for robust matching at a later time , under different emotional conditions ( template destabilization ) .A solution based on template updating was proposed for welfare monitoring environments .The performance was evaluated over ECG signals from 43 volunteers , under various arousal conditions induced with a video game .On average , an equal error rate of 3.96 % was achieved , which represents a dramatic reduction from the EER of 15 % for the particular dataset in the absence of template updating .", "label": "", "metadata": {}}
{"text": "This work has been supported by the Natural Sciences and Engineering Research Council of Canada ( NSERC ) .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. Hoekema , G. J. H. Uijen , and A. Van Oosterom , \" Geometrical aspects of the interindividual variability of multilead ECG recordings , \" IEEE Transactions on Biomedical Engineering , vol .48 , no .5 , pp .551 - 559 , 2001 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . H. W. Draper , C. J. Peffer , F. W. Stallmann , D. Littmann , and H. V. Pipberger , \" The corrected orthogonal electrocardiogram and vectorcardiogram in 510 normal men ( Frank lead system ) , \" Circulation , vol .", "label": "", "metadata": {}}
{"text": "853 - 864 , 1964 .View at Google Scholar \u00b7 View at Scopus . F. Agrafioti , D. Hatzinakos , and A. Anderson , \" ECG pattern analysis for emotion detection , \" IEEE Transactions on Affective Computing , vol .3 , pp .102 - 115 , 2012 .View at Google Scholar .G. N. Yannakakis , J. Hallam , and H. H. Lund , \" Entertainment capture through heart rate activity in physical interactive playgrounds , \" User Modelling and User - Adapted Interaction , vol .18 , no . 1 - 2 , pp .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Sornmo and P. Laguna , Bioelectrical Signal Processing in Cardiac and Neurological Applications , Elsevier , 2005 .J. T. Catalano , Guide to ECG Analysis , J.B. Lippincott , Philadelphia , Pa , USA , 1993 .M. Kyoso and A. Uchiyama , \" Development of an ECG identification system , \" in Proceedings of the 23rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society , vol .", "label": "", "metadata": {}}
{"text": "3721 - 3723 , October 2001 .View at Scopus .T. W. Shen , W. J. Tompkins , and Y. H. Hu , \" One - lead ECG for identity verification , \" in Proceedings of the 2nd Conference of the IEEE Engineering in Medicine and Biology Society , pp .62 - 63 , October 2002 .View at Scopus .R. Palaniappan and S. M. Krishnan , \" Identifying individuals using ECG beats , \" in Proceedings of the International Conference on Signal Processing and Communications ( SPCOM ' 04 ) , pp .569 - 572 , December 2004 .", "label": "", "metadata": {}}
{"text": "View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .C. M. Ting and S. H. Salleh , \" ECG based personal identification using extended Kalman filter , \" in Proceedings of the 10th International Conference on Information Sciences , Signal Processing and their Applications ( ISSPA ' 10 ) , pp .774 - 777 , May 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Scopus .G. G. Molina , F. Bruekers , C. Presura , M. Damstra , and M. van der Veen , \" Morphological synthesis of ECG signals for person authentication , \" in Proceedings of 15th European Signal Processing Conference , Poland , 2007 . A. D. C. Chan , M. M. Hamdy , A. Badre , and V. Badee , \" Wavelet distance measure for person identification using electrocardiograms , \" IEEE Transactions on Instrumentation and Measurement , vol .", "label": "", "metadata": {}}
{"text": "248 - 253 , 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .I. Odinaka , P. H. Lai , A. D. Kaplan et al . , \" ECG biometrics : a robust short - time frequency analysis , \" in 2010 IEEE International Workshop on Information Forensics and Security , WIFS 2010 , pp . 1 - 6 , December 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . D. P. Coutinho , A. L. N. Fred , and M. A. T. Figueiredo , \" One - lead ECG - based personal identification using Ziv - Merhav cross parsing , \" in Proceedings of the 20th International Conference on Pattern Recognition ( ICPR ' 10 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .M. Li and S. Narayanan , \" Robust ECG biometrics by fusing temporal and cepstral information , \" in Proceedings of the 20th International Conference on Pattern Recognition ( ICPR ' 10 ) , pp .1326 - 1329 , August 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . F. Agrafioti and D. Hatzinakos , \" ECG based recognition using second order statistics , \" in Proceedings of the 6th Annual Communication Networks and Services Research Conference ( CNSR ' 08 ) , pp .", "label": "", "metadata": {}}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . F. Agrafioti and D. Hatzinakos , \" Fusion of ECG sources for human identification , \" in Proceedings of the 3rd International Symposium on Communications , Control , and Signal Processing ( ISCCSP ' 08 ) , pp .1542 - 1547 , March 2008 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. W. Picard , E. Vyzas , and J. Healey , \" Toward machine emotional intelligence : analysis of affective physiological state , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}}
{"text": "10 , pp .1175 - 1191 , 2001 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. Ekman , R. W. Levenson , and W. V. Friesen , \" Autonomic nervous system activity distinguishes among emotions , \" Science , vol .221 , no .4616 , pp .1208 - 1210 , 1983 .View at Google Scholar \u00b7 View at Scopus . F. H\u00f6nig , A. Batliner , and E. N\u00f6th , \" Real - time Recognition of the Affective User State with Physiological Signals , \" in Proceedings of the 2nd International Conference on Affective Computing and Intelligent Interaction , pp . 1 - 8 , Roddy Cowie and Fiorella de Rosis , 2007 .", "label": "", "metadata": {}}
{"text": "491 - 499 , April 2005 .View at Scopus .C. M. Jones and T. Troen , \" Biometric valence and arousal recognition , \" in Proceedings of the Australasian Computer - Human Interaction Conference ( OZCHI ' 07 ) , pp .191 - 194 , November 2007 .View at Scopus .R. L. Mandryk , K. M. Inkpen , and T. W. Calvert , \" Using psychophysiological techniques to measure user experience with entertainment technologies , \" Behaviour and Information Technology , vol .25 , no . 2 , pp .141 - 158 , 2006 .", "label": "", "metadata": {}}
{"text": "R. Cowie , E. Douglas - Cowie , S. Savvidou , E. McMahon , M. Sawey , and M. Schroder , \" FEELTRACE : an instrument for recording perceived emotion in real time , \" in Proceedings of the iSCA Workshop Speech and Emotion , pp .19 - 24 , 2000 .A system and method for voice activity detection , in accordance with the invention includes the steps of inputting data including frames of speech and noise , and deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic and pitch .", "label": "", "metadata": {}}
{"text": "Abstract .A system and method for voice activity detection , in accordance with the invention includes the steps of inputting data including frames of speech and noise , and deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic and pitch .The frames of the input data are tagged based on the log - likelihood ratio test statistic and pitch characteristics of the input data as being most likely noise or most likely speech .The tags are counted in a plurality of frames to determine if the input data is speech or noise . deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic and pitch ; . tagging the frames of the input data based on the log - likelihood ratio test statistic and pitch characteristics of the input data as being most likely noise or most likely speech ; and .", "label": "", "metadata": {}}
{"text": "claim 1 , wherein the step of deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic includes the step of : . determining a first probability that a given frame of the input data is noise ; . determining a second probability that the given frame of the input data is speech ; and . determining a LLRT statistic by taking a difference between the logarithms of the first probability from the second probability .The method as recited in . claim 2 , wherein the step of determining a first probability includes the step of comparing the given frame to a model of Gaussian mixtures for noise .", "label": "", "metadata": {}}
{"text": "The method as recited in .claim 1 , wherein the step of tagging the frames of the input data based on the log - likelihood ratio test statistic and pitch characteristics include the step of tagging the frames according to an equation : .The method as recited in .claim 1 , wherein the step of providing a smoothing window of N frames includes the formula : . where w(t ) is the smoothing window , t is time , and \u03b1 is a decay constant .The method as recited in .claim 1 , wherein the step of providing a smoothing window of N frames includes the formula : . where w(t ) is the smoothing window , and t is time .", "label": "", "metadata": {}}
{"text": "The method as recited in .claim 1 , wherein the step of counting the tags further comprises the steps of : . comparing a normalized cumulative count to a first threshold and a second threshold ; . if the normalized cumulative count is above or equal to the first threshold and the current tag is most likely speech , the input data is speech ; and .if the normalized cumulative count is below to the second threshold and the current tag is most likely noise , the input data is noise .A program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform method steps for voice activity detection , the method steps comprising : . inputting data including frames of speech and noise ; . deciding if the frames of the input data include speech or noise by employing a log - likelihood ratio test statistic and pitch ; . tagging the frames of the input data based on the log - likelihood ratio test statistic and pitch characteristics of the input data as being most likely noise or most likely speech ; and .", "label": "", "metadata": {}}
{"text": "The program storage device as recited in .claim 11 , wherein the step of determining a first probability includes the step of comparing the given frame to a model of Gaussian mixtures for noise .The program storage device as recited in .claim 11 , wherein the step of determining a second probability includes the step of comparing the given frame to a model of Gaussian mixtures for speech .The program storage device as recited in . claim 10 , wherein the step of tagging the frames of the input data based on the log - likelihood ratio test statistic and pitch characteristics include the step of tagging the frames according to an equation : .", "label": "", "metadata": {}}
{"text": "The program storage device as recited in . claim 10 , wherein the step of providing a smoothing window of N frames includes the formula : . where w(t ) is the smoothing window , t is time , and \u03b1 is a decay constant .The program storage device as recited in . claim 10 , wherein the step of providing a smoothing window of N frames includes the formula : . where w(t ) is the smoothing window , and t is time .The program storage device as recited in .The program storage device as recited in . claim 10 , wherein the step of counting the tags further comprises the steps of : . comparing a normalized cumulative count to a first threshold and a second threshold ; . if the normalized cumulative count is above or equal to the first threshold and the current tag is most likely speech , the input data is speech ; and .", "label": "", "metadata": {}}
{"text": "Description .BACKGROUND OF THE INVENTION .Field of the Invention .The present invention relates to speech recognition , and more particularly to a system and method for discriminating speech ( silence ) using a log - likelihood ratio and pitch .Description of the Related Art .Voice activity detection ( VAD ) is an integral and significant part of a variety of speech processing systems , comprising speech coding , speech recognition , and hands - free telephony .For example , in wireless voice communication , a VAD device can be incorporated to switch off the transmitter during the absence of speech to preserve power or to enable variable bit rate coding to enhance capacity by minimizing interference .", "label": "", "metadata": {}}
{"text": "For the design of VAD , efficiency , accuracy , and robustness are among the most important considerations .Many prevailing VAD schemes have been proposed and used in different speech applications .Based on the operating mechanism , they can be categorized into a threshold - comparison approach , and a recognition - based approach .The advantages and disadvantages are briefly discussed as follows .The underlying basis of a threshold - comparison VAD scheme is that it extracts some selected features or quantities from the input signal and then compare these values with some thresholds .( See , e.g. , K. El - Maleh and P. Kabal , \" Comparison of Voice Activity Detection Algorithms for Wireless Personal Communications Systems \" , Proc .", "label": "", "metadata": {}}
{"text": "470 - 473 , May 1997 ; L. R. Rabiner , et al . , \" Application of an LPC Distance Measure to the Voiced - Unvoiced - Silence Detection Problem , \" IEEE Trans . on ASSP , vol .ASSP-25 , no . 4,pp .338 - 343 , August 1977 ; and M. Rangoussi and G. Carayannis , \" Higher Order Statistics Based Gaussianity Test Applied to On - line Speech Processing , \" In Proc . of the IEEE Asilomar Conf . , pp .303 - 307 , 1995 . )These thresholds are usually estimated from noise - only periods and updated dynamically .", "label": "", "metadata": {}}
{"text": "A major advantage of the threshold - comparison VAD approach is efficiency as the selected features are computationally inexpensive .Also , they can achieve good performance in high - SNR environments .However , all these arts rely on either empirically determined thresholds ( fixed or dynamically updated ) , the stationarity assumption of background noise , or the assumption of symmetry distribution process .Therefore , there are two issues to be addressed , including robustness in threshold estimation and adaptation , and ability to handle non - stationary and transient noises ( See , e.g. , S. F. Boll , \" Suppression of Acoustic Noise in Speech Using Spectral Subtraction , \" IEEE Trans . on Acoustics , Speech , and Signal Processing , Vol . ASSP-27 , No . 2 , pp .", "label": "", "metadata": {}}
{"text": "For recognition - based VAD , the recent advances in speech recognition technology have enabled its widespread use in speech processing applications .The discrimination of speech from background silence can be accomplished using speech recognition systems .In the recognition - based approach , very accurate detection of speech / noise activities can be achieved with the use of prior knowledge of text contents .However , this recognition - based operation may be too expensive for computation - sensitive applications , and therefore , it is mainly used for off - line applications with sufficient resources .Furthermore , it is language - specific and the quality highly depends on the availability of prior knowledge of text .", "label": "", "metadata": {}}
{"text": "Therefore , a need exists for a system and method which overcomes the deficiencies of the prior art , for example , the lack of robustness in threshold estimation and adaptation , the lack of the ability to handle non - stationary and transient noises and language - dependency .A further need exists for a model - based system and method for speech / silence detection using cepstrum and pitch .SUMMARY OF THE INVENTION .The frames of the input data are tagged based on the log - likelihood ratio test statistic and pitch characteristics of the input data as being most likely noise or most likely speech .", "label": "", "metadata": {}}
{"text": "The step of determining a first probability may include the step of comparing the given frame to a model of Gaussian mixtures for noise .The step of determining a second probability may include the step of comparing the given frame to a model of Gaussian mixtures for speech .The methods may be performed by a program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform the method steps .The methods may be performed by a program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform the method steps .", "label": "", "metadata": {}}
{"text": "The step of clustering the noise portions may include clustering the noise portions in accordance with a plurality of noise ambient environments .These and other objects , features and advantages of the present invention will become apparent from the following detailed description of illustrative embodiments thereof , which is to be read in connection with the accompanying drawings .BRIEF DESCRIPTION OF DRAWINGS .The invention will be described in detail in the following description of preferred embodiments with reference to the following figures wherein : .FIG .1 is a block / flow diagram of a system / method for training speech and noise models including Gaussian mixture densities in accordance with the present invention ; and .", "label": "", "metadata": {}}
{"text": "2 is a block / flow diagram of a system / method for voice activity detection in accordance with the present invention .DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS .The present invention includes a voice activity ( VAD ) system and method based on a log - likelihood ratio test statistic and pitch combined with a smoothing technique using a running decision window .To maintain accuracy , the present invention utilizes speech and noise statistics learned from a large training database with help from a speech recognition system .To achieve robustness to environmental changes , the need for threshold calibration is eliminated by applying the ratio test statistic .", "label": "", "metadata": {}}
{"text": "A training procedure of the invention advantageously employs cepstrum for voice activity detection .Log - Likelihood Ratio Test for VAD .The VAD method for the present invention is similar to the threshold - comparison in that it employs measured quantities for decision - making .The present invention advantageously employs log - likelihood ratio and pitch .The dependency on empirically determined thresholds is removed as the log - likelihood ratio considers similarity measurements from both speech and silence templates .The algorithm also benefits from a speech recognition system when templates are to be built in the training phase .", "label": "", "metadata": {}}
{"text": "Log - Likelihood Ratio Test ( LLRT ) .Assume that both speech and noise observations can be characterized by individual distributions of Gaussian mixture density functions : Let x(t ) be the input signal at time t. The input signals may include acoustic feature vectors , say for example , 24-dimension cepstral vectors .Two simple hypotheses may be defined as follows : .H 1 input is from probability distribution of speech .The probabilities for x(t ) , given it is a noise frame , and given it is a speech frame , can be written , respectively as : .", "label": "", "metadata": {}}
{"text": "t .Prob .x .t . )H .P .t .Prob .x .t . )H .Then the following decisions may be made based on the likelihood ratio test statistic as : . if .t . ) then .Reject .H . else . if .t . ) then .Reject .H . else . if .t . ) then .Pending . where \u03b1 and \u03b2 are the probabilities for a type I error and type II error , respectively .A type I error is to reject H o when it should not be rejected , and a type II error is to not reject H o when it should be rejected .", "label": "", "metadata": {}}
{"text": "^ .t . )Reject .H .^ .t . )Reject .H .Equation ( 4 ) and Equation ( 5 ) are the building blocks used in the VAD method of the present invention .A score tag , Tag(t ) , is generated for each input signal , x(t ) , based on the LLRT statistic or the decision to reject or accept H 0 .Pitch For VAD .Pitch is a feature used in some speech applications such as speech synthesis and speech analysis .Pitch can be used as an indicator for voiced / unvoiced sound classification .", "label": "", "metadata": {}}
{"text": "For consonants like fricatives and stops , pitch simply does not exist .Likewise , background noises do not exhibit pitch due to the lack of periodicity .Therefore , pitch itself is not an obvious choice for voice activity detection because the absence of pitch can not distinguish consonants from background noise .However , in accordance with the present invention , the combination of cepstrum and pitch as the selected feature for voice activity detection surprisingly improves overall performance .First , the information conveyed in cepstrum is useful in reducing the false silence errors as observed in the cepstrum - only case described above .", "label": "", "metadata": {}}
{"text": "To combine these two features , the score tags can be expressed as a function of \" LLRT statistic \" ( cepstrum ) and pitch : . where Tag(t ) is a decision function .Illustrative Tag functions which include pitch may include the following illustrative example : .Tag . t . )f .LLRT .pitch . ) score1 . t . ) score2 . t . ) where . score1 . t . ) when .^ .t . ) when .^ .t . ) score2 . t . ) with . pitch .", "label": "", "metadata": {}}
{"text": "\u03bb is a weighting factor for LLRT which may be experimentally determined or set in accordance with a user 's confidence that pitch is present .In one embodiment , \u03bb may be set to 0.5 .The LLRT statistic and pitch produce score tags on a frame - by - frame basis .The speech / non - speech classification based on this score tag may over - segment the utterances to make it unsuitable for the speech recognition purposes .To alleviate this issue , a smoothing technique based a running decision window is adopted .Smoothing Decision Window .", "label": "", "metadata": {}}
{"text": "One is to integrate information from adjacent observations and the other to incorporate continuity constraint to manage the \" hangover \" periods for transition between speech and noise sections .Let c(t ) be the normalized cumulative count of the score tag from the LLRT statistic in a N - frame - long decision window ending at time frame t. It can be expressed as : . c . t . )N .w .Tag . t .N .w .where w(t ) is the running decision window of N frames long , and \u03c4 is the summation index .", "label": "", "metadata": {}}
{"text": "Then , the final classification algorithm is described as : .Tag . t . ) AND .c . t . )TH1 . speech .Tag . t . ) AND .c . t . )TH2 . noise .Otherwise .unchanged . where TH1 and TH2 are the normalized thresholds for speech floor and silence ceiling , respectively .Note that these normalized thresholds are essentially applied to control the \" hangover \" periods to ensure proper segment length for various speech processing applications .Unlike the conventional threshold - comparison VAD algorithms , they are robust to environmental variability and do not need to be dynamically updated .", "label": "", "metadata": {}}
{"text": "Two sets of experiments were carried out by the inventors .The first one evaluated the effectiveness of extracted features for LLRT .The second one involved evaluation of the VAD for the present invention in modeless speech recognition , in which C&C and dictation may be mixed with short pauses .A set of training data was used to train a standard large - vocabulary continuous speech recognition system .The set of training data included 36000 utterances from 1300 speakers .2000 utterances of training data were used in the first experiment to evaluate various features and to determine the number of Gaussian mixtures for speech and silence models .", "label": "", "metadata": {}}
{"text": "One test included the Command - and - Control ( C&C ) task , in which each utterance included multiple C&C phrases with short pauses in between .The test included 8 speakers with 80 sentences from each speaker .Another test set included a mix C&C / dictation ( MIXED ) task , where C&C phrases are embedded in each dictation utterance with short pauses wrapped around .This set included 8 speakers with 68 sentences from each speaker .In summary , it uses MFCC - based front - end signal processing in a 39-dimensional feature vector computed every 10 micro - seconds .", "label": "", "metadata": {}}
{"text": "Then , a fast match decoding with context independent units is followed by a detailed match decoding with context dependent units .A finite - state grammar and a statistical language model are enabled in the decoder to handle commands and dictation .First , individual Gaussian mixture distributions are obtained for speech and silence during the training procedure steps .The first step is to label the training data .This is accomplished by using the speech recognition system in a forced alignment mode to identify the speech and silence sections given the correct word .Given contents , forced alignment determines the phonetic information for each signal segment using the same mechanism for speech recognition .", "label": "", "metadata": {}}
{"text": "Likewise , silence models are trained using data labeled as noise .Given the correct text contents , the speech / noise labels from forced alignment are treated as correct labels .For each set of Gaussian mixtures , different cepstrum - based features are evaluated , including static cepstrum ( Static CEP ) , linear discriminant analysis ( LDA ) , and time derivative dynamic cepstrum ( CEP+Delta+DD ) .Spliced CEP+LDA is computed by performing LDA on splice CEP ( say , for example , 9-frame CEP can be produced by concatenating the previous four and the following 4 frames ) .", "label": "", "metadata": {}}
{"text": "It shows that cepstrum with its time derivatives ( CEP+Delta+DD ) yields the best classification result .In general , the performance improves with more Gaussian mixtures for speech and noise distributions .Note that detection error rates include more false silence errors than false speech errors partly due to latent mislabeling from forced alignment and partly due to the fact that some low - energy consonants are confusing with background noise .Note that the cepstrum - based features are primarily chosen for the LLRT statistic in this invention with a major advantage that the efficiency can be maximized by using the same front - end .", "label": "", "metadata": {}}
{"text": "In this test , the speech decoder runs in a modeless fashion , in which both finite - state grammar and statistical language model are enabled .While the decoder can handle connected phrases without VAD , the detection of a transition between speech and silence from VAD suggests to the decoder a latent transition between C&C phrases and/or dictation sentences .The first test data was the C&C task , in which each utterance included 1 to 5-command phrases with short pauses ranging approximately from 100 micro - seconds and 1.5 seconds .Table 2 compares the recognition results obtained when the LLRT - based VAD , a conventional adaptive energy - comparison VAD ( Energy - Comp . ) , or no VAD ( Baseline ) is used .", "label": "", "metadata": {}}
{"text": "Table 3 compares the results for the MIXED task , in which the embedded command phrases are bounded by short pauses .It is shown that the LLRT - based VAD improves the overall word error rate to 26.6 % in contrast to 28.5 % when no VAD is used .It is noteworthy that the smaller improvement from the LLRT - based VAD is observed in the MIXED task than in the C&C task .It is due to the artifact that preceding decoded context before each speech / noise transition is discarded such that the language model stifles on the dictation portions .", "label": "", "metadata": {}}
{"text": "To test the robustness of VAD , another set of noisy test data is collected from one male speaker by playing a pre - recorded cafeteria noise during recording , including the NOISY - C&C and NOISY - MIXED task .Two microphones are used simultaneously , a close - talk microphone and a desktop - mounted microphone .The comparison of recognition results for noisy data is shown in Table 4 .It reveals that the LLRT - based VAD method of the present invention is robust with respect to environmental variability by achieving similar performance improvement over the baseline system .", "label": "", "metadata": {}}
{"text": "It should be understood that the elements shown in FIGS . 1 - 2 may be implemented in various forms of hardware , software or combinations thereof .Preferably , these elements are implemented in software on one or more appropriately programmed general purpose digital computers having a processor and memory and input / output interfaces .Referring now to the drawings in which like numerals represent the same or similar elements and initially to FIG .1 , a training system / method for voice activity - detection is shown in accordance with the present invention .Once the labels are obtained as output from forced alignment in block 14 , the training data from block 10 is divided into speech and noise in block 16 .", "label": "", "metadata": {}}
{"text": "In this way , the noise data is pooled for clustering .The noise data is clustered into classes or clusters to associate similar noise labeled training data , in block 20 .Clustering may be based on , for example , different background ambient environments .In block 22 , noise Gaussian mixtures densities are output to provide noise models for voice activity detection in accordance with the present invention .Noise Gaussian mixture distributions are trained for noise recognition .In block 24 , speech data is accumulated for the speech labeled training data .In this way , the speech data is pooled for clustering .", "label": "", "metadata": {}}
{"text": "Clustering may include different sound clusters , etc .In block 28 , speech Gaussian mixture densities are output to provide speech models for voice activity detection in accordance with the present invention .Speech Gaussian mixture distributions are trained for speech recognition .It is to be understood that the speech and noise models may be employed in speaker dependent and speaker - independent systems .The following table compares the performance of our VAD scheme using a composite database with two different data sources .A first set includes 720 command phrases from three different speakers and the second set contains only breath noises .", "label": "", "metadata": {}}
{"text": "Referring now to FIG .2 , a system / method for voice activity detection is shown in accordance with the present invention .In block 62 , test data is input to the system for voice activity detection , where x(t ) is the input signal at time t , e.g. , input test data from block 62 .Test data may include speech mixed with noise .The hypotheses are defined for probability distribution of noise H 0 and for the probability distribution of speech H 1 .The probabilities for x(t ) , given it is a noise frame , and given it is a speech frame , can be written for P 0 t and P 1 t in Equation ( 1 ) .", "label": "", "metadata": {}}
{"text": "1 , where the models output at blocks 22 and 28 provide the input for determining probabilities based on LLRT .Pitch is computed in block 65 for each input signal , x(t ) .Pitch may be computed by conventional means .In block 72 , a normalized cumulative count c(t ) of the score tag is computed based on from the LLRT statistic and pitch in a N - frame - long decision window ending at time frame t. It can be expressed as Equation ( 8) .Otherwise , if the criteria for blocks 74 and 76 are not met , then the nature of the input signal is undecided and the status remains unchanged .", "label": "", "metadata": {}}
{"text": "The LLRT statistic takes into account the similarity scores from both speech and silence templates simultaneously .Therefore , it is more robust with respect to the background noise environments than the conventional threshold - comparison approaches .Further , surprising improvements are gained when pith is considered along with LLRT to detect voice .Combined with a smoothing technique based on a running decision window , the present invention is capable of preserving continuity constraints and easily controlling the \" hangover \" periods to ensure proper segment length .When the invention is applied for speech recognition , the efficiency can be further maximized by using the same feature vectors .", "label": "", "metadata": {}}
{"text": "Having thus described the invention with the details and particularity required by the patent laws , what is claimed and desired protected by Letters Patent is set forth in the appended claims .all Addendum Article Book Review Case Report Comment Commentary Communication Concept Paper Conference Report Correction Creative Data Descriptor Discussion Editorial Erratum Essay Interesting Images Letter New Book Received Obituary Opinion Project Report Reply Retraction Review Short Note Technical Note .Department of Physics and Astronomy , Western Kentucky University , Bowling Green , KY 42101 , USA .Received : 29 May 2013 ; in revised form : 27 June 2013 / Accepted : 8 July 2013 / Published : 12 July 2013 .", "label": "", "metadata": {}}
{"text": "An application of spectral analysis to the transient response signals of ALD - fabricated conductometric sensors ( chemiresistors ) upon exposure to short vapor pulses is discussed .It is based on the representation of a response curve in the frequency domain , followed by the multi - dimensional Quadratic Discriminant Analysis ( QDA ) for analyte identification .Compared to the standard steady - state amplitude analysis , this technique does not depend on a short - term sensor drift , does not have limitations for the number of extracted features and has a strict physical validation .Effective recognition of some relatively simple combustible analytes ( acetone , toluene , ethanol ) was demonstrated using a single nonspecific chemiresistor .", "label": "", "metadata": {}}
{"text": "PACS : .Bd ; 73.63 .Rt .Introduction .Detection and recognition of combustible and explosive vapors remains an important problem for industry and national security .Major efforts in this direction have been concentrated on the development of analytical instruments , such as spectrometers of different kinds that are capable of detecting and analyzing the molecular structure of gaseous species .Currently , analytical tools of this type remain bulky and expensive , require considerable time for analysis , typically under laboratory conditions , and highly - qualified personnel to operate them .The best alternative for replacing the spectroscopy tools is the use of artificial olfactory systems also known as electronic noses [ 1 , 2 ] .", "label": "", "metadata": {}}
{"text": "An electronic nose consists of a mechanism for chemical detection , such as an array of electronic sensors , and a mechanism for pattern recognition , such as a neural network [ 3 ] .Conductometric sensors ( chemiresistors ) are traditionally used as the building blocks for electronic noses [ 1 , 2 ] .A chemiresistor is a device whose electrical resistance can be modulated by molecular adsorption on its surface .Typically , the changes in resistance are proportional to the partial vapor pressure of chemicals in the atmosphere ; hence a chemiresistor converts the concentration of chemicals in the atmosphere into a measurable electrical signal .", "label": "", "metadata": {}}
{"text": "Sensing behavior is one of the most important and well - known properties of metal oxide materials and it was found that metal oxide sensors usually demonstrate much higher sensitivity , selectivity , and stability to their chemical environment than the other materials .The sensing mechanism by metal oxide films is primarily based on high - temperature activation of atmospheric oxygen on the semiconductor surface [ 4 - 13 ] .Consequently , the catalytic reactions of gaseous species with oxygen sites on the surface induce charge transfer from the surface to the bulk , changing the electrical resistance of the device ( Figure 1a - c ) ) .", "label": "", "metadata": {}}
{"text": "Individual chemiresistors in the array are nonspecific and vary by physical or chemical parameters , such as : type of oxide , thickness of oxide layer , temperature , n or p -type volume doping , surface doping with catalytic nanoparticles .Upon the exposure to analyte , the integrated patterns of signals undergo processing by the pattern recognition software .Most feature extraction techniques for recognition software have been based on linear techniques , mainly principal components analysis ( PCA ) and Fisher 's linear discriminant analysis ( LDA ) [ 3 , 17 ] .PCA is a signal representation technique that generates projections along the directions of maximum variance , which are defined by the eigenvectors of covariance matrix .", "label": "", "metadata": {}}
{"text": "The LDA algorithm selects features that are most effective for class separability , while PCA selects features important for class representation .Initially , the most common practice for recognition of gaseous analytes was to use the steady state responses of the sensors as a feature vector [ 1 - 3 , 17 ] .At the same time , the transient response contains sufficient discriminatory information .Later , multiple successful studies have been conducted in order to expand the LDA and PCA for transient response .In an earlier work [ 21 ] the authors demonstrated the extraction of a transient feature , which is strongly correlated with the steady - state response , but available much earlier than the latter .", "label": "", "metadata": {}}
{"text": "There is no universal sensor system that can solve all the gas or vapor analysis problems .Instead , there is a need to employ intelligent sensor systems that are appropriate to the application .This means building in intelligence through the development of suitable sensor structures , sensor materials and pattern recognition methods .In this paper we present a technique that allows one to build a simple vapor recognition system based on a single broadly - tuned metal - oxide chemiresistor , fabricated using atomic layer deposition ( ALD ) .This method is based on the combination of fast Fourier transform ( FFT ) with exponential windowing and Quadratic Discrininant Analysis ( QDA ) .", "label": "", "metadata": {}}
{"text": "In contrast to the traditional analysis of the steady - state responses , the advantage of this method is the ability to analyze the entire catalytic process occurring on the sensor .Sensor calibration was performed via a VaporJet calibrator , which simulates vapor - pulse delivery typical for pre - concentrators of analytes [ 1 , 22 ] .This approach has strict physical validation , since the time - dependent features of the response curve are uniquely determined by a particular catalytic reaction .The number of extracted features in our method does not have limitations and can be adjusted depending on tested analytes .", "label": "", "metadata": {}}
{"text": "Chemiresistors were fabricated using a Beneq atomic layer deposition ( ALD ) system TFS 500 for deposition of ZnO on the silicon oxide substrates .ALD utilizes a binary reaction sequence of self - saturating chemical reactions between gaseous precursor molecules and a solid surface to deposit films in a monolayer - by - monolayer fashion .ALD of ZnO was conducted at 150 \u00b0 C using diethyl zinc ( DEZ ) and deionized water ( H 2 O ) as zinc and oxygen sources , respectively [ 23 - 26 ] .During the deposition , the background pressure of 1 Torr in the reaction chamber was maintained by a steady flow ( 300 sccm ) of the process gas nitrogen .", "label": "", "metadata": {}}
{"text": "A complete layer deposition consisted of 375 cycles .Following the above procedure , a uniformly distributed 85 nm polycrystalline ZnO coating was achieved .A standard two electrode test geometry was used for measuring the electrical response of chemiresistor to chemical vapors .Electrodes were deposited on the ZnO layer using shadow masking and consisted of the adhesion 50 nm thick nickel layer followed by 250 nm layer of gold .The electrodes were annealed and the ohmic nature of ZnO - metal contacts was verified by I - V characterization .The 5 mm \u00d7 5 mm sensor was connected to a thermocouple and placed on a variable temperature platform for temperature control .", "label": "", "metadata": {}}
{"text": "The sensor 's operational temperature range was found to be between 100 \u00b0 C and 500 \u00b0 C .The lack of sensitivity below 100 \u00b0 C is due to a sufficient drop in surface oxygen vacancies below this temperature .The reduction of sensitivity above 500 \u00b0 C is caused by the activation of surface phonons resulting in a sufficient increase in the oxygen desorption rate .Maximum sensor response was achieved at 400 \u00b0 C .The sensor was initially heated to 400 \u00b0 C in synthetic air at ambient pressure to obtain a steady state resistance .", "label": "", "metadata": {}}
{"text": "The principle of operation of the VaporJet calibrator is shown in Figure 2b .The ink - jet dispenser that is employed in the VaporJet calibrator is drop - on - demand ( DOD ) , meaning that it can produce a drop only when required .The actuation of the dispenser is done with a piezoelectric element .The dispenser consists of a glass tube having an orifice at one end and being connected by the means of Teflon \u2122 tubing to the reservoir containing the solution to be dispensed .An annular piezoelectric element poled in the radial direction is bonded to the glass using a thin epoxy layer .", "label": "", "metadata": {}}
{"text": "Because the structural response is very fast and the solution to be dispensed is in contact with the glass , the motion of the structure translates in a volumetric change in the solution .The change produces a localized pressure variation that travels as acoustic waves in the solution contained by the glass tube .The details of VaporJet design and operation can be found in [ 22 ] .Thanks to the advantages of this technology , short 0.1 s pulses of various analytes were used for sensor exposure in this study .Signal Processing and Pattern Recognition .", "label": "", "metadata": {}}
{"text": "All three of the tested chemicals effectively participate in a rapid catalytic oxidation on the surfaces of metal oxides .In the present study , the partial vapor pressures of the analytes in the ambient atmosphere were between 100 and 150 ppm .The raw data curves obtained from the sensors upon the exposure to 100 ppm of toluene , acetone and ethanol are shown in Figure 3a - c .Typically , the relative change of the sensor resistance in the range 0.1 - 10 times can only be achieved after a few seconds of exposure [ 10 - 16 ] .", "label": "", "metadata": {}}
{"text": "Specifically , the diffusion of the molecular species between the neighboring nanocrystals , as opposed to depletion of free carriers over the entire surface of an individual ZnO nanocrystal , creates stochastic contact potentials at grain boundaries ( Figure 4 ) .The contact potential can be viewed as a tunneling barrier to electrons , which in our case is modulated by the oxidation of the analyte .It is well known that the surface area and the surface defects are crucial for a high sensitivity given that the ionization happens primarily on the edges and corners of the nanocrystals [ 4 - 6 ] .", "label": "", "metadata": {}}
{"text": "The amplitudes of sensor responses are clearly different for different chemicals , which gives a discrimination mechanism for pure analytes having the same vapor pressure ; however , the amplitude data can be insufficient if the vapor pressures are different .In addition , a common sensor drift problem makes vapor recognition by amplitude using a single nonspecific chemiresistor impossible .A more productive approach would be to represent the entire response signal as a mathematical object suitable for processing by the recognition algorithm .The stages of signal processing and pattern recognition are shown in Figure 1d .In order to analyze the sensor response , the meaningful part of the response curve corresponding to the catalytic reaction on the surface has to be extracted .", "label": "", "metadata": {}}
{"text": "A drop of resistance , corresponding to vapor exposure , is a relatively fast process compared to the rising part of the curve , corresponding to the recovery of oxygen species on the chemiresistor surface ( Figure 1c ) .By monitoring the time derivative of the curve , the moment of rapid resistance drop can be detected .This moment is a starting point of the extracted signal .The sensor recovery takes longer , compared to the reaction phase .Therefore , the ending point of the extracted signal was determined by the analysis of an autocorrelation coefficient [ 27 ] : . r . a .", "label": "", "metadata": {}}
{"text": "N . k . x .i .x .x .i . k . x .i .N .x .i .x . where x i is a single observation , and .x .i .N .x .i . is the overall mean .The value of the autocorrelation coefficient that separates the signal from background noise depends on variety of factors corresponding to the particular experiment : type of background , humidity , temperature , or presence of electromagnetic field .Under the laboratory conditions the optimum lower boundary for autocorrelation coefficient that separates signal from noise was found to be 0.9 .", "label": "", "metadata": {}}
{"text": "In order to create an array of input parameters for recognition algorithm , these raw data curves have to be transformed into mathematical objects suitable for processing .A very efficient technique to mathematically reconstruct the signal is to use fast Fourier transform ( FFT ) .Application of FFT requires that the signal must be periodic in the sample window or frequency leakage will occur [ 27 ] .In other words , the signal must start and end at the same point in its cycle .Since the starting and ending points of them have different magnitudes ( Figure 3d - f ) , FFT can not be applied to the extracted part of the response curve directly .", "label": "", "metadata": {}}
{"text": "The exponential windowing is a multiplication of a response signal by the following function : . w .n . )e .n .N .The effect of the exponential window on the response signal in the time domain is shown in Figure 3g , h , i .The window weights the beginning and end of the sample to baseline so that it is more periodic during the FFT process .Upon applying the FFT to the enhanced data set , the response signal in a frequency domain is shown in the Figure 5 .The obtained harmonics can completely reconstruct the signal in time domain as Fourier series .", "label": "", "metadata": {}}
{"text": "The contribution of baseline to the sensor response was eliminated as constant , which makes the extracted features independent from the short - term sensor drift .Evolution of features under long - term sensor drift [ 28 ] has not been evaluated in the frame of this study .Reconstructed response signals in the time domain ( Figure 5c , f , k ) are mathematical functions of the following type : . x .t . )A .n .N .A .n . cos .n .n .t .n . ) where A 0 is a baseline dependent constant and N is a number of harmonics .", "label": "", "metadata": {}}
{"text": "Hence , in 60-dimentional hyperspace the entire signal can be represented as a single point .Introduction of pulses of different concentrations ( between 100 and to 150 ppm ) during the training process causes slight deviations in the spectral structure of the signal , which causes a formation of a cloud , rather than a single point .Upon the completion of training , the electronic smell - print of each chemical is represented as a cloud of points in 60-dimensional hyperspace .Figure 6a , b , c illustrate the 3-D subspaces of the first three harmonics out of twenty .", "label": "", "metadata": {}}
{"text": "Based on the training of our device , the pattern recognition algorithm was developed .A standard approach in recognition of chemical patterns is a linear discriminant analysis ( LDA ) [ 1 , 3 , 5 , 6 , 17 ] .However , the major difficulty of LDA is the assumption that the Gaussian densities for different classes ( analytes ) have the same shape , but are shifted versions of each other ( different mean vectors ) .Frequently , for chemiresistors this assumption is not supported by the experimental evidence and the linear boundaries between the classes are not always consistent .", "label": "", "metadata": {}}
{"text": "The QDA algorithm applied to the vapor recognition problem can be introduced using the following formalism .Therefore , the equations for boundary between the classes k and l can be written in the following form [ 3 ] : . f . k .X .p . k .e .X . k . )T . k .X . k . )f .l .X .p .e .X .l . )T .l .X .l . )f . k .X .f .l .", "label": "", "metadata": {}}
{"text": "where p is the dimension , \u03a3 k and \u03a3 l are the covariance matrices , and \u03bc k and \u03bc l are the mean vectors of classes k and l respectively .The visualization of the QDA in 3-D subspace of the first 3 harmonics for acetone , toluene and ethanol are shown in the Figure 6d - j .The lines in Figure 6d - j separating the analytes are the projections of a 60-dimensional surface on coordinate planes of 3-D subspace .For QDA the projections are the second order curves , compared to LDA where the projections are linear .", "label": "", "metadata": {}}
{"text": "Therefore , with an increase in the number of training inputs , the structure of boundaries will evolve and eventually stabilize .For very different chemicals like acetone , ethanol and toluene at 100 ppm levels of concentrations the electronic smell - prints are perfectly separable .However , for similar analytes , like DNT and TNT , at lower levels of concentrations ( ppb , ppt ) , the smell - prints will be less distinguishable and the statistical analysis of an integrated signal from multiple sensors with different catalytic properties will become essential .The extension of this method for multi - sensor detection will be considered in our future publications .", "label": "", "metadata": {}}
{"text": "One of the most complex problems of current sensor technology is the common issue of sensor drift due to the environmental conditions .Because of this , steady - state amplitude analysis has the potential to lead to false positives if the recognition algorithm training was conducted at a different humidity level than field conditions .This effect is especially well pronounced at low analyte concentrations , where drift becomes comparable with the sensor response .In contrast , the spectral analysis of the transient response is significantly more robust .In order to illustrate this point , vapor recognition using a transient response of a single chemiresistor was compared with recognition using the steady - state response of an integrated system of three chemiresistors with different thicknesses of sensing metal oxide layers .", "label": "", "metadata": {}}
{"text": "Water vapor was introduced in the ambient air flow to simulate varying levels of humidity using a standard chemical bubbler .The input for a single - sensor recognition system was in the form of 4 s exposures , while for the multi - sensory system sensors were exposed to analyte until they reached a steady - state .The extracted features for 16 exposures ( eight exposures to acetone and eight to ethanol ) for both configurations are shown in Figure 7a , b .Figure 7a shows the amplitude output of a multisensory system , and Figure 7b shows the sub - space of the first harmonic extracted from the transient response .", "label": "", "metadata": {}}
{"text": "By decreasing the amount of dimensions and projecting the data points into C-1 dimensional space where C is the number of classes , we maximize the separation between classes and minimize the separation within the classes .Figure 7c , d show the probability density for acetone and ethanol as functions of coordinate x that was obtained by transformation of coordinates according to Fisher 's criteria of LDA [ 3 , 17 ] .As it can be seen from the figure , the steady - state amplitude analysis leads to wide and overlapping distributions for two classes ( Figure 7c ) , while the harmonic analysis generates well - separated narrow peaks ( Figure 7d ) .", "label": "", "metadata": {}}
{"text": "Also , in order to provide a quantitative evaluation of the steady - state and harmonic analysis , we compared a parameter : .J . sum of standard deviations of the classes .Distance between the classes .which can be used to determine the discrimination power of the method [ 3 ] .The result of this comparison is shown in the Table 1 .Therefore , the variations in the level of humidity makes the separation of classes much less pronounced in the steady - state analysis , while through spectral analysis , the separation of classes remains much more stable .", "label": "", "metadata": {}}
{"text": "The application of spectral analysis to the response signals of conductometric sensors was discussed .The analysis was demonstrated on the example of an ALD - fabricated ZnO chemiresistor , upon exposure to short 0.1 s pulses of analytes .The techniques of signal extraction , enhancement , spectral analysis and reconstruction were demonstrated .The recognition of analytes was accomplished by separating them in multi - dimentional hyperspace of extracted spectral characteristics using Quadratic Discriminant Analysis .The method helps to overcome common problems like short - term sensor drift and limited amount of the extracted signal features .", "label": "", "metadata": {}}
{"text": "The method can be further developed for the integrated sensor arrays for recognition of more complex analytes .Acknowledgments .Authors would like to thank the Office of Naval Research ( grant # N00014 - 10 - 1 - 0282 ) for the support of this work .Conflict of Interest .The authors declare no conflict of interest .References .Handbook of Machine Olfaction : Electronic Nose Technology ; Pearce , T.C. , Schiffman , S.S. , Nagle , H.T. , Gardner , J.W. , Eds . ; Wiley - VCH : Weinheim , Germany , 2003 .", "label": "", "metadata": {}}
{"text": "Anal .Chem .2003 , 75 , 98A-105A. [ Google Scholar ] .Pattern Recognition and Machine Learning ; Bishop , C.M. , Nasrabadi , N.M. , Eds . ; Springer : New York , NY , USA , 2006 .Vladimir , D. ; Landon , O. ; Dewayne , S. ; Alexander , L. ; Alex , K. ; Pavel , B. ; Giancarlo , C. ; Timothy , C. ; Tej , P. ; Joseph , W. ; et al .ZnO coated nanospring - based chemiresistors .J. Appl .Phys .[ Google Scholar ] .", "label": "", "metadata": {}}
{"text": "Towards the nanospring - based artificial olfactory system for trace - detection of flammable and explosive vapors .Sens .Actuators B Chem .[ Google Scholar ] .Sensors 2012 , 12 , 5608 - 5622 .[ Google Scholar ] .Dobrokhotov , V.V. ; McIlroy , D.N. ; Norton , G.M. ; Abdelrahaman , R. ; Safir , A. ; Berven , C.A. Interaction of hybrid nanowire - nanoparticle structures with carbon monoxide .Nanotechnology 2009 , 20 , 135504 .[ Google Scholar ] .Dobrokhotov , V.V. ; McIlroy , D.N. ; Norton , M.G. ; Berven , C.A. Transport properties of hybrid nanoparticle - nanowire systems and their application to gas sensing .", "label": "", "metadata": {}}
{"text": "[ Google Scholar ] .Dobrokhotov , V. ; McIlroy , D.N. ; Grant Norton , M. ; Abuzir , A. ; Yeh , W.J. ; Stevenson , I. ; Pouy , R. ; Bochenek , J. ; Cartwright , M. ; Wang , L. ; et al .Principles and mechanisms of gas sensing by Gan - nanowires functionalized with gold nanoparticles .J. Appl .Phys .[ Google Scholar ] .Kolmakov , A. ; Klenov , D.O. ; Lilach , Y. ; Stemmer , S. ; Moskovits , M. Enhanced gas sensing by individual SnO 2 nanowires and nanobelts functionalized with Pd catalyst particles .", "label": "", "metadata": {}}
{"text": "[ Google Scholar ] .Sysoev , V.V. ; Joachim , G. ; Thomas , S. ; Evghenii , S. ; Andrei , K. A gradient microarray electronic nose based on percolating SnO 2 nanowire sensing elements .Nano Lett .[ Google Scholar ] .Sysoev , V.V. ; Ilya , K. ; Markus , F. ; Joachim , G. Temperature gradient effect on gas discrimination power of a metal - oxide thin - film sensor microarray .Sensors 2004 , 4 , 37 - 46 .[ Google Scholar ] .Sysoev , V.V. ; Bradly , K. ; Button , K.W. ; Serghei , D. ; Andrei , K. Towards the nanoscopic \" electronic nose \" : Hydrogen versus carbon monoxide discrimination with an array of individual metal oxide nano- and meso - wire sensors .", "label": "", "metadata": {}}
{"text": "[ Google Scholar ] .Doleman , B.J. ; Sanner , R.D. ; Severin , E.J. ; Grubbs , R.H. ; Lewis , N.S. Use of compatible polymer blends to fabricate arrays of carbon black - polymer composite vapor detectors .Anal .Chem .[ Google Scholar ] .Sotzing , G.A. ; Briglin , S.M. ; Grubbs , R.H. ; Lewis , N.S. Preparation and properties of vapor detector arrays formed from poly(3,4-ethylenedioxy)thiophene - Poly(styrene sulfonate)/insulating polymer composites .Anal .Chem .[ Google Scholar ] .Koscho , M.E. ; Grubbs , R.H. ; Lewis , N.S. Properties of vapor detector arrays formed through plasticization of carbon black - organic polymer composites .", "label": "", "metadata": {}}
{"text": "Chem .[ Google Scholar ] .Gutierrez - Osuna , R. Pattern analysis for machine olfaction : A review .IEEE Sens . J. 2002 , 2 , 189 - 202 .[ Google Scholar ] .Cosimo , D. ; Marco , L. ; Pietro , S. ; Krishna , C.P. On the study of feature extraction methods for an electronic nose .Sens .Actuators B Chem .[ Google Scholar ] .Gutierrez - Osuna , R. ; Nagle , H.T. ; Schiffman , S.S. Transient response analysis of an electronic nose using multi - exponential models .", "label": "", "metadata": {}}
{"text": "Actuators B Chem .[ Google Scholar ] .Alexander , V. ; Eduard , L. ; Eugenio , M. ; Corrado , D.N. ; Arnaldo , D'A. ; Xavier , C. Feature extraction of metal oxide gas sensors using dynamic moments .Sens .Actuators B Chem .[ Google Scholar ] .Mehmet , K. ; Muezzinoglua , A.V. ; Ramon , H. ; Nikolai , R. ; Mikhail , I. ; Rabinovich , A.S. ; Henry , D.I.A. Acceleration of chemo - sensory information processing using transient features .Sens .Actuators B Chem .[ Google Scholar ] .", "label": "", "metadata": {}}
{"text": "Proceedings of the 2009 IEEE International Conference on Technologies for Homeland Security , Boston , MA , USA , 11 - 12 May 2009 .Elam , J.W. ; Groner , M.D. ; George , S.M. Viscous flow reactor with quartz crystal microbalance for thin film growth by atomic layer deposition .Rev. Sci .Instrum .[ Google Scholar ] .George , S.M. ; Ott , A.W. ; Klaus , J.W. Surface chemistry for atomic layer growth .J. Phys .Chem .[ Google Scholar ] .Elam , J.W. ; George , S.M. Growth of ZnO / Al 2 O 3 alloy films using atomic layer deposition techniques .", "label": "", "metadata": {}}
{"text": "Mater .[ Google Scholar ] .Guziewicz , E. ZnO by ALD - advantages of the material grown at low temperature .Acta Phys .Polon .A 2009 , 116 , 814 - 817 .[ Google Scholar ] .Peter , B. Fourier Analysis of Time Series : An Introduction ; John Wiley and Sons : New York , NY , USA , 2003 .[ Google Scholar ] .Vergara , A. ; Vembu , S. ; Ayhan , T. ; Ryan , M.A. ; Margie , L.H. ; Ram\u00f3n , H. Chemical gas sensor drift compensation using classifier ensembles .", "label": "", "metadata": {}}
{"text": "Actuators B Chem .[ Google Scholar ] .Figure 1 .( c )A typical response curve of a metal oxide chemiresistor upon exposure to a combustible vapor ( d ) Stages of signal processing and pattern recognition .Figure 1 .( c )A typical response curve of a metal oxide chemiresistor upon exposure to a combustible vapor ( d ) Stages of signal processing and pattern recognition .Figure 6 .Visualization of the projections of 60-dimentional hyperspace ( a - c ) .Clouds of points corresponding to different analyte exposures in 3-D ( amplitude , frequency , phase ) coordinate systems , corresponding to the first ( a ) , second ( b ) and third ( c ) harmonics .", "label": "", "metadata": {}}
{"text": "Figure 6 .Visualization of the projections of 60-dimentional hyperspace ( a - c ) .Clouds of points corresponding to different analyte exposures in 3-D ( amplitude , frequency , phase ) coordinate systems , corresponding to the first ( a ) , second ( b ) and third ( c ) harmonics .Visualization of the quadratic discriminant analysis for the first ( d , h ) , second ( e , i ) and third ( g , j ) harmonics .Figure 7 .Separation of classes in the ( a ) hyperspace of steady - state responses of multi - sensory system ( b ) sub - space of the first harmonic extracted from the transient response .", "label": "", "metadata": {}}
{"text": "Coordinate x was obtained by transformation of coordinates according to Fisher 's criteria of LDA .Figure 7 .Separation of classes in the ( a ) hyperspace of steady - state responses of multi - sensory system ( b ) sub - space of the first harmonic extracted from the transient response .Probability density for acetone and ethanol for steady - state ( c ) and harmonic ( d ) analysis .Coordinate x was obtained by transformation of coordinates according to Fisher 's criteria of LDA .\u00a9 2013 by the authors ; licensee MDPI , Basel , Switzerland .", "label": "", "metadata": {}}
{"text": "Received : 4 May 2007 .Accepted : 10 August 2007 .This study reports the combination of multivariate techniques and pollen count analysis to classify honey samples accordingly to botanical sources , in samples from Uruguay .Honey samples from different botanical origins , namely Eucalyptu s spp .Principal component analysis ( PCA ) and linear discriminant analysis ( LDA ) were used to classify the honey samples accordingly to their botanical origin based on a pollen count . and Salix were 80 and 66 % correctly classified , respectively .The use of PCA and LDA combined with pollen identification proved useful in characterizing honey samples from different botanical origins .", "label": "", "metadata": {}}
{"text": "Este estudio reporta la combinaci\u00f3n de t\u00e9cnicas de an\u00e1lisis multivariado y de polen para clasificar el origen bot\u00e1nico de muestras de miel provenientes de Uruguay .Muestras de miel de diversos or\u00edgenes bot\u00e1nicos , a saber Eucaliptus spp .An\u00e1lisis de componentes principales ( APC ) y de discriminantes lineales ( ADL ) fueron utilizados para clasificar las muestras de la miel de acuerdo a su origen bot\u00e1nico basado en el conteo de polen .Las muestras de miel que conten\u00edan m\u00e1s de un 70 % de polen de Eucaliptus , Lotus y Scutia buxifolia fueron clasificadas correctamente en un 100 % de los casos .", "label": "", "metadata": {}}
{"text": "y Salix fueron clasificadas correctamente en un 80 y 66 % de los casos .El uso de APC y de ADL combinado con la identificaci\u00f3n del polen prob\u00f3 ser una herramienta \u00fatil para caracterizar muestras de miel de diversos origenes .Palabras clave : miel , Uruguay , componentes principales , an\u00e1lisis de discriminantes , an\u00e1lisis de polen .Scientists in the food and beverage industries are interested in identifying the main changes in process that may lead to a change in quality or compromises in any ingredient or finished products .Food authenticity issues in the form of adulteration and improper description have been around for a long time .", "label": "", "metadata": {}}
{"text": "Several factors contribute to the quality properties of honey , such as high osmotic pressure , lower water activity , low pH , and low protein content , among others ( Anklam , 1998 ; Bogdanov , 1999 ) .The authenticity of honey has two aspects , one related to honey production , and the other to description , such as geographic and botanical origin ., 2003 ; Serrano et al .Spectroscopic techniques , such as mid infrared ( MIR ) , near infrared ( NIR ) and Raman spectroscopy were also used to determine chemical characteristics ( e.g. , sugars ) and contamination in honey samples from different origins ( Cozzolino and Corbella , 2005 ; Bertelli et al .", "label": "", "metadata": {}}
{"text": "Quality control methods , in conjunction with multivariate statistical analysis , have been found to be able to classify honey from different geographic regions , detect adulteration and describe chemical characteristics ( Cordella et al . , 2002 ; 2003 ; Marini et al ., 2004 ; Devillers et al .Both , pollen identification and count have been used for authentication of honey samples accordingly to floral type , although there are difficulties in assuring a correct assignment of their origin ( Serrano et al .However , due to its simplicity , this technique has been used extensively to identify different types of honey samples from different botanical origins .", "label": "", "metadata": {}}
{"text": "It helps to look at the sample as a whole ( holistically ) and not just at a single component , allowing to untangle all the complicated interactions between the constituents and understand their combined effects on the whole matrix .The aim of this work was to explore the use of multivariate techniques applied to pollen count analysis to classify honey samples collected in Uruguay according to their botanical origin .MATERIALS AND METHODS .Samples were harvested from different locations across Uruguay , South America .Honey samples were collected from stainless steel drums ( 300 kg weight ) directly provided by the beekeepers .", "label": "", "metadata": {}}
{"text": "All samples were unheated and were analysed no later than four weeks after extraction from the hives by the beekeepers .Collection sites were selected to include different botanical origins , soil characteristics and regions .In Uruguay , species - specific floral types of honey are obtained by beekeepers , pursuing a particular floral species for honey production , through controlling the foraging of their honeybees , Apis mellifera ( Hymenoptera : Apidae ) , by hive location ( near to one species of plant ) .Information about season , hive location and available floral sources were collected by asking the beekeepers to accurately identify the floral source of the honey samples .", "label": "", "metadata": {}}
{"text": "Thus , five groups were defined , namely Eucalyptus spp .Honey samples belonging to the Myrtaceae , Scutia and Salix species were defined as Monte ( bush honey ) by the beekeepers , however they were analysed separately for the purpose of this study .Additionally , one of the honey samples belonging to the Lotus spp .group had a high content of pollen from clover ( Trifolium spp . )Nevertherless , it was included in this group for statistical analysis .Statistical and multivariate analysis Pollen count was analysed by means of unsupervised and supervised pattern recognition techniques , namely principal component analysis ( PCA ) and linear discriminant analysis ( LDA ) , respectively .", "label": "", "metadata": {}}
{"text": "PCA is a mathematical procedure for resolving sets of data into orthogonal components ( principal components ) whose linear combinations approximate the original data to any desired degree of accuracy , in such a way the data is presented graphically in those axes ( Naes et al .PCA was used to derive the first principal components from the data , and used in further analysis to examine the grouping of samples , outliers and in order to visualise the relative distribution of the honey samples according to their botanical origin .PCA was performed on the pollen count data , after centering and auto - scaling of the variables ( Naes et al .", "label": "", "metadata": {}}
{"text": "Each function allows the computation of classification scores for each case with respect to each group ( Otto , 1999 ; Naes et al .Cross validation ( leave one out ) was used as a validation method to evaluate the performance and robustness of the classification models developed .The Unscrambler software version 7.5 ( CAMO ASA , 1996 ) was used to develop the PCA models , while the LDA models were developed using the JMP software ( SAS Institute , 2002 ) .RESULTS AND DISCUSSION .The score plot of the first two principal components ( PC1 and PC2 ) for the classification of honey samples according to their botanical origin is shown in Figure 1 .", "label": "", "metadata": {}}
{"text": "In particular , it was observed for samples labelled as Myrtaceae and Scutia spp .These honey samples were identified as Monte ( bush honey ) by the beekeepers , lacking a dominant pollen from specific plant species ( e.g. , 40 % or more of pollen from Scutia spp . , 20 % or more of pollen from Myrtaceae spp . )The first three PCs accounted for more than 96 % of the variation in the honey samples analysed , where PC1 explains 71 % , PC2 18 % and PC3 7 % of the variation related to the different sources of pollen contained in the honey samples , respectively .", "label": "", "metadata": {}}
{"text": "Principal component score plot of honey samples from 2005 based on pollen content .The eigenvectors for the first three PCs used to develop the PCA plot are shown in Figure 2 .The highest eigenvector in PC1 is explained by the high percentage of pollen of Eucalyptus , whilst the highest eigenvector in PC2 is explained by the highest percentage of pollen of Lotus and Trifolium , whilst PC3 is explained by the highest percentage of Trifolium .Although no clear separation was observed among the honey samples , the PCA scores were related to different botanical origins .", "label": "", "metadata": {}}
{"text": "Even honeys classified as predominantly belonging to one floral origin could also be , to some extent , considered blends or mixtures of different species .The classification results obtained using LDA are shown in Table 1 .Honey samples belonging to Scutia , Eucalyptus and Lotus were 100 % correctly classified .On the other hand , honey samples identified as Salix and Myrtaceae spp . were 80 and 66 % correctly classified , respectively .Figure 2 .Eigenvectors for the first three principal components of honey samples from 2005 based on pollen content .In developing classification or discrimination models , it is known that when more properties ( variables ) are used for classification , more objects ( samples ) are needed to get a robust model .", "label": "", "metadata": {}}
{"text": "Honey samples being labelled as Eucalyptus and Lotus spp . showed that the pollen of these species is predominant in the honey samples analysed .However , in samples labelled either as Myrtaceae and Salix spp . , the blend with other botanical sources makes a correct classification difficult .This is explained by the fact that Myrtaceae and Salix spp . are not single species , and have a diverse pollen source compared to the other three types analysed .In general , supervised classification ( e.g. , discriminant analysis ) is used to test similarity of known authentic samples .", "label": "", "metadata": {}}
{"text": "The limited number of samples in some of the honey floral categories studied in the present work led us to be cautious about extrapolating these results to other conditions .The combination of multivariate techniques with pollen count have made it possible to ascertain , on a rigorous , scientific basis , the apicultural importance of the different plant species , whereas previously this evaluation was based on empirical general field observations made by beekeepers .CONCLUSIONS .The results obtained in this study showed the potential of combining multivariate techniques ( LDA and PCA ) with pollen count to classify the botanical origin of honey samples produced in Uruguay .", "label": "", "metadata": {}}
{"text": "Further experiments need to be carried out in order to address questions about misclassification , by using larger data sets or by incorporating authentic samples of monofloral honey samples .ACKNOWLEDGMENTS .The authors acknowledge the technical assistance of Mr. G. Ramallo at the Apiculture Project ( INIA La Estanzuela ) for the honey chemical analysis and the beekeepers who provided the honey samples .The work was supported by INIA ( Instituto Nacional de Investigaci\u00f3n Agropecuaria ) , Uruguay .LITERATURE CITED .Anapuma , D. , K.K. Bhat , and V.K. Sapna .Sensory and physico - chemical properties of commercial samples of honey .", "label": "", "metadata": {}}
{"text": "[Links ] .Anklam , E. 1998 .A review of the analytical methods to determine the geographical and botanical origin of honey .Food Chem .[Links ] .Ashurst , P.R. , and M.J. Dennis .Food authentication .399p. Blackie Academics and Professionals , London , UK .[Links ] .Bertelli , D. , M. Plessi , A.G. Sabatini , M. Lolli , and F. Grillenzoni 2007 .Classification of Italian honeys by mid - infrared diffuse reflectance spectroscopy ( DRIFTS ) .Food Chem .[Links ] .Bogdanov , S. 1999 .", "label": "", "metadata": {}}
{"text": "Bee World 90:61 - 69 .[Links ] .CAMO Process AS .The Unscrambler , version 7.5 .CAMO Process AS , Oslo , Norway .[Links ] .Cordella , Ch . , J.S. Militao , M - C. Clement , and D. Cabrol - Bass .Honey characterization and adulteration detection by pattern recognition on HPAEC - PAD profiles .Honey floral species characterization .J. Agric .Food Chem .[Links ] .Cordella , Ch . , I. Moussa , A - C. Martel , N. Sbirrazzuoli , and L. Lizzani - Cuvelier .", "label": "", "metadata": {}}
{"text": "J. Agric .Food Chem .[Links ] .Cozzolino , D. , and Corbella , E. 2005 .The use of visible and near infrared spectroscopy to classify the floral origin of honey samples produced in Uruguay .J. Near Infrared Spectros .[Links ] .Devillers , J. , M. Morlot , M.H. Pham - Delegue , and J.C. Dore .Classification of monofloral honeys based on their quality control data .Food Chem .[Links ] .Hermosin , I. , R.M. Chicon , and M.D. Cabezudo .Free amino acid composition and botanical origin of honey .", "label": "", "metadata": {}}
{"text": "[Links ] .SAS Institute .JMP Software .Version 5.01 , Cary , North Caroline , USA .[Links ] .Latorre , M.J. , R. Pe\u00f1a , S. Garc\u00eda , and C. Herrero .Authentication of Galician ( N.W. Spain ) honey by multivariate techniques based on metal content data .Analyst 125:307 - 310 .[Links ] .Latorre , M.J. , R. Pe\u00f1a , C. Pita , A. Botana , S. Garc\u00eda , and C. Herrero .Chemometric classification of honey samples according to their type .II .Metal content data .", "label": "", "metadata": {}}
{"text": "[Links ] .Marini , F. , A.L. Magri , F. Balestrieri , F. Fabretti , and D. Marinia .Supervised pattern recognition applied to the discrimination of the floral origin of six types of Italian honey samples .Anal .Chim .Acta 515:117 - 125 .[Links ] .Mateo , R. , and F. Bosch - Reig .Classification of Spanish unifloral honeys by discriminant analysis of electrical conductivity , color , water content , sugars and pH. J. Agric .Food Chem .[Links ] .Naes , T. , T. Isaksson , T. Fearn , and T. Davies .", "label": "", "metadata": {}}
{"text": "344 p. NIR Publications , Chichester , UK .[Links ] .Otto , M. 1999 .Chemometrics .314 p. Wiley - VCH .Weinheim , Germany .[Links ] .Serrano , S. , M. Villarejo , R. Espejo , and M. Jodral .Chemical and physical parameters of Andalusian honey : classification of Citrus and Eucalyptus honeys by discriminant analysis .Food Chem .[Links ] .Terrab , A. , M.L. Escudero , M.L. Gonzalez - Miret , and F.J. Heredia .Colour characteristics of honey as influenced by pollen grain content : a multivariate study .", "label": "", "metadata": {}}
{"text": "Food Agric .[Links ] A language model is a function , or an algorithm for learning such a function , that captures the salient statistical characteristics of the distribution of sequences of words in a natural language , typically allowing one to make probabilistic predictions of the next word given preceding ones .In the context of learning algorithms , the curse of dimensionality refers to the need for huge numbers of training examples when learning highly complex functions .When the number of input variables increases , the number of required examples can grow exponentially .The curse of dimensionality arises when a huge number of different combinations of values of the input variables must be discriminated from each other , and the learning algorithm needs at least one example per relevant combination of values .", "label": "", "metadata": {}}
{"text": "If a human were to choose the features of a word , he might pick grammatical features like gender or plurality , as well as semantic features like animate \" or invisible .With a neural network language model , one relies on the learning algorithm to discover these features , and the features are continuous - valued ( making the optimization problem involved in learning much simpler ) .The basic idea is to learn to associate each word in the dictionary with a continuous - valued vector representation .Each word corresponds to a point in a feature space .", "label": "", "metadata": {}}
{"text": "The hope is that functionally similar words get to be closer to each other in that space , at least along some directions .A sequence of words can thus be transformed into a sequence of these learned feature vectors .The neural network learns to map that sequence of feature vectors to a prediction of interest , such as the probability distribution over the next word in the sequence .The advantage of this distributed representation approach is that it allows the model to generalize well to sequences that are not in the set of training word sequences , but that are similar in terms of their features , i.e. , their distributed representation .", "label": "", "metadata": {}}
{"text": "Because many different combinations of feature values are possible , a very large set of possible meanings can be represented compactly , allowing a model with a comparatively small number of parameters to fit a large training set .The dominant methodology for probabilistic language modeling since the 1980 's has been based on n - gram models ( Jelinek and Mercer , 1980;Katz 1987 ) .See ( Manning and Schutze , 1999 ) for a review .These non - parametric learning algorithms are based on storing and combining frequency counts of word subsequences of different lengths , e.g. , 1 , 2 and 3 for 3-grams .", "label": "", "metadata": {}}
{"text": "Furthermore , a new observed sequence typically will have occurred rarely or not at all in the training set .The three estimators can then be combined , either by choosing only one of them in a particular context ( e.g. , based the frequency counts of the subsequences ) , or by combining them ( usually in a linear mixture ) .A large literature on techniques to smooth frequency counts of subsequences has given rise to a number of algorithms and variants .Distributed representations .The idea of distributed representation has been at the core of the revival of artificial neural network research in the early 1980 's , best represented by the connectionist bringing together computer scientists , cognitive psychologists , physicists , neuroscientists , and others .", "label": "", "metadata": {}}
{"text": "An early discussion can also be found in the Parallel Distributed Processing book ( 1986 ) , a landmark of the connectionist approach .For example , with \\(m\\ ) binary features , one can describe up to \\(2^m\\ ) different objects .The idea is that the brain would be learning and using such representations because they help it generalize to new objects that are similar to known ones in many respects .A distributed representation is opposed to a local representation , in which only one neuron ( or very few ) is active at each time , i.e. , as with grandmother cells .", "label": "", "metadata": {}}
{"text": "Hence the number of units needed to capture the possible sequences of interest grows exponentially with sequence length .Figure 1 : Example of 2-dimensional distributed representation for words obtained in ( Blitzer et al 2005 ) .In ( Bengio et al 2001 , Bengio et al 2003 ) , it was demonstrated how distributed representations for symbols could be combined with neural network probability predictions in order to surpass standard n - gram models on statistical language modeling tasks .Experiments on related algorithms for learning distributed representations of words have shown that the learned features make sense linguistically ( Blitzer et al 2005 ) .", "label": "", "metadata": {}}
{"text": "Vector \\(C_k\\ ) contains the learned features for word \\(k\\ .Let us denote \\(\\theta\\ ) for the concatenation of all the parameters .The capacity of the model is controlled by the number of hidden units \\(h\\ ) and by the number of learned word features \\(d\\ .\\ ) .Figure 2 : Architecture of neural net language model introduced in ( Bengio et al 2001 ) .Note that the gradient on most of \\(C\\ ) is zero ( and need not be computed or used ) for most of the columns of \\(C\\ : \\ ) only those corresponding to words in the input subsequence have a non - zero gradient .", "label": "", "metadata": {}}
{"text": "Computational issues and applications .The experiments have been mostly on small corpora , where training a neural network language model is easier , and show important improvements on both log - likelihood and speech recognition accuracy .Resampling techniques may be used to train the neural network language model on corpora of several hundreds of millions of words ( Schwenk and Gauvain 2004 ) .It has been noted that neural network language models and n - gram based language models make errors in different places : hence simply averaging the probabilistic predictions from the two types of models often yields improved predictions .", "label": "", "metadata": {}}
{"text": "Schwenk and Gauvain ( 2004 ) were able to build systems in which the neural network component took less than 5 % of real - time ( the duration of the speech being analyzed ) .English vocabulary sizes used in natural language processing applications such as speech recognition and translation involve tens of thousands , possibly hundreds of thousands of different words .This is much more than the number of operations typically involved in computing probability predictions for n - gram models .Several researchers have developed techniques to speed - up either probability prediction ( when using the model ) or estimating gradients ( when training the model ) .", "label": "", "metadata": {}}
{"text": "Another idea is to decompose the probability computation hierarchically , using a tree of binary probabilistic decisions , so as to replace \\(O(N)\\ ) computations by \\(O(\\log N)\\ ) computations ( Morin and Bengio 2005 ) .Yet another idea is to replace the exact gradient by a stochastic estimator obtained using a Monte - Carlo sampling technique ( Bengio and Senecal 2008 ) .Challenges ahead .In addition to the computational challenges briefly described above , several weaknesses of the neural network language model are being worked on by researchers in the field .One of them is the representation of a fixed - size context .", "label": "", "metadata": {}}
{"text": "This learned summarization would keep higher - level abstract summaries of more remote text , and a more detailed summary of very recent words .A fundamental obstacle to progress in this direction has to do with the diffusion of gradients through long chains of non - linear transformations , making it difficult to learn long - term dependencies ( Bengio et al 1994 ) in sequential data .Another weakness is the shallowness of the current model and the difficult optimization problem of training a neural net language model .For a discussion of shallow vs deep architectures , see ( Bengio and LeCun 2007 ) .", "label": "", "metadata": {}}
{"text": "There remains a debate between the use of local non - parametric methods based on n - grams , and methods based on more compact and distributed representations such as neural net language models .Optimizing the latter remains a difficult challenge .In addition , it could be argued that using a huge training set ( e.g. , all the text in the Web ) , one could get n - gram based language models that appear to capture semantics correctly .However , in the light of the exponential nature of the curse of dimensionality , one should also ask the question of how much closer to human understanding of language one can get by multiplying n - gram training corpora size by a mere 100 or 1000 .", "label": "", "metadata": {}}
{"text": "Jelinek , F. and Mercer , R.L. ( 1980 ) Interpolated Estimation of Markov Source Parameters from Sparse Data .Pattern Recognition in Practice , Gelsema E.S. and Kanal L.N. eds , North - Holland .pp .381 - 397 .Hinton , G.E. ( 1986 )Learning Distributed Representations of Concepts .Proceedings of the Eighth Annual Conference of the Cognitive Science Society:1 - 12 .Rumelhart , D. E. and McClelland , J. L ( 1986 ) Parallel Distributed Processing : Explorations in the Microstructure of Cognition .MIT Press , Cambridge .Katz , S.M. ( 1987 )", "label": "", "metadata": {}}
{"text": "IEEE Transactions on Acoustics , Speech and Signal Processing 3:400 - 401 .Hinton , G.E. ( 1989 )Connectionist Learning Procedures .Artificial Intelligence J. 40:185 -234 .Abstract .In this paper we present a novel theory of the cognitive and neural processes by which adults learn new spoken words .This proposal builds on neurocomputational accounts of lexical processing and spoken word recognition and complementary learning systems ( CLS ) models of memory .We review evidence from behavioural studies of word learning that , consistent with the CLS account , show two stages of lexical acquisition : rapid initial familiarization followed by slow lexical consolidation .", "label": "", "metadata": {}}
{"text": "We review behavioural and neuroscientific evidence consistent with this account , including a meta - analysis of PET and functional Magnetic Resonance Imaging ( fMRI ) studies that contrast responses to spoken words and pseudowords .From this meta - analysis we derive predictions for the location and direction of cortical response changes following familiarization with pseudowords .This allows us to assess evidence for learning - induced changes that convert pseudoword responses into real word responses .Results provide unique support for the CLS account since hippocampal responses change during initial learning , whereas cortical responses to pseudowords only become word - like if overnight consolidation follows initial learning .", "label": "", "metadata": {}}
{"text": "Many of us ' google ' information on the Internet , looking for articles and commentary from influential ' blog ' writers or ' bloggers ' ; activities and words that have become increasingly common in the last decade .There are more Google hits for ' blog ' than for ' tv ' ( 2.3 billion ) and ' science ' ( 0.78 billion ) .In this paper we examine the neurocomputational processes by which new words such as ' blog ' come to achieve their status as familiar and meaningful units stored in the brains of language users .", "label": "", "metadata": {}}
{"text": "Isolated representations of new words are initially encoded like other novel experiences as ' episodic ' memories of their first occurrences .These representations are supported by medial temporal lobe memory systems , functionally and neurally distinct from ( ii ) the neo - cortical representations that support long - term retention of words .Stable cortical representations are derived from multiple encounters with new words by consolidation processes that abstract away from the episodic representations that encode specific occurrences of novel words .Thus two distinct stages of learning and representation ( initial episodic and subsequent lexical ) are associated with the acquisition of new words .", "label": "", "metadata": {}}
{"text": "The goal of the current paper is therefore to develop a cognitive and neuroscientific account of word learning that reflects the computational constraints proposed by general accounts of memory processes .By integrating this framework with the specific computational demands of the perception of spoken language we can make detailed behavioural and neural predictions concerning processes involved in word learning .While the majority of this paper is focused on the acquisition of novel spoken rather than written words , our goal in developing this account is to achieve a broad coverage of phenomena that are relevant for word learning in general .", "label": "", "metadata": {}}
{"text": "We first explore the complementary learning systems ( CLS ) model ( McClelland et al .1995 ) , which partitions memory into hippocampal and neocortical components .These two systems contribute differentially to initial acquisition of episodic memories , and subsequent long - term retention , with transfer of information between these systems through offline consolidation .In the second section , we consider predictions from CLS accounts concerning the acquisition of new spoken words .We will propose specific computational signatures of processes supported by rapid , hippocampal learning as distinct from slower neocortical learning mechanisms .Of particular interest , here , is the proposal that learning involves overnight , sleep - associated consolidation processes to mediate between fast - learning hippocampal and slow - learning neocortical systems .", "label": "", "metadata": {}}
{"text": "Next we will review behavioural , neuropsychological and functional imaging evidence relating to this dual - process account .We begin by assessing behavioural evidence for two distinct stages of word learning .A particular focus of recent behavioural research has been to explore cognitive processes such as lexical competition that are unique to familiar words .Consistent with the CLS accounts we review evidence that newly learned words only become effective lexical competitors after offline consolidation .The next two sections review neuropsychological and functional imaging evidence for the involvement of two distinct neural systems in the medial temporal lobe and neocortex in word learning .", "label": "", "metadata": {}}
{"text": "Evidence that the medial temporal lobe contributes to initial word learning is also provided by functional imaging studies in which participants are scanned while learning new words .We then review evidence for cortical involvement in word recognition and learning .A particular focus for the CLS account is evidence from functional brain imaging studies in which neural responses are measured at different stages during the acquisition of novel words .Interpretation of these findings requires background information on the cortical systems that respond differently to familiar and unfamiliar spoken words .We therefore report a meta - analysis of functional imaging studies that compare words and pseudowords and test predictions derived from this meta - analysis for changes in neocortical responses to pseudowords following initial learning and consolidation .", "label": "", "metadata": {}}
{"text": "The cls model .The CLS model has much in common with other accounts of memory that invoke distinct learning systems specialized for different types of memory ( e.g. procedural versus declarative , Squire 1992 ; semantic versus episodic , Tulving 1972 ) .However , the CLS account goes beyond these traditional descriptions by considering the computational properties of neural networks that learn from experience .An important distinction for network models is whether learned information is stored in independent , sparse codes ( in which distinct memories have little or no overlap in their neural representations ) , or as overlapping , distributed representations that capture the similarity structure of specific domains of knowledge .", "label": "", "metadata": {}}
{"text": "These two forms of learning are best achieved by computational mechanisms that produce sparser , more independent representations and more overlapping , distributed representations , respectively .The CLS account proposes that sparse representations are rapidly and efficiently learned by the hippocampus and medial temporal lobe systems whereas overlapping , distributed representations are more slowly learned by the neocortex .Hence , amnesia caused by lesions to the hippocampus results in damage to learning mechanisms that are required to encode experiences rapidly into memory .Conversely , those aspects of memory function that are preserved in amnesic patients ( such as repetition priming or motor learning ) , arise from the operation of neocortical learning processes independent of the hippocampus .", "label": "", "metadata": {}}
{"text": "As we have described , the computational properties of two distinct forms of connectionist learning algorithm are central to the CLS account .The motivation for these two forms of learning is a consideration of the strengths and limitations of neural networks taught using gradient descent learning algorithms .The parallel distributed processing ( PDP , Rumelhart & McClelland 1986 ) approach to connectionist modelling of psychological processes commonly makes use of hidden units to mediate between input and output representations .These three - layer networks are trained to map from input to output by implementing gradual weight changes in the connections , using an algorithm such as backpropagation ( Rumelhart et al .", "label": "", "metadata": {}}
{"text": "As McClosky & Cohen ( 1989 ) demonstrated , a dichotomous shift in the training patterns can lead to ' catastrophic interference ' , in which learning of new mappings eliminates previously learned mappings ( see French 1999 for discussion ) .Learning of new associations in humans typically produces a moderate reduction in recall of A - B pairings , but in the connectionist networks , the effect of the new mappings was to essentially erase the network 's memory for the original mapping .The CLS model ( McClelland et al .1995 ; O'Reilly & Rudy 2000 ; Norman & O'Reilly 2003 ) provides a potential solution to this stability - plasticity dilemma ( Carpenter & Grossberg 1988 ) .", "label": "", "metadata": {}}
{"text": "This network has the ability to retain stable memories for long periods , despite changes in the form of the input ( i.e. to generalize ) , and the structure of the network ( i.e. robustness to damage ) .A second , hippocampal , system provides plasticity and can acquire new episodes without interference from previously or subsequently learned knowledge .This network is distinguished by its use of more sparse or near - localist representations , allowing representational independence and a means for swift learning of new patterns without overwriting existing knowledge .These rapidly learned representations in the hippocampal system can then be used to support slower , interleaved learning within the cortical system .", "label": "", "metadata": {}}
{"text": "2003 ; Atallah et al .Recent instantiations of the CLS model also incorporate more neurobiologically realistic learning rules that can be implemented using only local connections , and weight - update schemes ( O'Reilly 1996 ) .Nonetheless , the fundamental distinction between neocortical and hippocampal systems has not been substantially altered in recent descriptions and simulations .In terms of interaction between the two systems , McClelland et al .( 1995 ) suggested that a process of offline reinstatement of hippocampal memories drives further learning in the neocortex and a gradual reduction in the dependence of the memory on the hippocampus .", "label": "", "metadata": {}}
{"text": "In combination , these properties are invoked as an explanation of hippocampal amnesia .The reliance on the hippocampal network for the initial encoding and reinstantiation of episodic memory explains why amnesics are generally unable to retain such memories .On the other hand , memories that are formed gradually over the course of many different exposures , such as procedural skills , are more amenable to learning via the neocortical route despite the absence of short - term hippocampal storage .Once again , this fits with the classic description of learning abilities in amnesics ( e.g. Squire 1992 ) , although interestingly evidence of learning may not be restricted to non - declarative knowledge if the test of retention is chosen carefully .", "label": "", "metadata": {}}
{"text": "Thus , new declarative knowledge should be processed by the neocortical route as well as the hippocampal route even though the effect of the neocortical exposure may be limited , given the gradual nature of learning in that system .Bayley et al .( 2008 ) tested the prediction that some limited knowledge can be supported solely through neo - cortical learning in two amnesics with near complete damage to the hippocampus and associated medial temporal lobe structures .Previous research had suggested that these amnesics showed no memory of post - onset facts and faces in conventional tests of recognition or recall ( Bayley & Squire 2005 ) .", "label": "", "metadata": {}}
{"text": "This result fits with the idea that the neocortex can incorporate new declarative information to some extent , even when interactions with the hippocampal system are unavailable ( see also Duff et al .We will return to this question in \u00a7 4 where we consider the impact of hippocampal lesions on word learning .A final crucial prediction of the CLS account relates to retrograde amnesia .Hippocampal amnesics typically reveal impaired performance on recall of memories prior to the onset of brain damage , with the severity of the impairment reducing as the time between memory establishment and amnesia onset increases ( Ribot 1882 ; Kapur & Brooks 1999 ) .", "label": "", "metadata": {}}
{"text": "2003 ; Tse et al .( b ) Sleep and the CLS model .Reinstatement of hippocampal memories in order to strengthen neocortical representation was considered by McClelland et al .( 1995 , p. 424 ) to involve ' active rehearsal , reminiscence , and other inactive states including sleep ' .The potential involvement of sleep in the transfer process was motivated by research on hippocampal place cells in rats .Wilson & McNaughton ( 1994 ) ; see also Skaggs & McNaughton ( 1996 ) correlated firing rates of hippocampal cells responding to particular locations during activity with the firing rates of those same cells in subsequent slow - wave sleep ( SWS ) .", "label": "", "metadata": {}}
{"text": "Norman et al .( 2005 ) elaborated on a potential role for sleep in the CLS model .They argued that sleep provides an opportunity for both hippocampal replay , and also for restructuring / strengthening memories via an oscillating learning algorithm ( Norman et al .These offline learning processes during sleep are argued to play a critical role in training neocortical systems - indeed , separate ' wake ' and ' sleep ' phases are central to neural network learning algorithms that include biologically plausible forms of error - driven training ( O'Reilly 1996 ) .In the last 10 years a wealth of further neural evidence has amassed in support of some link between sleep and consolidation of hippocampal memories ( e.g. Cantero et al .", "label": "", "metadata": {}}
{"text": "These advances have been paralleled in behavioural data , although this area remains controversial because of the many potential confounds involved in sleep research .For example , a study that shows superior performance on a memory task after overnight sleep as opposed to an equivalent time awake during the day may be confounded with time - of - day effects on performance ( Keisler et al .If , on the other hand , time of day effects are controlled for by comparing overnight sleep with sleep deprivation overnight , then other confounds are possible relating to the effects of sleep deprivation .", "label": "", "metadata": {}}
{"text": "It is relatively uncontroversial that aspects of procedural and perceptual ( non - declarative ) performance can improve following sleep .For example , Karni et al .( 1994 ) used selective sleep deprivation to show that visual texture discrimination was benefited by REM sleep but not by SWS .Similarly , Fenn et al .( 2003 ) demonstrated a sleep - associated improvement in the ability to interpret synthesized speech .If listeners practised the task in the morning , the passing of time awake would lead to deterioration in perceptual skill by the evening .Thus , the change overnight could be thought of as a recovery of the originally strong performance ( cf .", "label": "", "metadata": {}}
{"text": "Other studies found similar performance enhancements across a range of non - declarative tasks ( see Walker 2005 ; Born et al .Until recently , the situation for declarative memory was less clear - cut , with a mixture of positive and negative results roughly balancing each other out ( cf .Stickgold & Walker 2005 ) .However , recent studies show more robust effects of sleep , at least for some types of declarative memory .Plihal & Born ( 1997 ) once again used selective deprivation to show an effect on paired - associate recall , although in this case the benefit was found for participants who were allowed SWS .", "label": "", "metadata": {}}
{"text": "( 2002 ) went further , demonstrating that paired - associate learning prior to sleep influenced neural activity during sleep .Specifically , EEG measurements of sleep spindle activity ( short bursts of higher frequency waves ) showed a rise associated with declarative learning in the non - REM component of early sleep .Marshall et al .( 2006 ) provided an even clearer link between non - REM sleep and declarative memory by showing that artificially enhancing the oscillations in SWS using transcranial oscillating potentials led to improved retention of paired associates following sleep ( see also Ellenbogen et al .", "label": "", "metadata": {}}
{"text": "These and other studies have led to the conclusion that sleep benefits the consolidation of both declarative and non - declarative memories , with REM sleep implicated in the case of procedural and perceptual abilities and SWS involved in the consolidation of declarative memory .However , this dichotomy may be too simplistic , and it is important to note that learning may well involve both types of memory , either independently or interactively .Some recent studies have demonstrated that sleep can help to alter the form of memories , leading to new insights ( Wagner et al .", "label": "", "metadata": {}}
{"text": "2006 ) , possibly through greater linkage between hippocampal and neocortical systems .Similarly , Ellenbogen et al .( 2007 ) argue that sleep offers a means of integrating new information .In their case sleep facilitated the transitive inference to link pairs of premises .Applying the cls model to spoken word learning .Based on the above review , we can outline how word learning might operate if it makes use of CLS principles .We begin by specifying the functional and anatomical organization of the neocortical networks involved in recognising spoken words .A particular focus here is a computational account of the perception and identification of spoken words constructed using a distributed connectionist model ( the Distributed Cohort Model , Gaskell & Marslen - Wilson 1997 , 1999 ) .", "label": "", "metadata": {}}
{"text": "All these forms of behaviour arise as emergent properties of a neural network model in which multiple , similar words are stored in overlapping neural representations .We therefore propose this model as an approximation to the neocortical component of the CLS account of word learning .In this section we begin by laying out the structure of the model , and the parallels between this neural network account and the anatomical organization of the cortical networks involved in perceiving speech .We then move onto a discussion of how CLS principles can be incorporated to provide an account of word learning .", "label": "", "metadata": {}}
{"text": "The distributed cohort model and neocortical networks for speech perception .The Distributed Cohort Model ( Gaskell & Marslen - Wilson 1997 ) uses a simple recurrent network ( Elman 1990 ) to map from a sequence of acoustic - phonetic features representing ongoing speech input onto a distributed representation of lexical knowledge .1995 ; Chi et al .From these features , both the model and current neuroscientific accounts postulate hierarchically organized processing pathways that extract different forms of abstract linguistic representation from ongoing speech input ( see figure 1 for a depiction of the Distributed Cohort Model and corresponding regions of the temporal lobe ) .", "label": "", "metadata": {}}
{"text": "( a ) Left temporal lobe regions involved in perceiving and comprehending spoken words ( based on Hickok & Poeppel 2004 ; Davis & Johnsrude 2007 ) and their interactions with medial temporal systems for word learning .( b )Functional organization of the Distributed Cohort Model ( Gaskell & Marslen - Wilson 1997 , 1999 ; depicted within the grey box ) with additional connections to hippocampal / episodic memory system for learning new words .In both diagrams , rapid cortico - cortico connections are shown with solid lines , and slower , cortico - hippocampal connections are shown with broken lines .", "label": "", "metadata": {}}
{"text": "In mapping sequences of speech segments onto lexical representations , the Distributed Cohort Model requires short - term storage so that information in the speech input can be accumulated over time , and sequences of phonemes can be discriminated .This is achieved in network simulations by including recurrent connections at the hidden unit level such that the model can take into account both the current input , and a representation of prior input during perception .These recurrent connections provided sufficient short - term storage for effective lexical processing in simulations thus far .However , in order to recognize temporally extended sequences , it might be that more complex computational architectures in which there is greater duplication of representations over time or a hierarchy of perceptual representations with progressively longer temporal receptive fields would be required .", "label": "", "metadata": {}}
{"text": "2005 ; Price et al .2005 ; Davis & Johnsrude 2007 ) .The short - term storage provided by auditory echoic memory plays a particular role in the perception of spoken sentences ( Mattys 1997 ) hence the frequent observation of anterior temporal activation in brain imaging studies of sentence comprehension ( Scott et al .2000 ; Davis & Johnsrude 2003 ; Humphries et al .One distinctive property of the lexical representations that are the target output for the Distributed Cohort Model is that they separate the phonological form and the meaning of spoken words .", "label": "", "metadata": {}}
{"text": "The semantic output is more critical for making lexical / semantic decisions , producing semantic priming and for simulating tasks that involve access to word meaning .In contrast , the phonological output is more critical for making phonological decisions , repeating spoken words and non - words and in simulations of cross - modal repetition priming ( Gaskell & Marslen - Wilson 1997 , 1999 ) .This separation of lexical identification into two distinct processes has clear parallels in current neuroanatomical accounts of auditory language pathways , which postulate distinct dorsal and ventral processing pathways ( Hickok & Poeppel 2004 , 2007 ; Davis & Johnsrude 2007 ) .", "label": "", "metadata": {}}
{"text": "This may reflect the fact that the neural systems involved in representing meaning are anatomically distributed and perhaps include regions that encode sensory - motor attributes of spoken word meaning ( Barsalou 1999 ; Pulvermuller 1999 ; Hauk et al .However , at least for the majority of concrete , content nouns , we follow the proposal made by Hickok & Poeppel ( 2004 , 2007 ) and others ( Binder et al .2000 ; Davis & Johnsrude 2007 ) , and suggest that the posterior inferior temporal and fusiform gyri play a crucial role in accessing the meaning of spoken words .", "label": "", "metadata": {}}
{"text": "( b )Incorporating word learning into the distributed cohort model .In describing its architecture , and correspondences between different components with underlying neuroanatomical systems , we have omitted one critical feature of the model .That is we have not explained how appropriately weighted connections between units in the network are established .In simulations these connection weights are initialized to small random values and a backpropagation learning algorithm is used to adjust the weights in the network .This procedure allows gradual learning of a set of training words over the course of many presentations .The overlapping , distributed representations produced by this learning process permit accurate recognition of familiar words despite variable input and appropriate generalization to novel input sequences .", "label": "", "metadata": {}}
{"text": "However , in order to learn from presentation of these non - words ( e.g. to activate an appropriate semantic representation or predict upcoming phonetic input ) further changes to the connection weights of the network are required .As we have already described , neural network models trained using back - propagation show a dramatic form of interference when additional novel items are to be learned .That is , new words must be interleaved with existing words if they are to be acquired by the network .We propose an account in which connections between networks for speech perception in the lateral temporal lobe and memory systems in the medial temporal lobe ( particularly the hippocampus ) play a critical role in the acquisition of new words .", "label": "", "metadata": {}}
{"text": "These connections support the recognition of newly learned words while existing neo - cortical connections operate in parallel and continue to support the identification of pre - existing , known words ( figure 1 ) .If a dual - process model such as this underlies word learning and word recognition , what effects would be predicted for the time course of learning ?Accessing the meaning and phonological form of a novel word should be viable as soon as the word has been learned , assuming that this information is provided during the learning process .Retrieval in these circumstances relies on the hippocampal route , which can operate independently of the main speech perception system .", "label": "", "metadata": {}}
{"text": "We suggest that sleep provides a means of reinstantiating hippocampal memories for neocortical learning .Data from amnesics suggest that such integration could take years or even decades to complete , although recent demonstrations of sleep effects on memory indicate that faster initial changes are also possible .In particular , effects such as Ellenbogen et al .( 2007 ) finding that acquiring transitive representations of ordered picture pairs requires overnight consolidation provide strong evidence in favour of the idea that one of the key roles for sleep is the integration of hippocampal memories .Therefore , we can expect changes in neural representation of novel words following sleep , with shifts in the balance between hippocampal and neocortical representations .", "label": "", "metadata": {}}
{"text": "Although hippocampal learning means that new form - meaning mappings can be acquired swiftly , there may be computational consequences of the fact that the new mapping is kept separate from the existing mappings .In particular , there may be time - course differences in terms of the speed of access of newly learned and existing words , depending on how quickly the two routes operate .Gaskell & Marslen - Wilson ( 1999 , 2001 ) argued that one advantage of a PDP - style architecture for spoken - word recognition was that the state of the output units of the network directly reflects the likelihoods of the lexical candidates .", "label": "", "metadata": {}}
{"text": "However , once the hippocampal route is brought into play and additional competitors have been learned , there is the possibility of losing optimality .Imagine the case where a listener learned the new word /k\u00e6ptIk/ ( captick ) .This new competitor would initially be learned via the hippocampal route , which would allow the appropriate distributed representation to be activated on presentation of the full spoken word .However , the state of activation of the output units prior to the final phoneme ( /k\u00e6ptI/ ) is potentially compromised .The neocortical route will still reflect the relative likelihoods of the two pre - existing words that it has been trained on , and the hippocampal route will reflect the episodic representation of the new word .", "label": "", "metadata": {}}
{"text": "The outcome in these circumstances therefore depends on the balance between the two routes .If the hippocampal route is weighted too highly then something similar to catastrophic interference occurs , in that learning new words ( e.g. captick ) may interfere with the ability to recognize existing words ( e.g. captain or captive ) .On the other hand , if the hippocampal route is weighted too weakly , the ability to retrieve stored information about the novel word is lost .One solution may be to have some kind of prioritization , such that the neocortical route is dominant up to the point where that route fails to recognize a familiar item .", "label": "", "metadata": {}}
{"text": "Such a solution would allow novel spoken words to be recognized , but would mean that they do not influence the recognition of existing competitors until they have been incorporated into the neocortical route .It might also suggest that the hippocampal route would have to operate more slowly than a purely neocortical recognition process and consequently that consolidation should serve to speed - up recognition of recently learned words .Behavioural evidence for complementary processes in word learning .As we have seen in the previous section , the CLS account makes specific predictions concerning the neuroanatomical substrates of word learning and the functional characteristics of these processes .", "label": "", "metadata": {}}
{"text": "It is only once consolidated into neocortical representations that newly learned words ( e.g. captick ) should be recognized quickly and efficiently , and be able to compete with existing words like captain .In this section we will review the existing literature on the time - course of identification of newly learned words with the goal of assessing evidence for the CLS account .Tracking of speech - contingent eye movements has proved to be a rich source of information about the time - course of spoken language processing across a variety of domains ( e.g. Tanenhaus et al .", "label": "", "metadata": {}}
{"text": "These experiments make use of a visual scene with objects chosen to inform about the lexical hypotheses and predictions that are made during the online processing of speech .For example , Allopenna et al .( 1998 ) used pictures of cohort pairs ( e.g. beaker and beetle ) , plus rhyming competitors ( e.g. speaker ) and unrelated competitors ( e.g. carriage ) and measured the probability of fixating each picture as participants listened to target words ( e.g. beaker ) .These experiments have often made use of novel words as a way of manipulating the parameters of interest ( e.g. semantic properties , Revill et al .", "label": "", "metadata": {}}
{"text": "( 2003 ) used artificial lexicons to create stimulus sets that mimicked the cohort and rhyme relationships described above ( e.g. target /pibo/ with cohort /pibu/ , rhyme /dibo/ and unrelated /tupa/ distractors ) .Participants learned these words over the course of two days by associating them with visually presented abstract shapes .Magnuson et al . showed that word - like competition could be measured for these sets using probability fixation curves .Furthermore , frequency effects from newly learned neighbours were apparent in fixations even when the competitor shape was not present .In terms of the CLS approach , we can assume that the novel words were largely encoded hippocampally on the first day of these experiments and then jointly coded after sleep .", "label": "", "metadata": {}}
{"text": "However , an alternative explanation suggested by the CLS account is that the hippocampal route is less able to differentiate between candidates on the basis of likelihood .This would fit with the idea that the hippocampus simply requires some threshold to be reached in order to learn a mapping , with a habituation response to subsequent presentations .Magnuson et al . 's ( 2003 ) final experiment went further in testing whether fixation probabilities to novel words could be modulated by the competitor environment of the listener 's pre - existing lexicon .Novel words varying in neighbourhood environment ( defined on the basis of the pre - existing lexicon ) were learned as in previous experiments over the course of two days .", "label": "", "metadata": {}}
{"text": "Thus , the novel lexicon could be considered ' functionally isolated from the native lexicon ' ( Magnuson et al .p. 223 ) .This result might suggest that the novel words were held separate from the pre - existing lexicon in the hippocampal mapping ( even on the second day ) .Alternatively this result could be a kind of context effect .Given that the stimuli at test were exclusively novel words , it may be that the language system is able to eliminate pre - existing words from the competition process early on , meaning that the neighbourhood environment of the novel words is no longer relevant ( cf .", "label": "", "metadata": {}}
{"text": "Rather than examining the effect of the existing lexicon on recognition of novel words , Gaskell & Dumay ( 2003 ) looked at whether learning novel words could influence the processing of existing words .The study made use of words such as cathedral that are uniquely identifiable early on in the word .Pseudowords that diverged from these existing words only at or after the uniqueness point ( e.g. cathedruke ) were selected to be taught to the participants as novel words .Critically , engagement of the novel words in lexical competition should lead to a delay in the recognition of words like cathedral , because the uniqueness point of the existing word had shifted closer to the end of the word ( figure 2 a ) .", "label": "", "metadata": {}}
{"text": "However , the effect of novel word learning on recognition of the existing words was slow to emerge .These changes were measured using a lexical decision task measuring responses to cathedral in comparison with counterbalanced control words for which no neighbouring novel word was learned .A lexical competition effect was absent on days 2 and 3 but then emerged on the final two days .Furthermore , the effect was selective for the case where novel words were onset - matching neighbours of the existing word .As predicted by models of spoken word recognition such as the Distributed Cohort Model , equivalent overlap at the end but not the beginning of the word ( e.g. yothedral - cathedral ) showed no competition effect on any day .", "label": "", "metadata": {}}
{"text": "The uniqueness point for cathedral is markedly later ( orange line versus blue line ) if the new word cathedruke must also be ruled out .( b ) Lexical organization of these words after learning and before or after sleep - associated consolidation .Before sleep ( blue box ) the strongest lexical competitor for cathedral is cathartic , hence the uniqueness point is reached once this word can be ruled out ( early uniqueness point shown in a ) .After sleep ( orange box ) , the addition of a new lexical competitor is such that additional speech input is required to rule out cathedruke ( late uniqueness point shown in a ) .", "label": "", "metadata": {}}
{"text": "Two groups of participants were trained on novel words ( e.g. cathedruke ) at either 8.00 h or 20.00 h and tested on matched items with and without new lexical competitors 0 , 12 or 24 h after training .Responses to existing words were significantly delayed by competition from newly learned words only for those conditions in which sleep intervened between training and testing ( orange bars ) .Because the above experiment used multiple training sessions over several days it is not clear whether the lexical competition effect is simply dependent on a critical level of exposure being reached , or whether a consolidation period is also required .", "label": "", "metadata": {}}
{"text": "These tests used a pause detection task , in which listeners are asked to monitor for silent pauses inserted in the existing words ( e.g. cathe_dral ) .Mattys & Clark ( 2002 ) ( see also Mattys et al .2005 ) have demonstrated that this task is sensitive to the overall level of lexical activity at the pause position and hence should provide an index of lexical competition .Gaskell & Dumay ( 2003 ) showed that soon after the single intensive learning session there was excellent 2AFC recognition of the novel words , but no evidence of increased competition in pause detection for existing words .", "label": "", "metadata": {}}
{"text": "The dissociation between form recognition and engagement in lexical competition is strong evidence in favour of the dual process CLS account of word learning , outlined above ( see figure 2 b for a sketch of these changes in lexical organization ) .Subsequent studies have shown similar divisions between swift and delayed aspects of learning novel words .When novel words were assigned clear meanings in sentence contexts during training , the emergence of lexical competition was again delayed , though in this case competition effects were found a day after initial learning ( Dumay et al .The same paper showed that the competition effect was not restricted to offset - diverging neighbours such as cathedruke and cathedral , but also for novel words that embedded the existing words ( e.g. shadowks and shadow , cf .", "label": "", "metadata": {}}
{"text": "1994 ) .This experiment also included both a recognition memory test and a free recall test , in which participants were given 3 min to recall as many of the novel items as they could .These explicit memory tests also showed improvements on the second day of the experiment .Thus delayed effects of lexical learning can also be detected in explicit memory tests of novel words with a sufficiently demanding task .Given the delayed emergence of lexical competition and associated improvements in recall , Dumay & Gaskell ( 2007 ) attempted to tease apart effects of time and sleep after learning .", "label": "", "metadata": {}}
{"text": "Participants were then tested on their knowledge of these words straight after training , 12 and 24 h later .The tests included 2AFC recognition , free recall and pause detection , as in previous experiments .Both groups exhibited good recognition of the novel items immediately and at all retests , with no differences emerging .In contrast , pause detection showed an association between nocturnal sleep and the emergence of lexical competition effects .Test detection rates were slowed relative to control only for the conditions that had a night 's sleep between training and test ( i.e. after 12 and 24 h for the group starting in the evening , and after 24 h for the group starting in the morning ) .", "label": "", "metadata": {}}
{"text": "Participants ' free recall also showed an interaction between training group and time .There were improvements in free recall rate between subsequent test points in all cases where sleep intervened between the testing points and also when both test points followed sleep .The only case where improvement was not seen was for the group trained in the morning and then tested prior to sleep , where there was a marginally significant deterioration in recall rate .This observation fits well with the wider memory research in showing a protective aspect of sleep after learning ( e.g. Ellenbogen et al .", "label": "", "metadata": {}}
{"text": "2005 ) are consistent with a model in which the hippocampus provides an initial means of binding representations of novel words in the short term .Integration of novel words with existing words occurs over a longer period of time and is associated with nocturnal sleep .Results that implicate the first night after learning as critical for consolidation do not imply a dichotomous transfer of knowledge .However , in those studies that test for an effect of a single night of sleep , it does appear to produce observable changes in behaviour .A further crucial prediction of the CLS approach is that the competition effect that emerges in the days following first learning should remain robust over a longer time - course , and may even strengthen .", "label": "", "metadata": {}}
{"text": "Salasoo et al .1985 ) , Tamminen & Gaskell ( 2008 ) did examine the profile of lexical competition effects for several months following learning .Competition effects as measured by lexical decision were still robust at the final test point eight months after training , with some suggestion of enhanced competition effects by the end of the experiment .Although training only occurred at the beginning of the experiment , each test point did provide limited reactivation of novel word representations .Nonetheless , there were long periods of up to 17 weeks without any testing , and no significant reductions in the strength of competition effects after these gaps .", "label": "", "metadata": {}}
{"text": "One feature of all the experiments described so far is that they used multiple test sessions , including a test for lexical competition after learning but prior to sleep .Conceivably , this test session could have had a causal role in the emergence of lexical competition after sleep ( e.g. through reactivation / reconsolidation , Walker et al .2003 ; Hupbach et al .2007 ; or through sleep - associated consolidation of test tasks , Plihal & Born 1997 ; Huber et al .We might therefore predict that competition effects would not be found after sleep if the competition test was not administered prior to sleep .", "label": "", "metadata": {}}
{"text": "( 2009 ) tested this by teaching people two sets of novel words , one the day before testing and one on the day of testing .There was no competition effect from words learned that day , but words learned the previous day did produce a competition effect and faster response times in a speeded repetition task .This result does not rule out involvement of reconsolidation or task - learning in the effects described previously , but it does imply that lexical competition effects can emerge in the absence of reconsolidation of the pre - existing word representation , or repetition of test tasks .", "label": "", "metadata": {}}
{"text": "Although the above studies show that some aspects of lexical processing rely on a late - emerging representation , there are other aspects of word learning that do not require consolidation .Snoeren et al .( 2009 ) looked at the ability of novel words to influence phoneme judgements in the context of compensation for the effects of assimilation .Previous research ( Gaskell & Marslen - Wilson 1998 ) has shown that listeners can use the following context of a segment to compensate for the change in place of articulation that often occurs in speech production .For example , in the sequence freight bearer , the final consonant of freight is often similar to /p/ in connected speech .", "label": "", "metadata": {}}
{"text": "Snoeren et al .found that newly learned words immediately affected the tendency to use context to compensate for assimilation , and once again the strength of the compensation was no different for a separate set of items learned the previous day .The only effect of a 24-h period of consolidation was to facilitate response times overall , supporting the CLS proposal that word recognition should be speeded - up by overnight consolidation .Sedin & colleagues ( Sedin & Gaskell 2005 ; Sedin et al .in preparation ) examined influences of newly learned words on speech perception using artificial phonetic continua , testing the extent to which novel words could bias listeners ' perceptions of ambiguous phonemes .", "label": "", "metadata": {}}
{"text": "The only hint of a consolidation effect was again in response times , where speed benefits were found only at the second test point .Leach & Samuel ( 2007 ) asked a related question concerning the influence of newly acquired lexical items on speech perception .They made use of the observation that spoken words ( but not non - words ) can drive changes to phoneme - category boundaries .For instance , Norris et al .Crucially , this compensatory adjustment to the category boundary only occurred when the ambiguous phoneme was embedded in words , as opposed to pseudowords .", "label": "", "metadata": {}}
{"text": "They found that non - words can show this lexical effect as long as they were assigned a meaning in some way during training .Strongest effects emerged when pictures were associated with the novel words , when training did not involve pronunciation , and effects seemed to strengthen over the course of 5 days .The typical result , however , was that although type of training was crucial , the amount of time since first exposure was not .This contrasts strongly with the effects of lexical competition , where type of training seems irrelevant and time is crucial .", "label": "", "metadata": {}}
{"text": "If , as we have speculated , the indirect hippocampal route to phonological representations is relatively slow then the response time advantage enjoyed by the 24-h delay conditions for phoneme monitoring in Snoeren et al .( 2009 ) and for delayed repetition in Davis et al .( 2009 ) , may be due to a partial shift in reliance away from the hippocampal route and towards the direct neocortical route .In sum , we have seen that a CLS approach to vocabulary acquisition fits well with the picture we have from behavioural data .Most aspects of lexical processing are available straight after learning and according to the CLS account may therefore be hippocampally mediated .", "label": "", "metadata": {}}
{"text": "Engagement in lexical competition is the best studied of these , but there also seem to be advantages in ability to recall words , and swifter processing of the novel words ( in speeded repetition and assimilated segment detection ) once integration into the neocortical route has begun .The neural predictions , however , can only be tested indirectly in behavioural studies .We therefore turn to neuropsychological and neuroimaging data as a more direct test of the CLS account .Medial temporal contributions to word learning .In this section we review neuroscientific evidence in support of the CLS proposal that rapid initial learning is dependent on medial temporal lobe systems including the hippocampus ( cf .", "label": "", "metadata": {}}
{"text": "1995 ; O'Reilly & Norman 2002 ) .We begin by reviewing evidence for new word learning in amnesic patients with medial temporal lobe lesions before assessing convergent evidence from functional imaging studies , primarily using fMRI .( a ) Neuropsychological evidence .In \u00a7 1 we reviewed the basic pattern of impairment associated with damage to the hippocampus and surrounding regions of the medial temporal lobe .Here , we focus on the question of whether amnesics are able to learn new items of vocabulary .Studies of the late patient HM showed significantly impaired acquisition of words that came into the language after his bilateral resection of the medial temporal lobe ( Gabrieli et al .", "label": "", "metadata": {}}
{"text": "Such findings suggest that amnesic syndromes are accompanied by impaired post - lesion learning of new words .However , recent anatomical investigations showed that HM had a more extensive bilateral lesion encompassing the hippocampus and adjacent regions of perirhinal and entorhinal cortex ( Corkin 2002 ) .Further evidence is therefore required if we are to assess the unique contribution of the hippocampus to word learning .Patients with lesions confined to the hippocampus appear to show less marked impairments in the acquisition of new words .One important source of evidence concerning more circumscribed medial temporal lesions comes from observations of developmental amnesia following anoxic episodes during birth ( Vargha - Khadem et al .", "label": "", "metadata": {}}
{"text": "Despite severe impairments in episodic memory , these children can show performance within the normal range in assessments of language function including tests of word knowledge ( Vargha - Khadem et al .1997 ; Gadian et al .Although these observations suggest that longer - term word learning can occur in the absence of the hippocampus , it might still be the case that the hippocampus normally plays a role in the initial acquisition and maintenance of new words .To explore the impact of hippocampal lesions on initial acquisition a number of authors have used laboratory tests of word and concept learning in patients with developmental or adult - acquired lesions of the hippocampus .", "label": "", "metadata": {}}
{"text": "For instance , Martins et al .( 2006 ) showed that a developmental amnesic with bilateral hippocampal lesions had impaired acquisition of new names and concepts in laboratory situations .Although this patient had a severe impairment ( perhaps due to damage to the surrounding entorhinal and perirhinal regions ) , a patient with amnesia due to mamillary body lesions showed a milder impairment of word and concept learning compared with controls .A single case study of Jon , a developmental amnesic with hypoxia - induced bilateral hippocampal damage also showed significantly slowed acquisition of new words and associated semantics under laboratory conditions ( Gardiner et al .", "label": "", "metadata": {}}
{"text": "Thus , these results suggest that intact word knowledge in developmental amnesia arises from the operation of slower ( perhaps cortically based ) learning processes , consistent with the CLS account .One question that arises in considering evidence from these developmental populations , however , is whether preservation of learning following early - onset hippocampal lesions reflects cortical learning mechanisms that remain plastic during childhood but would be absent following late acquired lesions .It is therefore reassuring that studies using adult amnesics largely confirm the pattern shown in these developmental studies .For instance , Verfaellie et al .", "label": "", "metadata": {}}
{"text": "Interestingly , of the two patients tested , a more severe impairment was observed in patient SS who subsequent to Herpes Simplex Encephalitis had lesions of both the hippocampus and adjacent entorhinal / perirhinal cortices .This is consistent with the profile of the developmental amnesic tested by Martins et al .Nonetheless , patient PS whose lesion was confined to the hippocampus also showed impaired knowledge of words that entered into the language after the anoxic episode that led to her amnesia .As well as word - form familiarity , both patients provided evidence of semantic knowledge of these words ( e.g. knowing that a ' website ' was a word associated with computers ) .", "label": "", "metadata": {}}
{"text": "Thus , evidence from adult and developmental amnesia would together imply that new word learning is severely impaired by bilateral hippocampal lesions .We therefore conclude that the initial acquisition of new words involves a similar dependence on medial temporal lobe learning systems to other forms of item - specific and associative learning ( see Gooding et al .2000 for a review ) .Some limited , residual learning abilities remain in amnesic patients , which we propose are supported by slower neocortical learning .( b )Functional neuroimaging evidence .Convergent evidence for hippocampal contributions to word learning has come from functional imaging studies in which participants are scanned while learning new words .", "label": "", "metadata": {}}
{"text": "Consistent pairings enabled participants to learn the picture - pseudoword associations , as shown by behavioural performance during and after scanning .Although activation differences between the consistent and inconsistent pairings were only observed in the right inferior frontal gyrus , there was also a significant linear decline in left hippocampal activity over five presentations of each consistent pairing , whereas the inconsistent pairings showed no such decline .Furthermore , a cross - subject analysis showed that participants who produced a greater response to the initial presentation of consistent pairings and a smaller decline in activation subsequently had better memory for the word - picture pairings .", "label": "", "metadata": {}}
{"text": "A subsequent fMRI experiment replicated this association between medial temporal activity and initial learning of form - meaning pairings for novel written words ( Mestres - Misse et al .Mestres - Misse et al . contrasted fMRI responses to written pseudowords presented at the offset of sentences that provided either a consistent or inconsistent meaning for that pseudoword .Comparison of consistent and inconsistent meaning pairings revealed activation clusters in the precuneus , left thalamus , and anterior parahippocampal gyrus - the latter cluster probably including perirhinal regions lesioned in patients with more severe impairments of word learning .", "label": "", "metadata": {}}
{"text": "Evidence from intracranial ERPs might suggest that at least one plausible generator of the N400 effect is localized in medial temporal regions consistent with the activation observed in their fMRI paradigm ( Nobre et al .1994 ; McCarthy et al .1995 ) , though this localization has been disputed ( see Lau et al .These findings , like the results of Breitenstein , suggest a role for the medial temporal lobe in learning associations between pseudowords and meanings .However , the studies leave unclear whether activation reflects involvement of medial temporal lobe systems in associative learning ( consistent with hippocampal activation during successful learning of word - word and face - name associations : Henke et al .", "label": "", "metadata": {}}
{"text": "2003 ; Prince et al .2005 ) , or a more general role in initial encoding of novel stimuli ( Strange et al .1999 ; Yamaguchi et al .Two recent studies in fMRI and PET , respectively , answer this question ; first by showing that hippocampal activation is associated with successful encoding of novel spoken pseudowords in the absence of accompanying pictures or semantic information ( Davis et al .2009 ) , second by showing equivalent medial temporal activity for form learning and associative learning ( Paulesu et al .In Davis et al .", "label": "", "metadata": {}}
{"text": "Activation of the hippocampus was primarily observed for those pseudowords that were entirely novel at the time of presentation , and declined rapidly with subsequent repetitions when these items were no longer truly novel .Furthermore , the magnitude of initial activation to novel pseudowords and the magnitude of the subsequent decline in activity on repetition predicted performance in a post - scanning forced - choice recognition memory test .Hence , this study suggests a role for the hippocampus in initial encoding of novel word forms , irrespective of whether participants associate these items with pictures or other semantic information .", "label": "", "metadata": {}}
{"text": "( 2009 ) who used PET to compare responses to words and pseudowords in both these tasks .Again , we will discuss cortical activation observed in this study subsequently , however , with regard to the medial temporal lobe both associative and form learning responses to pseudowords declined over time in the anterior parahippocampal gyrus and temporal pole .Form learning and associative learning thus recruit similar medial temporal structures - though in this study these were located outside of the hippocampus .In all these studies medial temporal activation during word learning reduced rapidly with stimulus repetition and most clearly predicted behavioural measures of successful learning ( though the Paulesu study did not test this correlation ) .", "label": "", "metadata": {}}
{"text": "This account would also explain the absence of hippocampal activation in studies in which participants received extensive training on novel items prior to testing ( Sandak et al .2004 ; Majerus et al .We next turn to evidence for the second neural prediction of the CLS account : that neocortical representations support long - term recognition of words and that cortical representations of pseudowords emerge slowly following stimulus familiarization and offline consolidation .Cortical contributions to word learning .In assessing the contribution of cortical regions to word learning , then , we will first consider evidence from neuropsychology concerning the neural regions that support knowledge of familiar words .", "label": "", "metadata": {}}
{"text": "This meta - analysis assists in the interpretation of functional imaging studies that assess changes to the neural response to spoken pseudowords during and after familiarization .A stringent test of these studies is whether they provide evidence concerning the time - course by which pseudoword responses become word - like during and subsequent to acquisition .The CLS account makes the strong prediction that offline consolidation is required to generate stable neocortical representations of pseudowords .( a ) Neuropsychological evidence .An important source of evidence concerning the cortical systems that are critical for word recognition comes from neuropsychological studies assessing brain areas that produce a significant impairment in the comprehension of familiar words when lesioned .", "label": "", "metadata": {}}
{"text": "Voxel - by - voxel analysis methods similar to those employed in functional brain imaging can thus be used for statistical assessment of lesion - symptom associations .Interestingly , the results of these analyses provide two distinct answers to the question of which brain regions produce impaired single word comprehension when lesioned .Lesion - symptom maps for speech comprehension impairments in a large group of aphasic stroke patients suggest an association between lesions and impaired comprehension in a region of the posterior middle temporal gyrus ( MTG ) extending into inferior temporal regions ( Bates et al .", "label": "", "metadata": {}}
{"text": "It is therefore encouraging that a follow - up study using a more sophisticated language battery ( Dronkers et al .2004 ) suggests that posterior MTG lesions are specifically associated with impairments of single word comprehension .Only posterior MTG lesions produced an impairment even for the simplest test sentences used , irrespective of syntactic complexity .A similar association between posterior inferior temporal lesions and impaired comprehension has also been reported by Peelle ( Peelle et al .2008 ) in a study of semantic dementia patients .Nonetheless , it remains unclear whether impairments are in word - form recognition or in the form - to - meaning mapping .", "label": "", "metadata": {}}
{"text": "2000 ; Williams et al .2005 ) , or that use a range of aetiologies ( Tyler et al .2005 a , b ) would suggest a more anterior locus of the representations that support single word comprehension .For example , the speed with which patients respond in lexical decision is predicted by lesions in antero - lateral regions of the temporal lobe including the temporal pole ( Tyler et al .2005 a ) , as is a measure of semantic priming ( Tyler et al .2005 b ) .Further evidence for an association between damage to anterior temporal regions and deficits in the recognition of words and other familiar stimuli comes from studies of patients with multimodal semantic impairments following the temporal lobe variant of fronto - temporal dementia ( semantic dementia ) .", "label": "", "metadata": {}}
{"text": "Voxel - based analysis methods have shown that cortical degeneration ( Mummery et al .2000 ; Williams et al .2005 ) and hypometabolism ( Nestor et al .2006 ; Desgranges et al .2007 ) in anterior temporal regions surrounding the temporal pole is most clearly associated with the degree of semantic impairment observed .At present , it is unclear how we are to reconcile results suggesting that lesions to two distinct regions of the temporal lobe can both produce impairments of word recognition in patient populations .One plausible interpretation is that both anterior and posterior temporal regions contribute to successful recognition of familiar words in different ways .", "label": "", "metadata": {}}
{"text": "2004 ; Patterson et al .2007 ) suggest that the anterior temporal lobe forms a semantic hub that binds together neurally distributed representations of perceptual and conceptual features stored in more posterior regions .One speculative extension of this proposal in the context of the CLS account is to suggest that anterior temporal regions lesioned in semantic dementia provide input to the hippocampus .It might therefore be that anterior temporal lesions lead to a progressive decline in comprehension because damage impairs the ability to acquire new representations , and that these processes are also required if knowledge of familiar words is to be retained .", "label": "", "metadata": {}}
{"text": "( b ) Meta - analysis of word and pseudoword responses in brain imaging .Given this uncertainty concerning the role of anterior and posterior temporal lobe regions in the recognition of familiar words it is clear that functional imaging can provide important additional evidence concerning the cortical systems supporting word recognition .We therefore report a meta - analysis of published PET and fMRI studies that include a direct contrast between spoken words and pseudowords .We use an Activation Likelihood Estimation ( ALE ) method to derive a statistical map of the brain regions in which activation differences between words and pseudowords are expected ( Turkeltaub et al .", "label": "", "metadata": {}}
{"text": "2002 ) and ( ii ) conduct random - effects analyses of activation maps collected from groups of healthy adult participants .We analysed all PET / fMRI studies of spoken word recognition that report the contrast between familiar words and phonologically well - formed , clearly spoken pseudowords in either direction .That is , we assessed regions involved in representing familiar items ( responding more strongly to words ) and regions that contribute to perception of pseudowords ( responding more to pseudowords ) .This focus on the word / pseudoword contrast excludes studies in which non - word stimuli were physically distorted / degraded , or unintelligible versions of spoken words ( e.g. Mummery et al .", "label": "", "metadata": {}}
{"text": "Following these exclusions , 11 studies reporting a direct contrast between responses to spoken words and pseudowords remained , as summarized in table 1 .Since certain of these studies included multiple contrasts , we focus our meta - analysis on main effects of lexicality , averaging over stimulus and task manipulations as appropriate .Where the results permitted ( e.g. Majerus et al .2005 ; Davis et al .2009 ) we excluded conditions in which participants were exposed to certain pseudowords before scanning .Studies included in the meta - analysis .All peak coordinates reported in the papers listed in table 1 were included in the meta - analysis .", "label": "", "metadata": {}}
{"text": "We begin by describing the elevated responses observed for pseudowords shown in red in figure 3 a - c and table 2 .These provide putative neural correlates of phonological - encoding processes that are challenged during the initial processing of unfamiliar spoken items and that may therefore contribute to initial encoding of pseudowords in conjunction with medial temporal regions .Activation Likelihood Estimation ( ALE ) map derived from 97 peak voxels from 11 functional imaging studies comparing neural responses to spoken words and pseudowords .( d , e ) Response profiles showing predicted changes in neural responses owing to familarization with pseudowords : ( d ) Within regions that initially show an additional response to pseudowords ( red in figure 3 a - c , e.g. STG , posterior inferior frontal gyrus ) .", "label": "", "metadata": {}}
{"text": "( d ) Predicted response within regions that show an additional response to real words ( anterior MTG , anterior fusiform , supramarginal gyrus , blue in figure 3 a - c ) , we predict an increased response to pseudowords following training .( f ) fMRI responses in a region of the STG overlapping with areas shown in red in figure 3 a - c ( replotted from Davis et al .An equivalent , additional response to pseudowords was seen for items that were untrained at the time of scanning or trained but not consolidated ( i.e. learned on the same day as scanning ) .", "label": "", "metadata": {}}
{"text": "Activation likelihood estimation results for 29 peak voxels in studies reporting a greater neural response to spoken pseudowords than words ( shown in red in figure 2 ) .Entries shown in bold are cluster summary statistics ( including centre of mass and volume ) , entries in plain type show local maxima .In the superior portion of the left temporal lobe we see two distinct clusters that show an additional response to spoken pseudowords compared with real words .These clusters are located posterior and anterior to Heschl 's Gyrus ( in planum polare and planum temporale , respectively ) extending into adjacent regions of the superior temporal gyrus .", "label": "", "metadata": {}}
{"text": "There is good agreement between these various accounts that the dorsal - going pathway , running into the posterior temporal lobe and on to inferior parietal regions serves to map heard speech onto inferior frontal regions involved in generating the phonological representations required for articulation .It is therefore of interest that we observe an elevated response to pseudowords in left inferior frontal ( opercularis ) and premotor regions that putatively form part of the articulatory network identified by Hickok & Poeppel ( 2004 ) and Scott & Johnsrude ( 2003 ) .A number of other regions that have been associated with mapping heard speech onto motoric responses also appear in this meta - analysis include the insula ( Dronkers 1996 ) , supplementary motor area and cerebellum .", "label": "", "metadata": {}}
{"text": "Convergent evidence for this interpretation comes from functional imaging studies that ascribe phonological functions to these posterior temporal regions .For example , fMRI has shown that the magnitude of the posterior Superior Temporal Gyrus ( STG ) response is correlated with speech intelligibility yet sensitive to acoustically distinct forms of speech distortion ( Davis & Johnsrude 2003 ) .Well - controlled speech / non - speech comparisons also produce posterior STG responses ( Mottonen et al .2006 ; Uppenkamp et al .2006 ; Heinrich et al .2008 ) as do studies that contrast neural responses to phonological and acoustic changes to spoken syllables ( Jacquemot et al .", "label": "", "metadata": {}}
{"text": "2005 ; Raizada & Poldrack 2007 ) .In considering the function and organization of the ventral pathway for speech processing , there is rather more disagreement between the different accounts reviewed here .While neither account makes specific predictions concerning neural responses to pseudowords , it is of interest that the elevated response to pseudowords in the anterior superior temporal lobe is clearly in front of primary auditory cortex in the superior temporal gyrus and planum polare .Our observation of an elevated response to pseudowords in these anterior auditory fields appears most clearly in line with accounts proposing that these regions contribute to echoic representations of speech ( cf .", "label": "", "metadata": {}}
{"text": "2005 ; Davis & Johnsrude 2007 ) , although other authors have proposed a role for these regions in syntactic or combinatorial language processes ( Friederici 2002 ; Humphries et al .2006 ; Hickok & Poeppel 2007 ) .Further data on the response of this portion of the anterior superior temporal gyrus to pseudowords would be valuable .We now turn to the meta - analysis of brain regions showing an elevated response to real words compared with pseudowords , displayed in blue in figure 3 a - c , and summarized in table 3 .In line with the dual - route accounts described earlier , we see additional activation for spoken words in temporal lobe regions extending both anterior and posterior from those activations that were reported for the pseudoword contrast .", "label": "", "metadata": {}}
{"text": "The spatial organization of these anterior and posterior temporal activations is consistent with the proposal that activations for real words are at a higher level of abstraction along anterior and posterior speech - processing pathways than those seen in the reverse contrast .Such findings parallel the results of a recent fMRI study using visual words and pseudowords in which familiar lexical items evoked activation at ' higher ' levels of the ventral visual processing stream ( Vinckier et al .Similarly , we would suggest that the spatial position of these activations is consistent with a hierarchical account proposed on the basis of functional imaging data by ( Davis & Johnsrude 2003 , 2007 ) .", "label": "", "metadata": {}}
{"text": "One complexity of the present results is that additional activation for real words is observed in all three temporal lobe pathways shown in figure 1 a .Activation likelihood estimation results for 68 peak voxels in studies reporting a greater neural response to spoken words than pseudowords ( shown in blue in figure 2 ) .Entries shown in bold are cluster summary statistics ( centre of mass and volume ) , entries in plain type show local maxima .( c )Imaging cortical correlates of word learning .The differential cortical responses to words and pseudowords reviewed above allow us to recast the critical experimental questions of word learning studies in neural terms .", "label": "", "metadata": {}}
{"text": "A number of studies have shown changes in the magnitude of neural responses to pseudowords following repeated presentation , and have linked these response changes to behavioural improvements and hence word learning .However , we would argue that response changes owing to learning should at least partially cancel response differences between pre - existing words and entirely novel pseudowords if we are to infer that cortical representations of newly learned items have become word - like .For the neural response to a pseudoword to become fully word - like requires two opposite changes following familiarization : response decreases in regions that respond more to pseudowords , and response increases in regions that respond preferentially to familiar words .", "label": "", "metadata": {}}
{"text": "The two interaction profiles depicted in figure 3 d , e therefore provide specific hypotheses concerning the cortical correlates of word learning .This section of the paper will review functional imaging studies that assess neural responses to pseudoword stimuli before , during and after familiarization with a view to testing for either of these two interactions .Building on behavioural evidence for offline consolidation , we predict that the emergence of robust , cortical representations of newly learned words requires not just initial familiarization , but also a period of offline consolidation .Evidence that these response changes can occur more rapidly has the potential to challenge the CLS account .", "label": "", "metadata": {}}
{"text": "They used event - related fMRI to measure neural responses during lexical decisions to spoken words and pseudowords , half of which were presented twice during scanning .Neural responses showed elevated responses to familiar words in many of the temporal lobe regions shown in the meta - analysis ( figure 3 ) .Critically , however , response differences between words and pseudowords were unaltered by stimulus repetition - neither of the interactions between stimulus repetition / familiarization and lexicality depicted in figure 3 d , e were significant in the fMRI data .This was not because of the lack of any effect of stimulus repetition on neural responses .", "label": "", "metadata": {}}
{"text": "Response reductions for repeated items were observed in bilateral inferior frontal regions , the SMA and posterior inferior temporal gyrus , though once more these were of equivalent magnitude for words and pseudowords ( unlike the profile in figure 3 d ) .Correlational analyses showed that reduced responses in inferior frontal and motor regions were correlated with the trial - by - trial magnitude of behavioural priming , suggesting that the expression of the repetition priming effect is linked with neural systems involved in decision - making and response execution ( cf .Dobbins et al .Despite the presence of a lexicality by repetition interaction in behaviour , neural responses showed no evidence for the emergence of word - like representations for repeated pseudowords .", "label": "", "metadata": {}}
{"text": "However , we must be careful to distinguish effects of familiarization from the task - based repetition effects that were documented by Orfanidou et al .Studies that only assess familiarization effects for pseudowords can not differentiate between emerging cortical representations of newly learned words as distinct from effects of stimulus repetition .For instance , Breitenstein et al .( 2005 ) report that neural responses in an anterior region of the fusiform showed a greater decline over five repetitions of consistent word - picture pairings than for inconsistent word - picture pairings .Our meta - analysis shows that this fusiform region ordinarily shows an increased response for words compared with pseudowords .", "label": "", "metadata": {}}
{"text": "Note that this observation does not negate any of the conclusions of the Breitenstein study concerning the contribution that the fusiform in conjunction with the hippocampus makes to the initial acquisition of word - picture associations .Two other event - related fMRI studies have similarly shown response reductions to repetitions of spoken pseudowords ( Graves et al .2008 ; Rauschecker et al .Both studies show that multiple presentations of pseudowords led to a reduced neural response within brain regions shown in our meta - analysis to produce an elevated response to pseudowords ( the STG , premotor cortex and SMA in Rauschecker et al .", "label": "", "metadata": {}}
{"text": "That both these studies show a reduced response in posterior superior temporal regions is encouraging since it suggests that the change in pseudoword responses is in the correct direction to reduce the response difference between pseudowords and words ( the interaction depicted in figure 3 d ) .However , neither study measured the effect of stimulus repetition for familiar words and so can not detect interactions that provide evidence for word - like neural responses .Critical for the interpretation of these event - related fMRI studies are the findings of two PET studies that did compare the effect of stimulus repetition on words and pseudowords ( Majerus et al .", "label": "", "metadata": {}}
{"text": "Both studies show equivalent repetition suppression in the STG when spoken words and pseudowords are presented repeatedly prior to scanning ( Majerus et al .2005 ) , or during scanning ( Paulesu et al .Hence , in this study there is no lexicality by repetition interaction in either the posterior STG ( Majerus et al .2005 ) or the anterior STG ( Paulesu et al .It therefore seems that had words been included in the fMRI studies of Rauschecker and Graves , then the required lexicality by repetition interaction would be absent and a main effect of repetition observed ( cf .", "label": "", "metadata": {}}
{"text": "One further finding from the Majerus et al .( 2005 ) study is that low phonotactic frequency non - words did not show the same response decrease owing to familiarization as familiar words and high - phonotactic frequency non - words .This might suggest that cortical correlates of rapid response learning are limited to items that are either familiar or very similar to familiar words .Such a finding is consistent with the Distributed Cohort Model , in which the ability to generalize to novel pseudowords is determined by the degree of similarity to pre - existing words .", "label": "", "metadata": {}}
{"text": "One fMRI study that both tested for a familiarity by repetition interaction and ruled out task repetition was presented by Gagnepain and colleagues ( Gagnepain et al .In this event - related fMRI study , participants made lexical decisions to acoustically degraded spoken words and pseudowords of which 50 per cent had been presented previously for a phoneme decision task .Gagnepain observed a symmetrical interaction between lexicality and stimulus repetition with responses in left posterior STG and right peri - auditory areas , i.e. a reduced response for second presentations of words , and an enhanced response for second presentations of pseudowords .", "label": "", "metadata": {}}
{"text": "Gagnepain and colleagues suggest that response increases for pseudowords reflect long - term encoding of previously unfamiliar items .However , these increases were observed in regions close to auditory cortex that showed an elevated response to pseudowords in our meta - analysis .This interaction serves to increase the neural response difference between pre - existing words and pseudowords , rather than decreasing this effect as predicted by figure 3 d .Thus , the reactivation of recently acquired pseudoword representations has the opposite effect on measured neural activity to the difference between familiar words and unfamiliar pseudowords .", "label": "", "metadata": {}}
{"text": "2005 ) and faces ( Henson et al .2000 , 2002 ) , which similarly differentiate familiar and unfamiliar items .In each of these studies , repetition effects for unfamiliar items are either absent , or do not appropriately overlap with regions that show an elevated response to familiar items .In summary , then , existing studies have failed to provide a convincing demonstration that repeated presentation of spoken pseudowords can lead to the emergence of word - like cortical responses over the time span of a typical functional imaging experiment .The lack of a significant interaction , however , is directly predicted by the CLS account which proposes that short - term stimulus repetition alone is insufficient to produce stable , task - independent cortical representations of newly learnt pseudowords .", "label": "", "metadata": {}}
{"text": "Consequently , neural effects of a consolidation period that included sleep were assessed in an fMRI study reported by Davis et al .Like certain other PET and fMRI studies reviewed previously , Davis and colleagues tested for interactions between prior familiarization and lexicality .Since two different tasks were used in training and testing ( phoneme monitoring and gap - detection , respectively ; Connine & Titone 1996 ; Mattys & Clark 2002 ) , task - based response learning could not account for effects of training on neural responses .The experimental design used three matched sets of words and pseudowords , two of which were familiarized prior to scanning .", "label": "", "metadata": {}}
{"text": "The design does not allow any effects found to be necessarily associated with sleep as opposed to an extended period of consolidation awake .Comparison of untrained words and pseudowords also permitted an assessment of simple lexicality effects as shown in the meta - analysis .However , perhaps because the tasks used depend on processing the surface form of speech , elevated responses were observed for pseudowords compared with words and not vice versa .We will discuss in the concluding section the implications of the lack of an elevated , word - like response to pseudowords following training and consolidation .", "label": "", "metadata": {}}
{"text": "found an elevated response to pseudowords in the STG ( anterior and posterior ) , and left cerebellum similar to those shown in figure 3 ( results included in the meta - analysis ) .Consistent with the findings of Orfanidou et al .( 2006 ) , no interaction between same - day familiarization and lexicality was shown .That is , an overlapping set of regions showed an elevated response to pseudowords compared with words when these items had been extensively trained in the hours prior to scanning .Indeed , for this pseudoword versus word contrast , an elevated response to pseudowords occurred in a more extensive phonological network including a bilateral region of the motor cortex and the left SMA ( though changes between untrained and trained items were not statistically significant ) .", "label": "", "metadata": {}}
{"text": "Indeed , we saw a significant consolidation by lexicality interaction in the STG , motor cortex and right cerebellum ( figure 3 f ) .As is apparent , the critical interaction was between words and pseudowords trained with overnight consolidation and items trained and tested on the same day ( hence not subject to consolidation ) .This finding is entirely predicted by a CLS account in which cortical learning requires offline consolidation .To be clear , this result does not imply that all neural correlates of word learning require overnight consolidation .We have already reviewed other results from the Davis et al . study showing that the degree to which participants become familiar with pseudowords that were presented for the first time during scanning is associated with the activation and subsequent decline in hippocampal responses ( cf .", "label": "", "metadata": {}}
{"text": "These data suggest that the role of the hippocampus in word learning appears confined to the initial acquisition of novel pseudowords , consistent with the CLS account .In the light of certain neuroimaging studies reviewed here ( Majerus et al .2005 ; Graves et al .2008 ; Rauschecker et al .2008 ) that show effects of repetition priming on neural responses to pseudowords , we must add a further significant caveat .These studies provide evidence for rapid neocortical learning that is involved in the acquisition and expression of stimulus - response associations ( Schacter et al .", "label": "", "metadata": {}}
{"text": "Majerus et al .If response learning applies to spoken words and pseudowords , then these effects can be observed for both items ( Orfanidou et al .However , differential repetition priming for words and pseudowords can more often be observed with greater priming for familiar words ( Gagnepain et al .In these experiments , pseudoword priming effects are often in the wrong direction to create more word - like cortical responses ( Gagnepain et al .We would contend , therefore , that rapid , response - based learning processes are limited to tuning of existing representations , and are ( on their own ) insufficient to establish cortical representations of new spoken words .", "label": "", "metadata": {}}
{"text": "Response - based learning processes can not be invoked to explain the overnight consolidation effects that we have observed in our functional imaging study ( Davis et al .Nor can task - based repetition priming effects explain the effect of overnight consolidation on the emergence of lexical competition in behavioural studies that were reviewed in \u00a7 3 .In all these studies , both the stimuli presented , and the responses measured differ between training and testing .This separation of rapid stimulus - response learning ( that can be achieved by cortical mechanisms without consolidation ) and slower cortical learning produced by hippocampal encoding and offline consolidation has the potential to explain certain puzzling observations from the literature on word learning in amnesic patients .", "label": "", "metadata": {}}
{"text": "Similarly , a developmental amnesic patient Jon could acquire new semantic / factual knowledge , but required many more repetitions than control participants ( Gardiner et al .These data might suggest that isolated neocortical learning mechanisms responsible are limited to supporting stimulus - response association of whole forms .Hence , there may be important benefits that hippocampal learning and overnight consolidation provide in the non - damaged brain .This two - stage learning process supports flexible and generalizable knowledge more effectively than rote or piecemeal learning using neocortical systems alone .Discussion and future directions .In this paper we have presented a cognitively and neuroanatomically informed account of word learning , grounded in principles that are well - established for learning other domains of knowledge .", "label": "", "metadata": {}}
{"text": "We will then consider some unanswered questions concerning the CLS account of word learning that should be pursued in further empirical research .( a )What can memory theory gain from considering word learning ?Word learning is a domain in which adult participants have a large and relatively uniform body of knowledge - there is a core vocabulary that is shared by all English speakers .Furthermore , the cognitive abilities and cortical processes that support our ability to recognize , understand and produce familiar words are ( as this review illustrates ) relatively well understood .Yet , monolingual adults continue to add to their vocabulary ( e.g. ' blog ' ) , an ability that is also critical for successful second language learning .", "label": "", "metadata": {}}
{"text": "Word learning also provides clear examples of the multiple forms of knowledge that are critical for successful performance .Word representations are jointly perceptual ( in systems involved in recognizing words ) , procedural ( in motor systems for producing words ) and semantic ( in systems representing word meaning ) .Representations in each of these linked systems must be robust and able to generalize from individual experiences to novel input .For instance , we must recognize familiar words spoken by unfamiliar voices or establish the meaning of familiar words in unfamiliar contexts .These properties are ably demonstrated by neural network models ( e.g. Gaskell & Marslen - Wilson 1997 ) that are subject to computational limitations typical of systems trained with distributed learning algorithms .", "label": "", "metadata": {}}
{"text": "Empirical evidence concerning the nature of these interactions between episodic and perceptual / procedural memories of spoken words therefore provides a natural interpretation within CLS accounts .One point of view on complementary learning systems has considered perceptual / procedural and episodic learning to be distinct processes that operate on different types of information and that are probed using different sorts of test ( e.g. Marshall & Born 2007 ) .Rather , we would contend that most ecologically valid forms of learning exemplify more than one single type of knowledge , and are hence not embodied in any single system .", "label": "", "metadata": {}}
{"text": "( b ) Unanswered questions for the CLS account of word learning .As the current review illustrates , existing evidence from neuropsychology and functional brain imaging concerning neural systems involved in word learning are largely consistent with the CLS account proposed here .However , more specific empirical tests of the predictions of the CLS account remain to be conducted .In particular , it should be noted that those behavioural data that most clearly show effects of overnight consolidation test knowledge of the form of spoken words and not their meaning ( speeded repetition tasks , e.g. Davis et al .", "label": "", "metadata": {}}
{"text": "Dumay & Gaskell 2007 ) .We have argued that these data can be understood in terms of consolidation processes that achieve optimal , probabilistic processing of perceptual input and integration of new knowledge with existing representations .Although the role of consolidation in supporting efficient perceptual processing is relatively well understood , it is less clear whether other aspects of word learning ( such as the acquisition of semantics ) are also subject to overnight consolidation .As yet there is limited behavioural evidence concerning the long - term acquisition of representations of word meaning ( e.g. McKay et al .", "label": "", "metadata": {}}
{"text": "The results of the fMRI study reported by Davis et al .( 2009 ) would support this second conclusion but further empirical investigation would be helpful .A further set of empirical questions concern the finding that recognition of lexical neighbours of newly learned words is altered by overnight , sleep - associated consolidation ( Dumay & Gaskell 2007 ; figure 2 ) .Although these results are striking , they fall short of showing a causal link between sleep and consolidation .Only by making direct interventions to sleep architecture in individual participants can we show that it is sleep itself ( rather than some other state ordinarily associated with sleep ) that is necessary for consolidation .", "label": "", "metadata": {}}
{"text": "The existing literature on motor learning provides evidence to link consolidation to specific sleep stages ( REM sleep , Plihal & Born 1997 ) and specific physiological processes ( Huber et al .Conversely , declarative , episodic memories such as word - pair associations appear to be consolidated during stage 2 slow - wave sleep , presumably by the spindles and k - complexes that predominate in EEG signals recording during this sleep stage ( Plihal & Born 1997 ; Marshall et al .Such findings naturally raise the question of which of these different sleep stages is associated with consolidation of word form knowledge , or indeed whether multiple sleep phases are required for consolidation of word representations that are both declarative and procedural ( Dumay & Gaskell 2007 ) .", "label": "", "metadata": {}}
{"text": "For instance , we reviewed evidence for hippocampal involvement during initial encoding ( indexed by elevated fMRI activity ) , but so far there is little data to show how hippocampal and neocortical representations are coupled .Conversely , we have seen that overnight consolidation appears to reduce elevated cortical responses for pseudowords .However , we have not yet provided any evidence that either initial learning or overnight consolidation can produce an elevated response to pseudowords as a consequence of training .One possible explanation of this finding is that elevated responses to real words reflect neural correlates of semantic representations that were not part of the training procedure used in the study of Davis et al .", "label": "", "metadata": {}}
{"text": "These and other questions are currently being addressed by follow - up functional imaging studies .A further set of questions concerns the nature of the neural connections that support consolidated representations of learned words .The CLS account predicts stronger connections within the cortical network and reduced connections with hippocampal representations for consolidated words .Further , more detailed evidence concerning the nature of neural interactions between neocortical and medial temporal systems at different stages during learning and at different time points after learning would therefore be a valuable test of the CLS account .One final point to be addressed in future work concerns the relationship between neural systems that support short - term representations of pseudowords ( such as in phonological working memory tasks , or that support repetition priming of pseudowords ) and long - term acquisition .", "label": "", "metadata": {}}
{"text": "Imaging studies of auditory - verbal short - term memory have highlighted superior temporal and inferior parietal regions that contribute to echoic and rehearsal - based aspects of pSTM , respectively ( Buchsbaum et al .However , the CLS account predicts that an additional consolidation process is required to turn these short - term representations into long - term lexical knowledge .Functional imaging tests of neural overlap between pSTM and long - term lexical learning would therefore provide an important bridge between the CLS account , and other , pre - existing data concerning the role of pSTM in word learning .", "label": "", "metadata": {}}
{"text": "We have presented an integrative account of the acquisition and recognition of spoken words that combines CLS theory with the existing computational and neuroanatomical accounts of word recognition .A range of behavioural , neuropsychological and functional imaging evidence points towards differential contributions of medial temporal and neocortical systems to rapid initial acquisition and long - term consolidation of spoken words , respectively .Although this account remains under - explored in the domain of word learning there a number of parallels that we have highlighted between word learning and other memory domains .Thus , we believe that the CLS account can provide a firm foundation for cognitive and neuroscientific explorations of processes that are fundamental to language acquisition and processing in adults and infants alike .", "label": "", "metadata": {}}
{"text": "Both the authors contributed equally to this work .This work was supported by funding from the UK Medical Research Council to the Cognition and Brain Sciences Unit ( M.H.D. , U.1055.4.13.1.1 ) , and the Economic and Social Research Council ( M.G.G. , RES-063 - 27 - 0061 ) .We would like to thank Rowena Eason and Jonathan Peelle for their assistance in preparing the fMRI meta - analysis and Shane Lindsay , Pierre Gagnepain and two reviewers for comments and suggestions on an earlier draft of this paper .Footnotes .This is an open - access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}}
{"text": "J. Neurosci .( doi:10.1523/JNEUROSCI.4107 - 04.2005 ) .2008 Spoken word memory traces within the human auditory cortex revealed by repetition priming and functional magnetic resonance imaging .J. Neurosci .( doi:10.1523/JNEUROSCI.0565 - 08.2008 ) .1995 Why there are complementary learning - systems in the hippocampus and neocortex : insights from the successes and failures of connectionist models of learning and memory .Psychol .Rev. 102 , 419 - 457 .( doi:10.1037/0033 - 295X.102.3.419 ) .1989 Catastrophic interference in connectionist networks : the sequential learning problem .In The psychology of learning and motivation ( ed .", "label": "", "metadata": {}}
{"text": "109 - 165 .New York , NY , USA : Academic Press .2005 Methods for reducing interference in the Complementary Learning Systems model : oscillating inhibition and autonomous memory rehearsal .Neural Netw .( doi:10.1016/j.neunet.2005.08.010 ) .2008 Sentence comprehension and voxel - based morphometry in progressive nonfluent aphasia , semantic dementia , and nonaphasic frontotemporal dementia .J. Neurolinguist .( doi:10.1016/j.jneuroling.2008.01.004 ) .Acquiring novel words and their past tense forms : evidence from lexical effects on phonetic categorisation .Paper presented at the ISCA Workshop on Plasticity in Speech Perception , London , UK .", "label": "", "metadata": {}}
{"text": "Nakayama Masashi 1 , 3 , Ishimitsu Shunsuke 2 and Nakagawa Seiji 3 .[ 3 ] National Institute of Advanced Industrial Science and Technology , Japan .Introduction .During recent years , applications using speech recognition have been developed to aid dictation during lectures and to advance voice - prompted car navigation systems .Research in speech recognition has been conducted to improve recognition performance and spoken document processing ( Nakagawa , 2007 ) .However , even with developments in speech recognition technology , high recognition performance can be compromised due to noisy environments .To achieve a high recognition performance , background noise should be minimal , and normal speech should be clear , because the system estimates recognition using a feature vector from its signal .", "label": "", "metadata": {}}
{"text": "When the noise level is low , sound quality becomes clear .However , when the noise level is high , the speech is buried in the noise , causing a change in the speaker 's utterance style , termed the Lombard effect .This change causes the basic frequency to rise because a speaker does not hear the feedback sound from the ear .The method of extracting normal speech under these complex conditions because environment always changes .Several methods have been investigated to extract clear speech under these conditions , such as a noise reduction method , the use of a microphone array or a body - conducted signal .", "label": "", "metadata": {}}
{"text": "The microphone array is typically combined with noise reduction .Body - conducted speech is a robust signal extraction method that differs from the other techniques , because it provides a solid signal that propagates through skin and bone .Previously , we built a body - conducted speech recognition system to recognize speech in a noisy environment ( 98 dB SPL ) , specifically in the engine room of Oshima - maru , a training ship in Oshima National College of Maritime Technology ( Ishimitsu et al ., 2004 ) .We found that this system exhibited an average recognition rate of greater than 95 % .", "label": "", "metadata": {}}
{"text": "Here , we aimed to extract a clear signal using body - conducted speech and to evaluate its efficacy by signal frequency characteristics and recognition performance .Though body - conducted speech gives a robust signal , it does not have a clear quality .Conventional retrieval methods for body - conducted speech include Modulation Transfer Function ( MTF ) , Linear Predictive Coefficients ( LPC ) , direct filtering and the use of a throat microphone .However , these methods need the direct input of speech ( Tamiya and Shimamura , 2006 ; Vu et al . , 2006 ; Liu et al .", "label": "", "metadata": {}}
{"text": ", 2004 ) .Additionally , a conventional microphone does not extract speech in a noisy environment .Thus , we proposed retrieval methods with only body - conducted speech .Body - conducted speech .Characteristics of body - conducted speech .Speech is an air - conducted signal and is easy to influence with surrounding noise .In contrast , body - conducted speech is a solid propagated signal and is less influenced by noise .Figures 1 and 2 demonstrate the word , \" Asahi \" , obtained from the database of JEIDA which contains 100 local place words ( Itahashi , 1991 ) .", "label": "", "metadata": {}}
{"text": "Speech was measured 30 cm from the mouth using a microphone , and body - conducted speech was extracted from the upper lip with an accelerator .This microphone position is commonly used for a speech input of the car navigation system .The upper lip , as a signal extraction position , can provide the best cepstral coefficient characteristic as a feature vector for recognition ( Ishimitsu et al ., 2004 ) .The signals were recorded at 16 kHz and 16 bits .Table 1 shows the recording environments used in this research .Speech generally provides a clear signal ; however , body - conducted speech is not always clear because it lacks a high frequency component ( 2 kHz or more ) .", "label": "", "metadata": {}}
{"text": "Table 1 .Figure 1 .Figure 2 .Body - conducted speech .Differential acceleration .Because body conducted speech does not exhibit a high frequency component , conventional retrieval techniques may also be needed to extract clear speech .However , speech is not well measured with a microphone in noisy environments .Therefore , we aimed to investigate the signal retrieval from body - conducted speech itself .To improve the sound quality , we focused on a high frequency component of 2 kHz or more , however this signal has little gain and includes an effective frequency .", "label": "", "metadata": {}}
{"text": "Even with the changing of sampling frequency and speaker , it was not necessary to design a new filter because the proposed technique allowed signal retrieval with only differential procedure .Figure 3 shows the differential acceleration signal estimated from Figure 2 .Figure 3 becomes a emphasized signal however the stationary noise was included .For this reason , differential acceleration involving a retrieval signal introduces conventional noise reduction ( Gong , 1995 ) .To obtain a signal that approximates natural speech and includes effective frequencies components , conventional noise reduction techniques were employed for the differential acceleration .", "label": "", "metadata": {}}
{"text": "Spectral subtraction method .The spectral subtraction method subtracts the spectrum of the noise sections from the average of spectrum of the noisy signal ( Gong , 1995 ) .Equations ( 1 ) and ( 2 ) describe this method .It is assumed that differential acceleration .x .i . ) consists of the speech signal .s .i . ) and the noise signal .n .i . )An estimated spectrum .S . can be obtained using the spectral subtraction method from Equation ( 2 ) .The phase information on the input signal spectrum , .", "label": "", "metadata": {}}
{"text": ", is represented by . arg .X .Figure 4 shows the results from the spectral subtraction method when the filtering was repeated seven times with a setting frame width of 128 samples .The stationary noise is not removed completely .The characteristics of the high frequency component can not be fully recovered because musical noise is produced in the signal ( Nomura et al . , 2006 ; Yamashita et al . , 2005 ) .So we concluded that it was difficult to recover frequency characteristics with this method .Wiener filtering method .The Wiener filtering method is a technique which estimates a speech spectrum envelope from noisy speech ( Li and O'Shaughnessy , 2003 ) .", "label": "", "metadata": {}}
{"text": "The following equation describes the Wiener filtering method .The estimated signal spectrum , .H .E . s .t .i . m . a .t .e . , is calculated from the noisy speech , .H .S . p .e .e .c . h . , and noise spectrum , .H .N .o .i . s .e .H .E . s .t .i . m . a .t .e . is expressed as a transfer function that converts a noisy signal to a clear signal .", "label": "", "metadata": {}}
{"text": "H .E . s .t .i . m . a .t .e . , autocorrelation functions and linear prediction coefficients by the Levinson Durbin algorithm are required ( Durbin , 1960 ) .Noise spectrum , .H .N .o .i . s .e . , is then estimated by autocorrelation functions and is used as a noise signal in differential acceleration .Figure 5 shows the result of each signal when the coefficient of both linear prediction coefficients and autocorrelation functions were equal to 1 , frame width was 764 sample , and repetition was three times .", "label": "", "metadata": {}}
{"text": "H .S . p .e .e .c . h . and .H .N .o .i . s .e . , the number of the linear prediction coefficients and autocorrelation function used the same number because this setting allows us to solve the problem simply and easily .The number of coefficients was changed from 1 to 32 , the frame width was changed from 128 to 4,096 , and the number of repetitions was also changed from 1 to 5 .The best results were obtained using the conditions shown in Figure 5 .", "label": "", "metadata": {}}
{"text": "Next , we compared the signal difference using spectrograms .The experimental results showed that the Wiener filtering method was suitable for differential acceleration .Improvement using a combination between the proposed method and conventional method .We attempted to extract a clear signal using a combination of differential acceleration and the Wiener filtering method .We next evaluated the combination of the proposed method with various conventional methods including the cross spectrum method and the adaptive filter method .These results are shown in the following sub - sections .Cross spectrum method .The cross spectrum method ( Morise et al . , 2007 ) was introduced using the auto spectrum of body - conducted speech , .", "label": "", "metadata": {}}
{"text": "B .C .S . , and the cross spectrum between normal speech and body - conducted speech , .H .S . p .e .e .c . h .B .C .S .To estimate the retrieval signal , .H .B .C .S .E . s .t .i . m . a .t .e . , the following equation was used .Figure 6 shows the retrieval signal using a transfer function in a word estimated by the cross spectrum method .Sufficient recovery of the frequency characteristic was not observed when processed by the cross spectrum method .", "label": "", "metadata": {}}
{"text": "However , it is possible to improve sound quality using a transfer function for sub - word , because sub - word is a minimum unit of uttered speech ( Ishimitsu et al . , 2007 ) .Figure 3 .Figure 4 .Figure 5 .Figure 6 .Figure 7 .Figure 8 .Figure 9 .Adaptive filter for sub - word unit .Adaptive filter method for word unit .In previous research ( Ishimitsu et al ., 2004 ) , the adaptive filter method ( Haykin , 1996 ) was not enough to recover a sufficient frequency characteristic when body - conducted speech was used as a reference signal .", "label": "", "metadata": {}}
{"text": ", 2004 ) .However , since a retrieval signal using differential acceleration is clear , the estimation of clearest signal can be expected by using the retrieval signal and adaptive filter ( Haykin , 1996 ) .The updated filter method is shown in the following equation and in Figure 7 . where , . w .n . is new filter , .\u03bc is the convergence coefficient , and .n is time index , respectively .Output signal .y .n . ) is provided by input signal .x .n . ) and current filter .", "label": "", "metadata": {}}
{"text": "n . )And then , error signal .e .n . ) is calculated from the difference between the input signal and the output signal .By using an error signal , the system can be used to estimate a new filter part using Equation 5 .Figure 8 shows the retrieval signal using an adaptive filter when the convergence coefficient was set to 0.01 , and the filter length of taps was 16,384 .Subsequently , the coefficients of the final stage of updated adaptive filter were used .Thus , a clear signal was produced using an adaptive filter .", "label": "", "metadata": {}}
{"text": "And it was also confirmed in the spectrogram .Adaptive filter method for sub - word unit .The result of previous sub - section confirmed the efficacy of the proposed method .Next , we proposed the use of an adaptive filter using a sub - word unit .Previously , we constructed the speech support system that used a transfer function for sub - word to create a clear speech from body - conducted speech ( Ishimitsu et al . , 2007 ) .Thus , the sound quality was improved by a transfer function for a sub - word .", "label": "", "metadata": {}}
{"text": "The proposed system would be able to estimate the boundary of a sub - word or a word using the recognition decoder .The continuous sub - word unit recognition decoder is made by Julian that is the Large vocabulary continuous speech recognition system ( Kawahara et al . , 1999 ; Lee et al . , 2001 ) .Our subjects are Japanese , so we choose the Mora unit as a sub - word .The Mora unit is constructed of a vowel or consonant and a vowel .There is a problem in length of sample because the length of an adaptive filter for a sub - word is very short .", "label": "", "metadata": {}}
{"text": "As a result , the adaptive filter for sub - word unit is required the long sample .The input signal can be a long sample using following equation .where .x is the length of long sample ; .i is the number of each sub - word sample , and .N is the number of connection .Figure 9 shows the results of using a adaptive filter for a sub - word .A convergence coefficient of 0.3 and number of connection of 6 times were used .It was possible to recover the high frequency components and the formant frequencies .", "label": "", "metadata": {}}
{"text": "The adaptive filter for word unit compared with the adaptive filter for sub - word unit , so we decided that the adaptive filter for word unit is suitable for retrieval signal with differential acceleration .Investigation of characteristics difference .To evaluate the efficacy of the retrieval signals , the following signals were compared with speech : .Retrieval signal with Wiener filtering and the cross spectrum method ( Cross ) .Retrieval signal with Wiener filtering and the adaptive filter for word ( Adaptive 1 ) .Retrieval signal with Wiener filtering and the adaptive filter for sub - word ( Adaptive 2 ) .", "label": "", "metadata": {}}
{"text": "Figure 11 shows the difference between speech and the signal retrieves by the spectral subtraction method , and Figure 12 represents the difference between speech and the signal retrieves using Wiener filtering .As shown in Figure 10 , there was a large difference between speech and body - conducted speech , including the formant frequencies greater than 2 kHz .However , body - conducted speech had no formant frequencies which are characteristic of the Japanese vowels .Comparing Figures 11 and 12 , there was little difference in the frequency component .Particularly , as shown in Figure 12 , the difference of formant frequencies was minimal .", "label": "", "metadata": {}}
{"text": "This technique worked effectively because the predictive coefficients provided suitable parameters in each retrieval phase .Therefore , we concluded that the most suitable noise reduction method was Wiener filtering combined with differential acceleration .Figures 13 , 14 and 15 demonstrate the differences between speech and each retrieval signal that was used in combination with a conventional method .These include the retrieval signals obtained using differential acceleration calculated from the cross spectrum method or an adaptive filter for a word or for a sub - word .Each figure was compared with its original signal obtained with Wiener filtering .", "label": "", "metadata": {}}
{"text": "The difference was similarly extended in Figure 15 .The retrieval signal calculated from the adaptive filter for a sub - word could not extract a clear signal from the body - conducted speech because the number of samples was reduced in each sub - word duration .However , there was a marginal difference of spectrograms in all frequencies of Figure 14 .Therefore , the adaptive filter for a word was confirmed as the most suitable retrieval method when it was combined with retrieval signal of differential acceleration .Figure 10 .Figure 11 .Figure 12 .", "label": "", "metadata": {}}
{"text": "Figure 14 .Figure 15 .Difference of Adaptive 2 .Recognition experiment .Next , we evaluated the performance of the proposed method with an isolated word recognition experiment .In previous research , we constructed the body - conducted speech recognition system , which could perform in noisy environments , specifically in the engine room of a training ship ( Ishimitsu et al ., 2004 ) .Here , to obtain a high recognition performance , the acoustic model needed to re - estimate the parameter using body - conducted speech .Because it is possible to estimate a speech from body - conducted speech , it expects that the retrieval signal can be directory used to speech recognition .", "label": "", "metadata": {}}
{"text": "Therefore , to perform an objective experiment with statistical analysis , the recognition rate of isolated word recognition was evaluated using an acoustic model for unspecified speakers built with a speech .Generally , a subjective listening experiment is often used to evaluate the sound quality however it needs many people and much data as a admitting result .Speech recognition was matched with the feature vector of each signal .The model parameters were able to approximate a natural speech when the recognition rate compared with body - conducted speech to each retrieval signal .Additionally , because HMM is an acoustic model that evaluates each feature vector using the output of a multi - dimensional normal distribution , it can be evaluated statistically .", "label": "", "metadata": {}}
{"text": "Table 2 shows the experimental environments for isolated word recognition .The recognition decoder , Julius ( Kawahara et al . , 1999 ; Lee et al . , 2001 ) , was used in this experiment .Because Julius is a decoder for large vocabulary continuous speech recognition , it can be changed into isolated word recognition .Thus , it became possible to recognize words without a language model .JEIDA 100 local place words were used as candidates for word recognition ( Itahashi , 1991 ) .The words consisted of a database of Japanese place names after consideration of phoneme balance .", "label": "", "metadata": {}}
{"text": "The differential acceleration was processed with the parameter used in the previous chapter .The candidates for recognition in this experiment included each of the following signals : .The body - conducted speech was compared with the retrieval signal from the recognition experiment .It was expected that the recognition performance would improve if the signal approximated natural speech from the body - conducted speech .Tables 3 - 5 show the recognition rate in each speaker .And Table 6 shows the average of all speakers .There was an improvement of 3 - 9 % in Speakers B and C but little improvement in Speaker A. About 5 % of the improvement was obtained through average of the recognition rate .", "label": "", "metadata": {}}
{"text": "Using an adaptation technique to estimate the new parameter in an acoustic model , the recognition performance increased to greater than 95 % .Here , we focused on the investigation of the signal retrieval , so the feature vectors in the acoustic models did not need new parameters in this experiment .Though the improvement was marginal , this result demonstrated the effectiveness for signal retrieval without speech .We expect that these recognition rates can be greatly improved by fine - tuning parameters for each speaker using an adaptation technique .Table 5 .Table 6 .Recognition results of all speakers .", "label": "", "metadata": {}}
{"text": "Signal recording in a noisy environment .In order to acquire , a noisy environment , we used the engine room of the ' Oshima - maru ' training ship from the Oshima National College of Technology , Japan .Noise within the engine room , under the two conditions of anchorage and cruising , were 93 and 98 dB SPL , respectively , and the SNR measurements from microphone .There was -20 and -25 dB SNR , respectively .The signals of 100 words , from the database of JEIDA were read three times in each environment by three males aged 20 , 20 and 37 years old .", "label": "", "metadata": {}}
{"text": "In this study , we experimented under anchorage condition to estimate retrieval signals .Figures 16 and 17 demonstrate the word \" Ageo \" that was obtained from the database of JEIDA .Figures 16 and 17 exhibit speech and body - conducted speech signals from the engine room of the Oshima - maru .Because body - conducted speech is a structure bone sound , it is less influenced by noise than normal speech .Unlike body - conducted speech , normal speech signals do not detect the utterance of speakers .Comparing Figures 2 and 17 , there was little difference of frequency characteristic between quiet and noisy environment , so it expects that the proposed method for signal retrieval can apply to the signal in noisy environment .", "label": "", "metadata": {}}
{"text": "Figure 17 .Body - conducted speech in noise .Differential acceleration in a noisy environment .The signals can be a clear with same setting of signal retrieval in quiet room with proposed method .Difference in signals characteristics between speech and body - conducted speech are little because that reason is shown a difference of Figures 2 and 17 .Thus , we also estimate the differential acceleration directory which the difference between the signals is calculated .Figure 18 shows the differential acceleration estimated from Figure 17 .Body - conducted speech was extracted with an accelerator from the noisy environment .", "label": "", "metadata": {}}
{"text": "Therefore , differential acceleration in the noisy environment exhibited a clearer signal compared with that extracted in the quiet environment .Signal retrieval for body - conducted speech in a noisy environment .The signal characteristic of body - conducted speech in a noisy environment is not affected by noise ; however , the basic frequency of the signal rises by the Lombard effect .Generally , since the decoder only uses spectral envelopes as recognition parameters , the problem is a matter of no importance .Figures 19 , 20 and 21 show the retrieval signals using the proposed methods that differ in the number of Wiener filtering repetitions .", "label": "", "metadata": {}}
{"text": "The estimated signal rejected stationary noise from the differential acceleration completely .The effect of repetitions was also clearly observable .We found that three repetitions allowed stationary noise to be completely reduced .In this study , parameter . settings in Wiener filtering were the same as for a quiet room because difference in signal characteristic between quiet and noise is little .From Figure 21 , we expect that performance of speech recognition can also be improved .Decoding algorithm for differential acceleration .Problem of recognition for differential acceleration .The differential acceleration exhibited a distorted signal when a consonant was present .", "label": "", "metadata": {}}
{"text": "However , the signal levels of vowels are high because of the formant frequencies .Thus , vowels were kept intact .The stationary noise level changed according to the environment of .Figure 18 .Figure 19 .Figure 20 .Figure 21 .Retrieval signal with Wiener 3 . the recording signal , so the number of the suitable repetitions should be selected appropriately for recognition with the proposed retrieval method and noise environment .The recognition performance decreases if the repetitions are not sufficient when the stationary noise level is changed .To solve the problem , we have to invent decision method for number of repetition in Wiener filtering .", "label": "", "metadata": {}}
{"text": "The algorithm chooses the clearest signal because it is appeared a highest likelihood from the recognition decoder .So we apply this idea to the decoding algorithm for differential acceleration .Fundamental speech recognition .The fundamental speech recognition is described as follows briefly ( Rabiner , 1993 ) .Speech were recorded with a microphone and sampled at 16 kHz and 16 bits .As part of the recognition parameters , speech data were converted to the feature vectors as cepstrum coefficients .Speech recognition systems often use cepstrum techniques that consist of LPC and melfrequency cepstral coefficients ( MFCCs ) ( Davis and Mermelstein , 1980 ) .", "label": "", "metadata": {}}
{"text": "The differences in coefficients ( \u0394MFCC ) and power ( \u0394LogPow ) were also incorporated into the feature vectors .The recognition system then uses these parameters to discriminate sub - word or word unit candidates .Each sub - word or word unit model consists of hidden Markov models ( HMM ) ( Rabiner , 1993 ) , which have transition probability and output probability distributions .A neural network ( NN ) is also used in speech recognition previously .However ANN is applied to other application ( Rivara et al . , 2009 ) , speech recognition systems uses only HMM recently .", "label": "", "metadata": {}}
{"text": "This system calculates the likelihood ( nearness of each acoustic model to an input parameter ) using feature vectors and HMM .From the highest likelihood , the system can determine the candidate word / sub - word HMM .Generally , likelihood of acoustic models is computed with Viterbi algorithms .This recognition system includes dictionary and acoustic models , however no language models .The dictionary indicates the sub - word sequence for a word , because a word consists of the sub - word unit acoustic model .Equation ( 6 ) shows the fundamental formulation of this isolated word / sub - word recognition .", "label": "", "metadata": {}}
{"text": "^ is an estimated candidate , .W is set of all candidates , w represents each candidate in .W , and .X .x .x .x .n are feature vectors .P .X .w . ) is likelihood from the acoustic model .Generally , the acoustic model represents the sub - word or word unit .The system determines the estimated candidate by the likelihood from each HMM .Proposed algorithm .To avoid decreasing of the recognition performance , the decoder algorithm was improved for signal retrieval using differential acceleration .", "label": "", "metadata": {}}
{"text": "First , the speaker uttered a word , and its signal was then extracted with the accelerator .Thus , the signals .X .X .X .N were performed for speech recognitions as input signals .The signals of Figure 22 represent original body - conducted speech , differential acceleration and retrieval signals using Wiener filtering .This experiment focused on the body - conducted speech recognition in a noisy environment , so the speech signal is removed in this experiment .Although the recognition performance is improve that its decoder combines speech as input signal when the noise level is low .", "label": "", "metadata": {}}
{"text": "The recognition decoders give the recognition results that are the candidates of words .w .w .w .N .The parameters of the frame lengths and acoustic scores differ in scale for each signal because Wiener filtering causes a problem in sample length .To compare the acoustic scores , it was necessary to regulate the number of samples .The regulated acoustic score was calculated by the acoustic score and flame length .With equation ( 8) , each score was compared and then the decoder determined the final candidate using the regulated acoustic scores .", "label": "", "metadata": {}}
{"text": "Finally , we evaluated the signal retrieval from body - conducted speech in a noisy environment with conventional decoding and the decoding algorithm for differential acceleration .The following signals and decoding algorithms were performed in this experiment : .Wiener 1 : differential acceleration using Wiener filtering that is repeated one time .Wiener 2 : differential acceleration using Wiener filtering that is repeated two times .Wiener 3 : differential acceleration using Wiener filtering that is repeated three times .Max : the decoding algorithm for differential acceleration using regulated acoustic scores from the retrieval signals and body - conducted speech .", "label": "", "metadata": {}}
{"text": "The experimental environments are shown Table 2 . R .e . l . a .t .i .v .e .I . m .p .r .o .v .e . m .e . n .t .C .o .r .r .e . c .t .r . a .t .e . B .C .o .r .r .e . c .t .r . a .t .e .A .C .o .r .", "label": "", "metadata": {}}
{"text": "e . c .t .r . a .t .e .A . [ . % . ]Equation ( 9 ) is a word correct rate , which calculates a result whether the word is recognized or not .Equation ( 10 ) is relative improvement , depicting major improvements above base line levels .Recognition results .Retrieval signals with Wiener filtering exhibited marginal improvement with a decrease in recognition because the algorithm rejects a stationary noise and consonant frequency .This problem is described in Section 8.1 .We speculated that the noise reduction made improved the recognition performance when the stationary noise level was louder .", "label": "", "metadata": {}}
{"text": "Tables 7 - 9 are shown the recognition results of each speaker .And Table 10 is the result of average of all speakers .The meaning of each data is described in Section 5 .In all speakers , the recognition performances are improved on ' Diff .Acc . ' and ' Max ' however Wiener 's results are little improvement . 'Diff .Acc . 'becomes a clear signal in this experiment because it does not produce a stationary noise from differential acceleration .And ' Max ' is worked on the recognition experiment correctly , so it is proven by Table 10 that the effectiveness of the combination method using retrieval method of signal and its decoding algorithm .", "label": "", "metadata": {}}
{"text": "Table 9 .Table 10 .Recognition results of all speakers in noisy environment .Conclusions and future work .Here , we investigated a signal retrieval from body - conducted speech using differential acceleration combined with conventional noise reduction methods .Specifically , differential acceleration was used to emphasize the high frequency component of body - conducted speech .Additionally , this method is little cost in calculation .Although the differential acceleration of body - conducted speech became a retrieval signal when stationary noise was present .Thus , it was possible to remove noise effectively using conventional noise reduction methods i.e. spectral subtraction or Wiener filtering .", "label": "", "metadata": {}}
{"text": "So , this method can be used to estimate a clear speech using only body - conducted speech .Thereafter , we combined the proposed method and conventional signal retrieval methods to make a clear signal .Combined methods using an adaptive filter for a word , its effectiveness is shown the results in the difference of spectrograms between each signal and speech .Thus , it appears that the proposed method was effective when pre - processing for the conventional signal retrieval techniques existed .The recognition experiment using the differential acceleration followed by the Wiener filtering method , demonstrated the efficacy of differential acceleration that the recognition performance improved 3 - 5 % in isolated word recognition .", "label": "", "metadata": {}}
{"text": "So we concluded that the proposed method was able to estimate clear speech from body - conducted speech in quiet room .As a next step of the proposed method , we applied the noise reduction methods to body - conducted speech in a noisy environment .From the experimental results , the Wiener filtering method proved to be a suitable noise reduction method for differential acceleration as evidenced by comparing spectrograms with normal speech and each retrieval signal in a noisy environment .To decide the suitable number of repetitions on Wiener filtering , we proposed a decoding algorithm that was used to regulate the acoustic scores .", "label": "", "metadata": {}}
{"text": "Furthermore , the system does not depend on the environments and speakers because the system chose the highest likelihood from the signals .As a future works , we will be examined as a pre - processing for the speech support system using body - conducted speech for disorders that converts a clear speech from body - conducted speech of disorders ( Ishimitsu and Nakayama , 2009 ) .And , the signal retrieval using differential acceleration is applied to body - conducted speech in noisy environments .Furthermore , we will also construct the microphone using body - conducted speech and differential acceleration for noise environment .", "label": "", "metadata": {}}
{"text": "IEEE International Workshop on Multimedia Signal Processing ( MMSP'04 ) , 363 366 . 8 - S. Dupont , C. Ris , D. Bachelart , 2004 Combined use of closetalk and throat microphones for improved speech recognition under non - stationary background noise , in proc .COST278 and ISCA Tutorial and Research Workshop ( ITRW ) on Robustness Issues in Conversational Interaction , paper31 .12 - K. Yamashita , S. Ogata , T. Shimamura , 2005 Improved Spectral Subtraction Utilizing Iterative Processing , in Trans . of IEICE on Inst . of Electronics , Information and Communication Engineers , J88-A 11 1246 1257 .", "label": "", "metadata": {}}
{"text": "European Conference on Speech Communication and Technology ( EUROSPEECH ) , 1691 1694 .20 - K. Itou , M. Yamamoto , K. Takeda , T. Takezawa , T. Matsuoka , T. Kobayashi , K. Shikano , S. Itahashi , 1999 JNAS : Japanese speech corpus for large vocabulary continuous speech recognition research , in Journal of ASJ , 20 3 199 206 .23 - S. B. Davis , P. Mermelstein , 1980 Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences , IEEE Trans .Acoustics , Speech Signal Proc . , ASSP-28 , 4 357 366 .", "label": "", "metadata": {}}
{"text": "25 - S. Ishimitsu , M. Nakayama , 2009 Construction of Speech Support System Using Body - Conducted Speech Recognition for Disorders , in proc . of The Third International Conference on Innovative Computing , Information and Control ( ICICIC2008 ) , CD - ROM all Addendum Article Book Review Case Report Comment Commentary Communication Concept Paper Conference Report Correction Creative Data Descriptor Discussion Editorial Erratum Essay Interesting Images Letter New Book Received Obituary Opinion Project Report Reply Retraction Review Short Note Technical Note .Hierarchical Recognition Scheme for Human Facial Expression Recognition Systems .UC Lab , Department of Computer Engineering , Kyung Hee University , Yongin - Si 446 - 701 , Korea .", "label": "", "metadata": {}}
{"text": "Author to whom correspondence should be addressed ; Tel . : +82 - 31 - 201 - 2514 .Received : 28 October 2013 ; in revised form : 30 November 2013 / Accepted : 2 December 2013 / Published : 5 December 2013 .Abstract .: Over the last decade , human facial expressions recognition ( FER ) has emerged as an important research area .Several factors make FER a challenging research problem .These include varying light conditions in training and test images ; need for automatic and accurate face detection before feature extraction ; and high similarity among different expressions that makes it difficult to distinguish these expressions with a high accuracy .", "label": "", "metadata": {}}
{"text": "Unlike the previous systems , the HL - FER uses a pre - processing step to eliminate light effects , incorporates a new automatic face detection scheme , employs methods to extract both global and local features , and utilizes a HL - FER to overcome the problem of high similarity among different expressions .Weighted average recognition accuracy of 98.7 % across three different datasets , using three classifiers , indicates the success of employing the HL - FER for human FER .Keywords : . face detection ; GHE ; facial expressions ; PCA ; ICA ; LDA ; HMMs .", "label": "", "metadata": {}}
{"text": "Human FER systems can be classified into two categories ; pose - based expression recognition systems [ 5 - 7 ] and spontaneous expression recognition systems [ 8 - 10 ] .Pose - based expressions are the artificial expressions produced by people when they are asked to do so [ 2 ] .Similarly , spontaneous expressions are those that people give out spontaneously , and they can be observed on a day - to - day basis , such as during conservations or while watching movies [ 2 ] .The focus of this article is pose - based FER systems .", "label": "", "metadata": {}}
{"text": "The pre - processing module performs two tasks .Firstly , it diminishes illumination and other light effects to increase the recognition accuracy , using techniques like morphological filters , homomorphic filters , or median filters .Most previously FER systems [ 11 - 15 ] have exhibited low accuracy due to the lack of this filtering element in their architecture .One of the most well - known methods that have been utilized to diminish such illumination effects is histogram equalization ( HE ) .However , in a gray level image HE assigns the highest gray level value to each pixel [ 16 ] , as a result the resulting image produced by HE contains gaps i.e. , \" empty - bins \" between very full histogram bins [ 17 ] .", "label": "", "metadata": {}}
{"text": "Therefore , two improved versions of HE were proposed in order to solve the limitations of HE .The first technique is Local Histogram Equalization ( LHE ) that uses a sliding window technique in order to compute the local histogram for each pixel and the gray level for center pixel is changed accordingly [ 17 ] .LHE , though better than HE , causes over - enhancement , and sometimes it produces checkerboards of the enhanced image [ 20 ] and it requires more time than other methods [ 21 ] .The second technique is Global Histogram Equalization ( GHE ) , which uses the histogram information of the whole image ; therefore , we employed GHE instead of using HE and LHE in preprocessing module .", "label": "", "metadata": {}}
{"text": "Naturally , before recognizing facial expressions a face is must be located in the image / video frame .Therefore , the second task of the preprocessing module is to detect faces in a given image , as it is the face that contains most of the expression - related information .For this , many well - known methods , including the appearance - based methods [ 22 , 23 ] , have been proposed .The appearance - based methods have shown excellent performance in a static environment ; however , their performance degrades when used in dynamic situations [ 24 ] .", "label": "", "metadata": {}}
{"text": "These methods utilize eye window ( eye regions ) in order to locate a face .However , eyes regions are highly sensitive to the hairstyle of the person , which may cause misclassification [ 27 ] .Moreover , in their methods , it is very hard to know the orientation of the detected face [ 27 ] .Many existing works , such as [ 28 - 30 ] , have performed facial expression recognition without face detection , making these systems heuristic in nature .To solve this problem , some face detection and extraction techniques were proposed [ 31 - 33 ] .", "label": "", "metadata": {}}
{"text": "However , this method failed to detect the face structure in very sensitive environmental conditions .In contrast , in [ 33 ] features for face detection were selected manually .PCA has been exploited by [ 34 , 35 ] to extract the features from eyes and the lips , which were then employed by a framework of radial basis function network ( RBFN ) to classify the expressions based on the extracted features .PCA extracts only the global features ; therefore , another well - known higher statistical order technique named ICA has also been widely employed in FER systems to extract the local features .", "label": "", "metadata": {}}
{"text": "As ICA is an unsupervised technique ; therefore , in their work , they modified the classical ICA and made it a supervised ICA ( sICA ) by including a prior knowledge that was reassembled from the training data using a Maximum Posteriori ( MAP ) scheme .Regarding the feature extraction module , several methods have been explored .In this article , we utilized the holistic feature extraction methods , i.e. , Principal Component Analysis ( PCA ) and Independent Component Analysis ( ICA ) in order to extract the prominent features from the expression frames .As for the recognition module , several classifiers have been investigated .", "label": "", "metadata": {}}
{"text": "However , an ANN is a black box and has incomplete capability to explicitly categorize possible fundamental relationships [ 52 ] .Moreover , the FER systems proposed in [ 8 , 53 - 57 ] used support vector machines ( SVMs ) .However , in SVMs , the probability is calculated using indirect techniques ; in other words , there is no direct estimation of the probability , these are calculated by employing five - fold cross validation due to which SVM suffers from the lack of classification [ 58 ] .Furthermore , SVMs simply disregard the temporal addictions among video frames , thus each frame is expected to be statistically independent from the rest .", "label": "", "metadata": {}}
{"text": "As stated earlier , the features could be very sensitive to noise ; therefore , fast variations in the facial frames can not be modeled by GMMs and produces problems for sensitive detection [ 61 ] .Hidden Markov Models ( HMMs ) are mostly used to handle sequential data when frame - level features are used .In such cases , other vector - based classifiers like GMMs , ANNs , and SVMs , have difficulty in learning the dependencies in a given sequence of frames .Due to this capability , some well - known FER systems , including [ 62 - 64 ] , utilized HMM as a classifier .", "label": "", "metadata": {}}
{"text": "Among them , PCA and ICA have been the most widely used feature extraction techniques , and HMMs have been the most commonly used classifier .A recent work by Zia et al .[ 64 ] proposed a complete approach for FER systems that provided high classification accuracy for the Cohn - Kanade database of facial expressions .In their work , they employed PCA and ICA for feature extraction .Once extracted , features were subject to Linear Discriminant Analysis ( LDA ) to find the most relevant features .The result after applying LDA was fed to an HMM .", "label": "", "metadata": {}}
{"text": "However , their technique failed in exhibiting the same accuracy when tested by us on other datasets , such as Japanese Female Facial Expression ( JAFFE ) database ( 83 % ) , and AT&T database ( 72 % ) of facial expressions .Low accuracy in these new experiments could be attributed to the following two reasons .Firstly , in their work , they did not use a pre - processing step to diminish the lighting and illumination effects .Furthermore , in some of the databases such as the AT&T database of facial expressions , the subjects have worn glasses that make it difficult to extract useful features from some parts of the face , such as the eyes .", "label": "", "metadata": {}}
{"text": "Zia et al .[ 64 ] applied LDA to the extracted feature space to improve the class separation among different classes with the assumption that the variance is distributed uniformly among all the classes .However , this is not the case .For example , expressions like happiness and sadness are very similar to each other but can easily be distinguished from anger and fear ( another pair with high similarity ) .Accordingly , this work implements a HL - FER that is capable of performing accurate facial expression recognition across multiple datasets .Previously , such model has been used in [ 65 ] that was dual - layer SVM ensemble classification .", "label": "", "metadata": {}}
{"text": "However , the performance of the dual - layer SVM classification can not match that of binary classification as SVMs use approximation algorithms in order to decrease the computation complexity but these have the effect of degrading classification performance [ 66 ] .In our HL - FER , firstly , images were passed through a pre - processing module to diminish the illumination effects , and to extract the human face automatically .Secondly , PCA and ICA were used for feature extraction .Finally , a hierarchical classifier was used , where the expression category was recognized at the first level , followed by the actual expression recognition at the second level .", "label": "", "metadata": {}}
{"text": "The results of these experiments show that the two - level recognition scheme , along with the proposed pre - processing module for noise reduction and accurate face detection , solved the aforementioned problems of the existing FER systems ; and therefore , succeeded in providing high recognition accuracy across multiple datasets .Above , we discussed some related work in this field .The rest of the paper is organized as follows .Section 2 provides an overview of our HL - FER .Section 3 discusses the experimental setup along with the experimental results with some discussion on the results and talks about the factors that could degrade systems performance if tested in real - life scenarios .", "label": "", "metadata": {}}
{"text": "Finally , the paper is concluded with some future directions in Section 5 .Materials and Methods .Pre - Processing .As mentioned earlier , in most of the datasets , the face images have various resolution and backgrounds , and were taken under varying light conditions ; therefore , pre - processing module is necessary to improve the quality of images .At this stage , background information , illumination noise , and unnecessary details are removed to enable fast and easy processing .After employing this stage , we can obtain sequences of images which have normalized intensity , size and shape .", "label": "", "metadata": {}}
{"text": "However , LHE causes over - enhancement , and sometimes it produces checkerboards of the enhanced image [ 38 ] .Therefore , we employed a GHE for diminishing illumination effects .To the best of our knowledge , this is the first time GHE has been exploited for facial expression recognition .For more detail on GHE , please refer to [ 39 ] .In the proposed face detection algorithm , two improved key face detection methods were used simultaneously : gray - level and skin - tone - based .To attain the best performance , the similarity angle measurement ( SAM ) method was used .", "label": "", "metadata": {}}
{"text": "The overall energy function can be defined as : .E .C . )F .C . )B .C . )F .C . ) inside .C . )I .c . i .n .d .x . outside .C . )I .c . out .d .x . where c in and c out are the average intensities inside and outside the variable boundary C , and I is the facial image .Furthermore : . B .C . )z .f .x . )", "label": "", "metadata": {}}
{"text": "x . )d .x .where : . f .x . )K .x . )[ .H .x . )I . ]K .x . )[ .H .x . ) . ]and : . f .x . )K .x . )[ .H .x . )I . ]K .x . )[ .H .x . ) . ]The facial geometry function \u03d5 ( x ) implementation for the energy functional in Equations ( 4 ) and ( 5 ) is carried out in order to define the boundary between the two regions ( face and background ) and can be derived as : . x . ) t .", "label": "", "metadata": {}}
{"text": "I .c . i .n . )I .c . out . ) 2 . ][ .B .C . )A . i .n .A . out . )z .K .z .A . out .f .x . )f .x . )A . i .n .f .x . )f .x . ) d .z .] Once the boundary between face and background is found , then in the next step , the skin - tone and gray - level methods are collectively applied in order to accurately detect and extract the face from the facial frame .", "label": "", "metadata": {}}
{"text": "In summary , the proposed face detection system is based on multiple features from a face image / frame .When a rough face image is presented to the system , an improved gray - level and skin - tone model is adopted to locate the face region .Very often , hair is included in the detected head contour .The second step is to find the precise face geometry using a facial geometry operation .We have developed a facial geometry filter for extracting potential face windows , based on similarity measurements of facial geometry signatures .This process generates a list of possible face signatures , since each face feature has unique identification , or signatures .", "label": "", "metadata": {}}
{"text": "The stored face signatures were in true ( original ) form and were not distorted .However , in some cases , the detected face boundary usually might consist of hair [ 68 ] .Hairstyles are different from person to person [ 69 ] .Therefore , in the next step another technique , i.e. , face skin region has been employed in order to locate the skin region from the detected face region and to get rid of the problem of different hairstyles .The facial features such as nose , mouth , and eyes possess relatively lower gray levels under normal illumination [ 27 ] .", "label": "", "metadata": {}}
{"text": "In most images , the number of possible cases for the second iteration of the loop ( see Figure 4 ) was less than two .For each possible case , the signature similarity measurement ( SSM ) function was adopted for face detection , tracking , and verification .If the face was detected in the face frame , the detection process completed ; if not , next possible case was tested .Details of each block are presented in Figure 4 .Feature Extraction .As described earlier , numerous techniques have been developed and validated for the purpose of feature extraction for FER systems .", "label": "", "metadata": {}}
{"text": "Therefore , we decided to use PCA and ICA for feature extraction to extract both the global and local features respectively .Recognizing the Expression Category .This work is based on the theory that different expressions can be grouped into three categories based on the parts of the face that contribute most toward the expression [ 70 - 72 ] .This classification is shown Table 1 .Lips - based expressions are those in which the lips make up the majority of the expression .In lips - eyes - based expressions , both lips and eyes contribute in the expression .", "label": "", "metadata": {}}
{"text": "In the HL - FER , an expression is classified into one of these three categories at the first level .At the second level , classifier ( trained for the recognized category ) is employed to give a label to this expression within this category .At the first level , LDA was firstly applied to the extracted features from all the classes and an HMM was trained to recognize the three expression categories : lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions .The LDA - features for these three categories are shown in Figure 5 .", "label": "", "metadata": {}}
{"text": "Recognizing the Expressions .As mentioned earlier , once the category of the given expression has been determined , the label for the expression within the recognized category is recognized at the second level .For this purpose , LDA was applied separately to the feature space of each category and the result was used to train three HMMs , one HMM per category .Collectively , the overall results for all the expression classes are shown in Figure 6 .These feature plots indicate that applying LDA to the features of three categories separately provided a much better separation as compared to single - LDA via single - HMM approach ( see Figure 7 ) .", "label": "", "metadata": {}}
{"text": "For Figures 5 , 6 and 7 , we used Cohn - Kanade dataset , for Figures 8 , 9 and 10 , we employed JAFFE dataset , and for Figures 11 , 12 and 13 , we used AT&T dataset .Each dataset consisted of six basic universal facial expressions and each expression has twelve facial expression frames .We have sequential data at both levels ; therefore at both levels HHMs have been employed , because HMMs have their own advantage of handling sequential data when frame - level features are used .In such cases , other vector - based classifiers like GMMs , ANNs , and SVMs , have difficulty in learning the dependencies in a given sequence of frames .", "label": "", "metadata": {}}
{"text": "O .Q .The parameters that used to model HMM for all experiments were 44 , 4 , and 4 respectively .Experimental Results .Setup .These datasets display the frontal view of the face , and each expression is composed of several sequences of expression frames .During each experiment , we reduced the size of each input image ( expression frame ) to 60 \u00d7 60 , where the images were fi wh converted to a zero - mean vector of size 1 \u00d7 3,600 for feature extraction .All the experiments were performed in Matlab using a dual - core Pentium processor ( 2.5 GHz ) with a RAM capacity of 3 GB .", "label": "", "metadata": {}}
{"text": "Cohn - Kanade Dataset .In this facial expressions dataset , there were 100 subjects ( university students ) performed basic six expressions .The age range of the subjects were from 18 to 30 years and most of them were female .We employed those expression for which the camera was fixed in front of the subjects .By the given instructions , the subjects performed a series of 23 facial displays .Six expressions were based on descriptions of prototypic emotions such as happy , anger , sad , surprise , disgust , and fear .In order to utilize these six expressions from this dataset , we employed total 450 image sequences from 100 subjects , and each of them was considered as one of the six basic universal expressions .", "label": "", "metadata": {}}
{"text": "For recognition purpose , twelve expression frames were taken from each expression sequence , which resulted in a total of 5,400 expression images .JAFFE Dataset .We also employed Japanese Female Facial Expressions ( JAFFE ) dataset in order to assess the performance of the HL - FER .The expressions in the dataset were posed by 10 different ( Japanese female ) subjects .Each image has been rated on six expression adjectives by 60 Japanese subjects .Most of the expression frames were taken from the frontal view of the camera with tied hair in order to expose all the sensitive regions of the face .", "label": "", "metadata": {}}
{"text": "Therefore , we selected 205 expression frames for six facial expressions performed by ten different Japanese female as subjects .The size of each facial frame was 256 \u00d7 256 pixels .AT&T Dataset .Additionally , we also employed AT&T dataset of facial expressions to evaluate the performance of the HL - FER .There are 10 facial frames in each expression performed by 40 distinct subjects .The frames were taken at different illuminations of light against a dark homogenous background with the subjects , and were in grey scale having size of 92 \u00d7 112 pixels .", "label": "", "metadata": {}}
{"text": "Among these expressions , few expressions that showed the basic six expressions ; therefore , we have manually chosen those suitable facial frames for our experiments .The total numbers of selected facial frames were 240 .Moreover , in order to show the efficacy of the HL - FER , we performed some more experiments on Yale database of facial expressions [ 76 ] .The results are shown in the Appendix in Figures A1 , A2 , A3 , and A4 and in Table A5 respectively .Results and Discussion .Experimental Face Detection Method Results .Some samples results for the proposed preprocessing method ( GHE ) along with the proposed face detection are shown in Figure 14 .", "label": "", "metadata": {}}
{"text": "After this , in the next step , the proposed face detection method found the facial faces in the frames ( shown in Figure 14c ) and cropped it accordingly , as shown in Figure 14d .The detection rates of the proposed face detection algorithm for the three datasets are summarized in Table 2 .It can be seen from Table 2 that the proposed face detection algorithm achieved high recognition rate on the three different standard datasets of facial expressions .Experimental Results of HL - FER Based on Subjects .The experiments for the HL - FER were performed in this order .", "label": "", "metadata": {}}
{"text": "Each dataset possessed different facial features , such as some of the subjects have worn glasses in AT&T dataset while the subjects of the Cohn - Kanade and JAFFE datasets are free of glasses .The remaining facial features of AT&T and Cohn - Kanade datasets are quite similar with each other .On the other hand , the facial features , such as the eyes of the subjects in the JAFFE dataset are totally different from the eyes of the subjects of AT&T and Cohn - Kanade datasets [ 77 , 78 ] .The HL - FER was evaluated for each dataset separately that means for each dataset , n -fold cross - validation rule ( based on subjects ) was applied .", "label": "", "metadata": {}}
{"text": "The value of n varied according to the dataset used .The detailed results of this experiment for the three datasets are shown in Tables 3 , 4 and 5 , respectively .Despite of all these differences , the HL - FER consistently achieved a high recognition rate when applied on these datasets separately , i.e. , 98.87 % on Cohn - Kanade , 98.80 % on JAFFE , and 98.50 % on the AT&T dataset .This means that , unlike Zia et al .[ 64 ] , the HL - FER is robust i.e. , the system not only achieves high recognition rate on one dataset but shows the same performance on other datasets as well .", "label": "", "metadata": {}}
{"text": "Experimental Results of HL - FER Based on Datasets .In the second experiment the HL - FER cross - dataset validation was performed .This means that from the three datasets , data from the two datasets were retained as the validation data for testing the system , and the data from the remaining dataset was used as the training data .This process was repeated three times , with data from each dataset used exactly once as the training data .Similarly , the experimental results of the HL - FER at the second level are summarized in Tables 9 , 10 , and 11 respectively .", "label": "", "metadata": {}}
{"text": "Thirdly , a set of experiments was performed to assess the effectiveness of each module of the HL - FER ( pre - processing , face detection and hierarchical recognition ) separately .This experiment was repeated three times and the recognition performance was analyzed under three different settings : Firstly , the experiment was repeated without the pre - processing step .Secondly , the experiment was performed without including the face detection module .And , lastly , a single LDA and HMM were used to recognize all the expressions instead of using the HL - FER .", "label": "", "metadata": {}}
{"text": "As indicated in Tables 13 , 15 , and 17 , the hierarchical recognition is mainly responsible for the high recognition accuracy of the HL - FER .When we removed the hierarchical recognition module , the recognition rate decreased significantly .These results support the theory that the problem of high similarity among the features of different expressions is a local problem .In other words , the features exist in the form of groups in the overall feature space .In the next experiment , the accuracy of the HL - FER when tested across different datasets decreased significantly .", "label": "", "metadata": {}}
{"text": "As explained earlier , the facial structures , especially eyes , of the subjects in the Japanese dataset are very different than those of the AT&T and Cohn - Kanade datasets [ 79 ] , which acts as noise and thus degrades the HL - FER performance .To test this theory , another experiment was performed where the HL - FER was first trained using the Cohn - Kanade and then tested on the AT&T dataset , and then the same experiment was repeated while switching the datasets .The results of these experiments are shown in Tables 18 and 19 .", "label": "", "metadata": {}}
{"text": "Comparison and Analysis of HL - FER .The performance of the HL - FER was compared against nine conventional methods [ 34 - 40 , 64 , 79 ] , for all the three datasets , i.e. , the Cohn - Kanade , JAFFE , and AT&T datasets of facial expressions .All of these methods were implemented by us using the instructions provided in their respective papers .For each dataset , n -fold cross - validation rule ( based on subjects ) was applied .This process was repeated n times , where the value of n varied according to the dataset used .", "label": "", "metadata": {}}
{"text": "It can be seen that the HL - FER outperformed the existing facial expression systems .Lastly , to analyze the computational cost of the HL - FER , its average recognition time for the three datasets was compared to that of [ 64 ] , as [ 64 ] achieved the highest recognition accuracy in the above experiment among the nine conventional methods .The average computational time taken by [ 64 ] for the Cohn - Kanade , JAFFE , and AT&T datasets was 662 , 375 , and 590 ms , respectively .The datasets had 5,400 , 205 , and 240 images , respectively .", "label": "", "metadata": {}}
{"text": "These results show that though the HL - FER showed significant improvement over conventional methods in terms of recognition accuracy , it achieved that at the expense of a higher computational cost .In the HL - FER , we used two level classifications and in each level , we utilized HMM for classification ; therefore , the HL - FER took a bit more time than of the existing method [ 64 ] .All these experiments were performed in the laboratory ( offline validation ) using three standard datasets .Though the system performed accurately and robustly in all the experiments , the effects on system performance once implemented in real time are yet to be investigated .", "label": "", "metadata": {}}
{"text": "Clutter means that there could be some unnecessary objects in the images along with the test subject .Solving such problems would require a real - time robust segmentation technique .Moreover , the images used in this work were taken only from the frontal view ; however , in real life the angles of the camera might vary i.e. , side views can also happen .Therefore , further study is needed to tackle these issues and maintain the same high recognition rate in real - life environment .Eventually , we envision that the HL - FER will be employed in smartphones .", "label": "", "metadata": {}}
{"text": "This might become a complexity issue , especially when used in smartphones .One solution could be to use a lightweight classifier such as k - nearest neighbor ( k - NN ) at the first level ; however k - NN has its own limitations such as it is very sensitive to the presence of inappropriate parameters and sensitive to noise as well .Therefore , it can have poor performance in a real - time environment if the training set is large .Therefore , further study is needed to find ways to maintain the high accuracy of the HL - FER while improving its efficiency at the same time to be used in smartphones .", "label": "", "metadata": {}}
{"text": "Over the last decade , automatic human FER has become an important research area for many applications .That is why , though several FER systems have been proposed that showed promising results for a certain dataset , their performance was significantly reduced when tested with different datasets .In this paper , we proposed and validated the accuracy of a HL - FER .Unlike the previous systems , the HL - FER involved a pre - processing step based on global histogram equalization ( GHE ) , which helped in provide high accuracy by eliminating the light effects .", "label": "", "metadata": {}}
{"text": "Further , we employed both PCA and ICA to extract both the global and the local features .Finally , we used a HL - FER to overcome the problem of high similarity among different expressions .Expressions were divided into three categories based on different parts of the face .At the first level , LDA was used with an HMM to recognize the expression category .At the second level , the label for an expression within the recognized category is recognized using a separate set of LDA and HMM , trained just for that category .In order to evaluate the performance of the HL - FER detailed experiments were conducted on three publicly available datasets in three different experimental settings .", "label": "", "metadata": {}}
{"text": "This work was supported by a post - doctoral fellowship grant from the Kyung Hee University Korea in 2009 [ KHU-20090439].Appendix .This sections provides an overview of the results of different other experiments performed during the course of the development of this work .Figure A1 .3D feature plots of the HL - FER after applying LDA at the first level for the three expression - categories such as lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions on Yale B dataset for six different types of facial expressions .", "label": "", "metadata": {}}
{"text": "Figure A1 .3D feature plots of the HL - FER after applying LDA at the first level for the three expression - categories such as lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions on Yale B dataset for six different types of facial expressions .It can be seen that at the first level , the HL - FER achieved 100 % classification rate in expressions categories classification .Figure A2 .3D feature plots of the HL - FER after applying LDA at the second level for recognizing the expressions in each category on Yale B dataset for six different types of facial expressions .", "label": "", "metadata": {}}
{"text": "Figure A2 .3D feature plots of the HL - FER after applying LDA at the second level for recognizing the expressions in each category on Yale B dataset for six different types of facial expressions .It can be seen that at the second level , the HL - FER achieved much higher recognition rate as compared to a single - LDA via single - HMM shown in Figure 7 .Figure A3 .3D - feature plot of single - LDA via single - HMM on Yale B dataset for six different types of facial expressions .It can be seen that using a single - LDA via single - HMM approach did not yield as good a separation among different classes as was achieved by the HL - FER ( See Figure 6 ) .", "label": "", "metadata": {}}
{"text": "3D - feature plot of single - LDA via single - HMM on Yale B dataset for six different types of facial expressions .It can be seen that using a single - LDA via single - HMM approach did not yield as good a separation among different classes as was achieved by the HL - FER ( See Figure 6 ) .Conflicts of Interest .References .Fasel , B. ; Luettin , J. Automatic facial expression analysis : A survey .Patt .Recognit .[ Google Scholar ] .Bettadapura , V. Face Expression Recognition and Analysis : The State of the Art ; Tech Report arXiv:1203.6722 ; April ; 2012 ; pp . 1 - 27 .", "label": "", "metadata": {}}
{"text": "Wu , X. ; Zhao , J. Curvelet Feature Extraction for Face Recognition and Facial Expression Recognition .Proceedings of IEEE 6th International Conference on Natural Computation , Yantai , China , 10 - 12 August 2010 ; Volume 3 , pp .1212 - 1216 .Bartlett , M. ; Hager , J. ; Ekman , P. ; Sejnowski , T. Measuring facial expressions by computer image analysis .Psychophysiology 1999 , 36 , 253 - 263 .[ Google Scholar ] .Moore , S. ; Bowden , R. ; Guildford , U. The Effects of Pose on Facial Expression Recognition .", "label": "", "metadata": {}}
{"text": "In Handbook of Face Recognition ; Springer : New York , NY , USA , 2005 ; pp .193 - 216 .[ Google Scholar ] .Zhu , Z. ; Ji , Q. Robust Real - Time Face Pose and Facial Expression Recovery .Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition , New York , USA , 17 - 22 June 2006 ; Volume 1 , pp .681 - 688 .Bartlett , M. ; Littlewort , G. ; Frank , M. ; Lainscsek , C. ; Fasel , I. ; Movellan , J. Recognizing Facial Expression : Machine Learning and Application to Spontaneous Behavior .", "label": "", "metadata": {}}
{"text": "568 - 573 .Bartlett , M.S. ; Littlewort , G. ; Braathen , P. ; Sejnowski , T.J. ; Movellan , J.R. A Prototype for Automatic Recognition of Spontaneous Facial Actions .In Advances in Neural Information Processing Systems ; MIT Press : Cambridge , MA , USA , 2003 ; Volume 15 , pp .1271 - 1278 .[ Google Scholar ] .Bartlett , M.S. ; Littlewort , G.C. ; Frank , M.G. ; Lainscsek , C. ; Fasel , I.R. ; Movellan , J.R. Automatic recognition of facial actions in spontaneous expressions .J. Multimed .", "label": "", "metadata": {}}
{"text": "Kulkarni , S. ; Reddy , N. ; Hariharan , S. Facial expression ( mood ) recognition from facial images using committee neural networks .BioMed .Eng .OnLine 2009 , 10 , 16 .[ Google Scholar ] .Sumathi , A. ; Marasamy , P. Automatic recognition and analysis of human faces and facial expression by LDA using wavelet transform .Eur .J. Sci .Res .[ Google Scholar ] .Feng , X. ; Pietikainen , M. ; Hadid , A. Facial expression recognition with local binary patterns and linear programming .Pattern Recognition And Image Analysis C / C of Raspoznavaniye Obrazov I Analiz Izobrazhenii 2005 , 15 , 546 .", "label": "", "metadata": {}}
{"text": "Kaur , M. ; Vashisht , R. ; Neeru , N. Recognition of facial expressions with principal component analysis and singular value decomposition .Int .J. Comput .Appl .[ Google Scholar ] .Gupta , S. ; Agrwal , S. ; Meena , Y. ; Nain , N. A Hybrid Method of Feature Extraction for Facial Expression Recognition .Proceeding of IEEE 7th International Conference on Signal - Image Technology and Internet - Based Systems , Dijon , France , 28 November-1 December 2011 ; pp .422 - 425 .Gonzalez , R.C. ; Woods , R.E. Digital Image Processing ; Prentice Hall : Upper Saddle River , NJ , USA , 2008 .", "label": "", "metadata": {}}
{"text": "Eramian , M. ; Mould , D. Histogram Equalization Using Neighborhood Metrics .Proceedings the 2nd Canadian Conference on Computer and Robot Vision , British Columbia , Canada , 9 - 11 May 2005 ; pp .397 - 404 .Ibrahim , H. ; Kong , N.S.P. Image sharpening using sub - regions histogram equalization .IEEE Trans .Consum .Electron .[ Google Scholar ] .Yeganeh , H. ; Ziaei , A. ; Rezaie , A. A Novel Approach for Contrast Enhancement Based on Histogram Equalization .Proceedings of International Conference on Computer and Communication Engineering , Kuala Lumpur , Malaysia , 13 - 15 May 2008 ; pp .", "label": "", "metadata": {}}
{"text": "Shanmugavadivu , P. ; Balasubramanian , K. Image inversion and Bi level histogram equalization for contrast enhancement .Int .J. Comput .Appl .[ Google Scholar ] .Zuo , C. ; Chen , Q. ; Sui , X. Range limited Bi - histogram equalization for image contrast enhancement .Optik 2013 , 124 , 425 - 431 .[ Google Scholar ] .Beham , M.P. ; Roomi , S.M.M. Face recognition using appearance based approach : A literature survey .Proceedings of International Conference & Workshop on Recent Trends in Technology , Mumbai , Maharashtra , India , 24 - 25 February 2012 ; pp .", "label": "", "metadata": {}}
{"text": "Tabatabaie , Z.S. ; Rahmat , R.W. ; Udzir , N.I. ; Kheirkhah , E. A hybrid face detection system using combination of appearance - based and feature - based methods .Int .J. Comput .Sci .Netw .Secur .[ Google Scholar ] .Rivera , R.A. ; Castillo , R.J. ; Chae , O. Local directional number pattern for face analysis : Face and expression recognition .IEEE Trans .Image Process .[ Google Scholar ] .Rowley , H.A. ; Baluja , S. ; Kanade , T. Neural network - based face detection .", "label": "", "metadata": {}}
{"text": "PAMI .[ Google Scholar ] .Rosenfeld , A. ; Johnshon , E. Angle detection on digital curves .IEEE Trans .Comput .[ Google Scholar ] .Feng , G.C. ; Yuen , P.C. Multi - cues eye detection on gray intensity image .Pattern Recognit .[ Google Scholar ] .Bashyal , S. ; Venayagamoorthy , G. Recognition of facial expressions using Gabor wavelets and learning vector quantization .Eng .Appl .Artif .Intell .[ Google Scholar ] .Jabid , T. ; Kabir , M. ; Chae , O. Facial Expression Recognition Using Local Directional Pattern ( LDP ) .", "label": "", "metadata": {}}
{"text": "IEEE International Conference on Image Processing , Hong Kong , 26 - 29 September 2010 ; pp .1605 - 1608 .Rahman , A. ; Ali , L. Weighted Local Directional Pattern for Robust Facial Expression Recognition .Proceedings of IEEE 2011 1stInternational Conference on Informatics and Computational Intelligence , Bandung , Indonesia , 12 - 14 December 2011 ; pp .268 - 271 .Kabir , M. ; Jabid , T. ; Chae , O. Local Directional Pattern Variance ( LDPv ) : A robust feature descriptor for facial expression recognition .Int .Arab J. Inf .", "label": "", "metadata": {}}
{"text": "[ Google Scholar ] .Gourier , N. ; Hall , D. ; Crowley , J. Estimating Face Orientation from Robust Detection of Salient Facial Structures .In FG Net Workshop on Visual Observation of Deictic Gestures ; FGnet ( IST-2000 - 26434 ) : Cambridge , UK ; 22 ; August ; 2004 ; pp . 1 - 9 .[ Google Scholar ] .Cox , I. ; Ghosn , J. ; Yianilos , P. Feature - Based Face Recognition Using Mixture - Distance .Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition , San Francisco , CA , USA , 18 - 20 June 1996 ; pp .", "label": "", "metadata": {}}
{"text": "Lin , D.T. Facial expression classification using PCA and hierarchical radial basis function network .J. Inf .Sci .Eng .[ Google Scholar ] .Lin , D.T. Human Facial Expression Recognition Using Hybrid Network of PCA and RBFN .In Artificial Neural Networks - ICANN 2006 ; Springer : Athens , Greece , 2006 ; pp .624 - 633 .[ Google Scholar ] .Fan , C. ; Kotani , K. Facial expression recognition by supervised independent component analysis using MAP estimation .IEICE Trans .Inf .Syst .[ Google Scholar ] .", "label": "", "metadata": {}}
{"text": "Proceedings of the IEEE 17th International Conference on Pattern Recognition , Cambridge , UK , 23 - 26 August 2004 ; Volume 1 , pp .288 - 291 .Shinohara , Y. ; Otsuf , N. Facial Expression Recognition Using fisher Weight Maps .Proceedings of Sixth IEEE International Conference on Automatic Face and Gesture Recognition , Seoul , South Korea , 17 - 19 May 2004 ; pp .499 - 504 .Lyons , M.J. ; Budynek , J. ; Akamatsu , S. Automatic classification of single facial images .IEEE Trans .Pattern Anal .Mach .", "label": "", "metadata": {}}
{"text": "[ Google Scholar ] .He , L. ; Zhou , J. ; Hu , D. ; Zou , C. ; Zhao , L. Boosted Independent Features for Face Expression Recognition .Proceedings of 2nd International Symposium on Neural Networks , 2005 , Chongqing , China , 30 May-1 June 2005 ; pp .137 - 146 .Lirong , W. ; Xiaoguang , Y. ; Jianlei , W. ; Jian , Z. Facial Expression Recognition Based on Local Texture Features .Proceedings of 14th IEEE International Conference on Computational Science and Engineering , Dalian , China , 24 - 26 August 2011 ; pp .", "label": "", "metadata": {}}
{"text": "Khandait , S.P. ; Thool , R.C. ; Khandait , P.D. Automatic facial feature extraction and expression recognition based on neural network .Int .J. Adv .Comput .Sci .Appl .[ Google Scholar ] .Pang , Y. ; Yuan , Y. ; Li , X. Iterative subspace analysis based on feature line distance .IEEE Trans .Image Process .[ Google Scholar ] .Aguilar - Torres , G. ; Toscano - Medina , K. ; Perez , G.S. ; Nakano - Miyatake , M. ; Perez - Meana , H. Eigenface - gabor algorithm for feature extraction in face recognition .", "label": "", "metadata": {}}
{"text": "J. Comput .[ Google Scholar ] .Kittusamy , S.R.V. ; Chakrapani , V. Facial expressions recognition using eigenspaces .J. Comput .Sci .[ Google Scholar ] .Kalita , J. ; Das , K. Recognition of facial expression using eigenvector based distributed features and euclidean distance based decision making technique .Int .J. Adv .Comput .Sci .Appl .[ Google Scholar ] .Abidin , Z. ; Harjoko , A. A neural network based facial expression recognition using sherface .Int .J. Comput .Appl .[ Google Scholar ] .", "label": "", "metadata": {}}
{"text": "Int .J. Eng .Adv .Technol .[ Google Scholar ] .Tian , Y. ; Kanade , T. ; Cohn , J. Facial Expression Analysis .In Handbook of Face Recognition ; Springer : Heidelberg , Germany , 2005 ; Chapter 11 ; pp .247 - 275 .[ Google Scholar ] .Shan , C. ; Gong , S. ; McOwan , P.W. Conditional Mutual Information Based Boosting for Facial Expression Recognition .In British Machine Vision Conference ( BMVC ) ; The British Machine Vision Association and Society for Pattern Recognition : Oxford , UK , 2005 ; Volume 1 , pp .", "label": "", "metadata": {}}
{"text": "[ Google Scholar ] .Filko , D. ; Goran , M. Emotion recognition system by a neural network based facial expression analysis .Autom.-J. Control Meas .Electron .Comput .Commun .[ Google Scholar ] .Tu , J. Advantages and disadvantages of using artificial neural networks versus logistic regression for predicting medical outcomes .J. Clin .Epidemiol .[ Google Scholar ] .Kotsia , I. ; Pitas , I. Facial expression recognition in image sequences using geometric deformation features and support vector machines .IEEE Trans .Image Process .[ Google Scholar ] .", "label": "", "metadata": {}}
{"text": "WSEAS Trans .Comput .[ Google Scholar ] .Tsai , H. ; Lai , Y. ; Zhang , Y. Using SVM to Design Facial Expression Recognition for Shape and Texture Features .Proceedings of IEEE International Conference on Machine Learning and Cybernetics , Qingdao , China , 11 - 14 July 2010 ; pp .2697 - 2704 .Chen , F. ; Kotani , K. Facial Expression Recognition by SVM - based Two - Stage Classifier on Gabor Features .Proceedings of IAPR Conference on Machine Vision Applications , Tokyo , Japan , 16 - 18 May 2007 ; pp .", "label": "", "metadata": {}}
{"text": "Shan , C. ; Gong , S. ; McOwan , P. Facial expression recognition based on local binary patterns : A comprehensive study .Image Vis .Comput .[ Google Scholar ] .Liu , W. ; Lu , J. ; Wang , Z. ; Song , H. An Expression Space Model for Facial Expression Analysis .Proceedings of IEEE Congress on Image and Signal Processing , Sanya , China , 27 - 30 May 2008 ; Volume 2 , pp .680 - 684 .Schels , M. ; Schwenker , F. A Multiple Classifier System Approach for Facial Expressions in Image Sequences Utilizing GMM Supervectors .", "label": "", "metadata": {}}
{"text": "4251 - 4254 .Bouwmans , T. ; El Baf , F. Modeling of dynamic backgrounds by type-2 fuzzy Gaussians mixture models .MASAUM J. Basic Appl .Sci .[ Google Scholar ] .Yeasin , M. ; Bullot , B. ; Sharma , R. Recognition of facial expressions and measurement of levels of interest from video .IEEE Trans .Multimed .[ Google Scholar ] .Aleksic , P.S. ; Katsaggelos , A.K. Automatic facial expression recognition using facial animation parameters and multistream HMMs .IEEE Trans .Inf .Forensics Secur .[ Google Scholar ] .", "label": "", "metadata": {}}
{"text": "IEEE Trans .Consum .Electron .[ Google Scholar ] .Mariappan , M.B. ; Suk , M. ; Prabhakaran , B. Facial Expression Recognition using Dual Layer Hierarchical SVM Ensemble Classification .Proceedings of IEEE International Symposium on Multimedia , Irvine , CA , USA , 10 - 12 December 2012 ; pp .104 - 107 .Kim , Y.-C. ; Pang , S. ; Je , H.-M. ; Kim , D. ; Bang , S - Y. Constructing support vector machine ensemble .Pattern Recognit .[ Google Scholar ] .Singh , S.K. ; Chauhan , D.S. ; Vatsa , M. ; Singh , R. A robust skin color based face detection algorithm .", "label": "", "metadata": {}}
{"text": "Eng .[ Google Scholar ] .Hu , J. ; Yan , H. ; Sakalli , M. Locating head and face boundaries for head shoulder images .Pattern Recognit .[ Google Scholar ] .Starovoitov , V.V. ; Samal , D.I. ; Sankur , B. Matching of Faces in Camera Images and Document Photographs .Proceedings of 2000 IEEE International Conference on Acoustics , Speech , and Signal Processing , Istanbul , Turkey , 5 - 9 June 2000 ; pp .2349 - 2352 .Nusseck , M. ; Cunningham , D.W. ; Wallraven , C. ; B\u00fclthoff , H.H. The contribution of different facial regions to the recognition of conversational expressions .", "label": "", "metadata": {}}
{"text": "[ Google Scholar ] .Kaulard , K. ; Cunningham , D.W. ; B\u00fclthoff , H.H. ; Wallraven , C. The MPI facial expression database a validated database of emotional and conversational facial expressions .PLoS One 2012 , 7 , e32321 .[ Google Scholar ] .Schmidt , K.L. ; Cohn , J.F. Human facial expressions as adaptations : Evolutionary questions in facial expression research .Am .J. Phys .Anthropol .[ Google Scholar ] .Kanade , T. ; Cohn , J.F. ; Tian , Y. Comprehensive Database for Facial Expression Analysis .Proceedings of Fourth IEEE International Conference on Automatic Face and Gesture Recognition , Grenoble , France , 28 - 30 March 2000 ; pp .", "label": "", "metadata": {}}
{"text": "Lyons , M. ; Akamatsu , S. ; Kamachi , M. ; Gyoba , J. Coding Facial Expressions with Gabor Wavelets .Proceedings of Third IEEE International Conference on Automatic Face and Gesture Recognition , Nara , Japan , 14 - 16 April 1998 ; pp .200 - 205 .Samaria , F.S. ; Harter , A. Parameterization of a Stochastic Model for Human Face Identification .Proceedings of the Second IEEE Workshop on Applications of Computer Vision , Sarasota , FL , USA , 5 - 7 December 1994 ; pp .138 - 142 .Georghiades , A.S. ; Belhumeur , P.N. ; Kriegman , D.J. From few to many : Illumination cone models for face recognition under variable lighting and pose .", "label": "", "metadata": {}}
{"text": "Pattern Anal .Mach .Intell .[ Google Scholar ] .Shamir , L. Evaluation of face datasets as tools for assessing the performance of face recognition methods .Int .J. Comput .Vis .[ Google Scholar ] .Zhou , J. ; Xu , T. ; Gan , J. Facial Expression Recognition Based on Local Directional Pattern Using SVM Decision - Level Fusion .Proceedings of Tenth International Conference on Computability and Complexity in Analysis , Nancy , France , 8 - 10 July 2013 ; pp .126 - 132 .Zhao , X. ; Zhang , S. Facial expression recognition based on local binary patterns and kernel discriminant isomap .", "label": "", "metadata": {}}
{"text": "[ Google Scholar ] .Figure 2 .3D - feature plot of Cohn - Kanade dataset for six different types of facial expressions , where each expression has twelve expression frames .It can be seen that the features are highly merged , due to the presence of similarity between the expressions , which could later results in a high misclassification rate .Figure 2 .3D - feature plot of Cohn - Kanade dataset for six different types of facial expressions , where each expression has twelve expression frames .It can be seen that the features are highly merged , due to the presence of similarity between the expressions , which could later results in a high misclassification rate .", "label": "", "metadata": {}}
{"text": "3D feature plots of the HL - FER after applying LDA at the first level for the three expression - categories such as lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions ( on Cohn - Kanade dataset ) .It can be seen that at the first level , the HL - FER achieved 100 % classification rate in expressions categories classification .Figure 5 .3D feature plots of the HL - FER after applying LDA at the first level for the three expression - categories such as lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions ( on Cohn - Kanade dataset ) .", "label": "", "metadata": {}}
{"text": "Figure 6 .3D feature plots of the HL - FER after applying LDA at the second level for recognizing the expressions in each category ( on Cohn - Kanade dataset ) .It can be seen that at the second level , the HL - FER achieved much higher recognition rate as compared to a single - LDA via single - HMM shown in Figure 7 .Figure 6 .3D feature plots of the HL - FER after applying LDA at the second level for recognizing the expressions in each category ( on Cohn - Kanade dataset ) .", "label": "", "metadata": {}}
{"text": "Figure 7 .3D - feature plot of single - LDA via single - HMM ( on Cohn - Kanade dataset ) .It can be seen that using a single - LDA via single - HMM approach did not yield as good a separation among different classes as was achieved by the HL - FER ( See Figure 6 ) .Figure 7 .3D - feature plot of single - LDA via single - HMM ( on Cohn - Kanade dataset ) .It can be seen that using a single - LDA via single - HMM approach did not yield as good a separation among different classes as was achieved by the HL - FER ( See Figure 6 ) .", "label": "", "metadata": {}}
{"text": "3D feature plots of the HL - FER after applying LDA at the first level for the three expression - categories such as lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions ( on JAFFE dataset ) .It can be seen that at the first level , the HL - FER achieved 100 % classification rate in expressions categories classification .Figure 8 .3D feature plots of the HL - FER after applying LDA at the first level for the three expression - categories such as lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions ( on JAFFE dataset ) .", "label": "", "metadata": {}}
{"text": "Figure 9 .3D feature plots of the HL - FER after applying LDA at the second level for recognizing the expressions in each category ( on JAFFE dataset ) .It can be seen that at the second level , the HL - FER achieved much higher recognition rate as compared to a single - LDA via single - HMM shown in Figure 10 .Figure 9 .3D feature plots of the HL - FER after applying LDA at the second level for recognizing the expressions in each category ( on JAFFE dataset ) .It can be seen that at the second level , the HL - FER achieved much higher recognition rate as compared to a single - LDA via single - HMM shown in Figure 10 .", "label": "", "metadata": {}}
{"text": "3D - feature plot of single - LDA via single - HMM ( on JAFFE dataset ) .It can be seen that using a single - LDA via single - HMM approach did not yield as good a separation among different classes as was achieved by the HL - FER ( See Figure 9 ) .Figure 10 .3D - feature plot of single - LDA via single - HMM ( on JAFFE dataset ) .It can be seen that using a single - LDA via single - HMM approach did not yield as good a separation among different classes as was achieved by the HL - FER ( See Figure 9 ) .", "label": "", "metadata": {}}
{"text": "3D feature plots of the HL - FER after applying LDA at the first level for the three expression - categories such as lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions ( on AT&T dataset ) .It can be seen that at the first level , the HL - FER achieved 100 % classification rate in expressions categories classification .Figure 11 .3D feature plots of the HL - FER after applying LDA at the first level for the three expression - categories such as lips - based , lips - eyes - based , or lips - eyes - forehead - based expressions ( on AT&T dataset ) .", "label": "", "metadata": {}}
{"text": "Figure 12 .3D feature plots of the HL - FER after applying LDA at the second level for recognizing the expressions in each category ( on AT&T dataset ) .It can be seen that at the second level , the HL - FER achieved much higher recognition rate as compared to a single - LDA via single - HMM shown in Figure 13 .Figure 12 .3D feature plots of the HL - FER after applying LDA at the second level for recognizing the expressions in each category ( on AT&T dataset ) .It can be seen that at the second level , the HL - FER achieved much higher recognition rate as compared to a single - LDA via single - HMM shown in Figure 13 .", "label": "", "metadata": {}}
{"text": "3D - feature plot of single - LDA via single - HMM ( on AT&T dataset ) .It can be seen that using a single - LDA via single - HMM approach did not yield as good a separation among different classes as was achieved by the HL - FER ( See Figure 12 ) .Figure 13 .3D - feature plot of single - LDA via single - HMM ( on AT&T dataset ) .It can be seen that using a single - LDA via single - HMM approach did not yield as good a separation among different classes as was achieved by the HL - FER ( See Figure 12 ) .", "label": "", "metadata": {}}
{"text": "The recognition rate of the HL - FER at the first level for recognizing the expressions category such as Lips - Based , Lips - Eyes - Based , and Lips - Eyes - Forehead - Based on Cohn - Kanade dataset ( Unit : % ) .Table 6 .The recognition rate of the HL - FER at the first level for recognizing the expressions category such as Lips - Based , Lips - Eyes - Based , and Lips - Eyes - Forehead - Based on Cohn - Kanade dataset ( Unit : % ) .Table 7 .", "label": "", "metadata": {}}
{"text": "Table 7 .The recognition rate of the HL - FER at the first level for recognizing the expressions category such as Lips - Based , Lips - Eyes - Based , and Lips - Eyes - Forehead - Based on the JAFFE dataset ( Unit : % ) .Table 8 .The recognition rate of the HL - FER at the first level for recognizing the expressions category such as Lips - Based , Lips - Eyes - Based , and Lips - Eyes - Forehead - Based on the AT&T dataset ( Unit : % ) .", "label": "", "metadata": {}}
{"text": "The recognition rate of the HL - FER at the first level for recognizing the expressions category such as Lips - Based , Lips - Eyes - Based , and Lips - Eyes - Forehead - Based on the AT&T dataset ( Unit : % ) .Table 9 .Confusion matrix for the HL - FER , showing the weighted average recognition accuracy for six expressions .Training on Cohn - Kanade dataset and testing on the JAFFE and AT&T datasets ( Unit : % ) .Table 9 .Confusion matrix for the HL - FER , showing the weighted average recognition accuracy for six expressions .", "label": "", "metadata": {}}
{"text": "Table 10 .Confusion matrix for the HL - FER , showing the weighted average recognition accuracy for six expressions .Training on the JAFFE dataset and testing on the Cohn - Kanade and AT&T datasets ( Unit : % ) .Table 10 .Confusion matrix for the HL - FER , showing the weighted average recognition accuracy for six expressions .Training on the JAFFE dataset and testing on the Cohn - Kanade and AT&T datasets ( Unit : % ) .Table 11 .Confusion matrix for the HL - FER , showing the weighted average recognition accuracy for six expressions .", "label": "", "metadata": {}}
{"text": "Table 11 .Confusion matrix for the HL - FER , showing the weighted average recognition accuracy for six expressions .Training on the AT&T dataset and testing on the Cohn - Kanade and JAFFE datasets ( Unit : % ) .Table 20 .Comparison results of the HL - FER with some of the existing works for the three standard Cohn - Kanade , JAFFE , and AT&T datasets for six basic facial expression under the same settings as described in Section 3.1 ( Unit : % ) .Table 20 .Comparison results of the HL - FER with some of the existing works for the three standard Cohn - Kanade , JAFFE , and AT&T datasets for six basic facial expression under the same settings as described in Section 3.1 ( Unit : % ) .", "label": "", "metadata": {}}
{"text": "Treatment of phantom limb pain ( PLP ) based on augmented reality and gaming controlled by myoelectric pattern recognition : a case study of a chronic PLP patient .1 Biomedical Engineering Division , Department of Signals and Systems , Chalmers University of Technology , Gothenburg , Sweden . 2 Department of Orthopaedics , Centre of Orthopaedic Osseointegration , Sahlgrenska University Hospital , Gothenburg , Sweden .A variety of treatments have been historically used to alleviate phantom limb pain ( PLP ) with varying efficacy .Recently , virtual reality ( VR ) has been employed as a more sophisticated mirror therapy .", "label": "", "metadata": {}}
{"text": "Moreover , this strategy disregards the actual effort made by the patient to produce phantom motions .In this work , we investigate a treatment in which the virtual limb responds directly to myoelectric activity at the stump , while the illusion of a restored limb is enhanced through augmented reality ( AR ) .Further , phantom motions are facilitated and encouraged through gaming .The proposed set of technologies was administered to a chronic PLP patient who has shown resistance to a variety of treatments ( including mirror therapy ) for 48 years .Individual and simultaneous phantom movements were predicted using myoelectric pattern recognition and were then used as input for VR and AR environments , as well as for a racing game .", "label": "", "metadata": {}}
{"text": "The phantom posture initially reported as a strongly closed fist was gradually relaxed , interestingly resembling the neutral posture displayed by the virtual limb .The patient acquired the ability to freely move his phantom limb , and a telescopic effect was observed where the position of the phantom hand was restored to the anatomically correct distance .More importantly , the effect of the interventions was positively and noticeably perceived by the patient and his relatives .Despite the limitation of a single case study , the successful results of the proposed system in a patient for whom other medical and non - medical treatments have been ineffective justifies and motivates further investigation in a wider study .", "label": "", "metadata": {}}
{"text": "In recent years , virtual reality ( VR ) has been used to treat PLP as a more technologically sophisticated version of the well - known \" mirror \" therapy introduced in 1996 ( Ramachandra and Rogers - Ramachandra , 1996 ) .VR has clear advantages over the physical constraints imposed by the conventional mirror box , as it allows a wider range of motion and rehabilitation exercises .In addition , VR allows interactive games that challenge patients with varying levels of difficulty , while keeping them entertained and motivated ( Sveistrup , 2004 ) .Contemporary reviews of the use of VR in neuromuscular rehabilitation are given in Sveistrup ( 2004 ) , and Holden ( 2005 ) .", "label": "", "metadata": {}}
{"text": "A virtual representation of the missing limb is then created to match the motions of the contralateral limb , thus delivering visual feedback ( Murray et al . , 2006a , b ; Mercier and Sirigu , 2009 ; Bach et al . , 2010 ) .Since the sound limb is required , this approach is only suitable for unilateral amputees .The patients have no direct volitional control of their phantom limb virtual representation .Instead , they simultaneously execute the same motions in both limbs .In this setup , the real effort and commitment of the patient to produce phantom limb motions is not part of the intervention , i.e. , the mirror limb will move as long as the sound limb does , and regardless of the intention of the phantom limb .", "label": "", "metadata": {}}
{"text": "We hypothesize that the higher degree of realism provided by augmented reality ( AR ) , together with direct volitional control through the prediction of motion intent using myoelectric signals at the stump , could improve the efficacy of this therapy .Furthermore , the addition of game control by phantom limb motions should help to engage the patient in executing these movements and , since only the amputated limb is involved , it is also suitable for bilateral amputees .VR - based treatment in which the virtual limb is controlled by the affected side has been previously explored with motion tracking technology ( Cole et al . , 2009 ) , which inherently , and considerably , restricts the amount of predictable motions .", "label": "", "metadata": {}}
{"text": "However , even if the musculature for physiologically appropriate actuation is no longer present , it has been shown that amputees are able to distinguish between imagining a phantom movement , and actually executing it .This suggests that the ability to naturally execute a movement is maintained after amputation , but more importantly , the effect on neuroplasticity and inter - hemispheric communication is different when practicing motor execution and motor imaginary ( Raffin et al . , 2012a , b ) .Experiments with implanted neural interfaces , which rely on the physiology of motor execution , have been shown to reduce PLP ( Di Pino et al .", "label": "", "metadata": {}}
{"text": "It has been suggested that incongruencies in the visual stimulus and sensory perception produce varying results in terms of pain relief , in some cases increasing it ( Desmond et al . , 2006 ) .This problem is avoided in our proposed myoelectrically controlled AR environment ( MCARE ) , where a conventional webcam captures the whole environment around the patient and integrates it in the rehabilitation task .To the best of our knowledge , this is the first time that AR , gaming , and the prediction of motion intent using myoelectric pattern recognition have been used together as a treatment for PLP .", "label": "", "metadata": {}}
{"text": "( 2006 ) .In this work , the results of using MCARE in a chronic , treatment - resistant PLP patient are reported .A chronic PLP patient for whom other treatments have proven ineffective was recruited to this study .The patient ( male , 72 years old ) lost his arm just below the elbow joint in 1965 due to a traumatic injury .He has experienced PLP since the amputation and reported a strongly closed fist as the permanent posture of his phantom hand .The PLP has continued over the years , despite conventional mirror therapy , different drug - based treatments , acupuncture , and self - suggested hypnosis .", "label": "", "metadata": {}}
{"text": "Methods .Pain Tracking .Pain perception was monitored after every session using the short - form McGill pain questionnaire ( SF - MGPQ )( Melzack , 1987 ) translated into Swedish ( Burckhardt and Bjelle , 1994 ) .The questionnaire was administered by a facilitator , with the exception of pain intensity where the patient noted the rating directly on the visual analogue scale .A percentage of total time at each level of pain was also reported .Additionally , the patient was free to self - report any comments on the system and the treatment .", "label": "", "metadata": {}}
{"text": "The prediction of motion intent was made using BioPatRec , an open source platform initially developed for advanced prosthetic control strategies based on pattern recognition algorithms ( Ortiz - Catalan et al . , 2013 ) .The myoelectric activity at the patient 's stump was utilized as the sole input to determine the intended phantom limb motions .Once the aimed motion is known , this can be used to command a variety of virtual environments and robotic devices .A custom - made AR environment was developed for this study to interface with BioPatRec and allow the patient to visualize himself ( in real - time ) with a virtual arm superimposed on his stump .", "label": "", "metadata": {}}
{"text": "The fiducial marker can be printed with a conventional printer .The virtual arm is superimposed on the marker and changes scale and rotation based on the tracking of the marker .These parameters can be also adjusted in real - time with the keyboard in order to improve the fitting of the virtual arm .Myoelectric Recordings .The location of the electrodes was defined by asking the patient to perform different movements and palpation of the corresponding muscular activity .We have empirically found that this procedure , rather than pre - defined selective placement , allows dealing with the difficulties of a commonly altered anatomy at the most distal part of the stump .", "label": "", "metadata": {}}
{"text": "Figure 1 .Setup for the myoelectrically controlled augmented reality environment ( MCARE ) .( A ) Surface electrodes and a fiduciary marker placed at the stump .( B ) Environment captured by the webcam and displayed on a computer screen , with the addition of the virtual limb superimposed on the fiduciary marker .( C ) Patient playing a racing game in which he drives the car by phantom motions ( Trackmania Nations Forever , free version ) .( D ) Patient using the Target Achievement Control ( TAC ) test as a rehabilitation tool .", "label": "", "metadata": {}}
{"text": "The signals were amplified with a gain of 2000 and digitalized at 2 kHz and 16 bits .The protocol for myoelectric signals acquisition and processing is described in Ortiz - Catalan et al .( 2013 ) .The classifiers used were Linear Discriminant Analysis in a One - Vs - One topology ( LDA - OVO ) , and Multi - layer Perceptron in a dedicated topology per degree of freedom ( MLP - AAM ) , for individual and simultaneous movements , respectively .These classifiers have been shown to be successful at both tasks in real - time studies and are further described in Ortiz - Catalan et al .", "label": "", "metadata": {}}
{"text": "Intervention .Once the electrodes and marker were in place , and the quality of the EMG signals was verified by short real - time myoelectric recordings , the subject was asked to perform the eight movements while being guided on the length and timing of the contractions by a virtual limb .The instructions given to the patient were to perform the motions \" as if he still had the missing limb , \" thus aiming for physiologically appropriate myoelectric activity to be used for control .The LDA - OVO was trained with this information and the patient had a 10-min session in the AR environment in which the facilitator prompted the patient to perform the recorded movements one by one in random order ( Figures 1A , B ) .", "label": "", "metadata": {}}
{"text": "This information was used to train the MLP - AAM , which real - time predictions were used to play a racing game ( Trackmania Nations Forever , free version ) .The game was controlled by using wrist pro / supination to turn left / right , while elbow flexion / extension controlled the car acceleration / deceleration .These combinations of motions were also used in the Target Achievement Control ( TAC ) test initially introduced by Simon et al .( 2011b ) , with modifications described in Ortiz - Catalan et al .( in press ) .", "label": "", "metadata": {}}
{"text": "The velocity - ramp algorithm was used to facilitate controllability ( Simon et al . , 2011a ) .In this work , the TAC test was used for rehabilitation and training , rather than as an evaluation tool ( Figure 1D ) .Once the TAC tasks were completed , a new set of movements was recorded using all eight movements to conduct a \" Motion Test \" ( Kuiken et al . , 2009 ) , as implemented in BioPatRec ( Ortiz - Catalan et al . , 2013 ) .Similarly to the TAC test , the Motion Test was aimed as a rehabilitation tool .", "label": "", "metadata": {}}
{"text": "This protocol was applied once a week starting in March 2013 and this work includes the results up to week 18 .In the last 5 weeks , two sessions a week were held , while in week eight no session was conducted because the patient was unavailable for reasons unrelated to treatment .A video showing examples of the interventions is available as Additional File 1 .Results .An increment in pain was reported by the patient after the first session , however , the pain decreased slightly below the original level in the second session , after which a slow yet consistent improvement was seen in the sustained level of pain .", "label": "", "metadata": {}}
{"text": "After 4 weeks , the patient reported starting to experience episodes of lower pain intensity .After 10 weeks , episodes of almost absent pain started occurring and this then developed into completely pain - free periods a couple of session later .This was reported by the patient as the most dramatic effect : \" These pain - free periods are something almost new to me and it is an extremely pleasant sensation . \"In addition , pain - free periods of 15 - 60 min were reported immediately after the rehabilitation sessions .Figure 2 .Evolution of pain intensity over time .", "label": "", "metadata": {}}
{"text": "( B )The sustained level of pain was also the lowest pain perceived by the patient , and it gradually decreased to around 10 % over the course of the interventions .Episodes of reduced pain started occurring after 4 weeks of treatment and gradually became pain - free periods .In week 11 , a problem with his socket prosthesis caused him to use an old , tighter socket that had previously been shown to induce pain .As the patient is very active in agricultural activities , despite his disabilities , he performs physical tasks that involve the use of his prosthesis .", "label": "", "metadata": {}}
{"text": "Each week , the patient reported that the periods of pain that normally came in the days following the activities had been dramatically reduced and that he was able to work harder without being afflicted by PLP .Surprisingly , the patient was capable of sequential control of three DoF from the first session , which evolved to four DoF and simultaneous control after four sessions .The patient reports that he is now able to control the motion of his phantom limb at will in the trained DoF. This is even possible in the absence of the visual feedback provided by the system , as is the case when he drives .", "label": "", "metadata": {}}
{"text": "Furthermore , he no longer wakes up at night due to PLP .The patient 's life partner reports that it is her belief that \" My husband can live 10 years more than I expected , as pain now plays a less important role in his life and those close to him can see it .\" We have previously observed that patients using BioPatRec reported a telescopic effect on the position of the phantom limb .The patient initially reported the perception of his phantom hand at the stump height , which over the course of the treatment extended to the anatomically unaltered position .", "label": "", "metadata": {}}
{"text": "However , as soon as he starts producing phantom motions , the perceived position is once again restored to the unaltered anatomy .This is a phenomenon that is now permanently present and it indicates the complexity of self - perception and how it can be altered by sensory feedback and motor execution .It is worth noting that the presence of a phantom limb map on the stump is weak , mixed , and fairly difficult for the patient to identify , thus providing limited sensory information from the phantom hand .The initial state of the phantom hand was described by the patient as a permanently , strongly closed fist and this has been the case for the last 48 years .", "label": "", "metadata": {}}
{"text": "This is now the permanent perception of phantom hand posture and it is greatly appreciated by the patient ( patient self - report ) .We do not have enough data to argue that the constant visualization of such position as the normal virtual state has influenced its perception as the default phantom limb state , or whether this is instead the result of the patient 's skill at moving the phantom limb .In any case , the relaxation of such a stressed position occurred at the same time as the appearance of reduced pain periods and it could therefore be attributed as one of the causes of reduced PLP .", "label": "", "metadata": {}}
{"text": "It is worth mentioning that no muscles directly responsible for the more distal movements were available due to the level of amputation ( e.g. , hand open and close ) .However , the patient was capable of voluntarily controlling the virtual limb to produce those motions .We hypothesize that the patterns of myoelectric activity produced by muscle synergies are distinctive enough to allow the classifiers to differentiate directly related movements from those occurring more distally at the hand .Figure 3 illustrates the learning curve through the improvement of the classification accuracy of nine classes ( eight movements plus \" no movement \" ) .", "label": "", "metadata": {}}
{"text": "Figure 3 .Offline accuracy .The motion test results after week 15 show performance comparable to that of 17 able - bodied subjects previously evaluated ( Ortiz - Catalan et al . , 2013 ) , where the signal processing , features and motion test settings were the same .Although these results can not be compared directly , they serve as an indication of the ability of the patient to produce distinctive motions in real - time .It is worthy of notice that the number of electrodes has been reduced to four since this report without a noticeable effect in classification performance .", "label": "", "metadata": {}}
{"text": "A complete understanding of the root causes and underlying mechanisms of PLP has evaded the scientific community for decades ( Nikolajsen and Jensen , 2001 ; Flor et al . , 2006 ) .This understanding will undoubtedly enable the creation of more effective treatments for the condition .Mirror therapy is based on the assumption that visual feedback can potentially correct tactile deafferentation ( to some degree ) due to brain plasticity .Evidence has been reported on the correlation between cortical reorganization and PLP ( Flor et al . , 1995 ) , which was further investigated to argue that extensive myoelectric prosthetic use prevents it , and thus reduces PLP ( Lotze et al . , 1999 ) .", "label": "", "metadata": {}}
{"text": "In this case , although limited visual feedback is provided by the prosthesis , the prosthesis does not respond to physiologically appropriate commands and the motion of the missing limb is thus neglected .This might explain why , although the patient has used his prosthesis extensively , the PLP has remained .This underlines the importance of a congruent relationship between feedback and motor execution , as well as the intention to perform motion execution itself .All this is synergistically provided by our system .In this case study , we present a system that can be used for PLP treatment and has had relative success in a patient with chronic PLP who had unsuccessfully explored several other treatments .", "label": "", "metadata": {}}
{"text": "It still remains to be seen whether the pain disappears completely after the long - term use of the system .The ideal medical treatment would be to administer it for a defined period of time and permanently cure the condition .We have intentionally avoided terminating the sessions to evaluate the long - term effect , as we feel this would be unethical , given the satisfaction reported by the patient after 48 years of chronic pain .As an alternative , the patient has been provided with a stand - alone system to be used at home and he has been instructed to use it at his own discretion .", "label": "", "metadata": {}}
{"text": "It has been argued that the second factor alone is a cause of PLP relief ( Sherman , 1980 ) .The independent contribution of these two factors could be difficult to isolate in the proposed system .Motor intention alone has been shown to similarly reduce PLP when comparing mirror therapy with and without visual feedback ( Brodie et al . , 2007 ) .When visual feedback was used , however , the capabilities of phantom limb motion increased .On the other hand , VR interventions where the controlling side is the amputated has shown signs of PLP relief , despite that the musculature at the stump was not directly involved ( Cole et al . , 2009 ) .", "label": "", "metadata": {}}
{"text": "The possibility of decoding distal movements using muscles synergies was initially explored decades ago ( Wirta et al . , 1978 ) .In our experience , patients can quickly learn to control a few distal motions and the results presented here suggest that they are able to develop that skill further to several motions .It is worth noting that one limitation of this non - invasive approach is that a certain degree of musculature is required , i.e. , shoulder disarticulations would hardly be treatable unless they were recipients of targeted muscle reinnvervation ( Kuiken et al .", "label": "", "metadata": {}}
{"text": "VR treatments are commonly justified and encouraged by the assumption that sensory stimulation boosts neuromuscular rehabilitation .At the current stage , the system employs only visual feedback stimuli , mostly due to the technical difficulties involved in providing proper somatosensory stimulation .In our experience , patients invariably prefer a virtual limb to any other visual feedback and we are therefore presently developing rehabilitation games based on AR that are specifically designed to exercise selected motions in a controlled manner .The proposed system incorporates different advantages of computational rehabilitation systems , such as progress tracking , adjustable task difficulty , engaging rehabilitation tasks , and portability .", "label": "", "metadata": {}}
{"text": "Conclusions .PLP has historically being a difficult condition to treat and it affects the majority of amputees .In this work , we introduce a non - invasive technological proposal that combines the prediction of motion intent through the decoding of myoelectric signals , virtual and augmented reality , and gaming .As opposed to conventional mirror therapy , this system allows full range of motion and direct volitional control of the virtual limb , and it is applicable for bilateral amputees , in addition to having the known motivational benefits of gaming and progress tracking by computerized systems .", "label": "", "metadata": {}}
{"text": "Having shown that the system has considerably increased the quality of life of a single patient , where other previous conventional treatments had proved unsuccessful , we believe that it offers sufficient justification to further explore its efficacy on a wider PLP population .Author Contributions .Max Ortiz - Catalan designed the study , developed the motion prediction technology ( software and hardware ) , performed the literature review , and drafted the manuscript .Nichlas Sander developed the virtual reality environment .Morten B. Kristoffersen developed the augmented reality environment .Max Ortiz - Catalan , Nichlas Sander , and Morten B. Kristoffersen performed the interventions and analyzed the results .", "label": "", "metadata": {}}
{"text": "All the authors have read and approved the final manuscript .Conflict of Interest Statement .In addition to governmental institutions , this work was partially funded by Integrum AB , which is currently investing in the advanced control of robotic prostheses .The technology for motion prediction was originally developed for prosthetic control and it is open source .Acknowledgments .The authors would like to thank the patient that participated in this study for his helpful feedback and cooperation .The authors also thank Alejandra Zepeda E. for her help in conducting the latest sessions , and Kerstin Caine - Winterberger .", "label": "", "metadata": {}}
{"text": "References .Bach , F. , Schmitz , B. , Maa\u00df , H. , Cakmak , H. , Diers , M. , Bodmann , R. , et al .( 2010 ) . \"Using interactive immersive VR / AR for the therapy of phantom limb pain , \" in Proceedings of the 13th International Conference on Humans Computer ( Aizu - Wakamatsu ) , 183 - 187 .Brodie , E. E. , Whyte , A. , and Niven , C. A. ( 2007 ) .Analgesia through the looking - glass ?A randomized controlled trial investigating the effect of viewing a \" virtual \" limb upon phantom limb pain , sensation and movement .", "label": "", "metadata": {}}
{"text": "J. Pain 11 , 428 - 436 .doi : 10.1016/j.ejpain.2006.06.002 .Brodie , E. E. , Whyte , A. , and Waller , B. ( 2003 ) .Increased motor control of a phantom leg in humans results from the visual feedback of a virtual leg .Neurosci .Lett . doi : 10.1016/S0304 - 3940(03)00160 - 5 .Clark , R. L. , Bowling , F. L. , Jepson , F. , and Rajbhandari , S. ( 2013 ) .Phantom limb pain after amputation in diabetic patients does not differ from that after amputation in nondiabetic patients .", "label": "", "metadata": {}}
{"text": "doi : 10.1016/j.pain.2013.01.009 .Cole , J. , Crowle , S. , Austwick , G. , and Slater , D. H. ( 2009 ) .Exploratory findings with virtual reality for phantom limb pain ; from stump motion to agency and analgesia .Disabil .Rehabil .doi : 10.1080/09638280802355197 .Desmond , D. , O'Neill , K. , De Paor , A. , McDarby , G. , and MacLachlan , M. ( 2006 ) .Augmenting the reality of phantom limbs : three case studies using an augmented mirror box procedure .J. Prosthet Orthot .doi : 10.1097/00008526 - 200607000 - 00005 .", "label": "", "metadata": {}}
{"text": "Phantom pain and risk factors : a multivariate analysis .J. Pain Symptom Manag .doi : 10.1016/S0885 - 3924(02)00538 - 9 .Di Pino , G. , Porcaro , C. , Tombini , M. , Assenza , G. , Pellegrino , G. , Tecchio , F. , et al .( 2012 ) .A neurally - interfaced hand prosthesis tuned inter - hemispheric communication .Restor .Neurol .Neurosci .doi : 10.3233/RNN-2012 - 120224 .Flor , H. , Elbert , T. , Knecht , S. , Wienbruch , C. , Pantev , C. , Birbaumer , N. , et al .", "label": "", "metadata": {}}
{"text": "Phantom - limb pain as a perceptual correlate of cortical reorganization following arm amputation .Nature 375 , 482 - 484 .doi : 10.1038/375482a0 .Kuiken , T. , Dumanian , G. , Lipschutz , R. , Miller , L. A. , and Stubblefield , K. ( 2004 ) .The use of targeted muscle reinnervation for improved myoelectric prosthesis control in a bilateral shoulder disarticulation amputee .Prosthet .Orthot .Int . doi : 10.3109/03093640409167756 .Kuiken , T. , Li , G. , Lock , B. A. , Lipschutz , R. D. , Miller , L. A. , Stubblefield , K. A. , et al .", "label": "", "metadata": {}}
{"text": "Targeted muscle reinnervation for real - time myoelectric control of multifunction artificial arms .J. Am .Med .Assoc .doi : 10.1001/jama.2009.116 .Lee , S. W. , Wilson , K. M. , Lock , B. A. , and Kamper , D. G. ( 2011 ) .Subject - specific myoelectric pattern classification of functional hand movements for stroke survivors .IEEE Trans .Neural Syst .Rehabil .Eng .doi : 10.1109/TNSRE.2010.2079334 .Liu , J. , and Zhou , P. ( 2013 ) .A novel myoelectric pattern recognition strategy for hand function restoration after incomplete cervical spinal cord injury .", "label": "", "metadata": {}}
{"text": "Neural Syst .Rehabil .Eng .doi : 10.1109/TNSRE.2012.2218832 .Lotze , M. , Grodd , W. , Birbaumer , N. , Erb , M. , Huse , E. , and Flor , H. ( 1999 ) .Does use of a myoelectric prosthesis prevent cortical reorganization and phantom limb pain ?Nat .Neurosci .doi : 10.1038/9145 .Murray , C. D. , Patchick , E. , Pettifer , S. , Caillette , F. , and Howard , T. ( 2006a ) .Immersive virtual reality as a rehabilitative technology for phantom limb experience : a protocol .", "label": "", "metadata": {}}
{"text": "Behav .doi : 10.1089/cpb.2006.9.167 .Murray , C. D. , Patchick , E. , Pettifer , S. , Howard , T. , Caillette , F. , Kulkarni , J. , et al .( 2006b ) .Investigating the efficacy of a virtual mirror box in treating phantom limb pain in a sample of chronic sufferers .Int .J. Disabil .Hum .Dev .doi : 10.1515/IJDHD.2006.5.3.227 .Ortiz - Catalan , M. , Br\u00e5nemark , R. , and H\u00e5kansson , B. ( 2013 ) .BioPatRec : a modular research platform for the control of artificial limbs based on pattern recognition algorithms .", "label": "", "metadata": {}}
{"text": "Med .doi : 10.1186/1751 - 0473 - 8 - 11 .Ortiz - Catalan , M. , H\u00e5kansson , B. , and Br\u00e5nemark , R. ( in press ) .Real - time and simultaneous control of artificial limbs based on pattern recognition algorithms .IEEE Trans .Neural Syst .Rehabil .Eng .( accepted ) .Raffin , E. , Giraux , P. , and Reilly , K. T. ( 2012a ) .The moving phantom : motor execution or motor imagery ?Cortex 48 , 746 - 757 .doi : 10.1016/j.cortex.2011.02.003 .", "label": "", "metadata": {}}
{"text": "A decision - based velocity ramp for minimizing the effect of misclassifications during real - time pattern recognition control .IEEE Trans .Biomed .Eng .doi : 10.1109/TBME.2011.2155063 .Simon , A. M. , Hargrove , L. J. , Lock , B. A. , and Kuiken , T. ( 2011b ) .Target achievement control test : evaluating real - time myoelectric pattern - recognition control of multifunctional upper - limb prostheses .J. Rehabil .Res .Dev .doi : 10.1682/JRRD.2010.08.0149 .Keywords : phantom limb pain , augmented reality , virtual reality , myoelectric control , electromyography , pattern recognition , neurorehabilitation .", "label": "", "metadata": {}}
{"text": "Treatment of phantom limb pain ( PLP ) based on augmented reality and gaming controlled by myoelectric pattern recognition : a case study of a chronic PLP patient .Front .Neurosci .doi : 10.3389/fnins.2014.00024 .Received : 04 October 2013 ; Accepted : 27 January 2014 ; Published online : 25 February 2014 .Edited by : .David Guiraud , Institut National de la Recherche en Informatique et Automatique , France .Copyright \u00a9 2014 Ortiz - Catalan , Sander , Kristoffersen , H\u00e5kansson and Br\u00e5nemark .This is an open - access article distributed under the terms of the Creative Commons Attribution License ( CC BY ) .", "label": "", "metadata": {}}
