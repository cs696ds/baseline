{"text": "The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .License : LGPL .The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .", "label": "", "metadata": {}}
{"text": "[ ftp://ftp.cs.cmu.edu/user/ai/new/daydreamer/0new.html DAYDREAMER ] is a computer model of the stream of thought developed at UCLA by Erik T. Mueller from 1983 to 1988 .The generator is located in the file dd_gen . cl .Common lisp source code available under GPL v2 . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .", "label": "", "metadata": {}}
{"text": "Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell .HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .", "label": "", "metadata": {}}
{"text": "The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .The forest ranker includes a 250-million word ngram language model ( unigram , bigram , and trigram ) trained on WSJ newspaper text .The symbolic generator is written in LISP and requires a CommonLisp interpreter .The download package consists of the symbolic generator , the forest ranker , and some sample inputs .The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .The forest ranker includes a 250-million word ngram language model ( unigram , bigram , and trigram ) trained on WSJ newspaper text .", "label": "", "metadata": {}}
{"text": "LKB is implemented in Common Lisp , and is freely available under an open source license .LKB is implemented in Common Lisp , and is freely available under an open source license .It includes also a KNOPPIX - based GNU / Linux live - CD , with all the system installed , ready to use .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .Currently supports English and Greek .Extensions for other languages welcome .( GPL ) .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .", "label": "", "metadata": {}}
{"text": "Extensions for other languages welcome .( GPL ) .Not to be confused with NLGen2 , below , which uses a different sentence generation theory .Java , Apache license .Not to be confused with NLGen , above , which uses a different sentence generation theory .Java , Apache license .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .OpenCCG is implemented in Java , and is freely available under the LGPL .It has been used in several dialog systems .", "label": "", "metadata": {}}
{"text": "OpenCCG is implemented in Java , and is freely available under the LGPL .There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .", "label": "", "metadata": {}}
{"text": "The software was written in Java and is available for Windows and Linux , including source code and database files .Revision as of 11:25 , 7 September 2012 .The natural language generation systems listed below are available for download over the web .If you know of a system which is not listed here , please click on Edit in the upper left corner of this page and add the system yourself .CLINT is a hybrid template / word - based generation system with an example application of business letter generation .The system is written in C++ and runs under Microsoft Windows .", "label": "", "metadata": {}}
{"text": "CRISP is Alexander Koller 's NLG system that tries to cast both microplanning and sentence realisation as an AI planning problem .The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .License : LGPL .DAYDREAMER .DAYDREAMER is a computer model of the stream of thought developed at UCLA by Erik T. Mueller from 1983 to 1988 .", "label": "", "metadata": {}}
{"text": "Common lisp source code available under GPL v2 . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell .Source code avalailable via darcs . provides a means of exploring large - scale systemic - functional grammars in order to see how they are organized and what kinds of things they cover .", "label": "", "metadata": {}}
{"text": "Downloadable standalone executables of the grammar explorer are available for Windows 95/98/NT .These already include a version of the Nigel grammar of English and pre - installed examples .The KPML system offers a robust , mature platform for large - scale grammar engineering that is particularly oriented to multilingual grammar development and generation .It is particularly targetted at providing resources for realistic but broad - coverage generation applications , where both flexibility of expression and speed of generation are at issue - for example in online webpage generation or spoken dialogue .KPML is also used extensively in multilingual text generation research and for teaching .", "label": "", "metadata": {}}
{"text": "Downloadable standalone executables of the system are available for PCs running Windows .The source code is written in ANSI Common Lisp and uses the Common Lisp Interface Manager ( CLIM ) .The system has been compiled and tested [ under Franz Allegro Common Lisp ( 4.2 , 4.3 , 4.3.1 , 5.0 , 6.0 , 7.0 ) for Unix and Franz Allegro Common Lisp 3.0 and Harlequin Lispworks 4.0 , 4.1 , 4.2 for Windows .It is possible to use the system without the window interface as a generator serving requests for generation across sockets or via files .", "label": "", "metadata": {}}
{"text": "It includes a realiser that takes as input Minimal Recursion Semantics ( MRS ) .LKB is implemented in Common Lisp , and is freely available under an open source license .It includes also a KNOPPIX - based GNU / Linux live - CD , with all the system installed , ready to use .MUG Workbench is a development and debugging tool for Multimodal NLG .The grammar formalism supported is Multimodal Functional Unification Grammar ( MUG ) .The MUG system runs MUG grammars with fixed ( test cases ) and arbitrary input specifications to produce output in a natural language , graphical user interface and possibly in other modes .", "label": "", "metadata": {}}
{"text": "It should help you to learn more about the nature of unification grammars used for parsing or natural language generation .Furthermore , the MUG Workbench is helpful in debugging your grammars .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .Currently supports English and Greek .Extensions for other languages welcome .NaturalOWL can also be used as a Prot\u00e9g\u00e9 plug - in .See here for publications describing NaturalOWL .( GPL ) .NLGen .The NLGen natural language generation system applies the SegSim strategy for generating English sentences .", "label": "", "metadata": {}}
{"text": "Not to be confused with NLGen2 , below , which uses a different sentence generation theory .Java , Apache license .See demo : Demo of AI Virtual Pet Answering Simple Questions .OpenCCG , the OpenNLP CCG Library ( formerly Grok ) , is both a parser and a realizer for Combinatory Categorial Grammar .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .OpenCCG is implemented in Java , and is freely available under the LGPL .Deliverables from the RAGS project - RAGSOCKS software for interfacing modules using RAGS data representations , example RAGS module ( genetic algorithm based text planner ) and RAGS wrapper for FUF / SURGE . is an ultra - simple Java - based realiser .", "label": "", "metadata": {}}
{"text": "However , because it is so simple , its relatively easy for people to learn how to use it .It has been used by many people in Aberdeen , and also for teaching .It is set up as a Java package , so it can only be used by Java programs .SPUD .SPUD ( Sentence Planner Using Descriptions ) is Matthew Purver 's LTAG - based NLG system .There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .", "label": "", "metadata": {}}
{"text": "The STANDUP project ( System To Augment Non - speakers ' Dialogue Using Puns ) is a collaborative project on generating simple jokes from a graphical user interface appropriate for non - speaking children .The project began in October 2003 and ran until March 2007 .The software was written in Java and is available for Windows and Linux , including source code and database files .Suregen-2 .Suregen is \" a hybrid , ontology based and NLG - oriented formalism for generating text for documents in clinical medicine .\" The system Suregen-2 is written in ( Allegro ) Common Lisp .", "label": "", "metadata": {}}
{"text": "A screencast video shows data being entered into computer forms using mouse and keyboard while a feedback text is continually updated and shown below .( Try playing the AVI file in VLC if you run into problems . )Perhaps this system could be considered an instance of the WYSIWYM approach .Syntactic realization package .( A CommonLisp package providing an interpreter for a functional unification formalism called FUF and SURGE , a large grammar of English written in FUF . )Offers download of SURGE 2.2 .Systemic Unification Reusable Grammar for Spanish is a large scale Spanish grammar allowing systems which already use FUF / SURGE for English NLG to be able to generate syntactically ( and many times semantically ) equivalent text in Spanish when new lexical items are introduced .", "label": "", "metadata": {}}
{"text": "It combines context - free grammars with templates and canned text in a single formalism .Thus the granularity of the language model may depend on the application needs .The system currently runs under Solaris 2.5 .It is available freely under a research license .The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .", "label": "", "metadata": {}}
{"text": "The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .License : LGPL .[ ftp://ftp.cs.cmu.edu/user/ai/new/daydreamer/0new.html DAYDREAMER ] is a computer model of the stream of thought developed at UCLA by Erik T. Mueller from 1983 to 1988 .The generator is located in the file dd_gen . cl .Common lisp source code available under GPL v2 . surface realiser for ( Feature - Based Lexicalised )", "label": "", "metadata": {}}
{"text": "Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .", "label": "", "metadata": {}}
{"text": "Written in Haskell .HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .The download package consists of the symbolic generator , the forest ranker , and some sample inputs .The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .The forest ranker includes a 250-million word ngram language model ( unigram , bigram , and trigram ) trained on WSJ newspaper text .", "label": "", "metadata": {}}
{"text": "The download package consists of the symbolic generator , the forest ranker , and some sample inputs .The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .The forest ranker includes a 250-million word ngram language model ( unigram , bigram , and trigram ) trained on WSJ newspaper text .The symbolic generator is written in LISP and requires a CommonLisp interpreter .LKB is implemented in Common Lisp , and is freely available under an open source license .LKB is implemented in Common Lisp , and is freely available under an open source license .", "label": "", "metadata": {}}
{"text": "Not to be confused with NLGen , above , which uses a different sentence generation theory .Java , . open source .Not to be confused with NLGen , above , which uses a different sentence generation theory .Java , .Apache license .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .OpenCCG is implemented in Java , and is freely available under the LGPL .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .", "label": "", "metadata": {}}
{"text": "There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .The project began in October 2003 and ran until March 2007 .", "label": "", "metadata": {}}
{"text": "Revision as of 11:25 , 7 September 2012 .The natural language generation systems listed below are available for download over the web .If you know of a system which is not listed here , please click on Edit in the upper left corner of this page and add the system yourself .CLINT is a hybrid template / word - based generation system with an example application of business letter generation .The system is written in C++ and runs under Microsoft Windows .CRISP .CRISP is Alexander Koller 's NLG system that tries to cast both microplanning and sentence realisation as an AI planning problem .", "label": "", "metadata": {}}
{"text": "CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .License : LGPL .DAYDREAMER .DAYDREAMER is a computer model of the stream of thought developed at UCLA by Erik T. Mueller from 1983 to 1988 .The generator is located in the file dd_gen . cl .Common lisp source code available under GPL v2 . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .", "label": "", "metadata": {}}
{"text": "Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell .Source code avalailable via darcs . provides a means of exploring large - scale systemic - functional grammars in order to see how they are organized and what kinds of things they cover .It can be used to explore the KPML resources .Downloadable standalone executables of the grammar explorer are available for Windows 95/98/NT .", "label": "", "metadata": {}}
{"text": "The KPML system offers a robust , mature platform for large - scale grammar engineering that is particularly oriented to multilingual grammar development and generation .It is particularly targetted at providing resources for realistic but broad - coverage generation applications , where both flexibility of expression and speed of generation are at issue - for example in online webpage generation or spoken dialogue .KPML is also used extensively in multilingual text generation research and for teaching .It is based on systemic functional linguistics .Downloadable standalone executables of the system are available for PCs running Windows .", "label": "", "metadata": {}}
{"text": "The system has been compiled and tested [ under Franz Allegro Common Lisp ( 4.2 , 4.3 , 4.3.1 , 5.0 , 6.0 , 7.0 ) for Unix and Franz Allegro Common Lisp 3.0 and Harlequin Lispworks 4.0 , 4.1 , 4.2 for Windows .It is possible to use the system without the window interface as a generator serving requests for generation across sockets or via files .LKB ( Linguistic Knowledge Builder ) is a grammar engineering environment for unification - based formalisms , typically HPSG .It includes a realiser that takes as input Minimal Recursion Semantics ( MRS ) .", "label": "", "metadata": {}}
{"text": "It includes also a KNOPPIX - based GNU / Linux live - CD , with all the system installed , ready to use .MUG Workbench is a development and debugging tool for Multimodal NLG .The grammar formalism supported is Multimodal Functional Unification Grammar ( MUG ) .The MUG system runs MUG grammars with fixed ( test cases ) and arbitrary input specifications to produce output in a natural language , graphical user interface and possibly in other modes .MUG Workbench can serve to inspect the data - structures used during generation .It should help you to learn more about the nature of unification grammars used for parsing or natural language generation .", "label": "", "metadata": {}}
{"text": "Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .Currently supports English and Greek .Extensions for other languages welcome .NaturalOWL can also be used as a Prot\u00e9g\u00e9 plug - in .See here for publications describing NaturalOWL .( GPL ) .NLGen .The NLGen natural language generation system applies the SegSim strategy for generating English sentences .Probabilistic inference for sentence construction is based on a statistical analysis of RelEx output .Not to be confused with NLGen2 , below , which uses a different sentence generation theory .", "label": "", "metadata": {}}
{"text": "See demo : Demo of AI Virtual Pet Answering Simple Questions .OpenCCG , the OpenNLP CCG Library ( formerly Grok ) , is both a parser and a realizer for Combinatory Categorial Grammar .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .OpenCCG is implemented in Java , and is freely available under the LGPL .Deliverables from the RAGS project - RAGSOCKS software for interfacing modules using RAGS data representations , example RAGS module ( genetic algorithm based text planner ) and RAGS wrapper for FUF / SURGE . is an ultra - simple Java - based realiser .", "label": "", "metadata": {}}
{"text": "However , because it is so simple , its relatively easy for people to learn how to use it .It has been used by many people in Aberdeen , and also for teaching .It is set up as a Java package , so it can only be used by Java programs .SPUD .SPUD ( Sentence Planner Using Descriptions ) is Matthew Purver 's LTAG - based NLG system .There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .", "label": "", "metadata": {}}
{"text": "The STANDUP project ( System To Augment Non - speakers ' Dialogue Using Puns ) is a collaborative project on generating simple jokes from a graphical user interface appropriate for non - speaking children .The project began in October 2003 and ran until March 2007 .The software was written in Java and is available for Windows and Linux , including source code and database files .Suregen-2 .Suregen is \" a hybrid , ontology based and NLG - oriented formalism for generating text for documents in clinical medicine .\" The system Suregen-2 is written in ( Allegro ) Common Lisp .", "label": "", "metadata": {}}
{"text": "A screencast video shows data being entered into computer forms using mouse and keyboard while a feedback text is continually updated and shown below .( Try playing the AVI file in VLC if you run into problems . )Perhaps this system could be considered an instance of the WYSIWYM approach .Syntactic realization package .( A CommonLisp package providing an interpreter for a functional unification formalism called FUF and SURGE , a large grammar of English written in FUF . )Offers download of SURGE 2.2 .Systemic Unification Reusable Grammar for Spanish is a large scale Spanish grammar allowing systems which already use FUF / SURGE for English NLG to be able to generate syntactically ( and many times semantically ) equivalent text in Spanish when new lexical items are introduced .", "label": "", "metadata": {}}
{"text": "It combines context - free grammars with templates and canned text in a single formalism .Thus the granularity of the language model may depend on the application needs .The system currently runs under Solaris 2.5 .It is available freely under a research license .The natural language generation systems listed below are available for download over the web .If you know of a system which is not listed here , please click on Edit in the upper left corner of this page and add the system yourself .CLINT is a hybrid template / word - based generation system with an example application of business letter generation .", "label": "", "metadata": {}}
{"text": "CRISP .CRISP is Alexander Koller 's NLG system that tries to cast both microplanning and sentence realisation as an AI planning problem .The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .License : LGPL . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .", "label": "", "metadata": {}}
{"text": "Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell .Source code avalailable via darcs . provides a means of exploring large - scale systemic - functional grammars in order to see how they are organized and what kinds of things they cover .It can be used to explore the KPML resources .Downloadable standalone executables of the grammar explorer are available for Windows 95/98/NT .", "label": "", "metadata": {}}
{"text": "HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .The download package consists of the symbolic generator , the forest ranker , and some sample inputs .The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .The forest ranker includes a 250-million word ngram language model ( unigram , bigram , and trigram ) trained on WSJ newspaper text .The symbolic generator is written in LISP and requires a CommonLisp interpreter .The KPML system offers a robust , mature platform for large - scale grammar engineering that is particularly oriented to multilingual grammar development and generation .", "label": "", "metadata": {}}
{"text": "KPML is also used extensively in multilingual text generation research and for teaching .It is based on systemic functional linguistics .Downloadable standalone executables of the system are available for PCs running Windows .The source code is written in ANSI Common Lisp and uses the Common Lisp Interface Manager ( CLIM ) .The system has been compiled and tested [ under Franz Allegro Common Lisp ( 4.2 , 4.3 , 4.3.1 , 5.0 , 6.0 , 7.0 ) for Unix and Franz Allegro Common Lisp 3.0 and Harlequin Lispworks 4.0 , 4.1 , 4.2 for Windows .", "label": "", "metadata": {}}
{"text": "LKB ( Linguistic Knowledge Builder ) is a grammar engineering environment for unification - based formalisms , typically HPSG .It includes a realiser that takes as input Minimal Recursion Semantics ( MRS ) .LKB is implemented in Common Lisp , and is freely available under an open source license .MUG Workbench is a development and debugging tool for Multimodal NLG .The grammar formalism supported is Multimodal Functional Unification Grammar ( MUG ) .The MUG system runs MUG grammars with fixed ( test cases ) and arbitrary input specifications to produce output in a natural language , graphical user interface and possibly in other modes .", "label": "", "metadata": {}}
{"text": "It should help you to learn more about the nature of unification grammars used for parsing or natural language generation .Furthermore , the MUG Workbench is helpful in debugging your grammars .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .Currently supports English and Greek .Extensions for other languages welcome .NaturalOWL can also be used as a Prot\u00e9g\u00e9 plug - in .See here for publications describing NaturalOWL .( GPL ) .NLGen .The NLGen natural language generation system applies the SegSim strategy for generating English sentences .", "label": "", "metadata": {}}
{"text": "Not to be confused with NLGen2 , below , which uses a different sentence generation theory .Java , Apache license .See demo : Demo of AI Virtual Pet Answering Simple Questions .OpenCCG , the OpenNLP CCG Library ( formerly Grok ) , is both a parser and a realizer for Combinatory Categorial Grammar .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .OpenCCG is implemented in Java , and is freely available under the LGPL .Project Reporter generates dynamic web - based project status reports from files created with Microsoft Project or other compatible project management software .", "label": "", "metadata": {}}
{"text": "Commercial product .Implemented in Java .Free 30-day evaluation ; on - line demo on website .Deliverables from the RAGS project - RAGSOCKS software for interfacing modules using RAGS data representations , example RAGS module ( genetic algorithm based text planner ) and RAGS wrapper for FUF / SURGE . is a tool which allows you to graphically annotate the rhetorical structure of your text .The structure can be saved in an xml format , or save eps versions of the structure diagram for inclusion in Latex , etc .Written in Tcl / Tk .", "label": "", "metadata": {}}
{"text": "Its grammatical coverage and syntactic knowledge is minuscule compared to KPML or FUF / SURGE .However , because it is so simple , its relatively easy for people to learn how to use it .It has been used by many people in Aberdeen , and also for teaching .It is set up as a Java package , so it can only be used by Java programs .SPUD .SPUD ( Sentence Planner Using Descriptions ) is Matthew Purver 's LTAG - based NLG system .There are two versions : SPUD version 0.01 was written in SML .", "label": "", "metadata": {}}
{"text": "The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .Suregen-2 .Suregen is \" a hybrid , ontology based and NLG - oriented formalism for generating text for documents in clinical medicine .\" The system Suregen-2 is written in ( Allegro ) Common Lisp .A demo system which runs under Windows is available for download .A screencast video shows data being entered into computer forms using mouse and keyboard while a feedback text is continually updated and shown below .( Try playing the AVI file in VLC if you run into problems . )", "label": "", "metadata": {}}
{"text": "Syntactic realization package .( A CommonLisp package providing an interpreter for a functional unification formalism called FUF and SURGE , a large grammar of English written in FUF . )Offers download of SURGE 2.2 .Systemic Unification Reusable Grammar for Spanish is a large scale Spanish grammar allowing systems which already use FUF / SURGE for English NLG to be able to generate syntactically ( and many times semantically ) equivalent text in Spanish when new lexical items are introduced .SURG - SP makes use of inputs almost identical to the English version Surge 2.3 . is a shallow verbalizer that can be quickly accustomed to new domains and tasks .", "label": "", "metadata": {}}
{"text": "Thus the granularity of the language model may depend on the application needs .The system currently runs under Solaris 2.5 .It is available freely under a research license .The system Suregen-2 is written in ( Allegro ) Common Lisp .Revision as of 07:09 , 12 February 2009 .The natural language generation systems listed below are available for download over the web .If you know of a system which is not listed here , please click on Edit in the upper left corner of this page and add the system yourself . surface realiser for ( Feature - Based Lexicalised )", "label": "", "metadata": {}}
{"text": "Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell .Source code avalailable via darcs . provides a means of exploring large - scale systemic - functional grammars in order to see how they are organized and what kinds of things they cover .It can be used to explore the KPML resources .Downloadable standalone executables of the grammar explorer are available for Windows 95/98/NT .", "label": "", "metadata": {}}
{"text": "HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .The download package consists of the symbolic generator , the forest ranker , and some sample inputs .The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .The forest ranker includes a 250-million word ngram language model ( unigram , bigram , and trigram ) trained on WSJ newspaper text .The symbolic generator is written in LISP and requires a CommonLisp interpreter .The KPML system offers a robust , mature platform for large - scale grammar engineering that is particularly oriented to multilingual grammar development and generation .", "label": "", "metadata": {}}
{"text": "KPML is also used extensively in multilingual text generation research and for teaching .It is based on systemic functional linguistics .Downloadable standalone executables of the system are available for PCs running Windows .The source code is written in ANSI Common Lisp and uses the Common Lisp Interface Manager ( CLIM ) .The system has been compiled and tested under Franz Allegro Common Lisp ( 4.2 , 4.3 , 4.3.1 , 5.0 , 6.0 , 7.0 ) for Unix and Franz Allegro Common Lisp 3.0 and Harlequin Lispworks 4.0 , 4.1 , 4.2 for Windows .It is possible to use the system without the window interface as a generator serving requests for generation across sockets or via files .", "label": "", "metadata": {}}
{"text": "The grammar formalism supported is Multimodal Functional Unification Grammar ( MUG ) .The MUG system runs MUG grammars with fixed ( test cases ) and arbitrary input specifications to produce output in a natural language , graphical user interface and possibly in other modes .MUG Workbench can serve to inspect the data - structures used during generation .It should help you to learn more about the nature of unification grammars used for parsing or natural language generation .Furthermore , the MUG Workbench is helpful in debugging your grammars .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .", "label": "", "metadata": {}}
{"text": "Extensions for other languages welcome .NaturalOWL can also be used as a Prot\u00e9g\u00e9 plug - in .See here for publications describing NaturalOWL .( GPL ) .Project Reporter generates dynamic web - based project status reports from files created with Microsoft Project or other compatible project management software .Reports feature hyperlinked textual descriptions of project elements , as well as coordinated multimodal display with an interactive Gantt chart applet .Commercial product .Implemented in Java .Free 30-day evaluation ; on - line demo on website .Deliverables from the RAGS project - RAGSOCKS software for interfacing modules using RAGS data representations , example RAGS module ( genetic algorithm based text planner ) and RAGS wrapper for FUF / SURGE . is a tool which allows you to graphically annotate the rhetorical structure of your text .", "label": "", "metadata": {}}
{"text": "Written in Tcl / Tk .Runs on any machine . is an ultra - simple Java - based realiser .Its grammatical coverage and syntactic knowledge is minuscule compared to KPML or FUF / SURGE .However , because it is so simple , its relatively easy for people to learn how to use it .It has been used by many people in Aberdeen , and also for teaching .It is set up as a Java package , so it can only be used by Java programs .Suregen-2 .Suregen is \" a hybrid , ontology based and NLG - oriented formalism for generating text for documents in clinical medicine .", "label": "", "metadata": {}}
{"text": "A demo system which runs under Windows is available for download .A screencast video shows data being entered into computer forms using mouse and keyboard while a feedback text is continually updated and shown below .( Try playing the AVI file in VLC if you run into problems . )Perhaps this system could be considered an instance of the WYSIWYM approach .Syntactic realization package .( A CommonLisp package providing an interpreter for a functional unification formalism called FUF and SURGE , a large grammar of English written in FUF . )Offers download of SURGE 2.2 .", "label": "", "metadata": {}}
{"text": "SURG - SP makes use of inputs almost identical to the English version Surge 2.3 . is a shallow verbalizer that can be quickly accustomed to new domains and tasks .It combines context - free grammars with templates and canned text in a single formalism .Thus the granularity of the language model may depend on the application needs .The system currently runs under Solaris 2.5 .It is available freely under a research license .The natural language generation systems listed below are available for download over the web .If you know of a system which is not listed here , please click on Edit in the upper left corner of this page and add the system yourself . surface realiser for ( Feature - Based Lexicalised )", "label": "", "metadata": {}}
{"text": "Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell .Source code avalailable via darcs . provides a means of exploring large - scale systemic - functional grammars in order to see how they are organized and what kinds of things they cover .It can be used to explore the KPML resources .Downloadable standalone executables of the grammar explorer are available for Windows 95/98/NT .", "label": "", "metadata": {}}
{"text": "HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .The download package consists of the symbolic generator , the forest ranker , and some sample inputs .The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .The forest ranker includes a 250-million word ngram language model ( unigram , bigram , and trigram ) trained on WSJ newspaper text .The symbolic generator is written in LISP and requires a CommonLisp interpreter .The KPML system offers a robust , mature platform for large - scale grammar engineering that is particularly oriented to multilingual grammar development and generation .", "label": "", "metadata": {}}
{"text": "KPML is also used extensively in multilingual text generation research and for teaching .It is based on systemic functional linguistics .Downloadable standalone executables of the system are available for PCs running Windows .The source code is written in ANSI Common Lisp and uses the Common Lisp Interface Manager ( CLIM ) .The system has been compiled and tested [ under Franz Allegro Common Lisp ( 4.2 , 4.3 , 4.3.1 , 5.0 , 6.0 , 7.0 ) for Unix and Franz Allegro Common Lisp 3.0 and Harlequin Lispworks 4.0 , 4.1 , 4.2 for Windows .", "label": "", "metadata": {}}
{"text": "LKB ( Linguistic Knowledge Builder ) is a grammar engineering environment for unification - based formalisms , typically HPSG .It includes a realiser that takes as input Minimal Recursion Semantics ( MRS ) .LKB is implemented in Common Lisp , and is freely available under an open source license .MUG Workbench is a development and debugging tool for Multimodal NLG .The grammar formalism supported is Multimodal Functional Unification Grammar ( MUG ) .The MUG system runs MUG grammars with fixed ( test cases ) and arbitrary input specifications to produce output in a natural language , graphical user interface and possibly in other modes .", "label": "", "metadata": {}}
{"text": "It should help you to learn more about the nature of unification grammars used for parsing or natural language generation .Furthermore , the MUG Workbench is helpful in debugging your grammars .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .Currently supports English and Greek .Extensions for other languages welcome .NaturalOWL can also be used as a Prot\u00e9g\u00e9 plug - in .See here for publications describing NaturalOWL .( GPL ) .OpenCCG .OpenCCG , the OpenNLP CCG Library ( formerly Grok ) , is both a parser and a realizer for Combinatory Categorial Grammar .", "label": "", "metadata": {}}
{"text": "The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .OpenCCG is implemented in Java , and is freely available under the LGPL .Project Reporter generates dynamic web - based project status reports from files created with Microsoft Project or other compatible project management software .Reports feature hyperlinked textual descriptions of project elements , as well as coordinated multimodal display with an interactive Gantt chart applet .Commercial product .Implemented in Java .Free 30-day evaluation ; on - line demo on website .Deliverables from the RAGS project - RAGSOCKS software for interfacing modules using RAGS data representations , example RAGS module ( genetic algorithm based text planner ) and RAGS wrapper for FUF / SURGE . is a tool which allows you to graphically annotate the rhetorical structure of your text .", "label": "", "metadata": {}}
{"text": "Written in Tcl / Tk .Runs on any machine . is an ultra - simple Java - based realiser .Its grammatical coverage and syntactic knowledge is minuscule compared to KPML or FUF / SURGE .However , because it is so simple , its relatively easy for people to learn how to use it .It has been used by many people in Aberdeen , and also for teaching .It is set up as a Java package , so it can only be used by Java programs .SPUD .SPUD ( Sentence Planner Using Descriptions ) is Matthew Purver 's LTAG - based NLG system .", "label": "", "metadata": {}}
{"text": "Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .Suregen-2 .Suregen is \" a hybrid , ontology based and NLG - oriented formalism for generating text for documents in clinical medicine .\" The system Suregen-2 is written in ( Allegro ) Common Lisp .A demo system which runs under Windows is available for download .A screencast video shows data being entered into computer forms using mouse and keyboard while a feedback text is continually updated and shown below .", "label": "", "metadata": {}}
{"text": "Perhaps this system could be considered an instance of the WYSIWYM approach .Syntactic realization package .( A CommonLisp package providing an interpreter for a functional unification formalism called FUF and SURGE , a large grammar of English written in FUF . )Offers download of SURGE 2.2 .Systemic Unification Reusable Grammar for Spanish is a large scale Spanish grammar allowing systems which already use FUF / SURGE for English NLG to be able to generate syntactically ( and many times semantically ) equivalent text in Spanish when new lexical items are introduced .SURG - SP makes use of inputs almost identical to the English version Surge 2.3 . is a shallow verbalizer that can be quickly accustomed to new domains and tasks .", "label": "", "metadata": {}}
{"text": "Thus the granularity of the language model may depend on the application needs .The system currently runs under Solaris 2.5 .It is available freely under a research license .Tools . by Cynthia A. Thompson , Raymond J. Mooney - Journal of Artificial Intelligence Research , 2003 . \" ...This paper focuses on a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .The lexicon learned consists of phrases paired with meaning representations .Wolfie is part of an integrated system that ... \" .", "label": "", "metadata": {}}
{"text": "The lexicon learned consists of phrases paired with meaning representations .Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind ( 1996 ) , with results favorable to Wolfie .A second set of experiments demonstrates Wolfie 's ability to scale to larger and more difficult , albeit artificially generated , corpora .", "label": "", "metadata": {}}
{"text": "Active learning methods ( Cohn , Atlas , & Ladner , 1994 ) attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .However , most results to date for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance . \" ...We present a novel method for extracting parallel sub - sentential fragments from comparable , non - parallel bilingual corpora .", "label": "", "metadata": {}}
{"text": "We present a novel method for extracting parallel sub - sentential fragments from comparable , non - parallel bilingual corpora .By analyzing potentially similar sentence pairs using a signal processinginspired approach , we detect which segments of the source sentence are translated into segments in the target sentence , and which are not .This method enables us to extract useful machine translation training data even from very non - parallel corpora , which contain no parallel sentence pairs .We evaluate the quality of the extracted data by showing that it improves the performance of a state - of - the - art statistical machine translation system . \" ...", "label": "", "metadata": {}}
{"text": "We present three new parameter estimation techniques that generalize the standard approach , maximum likel ... \" .This thesis is about estimating probabilistic models to uncover useful hidden structure in data ; specifically , we address the problem of discovering syntactic structure in natural language text .We present three new parameter estimation techniques that generalize the standard approach , maximum likelihood estimation , in different ways .Contrastive estimation maximizes the conditional probability of the observed data given a \" neighborhood \" of implicit negative examples .Skewed deterministic annealing locally maximizes likelihood using a cautious parameter search strategy that starts with an easier optimization problem than likelihood , and iteratively moves to harder problems , culminating in likelihood .", "label": "", "metadata": {}}
{"text": "Our estimation methods do not make use of annotated examples .The models capture dependencies that go beyond the scope of conventional SMT models such as phraseand language models .We show that the models improve translation quality by 1 % in BLEU over a competitive baseline on a large - scale task . by Kristina Toutanova , H. Tolga Ilhan , Christopher D. Manning - In Proc . of EMNLP , 2002 . \" ...This paper describes improved HMM - based word level alignment models for statistical machine translation .We present a method for using part of speech tag information to improve alignment accuracy , and an approach to modeling fertility and correspondence to the empty word in an HMM alignment mo ... \" .", "label": "", "metadata": {}}
{"text": "We present a method for using part of speech tag information to improve alignment accuracy , and an approach to modeling fertility and correspondence to the empty word in an HMM alignment model .We present accuracy results from evaluating Viterbi alignments against human - judged alignments on the Canadian Hansards corpus , as compared to a bigram HMM , and IBM model 4 . \" ...We introduce a simple method to pack words for statistical word alignment .Our goal is to simplify the task of automatic word alignment by packing several consecutive words together when we believe they correspond to a single word in the opposite language .", "label": "", "metadata": {}}
{"text": "We introduce a simple method to pack words for statistical word alignment .Our goal is to simplify the task of automatic word alignment by packing several consecutive words together when we believe they correspond to a single word in the opposite language .This is done using the word aligner itself , i.e. by bootstrapping on its output .We evaluate the performance of our approach on a Chinese - to - English machine translation task , and report a 12.2 % relative increase in BLEU score over a state - of - the art phrasebased SMT system .", "label": "", "metadata": {}}
{"text": "This article considers the task of automatically inducing role - semantic annotations in the FrameNet paradigm for new languages .We propose a general framework that is based on annotation projection , phrased as a graph optimization problem .It is relatively inexpensive and has the potential to reduce ... \" .This article considers the task of automatically inducing role - semantic annotations in the FrameNet paradigm for new languages .We propose a general framework that is based on annotation projection , phrased as a graph optimization problem .It is relatively inexpensive and has the potential to reduce the human effort involved in creating role - semantic resources .", "label": "", "metadata": {}}
{"text": "We provide an experimental evaluation on an English - German parallel corpus which demonstrates the feasibility of inducing high - precision German semantic role annotation both for manually and automatically annotated English data .For example , the IBM models introduced in the seminal work of Brown , Pietra , Pietra , and Mercer ( 1993 ) require eac ... . \" ...Word alignment methods can gain valuable guidance by ensuring that their alignments maintain cohesion with respect to the phrases specified by a monolingual dependency tree .However , this hard constraint can also rule out correct alignments , and its utility decreases as alignment models become more ... \" .", "label": "", "metadata": {}}
{"text": "However , this hard constraint can also rule out correct alignments , and its utility decreases as alignment models become more complex .We use a publicly available structured output SVM to create a max - margin syntactic aligner with a soft cohesion constraint .The resulting aligner is the first , to our knowledge , to use a discriminative learning method to train an ITG bitext parser . \" ...In this paper , we propose a hierarchical phrase alignment method that aims to acquire translation knowledge .Previous methods utilize the correspondence of sub - trees between bilingual parsing trees after determining the parsing result .", "label": "", "metadata": {}}
{"text": "In this paper , we propose a hierarchical phrase alignment method that aims to acquire translation knowledge .Previous methods utilize the correspondence of sub - trees between bilingual parsing trees after determining the parsing result .The method described in this paper combines partial tree candidates , and selects the best sequence of partial trees .Then , a structural similarity measure ( called a ' phrase score ' ) is used for evaluation .Using this method , about twice as many as equivalent phrases were extracted experimentally , and almost no deterioration was observed .In addition , we found that a word alignment function with a high recall rate is suitable for this method . by Adam Lopez , Michael Nossal , Rebecca Hwa , Philip Resnik - In Proceedings of the Workshop on Linguistic Knowledge Acquisition and Representation : Bootstrapping Annotated Language Data , 2002 . \" ...", "label": "", "metadata": {}}
{"text": "Our algorithm utilizes synchronous parsing and takes advantage of existing syntactic annotations .In our experiments the performance of this model is comparable to more complicated iterative methods .We discuss the challenges ... \" .We present a simple , one - pass word alignment algorithm for parallel text .Our algorithm utilizes synchronous parsing and takes advantage of existing syntactic annotations .In our experiments the performance of this model is comparable to more complicated iterative methods .We discuss the challenges and potential benefits of using this model to train syntactic parsers for new languages . ... is also a necessary step for many applications .", "label": "", "metadata": {}}
{"text": "Yarowsky and Ngai ( 2001 ) use an alignment to project part - of - speech ( POS ) tags from English to Chinese , and use the resulting n ..The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .License : LGPL .[ ftp://ftp.cs.cmu.edu/user/ai/new/daydreamer/0new.html DAYDREAMER ] is a computer model of the stream of thought developed at UCLA by Erik T. Mueller from 1983 to 1988 .", "label": "", "metadata": {}}
{"text": "Common lisp source code available under GPL v2 . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .", "label": "", "metadata": {}}
{"text": "Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell .HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .The download package consists of the symbolic generator , the forest ranker , and some sample inputs .The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .", "label": "", "metadata": {}}
{"text": "The symbolic generator is written in LISP and requires a CommonLisp interpreter .kfNgram is a free stand - alone Windows program for linguistic research which generates lists of n - grams in text and HTML files .Here n - gram is understood as a sequence of either n words , where n can be any positive integer , also known as lexical bundles , chains , wordgrams , and , in WordSmith , clusters , or else of n characters , also known as chargrams .LKB is implemented in Common Lisp , and is freely available under an open source license .", "label": "", "metadata": {}}
{"text": "Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .Currently supports English and Greek .Extensions for other languages welcome .( GPL ) .Not to be confused with NLGen2 , below , which uses a different sentence generation theory .Java , Apache license .Not to be confused with NLGen , above , which uses a different sentence generation theory .Java , Apache license .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .", "label": "", "metadata": {}}
{"text": "There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .The project began in October 2003 and ran until March 2007 .The software was written in Java and is available for Windows and Linux , including source code and database files .The system Suregen-2 is written in ( Allegro ) Common Lisp .Revision as of 04:10 , 9 January 2013 .", "label": "", "metadata": {}}
{"text": "If you know of a system which is not listed here , please click on Edit in the upper left corner of this page and add the system yourself .CLINT is a hybrid template / word - based generation system with an example application of business letter generation .The system is written in C++ and runs under Microsoft Windows .CRISP .CRISP is Alexander Koller 's NLG system that tries to cast both microplanning and sentence realisation as an AI planning problem .The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .", "label": "", "metadata": {}}
{"text": "License : LGPL .DAYDREAMER .DAYDREAMER is a computer model of the stream of thought developed at UCLA by Erik T. Mueller from 1983 to 1988 .The generator is located in the file dd_gen . cl .Common lisp source code available under GPL v2 . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .", "label": "", "metadata": {}}
{"text": "Source code avalailable via darcs . provides a means of exploring large - scale systemic - functional grammars in order to see how they are organized and what kinds of things they cover .It can be used to explore the KPML resources .Downloadable standalone executables of the grammar explorer are available for Windows 95/98/NT .These already include a version of the Nigel grammar of English and pre - installed examples .The KPML system offers a robust , mature platform for large - scale grammar engineering that is particularly oriented to multilingual grammar development and generation .", "label": "", "metadata": {}}
{"text": "KPML is also used extensively in multilingual text generation research and for teaching .It is based on systemic functional linguistics .Downloadable standalone executables of the system are available for PCs running Windows .The source code is written in ANSI Common Lisp and uses the Common Lisp Interface Manager ( CLIM ) .The system has been compiled and tested [ under Franz Allegro Common Lisp ( 4.2 , 4.3 , 4.3.1 , 5.0 , 6.0 , 7.0 ) for Unix and Franz Allegro Common Lisp 3.0 and Harlequin Lispworks 4.0 , 4.1 , 4.2 for Windows .", "label": "", "metadata": {}}
{"text": "LKB ( Linguistic Knowledge Builder ) is a grammar engineering environment for unification - based formalisms , typically HPSG .It includes a realiser that takes as input Minimal Recursion Semantics ( MRS ) .LKB is implemented in Common Lisp , and is freely available under an open source license .It includes also a KNOPPIX - based GNU / Linux live - CD , with all the system installed , ready to use .MUG Workbench is a development and debugging tool for Multimodal NLG .The grammar formalism supported is Multimodal Functional Unification Grammar ( MUG ) .", "label": "", "metadata": {}}
{"text": "MUG Workbench can serve to inspect the data - structures used during generation .It should help you to learn more about the nature of unification grammars used for parsing or natural language generation .Furthermore , the MUG Workbench is helpful in debugging your grammars .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .Currently supports English and Greek .Extensions for other languages welcome .NaturalOWL can also be used as a Prot\u00e9g\u00e9 plug - in .See here for publications describing NaturalOWL .", "label": "", "metadata": {}}
{"text": "NLGen .The NLGen natural language generation system applies the SegSim strategy for generating English sentences .Probabilistic inference for sentence construction is based on a statistical analysis of RelEx output .Not to be confused with NLGen2 , below , which uses a different sentence generation theory .Java , Apache license .See demo : Demo of AI Virtual Pet Answering Simple Questions .OpenCCG , the OpenNLP CCG Library ( formerly Grok ) , is both a parser and a realizer for Combinatory Categorial Grammar .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .", "label": "", "metadata": {}}
{"text": "Deliverables from the RAGS project - RAGSOCKS software for interfacing modules using RAGS data representations , example RAGS module ( genetic algorithm based text planner ) and RAGS wrapper for FUF / SURGE . is an ultra - simple Java - based realiser .Its grammatical coverage and syntactic knowledge is minuscule compared to KPML or FUF / SURGE .However , because it is so simple , its relatively easy for people to learn how to use it .It has been used by many people in Aberdeen , and also for teaching .It is set up as a Java package , so it can only be used by Java programs .", "label": "", "metadata": {}}
{"text": "SPUD ( Sentence Planner Using Descriptions ) is Matthew Purver 's LTAG - based NLG system .There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .STANDUP .The STANDUP project ( System To Augment Non - speakers ' Dialogue Using Puns ) is a collaborative project on generating simple jokes from a graphical user interface appropriate for non - speaking children .", "label": "", "metadata": {}}
{"text": "The software was written in Java and is available for Windows and Linux , including source code and database files .Suregen-2 .Suregen is \" a hybrid , ontology based and NLG - oriented formalism for generating text for documents in clinical medicine .\" The system Suregen-2 is written in ( Allegro ) Common Lisp .A demo system which runs under Windows is available for download .A screencast video shows data being entered into computer forms using mouse and keyboard while a feedback text is continually updated and shown below .( Try playing the AVI file in VLC if you run into problems . )", "label": "", "metadata": {}}
{"text": "Syntactic realization package .( A CommonLisp package providing an interpreter for a functional unification formalism called FUF and SURGE , a large grammar of English written in FUF . )Offers download of SURGE 2.2 .Systemic Unification Reusable Grammar for Spanish is a large scale Spanish grammar allowing systems which already use FUF / SURGE for English NLG to be able to generate syntactically ( and many times semantically ) equivalent text in Spanish when new lexical items are introduced .SURG - SP makes use of inputs almost identical to the English version Surge 2.3 . is a shallow verbalizer that can be quickly accustomed to new domains and tasks .", "label": "", "metadata": {}}
{"text": "Thus the granularity of the language model may depend on the application needs .The system currently runs under Solaris 2.5 .It is available freely under a research license .DAYDREAMER ] is a computer model of the stream of thought developed at UCLA by Erik T. Mueller from 1983 to 1988 .The generator is located in the file dd_gen . cl .Common lisp source code available under GPL v2 .FUF ] is available as the [ ftp://ftp.cs.bgu.ac.il/pub/fuf/fuf5.3 . to generate syntactically ( and many times semantically ) equivalent text in Spanish when . surface realiser for ( Feature - Based Lexicalised )", "label": "", "metadata": {}}
{"text": "Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .", "label": "", "metadata": {}}
{"text": "Written in Haskell .HALogen is a general - purpose natural language generation system developed by Irene Langkilde - Geary and Kevin Knight at the USC Information Sciences Institute .The download package consists of the symbolic generator , the forest ranker , and some sample inputs .The symbolic generator includes the Sensus Ontology dictionary ( which is based on WordNet ) .The forest ranker includes a 250-million word ngram language model ( unigram , bigram , and trigram ) trained on WSJ newspaper text .The symbolic generator is written in LISP and requires a CommonLisp interpreter .", "label": "", "metadata": {}}
{"text": "Here n - gram is understood as a sequence of either n words , where n can be any positive integer , also known as lexical bundles , chains , wordgrams , and , in WordSmith , clusters , or else of n characters , also known as chargrams .LKB is implemented in Common Lisp , and is freely available under an open source license .It includes also a KNOPPIX - based GNU / Linux live - CD , with all the system installed , ready to use .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .", "label": "", "metadata": {}}
{"text": "Extensions for other languages welcome .( GPL ) .Not to be confused with NLGen2 , below , which uses a different sentence generation theory .Java , Apache license .Not to be confused with NLGen , above , which uses a different sentence generation theory .Java , Apache license .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .OpenCCG is implemented in Java , and is freely available under the LGPL .There are two versions : SPUD version 0.01 was written in SML .", "label": "", "metadata": {}}
{"text": "The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .The project began in October 2003 and ran until March 2007 .The software was written in Java and is available for Windows and Linux , including source code and database files .The system Suregen-2 is written in ( Allegro ) Common Lisp .Revision as of 11:25 , 7 September 2012 .The natural language generation systems listed below are available for download over the web .If you know of a system which is not listed here , please click on Edit in the upper left corner of this page and add the system yourself .", "label": "", "metadata": {}}
{"text": "The system is written in C++ and runs under Microsoft Windows .CRISP .CRISP is Alexander Koller 's NLG system that tries to cast both microplanning and sentence realisation as an AI planning problem .The code is a mixture of Java and Scala , a scripting language for the Java virtual machine .CRISP comes with its own implementation of GraphPlan , but it can also output plans in PDDL ( \" Planning Domain Definition Language \" , a successor to STRIPS ) for use with other AI planners .License : LGPL .DAYDREAMER .DAYDREAMER is a computer model of the stream of thought developed at UCLA by Erik T. Mueller from 1983 to 1988 .", "label": "", "metadata": {}}
{"text": "Common lisp source code available under GPL v2 . surface realiser for ( Feature - Based Lexicalised )Tree Adjoining Grammar and a flat MRS - like semantics ( sans top handle and underspecification ) .Toy example grammars provided for English and French .Largish core grammar for French is under development ( contact us for details ) .GPL , known to work under Linux and Mac OS X ( potential for making it work on Windows as well ) .Written in Haskell .Source code avalailable via darcs . provides a means of exploring large - scale systemic - functional grammars in order to see how they are organized and what kinds of things they cover .", "label": "", "metadata": {}}
{"text": "Downloadable standalone executables of the grammar explorer are available for Windows 95/98/NT .These already include a version of the Nigel grammar of English and pre - installed examples .The KPML system offers a robust , mature platform for large - scale grammar engineering that is particularly oriented to multilingual grammar development and generation .It is particularly targetted at providing resources for realistic but broad - coverage generation applications , where both flexibility of expression and speed of generation are at issue - for example in online webpage generation or spoken dialogue .KPML is also used extensively in multilingual text generation research and for teaching .", "label": "", "metadata": {}}
{"text": "Downloadable standalone executables of the system are available for PCs running Windows .The source code is written in ANSI Common Lisp and uses the Common Lisp Interface Manager ( CLIM ) .The system has been compiled and tested [ under Franz Allegro Common Lisp ( 4.2 , 4.3 , 4.3.1 , 5.0 , 6.0 , 7.0 ) for Unix and Franz Allegro Common Lisp 3.0 and Harlequin Lispworks 4.0 , 4.1 , 4.2 for Windows .It is possible to use the system without the window interface as a generator serving requests for generation across sockets or via files .", "label": "", "metadata": {}}
{"text": "It includes a realiser that takes as input Minimal Recursion Semantics ( MRS ) .LKB is implemented in Common Lisp , and is freely available under an open source license .It includes also a KNOPPIX - based GNU / Linux live - CD , with all the system installed , ready to use .MUG Workbench is a development and debugging tool for Multimodal NLG .The grammar formalism supported is Multimodal Functional Unification Grammar ( MUG ) .The MUG system runs MUG grammars with fixed ( test cases ) and arbitrary input specifications to produce output in a natural language , graphical user interface and possibly in other modes .", "label": "", "metadata": {}}
{"text": "It should help you to learn more about the nature of unification grammars used for parsing or natural language generation .Furthermore , the MUG Workbench is helpful in debugging your grammars .Generates descriptions of entities and classes from OWL ontologies that have been annotated with linguistic and user modeling resources expressed in RDF .Currently supports English and Greek .Extensions for other languages welcome .NaturalOWL can also be used as a Prot\u00e9g\u00e9 plug - in .See here for publications describing NaturalOWL .( GPL ) .NLGen .The NLGen natural language generation system applies the SegSim strategy for generating English sentences .", "label": "", "metadata": {}}
{"text": "Not to be confused with NLGen2 , below , which uses a different sentence generation theory .Java , Apache license .See demo : Demo of AI Virtual Pet Answering Simple Questions .OpenCCG , the OpenNLP CCG Library ( formerly Grok ) , is both a parser and a realizer for Combinatory Categorial Grammar .It has been used in several dialog systems .The realizer has been enhanced with n - gram models and a supertagging approach called hypertagging .OpenCCG is implemented in Java , and is freely available under the LGPL .Deliverables from the RAGS project - RAGSOCKS software for interfacing modules using RAGS data representations , example RAGS module ( genetic algorithm based text planner ) and RAGS wrapper for FUF / SURGE . is an ultra - simple Java - based realiser .", "label": "", "metadata": {}}
{"text": "However , because it is so simple , its relatively easy for people to learn how to use it .It has been used by many people in Aberdeen , and also for teaching .It is set up as a Java package , so it can only be used by Java programs .SPUD .SPUD ( Sentence Planner Using Descriptions ) is Matthew Purver 's LTAG - based NLG system .There are two versions : SPUD version 0.01 was written in SML .Later versions , known as SPUD lite , are written in Prolog .The small codebase of SPUD lite makes it ideal for teaching , but it is also used in dialog system prototypes .", "label": "", "metadata": {}}
{"text": "The STANDUP project ( System To Augment Non - speakers ' Dialogue Using Puns ) is a collaborative project on generating simple jokes from a graphical user interface appropriate for non - speaking children .The project began in October 2003 and ran until March 2007 .The software was written in Java and is available for Windows and Linux , including source code and database files .Suregen-2 .Suregen is \" a hybrid , ontology based and NLG - oriented formalism for generating text for documents in clinical medicine .\" The system Suregen-2 is written in ( Allegro ) Common Lisp .", "label": "", "metadata": {}}
{"text": "A screencast video shows data being entered into computer forms using mouse and keyboard while a feedback text is continually updated and shown below .( Try playing the AVI file in VLC if you run into problems . )Perhaps this system could be considered an instance of the WYSIWYM approach .Syntactic realization package .( A CommonLisp package providing an interpreter for a functional unification formalism called FUF and SURGE , a large grammar of English written in FUF . )Offers download of SURGE 2.2 .Systemic Unification Reusable Grammar for Spanish is a large scale Spanish grammar allowing systems which already use FUF / SURGE for English NLG to be able to generate syntactically ( and many times semantically ) equivalent text in Spanish when new lexical items are introduced .", "label": "", "metadata": {}}
{"text": "It combines context - free grammars with templates and canned text in a single formalism .Thus the granularity of the language model may depend on the application needs .The system currently runs under Solaris 2.5 .It is available freely under a research license .Publications : Learning for Semantic Parsing .Semantic parsing is the process of mapping a natural - language sentence into a formal representation of its meaning .A shallow form of semantic representation is a case - role analysis ( a.k.a . a semantic role labeling ) , which identifies roles such as agent , patient , source , and destination .", "label": "", "metadata": {}}
{"text": "We have developed methods for automatically learning semantic parsers from annotated corpora using inductive logic programming and other learning methods .We have explored learning semantic parsers for mapping natural - language sentences to case - role analyses , formal database queries , and formal command languages ( i.e. the Robocup coaching language for use in advice - taking learners ) .We have also explored methods for learning semantic lexicons , i.e. databases of words or phrases paired with one or more alternative formal meaning representations .Semantic lexicons can also be learned from semantically annotated sentences and are an important source of knowledge for semantic parsing .", "label": "", "metadata": {}}
{"text": "\" The fish trap exists because of the fish .Once you 've gotten the fish you can forget the trap .The rabbit snare exists because of the rabbit .Once you 've gotten the rabbit , you can forget the snare .Words exist because of meaning .Once you 've gotten the meaning , you can forget the words .Where can I find a man who has forgotten words so I can talk with him ? \" -- The Writings of Chuang Tzu , 4th century B.C. ( Original text in Chinese ) .", "label": "", "metadata": {}}
{"text": "Tutorial on semantic parsing presented at ACL 2010 : .Using natural language to write programs is a touchstone problem for computational linguistics .We present an approach that learns to map natural - language descriptions of simple \" if - then \" rules to executable code .By training and testing on a large corpus of naturally - occurring programs ( called \" recipes \" ) and their natural language descriptions , we demonstrate the ability to effectively map language to code .We compare a number of semantic parsing approaches on the highly noisy training data collected from ordinary users , and find that loosely synchronous systems perform best .", "label": "", "metadata": {}}
{"text": "Intelligent robots frequently need to understand requests from naive users through natural language .Previous approaches either can not account for language variation , e.g. , keyword search , or require gathering large annotated corpora , which can be expensive and can not adapt to new variation .We introduce a dialog agent for mobile robots that understands human instructions through semantic parsing , actively resolves ambiguities using a dialog manager , and incrementally learns from human - robot conversations by inducing training data from user paraphrases .Our dialog agent is implemented and tested both on a web interface with hundreds of users via Mechanical Turk and on a mobile robot over several days , tasked with understanding navigation and delivery requests through natural language in an office environment .", "label": "", "metadata": {}}
{"text": "ML ID : 314 .Semantic Parsing using Distributional Semantics and Probabilistic Logic [ Details ] [ PDF ][Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .We propose a new approach to semantic parsing that is not constrained by a fixed formal ontology and purely logical inference .Instead , we use distributional semantics to generate only the relevant part of an on - the - fly ontology .Sentences and the on - the - fly ontology are represented in probabilistic logic .", "label": "", "metadata": {}}
{"text": "This semantic parsing approach is evaluated on two tasks , Textual Entitlement ( RTE ) and Textual Similarity ( STS ) , both accomplished using inference in probabilistic logic .Experiments show the potential of the approach .ML ID : 301 .Grounded Language Learning Models for Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joo Hyun Kim PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2013 .Communicating with natural language interfaces is a long - standing , ultimate goal for artificial intelligence ( AI ) agents to pursue , eventually .", "label": "", "metadata": {}}
{"text": "In order to ground the meanings of language in a real world situation , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .In this thesis , we focus on devising effective models for simultaneously disambiguating such supervision and learning the underlying semantics of language to map NL sentences into proper logical MRs .We present probabilistic generative models for learning such correspondences along with a reranking model to improve the performance further .", "label": "", "metadata": {}}
{"text": "Next , we describe two PCFG induction models for grounded language learning that extend the previous grounded language learning model of Borschinger , Jones , and Johnson ( 2011 ) .Borschinger et al .'s approach works well in situations of limited ambiguity , such as in the sportscasting task .However , it does not scale well to highly ambiguous situations when there are large sets of potential meaning possibilities for each sentence , such as in the navigation instruction following task first studied by Chen and Mooney ( 2011 ) .The two models we present overcome such limitations by employing a learned semantic lexicon as a basic correspondence unit between NL and MR for PCFG rule generation .", "label": "", "metadata": {}}
{"text": "Although such generative models are easy to implement and are intuitive , it is not always the case that generative models perform best , since they are maximizing the joint probability of data and model , rather than directly maximizing conditional probability .Because we do not have gold - standard references for training a secondary conditional reranker , we incorporate weak supervision of evaluations against the perceptual world during the process of improving model performance .All these approaches are evaluated on the two publicly available domains that have been actively used in many other grounded language learning studies .", "label": "", "metadata": {}}
{"text": "Further possible applications of the presented approaches include summarized machine translation tasks and learning from real perception data assisted by computer vision and robotics .ML ID : 291 .Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .We adapt discriminative reranking to improve the performance of grounded language acquisition , specifically the task of learning to follow navigation instructions from observation .", "label": "", "metadata": {}}
{"text": "Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .ML ID : 286 .Generative Models of Grounded Language Learning with Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joohyun Kim Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , June 2012 . \"Grounded \" language learning is the process of learning the semantics of natural language with respect to relevant perceptual inputs .", "label": "", "metadata": {}}
{"text": "With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .My research focuses on devising effective models for simultaneously disambiguating such supervision and learning the underlying semantics of language to map NL sentences into proper logical forms .Specifically , I will present two probabilistic generative models for learning such correspondences .The models are applied to two publicly available datasets in two different domains , sportscasting and navigation , and compared with previous work on the same data .", "label": "", "metadata": {}}
{"text": "Next , I present a PCFG induction model for grounded language learning that extends the model of Borschinger , Jones , and Johnson ( 2011 ) by utilizing a semantic lexicon .Our model overcomes such limitations by employing a semantic lexicon as the basic building block for PCFG rule generation .Our model also allows for novel combination of MR outputs when parsing novel test sentences .For future work , I propose to extend our PCFG induction model in several ways : improving the lexicon learning algorithm , discriminative re - ranking of top - k parses , and integrating the meaning representation language ( MRL ) grammar for extra structural information .", "label": "", "metadata": {}}
{"text": "ML ID : 273 . \"Grounded \" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts .Borschinger et al .( 2011 ) introduced an approach to grounded language learning based on unsupervised PCFG induction .Their approach works well when each sentence potentially refers to one of a small set of possible meanings , such as in the sportscasting task .However , it does not scale to problems with a large set of potential meanings for each sentence , such as the navigation instruction following task studied by Chen and Mooney ( 2011 ) .", "label": "", "metadata": {}}
{"text": "Experimental results on the navigation task demonstrates the effectiveness of our approach .ML ID : 272 .Learning Language from Ambiguous Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .Building a computer system that can understand human languages has been one of the long - standing goals of artificial intelligence .Currently , most state - of - the - art natural language processing ( NLP ) systems use statistical machine learning methods to extract linguistic knowledge from large , annotated corpora .", "label": "", "metadata": {}}
{"text": "In this thesis , we explore alternative ways of learning which do not rely on direct human supervision .In particular , we draw our inspirations from the fact that humans are able to learn language through exposure to linguistic inputs in the context of a rich , relevant , perceptual environment .We first present a system that learned to sportscast for RoboCup simulation games by observing how humans commentate a game .Using the simple assumption that people generally talk about events that have just occurred , we pair each textual comment with a set of events that it could be referring to .", "label": "", "metadata": {}}
{"text": "The system does not use any prior language knowledge and was able to learn to sportscast in both English and Korean .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans .For the sportscasting task , while each comment could be aligned to one of several events , the level of ambiguity was low enough that we could enumerate all the possible alignments .However , it is not always possible to restrict the set of possible alignments to such limited numbers .Thus , we present another system that allows each sentence to be aligned to one of exponentially many connected subgraphs without explicitly enumerating them .", "label": "", "metadata": {}}
{"text": "By only observing how humans follow navigation instructions , the system was able to infer the corresponding hidden navigation plans and parse previously unseen instructions in new environments for both English and Chinese data .With the rise in popularity of crowdsourcing , we also present results on collecting additional training data using Amazon 's Mechanical Turk .Since our system only needs supervision in the form of language being used in relevant contexts , it is easy for virtually anyone to contribute to the training data .ML ID : 269 .Learning to Interpret Natural Language Navigation Instructions from Observations [ Details ] [ PDF ] [ Slides ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th AAAI Conference on Artificial Intelligence ( AAAI-2011 ) , 859 - 865 , August 2011 .", "label": "", "metadata": {}}
{"text": "We present a system that learns to transform natural - language navigation instructions into executable formal plans .Given no prior linguistic knowledge , the system learns by simply observing how humans follow navigation instructions .The system is evaluated in three complex virtual indoor environments with numerous objects and landmarks .A previously collected realistic corpus of complex English navigation instructions for these environments is used for training and testing data .By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser , the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus .", "label": "", "metadata": {}}
{"text": "Generative Alignment and Semantic Parsing for Learning from Ambiguous Supervision [ Details ] [ PDF ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 23rdInternational Conference on Computational Linguistics ( COLING 2010 ) , 543 - -551 , Beijing , China , August 2010 .We present a probabilistic generative model for learning semantic parsers from ambiguous supervision .Our approach learns from natural language sentences paired with world states consisting of multiple potential logical meaning representations .It disambiguates the meaning of each sentence while simultaneously learning a semantic parser that maps sentences into logical form .", "label": "", "metadata": {}}
{"text": "Experimental results on the Robocup sportscasting corpora in both English and Korean indicate that our approach produces more accurate semantic alignments than existing methods and also produces competitive semantic parsers and improved language generators .ML ID : 251 .Learning for Semantic Parsing Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] [ Slides ] Ruifang Ge PhD Thesis , Department of Computer Science , University of Texas at Austin , Austin , TX , May 2010 .165 pages .Natural language understanding is a sub - field of natural language processing , which builds automated systems to understand natural language .", "label": "", "metadata": {}}
{"text": "Despite its complexity , natural language understanding continues to be a fundamental problem in natural language processing in terms of its theoretical and empirical importance .In recent years , startling progress has been made at different levels of natural language processing tasks , which provides great opportunity for deeper natural language understanding .In this thesis , we focus on the task of semantic parsing , which maps a natural language sentence into a complete , formal meaning representation in a meaning representation language .We present two novel state - of - the - art learned syntax - based semantic parsers using statistical syntactic parsing techniques , motivated by the following two reasons .", "label": "", "metadata": {}}
{"text": "Second , adopting a syntax - based approach allows us to directly leverage the enormous progress made in statistical syntactic parsing .The first semantic parser , SCISSOR , adopts an integrated syntactic - semantic parsing approach , in which a statistical syntactic parser is augmented with semantic parameters to produce a semantically - augmented parse tree ( SAPT ) .This integrated approach allows both syntactic and semantic information to be available during parsing time to obtain an accurate combined syntactic - semantic analysis .The performance of SCISSOR is further improved by using discriminative reranking for incorporating non - local features .", "label": "", "metadata": {}}
{"text": "This pipeline approach allows semantic parsing to conveniently leverage the most recent progress in statistical syntactic parsing .SYNSEM also significantly improves results with limited training data , and is shown to be robust to syntactic errors .ML ID : 246 .Training a Multilingual Sportscaster : Using Perceptual Context to Learn Language [ Details ] [ PDF ] David L. Chen , Joohyun Kim , Raymond J. Mooney Journal of Artificial Intelligence Research , 37:397 - -435 , 2010 .We present a novel framework for learning to interpret and generate language using only perceptual context as supervision .", "label": "", "metadata": {}}
{"text": "Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .The system simultaneously establishes correspondences between individual comments and the events that they describe while building a translation model that supports both parsing and generation .We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .ML ID : 240 .Learning Language from Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen December 2009 .", "label": "", "metadata": {}}
{"text": "Most current natural language processing ( NLP ) systems are built using statistical learning algorithms trained on large annotated corpora which can be expensive and time - consuming to collect .In contrast , humans can learn language through exposure to linguistic input in the context of a rich , relevant , perceptual environment .I will first present a system we completed that can describe events in RoboCup 2D simulation games by learning only from sample language commentaries paired with traces of simulated activities without any language - specific prior knowledge .By applying an EM - like algorithm , the system was able to simultaneously learn a grounded language model as well as align the ambiguous training data .", "label": "", "metadata": {}}
{"text": "For future work , I am proposing to solve the more complex task of learning how to give and receive navigation instructions in a virtual environment .In this setting , each instruction corresponds to a navigation plan that is not directly observable .Since an exponential number of plans can all lead to the same observed actions , we have to learn from compact representations of all valid plans rather than enumerating all possible meanings as we did in the sportscasting task .Initially , the system will passively observe a human giving instruction to another human , and try to learn the correspondences between the instructions and the intended plan .", "label": "", "metadata": {}}
{"text": "ML ID : 239 .We present a new approach to learning a semantic parser ( a system that maps natural language sentences into logical form ) .Unlike previous methods , it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .The resulting system produces improved results on standard corpora on natural language interfaces for database querying and simulated robot control .ML ID : 229 .A Dependency - based Word Subsequence Kernel [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the conference on Empirical Methods in Natural Language Processing ( EMNLP-2008 ) , 400 - -409 , Waikiki , Honolulu , Hawaii , October 2008 .", "label": "", "metadata": {}}
{"text": "The paper gives a very efficient algorithm to compute it .This kernel is also an improvement over the word subsequence kernel because it only counts linguistically meaningful word subsequences which are based on word dependencies .It overcomes some of the difficulties encountered by syntactic tree kernels as well .Experimental results demonstrate the advantage of this kernel over word subsequence and syntactic tree kernels .ML ID : 223 .Transforming Meaning Representation Grammars to Improve Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the Twelfth Conference on Computational Natural Language Learning ( CoNLL-2008 ) , 33 - -40 , Manchester , UK , August 2008 .", "label": "", "metadata": {}}
{"text": "This paper presents approaches for automatically transforming a meaning representation grammar ( MRG ) to conform it better with the natural language semantics .It introduces grammar transformation operators and meaning representation macros which are applied in an error - driven manner to transform an MRG while training a semantic parser learning system .Experimental results show that the automatically transformed MRGs lead to better learned semantic parsers which perform comparable to the semantic parsers learned using manually engineered MRGs .ML ID : 222 .Learning to Sportscast : A Test of Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] [ Video ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .", "label": "", "metadata": {}}
{"text": "The system learns to parse and generate commentaries without any engineered knowledge about the English language .Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games .The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model .We also present a novel algorithm , Iterative Generation Strategy Learning ( IGSL ) , for deciding which events to comment on .Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries .", "label": "", "metadata": {}}
{"text": "Learning for Semantic Parsing with Kernels under Various Forms of Supervision [ Details ] [ PDF ] [ Slides ] Rohit J. Kate PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .159 pages .Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing computing systems that understand natural language input .This thesis presents a new machine learning approach for semantic parsing based on string - kernel - based classification .", "label": "", "metadata": {}}
{"text": "For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .This method does not use any hard - matching rules and unlike previous and other recent methods , does not use grammar rules for natural language , probabilistic or otherwise , which makes it more robust to noisy input .Besides being robust , this approach is also flexible and able to learn under a wide range of supervision , from extra to weaker forms of supervision .", "label": "", "metadata": {}}
{"text": "Its learning algorithm can also take advantage of detailed supervision provided in the form of semantically augmented parse trees .A simple extension using transductive SVMs enables the system to do semi - supervised learning and improve its performance utilizing unannotated sentences which are usually easily available .Another extension involving EM - like retraining makes the system capable of learning under ambiguous supervision in which the correct meaning representation for each sentence is not explicitly given , but instead a set of possible meaning representations is given .This weaker and more general form of supervision is better representative of a natural training environment for a language - learning system requiring minimal human supervision .", "label": "", "metadata": {}}
{"text": "However meaning representation grammars are typically designed to best suit the application which will use the meaning representations with little consideration for how well they correspond to natural language semantics .We present approaches to automatically transform meaning representation grammars to make them more compatible with natural language semantics and hence more suitable for learning semantic parsers .Finally , we also show that ensembles of different semantic parser learning systems can obtain the best overall performance .ML ID : 215 .Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}}
{"text": "Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .One of the main goals of natural language processing ( NLP ) is to build automated systems that can understand and generate human languages .This goal has so far remained elusive .Existing hand - crafted systems can provide in - depth analysis of domain sub - languages , but are often notoriously fragile and costly to build .Existing machine - learned systems are considerably more robust , but are limited to relatively shallow NLP tasks .", "label": "", "metadata": {}}
{"text": "We focus on two important sub - tasks , semantic parsing and tactical generation .The key idea is that both tasks can be treated as the translation between natural languages and formal meaning representation languages , and therefore , can be performed using state - of - the - art statistical machine translation techniques .Specifically , we use a technique called synchronous parsing , which has been extensively used in syntax - based machine translation , as the unifying framework for semantic parsing and tactical generation .The parsing and generation algorithms learn all of their linguistic knowledge from annotated corpora , and can handle natural - language sentences that are conceptually complex .", "label": "", "metadata": {}}
{"text": "Moreover , charts are used as the unifying language - processing architecture for efficient parsing and generation .Therefore , the generators are said to be the inverse of the parsers , an elegant property that has been widely advocated .Furthermore , we show that our parsers and generators can handle formal meaning representation languages containing logical variables , including predicate logic .Our basic semantic parsing algorithm is called WASP .Most of the other parsing and generation algorithms presented in this thesis are extensions of WASP or its inverse .We demonstrate the effectiveness of our parsing and generation algorithms by performing experiments in two real - world , restricted domains .", "label": "", "metadata": {}}
{"text": "Our work is also the first attempt to use the same automatically - learned grammar for both parsing and generation .Unlike previous systems that require manually - constructed grammars and lexicons , our systems require much less knowledge engineering and can be easily ported to other languages and domains .ML ID : 214 .Learning Language Semantics from Ambiguous Supervision [ Details ] [ PDF ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the 22nd Conference on Artificial Intelligence ( AAAI-07 ) , 895 - 900 , Vancouver , Canada , July 2007 .This paper presents a method for learning a semantic parser from ambiguous supervision .", "label": "", "metadata": {}}
{"text": "Such ambiguous supervision models the type of supervision that can be more naturally available to language - learning systems .Given such weak supervision , our approach produces a semantic parser that maps sentences into meaning representations .An existing semantic parsing learning system that can only learn from unambiguous supervision is augmented to handle ambiguous supervision .Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers .ML ID : 200 .Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus [ Details ] [ PDF ] Yuk Wah Wong and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL-2007 ) , Prague , Czech Republic , June 2007 .", "label": "", "metadata": {}}
{"text": "Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with lambda - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain .ML ID : 199 .We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language ( NL ) sentences into their formal meaning representations ( MRs ) .Given NL sentences annotated with their MRs , the initial supervised semantic parser learns the mapping by training Support Vector Machine ( SVM ) classifiers for every production in the MR grammar .", "label": "", "metadata": {}}
{"text": "Experimental results show the improvements obtained over the purely supervised parser , particularly when the annotated training set is small .ML ID : 198 .This paper explores the use of statistical machine translation ( SMT ) methods for tactical natural language generation .We present results on using phrase - based SMT for learning to map meaning representations to natural language .Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations .Finally , we show that hybridizing these two approaches results in still more accurate generation systems .", "label": "", "metadata": {}}
{"text": "ML ID : 197 .Learning for Semantic Parsing [ Details ] [ PDF ] Raymond J. Mooney In A. Gelbukh , editors , Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , 311 - -324 , Mexico City , Mexico , February 2007 .Springer : Berlin , Germany .Invited paper .Semantic parsing is the task of mapping a natural language sentence into a complete , formal meaning representation .Over the past decade , we have developed a number of machine learning methods for inducing semantic parsers by training on a corpus of sentences paired with their meaning representations in a specified formal language .", "label": "", "metadata": {}}
{"text": "This paper reviews our prior work on this topic and discusses directions for future research .ML ID : 196 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .Our system learns these classifiers for every production in the formal language grammar .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .", "label": "", "metadata": {}}
{"text": "Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .Semantic parsing is the task of mapping natural language sentences to complete formal meaning representations .The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .", "label": "", "metadata": {}}
{"text": "We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .ML ID : 190 .We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .The main innovation of WASP is its use of state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}}
{"text": "We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .ML ID : 187 .Learning Semantic Parsers Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] Ruifang Ge 2006 .Most recent work on semantic analysis of natural language has focused on ' ' shallow ' ' semantics such as word - sense disambiguation and semantic role labeling .Our work addresses a more ambitious task we call semantic parsing where natural language sentences are mapped to complete formal meaning representations .", "label": "", "metadata": {}}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .Training the system requires sentences annotated with augmented parse trees .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .We present experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches on long sentences .In the future , we intend to pursue several directions in developing more accurate semantic parsing algorithms and automating the annotation process .This work will involve exploring alternative tree representations for better generalization in parsing .", "label": "", "metadata": {}}
{"text": "We also propose to design a method for automating the SAPT - generation process to alleviate the extra annotation work currently required for training Scissor .Finally , we will investigate the impact of different statistical syntactic parsers on semantic parsing using the automated SAPT - generation process .ML ID : 184 .A Kernel - based Approach to Learning Semantic Parsers [ Details ] [ PDF ] [ Slides ] Rohit J. Kate 2005 .Doctoral Dissertation Proposal , University of Texas at Austin .Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .", "label": "", "metadata": {}}
{"text": "Most of the research in natural language understanding , however , has mainly focused on shallow semantic analysis like case - role analysis or word sense disambiguation .The existing work in semantic parsing either lack the robustness of statistical methods or are applicable only to simple domains where semantic analysis is equivalent to filling a single semantic frame .In this proposal , we present a new approach to semantic parsing based on string - kernel - based classification .Our system takes natural language sentences paired with their formal meaning representations as training data .For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .", "label": "", "metadata": {}}
{"text": "These classifiers are further refined using EM - type iterations based on their performance on the training data .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .Our experiments on two real - world data sets that have deep meaning representations show that this approach compares favorably to other existing systems in terms of accuracy and coverage .For future work , we propose to extend this approach so that it will also exploit the knowledge of natural language syntax by using the existing syntactic parsers .We also intend to broaden the scope of application domains , for example , domains where the sentences are noisy as typical in speech , or domains where corpora available for training do not have natural language sentences aligned with their unique meaning representations .", "label": "", "metadata": {}}
{"text": "Finally , we also plan to investigate ways to combine our semantic parser with some recently developed semantic parsers to form committees in order to get the best overall performance .ML ID : 181 .Learning for Semantic Parsing Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong 2005 .Doctoral Dissertation Proposal , University of Texas at Austin .Semantic parsing is the construction of a complete , formal , symbolic meaning representation of a sentence .While it is crucial to natural language understanding , the problem of semantic parsing has received relatively little attention from the machine learning community .", "label": "", "metadata": {}}
{"text": "Semantic parsing , on the other hand , involves deep semantic analysis in which word senses , semantic roles and other components are combined to produce useful meaning representations for a particular application domain ( e.g. database query ) .Prior research in machine learning for semantic parsing is mainly based on inductive logic programming or deterministic parsing , which lack some of the robustness that characterizes statistical learning .Existing statistical approaches to semantic parsing , however , are mostly concerned with relatively simple application domains in which a meaning representation is no more than a single semantic frame .", "label": "", "metadata": {}}
{"text": "The WASP algorithm learns a semantic parser given a set of sentences annotated with their correct meaning representations .The parsing model is based on the synchronous context - free grammar , where each rule maps a natural - language substring to its meaning representation .The main innovation of the algorithm is its use of state - of - the - art statistical machine translation techniques .A statistical word alignment model is used for lexical acquisition , and the parsing model itself can be seen as an instance of a syntax - based translation model .In initial evaluation on several real - world data sets , we show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .", "label": "", "metadata": {}}
{"text": "This will involve exploiting prior knowledge about the natural - language syntax and the application domain .We also plan to construct a syntax - aware word - based alignment model for lexical acquisition .Finally , we will generalize the learning algorithm to handle context - dependent sentences and accept noisy training data .ML ID : 180 .A Statistical Semantic Parser that Integrates Syntax and Semantics [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of CoNLL-2005 , Ann Arbor , Michigan , June 2005 .We introduce a learning semantic parser , Scissor , that maps natural - language sentences to a detailed , formal , meaning - representation language .", "label": "", "metadata": {}}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .We present experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches .ML ID : 171 .Learning to Transform Natural to Formal Languages [ Details ] [ PDF ] [ Slides ] Rohit J. Kate , Yuk Wah Wong and Raymond J. Mooney In Proceedings of the Twentieth National Conference on Artificial Intelligence ( AAAI-05 ) , 1062 - 1068 , Pittsburgh , PA , July 2005 .", "label": "", "metadata": {}}
{"text": "The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .The learned transformation rules incrementally map a natural - language sentence or its syntactic parse tree into a parse - tree for the target formal language .Experimental results are presented for two corpora , one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents , and another which maps English U.S.-geography questions into a database query language .We show that our method performs overall better and faster than previous approaches in both domains .", "label": "", "metadata": {}}
{"text": "Learning Transformation Rules for Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate , Yuk Wah Wong , Ruifang Ge , and Raymond J. Mooney April 2004 .Unpublished Technical Report .This paper presents an approach for inducing transformation rules that map natural - language sentences into a formal semantic representation language .The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .Patterns for the transformation rules are learned using an induction algorithm based on longest - common - subsequences previously developed for an information extraction system .", "label": "", "metadata": {}}
{"text": "ML ID : 140 .Learning Semantic Parsers : An Important But Under - Studied Problem [ Details ] [ PDF ] Raymond J. Mooney In Papers from the AAAI 2004 Spring Symposium on Language Learning : An Interdisciplinary Perspective , 39 - -44 , Stanford , CA , March 2004 .Computational systems that learn to transform natural - language sentences into semantic representations have important practical applications in building natural - language interfaces .They can also provide insight into important issues in human language acquisition .However , within AI , computational linguistics , and machine learning , there has been relatively little research on developing systems that learn such semantic parsers .", "label": "", "metadata": {}}
{"text": "ML ID : 138 .Integrating Top - down and Bottom - up Approaches in Inductive Logic Programming : Applications in Natural Language Processing and Relational Data Mining [ Details ] [ PDF ] Lappoon R. Tang PhD Thesis , Department of Computer Sciences , University of Texas , Austin , TX , August 2003 .Inductive Logic Programming ( ILP ) is the intersection of Machine Learning and Logic Programming in which the learner 's hypothesis space is the set of logic programs .There are two major ILP approaches : top - down and bottom - up .", "label": "", "metadata": {}}
{"text": "Integrating both approaches has been demonstrated to be more effective .Integrated ILP systems were previously developed for two tasks : learning semantic parsers ( Chillin ) , and mining relational data ( Progol ) .Two new integrated ILP systems for these tasks that overcome limitations of existing methods will be presented .Cocktail is a new ILP algorithm for inducing semantic parsers .For this task , two features of a parse state , functional structure and context , provide important information for disambiguation .A bottom - up approach is more suitable for learning the former , while top - down is better for the latter .", "label": "", "metadata": {}}
{"text": "Experimental results on learning natural - language interfaces for two databases demonstrate that it learns more accurate parsers than Chillin , the previous best method for this task .Beth is a new integrated ILP algorithm for relational data mining .The Inverse Entailment approach to ILP , implemented in the Progol and Aleph systems , starts with the construction of a bottom clause , the most specific hypothesis covering a seed example .When mining relational data with a large number of background facts , the bottom clause becomes intractably large , making learning very inefficient .A top - down approach heuristically guides the construction of clauses without building a bottom clause ; however , it wastes time exploring clauses that cover no positive examples .", "label": "", "metadata": {}}
{"text": "Learning patterns for detecting potential terrorist activity is a current challenge problem for relational data mining .Experimental results on artificial data for this task with over half a million facts show that Beth is significantly more efficient at discovering such patterns than Aleph and m - Foil , two leading ILP systems .ML ID : 130 .Acquiring Word - Meaning Mappings for Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Journal of Artificial Intelligence Research , 18:1 - 44 , 2003 .This paper focuses on a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .", "label": "", "metadata": {}}
{"text": "Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind ( 1996 ) , with results favorable to Wolfie .A second set of experiments demonstrates Wolfie 's ability to scale to larger and more difficult , albeit artificially generated , corpora .In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .", "label": "", "metadata": {}}
{"text": "However , most results to date for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance .ML ID : 121 .Using Multiple Clause Constructors in Inductive Logic Programming for Semantic Parsing [ Details ] [ PDF ] Lappoon R. Tang and Raymond J. Mooney In Proceedings of the 12th European Conference on Machine Learning , 466 - 477 , Freiburg , Germany , 2001 .", "label": "", "metadata": {}}
{"text": "Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method .The task of sematnic parser acquisition in two different domains was attempted and preliminary results demonstrated that such an approach is promising .ML ID : 107 .The development of natural language interfaces ( NLI 's ) for databases has been a challenging problem in natural language processing ( NLP ) since the 1970 's .The need for NLI 's has become more pronounced due to the widespread access to complex databases now available through the Internet .", "label": "", "metadata": {}}
{"text": "We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches .Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic - based approach .ML ID : 102 .Integrating Statistical and Relational Learning for Semantic Parsing : Applications to Learning Natural Language Interfaces for Databases [ Details ] [ PDF ] Lappoon R. Tang May 2000 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .The development of natural language interfaces ( NLIs ) for databases has been an interesting problem in natural language processing since the 70 's .", "label": "", "metadata": {}}
{"text": "However , such systems are difficult to build and must be tailored to each application .A current research topic involves using machine learning methods to automate the development of NLI 's .This proposal presents a method for learning semantic parsers ( systems for mapping natural language to logical form ) that integrates logic - based and probabilistic methods in order to exploit the complementary strengths of these competing approaches .More precisely , an inductive logic programming ( ILP ) method , TABULATE , is developed for learning multiple models that are integrated via linear weighted combination to produce probabilistic models for statistical semantic parsing .", "label": "", "metadata": {}}
{"text": "Future research will further develop this integrated approach and demonstrate its ability to improve the automated development of NLI 's .ML ID : 99 .Learning for Semantic Interpretation : Scaling Up Without Dumbing Down [ Details ] [ PDF ] Raymond J. Mooney In Workshop Notes for the Workshop on Learning Language in Logic , 7 - 15 , Bled , Slovenia , 2000 .Most recent research in learning approaches to natural language have studied fairly ' ' low - level ' ' tasks such as morphology , part - of - speech tagging , and syntactic parsing .", "label": "", "metadata": {}}
{"text": "We have explored the use of inductive logic programming for learning parsers that map natural - language database queries into executable logical form .This work goes against the growing trend in computational linguistics of focusing on shallow but broad - coverage natural language tasks ( ' ' scaling up by dumbing down ' ' ) and instead concerns using logic - based learning to develop narrower , domain - specific systems that perform relatively deep processing .I first present a historical view of the shifting emphasis of research on various tasks in natural language processing and then briefly review our own work on learning for semantic interpretation .", "label": "", "metadata": {}}
{"text": "ML ID : 93 .Automatic Construction of Semantic Lexicons for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixteenth National Conference on Artificial Intelligence ( AAAI-99 ) , 487 - 493 , Orlando , FL , July 1999 .This paper describes a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .The lexicon learned consists of words paired with meaning representations .Wolfie is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .", "label": "", "metadata": {}}
{"text": "The lexicons learned by Wolfie are compared to those acquired by a competing system developed by Siskind .ML ID : 95 .Active Learning for Natural Language Parsing and Information Extraction [ Details ] [ PDF ] Cynthia A. Thompson , Mary Elaine Califf and Raymond J. Mooney In Proceedings of the Sixteenth International Conference on Machine Learning ( ICML-99 ) , 406 - 414 , Bled , Slovenia , June 1999 .In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .", "label": "", "metadata": {}}
{"text": "However , existing results for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to two non - classification tasks in natural language processing : semantic parsing and information extraction .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance for these complex tasks .ML ID : 92 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia Ann Thompson PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , December 1998 .", "label": "", "metadata": {}}
{"text": "Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .A long - standing goal for the field of artificial intelligence is to enable computer understanding of human languages .A core requirement in reaching this goal is the ability to transform individual sentences into a form better suited for computer manipulation .This ability , called semantic parsing , requires several knowledge sources , such as a grammar , lexicon , and parsing mechanism .Building natural language parsing systems by hand is a tedious , error - prone undertaking .", "label": "", "metadata": {}}
{"text": "The result is a combined system that learns semantic lexicons and semantic parsers from one common set of training examples .The input required is a corpus of sentence / representation pairs , where the representations are in the output format desired .A new system , Wolfie , learns semantic lexicons to be used as background knowledge by a previously developed parser acquisition system , Chill .The combined system is tested on a real world domain of answering database queries .We also compare this combination to a combination of Chill with a previously developed lexicon learner , demonstrating superior performance with our system .", "label": "", "metadata": {}}
{"text": "Finally , we test the system on an alternate sentence representation , and on a set of large , artificial corpora with varying levels of ambiguity and synonymy .One difficulty in using machine learning methods for building natural language interfaces is building the required annotated corpus .Therefore , we also address this issue by using active learning to reduce the number of training examples required by both Wolfie and Chill .Experimental results show that the number of examples needed to reach a given level of performance can be significantly reduced with this method .ML ID : 90 .", "label": "", "metadata": {}}
{"text": "Also available as TR AI 98 - 273 , Artificial Intelligence Lab , University of Texas at Austin , May 1998 .This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with meaning representations .WOLFIE is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating WOLFIE 's ability to learn useful lexicons for a database interface in four different natural languages .", "label": "", "metadata": {}}
{"text": "ML ID : 89 .For most natural language processing tasks , a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well - formed strings .This paper reviews our work on using inductive logic programming methods to learn deterministic shift - reduce parsers that translate natural language into a semantic representation .We focus on the task of mapping database queries directly into executable logical form .An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job - search queries .", "label": "", "metadata": {}}
{"text": "An Inductive Logic Programming Method for Corpus - based Parser Construction [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney January 1997 .Unpublished Technical Note .Empirical methods for building natural language systems has become an important area of research in recent years .Most current approaches are based on propositional learning algorithms and have been applied to the problem of acquiring broad - coverage parsers for relatively shallow ( syntactic ) representations .This paper outlines an alternative empirical approach based on techniques from a subfield of machine learning known as Inductive Logic Programming ( ILP ) .", "label": "", "metadata": {}}
{"text": "Using this approach , CHILL is able to learn parsers for a variety of different types of analyses , from traditional syntax trees to more meaning - oriented case - role and database query forms .Experimental evidence shows that CHILL performs comparably to propositional learning systems on similar tasks , and is able to go beyond the broad - but - shallow paradigm and learn mappings directly from sentences into useful semantic representations .In a complete database - query application , parsers learned by CHILL outperform an existing hand - crafted system , demonstrating the promise of empricial techniques for automating the construction certain NLP systems .", "label": "", "metadata": {}}
{"text": "Semantic Lexicon Acquisition for Learning Parsers [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney 1997 .Submitted for review .This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with representations of their meaning , and allows for both synonymy and polysemy .WOLFIE is part of an integrated system that learns to parse novel sentences into their meaning representations .Experimental results are presented that demonstrate WOLFIE 's ability to learn useful lexicons for a realistic domain .", "label": "", "metadata": {}}
{"text": "ML ID : 69 .Inductive Logic Programming for Natural Language Processing [ Details ] [ PDF ] Raymond J. Mooney In Stephen Muggleton , editors , Inductive Logic Programming : Selected papers from the 6th International Workshop , 3 - 22 , Berlin , 1996 .Springer Verlag .This paper reviews our recent work on applying inductive logic programming to the construction of natural language processing systems .We have developed a system , CHILL , that learns a parser from a training corpus of parsed sentences by inducing heuristics that control an initial overly - general shift - reduce parser .", "label": "", "metadata": {}}
{"text": "The ATIS corpus of airline information queries was used to test the acquisition of syntactic parsers , and CHILL performed competitively with recent statistical methods .English queries to a small database on U.S. geography were used to test the acquisition of a complete natural language interface , and the parser that CHILL acquired was more accurate than an existing hand - coded system .The paper also includes a discussion of several issues this work has raised regarding the capabilities and testing of ILP systems as well as a summary of our current research directions .ML ID : 68 .", "label": "", "metadata": {}}
{"text": "AAAI Press / MIT Press .This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural - language interface for database queries .CHILL treats parser acquisition as the learning of search - control rules within a logic program representing a shift - reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge .Starting with a general framework for constructing a suitable logical form , CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries .", "label": "", "metadata": {}}
{"text": "These results demonstrate the ability of a corpus - based system to produce more than purely syntactic representations .They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application .ML ID : 66 .Corpus - Based Lexical Acquisition For Semantic Parsing [ Details ] [ PDF ] Cynthia Thompson February 1996 .Ph.D. proposal .Building accurate and efficient natural language processing ( NLP ) systems is an important and difficult problem .There has been increasing interest in automating this process .The lexicon , or the mapping from words to meanings , is one component that is typically difficult to update and that changes from one domain to the next .", "label": "", "metadata": {}}
{"text": "This proposal describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a lexicon from input consisting of sentences paired with representations of their meanings .Preliminary experimental results show that this system can learn correct and useful mappings .The correctness is evaluated by comparing a known lexicon to one learned from the training input .The usefulness is evaluated by examining the effect of using the lexicon learned by WOLFIE to assist a parser acquisition system , where previously this lexicon had to be hand - built .Future work in the form of extensions to the algorithm , further evaluation , and possible applications is discussed .", "label": "", "metadata": {}}
{"text": "Lexical Acquisition : A Novel Machine Learning Problem [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Technical Report , Artificial Intelligence Lab , University of Texas at Austin , January 1996 .This paper defines a new machine learning problem to which standard machine learning algorithms can not easily be applied .The problem occurs in the domain of lexical acquisition .The ambiguous and synonymous nature of words causes the difficulty of using standard induction techniques to learn a lexicon .Additionally , negative examples are typically unavailable or difficult to construct in this domain .", "label": "", "metadata": {}}
{"text": "Future work includes extending the algorithm and performing tests on a more realistic corpus .ML ID : 56 .Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers [ Details ] [ PDF ] John M. Zelle PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , 1995 .Designing computer systems to understand natural language input is a difficult task .In recent years there has been considerable interest in corpus - based methods for constructing natural language parsers .These empirical approaches replace hand - crafted grammars with linguistic models acquired through automated training over language corpora .", "label": "", "metadata": {}}
{"text": "This dissertation presents an alternative approach based on techniques from a subfield of machine learning known as inductive logic programming ( ILP ) .ILP , which investigates the learning of relational ( first - order ) rules , provides an empirical method for acquiring knowledge within traditional , symbolic parsing frameworks .This dissertation details the architecture , implementation and evaluation of CHILL a computer system for acquiring natural language parsers by training over corpora of parsed text .CHILL treats language acquisition as the learning of search - control rules within a logic program that implements a shift - reduce parser .", "label": "", "metadata": {}}
{"text": "Both the control - rule framework and the induction algorithm are crucial to CHILL 's success .The main advantage of CHILL over propositional counterparts is its flexibility in handling varied representations .CHILL has produced parsers for various analyses including case - role mapping , detailed syntactic parse trees , and a logical form suitable for expressing first - order database queries .All of these tasks are accomplished within the same framework , using a single , general learning method that can acquire new syntactic and semantic categories for resolving ambiguities .Experimental evidence from both aritificial and real - world corpora demonstrate that CHILL learns parsers as well or better than previous artificial neural network or probablistic approaches on comparable tasks .", "label": "", "metadata": {}}
{"text": "These results support the claim that ILP techniques as implemented in CHILL represent a viable alternative with significant potential advantages over neural - network , propositional , and probablistic approaches to empirical parser construction .ML ID : 48 .This paper presents results from recent experiments with CHILL , a corpus - based parser acquisition system .CHILL treats grammar acquisition as the learning of search - control rules within a logic program .Unlike many current corpus - based approaches that use propositional or probabilistic learning algorithms , CHILL uses techniques from inductive logic programming ( ILP ) to learn relational representations .", "label": "", "metadata": {}}
{"text": "The results show that ILP techniques , as employed in CHILL , are a viable alternative to propositional methods and that the control - rule framework is fundamental to CHILL 's success .ML ID : 47 .Acquisition of a Lexicon from Semantic Representations of Sentences [ Details ] [ PDF ] Cynthia A. Thompson In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL-95 ) , 335 - 337 , Cambridge , MA , 1995 .A system , WOLFIE , that acquires a mapping of words to their semantic representation is presented and a preliminary evaluation is performed .", "label": "", "metadata": {}}
{"text": "The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears .Some promising experimental results on a non - artificial data set are presented .ML ID : 45 .Learning Semantic Grammars With Constructive Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In Proceedings of the 11th National Conference on Artificial Intelligence , 817 - 822 , 1993 .Menlo Park , CA : AAAI Press .Automating the construction of semantic grammars is a difficult and interesting problem for machine learning .", "label": "", "metadata": {}}
{"text": "Appropriate control rules are learned using a new first - order induction algorithm that automatically invents useful syntactic and semantic categories .Empirical results show that the learned parsers generalize well to novel sentences and out - perform previous approaches based on connectionist techniques .ML ID : 25 .Learning Search - Control Heuristics for Logic Programs : Applications to Speedup Learning and Language Acquisition [ Details ] [ PDF ] John M. Zelle March 1993 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .This paper presents a general framework , learning search - control heuristics for logic programs , which can be used to improve both the efficiency and accuracy of knowledge - based systems expressed as definite - clause logic programs .", "label": "", "metadata": {}}
{"text": "Two specific applications of this framework are detailed : dynamic optimization of Prolog programs ( improving efficiency ) and natural language acquisition ( improving accuracy ) .In the area of program optimization , a prototype system , DOLPHIN , is able to transform some intractable specifications into polynomial - time algorithms , and outperforms competing approaches in several benchmark speedup domains .A prototype language acquisition system , CHILL , is also described .It is capable of automatically acquiring semantic grammars , which uniformly incorprate syntactic and semantic constraints to parse sentences into case - role representations .", "label": "", "metadata": {}}
{"text": "Planned extensions of the general framework and the specific applications as well as plans for further evaluation are also discussed .11:00 - 11:30 Summarization with a Joint Model for Sentence Extraction and Compression Andre Martins and Noah Smith .11:30 - 12:00 A Scalable Global Model for Summarization Dan Gillick and Benoit Favre .12:00 - 12:30 Bounding and Comparing Methods for Correlation Clustering Beyond ILP Micha Elsner and Warren Schudy .12:30 - 2:00 Lunch break .2:45 - 3:15 A New Objective Function for Word Alignment Tugba Bodrumlu , Kevin Knight and Sujith Ravi .3:15 - 3:30 A Constraint Programming Approach to Probabilistic Syntactic Processing Irene Langkilde - Geary .", "label": "", "metadata": {}}
{"text": "Constrained Conditional Models : Learning and Inference in Natural Language Understanding Dan Roth .Structured learning problems provide one such example , but we are interested in a broader setting where multiple models are involved and it may not be ideal , or possible , to learn them jointly .I will present work on Constrained Conditional Models ( CCMs ) , a framework that augments probabilistic models with declarative constraints as a way to support decisions in an expressive output space while maintaining modularity and tractability of training .The focus will be on discussing training and inference paradigms for Constrained Conditional Models , with examples drawn from natural language understanding tasks such as semantic role learning , information extraction tasks , and transliteration .", "label": "", "metadata": {}}
{"text": "Many problems in NLP can be cast as structured prediction .Yet recent research shows that significant improvements can be made by modeling global phenomena .Since exact inference with arbitrary features is generally intractable , this raises multiple questions : which approximate algorithm is the best for each task ?What is the effect of approximate inference when used as a subroutine during learning ?We establish risk bounds for approximate max - margin learning via LP relaxations of the loss - augmented inference problem , and propose a new online discriminative learning algorithm that learns to penalize \" time - consuming \" models .", "label": "", "metadata": {}}
{"text": "We then apply these techniques to the problem of nonprojective dependency parsing , for which we present a novel ILP formulation with a polynomial number of variables and constraints in the size of the sentence .It can learn features that model correlations among neighboring arcs ( siblings and grand - parents ) , word valency , and tendencies toward nearly - projective parses .We evaluate the performance of our parser on data in several natural languages , achieving improvements over existing state - of - the - art methods .This is joint work with Eric Xing and portions of it will be published at ICML 2009 and ACL - IJCNLP 2009 .", "label": "", "metadata": {}}
{"text": "Formulating problems using ILP has several advantages .It allows us to focus on the modelling of problems , rather than engineering new search algorithms ; provides the opportunity to incorporate generic global constraints ; and guarantees exact inference .This and the availability of off - the - shelf solvers has lead to a large variety of natural language processing tasks being formulated in the ILP framework , including semantic role labelling , syntactic parsing , summarisation and joint information extraction .The use of ILP brings many benefits and opportunities but there are still challenges for the community ; these include : formulations of new applications , dealing with large - scale problems and understanding the interaction between learning and inference at training and decision time .", "label": "", "metadata": {}}
{"text": "We are interested in a broad range of topics including , but not limited to : .Novel ILP formulations of NLP tasks .This includes : the introduction of ILP formulations of tasks yet to be tackled within the framework ; and novel formulations , such as equivalent LP relaxations , that are more efficient to process than previous formulations .Learning and Inference .The utility of global hard and soft constraints in NLP .Sometimes constraints do not increase accuracy ( and can even decrease it ) , when and why do global constraints become useful ?", "label": "", "metadata": {}}
{"text": "Formulating and solving large NLP problems .Applying ILP to hard problems ( such as parsing , machine translation and joint inference for several NLP tasks at once ) often results in very large formulations which can be impossible to solve directly by the ILP engine .This may require exploring different ILP solving methods ( such as , approximate ILP solvers / methods ) or cutting plane and pricing techniques .Alternative declarative approaches .A variety of other modelling frameworks exist , of which ILP is just one instance .Using other approaches , such as weighted MAX - SAT , Constraint Satisfaction Problems ( CSP ) or Markov Networks , could be more suitable than ILP in some cases .", "label": "", "metadata": {}}
{"text": "First Order Modelling Languages .ILP , and other essentially propositional languages , require the creation of wrapper code to generate an ILP formulation for each problem instance .First ( Higher )Order languages , such as Learning Based Java and Markov Logic , reduce this overhead and can also aid the solver to be more efficient .Moreover , with such languages the automatic exploration of the model space is easier .Submission Information .We encourage submissions addressing the above questions and topics or other relevant issues .Authors are invited to submit a full paper of up to 8 pages ( with up to 1 additional page for references ) , or an abstract of up to 2 pages .", "label": "", "metadata": {}}
